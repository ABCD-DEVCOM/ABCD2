<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title></title>
</head>
<body><div class="page"><p/>
</div>
<div class="page"><p/>
<p>Physics of Semiconductor Devices</p>
<p/>
</div>
<div class="page"><p/>
<p>Massimo Rudan
</p>
<p>Physics of Semiconductor
Devices
</p>
<p>2123</p>
<p/>
</div>
<div class="page"><p/>
<p>Massimo Rudan
University of Bologna
Bologna
Italy
</p>
<p>ISBN 978-1-4939-1150-9 ISBN 978-1-4939-1151-6 (eBook)
DOI 10.1007/978-1-4939-1151-6
Springer New York Heidelberg Dordrecht London
</p>
<p>Library of Congress Control Number: 2014953969
</p>
<p>&copy; Springer Science+Business Media New York 2015
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microfilms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology
now known or hereafter developed. Exempted from this legal reservation are brief excerpts in connection
with reviews or scholarly analysis or material supplied specifically for the purpose of being entered and
executed on a computer system, for exclusive use by the purchaser of the work. Duplication of this
publication or parts thereof is permitted only under the provisions of the Copyright Law of the Publisher&rsquo;s
location, in its current version, and permission for use must always be obtained from Springer. Permissions
for use may be obtained through RightsLink at the Copyright Clearance Center. Violations are liable to
prosecution under the respective Copyright Law.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a specific statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
While the advice and information in this book are believed to be true and accurate at the date of publication,
neither the authors nor the editors nor the publisher can accept any legal responsibility for any errors or
omissions that may be made. The publisher makes no warranty, express or implied, with respect to the
material contained herein.
</p>
<p>Printed on acid-free paper
</p>
<p>Springer is part of Springer Science+Business Media (www.springer.com)</p>
<p/>
</div>
<div class="page"><p/>
<p>To Rossella and Morgana</p>
<p/>
</div>
<div class="page"><p/>
<p>Preface
</p>
<p>This volume originates from the lectures on Solid-State Electronics and Microelec-
tronics that I have been giving since 1978 at the School of Engineering of the
University of Bologna. Its scope is to provide the reader with a book that, start-
ing from the elementary principles of classical mechanics and electromagnetism,
introduces the concepts of quantum mechanics and solid-state theory, and describes
the basic physics of semiconductors including the hierarchy of transport models,
ending up with the standard mathematical model of semiconductor devices and the
analysis of the behavior of basic devices. The ambition of the work has been to
write a book, self contained as far as possible, that would be useful for both students
and researchers; to this purpose, a strong effort has been made to elucidate phys-
ical concepts, mathematical derivations, and approximation levels, without being
verbose.
</p>
<p>The book is divided into eight parts. Part I deals with analytical mechanics and
electromagnetism; purposedly, the material is not given in the form of a resum&eacute;:
quantum-mechanics and solid-state theory&rsquo;s concepts are so richly intertwined with
the classical ones that presenting the latter in an abridged form may make the read-
ing unwieldy and the connections more difficult to establish. Part II provides the
introductory concepts of statistical mechanics and quantum mechanics, followed
by the description of the general methods of quantum mechanics. The problem of
bridging the classical concepts with the quantum ones is first tackled using the his-
torical perspective, covering the years from 1900 to 1926. The type of statistical
description necessary for describing the experiments, and the connection with the
limiting case of the same experiments involving massive bodies, is related to the
properties of the doubly-stochastic matrices. Part III illustrates a number of applica-
tions of the Schr&ouml;dinger equation: elementary cases, solutions by factorization, and
time-dependent perturbation theory. Part IV analyzes the properties of systems of
particles, with special attention to those made of identical particles, and the methods
for separating the equations. The concepts above are applied in Part V to the analysis
of periodic structures, with emphasis to crystals of the cubic type and to silicon in
particular, which, since the late 1960s, has been and still is the most important ma-
terial for the fabrication of integrated circuits. Part VI illustrates the single-electron
dynamics in a periodic structure and derives the semiclassical Boltzmann Transport
</p>
<p>vii</p>
<p/>
</div>
<div class="page"><p/>
<p>viii Preface
</p>
<p>Equation; from the latter, the hydrodynamic and drift-diffusion models of semicon-
ductor devices are obtained using the moments expansion. The drift-diffusion model
is used in Part VII to work out analytically the electrical characteristics for the ba-
sic devices of the bipolar and MOS type. Finally, Part VIII presents a collection of
items which, although important per se, are not in the book&rsquo;s mainstream: some of
the fabrication-process steps of integrated circuits (thermal diffusion, thermal ox-
idation, layer deposition, epitaxy), and methods for measuring the semiconductor
parameters.
</p>
<p>In the preparation of the book I have been helped by many colleagues. I wish
to thank, in particular, Giorgio Baccarani, Carlo Jacoboni, and Rossella Brunetti,
who gave me important suggestions about the matter&rsquo;s distribution in the book, read
the manuscript and, with their observations, helped me to clarify and improve the
text; I wish also to thank, for reading the manuscript and giving me their comments,
Giovanni Betti Beneventi, Fabrizio Buscemi, Gaetano D&rsquo;Emma, Antonio Gnudi,
Elena Gnani, Enrico Piccinini, Susanna Reggiani, Paolo Spadini.
</p>
<p>Last, but not least, I wish to thank the students, undergraduate, graduate, and
postdocs, who for decades have accompanied my teaching and research activity with
stimulating curiosity. Many comments, exercises, and complements of this book are
the direct result of questions and comments that came from them.
</p>
<p>Bologna Massimo Rudan
September 2014</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents
</p>
<p>Part I A Review of Analytical Mechanics and Electromagnetism
</p>
<p>1 Analytical Mechanics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.2 Variational Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.3 Lagrangian Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
</p>
<p>1.3.1 Force Deriving from a Potential Energy . . . . . . . . . . . . . 7
1.3.2 Electromagnetic Force . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
1.3.3 Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
1.3.4 Hamilton Principle&mdash;Synchronous Trajectories . . . . . . . 10
</p>
<p>1.4 Generalized Coordinates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.5 Hamiltonian Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.6 Hamilton Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.7 Time&ndash;Energy Conjugacy&mdash;Hamilton&ndash;Jacobi Equation . . . . . . . . . 15
1.8 Poisson Brackets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
1.9 Phase Space and State Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
1.10 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
</p>
<p>1.10.1 Higher-Order Variational Calculus . . . . . . . . . . . . . . . . . . 19
1.10.2 Lagrangian Invariance and Gauge Invariance . . . . . . . . . 20
1.10.3 Variational Calculus with Constraints . . . . . . . . . . . . . . . 20
1.10.4 An Interesting Example of Extremum Equation . . . . . . . 21
1.10.5 Constant-Energy Surfaces . . . . . . . . . . . . . . . . . . . . . . . . . 23
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
</p>
<p>2 Coordinate Transformations and Invariance Properties . . . . . . . . . . . 25
2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
2.2 Canonical Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
2.3 An Application of the Canonical Transformation . . . . . . . . . . . . . . 29
2.4 Separation&mdash;Hamilton&rsquo;s Characteristic Function . . . . . . . . . . . . . . 30
2.5 Phase Velocity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.6 Invariance Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
</p>
<p>2.6.1 Time Reversal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
2.6.2 Translation of Time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
</p>
<p>ix</p>
<p/>
</div>
<div class="page"><p/>
<p>x Contents
</p>
<p>2.6.3 Translation of the Coordinates . . . . . . . . . . . . . . . . . . . . . 33
2.6.4 Rotation of the Coordinates . . . . . . . . . . . . . . . . . . . . . . . . 34
</p>
<p>2.7 Maupertuis Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
2.8 Spherical Coordinates&mdash;Angular Momentum . . . . . . . . . . . . . . . . . 36
2.9 Linear Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
2.10 Action-Angle Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
2.11 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
</p>
<p>2.11.1 Infinitesimal Canonical Transformations . . . . . . . . . . . . . 41
2.11.2 Constants of Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
</p>
<p>3 Applications of the Concepts of Analytical Mechanics . . . . . . . . . . . . . 43
3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
3.2 Particle in a Square Well . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
3.3 Linear Harmonic Oscillator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
3.4 Central Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
3.5 Two-Particle Collision . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
3.6 Energy Exchange in the Two-Particle Collision . . . . . . . . . . . . . . . 49
3.7 Central Motion in the Two-Particle Interaction . . . . . . . . . . . . . . . . 51
3.8 Coulomb Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
3.9 System of Particles near an Equilibrium Point . . . . . . . . . . . . . . . . 53
3.10 Diagonalization of the Hamiltonian Function . . . . . . . . . . . . . . . . . 55
3.11 Periodic Potential Energy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
3.12 Energy-Momentum Relation in a Periodic Potential Energy . . . . . 60
3.13 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
</p>
<p>3.13.1 Comments on the Linear Harmonic Oscillator . . . . . . . . 61
3.13.2 Degrees of Freedom and Coordinate Separation . . . . . . . 61
3.13.3 Comments on the Normal Coordinates . . . . . . . . . . . . . . 62
3.13.4 Areal Velocity in the Central-Motion Problem . . . . . . . . 63
3.13.5 Initial Conditions in the Central-Motion Problem . . . . . 64
3.13.6 The Coulomb Field in the Attractive Case . . . . . . . . . . . . 65
3.13.7 Dynamic Relations of Special Relativity . . . . . . . . . . . . . 67
3.13.8 Collision of Relativistic Particles . . . . . . . . . . . . . . . . . . . 68
3.13.9 Energy Conservation in Charged-Particles&rsquo; Interaction . 70
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
</p>
<p>4 Electromagnetism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
4.2 Extension of the Lagrangian Formalism . . . . . . . . . . . . . . . . . . . . . 71
4.3 Lagrangian Function for the Wave Equation . . . . . . . . . . . . . . . . . . 74
4.4 Maxwell Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
4.5 Potentials and Gauge Transformations . . . . . . . . . . . . . . . . . . . . . . 77
4.6 Lagrangian Density for the Maxwell Equations . . . . . . . . . . . . . . . 79
4.7 Helmholtz Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
4.8 Helmholtz Equation in a Finite Domain . . . . . . . . . . . . . . . . . . . . . 81</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents xi
</p>
<p>4.9 Solution of the Helmholtz Equation in an Infinite Domain . . . . . . 82
4.10 Solution of the Wave Equation in an Infinite Domain . . . . . . . . . . 83
4.11 Lorentz Force . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.12 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
</p>
<p>4.12.1 Invariance of the Euler Equations . . . . . . . . . . . . . . . . . . . 85
4.12.2 Wave Equations for the E and B Fields . . . . . . . . . . . . . . 85
4.12.3 Comments on the Boundary-Value Problem . . . . . . . . . . 86
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86
</p>
<p>5 Applications of the Concepts of Electromagnetism . . . . . . . . . . . . . . . . 87
5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
5.2 Potentials Generated by a Point-Like Charge . . . . . . . . . . . . . . . . . 87
5.3 Energy Continuity&mdash;Poynting Vector . . . . . . . . . . . . . . . . . . . . . . . . 89
5.4 Momentum Continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
5.5 Modes of the Electromagnetic Field . . . . . . . . . . . . . . . . . . . . . . . . 91
5.6 Energy of the Electromagnetic Field in Terms of Modes . . . . . . . . 93
5.7 Momentum of the Electromagnetic Field in Terms of Modes . . . . 95
5.8 Modes of the Electromagnetic Field in an Infinite Domain . . . . . . 96
5.9 Eikonal Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
5.10 Fermat Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
5.11 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
</p>
<p>5.11.1 Fields Generated by a Point-Like Charge . . . . . . . . . . . . 99
5.11.2 Power Radiated by a Point-Like Charge . . . . . . . . . . . . . 101
5.11.3 Decay of Atoms According to the Classical Model . . . . 102
5.11.4 Comments about the Field&rsquo;s Expansion into Modes . . . . 104
5.11.5 Finiteness of the Total Energy . . . . . . . . . . . . . . . . . . . . . . 105
5.11.6 Analogies between Mechanics and Geometrical Optics 106
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
</p>
<p>Part II Introductory Concepts to Statistical and Quantum Mechanics
</p>
<p>6 Classical Distribution Function and Transport Equation . . . . . . . . . . . 111
6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
6.2 Distribution Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
6.3 Statistical Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
6.4 Maxwell-Boltzmann Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
6.5 Boltzmann Transport Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
6.6 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
</p>
<p>6.6.1 Momentum and Angular Momentum at Equilibrium . . . 120
6.6.2 Averages Based on the Maxwell-Boltzmann Distribution 121
6.6.3 Boltzmann&rsquo;s H-Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . 123
6.6.4 Paradoxes &mdash; Kac-Ring Model . . . . . . . . . . . . . . . . . . . . . 124
6.6.5 Equilibrium Limit of the Boltzmann Transport Equation 125
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127</p>
<p/>
</div>
<div class="page"><p/>
<p>xii Contents
</p>
<p>7 From Classical Mechanics to Quantum Mechanics . . . . . . . . . . . . . . . . 129
7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
7.2 Planetary Model of the Atom . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
7.3 Experiments Contradicting the Classical Laws . . . . . . . . . . . . . . . . 134
7.4 Quantum Hypotheses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
</p>
<p>7.4.1 Planck&rsquo;s Solution of the Black-Body Problem . . . . . . . . 141
7.4.2 Einstein&rsquo;s Solution of the Photoelectric Effect . . . . . . . . 142
7.4.3 Explanation of the Compton Effect . . . . . . . . . . . . . . . . . 142
7.4.4 Bohr&rsquo;s Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
7.4.5 De Broglie&rsquo;s Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . 145
</p>
<p>7.5 Heuristic Derivation of the Schr&ouml;dinger Equation . . . . . . . . . . . . . 147
7.6 Measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
</p>
<p>7.6.1 Probabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
7.6.2 Massive Bodies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
7.6.3 Need of a Description of Probabilities . . . . . . . . . . . . . . . 153
</p>
<p>7.7 Born&rsquo;s Interpretation of the Wave Function . . . . . . . . . . . . . . . . . . . 153
7.8 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
</p>
<p>7.8.1 Core Electrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
</p>
<p>8 Time-Independent Schr&ouml;dinger Equation . . . . . . . . . . . . . . . . . . . . . . . . 155
8.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
8.2 Properties of the Time-Independent Schr&ouml;dinger Equation . . . . . . 155
</p>
<p>8.2.1 Schr&ouml;dinger Equation for a Free Particle . . . . . . . . . . . . . 157
8.2.2 Schr&ouml;dinger Equation for a Particle in a Box . . . . . . . . . 158
8.2.3 Lower Energy Bound in the Schr&ouml;dinger Equation . . . . 159
</p>
<p>8.3 Norm of a Function&mdash;Scalar Product . . . . . . . . . . . . . . . . . . . . . . . . 160
8.3.1 Adjoint Operators and Hermitean Operators . . . . . . . . . . 162
</p>
<p>8.4 Eigenvalues and Eigenfunctions of an Operator . . . . . . . . . . . . . . . 162
8.4.1 Eigenvalues of Hermitean Operators . . . . . . . . . . . . . . . . 163
8.4.2 Gram&ndash;Schmidt Orthogonalization . . . . . . . . . . . . . . . . . . 164
8.4.3 Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
8.4.4 Parseval Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
</p>
<p>8.5 Hamiltonian Operator and Momentum Operator . . . . . . . . . . . . . . 168
8.6 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
</p>
<p>8.6.1 Examples of Hermitean Operators . . . . . . . . . . . . . . . . . . 169
8.6.2 A Collection of Operators&rsquo; Definitions and Properties . . 170
8.6.3 Examples of Commuting Operators . . . . . . . . . . . . . . . . . 173
8.6.4 Momentum and Energy of a Free Particle . . . . . . . . . . . . 173
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
</p>
<p>9 Time-Dependent Schr&ouml;dinger Equation . . . . . . . . . . . . . . . . . . . . . . . . . . 175
9.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
9.2 Superposition Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
9.3 Time-Dependent Schr&ouml;dinger Equation . . . . . . . . . . . . . . . . . . . . . . 178
9.4 Continuity Equation and Norm Conservation . . . . . . . . . . . . . . . . . 179</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents xiii
</p>
<p>9.5 Hamiltonian Operator of a Charged Particle . . . . . . . . . . . . . . . . . . 180
9.6 Approximate Form of the Wave Packet for a Free Particle . . . . . . 181
9.7 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
</p>
<p>9.7.1 About the Units of the Wave Function . . . . . . . . . . . . . . . 183
9.7.2 An Application of the Semiclassical Approximation . . . 183
9.7.3 Polar Form of the Schr&ouml;dinger Equation . . . . . . . . . . . . . 184
9.7.4 Effect of a Gauge Transformation on the Wave Function 185
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
</p>
<p>10 General Methods of Quantum Mechanics . . . . . . . . . . . . . . . . . . . . . . . . 187
10.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
10.2 General Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
10.3 Separable Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
10.4 Eigenfunctions of Commuting Operators . . . . . . . . . . . . . . . . . . . . 190
10.5 Expectation Value and Uncertainty . . . . . . . . . . . . . . . . . . . . . . . . . 192
10.6 Heisenberg Uncertainty Relation . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
10.7 Time Derivative of the Expectation Value . . . . . . . . . . . . . . . . . . . . 194
10.8 Ehrenfest Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
10.9 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
</p>
<p>10.9.1 Minimum-Uncertainty Wave Function . . . . . . . . . . . . . . . 196
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
</p>
<p>Part III Applications of the Schr&ouml;dinger Equation
</p>
<p>11 Elementary Cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
11.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
11.2 Step-Like Potential Energy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
</p>
<p>11.2.1 Case A: 0 &lt; E &lt; V0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
11.2.2 Case B: E &gt; V0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
</p>
<p>11.3 Energy Barrier . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
11.3.1 Case A: 0 &lt; E &lt; V0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
11.3.2 Case B: 0 &lt; V0 &lt; E . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
</p>
<p>11.4 Energy Barrier of a General Form . . . . . . . . . . . . . . . . . . . . . . . . . . 210
11.5 Energy Well . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
</p>
<p>12 Cases Related to the Linear Harmonic Oscillator . . . . . . . . . . . . . . . . . 217
12.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
12.2 Linear Harmonic Oscillator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
12.3 Quantization of the Electromagnetic Field&rsquo;s Energy . . . . . . . . . . . 221
12.4 Quantization of the Electromagnetic Field&rsquo;s Momentum . . . . . . . 223
12.5 Quantization of a Diagonalized Hamiltonian Function . . . . . . . . . 224
12.6 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
</p>
<p>12.6.1 Comments About the Linear Harmonic Oscillator . . . . . 225</p>
<p/>
</div>
<div class="page"><p/>
<p>xiv Contents
</p>
<p>13 Other Examples of the Schr&ouml;dinger Equation . . . . . . . . . . . . . . . . . . . . 227
13.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
13.2 Properties of the One-Dimensional Schr&ouml;dinger Equation . . . . . . 227
13.3 Localized States&mdash;Operator&rsquo;s Factorization . . . . . . . . . . . . . . . . . . 229
</p>
<p>13.3.1 Factorization Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
13.3.2 First-Order Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
13.3.3 The Eigenfunctions Corresponding to l &lt; n . . . . . . . . . . 232
13.3.4 Normalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
</p>
<p>13.4 Schr&ouml;dinger Equation with a Periodic Coefficient . . . . . . . . . . . . . 234
13.5 Schr&ouml;dinger Equation for a Central Force . . . . . . . . . . . . . . . . . . . . 236
</p>
<p>13.5.1 Angular Part of the Equation . . . . . . . . . . . . . . . . . . . . . . . 237
13.5.2 Radial Part of the Equation in the Coulomb Case . . . . . . 239
</p>
<p>13.6 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
13.6.1 Operators Associated to Angular Momentum . . . . . . . . . 240
13.6.2 Eigenvalues of the Angular Equation . . . . . . . . . . . . . . . . 242
13.6.3 Eigenfunctions of the Angular Equation . . . . . . . . . . . . . 243
13.6.4 Eigenvalues of the Radial Equation&mdash;Coulomb Case . . 246
13.6.5 Eigenfunctions of the Radial Equation&mdash;Coulomb Case 247
13.6.6 Transmission Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251
</p>
<p>14 Time-Dependent Perturbation Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
14.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
14.2 Discrete Eigenvalues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
14.3 First-Order Perturbation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
14.4 Comments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256
14.5 Degenerate Energy Levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
14.6 Continuous Energy Levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
14.7 Screened Coulomb Perturbation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
14.8 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
</p>
<p>14.8.1 Perturbation Constant in Time . . . . . . . . . . . . . . . . . . . . . 262
14.8.2 Harmonic Perturbation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
14.8.3 Fermi&rsquo;s Golden Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
14.8.4 Transitions from Discrete to Continuous Levels . . . . . . . 265
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
</p>
<p>Part IV Systems of Interacting Particles&mdash;Quantum Statistics
</p>
<p>15 Many-Particle Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
15.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
15.2 Wave Function of a Many-Particle System . . . . . . . . . . . . . . . . . . . 269
15.3 Symmetry of Functions and Operators . . . . . . . . . . . . . . . . . . . . . . 271
15.4 Conservation of Symmetry in Time . . . . . . . . . . . . . . . . . . . . . . . . . 272
15.5 Identical Particles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
</p>
<p>15.5.1 Spin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents xv
</p>
<p>15.6 Pauli Exclusion Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
15.7 Conservative Systems of Particles . . . . . . . . . . . . . . . . . . . . . . . . . . 278
15.8 Equilibrium Statistics in the Quantum Case . . . . . . . . . . . . . . . . . . 280
</p>
<p>15.8.1 Fermi&ndash;Dirac Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
15.8.2 Bose&ndash;Einstein Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
</p>
<p>15.9 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286
15.9.1 Connection with Thermodynamic Functions . . . . . . . . . . 286
15.9.2 Density of States for a Particle in a Three-Dimensional
</p>
<p>Box . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
15.9.3 Density of States for a Two- or One-Dimensional Box . 289
15.9.4 Density of States for Photons . . . . . . . . . . . . . . . . . . . . . . 290
15.9.5 Derivation of Planck&rsquo;s Law . . . . . . . . . . . . . . . . . . . . . . . . 291
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292
</p>
<p>16 Separation of Many-Particle Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
16.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
16.2 System of Interacting Electrons and Nuclei . . . . . . . . . . . . . . . . . . 294
16.3 Adiabatic Approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295
16.4 Hartree Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297
16.5 Hartree&ndash;Fock Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299
16.6 Schr&ouml;dinger Equation for the Nuclei . . . . . . . . . . . . . . . . . . . . . . . . 300
16.7 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301
</p>
<p>16.7.1 Ritz Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301
</p>
<p>Part V Applications to Semiconducting Crystals
</p>
<p>17 Periodic Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
17.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
17.2 Bravais Lattice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306
17.3 Reciprocal Lattice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
17.4 Wigner&ndash;Seitz Cell&mdash;Brillouin Zone . . . . . . . . . . . . . . . . . . . . . . . . . 311
17.5 Translation Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312
</p>
<p>17.5.1 Bloch Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314
17.5.2 Periodic Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315
17.5.3 Periodic Boundary Conditions . . . . . . . . . . . . . . . . . . . . . 316
</p>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice . . . . . . . . . . . . . . . . . . . 318
17.6.1 Wave Packet in a Periodic Potential . . . . . . . . . . . . . . . . . 321
17.6.2 Parabolic-Band Approximation . . . . . . . . . . . . . . . . . . . . 322
17.6.3 Density of States in the Parabolic-Band Approximation 326
17.6.4 Crystals of Si, Ge, and GaAs . . . . . . . . . . . . . . . . . . . . . . 327
17.6.5 Band Structure of Si, Ge, and GaAs . . . . . . . . . . . . . . . . . 328
17.6.6 Further Comments About the Band Structure . . . . . . . . . 335
17.6.7 Subbands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
17.6.8 Subbands in a Periodic Lattice . . . . . . . . . . . . . . . . . . . . . 339
</p>
<p>17.7 Calculation of Vibrational Spectra . . . . . . . . . . . . . . . . . . . . . . . . . . 344</p>
<p/>
</div>
<div class="page"><p/>
<p>xvi Contents
</p>
<p>17.7.1 Labeling the Degrees of Freedom&mdash; Dynamic
Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346
</p>
<p>17.7.2 Application of the Bloch Theorem . . . . . . . . . . . . . . . . . . 347
17.7.3 Properties of the Eigenvalues and Eigenvectors . . . . . . . 349
</p>
<p>17.8 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351
17.8.1 Crystal Planes and Directions in Cubic Crystals . . . . . . . 351
17.8.2 Examples of Translation Operators . . . . . . . . . . . . . . . . . 353
17.8.3 Symmetries of the Hamiltonian Operator . . . . . . . . . . . . 354
17.8.4 Kronig&ndash;Penney Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . 356
17.8.5 Linear, Monatomic Chain . . . . . . . . . . . . . . . . . . . . . . . . . 360
17.8.6 Linear, Diatomic Chain . . . . . . . . . . . . . . . . . . . . . . . . . . . 363
17.8.7 Analogies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367
</p>
<p>18 Electrons and Holes in Semiconductors at Equilibrium . . . . . . . . . . . . 369
18.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369
18.2 Equilibrium Concentration of Electrons and Holes . . . . . . . . . . . . 370
18.3 Intrinsic Concentration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374
18.4 Uniform Distribution of Impurities . . . . . . . . . . . . . . . . . . . . . . . . . 377
</p>
<p>18.4.1 Donor-Type Impurities . . . . . . . . . . . . . . . . . . . . . . . . . . . 379
18.4.2 Acceptor-Type Impurities . . . . . . . . . . . . . . . . . . . . . . . . . 385
18.4.3 Compensation Effect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
</p>
<p>18.5 Non-Uniform Distribution of Dopants . . . . . . . . . . . . . . . . . . . . . . . 391
18.6 Band-Gap Narrowing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 393
18.7 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396
</p>
<p>18.7.1 Si, Ge, GaAs in the Manufacturing of Integrated
Circuits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396
</p>
<p>18.7.2 Qualitative Analysis of the Impurity Levels . . . . . . . . . . 397
18.7.3 Position of the Impurity Levels . . . . . . . . . . . . . . . . . . . . . 398
</p>
<p>Part VI Transport Phenomena in Semiconductors
</p>
<p>19 Mathematical Model of Semiconductor Devices . . . . . . . . . . . . . . . . . . . 403
19.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 403
19.2 Equivalent Hamiltonian Operator . . . . . . . . . . . . . . . . . . . . . . . . . . . 404
</p>
<p>19.2.1 Electron Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405
19.2.2 Expectation Values&mdash;Crystal Momentum . . . . . . . . . . . . 407
19.2.3 Dynamics in the Parabolic-Band Approximation . . . . . . 409
</p>
<p>19.3 Dynamics in the Phase Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411
19.3.1 Collision Term . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 413
19.3.2 Point-Like Collisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 416
19.3.3 Perturbative Form of the BTE . . . . . . . . . . . . . . . . . . . . . . 418
</p>
<p>19.4 Moments Expansion of the BTE. . . . . . . . . . . . . . . . . . . . . . . . . . . . 419
19.4.1 Moment Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 422
19.4.2 Hierarchical Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 425
</p>
<p>19.5 Hydrodynamic and Drift-Diffusion Models . . . . . . . . . . . . . . . . . . 429</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents xvii
</p>
<p>19.5.1 HD Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 430
19.5.2 DD Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 431
19.5.3 DD Model for the Valence Band . . . . . . . . . . . . . . . . . . . . 434
19.5.4 Coupling with Maxwell&rsquo;s Equations . . . . . . . . . . . . . . . . 436
19.5.5 Semiconductor-Device Model . . . . . . . . . . . . . . . . . . . . . 438
19.5.6 Boundary Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439
19.5.7 Quasi-Fermi Potentials . . . . . . . . . . . . . . . . . . . . . . . . . . . 442
19.5.8 Poisson Equation in a Semiconductor . . . . . . . . . . . . . . . 443
</p>
<p>19.6 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 444
19.6.1 Comments on the Equivalent Hamiltonian Operator . . . 444
19.6.2 Special Cases of Anisotropy . . . . . . . . . . . . . . . . . . . . . . . 445
19.6.3 Î±-Moment at Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . 445
19.6.4 Closure Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 445
19.6.5 Matthiessen&rsquo;s Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 447
19.6.6 Order of Magnitude of Mobility and Conductivity . . . . . 448
19.6.7 A Resum&eacute; of the Transport Model&rsquo;s Derivation . . . . . . . 449
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449
</p>
<p>20 Generation-Recombination and Mobility . . . . . . . . . . . . . . . . . . . . . . . . 451
20.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451
20.2 Net Thermal Recombinations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451
</p>
<p>20.2.1 Direct Thermal Recombinations . . . . . . . . . . . . . . . . . . . . 452
20.2.2 Trap-Assisted Thermal Recombinations . . . . . . . . . . . . . 455
20.2.3 Shockley-Read-Hall Theory . . . . . . . . . . . . . . . . . . . . . . . 457
</p>
<p>20.3 Auger Recombination and Impact Ionization . . . . . . . . . . . . . . . . . 462
20.3.1 Strong Impact Ionization . . . . . . . . . . . . . . . . . . . . . . . . . . 465
</p>
<p>20.4 Optical Transitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465
20.5 Macroscopic Mobility Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 468
</p>
<p>20.5.1 Example of Phonon Collision . . . . . . . . . . . . . . . . . . . . . . 469
20.5.2 Example of Ionized-Impurity Collision . . . . . . . . . . . . . . 471
20.5.3 Bulk and Surface Mobilities . . . . . . . . . . . . . . . . . . . . . . . 472
20.5.4 Beyond Analytical Modeling of Mobility . . . . . . . . . . . . 473
</p>
<p>20.6 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 475
20.6.1 Transition Rates in the SRH Recombination Function 475
20.6.2 Coefficients of the Auger and Impact-Ionization
</p>
<p>Events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 478
20.6.3 Total Recombination-Generation Rate . . . . . . . . . . . . . . . 479
20.6.4 Screened Coulomb Potential . . . . . . . . . . . . . . . . . . . . . . . 480
</p>
<p>Part VII Basic Semiconductor Devices
</p>
<p>21 Bipolar Devices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 485
21.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 485
21.2 P&ndash;N Junction in Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 485
</p>
<p>21.2.1 Built-In Potential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 486
21.2.2 Space-Charge and Quasi-Neutral Regions . . . . . . . . . . . . 489</p>
<p/>
</div>
<div class="page"><p/>
<p>xviii Contents
</p>
<p>21.3 Shockley Theory of the P&ndash;N Junction . . . . . . . . . . . . . . . . . . . . . . . 492
21.3.1 Derivation of the I (V ) Characteristic . . . . . . . . . . . . . . . . 496
</p>
<p>21.4 Depletion Capacitance of the Abrupt P&ndash;N Junction . . . . . . . . . . . . 498
21.5 Avalanche Due to Impact Ionization . . . . . . . . . . . . . . . . . . . . . . . . 501
21.6 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 504
</p>
<p>21.6.1 Weak-Injection Limit of the Drift-Diffusion Equations . 504
21.6.2 Shockley&rsquo;s Boundary Conditions . . . . . . . . . . . . . . . . . . . 505
21.6.3 Depletion Capacitance&mdash;Arbitrary Doping Profile . . . . . 506
21.6.4 Order of Magnitude of Junction&rsquo;s Parameters . . . . . . . . . 508
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 508
</p>
<p>22 MOS Devices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 509
22.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 509
22.2 Metal&ndash;Insulator&ndash;Semiconductor Capacitor . . . . . . . . . . . . . . . . . . . 510
</p>
<p>22.2.1 Surface Potential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 512
22.2.2 Relation Between Surface Potential and Gate Voltage 515
</p>
<p>22.3 Capacitance of the MOS Structure . . . . . . . . . . . . . . . . . . . . . . . . . . 520
22.4 Simplified Expression of the Inversion Charge . . . . . . . . . . . . . . . . 522
</p>
<p>22.4.1 Quantitative Relations in the MOS Capacitor . . . . . . . . . 524
22.5 Insulated-Gate Field-Effect Transistor&mdash;MOSFET . . . . . . . . . . . . 526
22.6 N-Channel MOSFET&mdash;Current-Voltage Characteristics . . . . . . . . 527
</p>
<p>22.6.1 Gradual-Channel Approximation . . . . . . . . . . . . . . . . . . . 529
22.6.2 Differential Conductances and Drain Current . . . . . . . . . 530
</p>
<p>22.7 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 534
22.7.1 Poisson&rsquo;s Equation in the MOSFET Channel . . . . . . . . . 534
22.7.2 Inversion-Layer Charge and Mobility Degradation . . . . 537
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 538
</p>
<p>Part VIII Miscellany
</p>
<p>23 Thermal Diffusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 541
23.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 541
23.2 Continuity Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 542
23.3 Diffusive Transport . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 545
23.4 Diffusion Equation&mdash;Model Problem . . . . . . . . . . . . . . . . . . . . . . . 546
23.5 Predeposition and Drive-in Diffusion . . . . . . . . . . . . . . . . . . . . . . . 547
</p>
<p>23.5.1 Predeposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 548
23.5.2 Drive-in Diffusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 551
</p>
<p>23.6 Generalization of the Model Problem . . . . . . . . . . . . . . . . . . . . . . . 553
23.7 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 553
</p>
<p>23.7.1 Generation and Destruction of Particles . . . . . . . . . . . . . 553
23.7.2 Balance Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 554
23.7.3 Lateral Diffusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 554
23.7.4 Alternative Expression of the Dose . . . . . . . . . . . . . . . . . 555
23.7.5 The Initial Condition of the Predeposition Step . . . . . . . 555
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 556</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents xix
</p>
<p>24 Thermal Oxidation&mdash;Layer Deposition . . . . . . . . . . . . . . . . . . . . . . . . . . 557
24.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 557
24.2 Silicon Oxidation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 558
24.3 Oxide-Growth Kinetics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 560
24.4 Linear&ndash;Parabolic Model of the Oxide Growth . . . . . . . . . . . . . . . . 562
24.5 Layer Deposition and Selective Oxide Growth . . . . . . . . . . . . . . . . 563
24.6 Epitaxy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 566
24.7 Kinetics of Epitaxy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 567
24.8 Complements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 568
</p>
<p>24.8.1 An Apparent Contradiction . . . . . . . . . . . . . . . . . . . . . . . . 568
24.8.2 Elementary Contributions to the Layer&rsquo;s Volume . . . . . . 569
24.8.3 Features of the Oxide Growth and Epitaxial Growth . . . 570
24.8.4 Reaction Velocity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 570
24.8.5 Molecular Beam Epitaxy . . . . . . . . . . . . . . . . . . . . . . . . . . 571
24.8.6 Secondary Reaction in the Epitaxial Growth . . . . . . . . . . 571
</p>
<p>Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 572
</p>
<p>25 Measuring the Semiconductor Parameters . . . . . . . . . . . . . . . . . . . . . . . 575
25.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 575
25.2 Lifetime Measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 575
25.3 Mobility Measurement&mdash;Haynes-Shockley Experiment . . . . . . . . 578
25.4 Hall-Voltage Measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 581
25.5 Measurement of Doping Profiles . . . . . . . . . . . . . . . . . . . . . . . . . . . 583
</p>
<p>Appendix A Vector and Matrix Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 585
</p>
<p>Appendix B Coordinates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 595
</p>
<p>Appendix C Special Integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 603
</p>
<p>Appendix D Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 625
</p>
<p>Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 627
</p>
<p>Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 645</p>
<p/>
</div>
<div class="page"><p/>
<p>Acronyms
</p>
<p>Abbreviations
</p>
<p>BJT Bipolar junction transistor. A transistor whose operation is obtained by
a suitable arrangement of two p-n junctions. The term &ldquo;bipolar&rdquo; is used
because both electrons and holes are involved in the device functioning.
</p>
<p>BTE Boltzmann transport equation. The equation expressing the continuity
of the distribution function in the phase space.
</p>
<p>CVD Chemical vapor deposition. A deposition process in which the material
to be deposited is the product of a chemical reaction that takes place on
the surface of the substrate or in its vicinity.
</p>
<p>DD Drift-diffusion. The term indicates a transport model for semiconductors
made, for each band, of the balance equation for the carrier number
and average velocity. Such equations contain the electric field and the
magnetic induction; as a consequence, their solution must be calculated
consistently with that of the Maxwell equations. Compare with the HD
model.
</p>
<p>HD HydroDynamic. The term indicates a transport model for semiconduc-
tors made, for each band, of the balance equation for the carrier number,
average velocity, average kinetic energy, and average flux of the kinetic
energy. Such equations contain the electric field and the magnetic in-
duction; as a consequence, their solution must be calculated consistently
with that of the Maxwell equations. Compare with the DD model.
</p>
<p>IC Integrated circuit. Also called chip or microchip. An assembly of elec-
tronic circuits on the same plate of semiconductor material. The idea
was proposed in the early 1950s, and demonstrated in 1958; it provided
an enormous improvement, both in cost and performance, with respect
to the manual assembly of circuits using discrete components.
</p>
<p>IGFET Insulated-gate field-effect transistor. A device architecture demonstrated
in the early 1930s. Its first implementation (1960) using a thermally-
oxidized silicon layer gave rise to the MOSFET architecture.
</p>
<p>LASER Light amplification by stimulated emission of radiation.
</p>
<p>xxi</p>
<p/>
</div>
<div class="page"><p/>
<p>xxii Acronyms
</p>
<p>LOCOS Local oxidation. The technological process consisting in depositing and
patterning a layer of silicon nitride over the areas where the substrate&rsquo;s
oxidation must be prevented.
</p>
<p>MBE Molecular beam epitaxy. A low-temperature epitaxial process based on
evaporation.
</p>
<p>MIS Metal insulator semiconductor. Structure made of the superposition of
a metal contact, an insulator, and a semiconductor.
</p>
<p>MOS Metal oxide semiconductor. Structure made of the superposition of a
metal contact, an oxide that acts as an insulator, and a semiconductor.
</p>
<p>MOSFET Metal-oxide-semiconductor, field-effect transistor. A transistor whose
active region is an MOS structure. In last-generation devices the in-
sulator may be deposited instead of being obtained by oxidizing the
semiconductor underneath. The MOSFET has been for decades, and
still is, the fundamental device of the integrated-circuit architecture.
</p>
<p>PDE Partial-differential equation.
PVD Physical vapor deposition. A deposition process in which the material
</p>
<p>to be deposited does not react chemically with other substances.
SGOI Silicon-germanium-on-insulator. A technology analogous to SOI. SGOI
</p>
<p>increases the speed of the transistors by straining the material under the
gate, this making the electron mobility higher.
</p>
<p>SOI Silicon on insulator. A technology introduced in 1998 for semiconductor
manufacturing, in which the standard silicon substrate is replaced with
a layered structure of the silicon-insulator-silicon type. SOI reduces the
parasitic capacitances and the short-channel effect in MOS transistors.
</p>
<p>SOS Silicon on sapphire. A technological process that consists in growing a
thin layer of silicon on a wafer made of sapphire (Al2O3).
</p>
<p>VLSI Very-large-scale integration. The process of creating an integrated circuit
by placing a very large number of transistors in a single chip.</p>
<p/>
</div>
<div class="page"><p/>
<p>List of Tables
</p>
<p>Table 13.1 The lowest-order spherical harmonics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
Table 13.2 Symbols and names for the states corresponding
</p>
<p>to l = 0, 1, 2, 3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
Table 17.1 Crystal constants of silicon and germanium.. . . . . . . . . . . . . . . . . . . . . 308
Table 17.2 Crystal constants of some III-V semiconductors. . . . . . . . . . . . . . . . . 309
Table 17.3 Normalized effective masses of the valence band of Si,
</p>
<p>Ge, and GasAs .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333
Table 17.4 Normalized effective masses of the conduction band of Si,
</p>
<p>Ge, and GasAs .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335
Table 18.1 Gap and average effective masses of silicon, germanium,
</p>
<p>and gallium arsenide. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374
Table 18.2 Intrinsic concentrations of silicon, germanium,
</p>
<p>and gallium arsenide. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377
Table 22.1 MOS capacitor, p substrate&mdash;functioning regimes. . . . . . . . . . . . . . . 517
Table 24.1 Examples of CVD reactions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 565
Table D.1 Fundamental constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 625
Table D.2 Greek alphabet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 625
</p>
<p>xxiii</p>
<p/>
</div>
<div class="page"><p/>
<p>Part I
</p>
<p>A Review of Analytical Mechanics
and Electromagnetism</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 1
</p>
<p>Analytical Mechanics
</p>
<p>1.1 Introduction
</p>
<p>The differential equations that govern the dynamical problems can be derived from
variational principles, upon which the theories of Euler and Lagrange, and those
of Hamilton and Jacobi, are based. Apart from being the source of the greatest in-
tellectual enjoyment, these theories have the definite advantage of generality. Their
concepts can in fact be extended to cases where the Newtonian equation of dy-
namics does not apply. Among such cases there are the equations governing the
electromagnetic field and those related to the quantum description of the particles&rsquo;
motion.
</p>
<p>The invariance property of the Lagrange equations with respect to a change of
coordinates gives origin to the concept of generalized coordinates and conjugate
momenta; in turn, the introduction of the Hamilton equations provides a picture
in which the intrinsic symmetry of the roles of coordinates and momenta becomes
apparent. Basing on the concept of conjugate coordinates, the time evolution of
a particle or of a system of particles is described in the phase space instead of
the coordinate space. This chapter and the next one illustrate the basic principles
of Analytical Mechanics. Their purpose is to introduce a number of concepts that
are not only useful per se, but also constitute a basis for the concepts of Quantum
Mechanics that are introduced in later chapters. A third chapter devoted to Analytical
Mechanics describes a number of important examples, that will be applied to later
developments illustrated in the book.
</p>
<p>As the velocity of particles within a semiconductor device is small with respect
to that of light, the non-relativistic form of the mechanical laws is sufficient for
the purposes of this book. The relativistic form is used only in a few paragraphs
belonging to the chapter devoted to examples, to the purpose of describing a specific
type of collision between particles. This chapter starts with the description of the
Lagrangian function and the Lagrange equations, that are derived as a consequence
of the variational calculus, followed by the derivation of the Hamiltonian function and
Hamilton equations. Next, the Hamilton&ndash;Jacobi equation is derived after discussing
the time&ndash;energy conjugacy. The chapter continues with the definition of the Poisson
</p>
<p>&copy; Springer Science+Business Media New York 2015 3
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_1</p>
<p/>
</div>
<div class="page"><p/>
<p>4 1 Analytical Mechanics
</p>
<p>brackets and the derivation of some properties of theirs, and concludes with the
description of the phase space and state space.
</p>
<p>1.2 Variational Calculus
</p>
<p>Consider a real function w(Î¾ ) defined in the interval Î¾ &isin; [a, b] and differentiable in
its interior at least twice. The first two derivatives will be indicated with wÌ e wÌ. Now,
define the integral
</p>
<p>G[w] =
&int; b
</p>
<p>a
</p>
<p>g(w, wÌ, Î¾ ) dÎ¾ , (1.1)
</p>
<p>where the form of the function g(w, wÌ, Î¾ ) is prescribed. If (1.1) is calculated for any
function w fulfilling the requisites stated above, with a and b fixed, the result is some
real number G whose value depends on the choice of w. By this procedure, (1.1)
establishes a correspondence G[w] between a set of functions and a set of numbers.
Such a correspondence is called functional.
</p>
<p>It is interesting to extend to the case of functionals some concepts and procedures
that apply to functions proper; among these it is important the concept of extremum.
In fact, one defines the extremum function of a functional by a method similar to that
used for defining the extremum point of a function: some w is an extremum of G if a
variation dw in (1.1) produces a variation dG that is infinitesimal of an order higher
than that of dw. The procedure by which the extremum functions are calculated is
called variational calculus.
</p>
<p>To proceed it is necessary to define the variation dw. For this one lets Î´w = Î±Î·,
with Î·(Î¾ ) an arbitrary function defined in [a, b] and differentiable in its interior, and
Î± a real parameter. The function Î´w thus defined is the finite variation of w. The sum
w + Î´w tends to w in the limit Î± &rarr; 0. As a consequence, such a limit provides the
infinitesimal variation dw. For simplicity it is convenient to restrict the choice of Î·
to the case Î·(a) = Î·(b) = 0, so that w + Î´w coincides with w at the integration
boundaries for any value of Î±.
</p>
<p>Now, replacing w with w+Î±Î· in (1.1) makes G a function of Î±, whose derivative
is
</p>
<p>dG
</p>
<p>dÎ±
=
</p>
<p>&int; b
</p>
<p>a
</p>
<p>[
&part;g
</p>
<p>&part;(w + Î±Î·) Î· +
&part;g
</p>
<p>&part;(wÌ + Î±Î·Ì) Î·Ì
]
</p>
<p>dÎ¾. (1.2)
</p>
<p>According to the definition given above, if w is an extremum function of G then it
must be limÎ±&rarr;0 dG/dÎ± = 0; in this case, in fact, the first-order term in the power
expansion of G with respect to Î± vanishes, and the variation of G becomes second
order in Î± or higher. In conclusion, one proceeds by imposing that the right hand side
of (1.2) vanishes for Î± = 0. Then, integrating by parts the second term in brackets
yields
</p>
<p>&int; b
</p>
<p>a
</p>
<p>&part;g
</p>
<p>&part;w
Î·dÎ¾ +
</p>
<p>[
&part;g
</p>
<p>&part;wÌ
Î·
</p>
<p>]b
</p>
<p>a
</p>
<p>=
&int; b
</p>
<p>a
</p>
<p>(
d
</p>
<p>dÎ¾
</p>
<p>&part;g
</p>
<p>&part;wÌ
</p>
<p>)
</p>
<p>Î·dÎ¾ (1.3)</p>
<p/>
</div>
<div class="page"><p/>
<p>1.2 Variational Calculus 5
</p>
<p>where, in turn, the integrated part vanishes because Î·(a) = Î·(b) = 0. This makes
the two integrals in (1.3) equal to each other. On the other hand, such an equality
must hold for any choice of Î· due to the arbitrariness of the latter. It follows that the
integrands must be equal to each other, namely,
</p>
<p>d
</p>
<p>dÎ¾
</p>
<p>&part;g
</p>
<p>&part;wÌ
= &part;g
</p>
<p>&part;w
. (1.4)
</p>
<p>The relation (1.4) thus found is a second-order differential equation in the unknown
w, whose explicit form is easily calculated:
</p>
<p>&part;2 g
</p>
<p>&part;wÌ2
wÌ + &part;
</p>
<p>2 g
</p>
<p>&part;w&part;wÌ
wÌ + &part;
</p>
<p>2 g
</p>
<p>&part;Î¾&part;wÌ
= &part;g
</p>
<p>&part;w
. (1.5)
</p>
<p>Its solution provides the extremum function w sought. To actually find a solution one
must associate to (1.4) suitable boundary conditions, e.g., w(a) = wa , wÌ(a) = wÌa ,
or w(a) = wa , w(b) = wb, and so on. As g does not contain wÌ, (1.4) is linear with
respect to wÌ. It is also worth noting that, consistently with what happens in the case
of functions proper, the above calculation does not provide in itself any information
about w being a minimum or maximum of G. Such an information must be sought
through additional calculations.
</p>
<p>The analysis above is easily extended to the case where g depends on several
functions w1, w2, . . . and the corresponding derivatives. Introducing the vectors
w(Î¾ ) = (w1, w2, . . . , wn), wÌ(Î¾ ) = (wÌ1, wÌ2, . . . , wÌn) one finds that the set of n
extremum functions wi(Î¾ ) of functional
</p>
<p>G[w] =
&int; b
</p>
<p>a
</p>
<p>g(w, wÌ, Î¾ ) dÎ¾ (1.6)
</p>
<p>is the solution of the set of differential equations
</p>
<p>d
</p>
<p>dÎ¾
</p>
<p>&part;g
</p>
<p>&part;wÌi
= &part;g
</p>
<p>&part;wi
, i = 1, . . . , n, (1.7)
</p>
<p>supplemented with suitable boundary conditions. Equations (1.7) are called Euler
equations of the functional G.
</p>
<p>Each equation (1.7) is homogeneous with respect to the derivatives of g and does
not contain g itself. As a consequence, the differential equations (1.7) are invariant
when g is replaced with Ag + B, where A,B ï¿½= 0 are constants. As the boundary
conditions of wi are not affected by that, the solutions wi are invariant under the
transformation. Moreover, it can be shown that the solutions are invariant under a
more general transformation. In fact, consider an arbitrary function h = h(w, Î¾ ) and
let g&prime; = g + dh/dÎ¾ , this transforming (1.6) into
</p>
<p>G&prime;[w] = A
&int; b
</p>
<p>a
</p>
<p>g(w, wÌ, Î¾ ) dÎ¾ + h(wb, Î¾b) &minus; h(wa , Î¾a). (1.8)
</p>
<p>When each wi is replaced with wi+dwi , the terms involvingh do not vary because the
variations vanish at the boundaries of the integration domain. Thus, the variation of</p>
<p/>
</div>
<div class="page"><p/>
<p>6 1 Analytical Mechanics
</p>
<p>G&prime; equals that of the integral, namely, it is of a higher order than dwi . In conclusion,
the extremum functions of G are also extremum functions of G&prime;. This means that the
solutions wi(Î¾ ) are invariant under addition to g of the total derivative of an arbitrary
function that depends on w and Î¾ only. This reasoning does not apply if h depends
also on the derivatives wÌ, because in general the derivatives of the variations do not
vanish at the boundaries.
</p>
<p>1.3 Lagrangian Function
</p>
<p>In many cases the solution of a physical problem is achieved by solving a set of
second-order differential equations of the form wÌi = wÌi(w, wÌ, Î¾ ). For instance, for
non-relativistic velocities the law of motion of a particle of constant mass m is
Newton&rsquo;s law F = ma which, in a Cartesian frame, takes the form
</p>
<p>m xÌi = Fi(r, rÌ, t), i = 1, 2, 3. (1.9)
</p>
<p>In (1.9), r(t) = (x1, x2, x3) is the particle&rsquo;s position vector1 at t . In the following the
particle&rsquo;s velocity will be indicated with u = rÌ.
</p>
<p>Equations (1.9) and (1.7) have the same form, as is easily found by observing that
t is the analogue of Î¾ and xi is that of wi . As a consequence, one may argue that
(1.9) could be deduced as Euler equations of a suitable functional. This problem is
in fact the inverse of that solved in Sect. 1.2: there, the starting point is the function
g, whose derivatives provide the coefficients of the differential equations (1.7); here,
the coefficients of the differential equation are given, while the function g is to
be found. For the inverse problem the existence of a solution is not guaranteed in
general; if a solution exists, finding the function g may be complicated because
the process requires an integration. In other terms, the direct problem involves only
the somewhat &ldquo;mechanical&rdquo; process of calculating derivatives, whereas the inverse
problem involves the integration which is, so to speak, an art.
</p>
<p>When dealing with the dynamics of a particle or of a system of particles, the
function g, if it exists, is called Lagrangian function and is indicated with L. The
equations corresponding to (1.7) are called Lagrange equations. The expression of the
Lagrangian function depends on the form of the force Fi in (1.9). Some examples are
given in the following. It is important to note that by &ldquo;system of particles&rdquo; it is meant
a collection of particles that interact with each other. If there were no interactions it
would be possible to tackle the dynamics of each particle separately; in other terms,
each particle would constitute a system in itself, described by a smaller number of
degrees of freedom.
</p>
<p>1 The units in (1.9) are: [m] = kg, [r] = m, [rÌ] = m s&minus;1, [xÌi ] = m s&minus;2, [Fi ] = N, where &ldquo;N&rdquo;
stands for Newton.</p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 Lagrangian Function 7
</p>
<p>1.3.1 Force Deriving from a Potential Energy
</p>
<p>Consider the case of a force deriving from a potential energy, namely F = &minus;gradV
with V = V (r, t), so that (1.9) becomes
</p>
<p>muÌi = &minus;
&part;V
</p>
<p>&part;xi
. (1.10)
</p>
<p>Using the replacements Î¾ &larr; t , wi &larr; xi , g &larr; L and equating (1.7) and (1.10) side
by side yields
</p>
<p>&part;L
</p>
<p>&part;xi
= &minus;&part;V
</p>
<p>&part;xi
,
</p>
<p>d
</p>
<p>dt
</p>
<p>&part;L
</p>
<p>&part;ui
= d
</p>
<p>dt
(mui), i = 1, 2, 3. (1.11)
</p>
<p>The first of (1.11) shows that the sum T = L+V does not depend on the coordinates
xi . Inserting L = T &minus; V into the second of (1.11) and taking i = 1 shows that the
difference Î¦ = &part;T /&part;u1 &minus; mu1 does not depend on time either, so it depends on
the ui components at most. Integrating Î¦ with respect to u1 yields T = mu21/2 +
T1(u2, u3, t), with T1 yet undetermined. Differentiating this expression of T with
respect to u2, and comparing it with the second of (1.11) specified for i = 2, yields
T = m (u21 + u22)/2 + T2(u3, t), with T2 undetermined. Repeating the procedure for
i = 3 finally provides T = m (u21 + u22 + u23)/2 + T0(t), with T0 an undetermined
function of time only. The latter, in turn, can be viewed as the time derivative of
another function h. Remembering the invariance property discussed at the end of
Sect. 1.2 with reference to (1.8), one lets T0 = 0. In conclusion, indicating with u
the modulus of u it is T = mu2/2, and the Lagrangian function reads
</p>
<p>L = 1
2
mu2 &minus; V. (1.12)
</p>
<p>The derivation of (1.12) may appear lengthy. However, the procedure is useful
because it is applicable to forces of a more complicated form.
</p>
<p>1.3.2 Electromagnetic Force
</p>
<p>Consider a charged particle subjected to an electromagnetic field and let m, e be
its mass and charge, respectively. The particle&rsquo;s velocity u is assumed to be non-
relativistic. The electromagnetic field acts on the particle with the Lorentz force
(Sect. 4.11) 2
</p>
<p>F = e (E + u &and; B), (1.13)
</p>
<p>2 The units in (1.13) are: [F] = N, [e] = C, [E] = V m&minus;1, [u] = m s&minus;1, [B] =
V s m&minus;2 = Wb m&minus;2 = T, where &ldquo;N&rdquo;, &ldquo;C&rdquo;, &ldquo;V&rdquo;, &ldquo;Wb&rdquo;, and &ldquo;T&rdquo; stand for Newton, Coulomb, Volt,
Weber, and Tesla, respectively. The coefficients in (1.13) differ from those of [4] because of the
different units adopted there. In turn, the units in (1.14) are: [Ï] = V, [A] = V s m&minus;1 = Wb m&minus;1.</p>
<p/>
</div>
<div class="page"><p/>
<p>8 1 Analytical Mechanics
</p>
<p>where the electric field E and the magnetic induction B are in turn expressed through
the scalar potential Ï = Ï(r, t) and the vector potential A = A(r, t) as (Sect. 4.5)
</p>
<p>E = &minus;gradÏ &minus; &part;A
&part;t
</p>
<p>, B = rotA. (1.14)
</p>
<p>Letting i = 1 in (1.9) one finds from (1.13) muÌ1 = e (E1 + u2 B3 &minus; u3 B2). Using
for E1, B3, B2 the expressions extracted from (1.14) yields
</p>
<p>muÌ1 + e
(
&part;A1
</p>
<p>&part;t
+ u2
</p>
<p>&part;A1
</p>
<p>&part;x2
+ u3
</p>
<p>&part;A1
</p>
<p>&part;x3
</p>
<p>)
</p>
<p>= e
(
</p>
<p>&minus; &part;Ï
&part;x1
</p>
<p>+ u2
&part;A2
</p>
<p>&part;x1
+ u3
</p>
<p>&part;A3
</p>
<p>&part;x1
</p>
<p>)
</p>
<p>.
</p>
<p>(1.15)
</p>
<p>Now, using ui = xÌi transforms the term in parentheses at the left hand side of (1.15)
into dA1/dt &minus; u1 &part;A1/&part;x1, which gives (1.15) the more compact form
</p>
<p>d
</p>
<p>dt
(mu1 + eA1) =
</p>
<p>&part;
</p>
<p>&part;x1
(eu &middot; A &minus; eÏ) . (1.16)
</p>
<p>Similar expressions are found for i = 2, 3. Comparing with (1.7) in the same manner
as in Sect. 1.3.1 yields
</p>
<p>&part;L
</p>
<p>&part;xi
= &part;
</p>
<p>&part;xi
(eu &middot; A &minus; eÏ) , d
</p>
<p>dt
</p>
<p>&part;L
</p>
<p>&part;ui
= d
</p>
<p>dt
(mui + eAi) , i = 1, 2, 3.
</p>
<p>(1.17)
</p>
<p>Note that (1.17) reduce to (1.11) when A = 0, with eÏ = V . The first of (1.17)
shows that the sum T = L + eÏ &minus; eu &middot; A does not depend on the coordinates
xi . Inserting L = T &minus; eÏ + eu &middot; A into the second of (1.17) transforms the latter
into d(&part;T /&part;ui)/dt = d(mui)/dt . Like in Sect. 1.3.2 the procedure eventually yields
T = mu2/2. In conclusion, the Lagrangian function of a particle subjected to the
Lorentz force (1.13) is
</p>
<p>L = 1
2
mu2 &minus; eÏ + eu &middot; A. (1.18)
</p>
<p>It is shown in Sect. 4.5 that the E and B fields are invariant under the gauge
transformation
</p>
<p>Ï &larr; Ï &minus; &part;h
&part;t
</p>
<p>, A &larr; A + gradh, (1.19)
</p>
<p>where h(r, t) is an arbitrary function. Using (1.19) in (1.18) transforms the terms
containing the potentials as
</p>
<p>&minus;eÏ + eu &middot; A &larr; &minus;eÏ + eu &middot; A + e dh
dt
</p>
<p>, (1.20)
</p>
<p>namely, the transformed Lagrangian function differs from the original one by the
total derivative of an arbitrary function that depends on position and time only. As a
consequence, the solutions xi(t) are invariant under the gauge transformation (1.19).
This is easily understood by observing that the invariance of the E and B fields makes
the Lorentz force (1.13) invariant as well. As a consequence, the particle&rsquo;s dynamics
is not influenced by the gauge transformation.</p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 Lagrangian Function 9
</p>
<p>1.3.3 Work
</p>
<p>The elementary work exerted by a force F acting on a particle of mass m during
the time dt is F &middot; dr, where r is the particle&rsquo;s position at t in a Cartesian frame and
dr = udt the elementary displacement. Let P = r(t = a), Q = r(t = b) be the
boundaries of the particle&rsquo;s trajectory. The work exerted from P to Q is found by
integrating F &middot; dr over the trajectory, namely,
</p>
<p>&int; Q
</p>
<p>P
</p>
<p>F &middot; dr = m
&int; b
</p>
<p>a
</p>
<p>uÌ &middot; udt = 1
2
m
</p>
<p>&int; b
</p>
<p>a
</p>
<p>du2
</p>
<p>dt
dt = T (b) &minus; T (a), (1.21)
</p>
<p>where the relation T = mu2/2 has been used. The exerted work is then equal to the
variation of T , which is the same quantity that appears in (1.12, 1.18) and is called
kinetic energy of the particle.
</p>
<p>If a system having n degrees of freedom is considered instead of a single particle,
the work exerted by the forces is defined as the sum of terms of the form (1.21). As
a consequence, the kinetic energy of the system is the sum of the kinetic energies of
the individual particles. The expression of the system&rsquo;s kinetic energy in Cartesian
coordinates is
</p>
<p>T =
n
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>1
</p>
<p>2
mi u
</p>
<p>2
i =
</p>
<p>n
&sum;
</p>
<p>i=1
</p>
<p>1
</p>
<p>2
mi xÌ
</p>
<p>2
i , (1.22)
</p>
<p>that is, a positive-definite quadratic form in the velocities. The masses in (1.22)
take the same value when they are referred to the same particle. When other types
of coordinates are used, the kinetic energy is still a second-degree function of the
velocities, however the function&rsquo;s coefficients may depend on the coordinates (an
example is given in Sect. 2.8).
</p>
<p>When a force deriving from a potential energy V = V (r, t) is considered, like that
of Sect. 1.3.1, the integrand of (1.21) becomes &minus;gradV &middot;dr. To calculate the integral
it is necessary to account for the explicit dependence of V on t by using mutually
consistent values of r and t ; in other terms, the integral in (1.21) can actually be
calculated only after determining the function r(t). An exception occurs when V has
no explicit dependence on time; in this case one finds
</p>
<p>&int; Q
</p>
<p>P
</p>
<p>F &middot; dr = &minus;
&int; Q
</p>
<p>P
</p>
<p>gradV &middot; dr = &minus;
&int; Q
</p>
<p>P
</p>
<p>dV = V (P ) &minus; V (Q), (1.23)
</p>
<p>namely, to calculate the integral it suffices to know the boundaries of the trajectory.
Moreover, whenV = V (r) the Lagrangian function (1.12) does not depend explicitly
on time either. It is shown in Sect. 1.6 that in this case also the sum T + V of the
kinetic and potential energies is independent of time. A dynamical property that does
not depend on time is called constant of motion. A force field that makes T + V a
constant of motion is called conservative.
</p>
<p>When a force of the form F = e (E+u&and;B) is considered, like that of Sect. 1.3.2,
the scalar multiplication by dr = u dt shows that the second term of the force does</p>
<p/>
</div>
<div class="page"><p/>
<p>10 1 Analytical Mechanics
</p>
<p>not contribute to the work because u &and; B &middot; u = 0 (Sect. A.7). Remembering the first
of (1.14), the integral corresponding to that of (1.23) reads
</p>
<p>&int; Q
</p>
<p>P
</p>
<p>F &middot; dr = &minus;e
&int; Q
</p>
<p>P
</p>
<p>(
</p>
<p>gradÏ + &part;A
&part;t
</p>
<p>)
</p>
<p>&middot; dr. (1.24)
</p>
<p>If the electromagnetic field is independent of time, the calculation is the same as in
(1.23) and the exerted work is eÏ(P ) &minus; eÏ(Q).
</p>
<p>1.3.4 Hamilton Principle&mdash;Synchronous Trajectories
</p>
<p>From the analysis of Sect. 1.2 it follows that the solutionsxi(t) of the motion equations
(1.9) are the extremum functions of the functional
</p>
<p>S[r] =
&int; b
</p>
<p>a
</p>
<p>L(r, rÌ, t) dt. (1.25)
</p>
<p>On the other hand, r(t) describes the particle&rsquo;s trajectory. The latter is also called
natural trajectory to distinguish it from the r + Î´r trajectories that are obtained
through a variation. In summary, the natural trajectory of the particle is the extremum
function of (1.25). This statement is called Hamilton principle.
</p>
<p>The integration boundaries in (1.25) determine a time interval b&minus;a that measures
the motion&rsquo;s duration between the initial and final position of the particle, r(a) and
r(b) respectively. The duration is the same also for the r + Î´r trajectories. In fact,
remembering the derivation of Sect. 1.2, the variation Î´r vanishes at the integration
boundaries, so that any trajectory obtained through a variation has the same initial
and final positions as the natural one at the same instants a and b. Moreover, any
position r+Î´r between r(a) and r(b) is considered at the same instant as the position
r of the natural trajectory. For this reason the r + Î´r trajectories of the functional
(1.25) are called synchronous.
</p>
<p>1.4 Generalized Coordinates
</p>
<p>The extremum functions are calculated as shown in Sect. 1.3 also when a system
of N particles, instead of a single particle, is considered. The starting point is still
(1.9), where a new index is introduced to distinguish the masses. The number of
coordinates that describe the motion of all particles in the system is not necessary
equal to 3N ; in fact, a number of constraints may exist that limit the relative positions
of the particles. As a consequence, letting n &le; 3N indicate the number of degrees
of freedom of the system, the set x1(t), . . . , xn(t) suffices to determine the positions
of the particles at time t.</p>
<p/>
</div>
<div class="page"><p/>
<p>1.4 Generalized Coordinates 11
</p>
<p>Depending on the problem in hand it may be more convenient to use a new set of
coordinates q1(t), . . . , qn(t) instead of the Cartesian set x1(t), . . . , xn(t). For this, it
is necessary to extend the calculation of the extremum functions to the case where
the new set is used. Let the relation between the old and new coordinates be
</p>
<p>â§
</p>
<p>âª
âª
âª
â¨
</p>
<p>âª
âª
âª
â©
</p>
<p>q1 = q1(x1, . . . , xn, t)
...
</p>
<p>qn = qn(x1, . . . , xn, t)
</p>
<p>â§
</p>
<p>âª
âª
âª
â¨
</p>
<p>âª
âª
âª
â©
</p>
<p>x1 = x1(q1, . . . , qn, t)
...
</p>
<p>xn = xn(q1, . . . , qn, t)
(1.26)
</p>
<p>The coordinates qi , whose units are not necessarily a length, are called generalized
coordinates. Their time derivatives qÌi = dqi/dt are called generalized velocities.
The explicit dependence on time in (1.26) is present if a relative motion of the two
frames exists: e.g., the relations q1 = x1 &minus; v0t , q2 = x2, q3 = x3 transform the
x1x2x3 set into the q1q2q3 set, that moves with respect to the former one with the
velocity v0 along the first axis.
</p>
<p>Differentiating qi twice with respect to time and using the first of (1.26) pro-
vides a relation of the form qÌi = qÌi(x1, xÌ1, xÌ1, . . . , xn, xÌn, xÌn, t). The above,
after eliminating the second derivatives xÌ1, . . . , xÌn through (1.9), becomes qÌi =
qÌi(x1, xÌ1, . . . , xn, xÌn, t). Finally, replacing x1, xÌ1, . . . , xn, xÌn extracted from the
second of (1.26) yields
</p>
<p>qÌi = qÌi(q, qÌ, t), i = 1, . . . , n, (1.27)
</p>
<p>where q indicates the set q1, . . . , qn, and qÌ indicates the corresponding derivatives.
Equations (1.27) have the same form as (1.9), hence they must be deducible as the
extremum functions of a functional. To show this, one starts from (1.25) by writing
the Lagrangian function in the new set of coordinates. A rather lengthy calculation
based on the chain-differentiation rule yields
</p>
<p>d
</p>
<p>dt
</p>
<p>&part;L
</p>
<p>&part;qÌi
= &part;L
</p>
<p>&part;qi
, i = 1, . . . , n, (1.28)
</p>
<p>that is, the Lagrange equations written in the qi coordinates. Specifically, (1.28) turn
out to be the Lagrange equations of the functional
</p>
<p>S[q] =
&int; b
</p>
<p>a
</p>
<p>L(q, qÌ, t) dt. (1.29)
</p>
<p>This result is very important because it shows that the Lagrange equations are
invariant under a change of coordinates of the type (1.26).
</p>
<p>The solution of (1.28) provides the time evolution of the coordinates qi describing
the particles&rsquo; motion. As (1.28) are n second-order equations, to determine their
solution it is necessary to specify at t = a the values of the n functions qi and
of the correspondent derivatives qÌi , namely, a total of 2 n constants. The function</p>
<p/>
</div>
<div class="page"><p/>
<p>12 1 Analytical Mechanics
</p>
<p>pi = &part;L/&part;qÌi is called generalized momentum or conjugate momentum of qi . From
this definition and from (1.28) it follows
</p>
<p>pi =
&part;L
</p>
<p>&part;qÌi
, pÌi =
</p>
<p>&part;L
</p>
<p>&part;qi
, i = 1, . . . , n. (1.30)
</p>
<p>The derivative pÌi is called generalized force. Due to the definitions (1.30), the gen-
eralized momentum and force depend on the same coordinates as the Lagrangian
function, namely, pi = pi(q, qÌ, t), pÌi = pÌi(q, qÌ, t).
</p>
<p>1.5 Hamiltonian Function
</p>
<p>From (1.30) one derives the following expression of the total derivative with respect
to time of the Lagrangian function:
</p>
<p>dL
</p>
<p>dt
= &part;L
</p>
<p>&part;t
+
</p>
<p>n
&sum;
</p>
<p>i=1
</p>
<p>(
&part;L
</p>
<p>&part;qi
qÌi +
</p>
<p>&part;L
</p>
<p>&part;qÌi
qÌi
</p>
<p>)
</p>
<p>= &part;L
&part;t
</p>
<p>+
n
</p>
<p>&sum;
</p>
<p>i=1
(pÌi qÌi + pi qÌi) . (1.31)
</p>
<p>The quantity in parentheses in (1.31) is the time derivative of pi qÌi , so that
</p>
<p>&part;L
</p>
<p>&part;t
= &minus;dH
</p>
<p>dt
, H =
</p>
<p>n
&sum;
</p>
<p>i=1
pi qÌi &minus; L. (1.32)
</p>
<p>The quantity H defined by (1.32) is called Hamiltonian function. Remembering the
derivation of the Lagrangian function one observes thatL, H , andpi qÌi have the units
of an energy. In turn, the product energy &times; time is called action. In particular, the
functional (1.29) is called action integral [42, Chap. 8]. From the above observation
it follows that qi pi has the units of an action in all coordinate sets.
</p>
<p>By way of example one takes the single-particle Lagrangian functions (1.12) and
(1.18), where the Cartesian coordinates are used. The momentum conjugate to xi is
given, respectively, by
</p>
<p>L = 1
2
mu2 &minus; V &rarr; pi = mui , L =
</p>
<p>1
</p>
<p>2
mu2 &minus; eÏ + eu &middot; A &rarr; pi = mui + eAi .
</p>
<p>(1.33)
</p>
<p>The expression ofH is found from (1.32) after introducing the vector p = (p1,p2,p3)
and indicating its modulus with p. For the case L = mu2/2 &minus; V one finds
</p>
<p>H = 1
2
mu2 + V = 1
</p>
<p>2m
p2 + V , (1.34)
</p>
<p>while the case L = mu2/2 &minus; eÏ + eu &middot; A yields
</p>
<p>H = 1
2
mu2 + eÏ = 1
</p>
<p>2m
|p &minus; eA|2 + eÏ. (1.35)</p>
<p/>
</div>
<div class="page"><p/>
<p>1.6 Hamilton Equations 13
</p>
<p>Still using the Cartesian coordinates, (1.34) is readily extended to the case of a
system of particles having n degrees of freedom. The force acting on the ith degree
of freedom at time t is given by a generalization of (1.10),
</p>
<p>mi uÌi = &minus;
&part;V
</p>
<p>&part;xi
, (1.36)
</p>
<p>where the time derivative is calculated at t and the x1, . . . , xn coordinates appearing
in V are calculated at t as well. For the sake of simplicity the coordinate index i
is also used to distinguish the masses in (1.36). It is implied that the same value of
mi must be applied to the indices associated with the same particle. The Lagrangian
function is calculated in the same manner as in Sect. 1.3 and reads
</p>
<p>L =
n
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>1
</p>
<p>2
miu
</p>
<p>2
i &minus; V (r, t), pi = miui , (1.37)
</p>
<p>whence
</p>
<p>H =
n
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>1
</p>
<p>2
miu
</p>
<p>2
i + V (r, t) =
</p>
<p>n
&sum;
</p>
<p>i=1
</p>
<p>1
</p>
<p>2mi
p2i + V (r, t). (1.38)
</p>
<p>Comparing the two forms of H shown in (1.38), one notes that the second of (1.37)
is exploited to express the Hamiltonian function in terms of the r, p sets instead of
the r, u sets. This procedure is generalized in Sect. 1.6.
</p>
<p>1.6 Hamilton Equations
</p>
<p>As the Lagrangian function depends on q, qÌ, and t , the generalized momentum pi
defined by (1.30) depends on the same variables at most. It is useful to consider also
the inverse relations, where the generalized velocities qÌi are expressed in terms of q,
p, and t . The two sets of relations are
â§
</p>
<p>âª
âª
âª
â¨
</p>
<p>âª
âª
âª
â©
</p>
<p>p1 = p1(q1, qÌ1, . . . , qn, qÌn, t)
...
</p>
<p>pn = pn(q1, qÌ1, . . . , qn, qÌn, t)
</p>
<p>â§
</p>
<p>âª
âª
âª
â¨
</p>
<p>âª
âª
âª
â©
</p>
<p>qÌ1 = qÌ1(q1,p1, . . . , qn,pn, t)
...
</p>
<p>qÌn = qÌn(q1,p1, . . . , qn,pn, t)
(1.39)
</p>
<p>A simple example is given by the two cases of (1.33). Letting qi = xi , qÌi = ui , the
first case gives (1.39) the form pi = m qÌi and qÌi = pi/m, while the second one gives
(1.39) the form pi = m qÌi + e Ai(q, t) and qÌi = [pi &minus; e Ai(q, t)]/m.
</p>
<p>Introducing the second of (1.39) into the definition (1.32) of the Hamiltonian
function expresses the latter in terms of q, p, and t . The derivatives of the Hamiltonian</p>
<p/>
</div>
<div class="page"><p/>
<p>14 1 Analytical Mechanics
</p>
<p>function with respect to the new variables qi , pi are very significant. In fact, for any
index r one finds
</p>
<p>&part;H
</p>
<p>&part;qr
=
</p>
<p>n
&sum;
</p>
<p>i=1
pi
</p>
<p>&part;qÌi
</p>
<p>&part;qr
&minus;
</p>
<p>(
</p>
<p>&part;L
</p>
<p>&part;qr
+
</p>
<p>n
&sum;
</p>
<p>i=1
</p>
<p>&part;L
</p>
<p>&part;qÌi
</p>
<p>&part;qÌi
</p>
<p>&part;qr
</p>
<p>)
</p>
<p>= &minus; &part;L
&part;qr
</p>
<p>= &minus;pÌr . (1.40)
</p>
<p>The two sums in (1.40) cancel each other thanks to the first of (1.30), while the last
equality is due to the second of (1.30). The derivative with respect to pr is found by
the same token,
</p>
<p>&part;H
</p>
<p>&part;pr
=
</p>
<p>(
</p>
<p>qÌr +
n
</p>
<p>&sum;
</p>
<p>i=1
pi
</p>
<p>&part;qÌi
</p>
<p>&part;pr
</p>
<p>)
</p>
<p>&minus;
n
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>&part;L
</p>
<p>&part;qÌi
</p>
<p>&part;qÌi
</p>
<p>&part;pr
= qÌr . (1.41)
</p>
<p>The results of (1.40, 1.41) are condensed in the Hamilton equations
</p>
<p>qÌi =
&part;H
</p>
<p>&part;pi
, pÌi = &minus;
</p>
<p>&part;H
</p>
<p>&part;qi
, i = 1, . . . , n, (1.42)
</p>
<p>that provide a set of 2n differential equations of the first order in the 2n independent
unknowns q1, . . . , qn, p1, . . . ,pn. It is important to note that from (1.42) one readily
derives the following:
</p>
<p>&part;qÌi
</p>
<p>&part;qi
+ &part;pÌi
</p>
<p>&part;pi
= &part;
</p>
<p>2 H
</p>
<p>&part;qi&part;pi
&minus; &part;
</p>
<p>2 H
</p>
<p>&part;pi&part;qi
= 0. (1.43)
</p>
<p>The Hamilton equations (1.42) provide the time evolution of the generalized coor-
dinates qi ; as a consequence, they are equivalent to the Lagrange equations (1.28).
Another way of obtaining the Hamilton equations is to derive them as the extremum
equations of a suitable functional. This is shown in Sect. 1.7.
</p>
<p>In contrast to the Lagrange equations (1.28), that are n second-order differential
equations, the Hamilton equations (1.42) are 2n, first-order differential equations.
To determine the solution of the latter it is necessary to prescribe the values of the
2n unknowns q1, . . . , qn, p1, . . . ,pn at the initial time t = a, that is, 2n constants.
Therefore, the number of constants to be prescribed is the same as for the Lagrange
equations. The independent functions q1, . . . , qn, p1, . . . ,pn are called canonical
coordinates. For each index i the functions qi ,pi are called conjugate coordinates.
</p>
<p>Thanks to (1.42) the total derivative of H reads
</p>
<p>dH
</p>
<p>dt
= &part;H
</p>
<p>&part;t
+
</p>
<p>n
&sum;
</p>
<p>i=1
</p>
<p>(
&part;H
</p>
<p>&part;pi
pÌi +
</p>
<p>&part;H
</p>
<p>&part;qi
qÌi
</p>
<p>)
</p>
<p>= &part;H
&part;t
</p>
<p>= &minus;&part;L
&part;t
</p>
<p>, (1.44)
</p>
<p>where the last equality derives from the first of (1.32). If the Lagrangian function
does not depend explicitly on time it follows dH/dt = 0, namely, H is a constant
of motion. Its value is fixed by the values of the canonical coordinates at the initial
time t = a. From (1.44) it also follows that dH/dt = 0 is equivalent to &part;H/&part;t = 0.
In other terms, the Hamiltonian function is a constant of motion if it does not depend
explicitly on time, and vice versa.</p>
<p/>
</div>
<div class="page"><p/>
<p>1.7 Time&ndash;Energy Conjugacy&mdash;Hamilton&ndash;Jacobi Equation 15
</p>
<p>If the Lagrangian function does not depend on one of the coordinates, say, qr ,
the latter is called cyclic or ignorable. From the second of (1.30) it follows that, if
qr is cyclic, its conjugate momentum pr is a constant of motion. Moreover, due to
the second of (1.42) it is &part;H/&part;qr = 0, namely, the Hamiltonian function does not
depend on qr either.
</p>
<p>1.7 Time&ndash;Energy Conjugacy&mdash;Hamilton&ndash;Jacobi Equation
</p>
<p>Equations (1.42) can also be derived as the extremum equations of a functional. To
show this it suffices to replace the Lagrangian function taken from the second of
(1.32) into the functional (1.29), this yielding
</p>
<p>S =
&int; b
</p>
<p>a
</p>
<p>(
n
</p>
<p>&sum;
</p>
<p>i=1
pi qÌi &minus;H
</p>
<p>)
</p>
<p>dt. (1.45)
</p>
<p>Using in (1.45) the expressions of the generalized velocities given by the second
of (1.39), the integrand becomes a function of qi , pi , and t . Then, the extremum
equations are found by introducing the variations in the coordinates, that become
qi+Î±iÎ·i . Like in the case of (1.1) it is assumed that Î·i vanishes at a and b. Similarly,
the conjugate momenta become pi + Î²iÎ¶i . Differentiating (1.45) with respect to Î±i
or Î²i yields, respectively,
</p>
<p>&part;S
</p>
<p>&part;Î±i
=
</p>
<p>&int; b
</p>
<p>a
</p>
<p>[
</p>
<p>(pi + Î²iÎ¶i) Î·Ìi &minus;
&part;H
</p>
<p>&part;(qi + Î±iÎ·i)
Î·i
</p>
<p>]
</p>
<p>dt , (1.46)
</p>
<p>&part;S
</p>
<p>&part;Î²i
=
</p>
<p>&int; b
</p>
<p>a
</p>
<p>[
</p>
<p>(qÌi + Î±i Î·Ìi) Î¶i &minus;
&part;H
</p>
<p>&part;(pi + Î²iÎ¶i)
Î¶i
</p>
<p>]
</p>
<p>dt. (1.47)
</p>
<p>Letting Î±1 = . . . = Î²n = 0 in (1.46, 1.47), integrating by parts the term containing
Î·Ìi , and using the condition Î·i(a) = Î·i(b) = 0 provides
(
&part;S
</p>
<p>&part;Î±i
</p>
<p>)
</p>
<p>0
</p>
<p>= &minus;
&int; b
</p>
<p>a
</p>
<p>(
</p>
<p>pÌi +
&part;H
</p>
<p>&part;qi
</p>
<p>)
</p>
<p>Î·i dt ,
</p>
<p>(
&part;S
</p>
<p>&part;Î²i
</p>
<p>)
</p>
<p>0
</p>
<p>=
&int; b
</p>
<p>a
</p>
<p>(
</p>
<p>qÌi &minus;
&part;H
</p>
<p>&part;pi
</p>
<p>)
</p>
<p>Î¶i dt. (1.48)
</p>
<p>As in Sect. 1.2 the equations for the extremum functions are found by letting
(&part;S/&part;Î±i)0 = 0, (&part;S/&part;Î²i)0 = 0. Such equations coincide with (1.42). It is worth
observing that, as no integration by part is necessary for obtaining the second of
(1.48), the derivation of (1.42) does not require any prescription for the boundary
conditions of Î¶i . On the other hand, considering that in the Hamilton equations qi
and pi are independent variables, one can add the prescription Î¶i(a) = Î¶i(b) = 0.
Although the latter is not necessary here, it becomes useful in the treatment of the
canonical transformations, as shown in Sect. 2.2.</p>
<p/>
</div>
<div class="page"><p/>
<p>16 1 Analytical Mechanics
</p>
<p>In the coordinate transformations discussed so far, time was left unchanged. This
aspect is not essential: in fact, within the coordinate transformation one can replace t
with another parameter that depends single-valuedly on t . This parameter, say, Î¸ (t),
is equally suitable for describing the evolution of the particles&rsquo; system; proceeding
in this way transforms (1.45) into
</p>
<p>S =
&int; Î¸ (b)
</p>
<p>Î¸ (a)
</p>
<p>(
n
</p>
<p>&sum;
</p>
<p>i=1
pi qÌi
</p>
<p>dt
</p>
<p>dÎ¸
&minus;H dt
</p>
<p>dÎ¸
</p>
<p>)
</p>
<p>dÎ¸ =
&int; Î¸ (b)
</p>
<p>Î¸ (a)
</p>
<p>(
n
</p>
<p>&sum;
</p>
<p>i=1
piq
</p>
<p>&prime;
i &minus;H t &prime;
</p>
<p>)
</p>
<p>dÎ¸ , (1.49)
</p>
<p>where the primes indicate the derivatives with respect to Î¸ . Now, letting qn+1 = t ,
pn+1 = &minus;H , the Lagrangian function is recast in the more compact form L =
&sum;n+1
</p>
<p>i=1 piq
&prime;
i . Remembering the definition (1.30) of the conjugate momenta, it follows
</p>
<p>that the latter becomes pi = &part;L/&part;q &prime;i . In conclusion, the negative Hamiltonian func-
tion is the momentum conjugate to Î¸ . This result is not due to any particular choice
of the relation Î¸ (t), hence it holds also for the identical transformation Î¸ = t ; in
other terms, &minus;H is the momentum conjugate to t .
</p>
<p>If the upper limit b in the action integral S (Eq. (1.29)) is considered as a variable,
the Langrangian is found to be the total time derivative of S. Letting b &larr; t , from
the (1.45) form of S one derives its total differential
</p>
<p>dS =
n
</p>
<p>&sum;
</p>
<p>i=1
pidqi &minus;Hdt. (1.50)
</p>
<p>As a consequence it is pi = &part;S/&part;qi , H = &minus;&part;S/&part;t . Remembering that H depends
on the generalized coordinates and momenta, and on time, one may abridge the
above findings into the relation
</p>
<p>&part;S
</p>
<p>&part;t
+H
</p>
<p>(
</p>
<p>q1, . . . , qn,
&part;S
</p>
<p>&part;q1
, . . . ,
</p>
<p>&part;S
</p>
<p>&part;qn
, t
</p>
<p>)
</p>
<p>= 0, pi =
&part;S
</p>
<p>&part;qi
, (1.51)
</p>
<p>that is, a partial-differential equation in the unknown function S. The former is called
Hamilton&ndash;Jacobi equation, while the latter in this context is called Hamilton&rsquo;s prin-
cipal function. As (1.51) is a first-order equation in the n+ 1 variables q1, . . . , qn, t ,
the solution S contains n+ 1 integration constants. One of them is an additive con-
stant on S, as is easily found by observing that (1.51) contains the derivatives of
S, not S itself. For this reason the additive constant is irrelevant and can be set to
zero, so that the integration constants reduce to n. It is shown in Sect. 2.2 that (1.51)
provides the time evolution of the generalized coordinates qi . As a consequence it
is equivalent to the Lagrange equations (1.28) and to the Hamilton equations (1.42)
for describing the system&rsquo;s dynamics.</p>
<p/>
</div>
<div class="page"><p/>
<p>1.8 Poisson Brackets 17
</p>
<p>1.8 Poisson Brackets
</p>
<p>Let Ï, Ï be arbitrary functions of the canonical coordinates, differentiable with
respect to the latter. The Poisson bracket of Ï and Ï is defined as the function3
</p>
<p>[Ï, Ï ] =
n
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>(
&part;Ï
</p>
<p>&part;qi
</p>
<p>&part;Ï
</p>
<p>&part;pi
&minus; &part;Ï
</p>
<p>&part;pi
</p>
<p>&part;Ï
</p>
<p>&part;qi
</p>
<p>)
</p>
<p>. (1.52)
</p>
<p>From (1.52) it follows [Ï, Ï ] = &minus; [Ï , Ï], [Ï, Ï] = 0. Also, due to (1.42) it is
dÏ
</p>
<p>dt
= &part;Ï
</p>
<p>&part;t
+ [Ï,H ] . (1.53)
</p>
<p>Letting Ï = H shows that (1.44) is a special case of (1.53). If Ï is a constant of
motion, then
</p>
<p>&part;Ï
</p>
<p>&part;t
+ [Ï,H ] = 0. (1.54)
</p>
<p>If Ï does not depend explicitly on time, (1.53) yields
</p>
<p>dÏ
</p>
<p>dt
= [Ï,H ] (1.55)
</p>
<p>where, in turn, the right hand side is equal to zero if Ï is a constant of motion, while
it is different from zero in the other case. Special cases of the Poisson bracket are
</p>
<p>[
</p>
<p>qi , qj
]
</p>
<p>= 0,
[
</p>
<p>pi ,pj
]
</p>
<p>= 0,
[
</p>
<p>qi ,pj
]
</p>
<p>= Î´ij , (1.56)
with Î´ij the Kronecker symbol (A.18). Other interesting expressions are found by
introducing the 2 n-dimensional vectors s, e defined as
</p>
<p>s =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â£
</p>
<p>q1
...
</p>
<p>qn
</p>
<p>p1
...
</p>
<p>pn
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¦
</p>
<p>, e =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â£
</p>
<p>&part;H/&part;p1
...
</p>
<p>&part;H/&part;pn
</p>
<p>&minus;&part;H/&part;q1
...
</p>
<p>&minus;&part;H/&part;qn
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¦
</p>
<p>. (1.57)
</p>
<p>Using the definitions (1.57) one finds
</p>
<p>sÌ = e, divs sÌ =
n
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>(
&part;qÌi
</p>
<p>&part;qi
+ &part;pÌi
</p>
<p>&part;pi
</p>
<p>)
</p>
<p>= 0, (1.58)
</p>
<p>3 The definition and symbol (1.52) of the Poisson bracket conform to those of [42, Sect. 9&ndash;5]. In
[67, Sect. 42], instead, the definition has the opposite sign and the symbol {Ï, Ï } is used. In [110,
Sect. 11] the definition is the same as that adopted here, while the symbol {Ï, Ï } is used.</p>
<p/>
</div>
<div class="page"><p/>
<p>18 1 Analytical Mechanics
</p>
<p>the first of which expresses the Hamilton equations (1.42) in vector form, while
the second one derives from (1.43). The symbol divs indicates the divergence with
respect to all the variables that form vector s (Sect. A.3). Now, taking an arbitrary
function Ï like that used in (1.53) and calculating the divergence of the product Ï sÌ
yields, thanks to (1.58) and to (A.16, A.12),
</p>
<p>divs(Ï sÌ) = Ï divs sÌ + sÌ &middot; gradsÏ =
n
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>(
&part;Ï
</p>
<p>&part;qi
qÌi +
</p>
<p>&part;Ï
</p>
<p>&part;pi
pÌi
</p>
<p>)
</p>
<p>= [Ï,H ]. (1.59)
</p>
<p>1.9 Phase Space and State Space
</p>
<p>Given a system of particles having n degrees of freedom it is often convenient to
describe its dynamical properties by means of a geometrical picture. To this purpose
one introduces a 2n-dimensional space whose coordinates areq1, . . . , qn,p1, . . . ,pn.
This space has no definite metrical structure, one simply assumes that qi and pi are
plotted as Cartesian coordinates of an Euclidean space [65, Chap. 6-5]. Following
Gibbs, the space thus defined is often called phase space. However, it is convenient to
better specify the terminology by using that of Ehrenfest, in which the term Î³-space
is used for this space (the citations of Gibbs and Ehrenfest are in [110, Sect. 17]).
At some instant t the whole set of canonical coordinates q1, . . . , qn, p1, . . . ,pn
corresponds to a point of the Î³-space. Such a point is called phase point. In turn, the
state of a mechanical system at some instant t is defined as the set of its canonical
coordinates at that instant. It follows that the phase point represents the dynamical
state of the system at t . As time evolves, the phase points representing the state at
different instants provide a curve of the Î³-space called phase trajectory.
</p>
<p>A generalization of the Î³-space is obtained by adding the time t as a (2n + 1)th
coordinate. The (2n+ 1)-dimensional space thus obtained is called state space [65,
Chap. 6&ndash;5]. The curve of the state space describing the system&rsquo;s dynamics is called
state trajectory. Consider two systems governed by the same Hamiltonian function
and differing only in the initial conditions. The latter are represented by two distinct
points of the 2n-dimensional section of the state space corresponding to t = 0. The
subsequent time evolution of the two systems provides two state trajectories that never
cross each other. In fact, if a crossing occurred at, say, t = tÌ , the canonical coordinates
of the two Hamiltonian functions would be identical there, this making the initial
conditions of the subsequent motion identical as well. As a consequence, the two
state trajectories would coincide for t &ge; tÌ . However, the same reasoning holds when
considering the motion backward in time (t &le; tÌ). Thus, the two trajectories should
coincide at all times, this contradicting the hypothesis that the initial conditions at
t = 0 were different.
</p>
<p>A similar reasoning about the crossing of trajectories is possible in the Î³-space.
The conclusion is that the phase trajectories do not cross each other if the Hamiltonian
function does not depend explicitly on time. Instead, they may cross each other if
the Hamiltonian function depends on time; the crossing, however, occurs at different</p>
<p/>
</div>
<div class="page"><p/>
<p>1.10 Complements 19
</p>
<p>times (in other terms, the set of canonical coordinates of the first system calculated
at t = t1 may coincide with the set of canonical coordinates of the second system
calculated at t = t2 only in the case t2 ï¿½= t1).
</p>
<p>Despite of the larger number of dimensions, the adoption of the state space is
convenient for the geometrical representation of the system&rsquo;s dynamics, because a
trajectory is uniquely specified by the initial point and no crossing of trajectories
occurs. With the provision stated above, this applies also to the Î³-space. In contrast,
consider a geometrical picture of the Lagrangian type, in which the generalized
coordinates q1, . . . , qn only are used. The latter may be considered as the Cartesian
coordinates of an n-dimensional Euclidean space called configuration space. To
specify a trajectory in such a space it is necessary to prescribe the position q1, . . . , qn
and velocity qÌ1, . . . , qÌn of the system at t = 0. If one considers two or more systems
differing only in the initial conditions, the motion of each system could start from
every point of the configuration space and in every direction. As a consequence,
it would be impossible to obtain an ordered picture of the trajectories, which will
inevitably cross each other.
</p>
<p>As mentioned above, the Î³-space for a system having n degrees of freedom is
a 2n-dimensional space whose coordinates are q1, . . . , qn, p1, . . . ,pn. It is some-
times convenient to use a different type of phase space whose dimension is twice
the number of degrees of freedom possessed by each of the system&rsquo;s particles. To
specifiy this issue, consider the case of a system made of N point-like particles,
with no constraints. In this case each particle (say, the j th one) has three degrees
of freedom and its dynamical state at the time t is determined by the six canonical
coordinates qÌ1j , qÌ2j , qÌ3j , pÌ1j , pÌ2j , pÌ3j . Together, the latter identify a point Xj of a
six-dimensional phase space called &micro;-space4. At the time t the system as a whole is
represented in the &micro;-space by the set of N points X1, . . . ,XN .
</p>
<p>1.10 Complements
</p>
<p>1.10.1 Higher-Order Variational Calculus
</p>
<p>The variational calculus described in Sect. 1.2 can be extended to cases were the
function g in (1.1) depends on derivatives of a higher order than the first. Consider
for instance the functional
</p>
<p>G[w] =
&int; b
</p>
<p>a
</p>
<p>g(w, wÌ, wÌ, Î¾ ) dÎ¾. (1.60)
</p>
<p>Following the procedure of Sect. 1.2 and assuming that the derivative Î·Ì vanishes
at a and b, yields the following differential equation for the extremum functions of
(1.60):
</p>
<p>&minus; d
2
</p>
<p>dÎ¾ 2
&part;g
</p>
<p>&part;wÌ
+ d
</p>
<p>dÎ¾
</p>
<p>&part;g
</p>
<p>&part;wÌ
= &part;g
</p>
<p>&part;w
. (1.61)
</p>
<p>4 The letter &ldquo;&micro;&rdquo; stands for &ldquo;molecule&rdquo;, whereas the letter &ldquo;Î³&rdquo; in the term &ldquo;Î³-space&rdquo; stands for &ldquo;gas&rdquo;.</p>
<p/>
</div>
<div class="page"><p/>
<p>20 1 Analytical Mechanics
</p>
<p>1.10.2 Lagrangian Invariance and Gauge Invariance
</p>
<p>It is shown in Sect. 1.2 that the extremum functions wi(Î¾ ) are invariant under addition
to g of the total derivative of an arbitrary function h that depends on w and Î¾ only
(refer to Eq. (1.8)). Then, it is mentioned in Sect. 1.3.2 that the E and B fields are
invariant under the gauge transformation (1.19), whereh(r, t) is an arbitrary function.
These two properties have in fact the same origin, namely, the description based upon
a Lagrangian function. In fact, as shown in Sect. 4.2, a Lagrangian description is
possible also in the case of a system having a continuous distribution of the degrees
of freedom like, for instance, the electromagnetic field.
</p>
<p>1.10.3 Variational Calculus with Constraints
</p>
<p>In several problems it is required that the function w, introduced in Sect. 1.2 as the
extremum function of functional (1.1), be able to fulfill one or more constraints. By
way of example consider the constraint
</p>
<p>G0 =
&int; b
</p>
<p>a
</p>
<p>g0(w, wÌ, Î¾ ) dÎ¾ , (1.62)
</p>
<p>where the function g0 and the number G0 are prescribed. A typical case where
(1.62) occurs is that of finding the maximum area bounded by a perimeter of given
length (Dido&rsquo;s problem). For this reason, extremum problems having a constraint
like (1.62) are called isoperimetric even when they have no relation with geometry
[115, Par. 4-1].
</p>
<p>To tackle the problem one extends the definition of the variation of w by letting
Î´w = Î±1Î·1+Î±2Î·2, where Î·1(Î¾ ), Î·2(Î¾ ) are arbitrary functions that are differentiable in
the interior of [a, b] and fulfill the conditions Î·1(a) = Î·1(b) = 0, Î·2(a) = Î·2(b) = 0.
</p>
<p>If w is an extremum function of G that fulfills (1.62), replacing w with w + Î´w
transforms (1.1, 1.62) to a pair of functions of the Î±1, Î±2 parameters, namely,
</p>
<p>G = G(Î±1,Î±2), G0(Î±1,Î±2) = G0(0, 0) = const. (1.63)
</p>
<p>The first of (1.63) has an extremum at Î±1 = Î±2 = 0, while the second one establishes
a relation between Î±1 and Î±2. The problem is thus reduced to that of calculating a
constrained extremum, and is solved by the method of the Lagrange multipliers.
</p>
<p>For this, one considers the function GÎ» = G(Î±1,Î±2) + Î»G0(Î±1,Î±2), with Î» an
indeterminate parameter, and calculates the free extremum of GÎ» by letting
</p>
<p>(
&part;GÎ»
</p>
<p>&part;Î±1
</p>
<p>)
</p>
<p>0
</p>
<p>= 0,
(
&part;GÎ»
</p>
<p>&part;Î±2
</p>
<p>)
</p>
<p>0
</p>
<p>= 0, (1.64)
</p>
<p>where index 0 stands for Î±1 = Î±2 = 0. The rest of the calculation is the same as
in Sect. 1.2; the two relations (1.64) turn out to be equivalent to each other and</p>
<p/>
</div>
<div class="page"><p/>
<p>1.10 Complements 21
</p>
<p>provide the same Euler equation. More specifically, from the definition of G and G0
as integrals of g and g0 one finds that the Euler equation of this case is obtained from
that of Sect. 1.2 by replacing g with gÎ» = g + Î»g0:
</p>
<p>d
</p>
<p>dÎ¾
</p>
<p>&part;gÎ»
</p>
<p>&part;wÌ
= &part;gÎ»
</p>
<p>&part;w
. (1.65)
</p>
<p>As (1.65) is a second-order equation, its solution w contains two integration con-
stants. The Î» multiplier is an additional indeterminate constant. The three constants
are found from the constraint (1.62) and from the two relations provided by the
boundary or initial conditions of w.
</p>
<p>1.10.4 An Interesting Example of Extremum Equation
</p>
<p>Consider the Hamilton&ndash;Jacobi Eq. (1.51) for a single particle of mass m. Using the
Cartesian coordinates and a Hamiltonian function of the form
</p>
<p>H = p
2
</p>
<p>2m
+ V (x1, x2, x3, t), p2 = p21 + p22 + p23 , (1.66)
</p>
<p>the Hamilton&ndash;Jacobi equation reads
</p>
<p>&part;S
</p>
<p>&part;t
+ |gradS|
</p>
<p>2
</p>
<p>2m
+ V (x1, x2, x3, t) = 0, pi =
</p>
<p>&part;S
</p>
<p>&part;qi
. (1.67)
</p>
<p>If V is independent of time, then H = E and the separation S = W &minus; E t
(Sect. 2.4) yields &part;S/&part;t = &minus;E, gradS = gradW = p. It follows
</p>
<p>|gradW |2
2m
</p>
<p>+ V (x1, x2, x3) = E. (1.68)
</p>
<p>Both Hamilton&rsquo;s principal (S) and characteristic (W ) functions have the dimensions
of an action and are defined apart from an additive constant. Also, the form of |gradW |
is uniquely defined by that of V &minus;E. In turn, E is prescribed by the initial conditions
of the particle&rsquo;s motion.
</p>
<p>Consider now the case where E &ge; V within a closed domain ï¿½ whose boundary
is &part;ï¿½. As gradW is real, the motion of the particle is confined within ï¿½, and gradW
vanishes at the boundary &part;ï¿½. The Hamilton&ndash;Jacobi equation for W (1.68) is recast
in a different form by introducing an auxiliary function w such that
</p>
<p>w = w0 exp (W/Î¼), (1.69)
</p>
<p>with Î¼ a constant having the dimensions of an action. The other constant w0 is used
for prescribing the dimensions of w. Apart from this, the choice of w0 is arbitrary
due to the arbitrariness of the additive constant of W . Taking the gradient of (1.69)
yields Î¼ gradw = w gradW , with w ï¿½= 0 due to the definition. As gradW vanishes</p>
<p/>
</div>
<div class="page"><p/>
<p>22 1 Analytical Mechanics
</p>
<p>at the boundary, gradw vanishes there as well. As a consequence, w is constant over
the boundary. Inserting (1.69) into (1.68) yields
</p>
<p>Î¼2
</p>
<p>2m
</p>
<p>|gradw|2
w2
</p>
<p>+ V (x1, x2, x3) = E, (1.70)
</p>
<p>which determines |gradw/w| as a function of V &minus; E. Rearranging the above and
observing that div(wgradw) = w&nabla;2 w + |gradw|2 (Sect. A.1) provides
</p>
<p>Î¼2
</p>
<p>2m
</p>
<p>[
</p>
<p>div(wgradw) &minus; w&nabla;2 w
]
</p>
<p>+ (V &minus; E) w2 = 0. (1.71)
</p>
<p>Integrating (1.71) over ï¿½ and remembering that gradw vanishes at the boundary,
&int;
</p>
<p>ï¿½
</p>
<p>w
</p>
<p>[
</p>
<p>&minus; Î¼
2
</p>
<p>2m
&nabla;2 w + (V &minus; E) w
</p>
<p>]
</p>
<p>dï¿½ = 0. (1.72)
</p>
<p>The term in brackets of (1.72) does not necessarily vanish. In fact, the form of w is
such that only the integral as a whole vanishes. On the other hand, by imposing that
the term in brackets vanishes, and replacing Î¼ with the reduced Planck constant hÌ,
yields
</p>
<p>&minus; hÌ
2
</p>
<p>2m
&nabla;2 w + (V &minus; E) w = 0, (1.73)
</p>
<p>namely, the Schr&ouml;dinger equation independent of time (7.45). This result shows that
the Schr&ouml;dinger equation derives from a stronger constraint than that prescribed by
the Hamilton&ndash;Jacobi equation.
</p>
<p>An immediate consequence of replacing the integral relation (1.72) with the dif-
ferential Eq. (1.73) is that the domain of w is not limited any more by the condition
E &ge; V , but may extend to infinity.
</p>
<p>Another consequence is that, if the boundary conditions are such that w vanishes
over the boundary (which, as said above, may also be placed at infinity), then (1.73)
is solvable only for specific values of E, that form its spectrum of eigenvalues.
Moreover it can be demonstrated, basing on the form of the Schrodinger equation,
that the condition E &ge; Vmin must be fulfilled (Sect. 8.2.3).
</p>
<p>It is interesting to note another relation between the Schr&ouml;dinger and the
Hamilton&ndash;Jacobi equations. For the sake of simplicity one takes the one-dimensional
case of the Hamilton&ndash;Jacobi equation expressed in terms of w (1.70):
</p>
<p>Î¼2
</p>
<p>2m
(w&prime;)2 + V (x) w2 = E w2, (1.74)
</p>
<p>where the prime indicates the derivative with respect to x. The left hand side of the
equation may be considered the generating function g = g(w, w&prime;, x) of a functional
G, defined over an interval of the x axis that may extend to infinity:
</p>
<p>G[w] =
&int; b
</p>
<p>a
</p>
<p>[
Î¼2
</p>
<p>2m
(w&prime;)2 + V w2
</p>
<p>]
</p>
<p>dx. (1.75)</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 23
</p>
<p>One then seeks the extremum function w of G that fulfills the constraint
</p>
<p>G0[w] =
&int; b
</p>
<p>a
</p>
<p>w2 dx = 1. (1.76)
</p>
<p>The problem is solved by the method of Sect. 1.10.3, namely, by letting g0 = w2,
gE = g &minus; E g0, and applying the Euler equation to gE :
</p>
<p>d
</p>
<p>dx
</p>
<p>&part;gE
</p>
<p>&part;w&prime;
= d
</p>
<p>dx
</p>
<p>Î¼2
</p>
<p>m
w&prime; = Î¼
</p>
<p>2
</p>
<p>m
w&prime;&prime;,
</p>
<p>&part;gE
</p>
<p>&part;w
= 2 (V &minus; E) w, (1.77)
</p>
<p>showing that the Schr&ouml;dinger equation is actually the Euler equation of the functional
G subjected to the constraint G0, with the eigenvalue E provided by the Lagrange
multiplier. This result holds also in the higher-dimensional cases, and is in fact the
method originally used by Schr&ouml;dinger to determine the time-independent equation
[94, Eqs. (23, 24)].
</p>
<p>1.10.5 Constant-Energy Surfaces
</p>
<p>Consider the Î³-space for a system having n degrees of freedom (Sect. 1.9). If the
system is conservative, the relation H (q1, . . . , qn, p1, . . . ,pn) = E introduces a
constraint among the canonical coordinates. Due to this, at each instant of time the
latter must belong to the (2n &minus; 1)-dimensional surface H = E of the phase space,
that is called constant-energy surface. As E is prescribed by the initial conditions,
the phase point of a conservative system always belongs to the same constant-energy
surface.
</p>
<p>For a system having one degree of freedom the relation describing the constant-
energy surface reduces to H (q,p) = E, that describes a curve in the q p plane. The
corresponding state trajectory is a curve of the three-dimensional q p t space.
</p>
<p>Problems
</p>
<p>1.1 In the xy plane find the geodesic y = y(x) through the points A &equiv; (a, ya),
B &equiv; (b, yb), A ï¿½= B.
</p>
<p>1.2 Given the Hamiltonian function H = p2/(2m) + (c/2) x2, m, c &gt; 0 (that
describes the linear harmonic oscillator, Sect. 3.3), find the constant-energy
curves of the xp plane corresponding to different values of the total energy E.
</p>
<p>1.3 Given the Hamiltonian function of the harmonic oscillator of the general form
H = p2/(2m) + (c/s) |x|s , m, c, s &gt; 0, find the constant-energy curves of
the xp plane corresponding to a fixed total energy E and to different values of
parameter s.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 2
</p>
<p>Coordinate Transformations and Invariance
Properties
</p>
<p>2.1 Introduction
</p>
<p>An important generalization of the subject of coordinate transformation is that of
canonical transformation, which leads to the concept of generating function and,
through it, to the definition of the principal function and characteristic function
of Hamilton. The principal function is found to coincide with the solution of the
Hamilton&ndash;Jacobi equation introduced in the previous chapter, this showing the equiv-
alence of the approach based on the variational principles with that based on the
canonical transformations. Connected with the Hamiltonian formalism is also the
important concept of separability. Still based on Hamilton&rsquo;s principal function is
the concept of phase velocity applied to a mechanical system, that brings about
an analogy with the electromagnetic theory. The aspects mentioned above give an-
other indication about the generality that is reached by the formalism of Analytical
Mechanics illustrated in this part of the book.
</p>
<p>Another fundamental issue is that of the invariance properties of the mechanical
systems. It is shown that, basing only on the observation of symmetries possessed by
the Lagrangian function or other functions connected to it, one derives the existence
of invariance properties of the system. Among these are the constants of motion,
namely, the dynamical properties that are constant in time and are therefore known
from the motion&rsquo;s initial condition.
</p>
<p>Of special relevance among the constants of motion are the total energy, the total
momentum, and the total angular momentum of the system. The conservation of
the total energy is related to the uniformity of time, that of the total momentum is
related to the uniformity of space and, finally, that of the total angular momentum
is related to the isotropy of space. Besides the theoretical interest connected to it,
the knowledge of a constant of motion is important also for practical purposes: by
introducing a known constraint among the canonical coordinates, it is of use in the
separation procedure.
</p>
<p>&copy; Springer Science+Business Media New York 2015 25
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_2</p>
<p/>
</div>
<div class="page"><p/>
<p>26 2 Coordinate Transformations and Invariance Properties
</p>
<p>This chapter completes the illustration of the basic principles of Analytical Me-
chanics started in the previous one. The purpose of the two chapters is to introduce
a number of concepts that are not only useful per se, but also constitute a basis for
the concepts of Quantum Mechanics that are introduced in later chapters. The first
subject is that of the canonical transformations, followed by the definition and prop-
erties of the Hamilton characteristic function and of the phase velocity. Then, the
invariance properties that derive from the symmetries of the Lagrangian function are
discussed. The chapter continues with a short description of the Maupertuis principle
and of the expression of the angular momentum in spherical coordinates. The last
paragraphs deal with the linear motion and the action-angle variables.
</p>
<p>2.2 Canonical Transformations
</p>
<p>Section 1.4 introduced the generalized coordinates q1, . . . , qn, that are defined by
the first of (1.26) starting from a set of Cartesian coordinates x1, . . . , xn. From this,
one defines the generalized velocities qÌi and, from the second of (1.26), calculates
the Lagrangian function in the new variables L(q, qÌ, t). The conjugate momenta pi
are derived from the latter using the first of (1.30) and, finally, the new Hamiltonian
function is determined from the second of (1.32). From this, the Hamilton equa-
tions (1.42) in the new coordinates are deduced. The process depicted here is a series
of replacement, elimination, and differentiation steps.
</p>
<p>Relations like (1.26), that transform a set of coordinates into another one, are
called point transformations. It has been observed in Sect. 1.4 that the canonical
coordinates q1, . . . , qn, p1, . . . ,pn are mutually independent. It follows that the
point transformations are not the most general coordinate transformations, because
they act on the q1, . . . , qn only. The most general transformations act simultaneously
on the generalized coordinate and momenta, hence they have the form
</p>
<p>â§
</p>
<p>âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
â¨
</p>
<p>âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
âª
â©
</p>
<p>qÌ1 = qÌ1(q1, . . . , qn,p1, . . . ,pn, t)
...
</p>
<p>qÌn = qÌn(q1, . . . , qn,p1, . . . ,pn, t)
pÌ1 = pÌ1(q1, . . . , qn,p1, . . . ,pn, t)
</p>
<p>...
</p>
<p>pÌn = pÌn(q1, . . . , qn,p1, . . . ,pn, t)
</p>
<p>(2.1)
</p>
<p>where qi ,pi indicate the old canonical coordinates and qÌi , pÌi indicate the new
ones. If H is the Hamiltonian function in the old coordinates, introducing into H
the inverse transformations of (2.1) yields a function HÌ that depends on the new
coordinates and on time.
</p>
<p>For an arbitrary choice of the form of (2.1) it is not possible in general to deduce
from HÌ the Hamilton equations in the new coordinates. In fact it is necessary to</p>
<p/>
</div>
<div class="page"><p/>
<p>2.2 Canonical Transformations 27
</p>
<p>limit the choice of the transformation (2.1) to the cases where the resulting HÌ is a
Hamiltonian function proper, namely, it is such that
</p>
<p>dqÌi
dt
</p>
<p>= &part;HÌ
&part;pÌi
</p>
<p>,
dpÌi
dt
</p>
<p>= &minus;&part;HÌ
&part;qÌi
</p>
<p>, i = 1, . . . , n (2.2)
</p>
<p>are fulfilled. The transformations (2.1) that make (2.2) to hold are called canonical
transformations. The procedure by which the Hamilton equations in the old coor-
dinates are found has been illustrated in Sect. 1.4 and is based on the derivation of
the extremum equation of the action integral (1.45). To obtain (2.2) the same calcu-
lation must be repeated based on the action integral defined in the new coordinates.
It follows that for two sets of coordinates qi ,pi and qÌi , pÌi connected by a canonical
transformation, the following must hold simultaneously:
</p>
<p>S =
&int; b
</p>
<p>a
</p>
<p>(
n
</p>
<p>&sum;
</p>
<p>i=1
pi
</p>
<p>dqi
dt
</p>
<p>&minus;H
)
</p>
<p>dt , SÌ =
&int; b
</p>
<p>a
</p>
<p>(
n
</p>
<p>&sum;
</p>
<p>i=1
pÌi
</p>
<p>dqÌi
dt
</p>
<p>&minus; HÌ
)
</p>
<p>dt. (2.3)
</p>
<p>The difference between the two integrals in (2.3) can be set equal to an arbitrary
constant because the calculation uses only the variations of S or SÌ. As the limits of
the two integrals are fixed to the same values a and b, the constant can in turn be
written as the integral between a and b of the total time derivative of an arbitrary
function K . In this way the relation between the two integrands in (2.3) reads
</p>
<p>n
&sum;
</p>
<p>i=1
pi
</p>
<p>dqi
dt
</p>
<p>&minus;H =
n
</p>
<p>&sum;
</p>
<p>i=1
pÌi
</p>
<p>dqÌi
dt
</p>
<p>&minus; HÌ + dK
dt
</p>
<p>. (2.4)
</p>
<p>It is worth reminding that in the derivation of the Hamilton equations in Sect. 1.6 it
is assumed that all variations of generalized coordinates and momenta vanish at the
integration limits. Here this applies to both the old and new sets of coordinates. As a
consequence, K can be made to depend on all 4n coordinates qi , pi , qÌi , pÌi , and on
time t . Due to the 2n relations (2.1) that define the canonical transformation, only
2n coordinates are independent. Thus, K can be made to depend on 2n coordinates
chosen among the 4n available ones, and on time. The most interesting cases are
those where K has one of the following forms [42, Sect. 9-1]:
</p>
<p>K1 = K1(q, qÌ, t), K2 = K2(q, pÌ, t), K3 = K3(p, qÌ, t), K4 = K4(p, pÌ, t).
(2.5)
</p>
<p>By way of example, select the first form: replacingK1 into (2.4), calculating dK1/dt ,
and multiplying both sides by dt yields
</p>
<p>n
&sum;
</p>
<p>i=1
</p>
<p>(
&part;K1
</p>
<p>&part;qi
&minus; pi
</p>
<p>)
</p>
<p>dqi +
n
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>(
&part;K1
</p>
<p>&part;qÌi
+ pÌi
</p>
<p>)
</p>
<p>dqÌi +
(
&part;K1
</p>
<p>&part;t
+H &minus; HÌ
</p>
<p>)
</p>
<p>dt = 0,
</p>
<p>(2.6)</p>
<p/>
</div>
<div class="page"><p/>
<p>28 2 Coordinate Transformations and Invariance Properties
</p>
<p>where the left hand side is a total differential in the independent variables qi , qÌi , and
t . To fulfill (2.6) the parentheses must vanish independently from each other, whence
</p>
<p>pi =
&part;K1
</p>
<p>&part;qi
, pÌi = &minus;
</p>
<p>&part;K1
</p>
<p>&part;qÌi
, HÌ = H + &part;K1
</p>
<p>&part;t
, i = 1, . . . , n. (2.7)
</p>
<p>As K1 is prescribed, the first two equations in (2.7) provide 2n relations involving
the 4n coordinates qi , pi , qÌi , pÌi , that constitute the canonical transformation sought.
Using the latter one expresses the right hand side of the third of (2.7) in terms of qÌi ,
pÌi , this yielding the new Hamiltonian function HÌ (qÌ, pÌ, t). The procedure is the same
for the other functions listed in (2.5), that can all be defined starting from K1. In fact,
letting
</p>
<p>K2(q, pÌ, t) = K1(q, qÌ, t) +
n
</p>
<p>&sum;
</p>
<p>i=1
pÌi qÌi , (2.8)
</p>
<p>and applying the same procedure used to determine (2.7), yields
</p>
<p>pi =
&part;K2
</p>
<p>&part;qi
, qÌi =
</p>
<p>&part;K2
</p>
<p>&part;pÌi
, HÌ = H + &part;K2
</p>
<p>&part;t
, i = 1, . . . , n. (2.9)
</p>
<p>In (2.8) the independent variables are qi , pÌi , so that the coordinates qÌi are expressed
through them. Similarly, when K3 is used one lets
</p>
<p>K3(p, qÌ, t) = K1(q, qÌ, t) &minus;
n
</p>
<p>&sum;
</p>
<p>i=1
piqi , (2.10)
</p>
<p>to find
</p>
<p>qi = &minus;
&part;K3
</p>
<p>&part;pi
, pÌi = &minus;
</p>
<p>&part;K3
</p>
<p>&part;qÌi
, HÌ = H + &part;K3
</p>
<p>&part;t
, i = 1, . . . , n. (2.11)
</p>
<p>Finally, in the case of K4 one lets
</p>
<p>K4(p, pÌ, t) = K1(q, qÌ, t) +
n
</p>
<p>&sum;
</p>
<p>i=1
pÌi qÌi &minus;
</p>
<p>n
&sum;
</p>
<p>i=1
piqi , (2.12)
</p>
<p>whence
</p>
<p>qi = &minus;
&part;K4
</p>
<p>&part;pi
, qÌi =
</p>
<p>&part;K4
</p>
<p>&part;pÌi
, HÌ = H + &part;K4
</p>
<p>&part;t
, i = 1, . . . , n. (2.13)
</p>
<p>Regardless of the choice of K , the relation between the old and new Hamiltonian
function is always of the form HÌ = H + &part;K/&part;t . As the canonical transformation is
completely determined when K is prescribed, the latter is called generating function
of the canonical transformation. Two interesting examples are those produced by
the generating functions F1 =
</p>
<p>&sum;n
i=1 qi qÌi and F2 =
</p>
<p>&sum;n
i=1 qi pÌi . Applying (2.7) to</p>
<p/>
</div>
<div class="page"><p/>
<p>2.3 An Application of the Canonical Transformation 29
</p>
<p>F1 yields qÌi = pi and pÌi = &minus;qi . As a consequence, the effect of the transforma-
tion generated by F1 is that of exchanging the roles of the generalized coordinates
and momenta. This result shows that the distinction between coordinates and mo-
menta is not fundamental, namely, these two groups of variables globally constitute
a set of 2n independent coordinates. Applying (2.9) to F2 provides the identical
transformation qÌi = qi , pÌi = pi . A generalization of this example is found using
F2 =
</p>
<p>&sum;n
i=1 zi(q, t)pÌi , where zi are arbitrary functions. The new coordinates are in
</p>
<p>this case qÌi = zi(q, t) which, as indicated at the beginning of this section, are point
transformations. This example shows that all point transformations are canonical.
</p>
<p>2.3 An Application of the Canonical Transformation
</p>
<p>The discussion of Sect. 2.2 has shown that a canonical transformation based on an
arbitrary generating function K brings a Hamiltonian function H (q, p, t) into a new
one HÌ (qÌ, pÌ, t). One may then exploit the arbitrariness of K to obtain the form of HÌ
that is most convenient for solving the problem in hand. For instance, remembering
the definition of cyclic coordinate given in Sect. 1.42, one may seek a transformation
such that the new canonical coordinates qÌi , pÌi are all cyclic. In this case, thanks to
(2.2), it is dqÌi/dt = &part;HÌ/&part;pÌi = 0, dpÌi/dt = &minus;&part;HÌ/&part;qÌi = 0, namely, each new
canonical coordinate is a constant of motion.
</p>
<p>The simplest way to obtain this result is to set the new Hamiltonian function
equal to zero. Remembering from Sect. 2.2 that in every canonical transformation
the relation between the old and new Hamiltonian function is HÌ = H + &part;K/&part;t ,
one finds in this case the relation &part;K/&part;t + H = 0. To proceed it is convenient to
choose a generating function of the K2 = K2(q, pÌ, t) type in which, as noted above,
the new momenta pÌi are constants of motion. Given that the aim is to obtain the
relation HÌ = 0, the generating function of this problem is the particular function of
the coordinates qi , pÌi , and t , that fulfills the equation &part;K2/&part;t + H = 0. In other
terms, the generating function becomes the problem&rsquo;s unknown. A comparison with
(1.51) shows that the equation to be solved is that of Hamilton&ndash;Jacobi, and that K2
coincides with Hamilton&rsquo;s principal function S.
</p>
<p>As mentioned in Sect. 1.7, (1.51) is a first-order, partial differential equation in
the unknown S and in the n+1 variables q1, . . . , qn, t . As one of the n+1 integration
constants can be set to zero, the actual number of integration constants is n. This
seems contradictory, because the Hamilton&ndash;Jacobi equation is expected to be equiv-
alent to those of Hamilton or Lagrange for the description of the system&rsquo;s motion. As
a consequence, the number of constants involved should be 2n. The contradiction is
easily removed by observing that n more constants appear in S, to be identified with
the new momenta pÌ1, . . . , pÌn: remembering the canonical transformations (2.9) to
be used in connection with the generating function of the K2 type one finds
</p>
<p>pi =
&part;S
</p>
<p>&part;qi
, qÌi =
</p>
<p>&part;S
</p>
<p>&part;pÌi
, i = 1, . . . , n . (2.14)</p>
<p/>
</div>
<div class="page"><p/>
<p>30 2 Coordinate Transformations and Invariance Properties
</p>
<p>Calculating the first of (2.14) at the initial time t = a yields a set of n algebraic equa-
tions in the n unknowns pÌ1, . . . , pÌn. In fact, at t = a the old canonical coordinates
qi ,pi are known because they are the problem&rsquo;s initial conditions. The solution of
such algebraic equations yields the first set of motion&rsquo;s constants pÌ1, . . . , pÌn. Then,
one considers the second of (2.14) at t = a, whose right hand sides, at this point
of the procedure, are known. As a consequence, the second of (2.14) yield the new
generalized coordinates qÌ1, . . . , qÌn, that are the second set of motion&rsquo;s constants.
</p>
<p>It is worth observing that the procedure depicted above provides also the time
evolution of the old canonical coordinates. In fact, after all constants have been cal-
culated, Eqs. (2.14) form 2n relations in the 2n+1 variables q1, . . . , qn,p1, . . . ,pn, t .
From them one extracts the relations q1 = q1(t), . . . ,pn = pn(t). This shows that the
Hamilton&ndash;Jacobi picture is equivalent to those based on the Hamilton or Lagrange
equations for the solution of the mechanical problem.
</p>
<p>2.4 Separation&mdash;Hamilton&rsquo;s Characteristic Function
</p>
<p>The Hamilton&ndash;Jacobi equation (1.51) can be recast in a more symmetric form by
letting qn+1 = t and incorporating &part;S/&part;t = &part;S/&part;qn+1 into the other term:
</p>
<p>C
</p>
<p>(
</p>
<p>q1, . . . , qn+1,
&part;S
</p>
<p>&part;q1
, . . . ,
</p>
<p>&part;S
</p>
<p>&part;qn+1
</p>
<p>)
</p>
<p>= 0. (2.15)
</p>
<p>Solving (2.15) becomes simpler if one of the coordinates, say qi , and the cor-
responding momentum pi = &part;S/&part;qi appear in (2.15) only through a relation
ci = ci(qi , &part;S/&part;qi) that does not contain any other coordinate, nor derivatives with
respect to them, nor time. In this case qi is called separable coordinate and the so-
lution of (2.15) can be written as S = Si +Wi , where Si depends only on qi and Wi
depends on the other coordinates and time [67, Sect. 48]. Replacing this expression
of S into (2.15) and extracting ci yields a relation of the form Ci = ci with
</p>
<p>Ci = Ci
(
</p>
<p>q1, . . . , qi&minus;1, qi+1, . . . , qn+1,
&part;Wi
</p>
<p>&part;q1
, . . . ,
</p>
<p>&part;Wi
</p>
<p>&part;qi&minus;1
,
&part;Wi
</p>
<p>&part;qi+1
, . . . ,
</p>
<p>&part;Wi
</p>
<p>&part;qn+1
</p>
<p>)
</p>
<p>,
</p>
<p>ci = ci
(
</p>
<p>qi ,
&part;Si
</p>
<p>&part;qi
</p>
<p>)
</p>
<p>. (2.16)
</p>
<p>The equality Ci = ci must hold for any value of the coordinates. As this is possible
only if the two sides are constant, Ci = ci separates and yields the pair
</p>
<p>ci
</p>
<p>(
</p>
<p>qi ,
&part;Si
</p>
<p>&part;qi
</p>
<p>)
</p>
<p>= ci0, (2.17)
</p>
<p>C
</p>
<p>(
</p>
<p>q1, . . . , qi&minus;1, qi+1, . . . , qn+1,
&part;Wi
</p>
<p>&part;q1
, . . . ,
</p>
<p>&part;Wi
</p>
<p>&part;qi&minus;1
,
&part;Wi
</p>
<p>&part;qi+1
, . . . ,
</p>
<p>&part;Wi
</p>
<p>&part;qn+1
, ci0
</p>
<p>)
</p>
<p>= 0,
</p>
<p>where C does not contain qi nor the corresponding derivative. The solution of the
first of (2.17) provides Si(qi). The latter contains two constants, namely, ci0 and the</p>
<p/>
</div>
<div class="page"><p/>
<p>2.5 Phase Velocity 31
</p>
<p>integration constant. As noted earlier, the latter can be set to zero because an additive
constant onS is irrelevant. In conclusion, ci0 is the only constant that remains after this
step. In turn, the solution of the second of (2.17), which is an n-variable differential
equation, contains n more constant, one of which is additive and can be disregarded.
It follows that the total number of integration constants in the set (2.17) is still n.
</p>
<p>If all coordinates are separable one has S = &sum;ni=1 Si(qi) and the problem is
solved by n individual integrations (an example is given in Sect. 3.10). In this case
one says that the Hamilton&ndash;Jacobi equation is completely separable. A special case
of separable coordinate is that of the cyclic coordinate. If qi is cyclic, in fact, (2.17)
reduces to &part;Si/&part;qi = ci0, whence Si = ci0qi and
</p>
<p>S = ci0qi +Wi . If the cyclic coordinate is qn+1 = t , the above becomes
</p>
<p>&part;Sn+1
&part;t
</p>
<p>= &minus;E, Sn+1 = &minus;Et , (2.18)
</p>
<p>where the symbolE is used for the constant cn+1,0. It is worth noting that the units ofE
are always those of an energy regardless of the choice of the generalized coordinates
qi . Comparing (2.18) with (1.51) yields H = E = cost, consistently with the
hypothesis that H does not depend on t . Using the symbol W instead of Wn+1
provides the pair
</p>
<p>H
</p>
<p>(
</p>
<p>q1, . . . , qn,
&part;W
</p>
<p>&part;q1
, . . . ,
</p>
<p>&part;W
</p>
<p>&part;qn
</p>
<p>)
</p>
<p>= E, S = W &minus; Et , (2.19)
</p>
<p>that holds when H is a constant of motion. The first of (2.19) is a differential equa-
tion in the generalized coordinates only, called time-independent Hamilton&ndash;Jacobi
equation. The unknown function W is called Hamilton&rsquo;s characteristic function.
</p>
<p>2.5 Phase Velocity
</p>
<p>The dynamics of a mechanical system can be obtained from Hamilton&rsquo;s principal
function S(q, pÌ, t) as shown in Sect. 2.3. After S has been determined it is possible to
build up an interesting geometrical construction, that is shown below. The indication
of the constants pÌi is omitted for the sake of conciseness.
</p>
<p>To begin, fix the time t and let S(q, t) = S0, where S0 is some constant. This
relation describes a surface belonging to the configuration space q1, . . . , qn. Now
change the time by dt : the corresponding variation in S is obtained from (1.50) and
reads dS = &sum;ni=1 pidqi &minus; Hdt = p &middot; dq &minus; Hdt . In this relation each component
pi = &part;S/&part;qi is calculated in terms of the coordinates q1, . . . , qn at the instant t ,
hence the vector p = gradqS is a function of q calculated at that instant. If q belongs
to the surface S = S0, then p is normal to the surface at q. Now let S &prime; = S+dS = S0,
where S0 is the same constant as before. The relation S &prime;(q, t) = S0 provides the new
surface into which S = S0 evolves in the interval dt . As both S = S0, S + dS = S0
hold, it must be dS = 0, namely, p &middot; dq = Hdt .</p>
<p/>
</div>
<div class="page"><p/>
<p>32 2 Coordinate Transformations and Invariance Properties
</p>
<p>WhenH has no explicit dependence on t , thanks to (2.19) the relation p&middot;dq = Hdt
becomes p&middot;dq = Edt , with p = gradqW . In this case, letting Ï be the angle between
the vectors p and dq (whose moduli are indicated with p, dq), and excluding the
points where p = 0, one obtains
</p>
<p>cosÏ
dq
</p>
<p>dt
= E
</p>
<p>p
. (2.20)
</p>
<p>The product cosÏ dq in (2.20) is the projection of dq over the direction of p, hence
it provides the variation of q in the direction normal to the surface S = S0. When
the Cartesian coordinates are used, the product cos Ï dq is a length and the left hand
side of (2.20) is a velocity, that provides the displacement of the point q during the
time interval dt and in the direction normal to the surface S = S0.
</p>
<p>As shown above, the vector p is normal to the S = S0 surface at each point
of the latter. Consider for simplicity the case of a single particle of mass m in the
conservative case, and use the Cartesian coordinates; from p = m qÌ one finds that at
each instant the surface S = S0 is normal to the particle&rsquo;s trajectory. This makes the
surface S = S0 the analogue of the constant-phase surface found in the wave theory
(e.g., Sect. 5.9). For this reason, cosÏ dq/dt is called phase velocity.
</p>
<p>Due to its definition, the phase velocity depends on the position q and is the
velocity with which each point of the S = S0 surface moves. It is worth adding that
the phase velocity does not coincide with the actual velocity of any of the system&rsquo;s
particles. To show this it suffices to consider the single particle&rsquo;s case with p = m qÌ:
from (2.20) one finds that the modulus of the phase velocity is in fact inversely
proportional to that of the particle.
</p>
<p>2.6 Invariance Properties
</p>
<p>A number of dynamical properties of the system of particles under consideration
can be inferred directly from the form of the Lagrangian or Hamiltonian function,
without the need of solving the motion&rsquo;s equations. An example is the conservation
of the momentum conjugate to a cyclic coordinate (Sect. 1.4). Other properties are
discussed below.
</p>
<p>2.6.1 Time Reversal
</p>
<p>It is found by inspection that the expression (1.22) of the system&rsquo;s kinetic energy in
Cartesian coordinates is invariant when t is replaced with&minus;t (time reversal). A rather
lengthy calculation based on the chain-differentiation rule shows that this property
still holds after a coordinate transformation.
</p>
<p>In some cases the whole Lagrangian function is invariant under time reversal.
This makes the Lagrange equations (1.28) invariant as well. Assume that (1.28) are
solved starting from a given initial condition at t = a to the final instant t = b. Then,</p>
<p/>
</div>
<div class="page"><p/>
<p>2.6 Invariance Properties 33
</p>
<p>replace t with t &prime; = &minus;t and solve the Lagrange equations again, using qi(t = b) and
&minus;qÌi(t = b) as initial conditions. Letting q &prime;i = dqi/dt &prime; = &minus;qÌi , (1.28) become
</p>
<p>d
</p>
<p>d(&minus;t &prime;)
&part;L
</p>
<p>&part;(&minus; q &prime;i)
= d
</p>
<p>dt &prime;
&part;L
</p>
<p>&part;q &prime;i
= &part;L
</p>
<p>&part;qi
, i = 1, . . . , n (2.21)
</p>
<p>where, due to the hypothesis of invariance, the Lagrangian function is the same as
that used to describe the motion from t = a to t = b. It follows that the trajectories of
the second motion are equal to those of the first one. Moreover, the initial velocities
of the second motion, calculated at t &prime; = &minus;b, are opposite to those of the first motion
at the same point. Due to the arbitrariness of b, at each point of a trajectory the
velocity described by the time t &prime; is opposite to that described by t . A motion having
this property is called reversible.
</p>
<p>Taking the examples of Sect. 1.3 and remembering the form (1.12, 1.18) of the
corresponding Lagrangian functions one finds that, in the first example, the motion is
reversible if the potential energyV is invariant under time reversal, namely, V (&minus;t) =
V (t), while in the second example the motion is reversible if Ï(&minus;t) = Ï(t) and
A(&minus;t) = &minus;A(t).
</p>
<p>2.6.2 Translation of Time
</p>
<p>Consider the case where the Hamiltonian function is invariant with respect to trans-
lations of the origin of time. The invariance holds also for an infinitesimal translation
dt , hence it is dH/dt = 0. In other terms H is a constant of motion. When this
happens, as illustrated in Sect. 1.4, the Lagrangian and Hamiltonian functions have
no explicit dependence on time, and vice versa.
</p>
<p>2.6.3 Translation of the Coordinates
</p>
<p>Another interesting case occurs when the Lagrangian function is invariant with re-
spect to translations of the coordinates&rsquo; origin. By way of example consider an
N -particle system with no constraints, whence n = 3N , and use the Cartesian co-
ordinates xjs . Here the first index is associated with the particles and the second
one with the axes. Then, choose an infinitesimal translation dh1 in the direction of
the first axis and, similarly, infinitesimal translations dh2 and dh3 in the other two
directions. Thus, each coordinate xj1, j = 1, . . . ,N within the Lagrangian function
is replaced by xj1 + dh1, and so on. The translational invariance then yields
</p>
<p>dL = dh1
N
&sum;
</p>
<p>j=1
</p>
<p>&part;L
</p>
<p>&part;xj1
+ dh2
</p>
<p>N
&sum;
</p>
<p>j=1
</p>
<p>&part;L
</p>
<p>&part;xj2
+ dh3
</p>
<p>N
&sum;
</p>
<p>j=1
</p>
<p>&part;L
</p>
<p>&part;xj3
= 0 . (2.22)
</p>
<p>Each sum in (2.22) vanishes independently of the others due to the arbitrariness of
the translations. Taking the sum multiplying dh1 and using (1.28) yields</p>
<p/>
</div>
<div class="page"><p/>
<p>34 2 Coordinate Transformations and Invariance Properties
</p>
<p>N
&sum;
</p>
<p>j=1
</p>
<p>&part;L
</p>
<p>&part;xj1
=
</p>
<p>N
&sum;
</p>
<p>j=1
</p>
<p>d
</p>
<p>dt
</p>
<p>&part;L
</p>
<p>&part;xÌj1
= d
</p>
<p>dt
</p>
<p>N
&sum;
</p>
<p>j=1
pj1 =
</p>
<p>dP1
dt
</p>
<p>= 0, (2.23)
</p>
<p>where P1 =
&sum;N
</p>
<p>j=1 pj1 is the first component of the total momentum
</p>
<p>P =
N
&sum;
</p>
<p>j=1
pj (2.24)
</p>
<p>of the system of particles. The other two components are treated in the same manner.
In conclusion, if the Lagrangian function is invariant with respect to translations
of the coordinates&rsquo; origin, then the total momentum of the system is a constant of
motion.
</p>
<p>The above reasoning applies independently to each axis. As a consequence, if
the Lagrangian function is such that the sum
</p>
<p>&sum;N
j=1 &part;L/&part;xj1 vanishes, while the
</p>
<p>analogous sums associated with the other two axes do not vanish, then P1 is a
constant of motion, while P2, P3 are not.
</p>
<p>An important example of a Langrangian function, that is invariant with respect to
translations of the coordinates&rsquo; origin, is found when the force Fi acting on the ith
particle derives from a potential energy V that depends only on the relative distances
rjk = |rj &minus; rk| among the particles, k ï¿½= j . An example is given in Sect. 3.7.
</p>
<p>2.6.4 Rotation of the Coordinates
</p>
<p>Consider the case where the Lagrangian function is invariant with respect to rotations
of the coordinates around an axis that crosses the origin. Like in Sect. 2.6.3 a system
ofN particles with no constraints is assumed, and the Cartesian coordinates are used.
Let Ï be the plane that contains the origin and is normal to the rotation axis. It is
convenient to use on Ï a polar reference (Sect. B.2) in which the rotation is defined
over Ï by the angle Ï. In turn, let Ïj be the angle between the rotation axis and the
position vector rj = (xj1, xj2, xj3) of the j th particle. The meaning of the angles
is the same as in Fig. B.1, where the axes x, y define plane Ï; then, Ïj and rj are
represented by Ï and r of the figure, respectively. If an infinitesimal rotation dÏ
is considered, the position vector rj undergoes a variation drj parallel to Ï and of
magnitude |drj | = rj sin Ïj dÏ. To specify the direction of drj one takes the unit
vector a of the rotation axis and associates to the rotation the vector a dÏ such that
</p>
<p>drj = a dÏ &and; rj . (2.25)
</p>
<p>The corresponding variations drÌj of the velocities are found by differentiating (2.25)
with respect to time. The variation of the Lagrangian function is
</p>
<p>dL =
N
&sum;
</p>
<p>j=1
</p>
<p>3
&sum;
</p>
<p>s=1
</p>
<p>(
&part;L
</p>
<p>&part;xjs
dxjs +
</p>
<p>&part;L
</p>
<p>&part;xÌjs
dxÌjs
</p>
<p>)
</p>
<p>, (2.26)</p>
<p/>
</div>
<div class="page"><p/>
<p>2.7 Maupertuis Principle 35
</p>
<p>where the variations of the components are found from (2.25) and read dxjs =
dÏ
</p>
<p>(
</p>
<p>a &and; rj
)
</p>
<p>s
, dxÌjs = dÏ
</p>
<p>(
</p>
<p>a &and; rÌj
)
</p>
<p>s
. Replacing the latter in (2.26) and using (1.28)
</p>
<p>yields
</p>
<p>dL = dÏ
N
&sum;
</p>
<p>j=1
</p>
<p>(
</p>
<p>a &and; rj &middot; pÌj + a &and; rÌj &middot; pj
)
</p>
<p>. (2.27)
</p>
<p>Due to the rotational invariance, (2.27) vanishes for any dÏ. Letting the sum to vanish
after exchanging the scalar and vector products, and remembering that a is constant,
one finds
</p>
<p>a &middot;
N
&sum;
</p>
<p>j=1
</p>
<p>(
</p>
<p>rj &and; pÌj + rÌj &and; pj
)
</p>
<p>= a &middot; d
dt
</p>
<p>N
&sum;
</p>
<p>j=1
rj &and; pj = a &middot;
</p>
<p>dM
</p>
<p>dt
= d
</p>
<p>dt
(M &middot; a) = 0,
</p>
<p>(2.28)
</p>
<p>where
</p>
<p>M =
N
&sum;
</p>
<p>j=1
rj &and; pj (2.29)
</p>
<p>is the total angular momentum of the system of particles. In conclusion, if the
Lagrangian function is invariant with respect to rotations of the coordinates around
an axis that crosses the origin, then the projection of the system&rsquo;s total angular
momentum M over the rotation axis is a constant of motion.
</p>
<p>2.7 Maupertuis Principle
</p>
<p>Besides the Hamilton principle described in Sect. 1.3.4, other variational principles
exist. Among them is the Maupertuis, or least action, principle, that applies to a
particle subjected to conservative forces. Let V = V (x1, x2, x3) be the potential
energy and E = const the total energy, and let A and B indicate the two points of the
(x1, x2, x3) space that limit the trajectory of the particle. The Maupertuis principle
states that the natural trajectory between A and B is the one that minimizes the
functional
</p>
<p>G =
&int;
</p>
<p>AB
</p>
<p>&radic;
E &minus; V ds, ds2 = dx21 + dx22 + dx23 , (2.30)
</p>
<p>where the integral is carried out along the trajectory. The form of (2.30) explains the
term &ldquo;least action&rdquo;: in fact, the relation p2/(2m) = m u2/2 = E &minus; V shows that the
integrand
</p>
<p>&radic;
E &minus; V is proportional to the particle&rsquo;s momentum p; as a multiplicative
</p>
<p>constant is irrelevant for calculating the extremum functions, the minimization of G
is equivalent to that of the action
</p>
<p>&int;
</p>
<p>AB
p ds.</p>
<p/>
</div>
<div class="page"><p/>
<p>36 2 Coordinate Transformations and Invariance Properties
</p>
<p>To calculate the extremum functions of (2.30) it is convenient to parametrize the
coordinates in the form xi = xi(Î¾ ), where the parameter Î¾ takes the same limiting
values, say, Î¾ = a at A and Î¾ = b at B, for the natural and all the virtual trajectories.
Letting xÌi = dxi/dÎ¾ one finds (ds/dÎ¾ )2 = xÌ21 + xÌ22 + xÌ23 which, remembering (1.7),
yields the extremum condition for (2.30):
</p>
<p>Î´
</p>
<p>&int; b
</p>
<p>a
</p>
<p>Î¸ dÎ¾ = 0, Î¸ =
&radic;
E &minus; V
</p>
<p>&radic;
</p>
<p>xÌ21 + xÌ22 + xÌ23 ,
d
</p>
<p>dÎ¾
</p>
<p>&part;Î¸
</p>
<p>&part;xÌi
= &part;Î¸
</p>
<p>&part;xi
. (2.31)
</p>
<p>The following relations are useful to work out the last of (2.31): ds/dt = u =&radic;
(2/m)(E &minus; V ), dxi = xÌi dÎ¾ , dxi/dt = ui . One finds
</p>
<p>&part;Î¸
</p>
<p>&part;xÌi
=
</p>
<p>&radic;
E &minus; V xÌi
</p>
<p>ds/dÎ¾
=
</p>
<p>&radic;
</p>
<p>m
</p>
<p>2
u
xÌi dÎ¾
</p>
<p>ds
=
</p>
<p>&radic;
</p>
<p>m
</p>
<p>2
</p>
<p>dxi
dt
</p>
<p>=
&radic;
</p>
<p>m
</p>
<p>2
ui , (2.32)
</p>
<p>&part;Î¸
</p>
<p>&part;xi
= ds
</p>
<p>dÎ¾
</p>
<p>&minus;&part;V/&part;xi
2
&radic;
E &minus; V
</p>
<p>= ds
dÎ¾
</p>
<p>Fi
</p>
<p>2
&radic;
m/2u
</p>
<p>= dt
dÎ¾
</p>
<p>Fi&radic;
2m
</p>
<p>, (2.33)
</p>
<p>with Fi the ith component of the force. The last of (2.31) then yields
</p>
<p>d
</p>
<p>dÎ¾
</p>
<p>(&radic;
</p>
<p>m
</p>
<p>2
ui
</p>
<p>)
</p>
<p>= dt
dÎ¾
</p>
<p>Fi&radic;
2m
</p>
<p>, Fi = m
dui
dÎ¾
</p>
<p>dÎ¾
</p>
<p>dt
= m dui
</p>
<p>dt
. (2.34)
</p>
<p>In conclusion, the equation that provides the extremum condition for functional G
is equivalent to Newton&rsquo;s second law F = ma.
</p>
<p>2.8 Spherical Coordinates&mdash;Angular Momentum
</p>
<p>Consider a single particle of mass m and use the transformation from the Cartesian
(x, y, z) to the spherical (r ,Ï ,Ï) coordinates shown in Sect. B.1. The kinetic energy
is given by (B.7), namely,
</p>
<p>T = m
2
</p>
<p>(rÌ2 + r2ÏÌ2 + r2ÏÌ2 sin2 Ï). (2.35)
</p>
<p>If the force acting onto the particle is derivable from a potential energy V =
V (x, y, z, t), the Lagrangian function in the spherical reference is L = T &minus;
V (r ,Ï ,Ï, t), where T is given by (2.35). The momenta conjugate to the spherical
coordinates are
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>pr = &part;L/&part;rÌ = mrÌ
pÏ = &part;L/&part;ÏÌ = mr2 ÏÌ
pÏ = &part;L/&part;ÏÌ = mr2 ÏÌ sin2 Ï
</p>
<p>(2.36)
</p>
<p>Using (2.36), the kinetic energy is recast as</p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Spherical Coordinates&mdash;Angular Momentum 37
</p>
<p>T = 1
2m
</p>
<p>(
</p>
<p>p2r +
p2Ï
</p>
<p>r2
+
</p>
<p>p2Ï
</p>
<p>r2 sin2 Ï
</p>
<p>)
</p>
<p>. (2.37)
</p>
<p>The components of the momentum p derived from the Lagrangian function written
in the Cartesian coordinates are mxÌ, myÌ, mzÌ. It follows that the components of the
angular momentum M = r &and; p written in the Cartesian and spherical references are
â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>Mx = m (y zÌ &minus; z yÌ) = &minus;mr2 (ÏÌ sin Ï + ÏÌ sin Ï cosÏ cosÏ)
My = m (z xÌ &minus; x zÌ) = mr2 (ÏÌ cosÏ &minus; ÏÌ sin Ï cosÏ sin Ï)
Mz = m (x yÌ &minus; y xÌ) = mr2 ÏÌ sin2 Ï
</p>
<p>(2.38)
</p>
<p>The square modulus of the angular momentum in spherical coordinates reads
</p>
<p>M2 = m2r4
(
</p>
<p>ÏÌ2 + ÏÌ2 sin2 Ï
)
</p>
<p>= p2Ï +
p2Ï
</p>
<p>sin2 Ï
, (2.39)
</p>
<p>where the last equality is due to (2.36). From (2.37, 2.39) one finds
</p>
<p>T = 1
2m
</p>
<p>(
</p>
<p>p2r +
M2
</p>
<p>r2
</p>
<p>)
</p>
<p>. (2.40)
</p>
<p>If M is a constant of motion, (2.40) shows that the kinetic energy depends on r and
rÌ only. Comparing (2.36) with (2.38) one also notices that
</p>
<p>pÏ = Mz, (2.41)
namely, the component along the z axis of the angular momentum turns out to be the
momentum conjugate to the Ï coordinate. The latter describes the rotations along the
same axis. In contrast, the other two components of M are not conjugate momenta.
This result is due to the asymmetry of the relations (B.1) that connect the Cartesian
to the spherical coordinates, and does not ascribe any privileged role to the z axis. In
fact, by exchanging the Cartesian axes one makes pÏ to coincide with Mx or My .
</p>
<p>Another example refers to a particle of mass m and charge e subjected to an
electromagnetic field. Remembering (1.33) one has L = (1/2)mu2 &minus; eU + eu &middot;
A, where the scalar potential is indicated with U to avoid confusion with the Ï
coordinate. It follows
</p>
<p>L = 1
2
m
</p>
<p>(
</p>
<p>rÌ2 + r2 ÏÌ2 + r2 ÏÌ2 sin2 Ï
)
</p>
<p>&minus; e U + eu &middot; A, (2.42)
</p>
<p>where the components of u = rÌ are given by (B.6), and U , A depend on the co-
ordinates and time. Indicating the components of A with Ax , Ay , Az, the momenta
read
â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>pr = &part;L/&part;rÌ = m rÌ + e Ax sin Ï cosÏ + e Ay sin Ï sin Ï + e Az cosÏ cosÏ
pÏ = &part;L/&part;ÏÌ = mr2 ÏÌ + e Ax r cosÏ cosÏ + e Ay r cosÏ sin Ï &minus; e Az r sin Ï
pÏ = &part;L/&part;ÏÌ = mr2 ÏÌ sin2 Ï &minus; e Ax r sin Ï sin Ï + e Ay r sin Ï cosÏ
</p>
<p>(2.43)</p>
<p/>
</div>
<div class="page"><p/>
<p>38 2 Coordinate Transformations and Invariance Properties
</p>
<p>Thanks to (B.1, B.6), the third of (2.43) can be written as
</p>
<p>pÏ = m (x yÌ &minus; y xÌ) + e (x Ay &minus; y Ax) = x (m yÌ + e Ay) &minus; y (m xÌ + e Ax),
(2.44)
</p>
<p>that coincides with the component of the angular momentum M = r &and; p = r &and;
(m u + eA) along the z axis. This result shows that (2.41) holds also when the force
acting onto the particle derives from an electromagnetic field.
</p>
<p>2.9 Linear Motion
</p>
<p>The linear motion is the motion of a system having only one degree of freedom. Using
the Cartesian coordinate x, and assuming the case where the force acting onto the
particle derives from a potential energy V (x), gives the Hamiltonian function (1.32)
the form H = p2/(2m) + V (x). As shown in Sect. 1.4, a Hamiltonian function of
this type is a constant of motion whence, remembering that here it is p = m xÌ,
</p>
<p>1
</p>
<p>2
m xÌ2 + V (x) = E = const. (2.45)
</p>
<p>The constant E is called total energy. Its value is given by the initial conditions
x0 = x(t = a), xÌ0 = xÌ(t = a). As the kinetic energy m xÌ2/2 can not be negative,
the motion is possible only in the intervals of the x axis such that V (x) &le; E. In
particular, the velocity xÌ vanishes at the points where V = E. Instead, the intervals
where V &gt; E can not be reached by the particle. Equation (2.45) is separable and
provides a relation of the form t = t(x),
</p>
<p>t = a &plusmn;
&radic;
</p>
<p>m
</p>
<p>2
</p>
<p>&int; x
</p>
<p>x0
</p>
<p>dÎ¾&radic;
E &minus; V (Î¾ ) . (2.46)
</p>
<p>By way of example consider a situation like that shown in Fig. 2.1, where it is assumed
that to the right of xC the potential energy V keeps decreasing as x &rarr; &infin;. If the
initial position of the particle is x0 = xC , there the velocity vanishes and the particle
is subjected to a positive force F = &minus;dV/dx &gt; 0. As a consequence, the particle&rsquo;s
motion will always be oriented to the right starting from xC . Such a motion is called
unlimited. If the initial position is x0 &gt; xC and the initial velocity is negative, the
particle moves to the left until it reaches the position xC , where it bounces back. The
subsequent motion is the same as described above.
</p>
<p>A different situation arises when the initial position of the particle belongs to
an interval limited by two zeros of the function E &minus; V (x) like, e.g., xA and xB in
Fig. 2.1. The motion is confined between xA and xB and, for this reason, is called
limited. The particle bounces back and forth endlessly under the effect of a force that
does not depend on time. As a consequence, the time necessary to complete a cycle
xA &rarr; xB &rarr; xA is the same for each cycle. In other terms, the motion is periodic in
time. Also, from (2.46) it is found by inspection that the time spent by the particle</p>
<p/>
</div>
<div class="page"><p/>
<p>2.10 Action-Angle Variables 39
</p>
<p>Fig. 2.1 Example of potential
energy discussed in Sect. 2.9
</p>
<p>V
</p>
<p>x x x x
C BA
</p>
<p>E
</p>
<p>in the xA &rarr; xB part of the cycle is the same as that spent in the xB &rarr; xA part. The
period of the oscillation is then found to be
</p>
<p>T = 2
&radic;
</p>
<p>m
</p>
<p>2
</p>
<p>&int; xB
</p>
<p>xA
</p>
<p>dx&radic;
E &minus; V (x) . (2.47)
</p>
<p>Note that the period depends on the total energy E. However there are exceptions,
as the example of Sect. 3.3 shows.
</p>
<p>2.10 Action-Angle Variables
</p>
<p>Consider a linear, conservative motion of constant energy E (Sect. 2.9) and let q, p
be two canonical coordinates describing it. The following hold
</p>
<p>H (q,p) = E, p = p(q,E). (2.48)
</p>
<p>The second of (2.48) is derived from the first one by solving for the momentum, and
provides the phase trajectory (Sect. 1.9) starting from the initial conditions q0, p0
of the motion. As shown below, in several mechanical systems of interest the phase
trajectory has some special characteristic that is worth examining.
</p>
<p>Consider, first, the situation where the phase trajectory is closed: in this case, after
a time T has elapsed from t = 0, the canonical coordinates take again the values q0,
p0. As a consequence, for t &gt; T the motion repeats itself, and so on. It follows that
both q and p are periodic functions of time with the same period T . As discussed
in Sect. 2.9, this type of periodic motion, in which both q and p are bounded, is
typically found when the initial position q0 lies between two zeros of E &minus; V , and is
of the oscillatory type. It is also indicated with the astronomical term libration.
</p>
<p>A second important situation occurs whenp is a periodic function of q. In this type
of motion q is unbounded. However, when q increases by a period the configuration</p>
<p/>
</div>
<div class="page"><p/>
<p>40 2 Coordinate Transformations and Invariance Properties
</p>
<p>of the mechanical system remains practically unchanged. In fact, in this type of
motion the canonical coordinate q is always an angle of rotation: the motion is still
periodic and is referred to as rotation. Note that the same mechanical system may
give rise to a libration or a rotation, depending on the motion&rsquo;s initial conditions: a
typical example is that of the simple pendulum where q is identified with the angle
of deflection [42, Chap. 10.6]. The action variable is defined as
</p>
<p>J (E) =
â®
</p>
<p>p(q,E) dq, (2.49)
</p>
<p>where the integral is carried out over a complete period of libration or rotation, de-
pending on the case under investigation. The name given to J stems from the fact
that, as mentioned in Sect. 1.5, the product q p has the units of an action in all
coordinate sets. The action variable is a constant of motion because it depends on
E only. Inverting J (E) yields H = H (J ). Now one applies a canonical transfor-
mation generated by a Hamilton characteristic function of the form W = W (q, J ).
Remembering the procedure depicted in Sect. 2.4, W is the solution of
</p>
<p>H
</p>
<p>(
</p>
<p>q,
&part;W
</p>
<p>&part;q
</p>
<p>)
</p>
<p>= E. (2.50)
</p>
<p>Applying (2.14) one finds the generalized coordinate w = &part;W/&part;J , called angle
variable, conjugate to J . The pair J , w constitutes the set of canonical coordinates
called action-angle variables. Finally, the Hamilton equations in the new coordinates
read
</p>
<p>wÌ = &part;H
&part;J
</p>
<p>= const, JÌ = &minus;&part;H
&part;w
</p>
<p>= 0. (2.51)
</p>
<p>The time evolution of the action-angle variables is then w = wÌ t + w0, J = const.
From the first of (2.51) it also follows that the units of wÌ are those of a frequency.
The usefulness of the action-angle variables becomes apparent when one calculates
the change Îw over a complete libration or rotation cycle of q:
</p>
<p>Îw =
â®
</p>
<p>dw =
â®
</p>
<p>&part;w
</p>
<p>&part;q
dq =
</p>
<p>â®
&part;2W
</p>
<p>&part;q&part;J
dq = d
</p>
<p>dJ
</p>
<p>â®
&part;W
</p>
<p>&part;q
dq = 1, (2.52)
</p>
<p>where the last equality derives from combining p = &part;W/&part;q with (2.49). On the
other hand, if T is the time necessary for completing a cycle of q, then it is Îw =
w(T )&minus;w(0) = wÌ T , whence wÌ = 1/T . Thus, the frequency Î½ = wÌ is that associated
with the periodic motion of q. In conclusion, the action-angle variables provide a
straightforward method to determine the frequency of a periodic motion without the
need of solving the motion equation. The method is applicable also to conservative
systems having more than one degree of freedom, provided there exists at least one
set of coordinates in which the Hamilton&ndash;Jacobi equation is completely separable
[42, Chap. 10.7].</p>
<p/>
</div>
<div class="page"><p/>
<p>2.11 Complements 41
</p>
<p>2.11 Complements
</p>
<p>2.11.1 Infinitesimal Canonical Transformations
</p>
<p>Consider a system with n degrees of freedom whose Hamiltonian function is
H (q1, . . . , qn,p1, . . . ,pn, t). Remembering (1.42) one finds that the canonical co-
ordinates at t + dt are expressed, in terms of the same coordinates at t , by the
relations
</p>
<p>qi + dqi = qi +
&part;H
</p>
<p>&part;pi
dt , pi + dpi = pi &minus;
</p>
<p>&part;H
</p>
<p>&part;qi
dt. (2.53)
</p>
<p>Letting qÌi = qi + dqi , pÌi = pi + dpi gives (2.53) the same form as (2.1), namely,
that of a coordinate transformation. It is interesting to check whether such a trans-
formation is canonical. For this, one notes that the transformation (2.53) differs by
infinitesimal quantities from the identical transformation qÌi = qi , pÌi = pi ; as a
consequence one expects the generating function of (2.53), if it exists, to differ by an
infinitesimal function from F2 =
</p>
<p>&sum;n
i=1 qi pÌi which, as shown in Sect. 2.2, generates
</p>
<p>the identical transformation. One then lets
</p>
<p>K2 =
n
</p>
<p>&sum;
</p>
<p>i=1
qi pÌi + Ç« G(q, pÌ, t), (2.54)
</p>
<p>where Ç« is an infinitesimal quantity. From the first two equations in (2.9) it follows
</p>
<p>pi =
&part;K2
</p>
<p>&part;qi
= pÌi + Ç«
</p>
<p>&part;G
</p>
<p>&part;qi
, qÌi =
</p>
<p>&part;K2
</p>
<p>&part;pÌi
= qi + Ç«
</p>
<p>&part;G
</p>
<p>&part;pÌi
. (2.55)
</p>
<p>In the last term of (2.55) one may replace pÌi with pi on account of the fact that the
difference between Ç« &part;G/&part;pÌi and Ç« &part;G/&part;pi is infinitesimal of a higher order. Then,
letting Ç« = dt , G(q, p, t) = H (q, p, t), and K2 =
</p>
<p>&sum;n
i=1 qi pÌi +H (q, p, t) dt , makes
</p>
<p>(2.55) identical to (2.53). Note that this replacement transforms the third of (2.9) into
HÌ = H + (&part;H/&part;t) dt , as should be (compare with (1.44)).
</p>
<p>The above reasoning shows that the H dt term in (2.54) generates a canonical
transformation that produces the variations of the canonical coordinates in the time
interval dt . Such a transformation is called infinitesimal canonical transformation.
On the other hand, as the application of more than one canonical transformation is still
canonical, the evolution of the coordinates qi ,pi during a finite interval of time can
be thought of as produced by a succession of infinitesimal canonical transformations
generated by the Hamiltonian function. In other terms, the Hamiltonian function
generates the motion of the system.
</p>
<p>2.11.2 Constants of Motion
</p>
<p>It has been shown in Sect. 2.11.1 that a succession of infinitesimal canonical trans-
formation generated by the Hamiltonian function determines the time evolution of</p>
<p/>
</div>
<div class="page"><p/>
<p>42 2 Coordinate Transformations and Invariance Properties
</p>
<p>the canonical coordinates qi ,pi . If such a succession starts with the initial conditions
qi0,pi0, at some later time t the transformations Eqs. (2.53) take the form
</p>
<p>qi = qi(q0, p0, t), pi = pi(q0, p0, t). (2.56)
</p>
<p>The relations (2.56) are nothing else than the solution of the mechanical problem;
in fact, they express the canonical coordinates at time t , given the initial conditions.
From another viewpoint, they show that the solution of the problem contains 2 n
constants. They are not necessarily constants of motion, in fact, their values at t &gt; 0
are in general different from those at t = 0. If the system has extra properties
(like, e.g., the invariance properties discussed in Sect. 2.6), it also has one or more
constants of motion. The latter keep the value that they possessed at t = 0, so they
are expressible as combinations of the canonical coordinates at t = 0; by way of
example, the total energy E of a single particle subjected to a conservative force
reads E = (p201 + p202 + p203)/(2m) + V (x10, x20, x30).
</p>
<p>For a system having n degrees of freedom the total number of independent
combinations of the initial conditions can not exceed the number of the initial con-
ditions themselves. As a consequence, for such a system the maximum number of
independent constants of motion is 2n.
</p>
<p>Problems
</p>
<p>2.1 Given the Hamiltonian function H = p2/(2m) + (c/2) x2, m, c &gt; 0 (that
describes the linear harmonic oscillator, Sect. 3.3), find the oscillation frequency
Î½ using the action-angle variables.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 3
</p>
<p>Applications of the Concepts of Analytical
Mechanics
</p>
<p>3.1 Introduction
</p>
<p>This chapter provides a number of important examples of application of the principles
of Analytical Mechanics. The examples are chosen with reference to the applications
to Quantum Mechanics shown in later chapters. The first sections treat the problems
of the square well, linear harmonic oscillator, and central motion. The subsequent
sections deal with the two-particle interaction: first, the description of the collision
is given, along with the calculation of the energy exchange involved in it, with
no reference to the form of the potential energy; this is followed by the treatment
of the collision when the potential energy is of the repulsive-Coulomb type. The
chapter continues with the treatment of a system of strongly-bound particles: the
diagonalization of its Hamiltonian function shows that the motion of the particles is
a superposition of harmonic oscillations. Finally, the motion of a particle subjected to
a periodic potential energy is analyzed, including the case where a weak perturbation
is superimposed to the periodic part. A number of complements are also given,
that include the treatment of the collision with a potential energy of the attractive-
Coulomb type, and that of the collision of two relativistic particles.
</p>
<p>3.2 Particle in a Square Well
</p>
<p>As a first example of linear motion consider the case of a potential energy V of the
form shown in Fig. 3.1. Such a potential energy is called square well and is to be
understood as the limiting case of a potential-energy well whose sides have a finite,
though very large, slope. It follows that the force F = &minus;dV/dx is everywhere equal
to zero with the exception of the two points &minus;xM and +xM , where it tends to +&infin;
and&minus;&infin;, respectively. From the discussion of Sect. 2.9 it follows that the caseE &lt; 0
</p>
<p>&copy; Springer Science+Business Media New York 2015 43
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_3</p>
<p/>
</div>
<div class="page"><p/>
<p>44 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>Fig. 3.1 The example of the
square well analyzed in
Sect. 3.2. Only the case
0 &le; E &le; V0 is shown
</p>
<p>&minus;x
M
</p>
<p>+x
M
</p>
<p>V
0
</p>
<p>x
</p>
<p>E
</p>
<p>V
</p>
<p>is forbidden. The motion of the particle is finite for 0 &le; E &le; V0, while it is infinite
for E &gt; V0.
</p>
<p>Considering the 0 &le; E &le; V0 case first, the motion is confined within the well
and the velocity of the particle is constant in the interval &minus;xM &lt; x &lt; +xM , where
the Hamiltonian function yields m xÌ2/2 = E. If the particle&rsquo;s motion is oriented to
the right, the velocity is xÌ = &radic;2E/m. When the particle reaches the position xM
its velocity reverses instantly to become xÌ = &minus;&radic;2E/m. The motion continues at a
constant velocity until the particle reaches the position &minus;xM where is reverses again,
and so on. As the spatial interval corresponding to a full cycle is 4 xM , the oscillation
period is T = &radic;8m/E xM .
</p>
<p>To treat theE &gt; V0 case assume that the particle is initially at a position x &lt; &minus;xM
with a motion oriented to the right. The Hamiltonian function outside the well yields
m xÌ2/2 + V0 = E. The constant velocity is xÌ =
</p>
<p>&radic;
2 (E &minus; V0)/m until the particle
</p>
<p>reaches the position &minus;xM . There the velocity increases abruptly to xÌ =
&radic;
</p>
<p>2E/m and
keeps this value until the particle reaches the other edge of the well, +xM . There,
the velocity decreases abruptly back to the initial value xÌ = &radic;2 (E &minus; V0)/m, and
the particle continues its motion at a constant velocity in the positive direction.
</p>
<p>3.3 Linear Harmonic Oscillator
</p>
<p>An important example of linear motion is found when the force derives from a
potential energy of the form V = c x2/2, with c &gt; 0. The force acting on the
particle turns out to be F = &minus;dV/dx = &minus;c x, namely, it is linear with respect to x,
vanishes at x = 0, and has a modulus that increases as the particle departs from the
origin. Also, due to the positiveness of c, the force is always directed towards the
origin. A force of this type is also called linear elastic force, and c is called elastic
constant (Fig. 3.2).
</p>
<p>From the discussion of Sect. 2.9 it follows that the case E &lt; 0 is forbidden. The
motion of the particle is always finite because for any E &ge; 0 it is confined between
the two zeros xM = &plusmn;
</p>
<p>&radic;
2E/c of the equation V = E. The Hamiltonian function
</p>
<p>reads</p>
<p/>
</div>
<div class="page"><p/>
<p>3.4 Central Motion 45
</p>
<p>Fig. 3.2 The example of the
linear harmonic oscillator
analyzed in Sect. 3.3
</p>
<p>+x
M
</p>
<p>&minus;x
M
</p>
<p>2c x  / 2
</p>
<p>x
</p>
<p>V
</p>
<p>E
</p>
<p>H = 1
2m
</p>
<p>p2 + 1
2
cx2 = E = const, (3.1)
</p>
<p>yielding the motion&rsquo;s equation pÌ = mxÌ = &minus;&part;H/&part;x = &minus;c x whose solution is
x(t) = xM cos (Ï t + Î±0), xÌ(t) = &minus;Ï xM sin (Ï t + Î±0), Ï =
</p>
<p>&radic;
</p>
<p>c/m. (3.2)
</p>
<p>Due to the form of (3.2), a particle whose motion is derived from the Hamiltonian
function (3.1) is called linear harmonic oscillator. The maximum elongation xM &gt;
0 and the initial phase Î±0 are readily expressed in terms of the initial conditions
x0 = x(t = 0), xÌ0 = xÌ(t = 0). In fact, letting t = 0 in (3.2) yields x2M = x20 + xÌ20/Ï2
and tan Î±0 = &minus;xÌ0/(Ï x0). The total energy in terms of the initial conditions reads
E = m xÌ20/2+c x20/2 and, finally, the oscillation&rsquo;s period is T = 2Ï/Ï. Note that T
depends on the two parameters m, c appearing in the Hamiltonian function, but not
on the total energy (in other terms, for a given pair m, c the oscillation period does
not depend on the initial conditions). As mentioned in Sect. 2.9, this is an exceptional
case.
</p>
<p>3.4 Central Motion
</p>
<p>Consider the case of a particle of mass m acted upon by a force that derives from a
potential energy of the form V = V (r), where r =
</p>
<p>&radic;
</p>
<p>x2 + y2 + z2 is the modulus
of the position vector r of the particle. The force
</p>
<p>F = &minus;gradV = &minus;dV
dr
</p>
<p>r
</p>
<p>r
, (3.3)
</p>
<p>depends on r only and is oriented along r. For this reason it is called central force. In
turn, the point whence the force originates (in this case, the origin of the reference)
is called center of force. The corresponding Lagrangian function
</p>
<p>L = 1
2
mrÌ2 &minus; V (r), p = mrÌ, rÌ = |rÌ| (3.4)</p>
<p/>
</div>
<div class="page"><p/>
<p>46 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>turns out to be invariant under any rotation (Sect. 2.6.4). Remembering (2.28, 2.29),
this type of invariance means that the projection of the angular momentum M onto
any direction is conserved. It follows that, for a particle acted upon by a central force,
the vector M itself is conserved. On the other hand it is M = r&and;mrÌ, so the constant
angular momentum is fixed by the initial conditions of the motion.
</p>
<p>As M is normal to the plane defined by r and rÌ, the trajectory of the particle lies
always on such a plane. It is then useful to select the Cartesian reference by aligning,
e.g., the z axis with M. In this way, the trajectory belongs to the x, y plane and
two coordinates eventually suffice to describe the motion. Turning to the spherical
coordinates (B.1) and using (2.40) yields the Hamiltonian function
</p>
<p>H = 1
2m
</p>
<p>(
</p>
<p>p2r +
M2
</p>
<p>r2
</p>
<p>)
</p>
<p>+ V (r) = p
2
r
</p>
<p>2m
+ Ve(r), Ve = V +
</p>
<p>M2
</p>
<p>2mr2
, (3.5)
</p>
<p>with M2 = p2Ï + p2Ï/ sin2 Ï , M = const, and pr = mrÌ , pÏ = mr2ÏÌ , pÏ = Mz =
mr2ÏÌ sin Ï . However, the z axis has been aligned with M, which is equivalent to
letting Ï = Ï/2. It turns out Mz = M , and pr = mrÌ , pÏ = 0, pÏ = M = mr2ÏÌ, so
that
</p>
<p>H = 1
2m
</p>
<p>(
</p>
<p>p2r +
p2Ï
</p>
<p>r2
</p>
<p>)
</p>
<p>+ V (r) = p
2
r
</p>
<p>2m
+ Ve(r), Ve = V +
</p>
<p>p2Ï
</p>
<p>2mr2
. (3.6)
</p>
<p>As the total energy is conserved it is H = E, where E is known from the initial
conditions. The intervals of r where the motion can actually occur are those in which
E &ge; Ve. Letting r0 = r(t = 0), the time evolution of the radial part is found from
p2r = m2(dr/dt)2 = 2m (E &minus; Ve), namely
</p>
<p>t(r) = &plusmn;
&radic;
</p>
<p>m
</p>
<p>2
</p>
<p>&int; r
</p>
<p>r0
</p>
<p>dÎ¾&radic;
E &minus; Ve(Î¾ )
</p>
<p>. (3.7)
</p>
<p>From pÏ = mr2ÏÌ = const it follows that Ï depends monotonically on time, and also
that dt = (mr2/pÏ) dÏ. Combining the latter with (3.7) written in differential form,
dt = &plusmn;&radic;m/2 [E &minus; Ve(r)]&minus;1/2 dr , yields the equation for the trajectory,
</p>
<p>Ï(r) = Ï0 &plusmn;
pÏ&radic;
2m
</p>
<p>&int; r
</p>
<p>r0
</p>
<p>dÎ¾
</p>
<p>Î¾ 2
&radic;
E &minus; Ve(Î¾ )
</p>
<p>, (3.8)
</p>
<p>with Ï0 = Ï(t = 0). Finally, elimination of r from t(r) and Ï(r) provides the time
evolution of Ï. It is convenient to let the initial time t = 0 correspond to an extremum
of the possible values of r . In this way the sign of t and Ï &minus; Ï0 changes at r = r0.
By this choice the trajectory is symmetric with respect to the line drawn from the
origin to the point of coordinates r0,Ï0, and the evolution of the particle&rsquo;s motion
over each half of the trajectory is symmetric with respect to time.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.5 Two-Particle Collision 47
</p>
<p>3.5 Two-Particle Collision
</p>
<p>Consider a system made of two particles whose masses are m1, m2. The system
is isolated, namely, the particles are not subjected to any forces apart those due
to the mutual interaction. As a consequence, the Lagrangian function is invariant
under coordinate translations, and the Hamiltonian function is invariant under time
translations. Thus, as shown in Sect. 2.6, the total momentum and total energy of the
system are conserved.
</p>
<p>The type of motion that is considered is such that the distance between the particles
is initially so large as to make the interaction negligible. The interaction becomes
significant when the particles come closer to each other; when they move apart, the
interaction becomes negligible again. This type of interaction is called collision. The
values of the dynamical quantities that hold when the interaction is negligible are
indicated as asymptotic values. The labels a and bwill be used to mark the asymptotic
values before and after the interaction, respectively.
</p>
<p>It is worth specifying that it is assumed that the collision does not change the
internal state of the particles (for this reason it is more appropriately termed elastic
collision, [67, Sect. 17]). When the distance is sufficiently large, the particles can
be considered as isolated: they move at a constant velocity and the total energy of
the system is purely kinetic, Ea = Ta and Eb = Tb. On the other hand, due to
the invariance under time translation the total energy of the system is conserved,
Eb = Ea . In conclusion it is Tb = Ta , namely, in an elastic collision the asymptotic
kinetic energy of the system is conserved.
</p>
<p>An analysis of the collision based only on the asymptotic values is incomplete
because it does not take into account the details of the interaction between the two
particles. However it provides a number of useful results, so it is worth pursuing.
Letting r1 and r2 be the positions of the particles in a reference O, the position of
the center of mass and the relative position of the particles are
</p>
<p>R = m1 r1 +m2 r2
m1 +m2
</p>
<p>, r = r1 &minus; r2. (3.9)
</p>
<p>The corresponding velocities are v1 = rÌ1, v2 = rÌ2, and v = rÌ. The relations between
the velocities are obtained by differentiating (3.9) with respect to time. Solving for
v1, v2 yields
</p>
<p>v1 = RÌ +
m2
</p>
<p>m1 +m2
v, v2 = RÌ &minus;
</p>
<p>m1
</p>
<p>m1 +m2
v. (3.10)
</p>
<p>Letting RÌ = |RÌ|, the system&rsquo;s kinetic energy before the interaction is
</p>
<p>Ta =
1
</p>
<p>2
m1 v
</p>
<p>2
1a +
</p>
<p>1
</p>
<p>2
m2 v
</p>
<p>2
2a =
</p>
<p>1
</p>
<p>2
(m1 +m2) RÌ2a +
</p>
<p>1
</p>
<p>2
m v2a , (3.11)
</p>
<p>where m = m1 m2/(m1 +m2) is called reduced mass. The expression of the kinetic
energy after the interaction is obtained from (3.11) by replacing a with b.</p>
<p/>
</div>
<div class="page"><p/>
<p>48 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>The total momentum before the collision is Pa = m1 v1a+m2 v2a = (m1+m2) RÌa .
The conservation of P due to the invariance under coordinate translations yields
Pb = Pa , whence RÌb = RÌa . Using (3.11) in combination with the conservation rules
RÌb = RÌa and Tb = Ta yields vb = va , namely, the asymptotic modulus of the relative
velocity is conserved.
</p>
<p>The analysis is now repeated in a new referenceB in which the particles&rsquo;positions
are defined as
</p>
<p>s1 = r1 &minus; R =
m2
</p>
<p>m1 +m2
(r1 &minus; r2), s2 = r2 &minus; R =
</p>
<p>m1
</p>
<p>m1 +m2
(r2 &minus; r1). (3.12)
</p>
<p>By construction, the origin of B coincides with the system&rsquo;s center of mass. The
relative position in B is the same as in O, in fact
</p>
<p>s = s1 &minus; s2 = r1 &minus; r2 = r. (3.13)
</p>
<p>From (3.12, 3.13) one finds
</p>
<p>m1 s1 = &minus;m2 s2, s1 =
m2
</p>
<p>m1 +m2
s, s2 = &minus;
</p>
<p>m1
</p>
<p>m1 +m2
s. (3.14)
</p>
<p>The velocities in reference B are u1 = sÌ1, u2 = sÌ2, and u = sÌ. The relations among
the latter are found by differentiating (3.12, 3.13) and read
</p>
<p>u1 = v1 &minus; RÌ, u2 = v2 &minus; RÌ, u = v, (3.15)
</p>
<p>u1 =
m2
</p>
<p>m1 +m2
u, u2 = &minus;
</p>
<p>m1
</p>
<p>m1 +m2
u, (3.16)
</p>
<p>which in turn yield
</p>
<p>v1 = RÌ +
m2
</p>
<p>m1 +m2
u, v2 = RÌ &minus;
</p>
<p>m1
</p>
<p>m1 +m2
u. (3.17)
</p>
<p>Thanks to (3.16) the system&rsquo;s kinetic energy before and after the interaction, in
reference B, is
</p>
<p>Ka =
1
</p>
<p>2
m1u
</p>
<p>2
1a +
</p>
<p>1
</p>
<p>2
m2u
</p>
<p>2
2a =
</p>
<p>1
</p>
<p>2
mu2a , Kb =
</p>
<p>1
</p>
<p>2
mu2b. (3.18)
</p>
<p>The conservation of the kinetic energy, Kb = Ka , yields ub = ua . Using the third of
(3.15) then yields
</p>
<p>ub = ua = vb = va , (3.19)
</p>
<p>that is, the asymptotic modulus of the relative velocity is conserved and has the same
value in the two references. Moreover, (3.16) show that it is also u1b = u1a and
u2b = u2a , namely, in reference B the asymptotic kinetic energy is conserved for
each particle separately.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.6 Energy Exchange in the Two-Particle Collision 49
</p>
<p>Fig. 3.3 Graphic
representation of the vector
relation (3.20)
</p>
<p>vm m= vaa1
</p>
<p>m
2
v
</p>
<p>2 b
</p>
<p>mub
</p>
<p>Ï
</p>
<p>Î¸Î¸
</p>
<p>3.6 Energy Exchange in the Two-Particle Collision
</p>
<p>To complete the asymptotic analysis of the two-particle collision it is useful to choose
for O a reference such that v2a = 0. In this case (3.10) yield va = v1a , whence the
total momentum reads (m1+m2) RÌa = m1v1a = m1va . Remembering that RÌb = RÌa
one finds RÌb = m1 va/(m1 + m2). Using the latter relation in the second of (3.17)
specified with the b label yields, after multiplying both sides by m2,
</p>
<p>m2v2b = mva &minus;mub. (3.20)
The triangle formed by the vectors m2v2b, mva , and mub is isosceles because va and
ub have the same modulus (Fig. 3.3). LettingÏ , Î¸ be the angle betweenm va andm ub
and, respectively, the common value of the other two angles, a scalar multiplication
of (3.20) by va yields m2 v2b cos Î¸ = mva &minus;mub cosÏ = mva (1 &minus; cosÏ). Using
2Î¸ + Ï = Ï and va = v1a transforms the latter into
</p>
<p>m2v2b = mv1a
1 &minus; cosÏ
</p>
<p>cos [(Ï &minus; Ï )/2] = 2mv1a sin (Ï/2). (3.21)
</p>
<p>This relation allows one to calculate, in reference O where the particle of mass m2
is initially at rest, the modulus of the final velocity of this particle in terms of the
initial velocity of the other particle and of angle Ï . As only v1a is prescribed, the two
quantities v2b and Ï can not be determined separately. The reason for this (already
mentioned in Sect. 3.5) is that (3.21) is deduced using the motion&rsquo;s asymptotic
conditions without considering the interaction&rsquo;s details. In fact, the calculation is
based only on the momentum and total-energy conservation and on the hypothesis
that the collision is elastic. From (3.21) one derives the relation between the kinetic
energies T1a = (1/2)m1v21a and T2b = (1/2)m2v22b,
</p>
<p>T2b (Ï) =
4m1 m2
</p>
<p>(m1 +m2)2
T1a sin
</p>
<p>2 (Ï/2). (3.22)
</p>
<p>As in reference O the particle of mass m2 is initially at rest, T2b is the variation of
the kinetic energy of this particle due to to the collision, expressed in terms of Ï .</p>
<p/>
</div>
<div class="page"><p/>
<p>50 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>The maximum variation is T2b(Ï = &plusmn;Ï ). The conservation relation for the kinetic
energy T1b + T2b = T1a coupled with (3.22) yields the kinetic energy of the particle
of mass m1 after the collision,
</p>
<p>T1b = T1a &minus; T2b =
[
</p>
<p>1 &minus; 4m1 m2
(m1 +m2)2
</p>
<p>sin2 (Ï/2)
</p>
<p>]
</p>
<p>T1a. (3.23)
</p>
<p>Expressing T1a and T1a in (3.23) in terms of the corresponding velocities yields the
modulus of the final velocity of the particle of mass m1 as a function of its initial
velocity and of angle Ï ,
</p>
<p>v1b = [(m21 +m22 + 2m1m2 cosÏ )1/2/(m1 +m2)] v1a. (3.24)
</p>
<p>Although expressions (3.21&ndash;3.24) are compact, the use of angle Ï is inconvenient.
It is preferable to use the angle, say Ï , between vectors v1b and v1a = va that
belong to the same reference O (Fig. 3.7).1 A scalar multiplication by v1a of the
conservation relation for momentum, m1v1b = m1v1a &minus; m2v2b, followed by the
replacement of the expressions of v2b and v1b extracted from (3.21, 3.24), eventually
yields cosÏ = (m1 +m2 cosÏ )/(m21 +m22 + 2m1m2 cosÏ )1/2. Squaring both sides
of the latter provides the relation between Ï and Ï ,
</p>
<p>tanÏ = sin Ï
m1/m2 + cosÏ
</p>
<p>. (3.25)
</p>
<p>Using (3.25) one expresses (3.21&ndash;3.24) in terms of the deflection Ï (in reference
O) of the particle of mass m1. If m1 &gt; m2, then Ï &lt; Ï/2, while it is Ï = Ï/2 if
m1 = m2. When m1 &lt; m2 and Ï = arccos ( &minus; m1/m2), then Ï = Ï/2; finally, if
m1 âª m2 it is Ï â Ï and, from (3.21&ndash;3.24), it follows v2b â 0, T2b â 0, v1b â v1a ,
T1b â T1a . In other terms, when m1 âª m2 the particle of mass m2 remains at rest;
the other particle is deflected, but its kinetic energy is left unchanged.
</p>
<p>In reference O, the angle between the final velocity of the particle of mass m2,
initially at rest, and the initial velocity of the other particle has been defined above
as Î¸ = (Ï &minus; Ï )/2. Replacing the latter in (3.25) provides the relation between Ï
and Î¸ ,
</p>
<p>tanÏ = sin (2Î¸ )
m1/m2 &minus; cos (2Î¸ )
</p>
<p>. (3.26)
</p>
<p>1 Note that the angle Î³ between two momenta p&prime; = m&prime;v&prime; and p&prime;&prime; = m&prime;&prime;v&prime;&prime; is the same as that
between the corresponding velocities because the masses cancel out in the angle&rsquo;s definition Î³ =
arccos [p&prime; &middot; p&prime;&prime;/(p&prime;p&prime;&prime;)]. In contrast, a relation like (3.20) involving a triad of vectors holds for the
momenta but not (with the exception of the trivial cases of equal masses) for the corresponding
velocities.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.7 Central Motion in the Two-Particle Interaction 51
</p>
<p>3.7 Central Motion in the Two-Particle Interaction
</p>
<p>Consider an isolated two-particle system where the force acting on each particle
derives from a potential energyV = V (r1, r2). Using the symbols defined in Sect. 3.5
yields the Lagrangian function L = m1v21/2+m2v22/2&minus;V (r1, r2). Now assume that
the potential energy V depends on the position of the two particles only through
the modulus of their distance, r = |r1 &minus; r2|. In this case it is convenient to use the
coordinates and velocities relative to the center of mass, (3.12&ndash;3.17), to find
</p>
<p>L = 1
2
</p>
<p>(m1 +m2) RÌ2 +
1
</p>
<p>2
m sÌ2 &minus; V (s), sÌ = |sÌ| = |u|. (3.27)
</p>
<p>As discussed in Sects. 2.6.3 and 3.5 the total momentum is conserved, whence RÌ
is constant. Another way of proving this property is noting that the components
of R are cyclic (Sect. 1.6). The first term at the right hand side of (3.27), being a
constant, does not influence the subsequent calculations. The remaining terms, in
turn, are identical to those of (3.4). This shows that, when in a two-particle system the
potential energy depends only on the relative distance, adopting suitable coordinates
makes the problem identical to that of the central motion. One can then exploit the
results of Sect. 3.4. Once the time evolution of s is found, the description of the
motion of the individual particles is recovered from (3.12&ndash;3.17), where the constant
RÌ is determined by the initial conditions.
</p>
<p>The total energy of the two-particle system is conserved and, in the new reference,
it reads
</p>
<p>1
</p>
<p>2
m sÌ2 + V (s) = EB , EB = E &minus;
</p>
<p>1
</p>
<p>2
(m1 +m2) RÌ2. (3.28)
</p>
<p>The total angular momentum is constant as well. Starting from the original reference
and using (3.12&ndash;3.17) yields
</p>
<p>M = r1 &and;m1v1 + r2 &and;m2v2 = (m1 +m2) R &and; RÌ +m s &and; u. (3.29)
</p>
<p>The constancy of RÌ yields R = R0 + RÌ t , with R0 the initial value of R, whence
(R0 + RÌ t) &and; RÌ = R0 &and; RÌ. Thus, the first term at the right hand side of (3.29) is
constant, which makes MB = m s&and;u a constant as well. The latter vector is parallel
to M because the motion is confined to a fixed plane (Sect. 3.4). Then, aligning
the z axis with M, turning to polar coordinates over the x, y plane (sx = s cosÏ,
sy = s sin Ï), and using (3.8), one finds
</p>
<p>Ï(s) = Ï0 &plusmn;
MB&radic;
</p>
<p>2m
</p>
<p>&int; s
</p>
<p>s0
</p>
<p>dÎ¾
</p>
<p>Î¾ 2
&radic;
EB &minus; Ve(Î¾ )
</p>
<p>, (3.30)
</p>
<p>with Ve(s) = V (s)+M2B/(2ms2). It is important to note that the factor MB in (3.30)
is the scalar coefficient of MB = MBk, with k the unit vector of the z axis. As a
consequence, MB may have sign. As observed in Sect. 2.9, the admissible values of
s are those belonging to the interval such that EB &ge; Ve(s). If two or more disjoint</p>
<p/>
</div>
<div class="page"><p/>
<p>52 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>Fig. 3.4 Graphic
representation of the
trajectory (3.35) for different
values of the angular
momentum. The curves have
been obtained by setting the
parameters&rsquo; values to s0 = 1,
Ï0 = 0, Î» = 0.5, and
Î¼ = 0.01, . . . , 0.6 (the units
are arbitrary)
</p>
<p>0 2 4 6 8 10
s
</p>
<p>x
 = s cosÏ   (a. u.)
</p>
<p>-5
</p>
<p>0
</p>
<p>5
</p>
<p>s y
 =
</p>
<p> s
si
</p>
<p>n
Ï
</p>
<p>  
 (
</p>
<p>a.
 u
</p>
<p>.)
</p>
<p>Î¼ = 0.01
Î¼ = 0.1
Î¼ = 0.2
Î¼ = 0.4
Î¼ = 0.6
</p>
<p>intervals exist that have this property, the actual interval of the motion is determined
by the initial conditions. The motion is limited or unlimited, depending on the extent
of this interval.
</p>
<p>The analysis can not be pursued further unless the form of the potential energy V
is specified. This is done in Sect. 3.8 with reference to the Coulomb case.
</p>
<p>3.8 Coulomb Field
</p>
<p>An important example is that of a potential energy of the form V &prop; 1/r , that occurs
for the gravitational and for the electrostatic force. In the latter case the term Coulomb
potential energy is used for V , that reads
</p>
<p>V (s) = Îº Z1 Z2 q
2
</p>
<p>4Ï Îµ0 s
, s &gt; 0, (3.31)
</p>
<p>with q &gt; 0 the elementary electric charge, Z1 q andZ2 q the absolute value of the net
charge of the first and second particle, respectively, Îµ0 the vacuum permittivity and,
finally, Îº = 1 (&minus;1) in the repulsive (attractive) case. The form of V fixes the additive
constant of the energy so that V (&infin;) = 0. The repulsive case only is considered here,
whence Ve is strictly positive and EB &ge; Ve &gt; 0. Defining the lengths
</p>
<p>Î» = Z1 Z2 q
2
</p>
<p>8Ï Îµ0 EB
&gt; 0, Î¼ = MB&radic;
</p>
<p>2mEB
(3.32)
</p>
<p>yields Ve/EB = 2Î»/s+Î¼2/s2. The zeros of EB &minus;Ve = EB (s2 &minus; 2 Î» s&minus;Î¼2)/s2 are
</p>
<p>sA = Î»&minus;
&radic;
</p>
<p>Î»2 + Î¼2, sB = Î»+
&radic;
</p>
<p>Î»2 + Î¼2, (3.33)
where sA is negative and must be discarded as s is strictly positive. The only accept-
able zero is then sB &ge; 2Î» &gt; 0, that corresponds to the position where the radial</p>
<p/>
</div>
<div class="page"><p/>
<p>3.9 System of Particles near an Equilibrium Point 53
</p>
<p>velocity sÌ = &plusmn;&radic;2 (EB &minus; V )/m reverses, and must therefore be identified with s0
(Sect. 3.7). The definitions (3.32, 3.33) are now inserted into the expression (3.30)
of the particle&rsquo;s trajectory. To calculate the integral it is convenient to use a new
variable w such that (s0 &minus; Î»)/(Î¾ &minus; Î») = (Î¼2 &minus; s20 w2)/(Î¼2 + s20 w2). The range of w
corresponding to s0 &le; Î¾ &le; s is
</p>
<p>0 &le; w &le; |Î¼|
s0
</p>
<p>&radic;
</p>
<p>s &minus; s0
s + s0 &minus; 2Î»
</p>
<p>, s &ge; s0 &ge; 2Î» &gt; 0. (3.34)
</p>
<p>From (3.30) the trajectory in the s,Ï reference is thus found to be
</p>
<p>Ï(s) = Ï0 &plusmn; 2 arctan
(
Î¼
</p>
<p>s0
</p>
<p>&radic;
</p>
<p>s &minus; s0
s + s0 &minus; 2Î»
</p>
<p>)
</p>
<p>. (3.35)
</p>
<p>Next, the trajectory in the Cartesian reference sx , sy is found by replacing (3.35) into
sx = s cosÏ, sy = s sin Ï and eliminating s from the pair sx(s), sy(s) thus found. A
graphic example is given in Fig. 3.4. It is worth observing that in the derivation of
(3.35) the factor |Î¼| appears twice, in such a way as to compensate for the sign of
Î¼. The result then holds irrespective of the actual sign of MB =
</p>
<p>&radic;
2mEB Î¼. It still
</p>
<p>holds for MB = 0, that yields Ï(s) = Ï0; such a case corresponds to a straight line
crossing the origin of the s,Ï reference: along this line the modulus s of the relative
position decreases until it reaches s0, then it increases from this point on.
</p>
<p>When MB ï¿½= 0 the angles corresponding to the asymptotic conditions of the
motion are found by letting s &rarr; &infin;, namely, Ïa = Ï0 &minus; 2 arctan (Î¼/s0) and Ïb =
Ï0 + 2 arctan (Î¼/s0). The total deflection is then Ïb &minus; Ïa which, in each curve of
Fig. 3.4, is the angle between the two asymptotic directions. Now one combines the
definition of angle Ï given in Sect. 3.6 with the equality u = v taken from the last
of (3.15); with the aid of Fig. 3.5 one finds
</p>
<p>Ï = Ï &minus; (Ïb &minus; Ïa) = Ï &minus; 4 arctan
(
Î¼
</p>
<p>s0
</p>
<p>)
</p>
<p>. (3.36)
</p>
<p>The definitions (3.32, 3.33) show that (3.36) eventually provides the relation
Ï = Ï (EB ,MB). In contrast with the approach of Sect. 3.6, where the asymp-
totic conditions only were considered, here the analysis has been brought to the end
by considering a specific type of interaction.
</p>
<p>When Î¼ ranges from &minus;&infin; to +&infin; at a fixed EB , the definitions (3.32, 3.33) make
the ratio Î¼/s0 = Î¼/sA to range from &minus;1 to +1. If Î¼/s0 = 1 (&minus;1), then Ï = 0 (2Ï ),
namely, no deflection between ua and ub occurs. If Î¼/s0 = 0, then Ï = Ï , namely,
the motion&rsquo;s direction reverses at s0 as noted above. From u = v one finds that Ï is
also the angle between va = v1a &minus; v2a and vb = v1b &minus; v2b.
</p>
<p>3.9 System of Particles near an Equilibrium Point
</p>
<p>Consider a system of N particles, not necessarily identical to each other, subjected
to conservative forces. The mass and instantaneous position of the j th particle are
indicated with mj and Rj = (Xj1,Xj2,Xj3), respectively. It is assumed that there</p>
<p/>
</div>
<div class="page"><p/>
<p>54 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>Fig. 3.5 Graphic
representation of (3.36)
</p>
<p>ua
</p>
<p>Ï
a
</p>
<p>Ï
b
&minus;
</p>
<p>ub
</p>
<p>Ï
</p>
<p>are no constraints, so that the number of degrees of freedom of the system is 3N .
The Hamiltonian function reads
</p>
<p>Ha = Ta + Va =
N
&sum;
</p>
<p>j=1
</p>
<p>P 2j
</p>
<p>2mj
+ Va(X11,X12, . . . ), (3.37)
</p>
<p>with P 2j = m2j (XÌ2j1 + XÌ2j2 + XÌ2j3). The force acting on the j th particle along the kth
axis is Fjk = &minus;&part;Va/&part;Xjk . The Hamilton equations (Sect. 1.6) read
</p>
<p>XÌjk =
&part;Ha
</p>
<p>&part;Pjk
= Pjk
</p>
<p>mj
, PÌjk = &minus;
</p>
<p>&part;Ha
</p>
<p>&part;Xjk
= &minus; &part;Va
</p>
<p>&part;Xjk
= Fjk. (3.38)
</p>
<p>They show that the relation Fjk = mj XÌjk , which yields the dynamics of the j th
particle along the kth axis, involves the positions of all particles in the system due to
the coupling of the latter.
</p>
<p>Define the 3N -dimensional vector R = (X11, . . . ,XN3) that describes the instan-
taneous position of the system in the configuration space, and let R0 be a position
where the potential energy Va has a minimum, namely, (&part;Va/&part;Xjk)R0 = 0 for all
j , k. Such a position is called equilibrium point of the system. To proceed, assume
that the instantaneous displacement R &minus; R0 with respect to the equilibrium point
is small. In this case one approximates V with a second-order Taylor expansion
around R0. To simplify the notation new symbols are adopted, namely, s1 = X11,
s2 = X12, . . . , s3j+k&minus;3 = Xjk , . . . , and hn = sn &minus; sn0, with n = 1, 2, . . . , 3N and
sn0 the equilibrium position. Remembering that the first derivatives of Va vanish at
R0 one finds
</p>
<p>Va â Va0 +
1
</p>
<p>2
</p>
<p>3N
&sum;
</p>
<p>k=1
hk
</p>
<p>3N
&sum;
</p>
<p>n=1
ckn hn, ckn =
</p>
<p>(
&part;2Va
</p>
<p>&part;hk &part;hn
</p>
<p>)
</p>
<p>R0
</p>
<p>. (3.39)
</p>
<p>In (3.39) it is Va0 = Va(R0), and the terms ckn are called elastic coefficients. As
the approximate form of the potential energy is quadratic in the displacements, each</p>
<p/>
</div>
<div class="page"><p/>
<p>3.10 Diagonalization of the Hamiltonian Function 55
</p>
<p>component of the force is a linear combination of the latter,
</p>
<p>Fr = &minus;
&part;Va
</p>
<p>&part;sr
= &minus;&part;Va
</p>
<p>&part;hr
= &minus;
</p>
<p>3N
&sum;
</p>
<p>n=1
crn hn, r = 3j + k &minus; 3. (3.40)
</p>
<p>To recast the kinetic energy in terms of the new symbols it is necessary to indicate
the masses with Î¼n, n = 1, . . . , 3N , where Î¼3j&minus;2 = Î¼3j&minus;1 = Î¼3j = mj , j =
1, . . . ,N . Observing that XÌjk = sÌ3j+k&minus;3 = hÌ3j+k&minus;3, one finds a quadratic form in
the derivatives of the displacements,
</p>
<p>Ta =
1
</p>
<p>2
</p>
<p>N
&sum;
</p>
<p>j=1
</p>
<p>3
&sum;
</p>
<p>k=1
Î¼3j+k&minus;3XÌ
</p>
<p>2
jk =
</p>
<p>1
</p>
<p>2
</p>
<p>N
&sum;
</p>
<p>j=1
</p>
<p>3
&sum;
</p>
<p>k=1
Î¼3j+k&minus;3hÌ
</p>
<p>2
3j+k&minus;3 =
</p>
<p>1
</p>
<p>2
</p>
<p>3N
&sum;
</p>
<p>n=1
Î¼nhÌ
</p>
<p>2
n. (3.41)
</p>
<p>The relations obtained so far are readily recast in matrix form. First, one de-
fines the mass matrix M as the real, 3N &times; 3N diagonal matrix whose entries are
[M]kn = Î¼n Î´kn &gt; 0, with Î´kn the Kronecker symbol (A.18). By construction,
the mass matrix is symmetric and positive definite; the entries of its inverse are
[M&minus;1]kn = Î´kn/Î¼n. Then, one defines the elastic matrix C as the real, 3N &times; 3N
matrix whose entries are [C]kn = ckn. The entries of the elastic matrix are the second
derivatives of the potential energy Va; as the order of the derivation is irrelevant,
the matrix is symmetric. Also, the derivatives are calculated in a minimum of Va;
from the first of (3.39) it follows that the quadratic form at the right hand side equals
Va &minus; Va0 which, by construction, is positive. It follows that the elastic matrix is
positive definite, namely, for any choice of the displacements (excluding the case
where all displacements are zero) the quadratic form generated by the matrix is pos-
itive. Finally, let h be the column vector of entries h1,h2, . . . , and hT its transpose.
Combining (3.37, 3.39, 3.41) expresses the Hamiltonian function in terms of the sum
of two quadratic forms,
</p>
<p>Ha &minus; Va0 =
1
</p>
<p>2
hÌT M hÌ + 1
</p>
<p>2
hT C h. (3.42)
</p>
<p>3.10 Diagonalization of the Hamiltonian Function
</p>
<p>Thanks to the properties of the matrices M and C, the right hand side of (3.42) can
be set in diagonal form. To this purpose one considers the eigenvalue equation
</p>
<p>C gÏ = Î»Ï M gÏ , Ï = 1, . . . , 3N , (3.43)
</p>
<p>where the eigenvalues Î»Ï are real because C and M are real and symmetric. As all
coefficients of (3.43) are real, the eigenvectors gÏ are real as well. Also, due to the
positive definiteness of C and M, the eigenvalues are positive and the eigenvectors
are linearly independent. They can also be selected in order to fulfill the property of
being orthonormal with respect to M, namely, gTÏ M gÏ = Î´ÏÏ .</p>
<p/>
</div>
<div class="page"><p/>
<p>56 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>Each of the 3N eigenvectors gÏ has 3N entries. Thus, the set of eigenvectors
can be arranged to form a 3N &times; 3N real matrix G, whose Ï th column is the Ï th
eigenvector. The inverse matrix G&minus;1 exists because, by construction, the columns of
G are linearly independent. The orthonormality relation between the eigenvectors
can now be expressed in matrix form as
</p>
<p>GT M G = I, (3.44)
</p>
<p>with I the identity matrix. Equation (3.44) is the basic ingredient for the diagonal-
ization of (3.42). From it one preliminarily derives four more relations,
</p>
<p>GT M = G&minus;1, G GT M = I, M G =
(
</p>
<p>GT
)&minus;1
</p>
<p>, M G GT = I. (3.45)
</p>
<p>The first of (3.45) is obtained by right multiplying (3.44) by G&minus;1 and using G G&minus;1 =
I. Left multiplying by G the first of (3.45) yields the second one. The third of (3.45)
is obtained by left multiplying (3.44) by (GT )&minus;1. Finally, right multiplying by GT the
third of (3.45) yields the fourth one. To complete the transformation of the equations
into a matrix form one defines the eigenvalue matrix L as the real, 3N&times;3N diagonal
matrix whose entries are [L]ÏÏ = Î»Ï Î´ÏÏ &gt; 0. The set of 3N eigenvalue Eqs. (3.43)
then takes one of the two equivalent forms
</p>
<p>C G = M G L, GT C G = L. (3.46)
</p>
<p>The first of (3.46) is the analogue of (3.43), while the second form is obtained from
the first one by left multiplying by GT and using (3.44). The diagonalization of
(3.42) is now accomplished by inserting the second and fourth of (3.45) into the
potential-energy term of (3.42) to obtain
</p>
<p>hT C h = hT (M G GT ) C (G GT M) h = (hT M G) (GT C G) (GT M h), (3.47)
</p>
<p>where the associative law has been used. At the right hand side of (3.47), the term in
the central parenthesis is replaced with L due to the second of (3.46). The term in the
last parenthesis is a column vector for which the short-hand notation b = GT M h is
introduced. Note that b depends on time because h does. The first of (3.45) shows
that h = G b, whence hT = bT GT . Finally, using (3.44), transforms the term in the
first parenthesis at the right hand side of (3.47) into hT M G = bT GT M G = bT .
In conclusion, the potential-energy term of (3.42) is recast in terms of b as hT C h =
bT L b, which is the diagonal form sought. By a similar procedure one finds for the
kinetic-energy term hÌT M hÌ = bÌT GT M G bÌ = bÌT bÌ.
</p>
<p>The terms bÌT bÌ and bT L b have the same units. As a consequence, the units of
L are the inverse of a time squared. Remembering that the entries of L are positive,
one introduces the new symbol Ï2Ï = Î»Ï for the eigenvalues, ÏÏ &gt; 0. In conclusion,
the diagonal form of (3.42) reads
</p>
<p>Ha &minus; Va0 =
3N
&sum;
</p>
<p>Ï=1
HÏ , HÏ =
</p>
<p>1
</p>
<p>2
bÌ2Ï +
</p>
<p>1
</p>
<p>2
Ï2Ï b
</p>
<p>2
Ï . (3.48)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.11 Periodic Potential Energy 57
</p>
<p>Apart from the constant Va0, the Hamiltonian function Ha is given by a sum of terms,
each associated with a single degree of freedom. A comparison with (3.1) shows that
the individual summands HÏ are identical to the Hamiltonian function of a linear
harmonic oscillator with m = 1. As a consequence, the two canonical variables of
the Ï th degree of freedom are qÏ = bÏ , pÏ = bÌÏ , and the time evolution of bÏ is the
same as that in (3.2),
</p>
<p>bÏ (t) = Î²Ï cos (ÏÏ t + ÏÏ ) =
1
</p>
<p>2
</p>
<p>[
</p>
<p>Î²ÌÏ exp ( &minus; iÏÏ t) + Î²Ì&lowast;Ï exp (iÏÏ t)
]
</p>
<p>. (3.49)
</p>
<p>The constants Î²Ï , ÏÏ depend on the initial conditions bÏ (0), bÌÏ (0). The complex
coefficients are related to the above constants by Î²ÌÏ = Î²Ï exp ( &minus; iÏÏ ). In turn,
the initial conditions are derived from those of the displacements, b(0) = G&minus;1 h(0),
bÌ(0) = G&minus;1 hÌ(0).
</p>
<p>The 3N functions bÏ (t) are called normal coordinates or principal coordinates.
Once the normal coordinates have been found, the displacements of the particles are
determined from h = G b. It follows that such displacements are superpositions of
oscillatory functions. Despite the complicacy of the system, the approximation of
truncating the potential energy to the second order makes the Hamiltonian function
completely separable in the normal coordinates. The problem then becomes a gen-
eralization of that of the linear harmonic oscillator (Sect. 3.3), and the frequencies
of the oscillators are determined by combining the system parameters, specifically,
the particle masses and elastic constants. The Hamiltonian function associated with
each degree of freedom is a constant of motion, HÏ = EÏ , whose value is prescribed
by the initial conditions. The total energy of the system is also a constant and is given
by
</p>
<p>E = Va0 +
3N
&sum;
</p>
<p>Ï=1
EÏ , EÏ =
</p>
<p>1
</p>
<p>2
bÌ2Ï (0) +
</p>
<p>1
</p>
<p>2
Ï2Ï b
</p>
<p>2
Ï (0). (3.50)
</p>
<p>The oscillation of the normal coordinate of indexÏ is also called mode of the vibrating
system.
</p>
<p>3.11 Periodic Potential Energy
</p>
<p>An interesting application of the action-angle variables introduced in Sect. 2.10 is
found in the case of a conservative motion where the potential energy V is periodic.
For simplicity a linear motion is considered (Sect. 2.9), whence V (x + a) = V (x),
with a &gt; 0 the spatial period. Letting E be the total energy and m the mass of the
particle, an unlimited motion is assumed, namely, E &gt; V ; it follows that the mo-
mentum p = &radic;2m [E &minus; V (x)] is a spatially-periodic function of period a whence,
according to the definition of Sect. 2.10, the motion is a rotation. For any position g,
the time Ï necessary for the particle to move from g to g + a is found from (2.47),</p>
<p/>
</div>
<div class="page"><p/>
<p>58 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>where the positive sign is provisionally chosen:
</p>
<p>Ï =
&radic;
</p>
<p>m
</p>
<p>2
</p>
<p>&int; g+a
</p>
<p>g
</p>
<p>dx&radic;
E &minus; V (x) &gt; 0. (3.51)
</p>
<p>The integral in (3.51) is independent of g due to the periodicity of V . As a conse-
quence, for any g the position of the particle grows by a during the time Ï . The action
variable is found from (2.49):
</p>
<p>J (E) =
&int; g+a
</p>
<p>g
</p>
<p>p dx =
&radic;
</p>
<p>2m
&int; g+a
</p>
<p>g
</p>
<p>&radic;
</p>
<p>E &minus; V (x) dx = const. (3.52)
</p>
<p>In turn, the derivative of the angle variable is found from (2.51). It reads wÌ =
&part;H/&part;J = 1/(dJ/dE) = const, with H the Hamiltonian function. The second
form of wÌ holds because H does not depend on w, and H = E. Using (3.52) and
comparing with (3.51) one finds
</p>
<p>1
</p>
<p>wÌ
= dJ
</p>
<p>dE
=
</p>
<p>&int; g+a
</p>
<p>g
</p>
<p>m
</p>
<p>[2m (E &minus; V (x))]1/2
dx = Ï. (3.53)
</p>
<p>As expected, 1/Ï is the rotation frequency. In conclusion, the time evolution of the
action-angle variables is given by w = t/Ï + w0, J = const. Note that the relation
(3.52) between E and J holds when the positive sign is chosen in (2.47); if the
above calculations are repeated after choosing the negative sign, one finds that &minus;J
is associated to the same E. As a consequence, E is an even function of J .
</p>
<p>Another observation is that the action-angle variables can be scaled by letting,
e.g., w J = (a w) (J/a). In this way the property that the product of two canonically-
conjugate variables is dimensionally an action is still fulfilled. A comparison with
(3.52) shows that, thanks to this choice of the scaling factor, P = J/a is the average
momentum over a period, while X = a w is a length. The Hamilton equations and
the time evolution of the new variables are then
</p>
<p>XÌ = &part;H
&part;P
</p>
<p>, PÌ = &minus;&part;H
&part;X
</p>
<p>= 0, X = a
Ï
t +X0, P = P0 = const, (3.54)
</p>
<p>where a/Ï is the average velocity of the particle over the spatial period, and X0 =
X(0), P0 = P (0). In conclusion, in the new canonical variables no force is acting
(PÌ = 0), and the motion of the new position X is uniform in time. However, the
relation between E and P = J/a, given by (3.52), is not quadratic as it would be in
free space.2
</p>
<p>In many cases it is of interest to investigate the particle&rsquo;s dynamics when a per-
turbation Î´H is superimposed to the periodic potential energy V . It is assumed that
Î´H depends on x only, and that E is the same as in the unperturbed case (the latter
assumption is not essential). The Hamiltonian function of the perturbed case is then
</p>
<p>2 Compare with comments made in Sect. 19.6.1.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.11 Periodic Potential Energy 59
</p>
<p>written as the sum of the unperturbed one and of the perturbation; also in this case
an unlimited motion is assumed, specifically, E &gt; V and E &gt; V + Î´H . Still using
the positive sign for the momentum, one finds
</p>
<p>H (x,p) = p
2
</p>
<p>2m
+ V (x) + Î´H (x) = E, p(x,E) =
</p>
<p>&radic;
</p>
<p>2m (E &minus; V &minus; Î´H ).
(3.55)
</p>
<p>As in the unperturbed case one defines the average momentum over a,
</p>
<p>PÌ (g,E) =
&radic;
</p>
<p>2m
</p>
<p>a
</p>
<p>&int; g+a
</p>
<p>g
</p>
<p>&radic;
E &minus; V &minus; Î´H dx, (3.56)
</p>
<p>which depends also on g because Î´H is not periodic. Differentiating (3.56) with
respect to E and comparing with (3.51) shows that
</p>
<p>&part;PÌ
</p>
<p>&part;E
= ÏÌ
</p>
<p>a
, ÏÌ (g) =
</p>
<p>&int; g+a
</p>
<p>g
</p>
<p>m
</p>
<p>[2m (E &minus; V (x) &minus; Î´H )]1/2 dx, (3.57)
</p>
<p>with ÏÌ the time necessary for the particle to move from g to g + a in the perturbed
case. Using H = E in the above yields
</p>
<p>&part;H
</p>
<p>&part;PÌ
= a
</p>
<p>ÏÌ
= (g + a) &minus; g
</p>
<p>ÏÌ
. (3.58)
</p>
<p>So far no hypothesis has been made about the perturbation. Now one assumes that Î´H
is weak and varies little over the period a. The first hypothesis implies |Î´H | âª E&minus;V
so that, to first order, [2m (E &minus; V &minus; Î´H )]1/2 â [2m (E &minus; V )]1/2 &minus; m [2m (E &minus;
V )]&minus;1/2 Î´H . Using P = J/a and (3.52), the average momentum (3.56) becomes
</p>
<p>PÌ (g,E) â P (E) &minus; 1
a
</p>
<p>&int; g+a
</p>
<p>g
</p>
<p>mÎ´H
</p>
<p>[2m (E &minus; V )]1/2 dx. (3.59)
</p>
<p>In turn, the hypothesis that the perturbation varies little over the period a implies that
in the interval [g, g+ a] one can approximate Î´H (x) with Î´H (g), which transforms
(3.59), due to (3.53), into
</p>
<p>PÌ (g,E) â P (E) &minus; Ï
a
Î´H (g). (3.60)
</p>
<p>If the procedure leading to (3.60) is repeated in the interval [g + a, g + 2 a] and the
result is subtracted from (3.60), the following is found:
</p>
<p>PÌ (g + a,E) &minus; PÌ (g,E)
Ï
</p>
<p>= &minus;Î´H (g + a) &minus; Î´H (g)
a
</p>
<p>. (3.61)
</p>
<p>The above shows that the perturbed momentum PÌ varies between g and g + a due
to the corresponding variation in Î´H . Fixing the time origin at the position g and
letting Ï â ÏÌ in the denominator transforms (3.61) into
</p>
<p>PÌ (ÏÌ ,E) &minus; PÌ (0,E)
ÏÌ
</p>
<p>â &minus;Î´H (g + a) &minus; Î´H (g)
a
</p>
<p>. (3.62)</p>
<p/>
</div>
<div class="page"><p/>
<p>60 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>The relations (3.58, 3.62) are worth discussing. If one considers g as a position coor-
dinate and PÌ as the momentum conjugate to it, (3.58, 3.62) become a pair of Hamilton
equations where some derivatives are replaced with difference quotients. Specifically,
(3.62) shows that the average momentum varies so that its &ldquo;coarse-grained&rdquo; variation
with respect to time, ï¿½PÌ/ï¿½ÏÌ , is the negative coarse-grained variation of the Hamil-
tonian function with respect to space, &minus;ï¿½H/ï¿½g = &minus;ï¿½Î´H/ï¿½g. In turn, (3.58)
shows that the coarse-grained variation of position with respect to time, ï¿½g/ï¿½ÏÌ , is
the derivative of the Hamiltonian function with respect to the average momentum.
In conclusion, (3.58, 3.62) are useful when one is not interested in the details of the
particle&rsquo;s motion within each spatial period, but wants to investigate on a larger scale
how the perturbation influences the average properties of the motion.
</p>
<p>3.12 Energy-Momentum Relation in a Periodic Potential
</p>
<p>Energy
</p>
<p>It has been observed, with reference to the non-perturbed case, that the relation (3.52)
between the total energy and the average momentum is not quadratic. In the perturbed
case, as shown by (3.56), the momentum depends on both the total energy and the
coarse-grained position. To investigate this case it is then necessary to fix g and
consider the dependence of PÌ on E only. To proceed one takes a small interval of PÌ
around a given value, say, PÌs , corresponding to a total energy Es , and approximates
the E(PÌ ) relation with a second-order Taylor expansion around PÌs ,
</p>
<p>E â Es +
(
</p>
<p>dE
</p>
<p>dPÌ
</p>
<p>)
</p>
<p>s
</p>
<p>(PÌ &minus; PÌs) +
1
</p>
<p>2
</p>
<p>(
d2E
</p>
<p>dPÌ 2
</p>
<p>)
</p>
<p>s
</p>
<p>(PÌ &minus; PÌs)2. (3.63)
</p>
<p>Although in general the PÌ (E) relation (3.56) can not be inverted analytically, one
can calculate the derivatives that appear in (3.63). The latter are worked out in the
unperturbed case Î´H = 0 for simplicity. Using (3.53), the first derivative is found to
be (dE/dPÌ )s â (dE/dP )s = a/Ïs , with Ïs = Ï (Es). For the second derivative,
</p>
<p>d2E
</p>
<p>dPÌ 2
â d
</p>
<p>2E
</p>
<p>dP 2
= d(a/Ï )
</p>
<p>dP
= &minus; a
</p>
<p>Ï 2
</p>
<p>dÏ
</p>
<p>dE
</p>
<p>dE
</p>
<p>dP
= &minus;a
</p>
<p>3
</p>
<p>Ï 3
</p>
<p>d2P
</p>
<p>dE2
. (3.64)
</p>
<p>On the other hand, using (3.53) again, it is
</p>
<p>d2P
</p>
<p>dE2
= d(Ï/a)
</p>
<p>dE
= &minus;m
</p>
<p>2
</p>
<p>a
</p>
<p>&int; g+a
</p>
<p>g
</p>
<p>K3 dx, K = [2m (E &minus; V (x))]&minus;1/2 . (3.65)
</p>
<p>Combining (3.64) with (3.65) and defining the dimensionless parameter
</p>
<p>rs =
&int; g/a+1
</p>
<p>g/a
</p>
<p>K3 d(x/a) &times;
[&int; g/a+1
</p>
<p>g/a
</p>
<p>K d(x/a)
</p>
<p>]&minus;3
, (3.66)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.13 Complements 61
</p>
<p>transforms (3.63) into
</p>
<p>E â Es +
a
</p>
<p>Ïs
(PÌ &minus; PÌs) +
</p>
<p>rs
</p>
<p>2m
(PÌ &minus; PÌs)2, (3.67)
</p>
<p>where the coefficients, thanks to the neglect of the perturbation, do not depend on g.
The linear term is readily eliminated by shifting the origin of the average momentum;
in fact, letting PÌ &minus; PÌs = pÌ &minus; (m/rs) (a/Ïs) yields
</p>
<p>E &minus; E(0) = rs
2m
</p>
<p>pÌ2, E(0) = Es &minus;
1
</p>
<p>2
</p>
<p>m
</p>
<p>rs
</p>
<p>(
a
</p>
<p>Ïs
</p>
<p>)2
</p>
<p>. (3.68)
</p>
<p>In conclusion, in a small interval of pÌ the relation between energy and average
momentum of a particle of mass m subjected to a periodic potential has the same
form as that of a free particle of mass m/rs . In other terms, the ratio m/rs acts as an
effective mass within the frame of the coarse-grained dynamics.
</p>
<p>A bound for rs is obtained from H&ouml;lder&rsquo;s inequality (C.110). Letting |F | = K ,
G = 1, b = 3, x1 = g/a, x2 = g/a + 1 in (C.110), and using the definition
(3.66), yields rs &ge; 1, whence m/rs &le; m: the effective mass can never exceed
the true mass. The equality between the two masses is found in the limiting case
E &minus; VM â« VM &minus; V &minus; Î´H , with VM the maximum of V . In fact, (3.66) yields
r â 1 and, from (3.56), it is PÌ â
</p>
<p>&radic;
2mE. As expected, this limiting case yields the
</p>
<p>dynamics of a free particle.
</p>
<p>3.13 Complements
</p>
<p>3.13.1 Comments on the Linear Harmonic Oscillator
</p>
<p>The paramount importance of the example of the linear harmonic oscillator, shown in
Sect. 3.3, is due to the fact that in several physical systems the position of a particle
at any instant happens to depart little from a point where the potential energy V
has a minimum. As a consequence, the potential energy can be approximated with a
second-order expansion around the minimum, that yields a positive-definite quadratic
form for the potential energy and a linear form for the force. The theory depicted in
this section is then applicable to many physical systems, as shown by the examples
of Sects. 3.9 and 5.6. The approximation of the potential energy with a second-order
expansion, like that discussed in Sects. 3.9, 3.10, is called harmonic approximation.
The terms beyond the second order in the expansion are called anharmonic.
</p>
<p>3.13.2 Degrees of Freedom and Coordinate Separation
</p>
<p>With reference to the analysis of the central motion carried out in Sect. 3.4, it is
worth noting that the constancy of M reduces the number of degrees of freedom of</p>
<p/>
</div>
<div class="page"><p/>
<p>62 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>the problem from three to two. Also, the form (3.6) of the Hamiltonian function is
such as to provide a relation containing only r and the corresponding momentum
pr . Thus, the coordinate r is separable according to the definition of Sect. 2.4. This
allows one to independently find the time evolution (3.7) of r by solving an ordinary
differential equation of the first order. Then one finds (3.8), that is, the trajectory
Ï(r), through another equation of the same type. Finally, combining (3.7) with (3.8)
yields the time evolution of the remaining coordinate Ï.
</p>
<p>It has been noted in Sect. 3.4 that, thanks to the constancy of the angular momen-
tum, the adoption of spherical coordinates allows one to separate the radial coordinate
r . This simplifies the problem, whose solution is in fact reduced to the successive
solution of the evolution equations for r and Ï. The same problem, instead, is not
separable in the Cartesian coordinates. In other terms, separability may hold in some
coordinate reference, but does not hold in general in an arbitrarily-chosen reference.
</p>
<p>Another example of separability is that illustrated in Sects. 3.9, 3.10. In general
the Hamiltonian function is not separable in the Cartesian coordinates, whereas it
is completely separable in the normal coordinates, no matter how large the number
of the degrees of freedom is. Moreover, after the separation has been accomplished,
one finds that all the equations related to the single degrees of freedom (the second
relation in (3.48)) have the same form. In fact, they differ only in the numerical value
of the angular frequency ÏÏ . As a consequence, the expression of the solution is the
same for all. Also, as the energy HÏ of each degree of freedom is independently
conserved, no exchange of energy among the normal coordinates occurs: therefore,
the distribution of energy among the normal coordinates that is present at t = 0 is
maintained forever. This result is baffling because, for instance, it seems to prevent
the condition of thermal equilibrium from being established; actually it is due to
the fact that the system under investigation is isolated: if it were put in contact with
a thermal reservoir, the exchanges of energy occurring with the reservoir would
eventually bring the energy distribution of the system to the condition of thermal
equilibrium.
</p>
<p>Still with reference to the system discussed in Sects. 3.9, 3.10 it is important to
underline the formal analogy between the modes of a mechanical, vibrating system
and those of the electromagnetic field in vacuo described in Sect. 5.6. In both cases
the energy of each mode is that of a linear harmonic oscillator of unit mass (Eq.
(3.48) and, respectively, (5.40)).
</p>
<p>3.13.3 Comments on the Normal Coordinates
</p>
<p>It has been shown in Sect. 3.9 that the elastic matrix C is positive definite. One may
argue that in some cases the matrix is positive semi-definite. Consider, for instance,
the case where the potential energy depends on the relative distance of the particles,
Va = Va(R1 &minus; R2, R1 &minus; R3, . . . ). For any set of positions R1, R2, . . . , a uniform
displacement RÎ´ of all particles, that tranforms each Rj into Rj + RÎ´ , leaves Va
unchanged. As a consequence, if the positions prior to the displacement correspond</p>
<p/>
</div>
<div class="page"><p/>
<p>3.13 Complements 63
</p>
<p>Fig. 3.6 Graphic
representation of (3.69)
</p>
<p>d r
</p>
<p>d + r r
</p>
<p>Q
1
</p>
<p>Q
2
</p>
<p>Q
3
</p>
<p>Q
4
</p>
<p>r
</p>
<p>to the equilibrium point R01, R02, . . . , it is Va(R01+RÎ´ , . . . ) = Va(R01, . . . ) = Va0.
In such a case all terms beyond the zero-order term in the Taylor expansion of Va
around the equilibrium point vanish, which implies that the elastic matrix C is positive
semi-definite. In the case examined in Sect. 3.9 the eigenvalues are real and positive;
here, instead, they are real and non-negative. Remembering (3.48), one finds that the
Hamiltonian function of the degree of freedom corresponding to the null eigenvalue
reads H = bÌ2Ï /2, whence bÌÏ = 0, bÏ = bÏ (0) + a t , with a a constant.
</p>
<p>The problem tackled in Sect. 3.10 is that of diagonalizing the right hand side
of (3.42). The diagonalization of a quadratic form entails a linear transformation
over the original vector (h in this case) using a matrix formed by eigenvectors. One
may observe that, in (3.42), the kinetic energy hÌT M hÌ/2 is already diagonal in the
original vector, while the potential energy hT C h/2 is not. If the diagonalization
were carried out using the matrix formed by the eigenvalues of C alone, the outcome
of the process would be that of making the potential energy diagonal while making
the kinetic energy non-diagonal (both in the transformed vector). The problem is
solved by using the eigenvalue Eq. (3.43), that involves both matrices M and C in
the diagonalization process. In fact, as shown in Sect. 3.10, in the transformed vector
b the potential energy becomes diagonal, and the kinetic energy remains diagonal.
</p>
<p>One may observe that, given the solutions of the eigenvalue Eq. (3.43), the process
of diagonalizing (3.42) is straightforward. The real difficulty lies in solving (3.43).
When the number of degrees of freedom is large, the solution of (3.43) must be tackled
by numerical methods and may become quite cumbersome. In practical applications
the elastic matrix C exhibits some structural properties, like symmetry or periodicity
(e.g., Sect. 17.7.1), that are exploited to ease the problem of solving (3.43).
</p>
<p>3.13.4 Areal Velocity in the Central-Motion Problem
</p>
<p>Consider the central-motion problem discussed in Sect. 3.4. In the elementary time-
interval dt the position vector changes from r to r + dr. The area dA of the triangle
whose sides are r, r + dr, and dr is half the area of the parallelogram Q1Q2Q3Q4</p>
<p/>
</div>
<div class="page"><p/>
<p>64 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>Fig. 3.7 Definition of the
angles used in Sects. 3.6 and
3.13.5
</p>
<p>v
1b
</p>
<p>v
2b
</p>
<p>v
1a
</p>
<p>y
</p>
<p>x
Î¸
</p>
<p>Ï
</p>
<p>c
</p>
<p>whose consecutive sides are, e.g., r and dr (Fig. 3.6). Thus,
</p>
<p>dA = 1
2
|r &and; dr| = 1
</p>
<p>2
|r &and; rÌ dt | = |M|
</p>
<p>2m
dt ,
</p>
<p>dA
</p>
<p>dt
= |M|
</p>
<p>2m
, (3.69)
</p>
<p>with M the angular momentum. The derivative dA/dt is called areal velocity. The
derivation of (3.69) is based purely on definitions, hence it holds in general. For a
central motion the angular momentum M is constant, whence the areal velocity is
constant as well: the area swept out by the position vector r in a given time interval
is proportional to the interval itself (Kepler&rsquo;s second law). If the particle&rsquo;s trajectory
is closed, the time T taken by r to complete a revolution and the area A enclosed by
the orbit are related by
</p>
<p>A =
&int; T
</p>
<p>0
</p>
<p>dA
</p>
<p>dt
dt = |M|
</p>
<p>2m
T , T = 2mA|M| . (3.70)
</p>
<p>3.13.5 Initial Conditions in the Central-Motion Problem
</p>
<p>The theory of the central motion for a two-particle system has been worked out in
Sects. 3.7,3.8 without specifying the initial conditions. To complete the analysis it
is convenient to use the same prescription as in Sect. 3.6, namely, to select an O
reference where the particle of mass m2 is initially at rest (v2a = 0). Moreover, here
reference O is chosen in such a way as to make the initial position of the particle of
mass m2 to coincide with the origin (r2a = 0), and the initial velocity va = v1a of
the particle of mass m1 to be parallel to the x axis (Fig. 3.7), so that v1a = (v1a &middot; i) i.
From (3.11) one finds E = Ea = Ta = T1a = m1v21a/2 and, from Sect. 3.5,
(m1 +m2) RÌa = m1 v1a . Using r1a = x1a i + y1a j and (3.28) then yields
</p>
<p>EB =
1
</p>
<p>2
m v21a , M = r1a &and;m1 v1a = &minus;m1 y1a (v1a &middot; i) k, (3.71)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.13 Complements 65
</p>
<p>Fig. 3.8 Dependence of Ve
on the distance s from the
center of force, as given by
(3.74) in arbitrary units
</p>
<p>0 1 2 3
s   (a.u.)
</p>
<p>-2
</p>
<p>-1
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p>V
e
</p>
<p>(s
) 
</p>
<p>  
 (
</p>
<p>a.
u
.)
</p>
<p>with i, j, k the unit vectors of the x, y, z axes and m the reduced mass. On the other
hand, (3.29) shows that M = (m1 + m2) Ra &and; RÌ + MB whence, writing Ra , RÌ in
terms of r1a , v1a and equating the two expressions of M provides
</p>
<p>MB = &minus;y1a m v1a &middot; i. (3.72)
</p>
<p>Replacing (3.72) and the first of (3.71) in (3.32, 3.33) yields
</p>
<p>Î¼ = ây1a , s0 = Î»+
&radic;
</p>
<p>Î»2 + c2, c = |y1a|. (3.73)
</p>
<p>The distance c between the x axis and the direction of v1a (Fig. 3.7) is called impact
parameter. The outcome of the calculation demonstrates the usefulness of choosing
reference O as described above. In fact, for a given form of the potential energy V ,
the angleÏ defined in Sect. 3.6 becomes a function of two easily-specified quantities:
kinetic energy (E = m1 v21a/2 or EB = m v21a/2) and impact parameter c (compare,
e.g., with (3.36)). Once Ï is determined, the final kinetic energies T1b, T2b and the
angles Ï , Î¸ are recovered from (3.22, 3.23) and (3.25, 3.26), respectively. Another
property of reference O is that Î¸ turns out to be the angle between the x axis and the
final direction of the particle of mass m2.
</p>
<p>3.13.6 The Coulomb Field in the Attractive Case
</p>
<p>To treat the attractive case one lets Îº = &minus;1 in (3.31). The trajectory lies in the x, y
plane; in polar coordinates it is still given by (3.30), with
</p>
<p>Ve(s) =
M2B
</p>
<p>2ms2
&minus; Z1 Z2 q
</p>
<p>2
</p>
<p>4Ï Îµ0 s
, s &gt; 0. (3.74)
</p>
<p>In this case Ve becomes negative for some values of s. As a consequence, EB may
also be negative, provided the condition EB &ge; Ve is fulfilled. Then, it is not possible</p>
<p/>
</div>
<div class="page"><p/>
<p>66 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>to use the definitions (3.32) because EB is positive there. The following will be used
instead,
</p>
<p>Î± = Z1 Z2 q
2
</p>
<p>8Ï Îµ0
&gt; 0, Î² = MB&radic;
</p>
<p>2m
, (3.75)
</p>
<p>so that Ve(s) = (Î²/s)2 &minus; 2 Î±/s. Like in Sect. 3.8 it is assumed that MB differs
from zero and has either sign. It is found by inspection that Ve has only one zero at
s = sc = Î²2/(2 Î±) and only one minimum at s = 2 sc, with min(Ve) = Ve(2 sc) =
&minus;Î±2/Î²2. Also, it is lims&rarr;0 Ve = &infin;, lims&rarr;&infin; Ve = 0 (Fig. 3.8). The motion is
unlimited when EB &ge; 0, while it is limited when min(Ve) &le; EB &lt; 0. The case
EB = min(Ve) yields s = 2 sc = const, namely, the trajectory is a circumference.
When min(Ve) = &minus;Î±2/Î²2 &lt; EB &lt; 0 it is Î±2 &gt; Î²2 |EB |. Then, the difference
EB &minus; Ve = &minus;(|EB | s2 &minus; 2 Î± s + Î²2)/s2 has two real, positive zeros given by
</p>
<p>s0 =
Î± &minus;
</p>
<p>&radic;
</p>
<p>Î±2 &minus; Î²2 |EB |
|EB |
</p>
<p>, s1 =
Î± +
</p>
<p>&radic;
</p>
<p>Î±2 &minus; Î²2 |EB |
|EB |
</p>
<p>, s0 &lt; s1. (3.76)
</p>
<p>Using the zeros one finds s2
&radic;
EB &minus; Ve =
</p>
<p>&radic;|EB | s
&radic;
</p>
<p>(s &minus; s0)(s1 &minus; s), that is re-
placed within (3.30) after letting s &larr; Î¾ . The upper limit of the integral belongs
to the interval s0 &le; s &le; s1. To calculate the integral it is convenient to use a new
variable w such that 2 s0 s1/Î¾ = (s1 &minus; s0) w+ s1 + s0. The range of w corresponding
to the condition s0 &le; Î¾ &le; s is
</p>
<p>2 s0 s1 &minus; (s0 + s1) s
(s1 &minus; s0) s
</p>
<p>&le; w &le; 1, w(s1) = &minus;1. (3.77)
</p>
<p>From (3.30) the trajectory in the s,Ï reference is thus found to be
</p>
<p>Ï(s) = Ï0 &plusmn;
MB
</p>
<p>|MB |
arccos
</p>
<p>[
2 s0 s1 &minus; (s0 + s1) s
</p>
<p>(s1 &minus; s0) s
</p>
<p>]
</p>
<p>. (3.78)
</p>
<p>As noted in Sect. 3.4, the trajectory is symmetric with respect to Ï0. When (3.78) is
inverted, the &plusmn;MB/|MB | factor is irrelevant because the cosine is an even function
of the argument. Thus,
</p>
<p>1
</p>
<p>s
= s1 + s0
</p>
<p>2 s0 s1
</p>
<p>[
</p>
<p>1 + s1 &minus; s0
s1 + s0
</p>
<p>cos (Ï &minus; Ï0)
]
</p>
<p>. (3.79)
</p>
<p>When Ï = Ï0 it is s = s0; when Ï = Ï0 + Ï it is s = s1. The s(Ï) relation (3.79) is
the equation of an ellipse of eccentricity e = (s1 &minus; s0)/(s1 + s0), where the center of
force s = 0 is one of the foci. The distance between the foci is s1&minus;s0. With the aid of
Fig. 3.9 one finds that the semimajor and semiminor axes are obtained, respectively,
from a = (s1 + s0)/2, b2 = a2 &minus; (s1 &minus; s0)2/4 whence, using (3.76),
</p>
<p>a = Î±|EB |
, b = |Î²||EB |
</p>
<p>= |MB |&radic;
2m |EB |
</p>
<p>. (3.80)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.13 Complements 67
</p>
<p>Fig. 3.9 The elliptical
trajectory described by (3.79)
with Ï0 = 0
</p>
<p>s
1
</p>
<p>s
0
</p>
<p>s
1
</p>
<p>s
0
</p>
<p>&minus;
</p>
<p>x
</p>
<p>y
</p>
<p>Ï
</p>
<p>As the particle&rsquo;s trajectory is two-dimensional, the problem has four constants of
motion (Sect. 2.11.2); the total energy EB and the angular momentum MB are two
of such constants. As shown by (3.80), the semimajor axis of the elliptical trajectory
depends only on EB ; the area of the ellipse in terms of the constants of motion is
A = Ï a b = (Ï Î±/
</p>
<p>&radic;
2m) |MB | |EB |&minus;3/2. The position vector s completes a full
</p>
<p>orbit in a period T given by (3.70); combining the latter with the expression of A
yields
</p>
<p>T = Ï Î±
&radic;
</p>
<p>2m
</p>
<p>|EB |3/2
= Ï
</p>
<p>&radic;
</p>
<p>2m
</p>
<p>Î±
a3/2, (3.81)
</p>
<p>namely, the period depends on the total energy, but not on the angular momentum.
Thus, the period is still given by (3.81) in the limiting caseMB &rarr; 0, which makes the
trajectory to shrink into a segment of length a crossing the origin of the s,Ï reference,
and the position vector to oscillate along this segment (compare with problem 3.2).
The second form of (3.81) shows that T 2 &prop; a3 (Kepler&rsquo;s third law).
</p>
<p>3.13.7 Dynamic Relations of Special Relativity
</p>
<p>The dynamic relations considered in this book refer almost invariably to situations
where the particle velocity is small with respect to that of light. For this reason it is
sufficient to use the non-relativistic relations. The only exception where the velocities
of the particles involved do not allow for such an approximation is considered in
Sects. 3.13.8 and 7.4.3. For this reason a set of relations of the Special-Relativity
Theory are given here, that apply to the case of a free particle. The first of them is
the relation between velocity u and momentum p,
</p>
<p>p = m0 u&radic;
1 &minus; u2/c2
</p>
<p>, u = |u|, (3.82)</p>
<p/>
</div>
<div class="page"><p/>
<p>68 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>with c the velocity of light and m0 a constant mass. The second relation involves
energy and velocity and reads
</p>
<p>E = mc2, m = m0&radic;
1 &minus; u2/c2
</p>
<p>, (3.83)
</p>
<p>where E is a kinetic energy because a free particle is considered. In the above,
m = m(u) is called relativistic mass and m0 = m(0) is called rest mass. The latter is
the mass measured in a reference where the particle is at rest, and is the value of the
mass that is used in non-relativistic mechanics. From (3.82, 3.83) it follows
</p>
<p>p = m u, m2 c2 &minus;m2 u2 = m20 c2, m2 c2 = E2/c2, (3.84)
</p>
<p>whence the elimination of u provides the relation between E and the modulus of p:
</p>
<p>E2/c2 &minus; p2 = m20 c2, p =
&radic;
</p>
<p>E2/c2 &minus;m20 c2. (3.85)
</p>
<p>In general the p = p(E) relation is non linear. However, for particles with m0 = 0
the expressions (3.85) simplify to the linear relation p = E/c. An example of this is
found in the theory of the electromagnetic field, where the same momentum-energy
relation is derived from the Maxwell equations (Sect. 5.7). It is worth observing that
if a particle has m0 = 0 and p ï¿½= 0, its velocity is necessarily equal to c; in fact,
the first of (3.84) yields limm0&rarr;0 p = 0 when u &lt; c. Another limiting case is found
when u/c âª 1. In fact, the second of (3.83) simplifies to
</p>
<p>m â m0
1 &minus; u2/(2 c2) â m0
</p>
<p>(
</p>
<p>1 + u
2
</p>
<p>2 c2
</p>
<p>)
</p>
<p>. (3.86)
</p>
<p>Inserting the last form into the first of (3.83) yields
</p>
<p>E â m0 c2 +
1
</p>
<p>2
m0 u
</p>
<p>2. (3.87)
</p>
<p>The constant m0 c2 is called rest energy. The limiting case u/c âª 1 then renders for
E &minus;m0 c2 the non-relativistic expression of the kinetic energy.
</p>
<p>3.13.8 Collision of Relativistic Particles
</p>
<p>This section illustrates the collision between two relativistic particles that consti-
tute an isolated system. The same approach of Sect. 3.5 is used here, namely, the
asymptotic values only are considered. Also, the case where the particles&rsquo; trajecto-
ries belong to the same plane, specifically, the x, y plane, is investigated. The initial
conditions are the same as in Sect. 3.6: the asymptotic motion of the first particle
before the collision is parallel to the x axis, while the second particle is initially at
rest. Finally, it is assumed that the rest mass of the first particle is zero, so that the</p>
<p/>
</div>
<div class="page"><p/>
<p>3.13 Complements 69
</p>
<p>momentum-energy relation of this particle is p = E/c as shown in Sect. 3.13.7,
while the rest mass of the second particle is m0 ï¿½= 0.
</p>
<p>The collision is treated by combining the conservation laws of energy and mo-
mentum of the two-particle system. Let Ea , Eb be the asymptotic energies of the first
particle before and after the collision, respectively. As for the second particle, which
is initially at rest, the energy before the collision is its rest energy m0c2, while that
after the collision is mc2 (Sect. 3.13.7). The conservation of energy then reads
</p>
<p>Ea +m0 c2 = Eb +mc2, (3.88)
</p>
<p>while the conservation of momentum reads, respectively for the x and y components,
</p>
<p>Ea
</p>
<p>c
= Eb
</p>
<p>c
cosÏ +mu cos Î¸ , 0 = Eb
</p>
<p>c
sinÏ &minus;mu sin Î¸. (3.89)
</p>
<p>The angles Ï and Î¸ in (3.89) are the same as in Fig. 3.7. Extracting mc2 from (3.88)
and squaring both sides yields
</p>
<p>(Ea &minus; Eb)2 + 2m0 c2 (Ea &minus; Eb) = m2 c4 &minus;m20 c4 = m2 u2 c2, (3.90)
</p>
<p>where the last equality derives from the second of (3.84). Then, the momentum-
conservation relations (3.89) are used to eliminate Î¸ by squaring and adding up the
results, to find
</p>
<p>m2 u2 c2 = E2a + E2b &minus; 2Ea Eb cosÏ = (Ea &minus; Eb)2 + 4Ea Eb sin2 (Ï/2).
(3.91)
</p>
<p>Eliminating m2 u2 c2 &minus; (Ea &minus; Eb)2 between (3.90) and (3.91) yields
</p>
<p>1
</p>
<p>Eb
&minus; 1
</p>
<p>Ea
= 2
</p>
<p>m0 c2
sin2
</p>
<p>(
Ï
</p>
<p>2
</p>
<p>)
</p>
<p>, (3.92)
</p>
<p>that provides the asymptotic energy after the collision of the first particle, as a function
of the asymptotic energy before the collision, the deflection angle of the same particle,
and the rest energy of the second particle. Equation (3.92) is used in Sect. 7.4.3 for
the explanation of the Compton effect.
</p>
<p>The non-relativistic analogue of the above procedure is illustrated in Sect. 3.6. It is
interesting to note that the calculation carried out here seems rather less involved than
the non-relativistic one. This surprising fact is actually due to the special choice of
the first particle, whose rest energy is zero. In this case, in fact, the relation between
momentum and energy becomes linear. That of the second particle, which is non
linear, is eliminated from the equations. On the contrary, in the non-relativistic case
treated in Sect. 3.6 the energy-momentum relations are non linear for both particles,
this making the calculation more laborious.</p>
<p/>
</div>
<div class="page"><p/>
<p>70 3 Applications of the Concepts of Analytical Mechanics
</p>
<p>3.13.9 Energy Conservation in Charged-Particles&rsquo; Interaction
</p>
<p>The two-particle interaction considered in Sect. 3.8 involves charged particles. As
the particles&rsquo; velocity during the interaction is not constant, the particles radiate
(Sect. 5.11.2) and, consequently, lose energy. This phenomenon is not considered in
the analysis carried out in Sect. 3.8, where the total energy of the two-particle system
is assumed constant. The assumption is justified on the basis that the radiated power
is relatively small. This subject is further discussed in Sect. 5.11.3.
</p>
<p>Problems
</p>
<p>3.1 Given the Hamiltonian function of the one-dimensional harmonic oscillator of
the general form H = p2/(2m) + (c/s) |x|s , m, c, s &gt; 0, find the oscillator&rsquo;s
period.
</p>
<p>3.2 Given the Hamiltonian function of the one-dimensional harmonic oscillator of
the general form H = p2/(2m) &minus; (k/s) |x|&minus;s = E &lt; 0, m, k, s &gt; 0, find the
oscillator&rsquo;s period.
</p>
<p>3.3 Consider the collision between two particles in the repulsive Coulomb case.
Calculate the relation T1b(T1a , c), with c the impact parameter (hint: follow the
discussion of Sect. 3.13.5 and use (3.23, 3.36), (3.32, 3.33), and (3.73)).</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 4
</p>
<p>Electromagnetism
</p>
<p>4.1 Introduction
</p>
<p>This chapter outlines the basic principles of the electromagnetic theory in vacuo.
First, the extension of the Lagrangian formalism to functions that depend on more
than one variable is tackled: this yields useful tools for the analysis of continuous
media. Next, the Maxwell equations are introduced along with the derivation of
the electric and magnetic potentials, and the concept of gauge transformation is
illustrated. The second part of the chapter is devoted to the Helmholtz and wave
equations, both in a finite and infinite domain. The chapter finally introduces the
Lorentz force, that connects the electromagnetic field with the particles&rsquo; dynamics.
The complements discuss some invariance properties of the Euler equations, derive
the wave equations for the electric and magnetic field, and clarify some issues related
to the boundary conditions in the application of the Green method to the boundary-
value problem.
</p>
<p>4.2 Extension of the Lagrangian Formalism
</p>
<p>In Sect. 1.2 the derivation of the extremum functions has been carried out with
reference to a functional G[w] of the form (1.1). Such a functional contains one
unknown function w that, in turn, depends on one independent variable Î¾ . The result
has been extended to the case where the functional depends on several unknown
functions w1, w2, . . . , each dependent on one variable only (compare with (1.6)).
The extension to more than one independent variable is shown here.
</p>
<p>To proceed it suffices to consider a single unknown function w that depends on
two independent variables Î¾ , Ï and is differentiable at least twice with respect to
each. The first and second derivatives of w are indicated with wÎ¾ , wÏ , wÎ¾Î¾ , wÏÏ , and
wÎ¾Ï . Letting ï¿½ be the domain over which w is defined, and g the generating function,
the functional reads
</p>
<p>G[w] =
&int;
</p>
<p>ï¿½
</p>
<p>g(w, wÎ¾ , wÏ , Î¾ , Ï ) dï¿½. (4.1)
</p>
<p>&copy; Springer Science+Business Media New York 2015 71
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_4</p>
<p/>
</div>
<div class="page"><p/>
<p>72 4 Electromagnetism
</p>
<p>Then, let Î´w = Î± Î·, with Î·(Î¾ , Ï ) an arbitrary function defined in ï¿½ and differentiable
in its interior, and Î± a real parameter. Like in the case of one independent variable
the choice is restricted to those functions Î· that vanish at the boundary of ï¿½, so that
w and w + Î´w coincide along the boundary for any value of Î±. If w is an extremum
function of G, the extremum condition if found by replacing w with w + Î± Î· and
letting (dG/dÎ±)0 = 0, where suffix 0 indicates that the derivative is calculated at
Î± = 0 (compare with Sect. 1.2). Exchanging the integral with the derivative in (4.1)
yields
</p>
<p>(
dG
</p>
<p>dÎ±
</p>
<p>)
</p>
<p>0
</p>
<p>=
&int;
</p>
<p>ï¿½
</p>
<p>(
&part;g
</p>
<p>&part;w
Î· + &part;g
</p>
<p>&part;wÎ¾
Î·Î¾ +
</p>
<p>&part;g
</p>
<p>&part;wÏ
Î·Ï
</p>
<p>)
</p>
<p>dï¿½ = 0. (4.2)
</p>
<p>The second and third term of the integrand in (4.2) are recast in compact form by
defining vector u = (&part;g/&part;wÎ¾ , &part;g/&part;wÏ ) and using the second identity in (A.16), so
that the sum of the two terms reads u &middot; gradÎ· = div(Î·u) &minus; Î· divu. Integrating over
ï¿½ and using the divergence theorem (A.23) yields
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>u &middot; gradÎ· dï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>Î· u &middot; n dï¿½ &minus;
&int;
</p>
<p>ï¿½
</p>
<p>Î· divu dï¿½, (4.3)
</p>
<p>where ï¿½ is the boundary of ï¿½ and n the unit vector normal to dï¿½, oriented in the
outward direction with respect to ï¿½. The first term at the right hand side of (4.3) is
equal to zero because Î· vanishes over ï¿½.
</p>
<p>It is important to clarify the symbols that will be used to denote the derivatives.
In fact, to calculate divu one needs, first, to differentiate &part;g/&part;wÎ¾ with respect to Î¾
considering also the implicit Î¾ -dependence within w, wÎ¾ , and wÏ ; then, one differen-
tiates in a similar manner &part;g/&part;wÏ with respect to Ï . The two derivatives are summed
up to form divu. For this type of differentiation the symbols d/dÎ¾ and d/dÏ are used,
even if the functions in hand depend on two independent variables instead of one.
The symbols &part;/&part;Î¾ and &part;/&part;Ï are instead reserved to the derivatives with respect to
the explicit dependence on Î¾ or Ï only. With this provision, inserting (4.3) into (4.2)
yields the extremum condition
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>(
&part;g
</p>
<p>&part;w
&minus; d
</p>
<p>dÎ¾
</p>
<p>&part;g
</p>
<p>&part;wÎ¾
&minus; d
</p>
<p>dÏ
</p>
<p>&part;g
</p>
<p>&part;wÏ
</p>
<p>)
</p>
<p>Î· dï¿½ = 0. (4.4)
</p>
<p>As (4.4) holds for any Î·, the term in parentheses must vanish. In conclusion, the
extremum condition is
</p>
<p>d
</p>
<p>dÎ¾
</p>
<p>&part;g
</p>
<p>&part;wÎ¾
+ d
</p>
<p>dÏ
</p>
<p>&part;g
</p>
<p>&part;wÏ
= &part;g
</p>
<p>&part;w
, (4.5)
</p>
<p>namely, a second-order partial-differential equation in the unknown function w, that
must be supplemented with suitable boundary conditions. The equation is linear with
respect to the second derivatives of w because g does not depend on such derivatives.
</p>
<p>The result is readily extended to the case where g depends on several functions
w1, w2, . . . , wl and the corresponding derivatives. Defining the vectors w(Î¾ , Ï ) =</p>
<p/>
</div>
<div class="page"><p/>
<p>4.2 Extension of the Lagrangian Formalism 73
</p>
<p>(w1, . . . , wl), wÎ¾ = (&part;w1/&part;Î¾ , . . . , &part;wl/&part;Î¾ ), wÏ = (&part;w1/&part;Ï , . . . , &part;wl/&part;Ï ), the set
of the l extremum functions wi of functional
</p>
<p>G[w] =
&int;
</p>
<p>ï¿½
</p>
<p>g(w, wÎ¾ , wÏ , Î¾ , Ï ) dï¿½ (4.6)
</p>
<p>is found by solving the equations
</p>
<p>d
</p>
<p>dÎ¾
</p>
<p>&part;g
</p>
<p>&part;(&part;wi/&part;Î¾ )
+ d
</p>
<p>dÏ
</p>
<p>&part;g
</p>
<p>&part;(&part;wi/&part;Ï )
= &part;g
</p>
<p>&part;wi
, i = 1, . . . , l, (4.7)
</p>
<p>supplemented with the suitable boundary conditions. It follows that (4.7) are the
Euler equations of G. Finally, the case where the independent variables are more
than two is a direct extension of (4.7). For instance, for m variables Î¾1, . . . , Î¾m one
finds
</p>
<p>m
&sum;
</p>
<p>j=1
</p>
<p>d
</p>
<p>dÎ¾j
</p>
<p>&part;g
</p>
<p>&part;(&part;wi/&part;Î¾j )
= &part;g
</p>
<p>&part;wi
, i = 1, . . . , l. (4.8)
</p>
<p>If g is replaced with g&prime; = g+divh, where h is an arbitrary vector of length m whose
entries depend on w and Î¾1, . . . , Î¾m, but not on the derivatives of w, then (4.8) is still
fulfilled. The replacement, in fact, adds the same term to both sides. For instance,
the term added to the left hand side is
</p>
<p>m
&sum;
</p>
<p>j=1
</p>
<p>d
</p>
<p>dÎ¾j
</p>
<p>&part;
</p>
<p>&part;(&part;wi/&part;Î¾j )
</p>
<p>m
&sum;
</p>
<p>r=1
</p>
<p>(
</p>
<p>&part;hr
</p>
<p>&part;Î¾r
+
</p>
<p>l
&sum;
</p>
<p>s=1
</p>
<p>&part;hr
</p>
<p>&part;ws
</p>
<p>&part;ws
</p>
<p>&part;Î¾r
</p>
<p>)
</p>
<p>, i = 1, . . . , l, (4.9)
</p>
<p>where the sum over r is the explicit expression of divh. Remembering that h does
not depend on the derivatives of wi one recasts (4.9) as
</p>
<p>m
&sum;
</p>
<p>j=1
</p>
<p>d
</p>
<p>dÎ¾j
</p>
<p>m
&sum;
</p>
<p>r=1
</p>
<p>l
&sum;
</p>
<p>s=1
</p>
<p>&part;hr
</p>
<p>&part;ws
</p>
<p>&part;(&part;ws/&part;Î¾r )
</p>
<p>&part;(&part;wi/&part;Î¾j )
=
</p>
<p>m
&sum;
</p>
<p>j=1
</p>
<p>&part;
</p>
<p>&part;Î¾j
</p>
<p>&part;hj
</p>
<p>&part;wi
, i = 1, . . . , l, (4.10)
</p>
<p>where the equality is due to the relation &part;(&part;ws/&part;Î¾r )/&part;(&part;wi/&part;Î¾j ) = Î´isÎ´jr , with Î´is(jr)
the Kronecker symbol (A.18). Inverting the order of the derivatives at the right hand
side of (4.10) yields &part; divh/&part;wi , that coincides with the term added to the right hand
side of (4.8). Finally, (4.8) is recast in compact form by defining a vector ui and a
scalar si as
</p>
<p>ui =
[
</p>
<p>&part;g
</p>
<p>&part;(&part;wi/&part;Î¾1)
, . . . ,
</p>
<p>&part;g
</p>
<p>&part;(&part;wi/&part;Î¾m)
</p>
<p>]
</p>
<p>, si =
&part;g
</p>
<p>&part;wi
(4.11)
</p>
<p>to find
</p>
<p>divÎ¾ui = si , i = 1, . . . , l. (4.12)
If wi depends on one variable only, say Î¾ , (4.8, 4.12) reduce to (1.7). Using the
language of the Lagrangian theory, the comparison between the one-dimensional
and multi-dimensional case shows that in both cases the functions wi play the role
of generalized coordinates; in turn, the scalar parameter Î¾ of (1.7) becomes the
vector (Î¾1, . . . , Î¾m) of (4.8) and, finally, each generalized velocity wÌi becomes the
set &part;wi/&part;Î¾1, . . . , &part;wi/&part;Î¾m.</p>
<p/>
</div>
<div class="page"><p/>
<p>74 4 Electromagnetism
</p>
<p>4.3 Lagrangian Function for the Wave Equation
</p>
<p>It has been shown in Sect. 1.3 that the relations wÌi = wÌi(w, wÌ, Î¾ ), i = 1, . . . , n,
describing the motion of a system of particles with n degrees of freedom, are the
Euler equations of a suitable functional. Then, the analysis of Sect. 4.2 has shown
that, when the unknown functions w1, . . . , wl depend on more than one variable, the
Euler equations are the second-order partial-differential equations (4.8). The form
(4.8) is typical of the problems involving continuous media (e.g., elasticity field,
electromagnetic field). Following the same reasoning as in Sect. 1.3 it is possible to
construct the Lagrangian function whence the partial-differential equation derives.
This is done here with reference to the important case of the wave equation1
</p>
<p>&nabla;2w &minus; 1
u2
</p>
<p>&part;2w
</p>
<p>&part;t2
= s, (4.13)
</p>
<p>where u = const is a velocity and, for the sake of simplicity, s is assumed to
depend on x and t , but not on w or its derivatives. It is worth noting that, when
a differential equation other than Newton&rsquo;s law is considered, the corresponding
Lagrangian function is not necessarily an energy. For this reason it will provisionally
be indicated with Le instead of L. To proceed one considers the one-dimensional
form of (4.13), &part;2w/&part;x2 &minus; (1/u2) &part;2w/&part;t2 = s and replaces Î¾ , Ï , g with x, t , Le,
respectively. Then, one makes the one-dimensional form identical to (4.5) by letting
</p>
<p>&part;2Le
</p>
<p>&part;w2x
= 1, &part;
</p>
<p>2Le
</p>
<p>&part;w2t
= &minus; 1
</p>
<p>u2
,
</p>
<p>&part;Le
</p>
<p>&part;w
= s, (4.14)
</p>
<p>with wx = &part;w/&part;x and wt = &part;w/&part;t . The second derivatives ofLe(w, wx , wt , x, t) with
respect to the combinations of the arguments not appearing in the first two equations
of (4.14) are set to zero. The third of (4.14) providesLe = s w+c, with c independent
of w. Replacing Le = sw + c into the first two equations in (4.14), and integrating
the first one with respect to wx , yields &part;c/&part;wx = wx + a01, with a01 independent of
wx . Similarly, from the second equation in (4.14), &part;c/&part;wt = &minus;wt/u2 +a02, with a02
independent of wt . Also, remembering that c is independent of w, one finds that a01
and a02 do not depend on w either. Considering that all the second derivatives of Le
not appearing in (4.14) are equal to zero shows that a01 depends on t at most, while a02
depends on x at most. Integrating &part;c/&part;wx = wx + a01 and &part;c/&part;wt = &minus;wt/u2 + a02
one finds
</p>
<p>c = 1
2
</p>
<p>w2x + a01(t) wx + a11, c = &minus;
1
</p>
<p>2u2
w2t + a02(x) wt + a12, (4.15)
</p>
<p>where a11 does not depend on w or wx , while a12 does not depend on w or wt . Also,
a11 can not depend on both t and wt due to &part;2Le/(&part;t &part;wt ) = 0; similarly, a12 can
not depend on both x and wx due to &part;2Le/(&part;x &part;wx) = 0. On the other hand, as both
</p>
<p>1 Also called D&rsquo;Alembert equation in the homogeneous case.</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4 Maxwell Equations 75
</p>
<p>(4.15) hold, a11 must coincide (apart from an additive constant) with the first two
terms at the right hand side of the second equation in (4.15), and a12 must coincide
with the first two terms at the right hand side of the first equation. In conclusion,
</p>
<p>c = 1
2
</p>
<p>w2x &minus;
1
</p>
<p>2u2
w2t + a01(t) wx + a02(x) wt , (4.16)
</p>
<p>with a01(t), a02(x) arbitrary functions. The last two terms in (4.16) are equal to
d(a01 w)/dx + d(a02 w)/dt , namely, they form the divergence of a vector. As shown
in Sect. 4.2 such a vector is arbitrary, so it can be eliminated by letting a01 = 0,
a02 = 0. The relation Le = sw + c then yields
</p>
<p>Le =
1
</p>
<p>2
w2x &minus;
</p>
<p>1
</p>
<p>2u2
w2t + sw. (4.17)
</p>
<p>The generalization to the three-dimensional case (4.13) is immediate,
</p>
<p>Le =
1
</p>
<p>2
|gradw|2 &minus; 1
</p>
<p>2u2
</p>
<p>(
&part;w
</p>
<p>&part;t
</p>
<p>)2
</p>
<p>+ sw. (4.18)
</p>
<p>with |gradw|2 = w2x + w2y + w2z .
</p>
<p>4.4 Maxwell Equations
</p>
<p>The Maxwell equations, that describe the electromagnetic field, lend themselves to
an interesting application of the results of Sect. 4.3. The first group of Maxwell
equations reads
</p>
<p>divD = Ï, rotH &minus; &part;D
&part;t
</p>
<p>= J, (4.19)
</p>
<p>where D is the electric displacement and H the magnetic field.2 The sources of
the electromagnetic field are the charge density Ï and the current density J. When
point-like charges are considered, they read
</p>
<p>Ïc =
&sum;
</p>
<p>j
</p>
<p>ej Î´
(
</p>
<p>r &minus; sj (t)
)
</p>
<p>, Jc =
&sum;
</p>
<p>j
</p>
<p>ej Î´
(
</p>
<p>r &minus; sj (t)
)
</p>
<p>uj (t), (4.20)
</p>
<p>where index c is used to distinguish the case of point-like charges from that of a
continuous charge distribution. In (4.20), ej is the value of the j th charge, sj and
</p>
<p>2 The units in (4.19, 4.23, 4.24) are: [D] = C m&minus;2, [Ï] = C m&minus;3, [H] = A m&minus;1, [J] =
C s&minus;1 m&minus;2 = A m&minus;2, [B] = V s m&minus;2 = Wb m&minus;2 = T, [E] = V m&minus;1, where &ldquo;C&rdquo;, &ldquo;A&rdquo;, &ldquo;V&rdquo;, &ldquo;Wb&rdquo;,
and &ldquo;T&rdquo; stand for Coulomb, Ampere, Volt, Weber, and Tesla, respectively. The coefficients in (4.19,
4.23, 4.24) differ from those of [4] because of the different units adopted there. In turn, the units
in (4.25) are [Îµ0] = C V&minus;1 m&minus;1 = F m&minus;1, [Î¼0] = s2 F&minus;1 m&minus;1 = H m&minus;1, where &ldquo;F&rdquo; and &ldquo;H&rdquo; stand
for Farad and Henry, respectively, and those in (4.26) are [Ï] = V, [A] = V s m&minus;1 = Wb m&minus;1.</p>
<p/>
</div>
<div class="page"><p/>
<p>76 4 Electromagnetism
</p>
<p>uj its position and velocity at time t , respectively, and r the independent positional
variable. If the spatial scale of the problem is such that one can replace the point-
like charges with a continuous distribution, one applies the same procedure as in
Sect. 23.2. The number of charges belonging to a cell of volume ï¿½V centered at r is
&int;
</p>
<p>ï¿½V
Ïc d3s &prime; =
</p>
<p>&sum;&prime;
j ej , where the prime indicates that the sum is limited to the charges
</p>
<p>that belong to ï¿½ at time t . Then one defines Ï(r, t) = &sum;&prime;j ej/ï¿½V . The continuous
distribution of the current density is obtained in a similar manner,
</p>
<p>J = 1
ï¿½V
</p>
<p>&int;
</p>
<p>ï¿½V
</p>
<p>Jc d
3s &prime; = 1
</p>
<p>ï¿½V
</p>
<p>&sum;
</p>
<p>j
</p>
<p>&prime;
ej uj = Ï v, v =
</p>
<p>&sum;&prime;
j ej uj
&sum;&prime;
</p>
<p>j ej
, (4.21)
</p>
<p>with v(r, t) the average velocity of the charges. If all charges are equal, e1 = e2 =
. . . = e, then Ï = e N , with N (r, t) the concentration, and J = e Nv = e F, with
F(r, t) the flux density (compare with the definitions of Sect. 23.2). If the charges are
different from each other it is convenient to distribute the sum
</p>
<p>&sum;
</p>
<p>j over the groups
made of equal charges. In this case the charge density and current density read
</p>
<p>Ï = Ï1 + Ï2 + . . . , J = Ï1 v1 + Ï2 v2 + . . . , (4.22)
</p>
<p>where Ï1, v1 are the charge density and average velocity of the charges of the first
group, and so on. Taking the divergence of the second equation in (4.19) and using
the third identity in (A.35) yields the continuity equation
</p>
<p>&part;Ï
</p>
<p>&part;t
+ divJ = 0. (4.23)
</p>
<p>Apart from the different units of the functions involved, the form of (4.23) is the
same as that of (23.3). The meaning of (4.23) is that of conservation of the electric
charge. The second group of Maxwell equations is
</p>
<p>divB = 0, rotE + &part;B
&part;t
</p>
<p>= 0, (4.24)
</p>
<p>where B and E are the magnetic induction and the electric field, respectively. Here
the Maxwell equations are considered in vacuo, so that the following hold
</p>
<p>D = Îµ0 E, B = Î¼0 H,
1&radic;
Îµ0 Î¼0
</p>
<p>= c, (4.25)
</p>
<p>with Îµ0 â 8.854&times; 10&minus;12 F m&minus;1 and Î¼0 â 1.256&times; 10&minus;6 H m&minus;1 the vacuum permit-
tivity and permeability, respectively, and c â 2.998 &times; 108 m s&minus;1 the speed of light
in vacuo.</p>
<p/>
</div>
<div class="page"><p/>
<p>4.5 Potentials and Gauge Transformations 77
</p>
<p>4.5 Potentials and Gauge Transformations
</p>
<p>Thanks to (4.25), the electromagnetic field in vacuo is determined by two suitably-
chosen vectors&mdash;typically, E and B&mdash;out of the four ones appearing in (4.25). This
amounts to using six scalar functions of position and time. However, the number of
scalar functions is reduced by observing that, while (4.19) provide relations between
the electromagnetic field and its sources, (4.24) provide relations among the field
vectors themselves; as a consequence, (4.24) reduce the number of independent
vectors. In fact, using the properties illustrated in Sect. A.9, one finds that from
divB = 0 one derives B = rotA, where A is called vector potential or magnetic
potential. In turn, the vector potential transforms the second of (4.24) into rot(E +
&part;A/&part;t) = 0; using again the results of Sect. A.9 shows that the term in parentheses
is the gradient of a scalar function, that is customarily indicated with &minus;Ï. Such a
function3 is called scalar potential or electric potential. In summary,
</p>
<p>B = rotA, E = &minus;gradÏ &minus; &part;A
&part;t
</p>
<p>, (4.26)
</p>
<p>showing that for determining the electromagnetic field in vacuo it suffices to know
four scalar functions, namely, Ï and the three components of A. To proceed, one
replaces (4.26) into (4.19) and uses the third relation in (4.25), to find
</p>
<p>&nabla;2Ï + &part;
&part;t
</p>
<p>divA = &minus; Ï
Îµ0
</p>
<p>, &minus;rot rotA &minus; 1
c2
</p>
<p>&part;2A
</p>
<p>&part;t2
= &minus;Î¼0 J +
</p>
<p>1
</p>
<p>c2
grad
</p>
<p>&part;Ï
</p>
<p>&part;t
.
</p>
<p>(4.27)
</p>
<p>Thanks to the first identity in (A.36) the second equation in (4.27) becomes
</p>
<p>&nabla;2A &minus; 1
c2
</p>
<p>&part;2A
</p>
<p>&part;t2
= &minus;Î¼0 J + gradÎ¸ , Î¸ = divA +
</p>
<p>1
</p>
<p>c2
</p>
<p>&part;Ï
</p>
<p>&part;t
(4.28)
</p>
<p>while, using the definition (4.28) of Î¸ , one transforms the first equation in (4.27) into
</p>
<p>&nabla;2Ï &minus; 1
c2
</p>
<p>&part;2Ï
</p>
<p>&part;t2
= &minus; Ï
</p>
<p>Îµ0
&minus; &part;Î¸
</p>
<p>&part;t
. (4.29)
</p>
<p>In conclusion, (4.29) and the first equation in (4.28) are a set of four scalar differential
equations whose unknowns are Ï and the components of A. Such equations are
coupled because Î¸ contains all unknowns; however, they become decoupled after
suitable transformations, shown below.
</p>
<p>To proceed, one observes that only the derivatives of the potentials, not the po-
tential themselves, appear in (4.26); as a consequence, while the fields E, B are
uniquely defined by the potentials, the opposite is not true. For instance, replacing A
</p>
<p>3 The minus sign in the definition of Ï is used for consistency with the definition of the gravitational
potential, where the force is opposite to the direction along which the potential grows.</p>
<p/>
</div>
<div class="page"><p/>
<p>78 4 Electromagnetism
</p>
<p>with A&prime; = A + gradf , where f (r, t) is any differentiable scalar function, and using
the second identity in (A.35), yields B&prime; = rotA&prime; = B, namely, B is invariant with
respect to such a replacement. If, at the same time, one replaces Ï with a yet undeter-
mined function Ï&prime;, (4.26) yields E&prime; = &minus;grad(Ï&prime;+&part;f/&part;t)&minus;&part;A/&part;t . It follows that by
choosing Ï&prime; = Ï&minus; &part;f/&part;t one obtains E&prime; = E. The transformation (Ï, A) &rarr; (Ï&prime;, A&prime;)
defined by
</p>
<p>Ï&prime; = Ï &minus; &part;f
&part;t
</p>
<p>, A&prime; = A + gradf. (4.30)
</p>
<p>is called gauge transformation. As shown above, E and B are invariant with respect
to such a transformation. One also finds that (4.29) and the first equation in (4.28)
are invariant with respect to the transformation: all terms involving f cancel each
other, so that the equations in the primed unknowns are identical to the original ones.
However, the solutions Ï&prime;, A&prime; are different from Ï, A because, due to (4.30), their
initial and boundary conditions are not necessarily the same. The difference between
the primed and unprimed solutions is unimportant because the fields, as shown above,
are invariant under the transformation. Using (4.30) in the second equation of (4.28)
shows that Î¸ transforms as
</p>
<p>Î¸ &prime; = divA&prime; + 1
c2
</p>
<p>&part;Ï&prime;
</p>
<p>&part;t
= Î¸ + &nabla;2f &minus; 1
</p>
<p>c2
</p>
<p>&part;2f
</p>
<p>&part;t2
. (4.31)
</p>
<p>The arbitrariness of f may be exploited to give Î¸ &prime; a convenient form. For instance
one may choose f such that Î¸ &prime; = (1/c2) &part;Ï/&part;t , which is equivalent to letting
</p>
<p>divA&prime; = 0, (4.32)
</p>
<p>called Coulomb gauge. The latter yields
</p>
<p>&nabla;2Ï&prime; = &minus; Ï
Îµ0
</p>
<p>, &nabla;2A&prime; &minus; 1
c2
</p>
<p>&part;2A&prime;
</p>
<p>&part;t2
= &minus;Î¼0 J +
</p>
<p>1
</p>
<p>c2
</p>
<p>&part;
</p>
<p>&part;t
gradÏ&prime;, (4.33)
</p>
<p>the first of which (the Poisson equation) is decoupled from the second one. After
solving the Poisson equation, the last term at the right hand side of the second
equation is not an unknown any more, this showing that the equations resulting from
the Coulomb gauge are indeed decoupled. Another possibility is choosing f such
that Î¸ &prime; = 0, which is equivalent to letting
</p>
<p>divA&prime; = &minus; 1
c2
</p>
<p>&part;Ï&prime;
</p>
<p>&part;t
, (4.34)
</p>
<p>called Lorentz gauge. This transformation yields
</p>
<p>&nabla;2Ï&prime; &minus; 1
c2
</p>
<p>&part;2Ï&prime;
</p>
<p>&part;t2
= &minus; Ï
</p>
<p>Îµ0
, &nabla;2A&prime; &minus; 1
</p>
<p>c2
</p>
<p>&part;2A&prime;
</p>
<p>&part;t2
= &minus;Î¼0 J. (4.35)
</p>
<p>that are decoupled and have the form of the wave Eq. (4.13). Another interesting
application of the gauge transformation is shown in Sect. 5.11.4.</p>
<p/>
</div>
<div class="page"><p/>
<p>4.6 Lagrangian Density for the Maxwell Equations 79
</p>
<p>4.6 Lagrangian Density for the Maxwell Equations
</p>
<p>To apply the Lagrangian formalism to the Maxwell equations it is useful to use the
expressions (4.26) of the fields in terms of the potentials. It follows that the functions
playing the role of generalized coordinates and generalized velocities are Ï, Ai , and,
respectively, &part;Ï/&part;xk , &part;Ai/&part;xk , &part;Ai/&part;t , with i, k = 1, 2, 3, k ï¿½= i. The Lagrangian
density, whose units are J m&minus;3, then reads
</p>
<p>Le =
Îµ0
</p>
<p>2
E2 &minus; 1
</p>
<p>2Î¼0
B2 &minus; Ï Ï + J &middot; A, (4.36)
</p>
<p>with
</p>
<p>E2 =
(
&part;Ï
</p>
<p>&part;x1
+ &part;A1
</p>
<p>&part;t
</p>
<p>)2
</p>
<p>+
(
&part;Ï
</p>
<p>&part;x2
+ &part;A2
</p>
<p>&part;t
</p>
<p>)2
</p>
<p>+
(
&part;Ï
</p>
<p>&part;x3
+ &part;A3
</p>
<p>&part;t
</p>
<p>)2
</p>
<p>(4.37)
</p>
<p>and
</p>
<p>B2 =
(
&part;A3
</p>
<p>&part;x2
&minus; &part;A2
</p>
<p>&part;x3
</p>
<p>)2
</p>
<p>+
(
&part;A1
</p>
<p>&part;x3
&minus; &part;A3
</p>
<p>&part;x1
</p>
<p>)2
</p>
<p>+
(
&part;A2
</p>
<p>&part;x1
&minus; &part;A1
</p>
<p>&part;x2
</p>
<p>)2
</p>
<p>, (4.38)
</p>
<p>To show that (4.36) is in fact the Lagrangian function of the Maxwell equations one
starts with the generalized coordinate Ï, to find &part;Le/&part;Ï = &minus;Ï. Then, considering
the kth component,
</p>
<p>&part;Le/Îµ0
</p>
<p>&part;(&part;Ï/&part;xk)
= &part;E
</p>
<p>2/2
</p>
<p>&part;(&part;Ï/&part;xk)
= &part;E
</p>
<p>2/2
</p>
<p>&part;(&part;Ak/&part;t)
= &part;Ï
</p>
<p>&part;xk
+ &part;Ak
</p>
<p>&part;t
= &minus;Ek = &minus;
</p>
<p>Dk
</p>
<p>Îµ0
. (4.39)
</p>
<p>Using (4.8) after replacing g with Le, Î¾j with xj , and wi with Ï yields divD = Ï,
namely, the first equation in (4.19). Turning now to another generalized coordinate,
say, A1, one finds &part;Le/&part;A1 = J1. As Le depends on the spatial derivatives of A1
only through B2, (4.38) and the first of (4.26) yield
</p>
<p>&part;B2/2
</p>
<p>&part;(&part;A1/&part;x3)
= &part;A1
</p>
<p>&part;x3
&minus; &part;A3
</p>
<p>&part;x1
= B2,
</p>
<p>&part;B2/2
</p>
<p>&part;(&part;A1/&part;x2)
= &part;A1
</p>
<p>&part;x2
&minus; &part;A2
</p>
<p>&part;x1
= &minus;B3.
</p>
<p>(4.40)
</p>
<p>In contrast, Le depends on the time derivative of A1 only through E2, as shown by
(4.39). To use (4.8) one replaces g with Le and wi with A1, then takes the derivative
with respect to x3 in the first relation in (4.40), the derivative with respect to x2 in
the second relation, and the derivative with respect to t of the last term in (4.39). In
summary this yields
</p>
<p>1
</p>
<p>Î¼0
</p>
<p>(
&part;B3
</p>
<p>&part;x2
&minus; &part;B2
</p>
<p>&part;x3
</p>
<p>)
</p>
<p>&minus; &part;D1
&part;t
</p>
<p>= J1, (4.41)
</p>
<p>namely, the first component of the second equation in (4.19).</p>
<p/>
</div>
<div class="page"><p/>
<p>80 4 Electromagnetism
</p>
<p>Fig. 4.1 The domain V used
for the solution of the
Helmholtz equation (4.43).
The three possible positions
of point r are shown: external
to V , internal to V , or on the
boundary S
</p>
<p>r
</p>
<p>q
</p>
<p>n
</p>
<p>Îµ
</p>
<p>V
</p>
<p>S
</p>
<p>r
</p>
<p>n
</p>
<p>r
</p>
<p>4.7 Helmholtz Equation
</p>
<p>Consider the wave equations (4.35) and assume that the charge density Ï and current
density J are given as functions of position and time. In the following, the apex
in Ï and A will be dropped for the sake of conciseness. The four scalar equations
(4.35) are linear with respect to the unknowns and have the same structure; also,
their coefficients and unknowns are all real. The solution of (4.35) will be tackled
in this section and in the following ones, basing upon the Fourier transform whose
general properties are depicted in Sect. C.2. This solution procedure involves the use
of complex functions. The starting assumption is that the condition for the existence
of the Fourier transform with respect to time holds (such a condition is found by
replacing x with t in (C.19)). Then one obtains
</p>
<p>&nabla;2FtÏ +
Ï2
</p>
<p>c2
FtÏ = &minus;
</p>
<p>1
</p>
<p>Îµ0
FtÏ, &nabla;2FtA +
</p>
<p>Ï2
</p>
<p>c2
FtA = &minus;Î¼0 FtJ. (4.42)
</p>
<p>Indicating with f the transform of Ï or Ai , and with b the transform of &minus;Ï/Îµ0 or
&minus;Î¼0 Ji , i = 1, 2, 3, and letting k2 = Ï2/c2, each scalar equation in (4.42) has the
form of the Helmholtz equation
</p>
<p>&nabla;2f + k2 f = b. (4.43)
The solution of (4.43) is sought within a finite domain V (Fig. 4.1), for a given
set of boundary conditions defined over the boundary S of V , and for a given right
hand side b defined within V and over S. Let r = (x, y, z) be a point external to V ,
q = (Î¾ , Î·, Î¶ ) a point internal to V , and
</p>
<p>g = r &minus; q, g =
[
</p>
<p>(x &minus; Î¾ )2 + (y &minus; Î·)2 + (z &minus; Î¶ )2
]1/2
</p>
<p>(4.44)
</p>
<p>where, by construction, it is g &gt; 0. In the following calculation, r is kept fixed while
q varies. As a consequence, the derivatives of g are calculated with respect to Î¾ , Î·,
and Î¶ . It is easily shown that in a three-dimensional space the auxiliary function
</p>
<p>G(g) = 1
g
</p>
<p>exp (&minus;i k g), k real, (4.45)</p>
<p/>
</div>
<div class="page"><p/>
<p>4.8 Helmholtz Equation in a Finite Domain 81
</p>
<p>fulfills the homogeneous Helmholtz equation &nabla;2G+k2 G = 0. Using the procedure
that leads to the second Green theorem (Sect. A.5, Eq. (A.25)) yields the integral
relation
</p>
<p>&int;
</p>
<p>S
</p>
<p>(
</p>
<p>G
&part;f
</p>
<p>&part;n
&minus; f &part;G
</p>
<p>&part;n
</p>
<p>)
</p>
<p>dS =
&int;
</p>
<p>V
</p>
<p>Gb dV , (4.46)
</p>
<p>where the unit vector n over S is oriented in the outward direction and, by
construction, point r is external to V .
</p>
<p>4.8 Helmholtz Equation in a Finite Domain
</p>
<p>The relation (4.46) would not be applicable if r were internal toV , becauseGdiverges
for g &rarr; 0 and, as a consequence, is not differentiable in q = r. On the other hand,
in many applications r happens to be internal to V . In such cases one must exclude
from the integral a suitable portion of volume V ; this is achieved by considering a
spherical domain of radius Îµ centered on r and internal to V (Fig. 4.1). Letting VÎµ, SÎµ
be, respectively, the volume and surface of such a sphere, and considering the new
volume V &prime; = V &minus; VÎµ, having S &prime; = S &cup; SÎµ as boundary, makes (4.46) applicable to
V &prime;, to yield
</p>
<p>&int;
</p>
<p>S
</p>
<p>(
</p>
<p>G
&part;f
</p>
<p>&part;n
&minus; f &part;G
</p>
<p>&part;n
</p>
<p>)
</p>
<p>dS +
&int;
</p>
<p>SÎµ
</p>
<p>(. . . ) dSÎµ =
&int;
</p>
<p>V
</p>
<p>Gb dV &minus;
&int;
</p>
<p>VÎµ
</p>
<p>Gb dVÎµ, (4.47)
</p>
<p>where the dots indicate that the integrand is the same as in the first integral at the left
hand side. Over SÎµ it is G = (1/Îµ) exp (&minus; ik Îµ), with the unit vector n pointing from
the surface towards the center of the sphere, namely, opposite to the direction along
which Îµ increases. It follows &part;G/&part;n = &minus;&part;G/&part;Îµ = (ik + 1/Îµ)G. Letting [f ] and
[&part;f/&part;n] be the average values of f and, respectively, &part;f/&part;n over SÎµ, and observing
that G and &part;G/&part;Îµ are constant there, yields
</p>
<p>&int;
</p>
<p>SÎµ
</p>
<p>(
</p>
<p>G
&part;f
</p>
<p>&part;n
&minus; f &part;G
</p>
<p>&part;n
</p>
<p>)
</p>
<p>dSÎµ = 4Ï exp (&minus;i k Îµ)
(
</p>
<p>Îµ
</p>
<p>[
&part;f
</p>
<p>&part;n
</p>
<p>]
</p>
<p>&minus; (1 + i kÎµ) [f ]
)
</p>
<p>.
</p>
<p>(4.48)
</p>
<p>As for the integral I =
&int;
</p>
<p>VÎµ
Gb dVÎµ it is useful to adopt the spherical coordinates
</p>
<p>(B.1) after shifting the origin to the center of the sphere. In the new reference it is
r = 0, so that the radial coordinate coincides with g. It follows
</p>
<p>I =
&int; Îµ
</p>
<p>0
</p>
<p>&int; Ï
</p>
<p>0
</p>
<p>&int; 2Ï
</p>
<p>0
g sin Ï exp (&minus;i k g) b(g,Ï ,Ï) dg dÏ dÏ. (4.49)
</p>
<p>Taking the absolute value of I and observing that g and sin Ï are positive yields
|I | &le; 2Ï Îµ2 supVÎµ |b|. To proceed, one assumes that f and b are sufficiently smooth
as to fulfill the conditions
</p>
<p>lim
Îµ&rarr;0
</p>
<p>Îµ [f ] = 0, lim
Îµ&rarr;0
</p>
<p>Îµ
</p>
<p>[
&part;f
</p>
<p>&part;n
</p>
<p>]
</p>
<p>= 0, lim
Îµ&rarr;0
</p>
<p>Îµ2 sup
VÎµ
</p>
<p>|b| = 0. (4.50)</p>
<p/>
</div>
<div class="page"><p/>
<p>82 4 Electromagnetism
</p>
<p>Thanks to (4.50) one restores the original volume V by taking the limit Îµ &rarr; 0.
Observing that limÎµ&rarr;0 [f ] = f (r), one finds
</p>
<p>4Ï f (r) =
&int;
</p>
<p>S
</p>
<p>(
</p>
<p>G
&part;f
</p>
<p>&part;n
&minus; f &part;G
</p>
<p>&part;n
</p>
<p>)
</p>
<p>dS &minus;
&int;
</p>
<p>V
</p>
<p>Gb dV , (4.51)
</p>
<p>that renders f (r) as a function of b, of the boundary values of f and &part;f/&part;n, and of
the auxiliary function G. It is easily found that, if r were on the boundary S instead
of being internal to V , the left hand side of (4.51) would be replaced by 2Ï f (p).
Similarly, if r were external to V , the left hand side would be zero. In conclusion
one generalizes (4.51) to
</p>
<p>Ïr f (r) =
&int;
</p>
<p>S
</p>
<p>(
</p>
<p>G
&part;f
</p>
<p>&part;n
&minus; f &part;G
</p>
<p>&part;n
</p>
<p>)
</p>
<p>dS &minus;
&int;
</p>
<p>V
</p>
<p>Gb dV , (4.52)
</p>
<p>where Ïr is the solid angle under which the surface S is seen from r considering the
orientation of the unit vector n. Namely, Ïr = 0, Ïr = 2Ï , or Ïr = 4Ï when r is
external to V , on the boundary of V , or internal to V , respectively.
</p>
<p>Letting k = 0 in (4.45), namely, taking G = 1/g, makes the results of this
section applicable to the Poisson equation &nabla;2f = b. It must be noted that (4.52)
should be considered as an integral relation forf , not as the solution of the differential
equation whence it derives. In fact, for actually calculating (4.52) it is necessary to
prescribe both f and &part;f/&part;n over the boundary. This is an overspecification of the
problem: in fact, the theory of boundary-value problems shows that the solution of
an equation of the form (4.43) is found by specifying over the boundary either the
unknown function only (Dirichlet boundary condition), or its normal derivative only
(Neumann boundary condition). To find a solution starting from (4.52) it is necessary
to carry out more steps, by which either f or &part;f/&part;n is eliminated from the integral
at the right hand side [53, Sect. 1.8&ndash;1.10]. In contrast, when the solution is sought in
a domain whose boundary extends to infinity, and the contribution of the boundary
conditions vanish as shown in Sect. 4.9, the limiting case of (4.52) provides a solution
proper. More comments about this issue are made in Sect. 4.12.3.
</p>
<p>4.9 Solution of the Helmholtz Equation in an Infinite Domain
</p>
<p>The procedure shown in Sect. 4.8 is readily extended to the case V &rarr; &infin;. Here
one may replace S with a spherical surface of radius R &rarr; &infin;, centered on r; this
makes the calculation of the integral over S similar to that over the sphere of radius
Îµ outlined in Sect. 4.8, the only difference being that the unit vector n now points in
the direction where R increases. Shifting the origin to r and observing that Ïr = 4Ï
yields
</p>
<p>&int;
</p>
<p>S
</p>
<p>(
</p>
<p>G
&part;f
</p>
<p>&part;n
&minus; f &part;G
</p>
<p>&part;n
</p>
<p>)
</p>
<p>dS = 4Ï exp (&minus;i k R)
(
</p>
<p>R
</p>
<p>[
&part;f
</p>
<p>&part;n
</p>
<p>]
</p>
<p>+ (1 + i k R) [f ]
)
</p>
<p>,
</p>
<p>(4.53)</p>
<p/>
</div>
<div class="page"><p/>
<p>4.10 Solution of the Wave Equation in an Infinite Domain 83
</p>
<p>where the averages are calculated over S. To proceed one assumes that the following
relations hold,
</p>
<p>lim
R&rarr;&infin;
</p>
<p>[f ] = 0, lim
R&rarr;&infin;
</p>
<p>R
</p>
<p>([
&part;f
</p>
<p>&part;n
</p>
<p>]
</p>
<p>+ ik [f ]
)
</p>
<p>= 0, (4.54)
</p>
<p>that are called Sommerfeld asymptotic conditions. Due to (4.54) the surface integral
(4.53) vanishes. Shifting the origin back from r to the initial position, the solution
of the Helmholtz equation (4.43) over an infinite domain finally reads
</p>
<p>f (r) = &minus; 1
4Ï
</p>
<p>&int;
</p>
<p>&infin;
b(q)
</p>
<p>exp (&minus;ik |r &minus; q|)
|r &minus; q| d
</p>
<p>3q, (4.55)
</p>
<p>where
&int;
</p>
<p>&infin; indicates the integral over the whole three-dimensional q space. The k = 0
case yields the solution of the Poisson equation &nabla;2f = b in an infinite domain,
</p>
<p>f (r) = &minus; 1
4Ï
</p>
<p>&int;
</p>
<p>&infin;
b(q)
</p>
<p>1
</p>
<p>|r &minus; q| d
3q. (4.56)
</p>
<p>4.10 Solution of the Wave Equation in an Infinite Domain
</p>
<p>The solutions of the Helmholtz equation found in Sects. 4.8, 4.9 allow one to calculate
that of the wave equation. In fact, it is worth reminding that the Helmholtz Eq. (4.43)
was deduced in Sec. 4.7 by Fourier transforming the wave equation (4.35) and i)
letting f indicate the transform of the scalar potential Ï or of any component Ai
of the vector potential, ii) letting b indicate the transform of &minus;Ï/Îµ0 or &minus;Î¼0 Ji ,
i = 1, 2, 3. As a consequence, f and b depend on the angular frequency Ï besides
the spatial coordinates. From the definition k2 = Ï2/c2 one may also assume that
both k and Ï have the same sign, so that k = Ï/c. Considering for simplicity the
case V &rarr; &infin;, applying (C.17) to antitransform (4.56), and interchanging the order
of integrals yields
</p>
<p>F&minus;1f = &minus; 1
4Ï
</p>
<p>&int;
</p>
<p>&infin;
</p>
<p>1
</p>
<p>g
</p>
<p>[
1&radic;
2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
b(q,Ï) exp [iÏ (t &minus; g/c)] dÏ
</p>
<p>]
</p>
<p>d3q, (4.57)
</p>
<p>with g = |r &minus; q|. Now, denote with a the antitransform of b, a(q, t) = F&minus;1b. It
follows that the function between brackets in (4.57) coincides with a(q, t &minus; g/c).
As remarked above, when f represents Ï, then a stands for &minus;Ï/Îµ0; similarly, when
f represents a component of A, then a stands for the corresponding component of
&minus;Î¼0 J. In conclusion,
</p>
<p>Ï(r, t) = 1
4Ï Îµ0
</p>
<p>&int;
</p>
<p>&infin;
</p>
<p>Ï(q, t &minus; |r &minus; q|/c)
|r &minus; q| d
</p>
<p>3q, (4.58)
</p>
<p>A(r, t) = Î¼0
4Ï
</p>
<p>&int;
</p>
<p>&infin;
</p>
<p>J(q, t &minus; |r &minus; q|/c)
|r &minus; q| d
</p>
<p>3q, (4.59)</p>
<p/>
</div>
<div class="page"><p/>
<p>84 4 Electromagnetism
</p>
<p>that express the potentials in terms of the field sources Ï and J, when the asymptotic
behavior of the potentials fulfills the Sommerfeld conditions (4.54). The functions
rendered by the antitransforms are real, as should be. Note that |r &minus; q|/c &gt; 0 is the
time necessary for a signal propagating with velocity c to cross the distance |r &minus; q|.
As t&minus;|r&minus;q|/c &lt; t , the above expressions of Ï and A are called retarded potentials4.
</p>
<p>4.11 Lorentz Force
</p>
<p>It has been assumed so far that the sources of the electromagnetic field, namely, charge
density and current density, are prescribed functions of position and time. This is not
necessarily so, because the charges are in turn acted upon by the electromagnetic
field, so that their dynamics is influenced by it. Consider a test charge of value e
immersed in an electromagnetic field described by the vectors E, B generated by
other charges. The force acting upon the test charge is the Lorentz force [4, Vol. I,
Sect. 44]
</p>
<p>F = e (E + u &and; B), (4.60)
</p>
<p>where u is the velocity of the test charge and E, B are independent of u. The expression
of the Lorentz force does not derive from assumptions separate from Maxwell&rsquo;s
equations; in fact, it follows from Maxwell&rsquo;s equations and Special Relativity [109,
39]. The extension of (4.60) to the case of a number of point-like charges follows the
same line as in Sect. 4.4: considering the charges belonging to a cell of volume ï¿½V
centered at r, one writes (4.60) for the j th charge and takes the sum over j , to find
</p>
<p>f =
&sum;&prime;
</p>
<p>j Fj
</p>
<p>ï¿½V
= Ï (E + v &and; B), (4.61)
</p>
<p>where Ï, v are defined in (4.21) and f is the force density ([f] = N m&minus;3). The fields
in (4.61) are calculated in r and t .
</p>
<p>Consider a small time interval Î´t during which the charge contained within ï¿½V
is displaced by Î´r = v Î´t . The work per unit volume exchanged between the charge
and the electromagnetic field due to such a displacement is
</p>
<p>Î´w = f &middot; Î´r = Ï (E + v &and; B) &middot; v Î´t = E &middot; J Î´t , [w] = J m&minus;3, (4.62)
</p>
<p>4 Expressions of Ï and A obtained from (4.58, 4.59) after replacing t &minus;|r&minus;q|/c with t +|r&minus;q|/c
are also solutions of the wave equations (4.35). This is due to the fact that the Helmholtz equation
(4.43) can also be solved by using G&lowast; instead of G, which in turn reflects the time reversibility
of the wave equation. However, the form with t &minus; |r &minus; q|/c better represents the idea that an
electromagnetic perturbation, that is present in r at the time t , is produced by a source acting in q
at a time prior to t .</p>
<p/>
</div>
<div class="page"><p/>
<p>4.12 Complements 85
</p>
<p>where (A.32) and (4.21) have been used. When the scalar product is positive, the
charge acquires kinetic energy from the field, and vice versa. Letting Î´t &rarr; 0 yields
</p>
<p>&part;w
</p>
<p>&part;t
= E &middot; J, (4.63)
</p>
<p>where the symbol of partial derivative is used because (4.63) is calculated with r
fixed.
</p>
<p>4.12 Complements
</p>
<p>4.12.1 Invariance of the Euler Equations
</p>
<p>It has been shown in Sect. 4.2 that the Euler equations (4.8) are still fulfilled if the
generating function g is replaced with g&prime; = g + divh, where h is an arbitrary vector
of length m whose entries depend on w and Î¾1, . . . , Î¾m, but not on the derivatives of
w. This property is a generalization of that illustrated in Sect. 1.2 with reference to a
system of particles, where it was shown that the solutions wi(Î¾ ) are invariant under
addition to g of the total derivative of an arbitrary function that depends on w and Î¾
only.
</p>
<p>4.12.2 Wave Equations for the E and B Fields
</p>
<p>The Maxwell equations can be rearranged in the form of wave equations for the
electric and magnetic fields. To this purpose, one takes the rotational of both sides
of the second equation in (4.24). Using the first identity in (A.36) and the relation
D = Îµ0 E provides &minus;&part;rotB/&part;t = rot rot E = graddiv(D/Îµ0) &minus; &nabla;2E. Replacing
divD and rotH = rotB/Î¼0 from (4.19) and using Îµ0 Î¼0 = 1/c2 then yields
</p>
<p>&nabla;2E &minus; 1
c2
</p>
<p>&part;2E
</p>
<p>&part;t2
= 1
</p>
<p>Îµ0
gradÏ + Î¼0
</p>
<p>&part;J
</p>
<p>&part;t
. (4.64)
</p>
<p>Similarly, one takes the rotational of both sides of the second equation in (4.19). Using
the relation B = Î¼0 H provides Îµ0 &part;rotE/&part;t + rotJ = rot rot H = graddiv(B/Î¼0)&minus;
&nabla;2H. Replacing divB and rotE from (4.24) yields
</p>
<p>&nabla;2H &minus; 1
c2
</p>
<p>&part;2H
</p>
<p>&part;t2
= &minus;rotJ. (4.65)</p>
<p/>
</div>
<div class="page"><p/>
<p>86 4 Electromagnetism
</p>
<p>4.12.3 Comments on the Boundary-Value Problem
</p>
<p>Considering relation (4.52) derived in Sect. 4.8, one notes that the right hand side
is made of the difference between two terms; the first one depends on the boundary
values of f , &part;f/&part;n, but not on b, while the second one depends only on the values of
b within V and over the boundary. In these considerations it does not matter whether
point r is external to V , on the boundary of V , or internal to it. In latter case the two
terms at the right hand side of (4.52) balance each other.
</p>
<p>If b is replaced with a different function bÌ, and thereby the value of the second
integral changes, it is possible to modify the boundary values in such a way as to
balance the variation of the second integral with that of the first one; as a consequence,
f (r) is left unchanged. A possible choice for the modified b is bÌ = 0; by this choice
one eliminates the data of the differential equation and suitably modifies the boundary
values, leaving the solution unaffected. An observer placed at r would be unable to
detect that the data have disappeared. The same process can also be carried out in
reverse, namely, by eliminating the boundary values and suitably changing the data.
</p>
<p>An example is given in Prob. 4.4 with reference to a one-dimensional Poisson
equation where the original charge density differs from zero in a finite interval [a, b].
The charge density is removed and the boundary values at a are modified so that the
electric potential Ï is unaffected for x &ge; b. Obviously Ï changes for a &lt; x &lt; b
because both the charge density and boundary conditions are different, and also for
x &le; a because the boundary conditions are different.
</p>
<p>Problems
</p>
<p>4.1 Solve the one-dimensional Poisson equation d2Ï/dx2 = &minus;Ï(x)/Îµ0, with Ï
given, using the integration by parts to avoid a double integral. The solution is
prescribed at x = a while the first derivative is prescribed at x = c.
</p>
<p>4.2 Let c = a in the solution of Prob. 4.1 and assume that the charge density Ï
differs from zero only in a finite interval a &le; x &le; b. Find the expression of Ï
for x &gt; b when both the solution and the first derivative are prescribed at x = a.
</p>
<p>4.3 In Prob. 4.2 replace the charge density Ï with a different one, say, ÏÌ. Discuss
the conditions that leave the solution unchanged.
</p>
<p>4.4 In Prob. 4.2 remove the charge density Ï and modify the boundary conditions
at a so that the solution for x &gt; b is left unchanged.
</p>
<p>4.5 Using the results of Probs. 4.2 and 4.3, and assuming that both M0 and M1 are
different from zero, replace the ratioÏ/Îµ0 withÎ¼Î´(x&minus;h) and find the parameters
Î¼, h that leave M0, M1 unchanged. Noting that h does not necessarily belong to
the interval [a, b], discuss the outcome for different positions of h with respect
to a.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 5
</p>
<p>Applications of the Concepts
of Electromagnetism
</p>
<p>5.1 Introduction
</p>
<p>This chapter provides a number of important applications of the concepts of Electro-
magnetism. The solution of the wave equation found in Chap. 4 is used to calculate
the potentials generated by a point-like charge; this result is exploited later to analyze
the decay of atoms in the frame of the classical model, due to the radiated power.
Next, the continuity equations for the energy and momentum of the electromagnetic
field are found. As an application, the energy and momentum of the electromagnetic
field are calculated in terms of modes in a finite domain, showing that the energy of
each mode has the same expression as that of a linear harmonic oscillator. The analy-
sis is extended also to an infinite domain. The chapter is concluded by the derivation
of the eikonal equation, leading to the approximation of Geometrical Optics, fol-
lowed by the demonstration that the eikonal equation is generated by a variational
principle, namely, the Fermat principle. The complements show the derivation of
the fields generated by a point-like charge and the power radiated by it. It is found
that the planetary model of the atom is inconsistent with electromagnetism because
it contradicts the atom&rsquo;s stability. Finally, a number of analogies are outlined and
commented between Mechanics and Geometrical Optics, based on the comparison
between the Maupertuis and Fermat principles. The course of reasoning deriving
from the comparison hints at the possibility that mechanical laws more general than
Newton&rsquo;s law exist.
</p>
<p>5.2 Potentials Generated by a Point-Like Charge
</p>
<p>The calculation of Ï and A based upon (4.58, 4.59) has the inconvenience that, as q
varies over the space, it is necessary to consider the sources Ï and J at different time
instants. This may be avoided by recasting a in the form
</p>
<p>&copy; Springer Science+Business Media New York 2015 87
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_5</p>
<p/>
</div>
<div class="page"><p/>
<p>88 5 Applications of the Concepts of Electromagnetism
</p>
<p>a(q, t &minus; |r &minus; q|/c) =
&int; +&infin;
</p>
<p>&minus;&infin;
a(q, t &prime;) Î´(t &prime; &minus; t + |r &minus; q|/c) dt &prime;, (5.1)
</p>
<p>and interchanging the integration over q in (4.58, 4.59) with that over t &prime;. This proce-
dure is particularly useful when the source of the field is a single point-like charge.
Remembering (4.20), one replaces Ï and J with
</p>
<p>Ïc(q, t
&prime;) = e Î´
</p>
<p>(
</p>
<p>q &minus; s(t &prime;)
)
</p>
<p>, Jc(q, t
&prime;) = e Î´
</p>
<p>(
</p>
<p>q &minus; s(t &prime;)
)
</p>
<p>u(t &prime;), (5.2)
</p>
<p>where e is the value of the point-like charge, s = s(t &prime;) its trajectory, and u(t &prime;) = ds/dt &prime;
its velocity. First, the integration over space fixes q at s&prime; = s(t &prime;), this yielding
</p>
<p>Ï(r, t) = e
4Ï Îµ0
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>Î´[Î²(t &prime;)]
</p>
<p>|r &minus; s&prime;| dt
&prime;, A(r, t) = e Î¼0
</p>
<p>4Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>Î´[Î²(t &prime;)] u(t &prime;)
</p>
<p>|r &minus; s&prime;| dt
&prime;,
</p>
<p>(5.3)
</p>
<p>with Î²(t &prime;) = t &prime; &minus; t + |r &minus; s&prime;|/c. Next, the integration over t &prime; fixes the latter to the
value that makes the argument of Î´ to vanish. Such a value is the solution of
</p>
<p>|r &minus; s(t &prime;)| = c (t &minus; t &prime;), (5.4)
where t , r, and the function s(t &prime;) are prescribed. As |u| &lt; c it can be shown that the
solution of (5.4) exists and is unique [68, Sect. 63]. Observing that the argument of Î´
in (5.3) is a function of t &prime;, to complete the calculation one must follow the procedure
depicted in Sect. C.5, which involves the derivative
</p>
<p>dÎ²
</p>
<p>dt &prime;
= 1 + 1
</p>
<p>c
</p>
<p>d|r &minus; s&prime;|
dt &prime;
</p>
<p>= 1 + d[(r &minus; s
&prime;) &middot; (r &minus; s&prime;)]
</p>
<p>2c |r &minus; s&prime;| dt &prime; = 1 &minus;
r &minus; s&prime;
|r &minus; s&prime;|
</p>
<p>u
</p>
<p>c
. (5.5)
</p>
<p>Then, letting t &prime; = Ï be the solution of (5.4) and Î²Ì = (dÎ²/dt &prime;)t &prime;=Ï , one applies
(C.57) to (5.3). The use of the absolute value is not necessary here, in fact one has
[(r &minus; s&prime;)/|r &minus; s&prime;|] &middot; (u/c) &le; u/c &lt; 1, whence |Î²Ì| = Î²Ì. In conclusion one finds
</p>
<p>Ï(r, t) = e/(4Ï Îµ0)|r &minus; s(Ï )| &minus; (r &minus; s(Ï )) &middot; u(Ï )/c , (5.6)
</p>
<p>A(r, t) = e Î¼0/(4Ï ) u(Ï )|r &minus; s(Ï )| &minus; (r &minus; s(Ï )) &middot; u(Ï )/c , (5.7)
</p>
<p>that provide the potentials generated in r and at time t by a point-like charge that
follows the trajectory s = s(Ï ). The relation between t and Ï is given by t =
Ï + |r &minus; s(Ï )|/c, showing that t &minus; Ï is the time necessary for the electromagnetic
perturbation produced by the point-like charge at s to reach the position r. The
expressions (5.6, 5.7) are called Li&eacute;nard and Wiechert potentials. In the case u = 0
they become
</p>
<p>Ï(r) = e
4Ï Îµ0 |r &minus; s|
</p>
<p>, A(r) = 0, (5.8)
</p>
<p>s = const, the first of which is the Coulomb potential. The fields E, B generated
by a point-like charge are obtained from (5.6, 5.7) using (4.26). The calculation is
outlined in Sect. 5.11.1.</p>
<p/>
</div>
<div class="page"><p/>
<p>5.3 Energy Continuity&mdash;Poynting Vector 89
</p>
<p>5.3 Energy Continuity&mdash;Poynting Vector
</p>
<p>The right hand side of (4.63) is recast in terms of the fields by replacing J with the
left hand side of the second equation in (4.19); using D = Îµ0 E,
</p>
<p>&part;w
</p>
<p>&part;t
= E &middot;
</p>
<p>(
</p>
<p>rotH &minus; Îµ0
&part;E
</p>
<p>&part;t
</p>
<p>)
</p>
<p>= E &middot; rotH &minus; Îµ0
2
</p>
<p>&part;E2
</p>
<p>&part;t
. (5.9)
</p>
<p>The above expression is given a more symmetric form by exploiting the first equation
in (4.19). In fact, a scalar multiplication of the latter by H along with the relation
B = Î¼0 H provides 0 = H &middot; rotE + Î¼0 &part;(H 2/2)/&part;t which, subtracted from (5.9),
finally yields
</p>
<p>&part;w
</p>
<p>&part;t
= E &middot; rotH &minus; H &middot; rotE &minus; &part;wem
</p>
<p>&part;t
, wem =
</p>
<p>1
</p>
<p>2
</p>
<p>(
</p>
<p>Îµ0 E
2 + Î¼0 H 2
</p>
<p>)
</p>
<p>. (5.10)
</p>
<p>Then, using the second identity in (A.36) transforms (5.10) into
</p>
<p>&part;
</p>
<p>&part;t
(w + wem) + divS = 0, S = E &and; H. (5.11)
</p>
<p>As w+wem is an energy density, S (called Poynting vector) is an energy-flux density
([S] = J m&minus;2 s&minus;1). To give wem and S a physical meaning one notes that (5.11) has
the form of a continuity equation (compare, e.g., with (23.3) and (4.23)) where two
interacting systems are involved, namely, the charges and the electromagnetic field.
Integrating (5.11) over a volume V yields
</p>
<p>d
</p>
<p>dt
(W +Wem) = &minus;
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>S &middot; n dï¿½, W =
&int;
</p>
<p>V
</p>
<p>w dV , Wem =
&int;
</p>
<p>V
</p>
<p>wem dV ,
</p>
<p>(5.12)
</p>
<p>where ï¿½ is the boundary of V , n is the unit vector normal to dï¿½ oriented in the
outward direction with respect to V , and W , Wem are energies. If V is let expand
to occupy all space, the surface integral in (5.12) vanishes because the fields E, H
vanish at infinity; it follows that for an infinite domain the sumW+Wem is conserved
in time, so that dWem/dt = &minus;dW/dt . Observing that W is the kinetic energy of the
charges, and that the latter exchange energy with the electromagnetic field, gives
Wem the meaning of energy of the electromagnetic field; as a consequence, wem is
the energy density of the electromagnetic field, and the sum W +Wem is the constant
energy of the two interacting systems.
</p>
<p>When V is finite, the surface integral in (5.12) may be different from zero, hence
the sum W +Wem is not necessarily conserved. This allows one to give the surface
integral the meaning of energy per unit time that crosses the boundary ï¿½, carried
by the electromagnetic field. In this reasoning it is implied that, when V is finite, it
is chosen in such a way that no charge is on the boundary at time t . Otherwise the
kinetic energy of the charges crossing ï¿½ during dt should also be accounted for.</p>
<p/>
</div>
<div class="page"><p/>
<p>90 5 Applications of the Concepts of Electromagnetism
</p>
<p>5.4 Momentum Continuity
</p>
<p>The procedure used in Sect. 5.3 to derive the continuity equation for the charge energy
can be replicated to obtain the continuity equation for the charge momentum per unit
volume, m. Remembering (4.61) one finds the relation f = mÌ = &sum;&prime;j pÌj/ï¿½V , with
pj the momentum of the j th charge contained within ï¿½V . Using (4.19) along with
J = Ï v yields
</p>
<p>mÌ = Ï E + J &and; B = E divD +
(
</p>
<p>rotH &minus; &part;D
&part;t
</p>
<p>)
</p>
<p>&and; B. (5.13)
</p>
<p>Adding D &and; &part;B/&part;t to both sides of (5.13), using &part;B/&part;t = &minus;rotE, and rearranging:
</p>
<p>mÌ + &part;D
&part;t
</p>
<p>&and; B + D &and; &part;B
&part;t
</p>
<p>= E divD + (rotH) &and; B + (rotE) &and; D. (5.14)
</p>
<p>Poynting vector&rsquo;s definition (5.11) transforms the left hand side of (5.14) into mÌ +
Îµ0 Î¼0 &part;(E &and; H)/&part;t = &part;(m + S/c2)/&part;t . In turn, the kth component of E divD +
(rotE) &and; D can be recast as
</p>
<p>Îµ0 (Ek divE + E &middot; gradEk)&minus;
Îµ0
</p>
<p>2
</p>
<p>&part;E2
</p>
<p>&part;xk
= Îµ0 div(Ek E) &minus;
</p>
<p>Îµ0
</p>
<p>2
</p>
<p>&part;E2
</p>
<p>&part;xk
. (5.15)
</p>
<p>Remembering that divB = 0, the kth component of the term (rotH)&and;B = H divB+
(rotH)&and;B is treated in the same manner. Adding up the contributions of the electric
and magnetic parts and using the definition (5.10) of wem yields
</p>
<p>&part;
</p>
<p>&part;t
</p>
<p>(
</p>
<p>mk +
1
</p>
<p>c2
Sk
</p>
<p>)
</p>
<p>+ divTk = 0, Tk = wem ik &minus; Îµ0 Ek E &minus; Î¼0 HkH, (5.16)
</p>
<p>with ik the unit vector of the kth axis. As mk + Sk/c2 is a momentum density, Tk
is a momentum-flux density ([Tk] = J m&minus;3). Following the same reasoning as in
Sect. 5.3 one integrates (5.16) over a volume V , to find
</p>
<p>d
</p>
<p>dt
</p>
<p>&int;
</p>
<p>V
</p>
<p>(
</p>
<p>mk +
1
</p>
<p>c2
Sk
</p>
<p>)
</p>
<p>dV = &minus;
&int;
</p>
<p>ï¿½
</p>
<p>Tk &middot; n dï¿½, (5.17)
</p>
<p>where ï¿½ and n are defined as in (5.12). If V is let expand to occupy all space, the
surface integral in (5.17) vanishes because the fields E, H vanish at infinity; it follows
that for an infinite domain the sum
</p>
<p>&int;
</p>
<p>V
</p>
<p>(
</p>
<p>m + 1
c2
</p>
<p>S
</p>
<p>)
</p>
<p>dV = p +
&int;
</p>
<p>V
</p>
<p>1
</p>
<p>c2
S dV , p =
</p>
<p>&int;
</p>
<p>V
</p>
<p>m dV (5.18)
</p>
<p>is conserved in time. As p is the momentum of the charges,
&int;
</p>
<p>V
S/c2 d3r takes the
</p>
<p>meaning of momentum of the electromagnetic field within V . As a consequence,
S/c2 takes the meaning of momentum per unit volume of the electromagnetic field.</p>
<p/>
</div>
<div class="page"><p/>
<p>5.5 Modes of the Electromagnetic Field 91
</p>
<p>Fig. 5.1 The domain used
for the expansion of the
vector potential into a Fourier
series (Sect. 5.5)
</p>
<p>x1
</p>
<p>x2
</p>
<p>d1
</p>
<p>d2
</p>
<p>d3
</p>
<p>x3
</p>
<p>When V is finite, the surface integral in (5.17) may be different from zero, hence
the sum (5.18) is not necessarily conserved. This allows one to give the surface
integral in (5.17) the meaning of momentum per unit time that crosses the boundary
ï¿½, carried by the electromagnetic field. In this reasoning it is implied that, when V is
finite, it is chosen in such a way that no charge is on the boundary at time t . Otherwise
the momentum of the charges crossing ï¿½ during dt should also be accounted for.
</p>
<p>5.5 Modes of the Electromagnetic Field
</p>
<p>The expressions of the energy and momentum of the electromagnetic field, worked
out in Sects. 5.3 and 5.4, take a particularly interesting form when a spatial region
free of charges is considered. In fact, if one lets Ï = 0, J = 0, equations (4.33) or
(4.35) that provide the potentials become homogeneous. To proceed one takes a finite
region of volume V ; the calculation will be extended in Sect. 5.8 to the case of an
infinite domain. As the shape of V is not essential for the considerations illustrated
here, it is chosen as that of a box whose sides d1, d2, d3 are aligned with the coordinate
axes and start from the origin (Fig. 5.1). The volume of the box is V = d1 d2 d3.
</p>
<p>The calculation is based on (4.33), that are the equations for the potentials deriving
from the Coulomb gauge (4.32). Letting Ï = 0, J = 0 and dropping the primes yields
</p>
<p>&nabla;2Ï = 0, &nabla;2A &minus; 1
c2
</p>
<p>&part;2A
</p>
<p>&part;t2
= 1
</p>
<p>c2
</p>
<p>&part;
</p>
<p>&part;t
gradÏ, (5.19)
</p>
<p>the first of which is a Laplace equation. It is shown in Sect. 5.11.4 that a gauge
transformation exists such that Ï = 0 here. The system (5.19) then reduces to the
linear, homogeneous wave equation for the vector potential A = A(r, t),
</p>
<p>&nabla;2A &minus; 1
c2
</p>
<p>&part;2A
</p>
<p>&part;t2
= 0. (5.20)</p>
<p/>
</div>
<div class="page"><p/>
<p>92 5 Applications of the Concepts of Electromagnetism
</p>
<p>As the vector potential is defined within a finite volume and has a finite module as
well, one can expand it into the Fourier series
</p>
<p>A =
&sum;
</p>
<p>k
</p>
<p>ak exp (i k &middot; r), ak =
1
</p>
<p>V
</p>
<p>&int;
</p>
<p>V
</p>
<p>A exp ( &minus; i k &middot; r) dV , (5.21)
</p>
<p>where ak = a(k, t) is complex and the wave vector k is given by
</p>
<p>k = n1
2Ï
</p>
<p>d1
i1 + n2
</p>
<p>2Ï
</p>
<p>d2
i2 + n3
</p>
<p>2Ï
</p>
<p>d3
i3, ni = 0,&plusmn;1,&plusmn;2, . . . (5.22)
</p>
<p>The symbol
&sum;
</p>
<p>k indicates a triple sum over all integers n1, n2, n3. The definition of
ak yields
</p>
<p>a&minus;k = a&lowast;k, a0 =
1
</p>
<p>V
</p>
<p>&int;
</p>
<p>V
</p>
<p>A dV , (5.23)
</p>
<p>with a0 real. Applying Coulomb&rsquo;s gauge divA = 0 to the expansion (5.21) provides
</p>
<p>divA =
&sum;
</p>
<p>k
</p>
<p>3
&sum;
</p>
<p>m=1
akm i km exp (i k &middot; r) = i
</p>
<p>&sum;
</p>
<p>k
</p>
<p>ak &middot; k exp (i k &middot; r) = 0, (5.24)
</p>
<p>that is, a linear combination of functions of r. As such functions are linearly in-
dependent from each other, (5.24) vanishes only if the coefficients vanish, so it is
ak &middot; k = 0. Replacing k with &minus;k and using (5.23) shows that a&minus;k &middot; k = a&lowast;k &middot; k = 0.
In conclusion, ak has no components in the direction of k, namely, it has only two
independent (complex) components that lie on the plane normal to k: letting e1, e2
be unit vectors belonging to such a plane and normal to each other, one has
</p>
<p>ak = ak &middot; e1 e1 + ak &middot; e2 e2. (5.25)
</p>
<p>Clearly the reasoning above does not apply to a0; however, it is shown below that
eventually this term does not contribute to the fields. The Fourier series (5.21) is now
inserted into the wave equation (5.20), whose two summands become
</p>
<p>&nabla;2A =
&sum;
</p>
<p>k
</p>
<p>ak
</p>
<p>3
&sum;
</p>
<p>m=1
(i km)
</p>
<p>2 exp (i k &middot; r) = &minus;
&sum;
</p>
<p>k
</p>
<p>ak k
2 exp (ik &middot; r), (5.26)
</p>
<p>&minus; 1
c2
</p>
<p>&part;2A
</p>
<p>&part;t2
= &minus; 1
</p>
<p>c2
</p>
<p>&sum;
</p>
<p>k
</p>
<p>aÌk exp (i k &middot; r). (5.27)
</p>
<p>Adding up yields
&sum;
</p>
<p>k
</p>
<p>(
</p>
<p>aÌk + c2 k2 ak
)
</p>
<p>exp (i k &middot; r) = 0 whence, using the same
reasoning as that used for discussing (5.24),
</p>
<p>aÌk + Ï2 ak = 0, Ï(k) = c k &ge; 0, Ï( &minus; k) = Ï(k). (5.28)</p>
<p/>
</div>
<div class="page"><p/>
<p>5.6 Energy of the Electromagnetic Field in Terms of Modes 93
</p>
<p>The case k = 0 yields aÌ0 = 0 whence a0(t) = a0(t = 0)+ aÌ0(t = 0) t . The constant
aÌ0(t = 0) must be set to zero to prevent a0 from diverging. When k ï¿½= 0 the solution
of (5.28) is readily found to be ak(t) = ck exp ( &minus; iÏt) + c&prime;k exp (iÏt), where the
complex vectors ck, c&prime;k depend on k only and lie on the plane normal to it. Using the
first relation in (5.23) yields c&prime;k = c&lowast;&minus;k and, finally,
</p>
<p>ak = sk + s&lowast;&minus;k, sk(t) = ck exp ( &minus; iÏ t), k ï¿½= 0. (5.29)
</p>
<p>Thanks to (5.29) one reconstructs the vector potential A in a form that shows its
dependence on space and time explicitly. To this purpose one notes that the sum
(5.21) contains all possible combinations of indices n1, n2, n3, so that a sum-
mand corresponding to k is paired with another summand corresponding to &minus;k. One
can then rearrange (5.21) as A = (1/2) &sum;k
</p>
<p>[
</p>
<p>ak exp (i k &middot; r) + a&minus;k exp ( &minus; i k &middot; r)
]
</p>
<p>,
where the factor 1/2 is introduced to eliminate a double counting. Using (5.29), and
remembering from (5.28) that Ï(k) is even, renders A as a sum of real terms,
</p>
<p>A =
&sum;
</p>
<p>k
</p>
<p>&real;
{
</p>
<p>ck exp [i (k &middot; r &minus; Ït)] + c&lowast;&minus;k exp [i (k &middot; r + Ït)]
}
</p>
<p>, (5.30)
</p>
<p>The summands of (5.30) corresponding to k and &minus;k describe two plane and
monochromatic waves that propagate in the k and &minus;k direction, respectively. The
two waves together form a mode of the electromagnetic field, whose angular fre-
quency is Ï = c k. The summands corresponding to k = 0 yield the real constant
c0 + c&lowast;0 = a0. Finally, the E and B fields are found by introducing the expansion of
A into (4.26) after letting Ï = 0. For this calculation it is convenient to use the form
of the expansion bearing the factor 1/2 introduced above: from the definition (5.29)
of sk and the first identity in (A.35) one finds
</p>
<p>E = &minus;&part;A
&part;t
</p>
<p>= 1
2
</p>
<p>&sum;
</p>
<p>k
</p>
<p>iÏ
[(
</p>
<p>sk &minus; s&lowast;&minus;k
)
</p>
<p>exp (i k &middot; r) +
(
</p>
<p>s&minus;k &minus; s&lowast;k
)
</p>
<p>exp ( &minus; i k &middot; r)
]
</p>
<p>,
</p>
<p>(5.31)
</p>
<p>B = rotA = 1
2
</p>
<p>&sum;
</p>
<p>k
</p>
<p>i k &and;
[(
</p>
<p>sk + s&lowast;&minus;k
)
</p>
<p>exp (i k &middot; r) &minus;
(
</p>
<p>s&minus;k + s&lowast;k
)
</p>
<p>exp ( &minus; i k &middot; r)
]
</p>
<p>.
</p>
<p>(5.32)
</p>
<p>As anticipated, the constant term a0 does not contribute to the fields. Also, due to the
second relation in (5.29), the vectors sk, s&lowast;&minus;k, s&minus;k, and s
</p>
<p>&lowast;
k lie over the plane normal to k.
</p>
<p>Due to (5.31, 5.32) the E and B fields lie on the same plane as well, namely, they have
no component in the propagation direction. For this reason they are called transversal.
</p>
<p>5.6 Energy of the Electromagnetic Field in Terms of Modes
</p>
<p>The expressions of the E, B fields within a finite volume V free of charges have been
calculated in Sect. 5.5 as superpositions of modes, each of them associated with a
wave vector k and an angular frequency Ï = ck. Basing upon such expressions</p>
<p/>
</div>
<div class="page"><p/>
<p>94 5 Applications of the Concepts of Electromagnetism
</p>
<p>one is able to determine the electromagnetic energy within V in terms of modes.
To this purpose one calculates from (5.31, 5.32) the squares E2 = E &middot; E and B2 =
B &middot; B, inserts the resulting expression into the second relation of (5.10) to obtain
the energy per unit volume and, finally, integrates the latter over V (last relation
in (5.12)). Letting Ik be the quantity enclosed within brackets in (5.31), it is E2 =
&minus;(1/4) &sum;k
</p>
<p>&sum;
</p>
<p>k&prime; ÏÏ
&prime; Ik &middot; Ik&prime; , where Ï&prime; = ck&prime;. The integration over V avails itself of
</p>
<p>the integrals (C.121), to yield
</p>
<p>&minus;1
4
</p>
<p>&sum;
</p>
<p>k&prime;
ÏÏ&prime;
</p>
<p>&int;
</p>
<p>V
</p>
<p>Ik &middot; Ik&prime; dV = V Ï2
(
</p>
<p>sk &minus; s&lowast;&minus;k
)
</p>
<p>&middot;
(
</p>
<p>s&lowast;k &minus; s&minus;k
)
</p>
<p>, (5.33)
</p>
<p>so that the part of the electromagnetic energy deriving from E reads
&int;
</p>
<p>V
</p>
<p>Îµ0
</p>
<p>2
E2 dV = Îµ0
</p>
<p>2
V
</p>
<p>&sum;
</p>
<p>k
</p>
<p>Ï2
(
</p>
<p>sk &minus; s&lowast;&minus;k
)
</p>
<p>&middot;
(
</p>
<p>s&lowast;k &minus; s&minus;k
)
</p>
<p>. (5.34)
</p>
<p>By the same token one lets Yk be the quantity enclosed within brackets in (5.32),
whence B2 = &minus;(1/4) &sum;k
</p>
<p>&sum;
</p>
<p>k&prime; (k &and; Yk) &middot; (k&prime; &and; Yk&prime; ) and
</p>
<p>&minus;1
4
</p>
<p>&sum;
</p>
<p>k&prime;
</p>
<p>&int;
</p>
<p>V
</p>
<p>(k &and; Yk) &middot; (k&prime; &and; Yk&prime; ) dV = V
[
</p>
<p>k &and;
(
</p>
<p>sk + s&lowast;&minus;k
)]
</p>
<p>&middot;
[
</p>
<p>k &and;
(
</p>
<p>s&minus;k + s&lowast;k
)]
</p>
<p>.
</p>
<p>(5.35)
</p>
<p>The expression at the right hand side of (5.35) simplifies because, due to (5.29), k
is normal to the plane where sk, s&lowast;&minus;k, s&minus;k, and s
</p>
<p>&lowast;
k lie, so that [k &and; (sk + s&lowast;&minus;k)] &middot; [k &and;
</p>
<p>(s&minus;k + s&lowast;k)] = k2 (sk + s&lowast;&minus;k) &middot; (s&minus;k + s&lowast;k). Using the relation k2 = Ï2/c2 = Îµ0 Î¼0 Ï2
yields the part of the electromagnetic energy deriving from H = B/Î¼0,
</p>
<p>&int;
</p>
<p>V
</p>
<p>1
</p>
<p>2Î¼0
B2 dV = Îµ0
</p>
<p>2
V
</p>
<p>&sum;
</p>
<p>k
</p>
<p>Ï2 (sk + s&lowast;&minus;k) &middot; (s&minus;k + s&lowast;k). (5.36)
</p>
<p>Adding up (5.34) and (5.36) one finally obtains
</p>
<p>Wem = Îµ0 V
&sum;
</p>
<p>k
</p>
<p>Ï2
(
</p>
<p>sk &middot; s&lowast;k + s&minus;k &middot; s&lowast;&minus;k
)
</p>
<p>= 2 Îµ0 V
&sum;
</p>
<p>k
</p>
<p>Ï2 sk &middot; s&lowast;k. (5.37)
</p>
<p>This result shows that the energy of the electromagnetic field within V is the sum of
individual contributions, each associated to a wave vector k through the complex vec-
tor sk. As the latter lies on the plane normal to k, it is expressed in terms of two scalar
components as sk = sk1 e1 + sk2 e2. Such components are related to the polarization
of the electromagnetic field over the plane [9, Sect. 1.4.2]. These considerations al-
low one to count the number of indices that are involved in the representation (5.37)
of Wem: in fact, the set of k vectors is described by the triple infinity of indices n1,
n2, n3 &isin; Z that appear in (5.22), while the two scalar components require another
index Ï = 1, 2. The sk vectors describe the electromagnetic field through (5.31) and
(5.32), hence one may think of each scalar component skÏ as a degree of freedom of</p>
<p/>
</div>
<div class="page"><p/>
<p>5.7 Momentum of the Electromagnetic Field in Terms of Modes 95
</p>
<p>the field; the counting outlined above shows that the number of degrees of freedom
is 2 &times; Z3. In turn, each degree of freedom is made of a real and an imaginary part,
skÏ = RkÏ + i IkÏ , this yielding
</p>
<p>Wem =
&sum;
</p>
<p>kÏ
</p>
<p>WkÏ , WkÏ = 2 Îµ0 V Ï2
(
</p>
<p>R2kÏ + I 2kÏ
)
</p>
<p>. (5.38)
</p>
<p>As Ï = ck, the mode with k = 0 does not contribute to the energy. In (5.38) it is
RkÏ = |ckÏ | cos [iÏ (t0 &minus; t)], IkÏ = |ckÏ | sin [iÏ (t0 &minus; t)], where the polar form
|ckÏ | exp (iÏ t0) has been used for ckÏ . One notes that each summand in (5.38) is
related to a single degree of freedom and has a form similar to the Hamiltonian
function of the linear harmonic oscillator discussed in Sect. 3.3. To further pursue
the analogy one defines the new pair
</p>
<p>qkÏ (t) = 2
&radic;
</p>
<p>Îµ0 V RkÏ , pkÏ (t) = 2Ï
&radic;
</p>
<p>Îµ0 V IkÏ , (5.39)
</p>
<p>whence
</p>
<p>WkÏ =
1
</p>
<p>2
</p>
<p>(
</p>
<p>p2kÏ + Ï2 q2kÏ
)
</p>
<p>,
&part;WkÏ
</p>
<p>&part;pkÏ
= pkÏ ,
</p>
<p>&part;WkÏ
</p>
<p>&part;qkÏ
= Ï2 qkÏ . (5.40)
</p>
<p>On the other hand, the time dependence of RkÏ , IkÏ is such that
</p>
<p>qÌkÏ = pkÏ =
&part;WkÏ
</p>
<p>&part;pkÏ
, pÌkÏ = &minus;Ï2 qkÏ = &minus;
</p>
<p>&part;WkÏ
</p>
<p>&part;qkÏ
. (5.41)
</p>
<p>Comparing (5.41) with (1.42) shows that qkÏ , pkÏ are canonically-conjugate vari-
ables andWkÏ is the Hamiltonian function of the degree of freedom associated to kÏ .
Then, comparing (5.40) with (3.1, 3.2) shows that WkÏ is indeed the Hamiltonian
function of a linear harmonic oscillator of unit mass.
</p>
<p>The energy associated to each degree of freedom is constant in time. In fact, from
the second relation in (5.29) one derives WkÏ = 2 Îµ0 V Ï2 ckÏ &middot; c&lowast;kÏ . The same result
can be obtained from the properties of the linear harmonic oscillator (Sect. 3.3). It
follows that the total energy Wem is conserved. As shown in Sect. 5.11.4 this is due
to the periodicity of the Poynting vector (5.11): in fact, the electromagnetic energies
the cross per unit time two opposite faces of the boundary of V are the negative of
each other.
</p>
<p>5.7 Momentum of the Electromagnetic Field in Terms of Modes
</p>
<p>It has been shown in Sect. 5.4 that the momentum per unit volume of the electro-
magnetic field is S/c2 = E &and; B/(Î¼0 c2) = Îµ0E &and; B. Using the symbols defined in
Sect. 5.6 one finds Îµ0E &and; B = &minus;(Îµ0/4)
</p>
<p>&sum;
</p>
<p>k
</p>
<p>&sum;
</p>
<p>k&prime; Ï Ik &and; (k&prime; &and; Yk&prime; ) and
</p>
<p>&minus;Îµ0
4
</p>
<p>&sum;
</p>
<p>k&prime;
</p>
<p>&int;
</p>
<p>V
</p>
<p>Ï Ik &and; (k&prime; &and; Yk&prime; ) dV =
Îµ0
</p>
<p>2
ÏV (Zk + Z&minus;k) , (5.42)</p>
<p/>
</div>
<div class="page"><p/>
<p>96 5 Applications of the Concepts of Electromagnetism
</p>
<p>with Zk = (sk &minus; s&lowast;&minus;k) &and; [k &and; (s&minus;k + s&lowast;k)]. The expression of Zk simplifies because,
due to (5.29), k is normal to the plane where sk, s&lowast;&minus;k, s&minus;k, and s
</p>
<p>&lowast;
k lie, so that Zk =
</p>
<p>k (sk &minus; s&lowast;&minus;k) &middot; (s&minus;k + s&lowast;k) and Zk +Z&minus;k = 2 k sk &middot; s&lowast;k +2 (&minus;k) s&minus;k &middot; s&lowast;&minus;k. In conclusion,
observing that Ï k = (Ï2/c) k/k,
&int;
</p>
<p>V
</p>
<p>S
</p>
<p>c2
dV = 2 Îµ0 V
</p>
<p>&sum;
</p>
<p>k
</p>
<p>Ï sk &middot; s&lowast;k k =
&sum;
</p>
<p>kÏ
</p>
<p>1
</p>
<p>c
WkÏ
</p>
<p>k
</p>
<p>k
= 1
</p>
<p>2c
</p>
<p>&sum;
</p>
<p>kÏ
</p>
<p>(
</p>
<p>p2kÏ + Ï2q2kÏ
) k
</p>
<p>k
,
</p>
<p>(5.43)
</p>
<p>where the last two equalities derive from (5.37, 5.38, 5.40). One notes from (5.43)
that the momentum of the electromagnetic field is the sum of individual momenta,
each related to a single degree of freedom. The modulus of the individual momentum
is equal to the energyWkÏ pertaining to the same degree of freedom divided by c. The
same relation between momentum and energy has been derived in Sect. 3.13.7 with
reference to the dynamic relations of Special Relativity. Each summand in (5.43)
is constant in time, so the electromagnetic momentum is conserved; as noted in
Sects. 5.6, 5.11.4, this is due to the periodicity of the Poynting vector.
</p>
<p>5.8 Modes of the Electromagnetic Field in an Infinite Domain
</p>
<p>The treatment of Sects. 5.5, 5.6, 5.7 is extended to the case of an infinite domain by
means of the Fourier transform (Sect. C.2)1
</p>
<p>A =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
bk
</p>
<p>exp (i k &middot; r)
(2Ï )3/2
</p>
<p>d3k, bk =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
A
</p>
<p>exp ( &minus; i k &middot; r)
(2Ï )3/2
</p>
<p>d3r. (5.44)
</p>
<p>where bk = b(k, t) is complex, with b&minus;k = b&lowast;k, and the components of the wave
vector k are continuous. Relations of the same form as (5.29) hold for bk, yielding
</p>
<p>bk = sÌk + sÌ&lowast;&minus;k, sÌk(t) = dk exp ( &minus; iÏ t), k ï¿½= 0. (5.45)
</p>
<p>where the complex vector dk depend on k only and lies on the plane normal to it.
Relations similar to (5.30, 5.31, 5.32) hold as well, where ck and sk are replaced
with dk and sÌk, respectively, and the sum is suitably replaced with an integral over
k. To determine the energy of the electromagnetic field one must integrate over the
whole space the energy density wem. Using (C.56) and the second relation in (5.45)
one finds
</p>
<p>Wem =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
wem d
</p>
<p>3r = 2 Îµ0
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ï2 dk &middot; d&lowast;k d3k. (5.46)
</p>
<p>1 For the existence of (5.44) it is implied that the three-dimensional equivalent of condition (C.19)
holds.</p>
<p/>
</div>
<div class="page"><p/>
<p>5.9 Eikonal Equation 97
</p>
<p>It is sometimes useful to consider the frequency distribution of the integrand at the
right hand side of (5.46). For this one converts the integral into spherical coordinates
k,Ï , Î³ and uses the relation k = Ï/c = 2Ï Î½/c to obtain dk = d(Î½,Ï , Î³ ); then,
from (B.3),
</p>
<p>Wem =
&int; +&infin;
</p>
<p>&minus;&infin;
Uem(Î½) dÎ½, Uem =
</p>
<p>2 Îµ0
c2
</p>
<p>(2Ï Î½)4
&int; Ï
</p>
<p>0
</p>
<p>&int; 2Ï
</p>
<p>0
|d|2 sin Ï dÏ dÎ³ ,
</p>
<p>(5.47)
</p>
<p>whereUem (whose units are J s) is called spectral energy of the electromagnetic field.
By a similar procedure one finds the total momentum, that reads
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>S
</p>
<p>c2
d3r = 2 Îµ0
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ï |d|2 k d3k. (5.48)
</p>
<p>5.9 Eikonal Equation
</p>
<p>Consider the case of a monochromatic electromagnetic field with angular frequency
Ï. For the calculation in hand it is convenient to consider the Maxwell equations in
complex form; specifically, rotH = &part;D/&part;t yields, in vacuo,
</p>
<p>&real;
[
</p>
<p>(rotHc + iÏ Îµ0 Ec) exp ( &minus; iÏ t)
]
</p>
<p>= 0, (5.49)
while rotE = &minus;&part;B/&part;t yields
</p>
<p>&real;
[
</p>
<p>(rotEc &minus; iÏÎ¼0 Hc) exp ( &minus; iÏ t)
]
</p>
<p>= 0. (5.50)
The solution of (5.49, 5.50) has the form Ec = Ec0 exp (i k&middot;r), Hc = Hc0 exp (i k&middot;r),
with Ec0, Hc0 = const, i.e., a planar wave propagating along the direction of k. In a
non-uniform medium it is Îµ = Îµ(r), Î¼ = Î¼(r), and the form of the solution differs
from the planar wave. The latter can tentatively be generalized as
</p>
<p>Ec = Ec0 (r) exp [i k S(r)], Hc = Hc0(r) exp [i k S(r)], (5.51)
with k = Ï&radic;Îµ0 Î¼0 = Ï/c. Function k S is called eikonal ([S] = m). Replacing
(5.51) into (5.49, 5.50) and using the first identity in (A.35) yields
</p>
<p>gradS &and; Hc0 + c Îµ Ec0 = &minus;
c
</p>
<p>iÏ
rotHc0, (5.52)
</p>
<p>gradS &and; Ec0 &minus; c Î¼Hc0 = &minus;
c
</p>
<p>iÏ
rotEc0. (5.53)
</p>
<p>Now it is assumed that Ï is large enough to make the right hand side of (5.52,
5.53) negligible; in this case gradS, Ec0, Hc0 become normal to each other. Vector
multiplying (5.52) by gradS and using (5.53) then yields
</p>
<p>gradS &and; (gradS &and; Hc0)+
Îµ Î¼
</p>
<p>Îµ0 Î¼0
Hc0 = 0. (5.54)</p>
<p/>
</div>
<div class="page"><p/>
<p>98 5 Applications of the Concepts of Electromagnetism
</p>
<p>Remembering that c = 1/&radic;Îµ0 Î¼0 one defines the phase velocity, refraction index,
and wavelength of the medium as
</p>
<p>uf (r) =
1&radic;
Îµ Î¼
</p>
<p>, n(r) = c
uf
</p>
<p>, Î»(r) = uf
Î½
</p>
<p>, (5.55)
</p>
<p>respectively, so that Îµ Î¼/(Îµ0 Î¼0) = n2. Using the first identity in (A.33) and remem-
bering that gradS &middot; Hc0 = 0 transforms (5.54) into (|gradS|2 &minus; n2) Hc0 = 0. As
Hc0 ï¿½= 0 it follows
</p>
<p>|gradS|2 = n2, n = n(r), (5.56)
</p>
<p>that is, a partial-differential equation, called eikonal equation, in the unknown S. The
equation has been derived in the hypothesis that Ï = 2ÏÎ½ is large, hence Î» = uf /Î½
is small; it is shown below that this condition is also described by stating that Ec0(r),
Hc0(r), and S(r) vary little over a distance of the order of Î».
</p>
<p>The form of (5.51) is such that S(r) = const defines the constant-phase surface
(the same concept has been encountered in Sect. 2.5 for the case of a system of
particles). It follows that the normal direction at each point r of the surface is that of
gradS. Let t = dr/ds be the unit vector parallel to gradS in the direction of increasing
S. A ray is defined as the envelope of the t vectors, taken starting from a point A in
a given direction. The description of rays obtained through the approximation of the
eikonal equation is called Geometrical Optics.
</p>
<p>The eikonal equation (5.56) can be given a different form by observing that from
the definition of t it follows gradS = n t and t &middot; gradS = dS/ds = n, whence
</p>
<p>gradn = grad dS
ds
</p>
<p>= dgradS
ds
</p>
<p>= d (nt)
ds
</p>
<p>= d
ds
</p>
<p>(
</p>
<p>n
dr
</p>
<p>ds
</p>
<p>)
</p>
<p>. (5.57)
</p>
<p>This form of the eikonal equation is more often used. It shows that the equation is
of the second order in the unknown function r(s), where r is the point of the ray
corresponding to the curvilinear abscissa s along the ray itself. The equation&rsquo;s coef-
ficient and data are given by the refraction index n. As the equation is of the second
order, two boundary conditions are necessary to completely define the solution; for
instance, the value of r(s = 0) corresponding to the initial point A, and the direction
t = dr/ds of the ray at the same point. Remembering that dt/ds = n/Ïc, where
Ïc is the curvature radius of the ray at r, and n the principal normal unit vector,
the eikonal equation may also be recast as gradn = (dn/ds) t + (n/Ïc) n. Using the
curvature radius one can specify in a quantitative manner the approximation upon
which the eikonal equation is based; in fact, for the approximation to hold it is
necessary that the electromagnetic wave can be considered planar, namely, that its
amplitude and direction do not significantly change over a distance of the order of
Î». This happens if at each point r along the ray it is Ïc â« Î».</p>
<p/>
</div>
<div class="page"><p/>
<p>5.11 Problems 99
</p>
<p>5.10 Fermat Principle
</p>
<p>It is worth investigating whether the eikonal equation (5.57) worked out in Sect. 5.9
is derivable from a variational principle. In fact it is shown below that the Fermat (or
least time) principle holds, stating that, if A and B are two different points belonging
to a ray, the natural ray (that is, the actual path followed by the radiation between
the given points) is the one that minimizes the time
</p>
<p>&int;
</p>
<p>AB
dt . The principle thus reads
</p>
<p>Î´
</p>
<p>&int;
</p>
<p>AB
</p>
<p>dt = 0, (5.58)
</p>
<p>where the integral is carried out along the trajectory. The analysis is similar to that
carried out in Sect. 2.7 with reference to the Maupertuis principle.
</p>
<p>Using the relations (5.55) and observing that dt = ds/uf = n ds/c transforms
(5.58) into Î´
</p>
<p>&int;
</p>
<p>AB
n ds = 0. Introducing a parametric description r = r(Î¾ ) of the ray,
</p>
<p>with Î¾ = a when r = A and Î¾ = b when r = B, yields
&int;
</p>
<p>AB
</p>
<p>n ds =
&int; b
</p>
<p>a
</p>
<p>g dÎ¾ , g = n ds
dÎ¾
</p>
<p>= n(x1, x2, x3)
&radic;
</p>
<p>xÌ21 + xÌ22 + xÌ23 , (5.59)
</p>
<p>&part;g
</p>
<p>&part;xÌi
= n 2xÌi
</p>
<p>2 ds/dÎ¾
= n dxi
</p>
<p>ds
,
</p>
<p>&part;g
</p>
<p>&part;xi
= &part;n
</p>
<p>&part;xi
</p>
<p>ds
</p>
<p>dÎ¾
. (5.60)
</p>
<p>Remembering (1.7), the Euler equation for the ith coordinate reads
</p>
<p>d
</p>
<p>dÎ¾
</p>
<p>(
</p>
<p>n
dxi
ds
</p>
<p>)
</p>
<p>= &part;n
&part;xi
</p>
<p>ds
</p>
<p>dÎ¾
, i = 1, 2, 3, (5.61)
</p>
<p>whence
</p>
<p>d
</p>
<p>ds
</p>
<p>(
</p>
<p>n
dxi
ds
</p>
<p>)
</p>
<p>= &part;n
&part;xi
</p>
<p>. (5.62)
</p>
<p>As (5.62) is the ith component of the eikonal equation (5.57), such an equation is in-
deed derivable from the variational principle (5.58). Some comments about the formal
analogy between the Maupertuis and Fermat principles are made in Sect. 5.11.6.
</p>
<p>5.11 Complements
</p>
<p>5.11.1 Fields Generated by a Point-Like Charge
</p>
<p>The Li&eacute;nard and Wiechert expressions (5.6, 5.7) provide the potentials generated in
r at time t by a point-like charge that follows a trajectory s. More specifically, if
s = s(Ï ) is the position occupied by the charge at the instant Ï , and r is the position</p>
<p/>
</div>
<div class="page"><p/>
<p>100 5 Applications of the Concepts of Electromagnetism
</p>
<p>where the potentials produced by the charge are detected at time t &gt; Ï , the relation
(5.4) holds, namely, |r &minus; s(Ï )| = c (t &minus; Ï ), that links the spatial coordinates with the
time instants. Letting
</p>
<p>g = r &minus; s(Ï ), g = |g|, u = ds
dÏ
</p>
<p>, uÌ = du
dÏ
</p>
<p>, (5.63)
</p>
<p>the fields E, B are determined by applying (4.26) to (5.6, 5.7), which amounts
to calculating the derivatives with respect to t and the components of r. This is
somewhat complicated because (4.26) introduces a relation of the form Ï = Ï (r, t),
so that Ï = Ï(r, Ï (r, t)) and A = A(r, Ï (r, t)). It is therefore convenient to calculate
some intermediate steps first. To this purpose, (5.4) is recast in implicit form as
</p>
<p>Ï (x1, x2, x3, t , Ï ) =
[
</p>
<p>3
&sum;
</p>
<p>i=1
(xi &minus; si(Ï ))2
</p>
<p>]1/2
</p>
<p>+ c (Ï &minus; t) = 0, (5.64)
</p>
<p>whence gradÏ = g/g, &part;Ï/&part;t = &minus;c, &part;Ï/&part;Ï = c &minus; u &middot; g/g. The differentiation rule
of the implicit functions then yields
</p>
<p>&part;Ï
</p>
<p>&part;t
= &minus; &part;Ï/&part;t
</p>
<p>&part;Ï/&part;Ï
= c
</p>
<p>c &minus; u &middot; g/g (5.65)
</p>
<p>Basing on (5.64, 5.65) and following the calculation scheme reported, e.g., in [96,
Chap. 6] one obtains
</p>
<p>E = e (&part;Ï/&part;t)
3
</p>
<p>4Ï Îµ0 g3
</p>
<p>{(
</p>
<p>1 &minus; u
2
</p>
<p>c2
</p>
<p>)
(
</p>
<p>g &minus; g u
c
</p>
<p>)
</p>
<p>+ g &and;
[
(
</p>
<p>g &minus; g u
c
</p>
<p>)
</p>
<p>&and; uÌ
c2
</p>
<p>]}
</p>
<p>, (5.66)
</p>
<p>B = g
g
&and; E
</p>
<p>c
. (5.67)
</p>
<p>This result shows that E and B are the sum of two terms, the first of which decays
at infinity like g&minus;2, while the second decays like g&minus;1. The latter term differs from
zero only if the charge is accelerated (uÌ ï¿½= 0); its contribution is called radiation
field. Also, E and B are orthogonal to each other, while g is orthogonal to B but not
to E; however, if g is large enough to make the second term in (5.66) dominant, g
becomes orthogonal also to E and (5.67) yields B = E/c. In the case u = 0 the
relations (5.66, 5.67) simplify to
</p>
<p>E = e
4Ï Îµ0 g2
</p>
<p>g
</p>
<p>g
, B = 0, (5.68)
</p>
<p>that hold approximately also for u = const, u/c âª 1.</p>
<p/>
</div>
<div class="page"><p/>
<p>5.11 Complements 101
</p>
<p>5.11.2 Power Radiated by a Point-Like Charge
</p>
<p>The expressions of the E and B fields worked out in Sect. 5.11.1 are readily exploited
to determine the power radiated by a point-like charge. Remembering the results of
Sect. 5.3, it suffices to integrate the Poynting vector over a surface ï¿½ surrounding the
charge. Introducing (5.67) into the definition (5.11) of Poynting&rsquo;s vector and using
the first identity in (A.33) yields
</p>
<p>S = 1
Î¼0 c
</p>
<p>E &and;
(
</p>
<p>g
</p>
<p>g
&and; E
</p>
<p>)
</p>
<p>= Îµ0 c
g
</p>
<p>(
</p>
<p>E2 g &minus; E &middot; g E
)
</p>
<p>. (5.69)
</p>
<p>The case uÌ ï¿½= 0, u/c âª 1 is considered, which is typical of a bound particle. As the
surfaceï¿½ can be chosen arbitrarily, it is convenient to select it at a large distance from
the charge in order to make the second term in (5.66) dominant and E practically
normal to g. This simplifies (5.66) and (5.69) to
</p>
<p>S â Îµ0 c E2
g
</p>
<p>g
, E â e
</p>
<p>4Ï Îµ0 g
</p>
<p>(
g
</p>
<p>g
&middot; uÌ
c2
</p>
<p>g
</p>
<p>g
&minus; uÌ
</p>
<p>c2
</p>
<p>)
</p>
<p>, (5.70)
</p>
<p>where the first identity in (A.33) has been used. Letting Ï be the angle between g
and uÌ, one combines the two expressions in (5.70) to find
</p>
<p>S â Îµ0 cE &middot; E
g
</p>
<p>g
= 1
</p>
<p>4Ï Îµ0
</p>
<p>e2 uÌ2
</p>
<p>4Ï c3
sin2 Ï
</p>
<p>g2
</p>
<p>g
</p>
<p>g
. (5.71)
</p>
<p>To proceed one chooses for ï¿½ a spherical surface centered at s(Ï ) and shifts the
origin to its center. This yields g = r at time Ï , whence the unit vector normal
to ï¿½ becomes n = g/g. The radiation emitted by the charge reaches ï¿½ at a later
time t = Ï + g/c; however, thanks to the hypothesis u/c âª 1, during the interval
t &minus; Ï the charge moves little with respect to center of the sphere. For this reason,
the surface integral can be calculated by keeping the charge fixed in the center of
the spherical surface, so that the integral
</p>
<p>&int;
</p>
<p>ï¿½
( sin2 Ï/g2) dï¿½ must be evaluated with
</p>
<p>g = const. Such an integral is easily found to equal 8Ï/3: first, one turns to spherical
coordinates and expresses the volume element as J dÏ dÏ dg = dï¿½ dg; then, one
finds from (B.3) the ratio dï¿½/g2 = sin Ï dÎ¸ dÏ and replaces it in the integral. In
conclusion, combining the above result with (5.12, 5.71),
</p>
<p>&minus;d(W +Wem)
dt
</p>
<p>= 1
4Ï Îµ0
</p>
<p>e2 uÌ2
</p>
<p>4Ï c3
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>sin2 Ï
</p>
<p>g2
n &middot; n dï¿½ = 2 e
</p>
<p>2/3
</p>
<p>4Ï Îµ0 c3
uÌ2. (5.72)
</p>
<p>The expression at the right hand side of (5.72), called Larmor formula, gives an
approximate expression of the power emitted by a point-like charge, that is appli-
cable when u/c âª 1. As shown by the left hand side, part of the emitted power
(&minus;dW/dt) is due to the variation in the charge&rsquo;s mechanical energy, while the other
part (&minus;dWem/dt) is due to the variation in the electromagnetic energy within the
volume enclosed by ï¿½.</p>
<p/>
</div>
<div class="page"><p/>
<p>102 5 Applications of the Concepts of Electromagnetism
</p>
<p>5.11.3 Decay of Atoms According to the Classical Model
</p>
<p>The power radiated by a point-like charge has been determined in Sect. 5.11.2 under
the approximations uÌ ï¿½= 0, u/c âª 1, typical of a bound particle. The radiated
power (5.72) is proportional to the square of the particle&rsquo;s acceleration: this result
is of a paramount importance, because it shows that the so-called planetary model
of the atom is not stable. Considering for instance the simple case of hydrogen,
the model describes the atom as a planetary system whose nucleus is fixed in the
reference&rsquo;s origin while the electron orbits around it. If no power were emitted the
motion&rsquo;s description would be that given, e.g., in Sect. 3.13.6, where the Hamiltonian
function is a constant of motion. In other terms, the total energy would be conserved.
In fact, in the planetary motion the electron&rsquo;s acceleration, hence the emitted power,
differ from zero; the emission produces an energy loss which was not considered in
the analysis of Sect. 3.13.6. Some comments about this problem were anticipated in
Sect. 3.13.9.
</p>
<p>To proceed it is useful to carry out a quantitative estimate of the emitted power.
The outcome of it is that in the case of a bound electron the emission is relatively
weak, so that one can consider it as a perturbation with respect to the conservative
case analyzed in Sect. 3.13.6. The estimate starts from the experimental observation
of the emission of electromagnetic radiation by excited atoms; here the datum that
matters is the minimum angular frequency Ï0 of the emitted radiation, which is
found to be in the range [1015, 1016] rad s&minus;1. The simplest model for describing the
unperturbed electron&rsquo;s motion is that of the linear harmonic oscillator [4, Vol. II,
Sect. 4]
</p>
<p>s(Ï ) = s0 cos (Ï0Ï ), (5.73)
</p>
<p>with s0 = |s0| the maximum elongation with respect to the origin, where the nucleus
is placed. Equation (5.73) may be thought of as describing the projection over the di-
rection of s0 of the instantaneous position of an electron that follows a circular orbit.
The product e s is called electric dipole moment of the oscillator. Other experimental
results, relative to the measure of the atom&rsquo;s size, show that s0 is of the order of
10&minus;10 m so that, calculating u = ds/dÏ = &minus;s0 Ï0 sin (Ï0Ï ) from (5.73) and let-
ting Ï0 = 5 &times; 1015, one finds u/c &le; s0 Ï0/c â 2 &times; 10&minus;3. This shows that the
approximations of Sect. 5.11.2 are applicable.
</p>
<p>It is worth noting that the type of motion (5.73) is energy conserving, hence it must
be understood as describing the unperturbed dynamics of the electron. Remembering
the discussion of Sect. 3.3 one finds for the total, unperturbed energy the expression
Eu = mÏ20 s20/2, with m = 9.11 &times; 10&minus;31 kg the electron mass. To tackle the pertur-
bative calculation it is now necessary to estimate the energy Er lost by the electron
during an oscillation period 2Ï/Ï0 and compare it withEu. From uÌ = du/dÏ = Ï20 s
one obtains the maximum square modulus of the electron&rsquo;s acceleration, uÌ2M = Ï40 s20 ;
inserting the latter into (5.72) and using e = &minus;q = &minus;1.602&times;10&minus;19 C for the electron</p>
<p/>
</div>
<div class="page"><p/>
<p>5.11 Complements 103
</p>
<p>charge provides the upper bounds
</p>
<p>Er &le;
2Ï
</p>
<p>Ï0
</p>
<p>2 e2/3
</p>
<p>4Ï Îµ0 c3
Ï40 s
</p>
<p>2
0 =
</p>
<p>e2 s20 Ï
3
0
</p>
<p>3 Îµ0 c3
,
</p>
<p>Er
</p>
<p>Eu
&le; 2 e
</p>
<p>2Ï0
</p>
<p>Îµ0 mc3
â 4 &times; 10&minus;7. (5.74)
</p>
<p>This result shows that the energy lost during an oscillation period is indeed small,
so that the electron&rsquo;s motion is only slightly perturbed with respect to the periodic
case. The equation of motion of the perturbed case can now tentatively be written as
</p>
<p>m sÌ +mÏ20 s = Fr , (5.75)
</p>
<p>where Fr is a yet unknown force that accounts for the emitted power. A scalar
multiplication of (5.75) by u yields m u &middot; uÌ + mÏ20 s &middot; u = dW/dÏ = u &middot; Fr , with
W = (m/2) (u2 + Ï20 s2). One notes that W has the same expression as the total
energy Eu of the unperturbed case; however, W is not conserved due to the presence
of Fr ï¿½= 0 at the right hand side. In fact, &minus;dW/dÏ = &minus;u &middot; Fr &gt; 0 is the power
emitted by the electron, and its time average over 2Ï/Ï0,
</p>
<p>&minus;ãu &middot; Frã = &minus;
Ï0
</p>
<p>2Ï
</p>
<p>&int; 2Ï/Ï0
</p>
<p>0
u &middot; Fr dÏ &gt; 0, (5.76)
</p>
<p>is the variation in the oscillator&rsquo;s energy during a period; a part of it crosses the
surface ï¿½, while the other part is the variation in the electromagnetic energy within
ï¿½ (Sects. 5.3 and 5.11.2). The part that crossesï¿½ is the time average of (5.72);2 for the
sake of simplicity it is assumed that it is dominant with respect to the other one. The
factor uÌ2 that appears in (5.72) is worked out by taking the time average of the identity
d(u &middot; uÌ)/dÏ = uÌ2 +u &middot; uÌ and observing that ãd(u &middot; uÌ)/dÏ ã is negligibly small, whence
ãuÌ2ã = &minus;ãu&middot;uÌã &gt; 0. In conclusion, defining a time Ï0 such that e2/(6Ï Îµ0 c3) = mÏ0
and equating (5.76) to the time average of (5.72) yields ãu &middot;mÏ0 uÌã = ãu &middot; Frã. It is
found Ï0 â 6 &times; 10&minus;24 s.
</p>
<p>As a crude approximation one finally converts the equality of the averages just
found into an equality of the arguments, whence Fr â mÏ0 uÌ. Replacing the latter
into (5.75) yields sÌ + Ï20 s = Ï0 uÌ, that is, a linear, homogeneous equation of the
third order in s with constant coefficients. The equation is solved by letting s =
s(Ï = 0) exp (Î± Ï ) cos (Ï Ï ), with Î±, Ï undetermined. Using the tentative solution
provides the system of characteristic algebraic equations
</p>
<p>Ï0 Ï
2 = 3 Ï0 Î±2 &minus; 2 Î±, Î±2 + Ï20 = Ï0 Î±3 + (1 &minus; 3 Ï0 Î±) Ï2, (5.77)
</p>
<p>whence the elimination of Ï2 yields 8Î±2 &minus; 2 Î±/Ï0 &minus; Ï20 = 8 Ï0Î±3. Thanks to the
smallness of Ï0 the latter equation may be solved by successive approximations
starting from the zeroth-order solution Î±(0) â &minus;Ï0 Ï20/2 (this solution is found by
</p>
<p>2 Remembering the discussion of Sect. 5.11.2, the use of (5.72) implies that the particle&rsquo;s position
departs little from the center of the spherical surface. Thus the radius of ï¿½ must be much larger
than the size of the atom.</p>
<p/>
</div>
<div class="page"><p/>
<p>104 5 Applications of the Concepts of Electromagnetism
</p>
<p>solving 8Î±2 &minus; 2 Î±/Ï0 &minus; Ï20 = 0 and using the binomial approximation; the other
possible value of Î±(0) is positive and must be discarded to prevent s from diverging).
Replacing Î±(0) into the first equation in (5.77) yields Ï2 = Ï20 (1+ 3 Ï 20 Ï20/4) â Ï20.
In conclusion, the zeroth-order solution of the differential equation for s reads
</p>
<p>s(Ï ) â s(Ï = 0) cos (Ï0 Ï ) exp ( &minus; Ï0 Ï20 Ï/2). (5.78)
</p>
<p>Basing upon (5.78) one can identify the decay time of the atom with the time necessary
for the modulus of s to reduce by a factor 1/e with respect to the initial value. The
decay time is thus found to be 2/(Ï0 Ï20) â 13 &times; 10&minus;9 s. As the ratio of the decay
time to the period 2Ï/Ï0 is about 107, the perturbative approach is indeed justified.
</p>
<p>As anticipated at the beginning of this section, the planetary model of the atom
is not stable. The approximate solution (5.78) of the electron&rsquo;s dynamics shows that
according to this model the electron would collapse into the nucleus in a very short
time due to the radiation emitted by the electron. This behavior is not observed
experimentally: in fact, the experiments show a different pattern in the energy-
emission or absorption behavior of the atoms. The latter are able to absorb energy
from an external radiation and subsequently release it: an absorption event brings
the atom to a higher-energy state called excited state; the absorbed energy is then
released by radiation in one or more steps (emissions) until, eventually, the atom
reaches the lowest energy state (ground state). However, when the atom is in the
ground state and no external perturbations is present, the atom is stable and no
emission occurs. In conclusion, the experimental evidence shows that the planetary
model is not applicable to the description of atoms.3
</p>
<p>5.11.4 Comments about the Field&rsquo;s Expansion into Modes
</p>
<p>The homogeneous wave equation (5.20) used in Sects. 5.5, 5.8 as a starting point
for the derivation of the field&rsquo;s expansion into modes is based on the hypothesis
that a gauge transformation exists such that Ï = 0. In turn, (5.20) derives from
(5.19), that implies the Coulomb gauge divA = 0. To show that these conditions
are mutually compatible one chooses f in (4.30) such that Ï&prime; = 0, whence E&prime; =
&minus;&part;A&prime;/&part;t due to the second relation in (4.26). In a charge-free space it is divD&prime; =
Îµ0 divE&prime; = 0; it follows &part;divA&prime;/&part;t = 0, namely, divA&prime; does not depend on time.
The second equation in (4.19) with J = 0 yields (1/c2) &part;E&prime;/&part;t = rotB&prime;, so that
&minus;(1/c2) &part;2A&prime;/&part;t2 = rotrotA&prime;. Now let A&prime; = A&prime;&prime; + gradg, where g is an arbitrary
function of the coordinates only; the second identity in (A.35) and the first identity in
(A.36) then yield &minus;(1/c2) &part;2A&prime;&prime;/&part;t2 = graddivA&prime;&prime; &minus; &nabla;2A&prime;&prime;, with divA&prime;&prime; = divA&prime; &minus;
</p>
<p>3 In this respect one might argue that the inconsistency between calculation and experiment is due
to some flaw in the electromagnetic equations. However, other sets of experiments show that it is
not the case.</p>
<p/>
</div>
<div class="page"><p/>
<p>5.11 Complements 105
</p>
<p>&nabla;2g. Choosing g such that divA&prime;&prime; = 0 and dropping the double apex finally yields
(5.20) [68, Sect. 46].
</p>
<p>The vector potential A has been expressed in (5.21) as a Fourier series and in (5.44)
as a Fourier integral. Such expressions produce a separation of the spatial coordinates
from the time coordinate: the former appear only in the terms exp (i k &middot; r), while the
latter appears only in the terms ak and, respectively, bk.
</p>
<p>The Fourier series (5.21) applies to the case of a finite domain of the form shown
in Fig. 5.1 and prescribes the spatial periodicity of A at all times. By way of example,
let 0 &le; x2 &le; d2, 0 &le; x3 &le; d3 and consider the point rA = x2 i2+x3 i3; then, consider
a second point rB = d1 i1 + x2 i2 + x3 i3. By construction, rA and rB belong to two
opposite faces of the domain of Fig. 5.1 and are aligned with each other in the x1
direction. From (5.22) one obtains for any k
</p>
<p>exp (i k &middot; rB) = exp (i 2Ï n1) exp (i k &middot; rA) = exp (i k &middot; rA) (5.79)
</p>
<p>which, combined with (5.21), yields A(rB , t) = A(rA, t). Clearly an equality of
this form is found for any pair of opposite boundary points that are aligned along the
coordinate direction normal to the faces where the points lie. On the other hand, such
an equality is a homogeneous relation among the boundary values of the solution of
the differential equation (5.20), namely, it is a homogeneous boundary condition of
the Dirichlet type.
</p>
<p>The reasoning based on (5.79) is applicable also to the expressions (5.31, 5.32) to
yield E(rB , t) = E(rA, t) and B(rB , t) = B(rA, t), namely, the fields have the same
periodicity as A. The Poynting vector S = E &and; H has this property as well, whence
S(rB , t) &middot; nB = &minus;S(rA, t) &middot; nA; in fact, the unit vector n is oriented in the outward
direction with respect to the domain (Sect. 5.3), so that when two opposite faces of V
are considered it is nB = &minus;nA. Using (5.12) with W = 0 shows that dWem/dt = 0
namely, as noted in Sect. 5.6, the electromagnetic energy within V is conserved. The
same reasoning applies to the conservation of the electromagnetic momentum found
in Sect. 5.7. As for the initial condition on A, from (5.21) and (5.29) one derives
A(r, t = 0) = &sum;k (ck + c&lowast;&minus;k) exp (i k &middot; r). It follows that the initial condition is
provided by the vectors ck.
</p>
<p>5.11.5 Finiteness of the Total Energy
</p>
<p>The differential equation (5.20) is linear and homogeneous with respect to the un-
known A; when the Fourier series (5.21) is replaced in it, the resulting equation (5.28)
is linear and homogeneous with respect to ak, hence (due to (5.29)) with respect to sk
and ck as well. It follows that the fields (5.31, 5.32) are linear and homogeneous func-
tions of these quantities. The same applies in the case of an infinite domain (Sect. 5.8),
in which the fields E, B are linear and homogeneous functions of sÌk and dk.
</p>
<p>In turn, the energy density wem of the electromagnetic field, given by the second
relation in (5.11), is a quadratic and homogeneous function of the fields; this explains</p>
<p/>
</div>
<div class="page"><p/>
<p>106 5 Applications of the Concepts of Electromagnetism
</p>
<p>why the expressions (5.37) and (5.46) are quadratic and homogeneous functions of
sk, ck or, respectively, sÌk, dk.
</p>
<p>When (5.37) is considered, the energy associated to the individual degree of
freedom is WkÏ = 2 Îµ0 V Ï2 |ckÏ |2; as the sum
</p>
<p>&sum;
</p>
<p>kÏ WkÏ spans all wave vectors,
the factor Ï2 = c2 k2 diverges. On the other hand, the energy of the electromagnetic
field within a finite region of space is finite; this means that the term |ckÏ |2 becomes
vanishingly small as |k| &rarr; &infin;, in such a way as to keep the sum &sum;kÏ WkÏ finite.
The same reasoning applies to the term |dkÏ |2 in (5.46); in this case the finiteness
of the total energy Wem is due to the fact that the vanishing of the fields at infinity
makes the Fourier transform in (5.44) to converge.
</p>
<p>5.11.6 Analogies between Mechanics and Geometrical Optics
</p>
<p>A number of analogies exist between the Maupertuis principle, discussed in Sect. 2.7,
and the Fermat principle discussed in Sect. 5.10. The principles read, respectively,
</p>
<p>Î´
</p>
<p>&int;
</p>
<p>AB
</p>
<p>&radic;
E &minus; V ds = 0, Î´
</p>
<p>&int;
</p>
<p>AB
</p>
<p>n ds = 0, (5.80)
</p>
<p>and the analogies are:
</p>
<p>1. A constant parameter is present, namely, the total energy E on one side, the fre-
quency Î½ on the other side (in fact, the Fermat principle generates the eikonal
equation which, in turn, applies to a monochromatic electromagnetic field,
Sect. 5.9).
</p>
<p>2. Given the constant parameter, the integrand is uniquely defined by a property of
the medium where the physical phenomenon occurs: the potential energy V (r)
and the refraction index n(r), respectively.
</p>
<p>3. The outcome of the calculation is a curve of the three-dimensional space: the
particle&rsquo;s trajectory and the optical ray, respectively. In both cases the initial
conditions are the starting position and direction (in the mechanical case the
initial velocity is obtained by combining the initial direction with the momentum
extracted from E &minus; V ).
</p>
<p>In summary, by a suitable choice of the units, the same concept is applicable to both
mechanical and optical problems. In particular it is used for realizing devices able
to obtain a trajectory or a ray of the desired form: the control of the ray&rsquo;s shape is
achieved by prescribing the refraction index n by means of, e.g., a lens or a system
of lenses; similarly, the trajectory of a particle of charge e is controlled by a set of
electrodes (electrostatic lenses) that prescribe the electric potential Ï = V/e. The
design of electron guns and of the equipments for electron-beam lithography and
ion-beam lithography is based on this analogy.
</p>
<p>It must be emphasized that the Maupertuis principle is derived without approxi-
mations: as shown in Sect. 2.7, the principle is equivalent to Newton&rsquo;s law applied
to a particle of constant energy. The Fermat principle, instead, is equivalent to the</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 107
</p>
<p>eikonal equation; the latter, in turn, is derived from the Maxwell equations in the
hypothesis that at each position along the ray the curvature radius of the ray is much
larger than the wavelength. In other terms, the mechanical principle is exact whereas
the optical principle entails an approximation. If the exact formulation of electro-
magnetism given by the Maxwell equation were used, the analogy discussed here
would be lost.
</p>
<p>The rather surprising asymmetry outlined above could be fixed by speculating that
Newton&rsquo;s law is in fact an approximation deriving from more general laws, possibly
similar to the Maxwell equations. In this case one could identify in such laws a
parameter analogue of the wavelength, and deduce Newton&rsquo;s law as the limiting
case in which the parameter is small. It will be shown later that mechanical laws
more general than Newton&rsquo;s laws indeed exist: they form the object of Quantum
Mechanics.4
</p>
<p>The analogy between Mechanics and Geometrical Optics discussed here is one
of the possible courses of reasoning useful for introducing the quantum-mechanical
concepts; however, in this reasoning the analogy should not be pushed too far. In fact,
one must observe that the Maupertuis principle given by the first expression in (5.80)
provides the non-relativistic form of Newton&rsquo;s law, whereas the Maxwell equations,
of which the Fermat principle is an approximation, are intrinsically relativistic. As
a consequence, the analogy discussed in this section is useful for generalizing the
geometrical properties of the motion, but not the dynamical properties.
</p>
<p>Problems
</p>
<p>5.1 Solve the eikonal equation (5.57) in a medium whose refraction index depends
on one coordinate only, say, n = n(x1).
</p>
<p>5.2 Use the solution of Problem 5.1 to deduce the Descartes law of refraction.
</p>
<p>4 Once Quantum Mechanics is introduced, Newtonian Mechanics is distinguished from it by the
designation Classical Mechanics.</p>
<p/>
</div>
<div class="page"><p/>
<p>Part II
</p>
<p>Introductory Concepts to Statistical
and Quantum Mechanics</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 6
</p>
<p>Classical Distribution Function and Transport
Equation
</p>
<p>6.1 Introduction
</p>
<p>When a system made of a large number of molecules is considered, the description
of the dynamics of each individual member of the system is practically impossible,
and it is necessary to resort to the methods of Statistical Mechanics. The chapter
introduces the concept of distribution function in the phase space and provides the
definition of statistical average (over the phase space and momentum space) of a
dynamical variable. The derivation of the equilibrium distribution in the classical
case follows, leading to the Maxwell&ndash;Boltzmann distribution. The analysis proceeds
with the derivation of the continuity equation in the phase space: the collisionless case
is treated first, followed by the more general case where the collisions are present, this
leading to the Boltzmann Transport Equation. In the Complements, after a discussion
about the condition of a vanishing total momentum and angular momentum in the
equilibrium case, and the derivation of statistical averages based on the Maxwell-
Boltzmann distribution, the Boltzmann H -theorem is introduced. This is followed
by an illustration of the apparent paradoxes brought about by Boltzmann&rsquo;s Transport
Equation and H -theorem: the violation of the symmetry of the laws of mechanics
with respect to time reversal, and the violation of Poincar&eacute;&rsquo;s time recurrence. The
illustration is carried out basing on Kac&rsquo;s ring model. The chapter is completed by
the derivation of the equilibrium limit of the Boltzmann Transport Equation.
</p>
<p>6.2 Distribution Function
</p>
<p>Consider a system made of N identical particles with no constraints. For the sake
of simplicity, point-like particles are assumed, so that the total number of degrees
of freedom is 3N . The dynamics of the j th particle is described by the canonical
</p>
<p>&copy; Springer Science+Business Media New York 2015 111
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_6</p>
<p/>
</div>
<div class="page"><p/>
<p>112 6 Classical Distribution Function and Transport Equation
</p>
<p>coordinates q1j , q2j , q3j , p1j , p2j , p3j , that belong to the 6-dimensional &micro;-space
introduced in Sect. 1.9.
</p>
<p>If the number of particles is large, the description of the dynamics of each individ-
ual belonging to the system is in fact impossible. For instance, the number density
of air at 20â¦C and 1 atm is about 2.5 &times; 1019 cm&minus;3. Even if the measurement of the
initial conditions were possible, it would not be feasible in practice ([66], Sect. 1).
This problem is present also when the number of particles is much lower than in the
example above.
</p>
<p>The problem is faced by adopting the viewpoint of statistical mechanics, whose
object is not the description of the dynamical behavior of the individual particles
but, rather, that of the distribution of the dynamical properties over the phase space.
To this purpose one identifies each point of the &micro;-space with the pair of vectors
q = (q1, q2, q3), p = (p1,p2,p3) pertaining to it, and considers the elementary
volume dÏ = d3q d3p of the &micro;-space centered at (q, p), with d3q = dq1 dq2 dq3
and the like for d3p. Then, the number of particles dN that at time t belong to dÏ is
given by
</p>
<p>dN = f&micro;(q, p, t) dÏ, (6.1)
</p>
<p>with f&micro; the concentration in the&micro;-space. The procedure here is similar to that carried
out in Sect. 23.2, the difference being that the space considered here is the phase
space instead of the configuration space of Sect. 23.2.1 In both cases, the motion of
the particles is described as that of a continuous fluid: in fact, index j is dropped
from the canonical coordinates, which do not indicate any more a specific particle,
but the center of the elementary cell of the phase space where the concentration f&micro;
is considered. As in Sect. 23.2, this procedure is legitimate if the cells of volume dÏ
into which the phase space is partitioned can be treated as infinitesimal quantities
in the scale of the problem that is being investigated, and the number of particles
within each cell is large enough to make their average properties significant. The
concentration f&micro; is also called distribution function. By definition it fulfills the
normalization condition
</p>
<p>&int;
</p>
<p>f&micro;(q, p, t) dÏ = N , (6.2)
</p>
<p>where the integral is 6-dimensional and extends over the whole&micro;-space. As the order
of integration is immaterial, the calculation can be split into two steps, namely,
</p>
<p>n(q, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
f&micro;(q, p, t) d
</p>
<p>3p, N =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
n(q, t) d3q. (6.3)
</p>
<p>The function n(q, t) defined by the first of (6.3) is the concentration of the particles
in the configuration space.
</p>
<p>1 Note that here the symbol N indicates the number of particles; instead, in Sect. 23.2 the number
of particles is indicated with N , whereas N indicates the concentration.</p>
<p/>
</div>
<div class="page"><p/>
<p>6.3 Statistical Equilibrium 113
</p>
<p>Basing on the distribution function it is possible to define the average of a dynam-
ical function. For the sake of generality the dynamical function is considered to be a
vector that depends on all canonical coordinates and time, say, a = a(q, p, t). Due to
the smallness of the cell size one assumes that the dynamical function takes the same
value for all particles within the same cell. As a consequence, the product a f&micro; dÏ
is the cell value of the function weighed by the number of particles belonging to the
cell. The statistical average of a over the phase space is then
</p>
<p>Av [a](t) = 1
N
</p>
<p>&int;
</p>
<p>a(q, p, t) f&micro;(q, p, t) dÏ, (6.4)
</p>
<p>where the integral is 6-dimensional, while the average over the momentum space is
</p>
<p>a(q, t) = 1
n(q, t)
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
a(q, p, t) f&micro;(q, p, t) d
</p>
<p>3p. (6.5)
</p>
<p>Using the expression of N given by (6.2), and that of n given by the first of (6.3),
shows that the definitions (6.4, 6.5) indeed provide the weighed averages of interest.
By way of example, the dynamical function may be identified with the particle
velocity u: using the Cartesian coordinates one finds for the average velocity v in the
configuration space the expression
</p>
<p>v(r, t) = 1
n(r, t)
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u(r, p, t) f&micro;(r, p, t) d
</p>
<p>3p. (6.6)
</p>
<p>Similarly, the average Hamiltonian function in the configuration space reads
</p>
<p>H (r, t) = 1
n(r, t)
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
H (r, p, t) f&micro;(r, p, t) d
</p>
<p>3p. (6.7)
</p>
<p>6.3 Statistical Equilibrium
</p>
<p>This section deals with the properties of a system of particles in a condition of macro-
scopic equilibrium. Considering that in general the systems that are considered are
composed of a large number of particles or molecules, the statistical concepts in-
troduced in Sect. 6.2 will be used. Generally speaking, the condition of statistical
equilibrium is fulfilled if the distribution function is independent of time. This condi-
tion may be achieved in different ways: for instance, f&micro; = const fulfills the required
condition. A more general definition of a distribution function fulfilling the condi-
tion of statistical equilibrium is f&micro; = f&micro;(c), where c is any constant of motion of
the system. In case of a conservative system, energy is the most natural constant of
motion to be used.
</p>
<p>To proceed, consider a conservative system having a total energy ES , enclosed in
a stationary container of volume ï¿½. Let the walls of the container be such that no
energy flows across them. Also, the container is assumed to be sufficiently massive</p>
<p/>
</div>
<div class="page"><p/>
<p>114 6 Classical Distribution Function and Transport Equation
</p>
<p>so that it can be regarded as stationary despite the transfer of kinetic energy due to
the molecules&rsquo; collisions with the walls. If any external force acts on the molecules,
it is assumed to be independent of time and conservative ([110], Sect. 26). Finally,
the total momentum and angular momentum of the system are assumed to vanish;
this condition is by no means obvious and requires some reasoning, as detailed in
Sect. 6.6.1.
</p>
<p>So far it has not been explicitly indicated whether the molecules that form the
system are identical to each other or not; in the practical cases it is to be expected
that the system under consideration be made of a mixture of different atoms or
molecules. As the extension to a mixture is straightforward ([110], Sect. 30), the
analysis is limited here to a system made of identical molecules. It should be noted
that the molecules are identical, but distinguishable from each other: from the point
of view of Classical Mechanics a continuous observation of the trajectory of each
molecule is in fact possible, without disturbing its motion. As a consequence, systems
that differ by the exchange of two molecules are to be considered as different from
each other.
</p>
<p>To proceed one assumes that the number of molecules forming the system is
N , and that each molecule has R degrees of freedom. The canonical coordinates
that describe the motion of a single molecule are then q1, . . . , qR , p1, . . . ,pR , so
that the number of dimensions of the &micro;-space is 2R. As anticipated in Sect. 6.2,
the description of the precise state of each molecule is impossible in practice; the
state of the system will then be specified in a somewhat less precise manner, as
detailed below. First, each q axis of the &micro;-space is divided into equal intervals of
size ï¿½q1, . . . ,ï¿½qR and, similarly, each p axis is divided into equal intervals of size
ï¿½p1, . . . ,ï¿½pR . As a consequence, the &micro;-space is partitioned into elements, called
cells, whose volume and units are, respectively,
</p>
<p>ï¿½M = (ï¿½q1 ï¿½p1) . . . (ï¿½qR ï¿½pR), [ï¿½M] = (J s)R. (6.8)
</p>
<p>The partitioning of the &micro;-space into cells has the advantage, first, that the set of
cells is countable. Besides that, the partitioning into cells of finite size has a deeper
meaning, that becomes apparent when the theory outlined in this section is extended
to the quantum-mechanical case. In fact, due to the Heisenberg uncertainty relation
(Sect. 10.6), the precision by which two conjugate variables can simultaneously be
known is limited, so that each product ï¿½qi ï¿½pi in (6.8) is bounded below, the bound
being of the order of the Planck constant.
</p>
<p>After the partitioning is accomplished, the state of the system is assigned by
specifying the numbers N1,N2, . . . &ge; 0 of molecules that belong, respectively, to the
cell labeled 1, 2, . . . ; such numbers are subjected to the constraintN1+N2+. . . = N
which, in view of the calculations that follow, is more conveniently expressed as
</p>
<p>FN (N1,N2, . . . ) = 0, FN = N &minus;
&sum;
</p>
<p>i
</p>
<p>Ni . (6.9)
</p>
<p>The sum in (6.9) may be thought of as extending to all cells, due to the fact that
only in a finite number of cases the cell population Ni differs from zero. Clearly,</p>
<p/>
</div>
<div class="page"><p/>
<p>6.3 Statistical Equilibrium 115
</p>
<p>the description using the numbers N1,N2, . . . is less precise than that given by
the molecules&rsquo; trajectories, and provides a partial specification of the state of each
molecule within the limits of the size of ï¿½M . This means, among other things, that
identical molecules belonging to different cells are distinguishable from each other,
whereas identical molecules belonging to the same cell are not distinguishable.
</p>
<p>As mentioned above, the total energy of the system isES , which provides a second
constraint to be vested with mathematical form. It is provisionally assumed that the
system is dilute, namely, that the energy of the interaction among the molecules is
negligible. It follows that one can approximately assign to each molecule a total
energy that corresponds to its position, momentum, and internal configuration, in
other terms, to the cell where the molecule belongs. Letting the energy corresponding
to the ith cell beEi , the constraint on energy readsN1 E1+N2 E2+. . . = ES , namely,
</p>
<p>FE(N1,N2, . . . ) = 0, FE = ES &minus;
&sum;
</p>
<p>i
</p>
<p>Ni Ei . (6.10)
</p>
<p>The above reasoning does not apply to concentrated systems, where the interaction
energy is strong. However, it can be shown that (6.10) still holds, albeit with a
different interpretation of Ei ([110], Sect. 29). Another observation is that, given
the constraints to which the system is subjected, the set of numbers N1,N2, . . . may
not be unique. It is therefore necessary to extract the set, that actually describes the
system, from a larger number of sets made of all possible sets that are compatible
with the constraints.
</p>
<p>To proceed, letN1,N2, . . . be a set that provides a molecules&rsquo;distribution compat-
ible with the constraints; such a set is called accessible state. It is postulated that no
accessible state is privileged with respect to any other; this is in fact the fundamental
hypothesis of equal a priori probability of the accessible states, upon which Statisti-
cal Mechanics is based ([110], Sect. 23). Remembering that the particles are identical
to each other, any system obtained from the original distribution by exchanging two
molecules is also compatible with the constraints. However, the system resulting
from the exchange of molecules belonging to different cells is different from the
original one because such molecules are distinguishable; in contrast, an exchange
within the same cell does not produce a different system. As the total number of
possible exchanges of N molecules of the system as a whole is N !, and the number
of possible exchanges within the ith cell is Ni !, the total number of different systems
corresponding to a set N1,N2, . . . is
</p>
<p>W (N1,N2, . . . ) =
N !
</p>
<p>N1!N2! . . .
(6.11)
</p>
<p>As time evolves, the interactions among the molecules makes the numbersN1,N2, . . .
to change, so that, if the system is inspected at successive times, it may be found to
belong to different accessible states (as the principles of Classical Mechanics apply
here, such an inspection does not perturb the state of the system); in principle, given
enough time, the system will go through all accessible states. Now, the dependence
of W on N1,N2, . . . is quite strong, so that some accessible states correspond to a</p>
<p/>
</div>
<div class="page"><p/>
<p>116 6 Classical Distribution Function and Transport Equation
</p>
<p>large numberW of systems, others to a much smaller number.2 As no accessible state
is privileged with respect to any other, the majority of inspections carried out onto the
system will provide the accessible state that maximizes W . Such an accessible state
corresponds, by definition, to the condition of statistical equilibrium of the system
under consideration.
</p>
<p>6.4 Maxwell-Boltzmann Distribution
</p>
<p>The analysis carried out in Sect. 6.3 led to the conclusion that the condition of
statistical equilibrium of the system is found by maximizing the expression of W
given by (6.11), under the constraints (6.9) and (6.10). The calculation is based upon
the Lagrange method, that determines the free maximum of an auxiliary function F
embedding the constraints. It is convenient to maximize logW , which is a monotonic
function of W , instead of W itself, so that the auxiliary function reads
</p>
<p>F (N1,N2, . . . ,Î±,Î²) = logW + Î± FN + Î² FE , (6.12)
</p>
<p>where Î±, Î² are the Lagrange multipliers, respectively related to the total number of
molecules and total energy of the system. In a typical system the total number of
molecules and the populations of the majority of non empty cells are very large,3
</p>
<p>so that the Stirling approximation (C.97) is applicable; it follows, after neglecting
terms of the form log
</p>
<p>&radic;
2Ï N and log
</p>
<p>&radic;
2Ï Ni ,
</p>
<p>logW = log (N !) &minus;
&sum;
</p>
<p>i
</p>
<p>log (Ni !) â N log (N ) &minus;N &minus;
&sum;
</p>
<p>i
</p>
<p>Ni log (Ni) +
&sum;
</p>
<p>i
</p>
<p>Ni ,
</p>
<p>(6.13)
</p>
<p>where &minus;N and &sum;i Ni cancel each other due to (6.9). The function to maximize then
becomes F = N log (N ) &minus; &sum;i Ni log (Ni) + Î± FN + Î² FE . Here the property of
Ni of being very large is again of help, because, on account of the fact that a change
of Ni by one unit is negligibly small with respect to Ni itself, in calculating the
maximum one treats the integers Ni as continuous variables. Taking the derivative of
F with respect to, say, Nr , and equating it to zero, yields logNr + 1 = &minus;Î± &minus; Î² Er .
Neglecting the unity at the left hand side eventually yields the Maxwell-Boltzmann
distribution law
</p>
<p>Nr = exp ( &minus; Î± &minus; Î² Er ). (6.14)
</p>
<p>2 This is apparent even if the numbers N1,N2, . . . are much smaller than in realistic systems. Let
for instance N = 8: the combination N1 = 8, N2 = N3 = . . . = 0 yields W = 1, whereas the
combination N2 = N3 = N4 = N5 = 2, N1 = N6 = N7 = . . . = 0 yields W = 2.520. It is
implied that 8E1 = 2 (E2 + E3 + E4 + E5) = ES .
3 The hypothesis that the populations are large is not essential. A more complicate calculation, in
which such a hypothesis is not present, leads to the same result [22].</p>
<p/>
</div>
<div class="page"><p/>
<p>6.4 Maxwell-Boltzmann Distribution 117
</p>
<p>The Lagrange multipliers are then determined from (6.9, 6.10); the first one yields
</p>
<p>&sum;
</p>
<p>r
</p>
<p>exp ( &minus; Î± &minus; Î² Er ) = N , N exp (Î±) =
&sum;
</p>
<p>r
</p>
<p>exp ( &minus; Î² Er ) = Z, (6.15)
</p>
<p>whereZ denotes the partition function.4. Extracting exp (Î±) from (6.15) and replacing
it into (6.10) provides the relation
</p>
<p>ES
</p>
<p>N
= 1
</p>
<p>Z
</p>
<p>&sum;
</p>
<p>r
</p>
<p>Er exp ( &minus; Î² Er ) = &minus;
&part;
</p>
<p>&part;Î²
logZ, (6.16)
</p>
<p>with Î² the only unknown. This procedure is able to express Î² and, consequently,
Î±, in terms of the dynamical properties of the molecules. A different method to
determine the parameters, that relates them with macroscopic quantities typical of
Thermodynamics, like pressure and temperature, is shown in the following. First,
one introduces a constant C such that
</p>
<p>CN ï¿½M = exp ( &minus; Î±), (6.17)
</p>
<p>where ï¿½M is given by (6.8). After replacing (6.17) in (6.14), the cell&rsquo;s volume
ï¿½M is made smaller and smaller so that, after dropping index r , (6.14) is recast in
differential form as
</p>
<p>dN = C N exp ( &minus; Î²E) dM , 1
C
</p>
<p>=
&int;
</p>
<p>exp ( &minus; Î²E) dM , (6.18)
</p>
<p>where the integral is extended over the&micro;-space and energyE is expressed in terms of
the 2R coordinates q1, . . . , qR ,p1, . . . ,pR . The nature of the system is now specified
as that of a monatomic gas of mass m, described by the Cartesian coordinates xi and
conjugate momenta pi . Integrating (6.18) over the container&rsquo;s volume ï¿½ yields the
number dNp of atoms belonging to the elementary volume of the momentum space.
As the gas is assumed to be dilute, the energy in (6.18) is substantially of the kinetic
type,
</p>
<p>E â 1
2m
</p>
<p>(
</p>
<p>p21 + p22 + p23
)
</p>
<p>, (6.19)
</p>
<p>so that the integrand is independent of the spatial coordinates. It follows
</p>
<p>dNp = C N ï¿½ exp ( &minus; Î² E) dp1 dp2 dp3. (6.20)
</p>
<p>The integral of (6.20) over the momentum space yields N , whence
</p>
<p>1
</p>
<p>C ï¿½
=
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
exp ( &minus; Î² E) dp1 dp2 dp3. (6.21)
</p>
<p>4 Symbol Z comes from the German term Zustandssumme (&ldquo;sum over states&rdquo;) ([95], Chap. II).</p>
<p/>
</div>
<div class="page"><p/>
<p>118 6 Classical Distribution Function and Transport Equation
</p>
<p>The pressure P exerted by the gas is uniform over all the container&rsquo;s walls, hence
it can be calculated with reference to any surface element dï¿½ belonging to them.
One can then choose a surface element normal to the x1 axis, placed in such a
way that the atoms impinging on it travel in the positive direction. Let p1 be the
component of momentum of one of such atoms before hitting the wall; after the atom
is reflected by the wall, the component transforms into &minus;p1, so that the variation in
the momentum component along the x1 direction is 2p1. The p2, p3 components,
instead, are left unchanged. The product of 2p1 by the number of atoms hitting dï¿½
in the unit time provides the force dF exerted by the gas on the surface element,
whence the pressure is obtained as P = dF/dï¿½. Now, consider an elementary
cylinder whose base and height are dï¿½ and dx1 respectively; the number dNÌ1 of
atoms that belong to such a cylinder and whose momentum p1 belongs to dp1 is
obtained as the product of the atoms&rsquo; concentration dNp/ï¿½ times the cylinder&rsquo;s
volume dï¿½ dx1 = dï¿½ dt dx1/dt = dï¿½ (p1/m) dt , integrated over the other two
momenta p2, p3:
</p>
<p>dNÌ1 = dï¿½
p1
</p>
<p>m
dt dp1 C N
</p>
<p>&int;&int; +&infin;
</p>
<p>&minus;&infin;
exp ( &minus; Î² E) dp2 dp3. (6.22)
</p>
<p>As each atom in (6.22) undergoes a change 2p1 in the momentum component due to
the reflexion at the wall, the force dF = P dï¿½ is obtained by multiplying (6.22) by
2p1, dividing it by dt , and integrating over p1 between 0 and +&infin;; in fact, only the
atoms that move towards the wall must be accounted for. Eliminating dï¿½ yields
</p>
<p>P
</p>
<p>C N
= 2
</p>
<p>m
</p>
<p>&int; +&infin;
</p>
<p>0
</p>
<p>&int;&int; +&infin;
</p>
<p>&minus;&infin;
p21 exp ( &minus; Î² E) dp1 dp2 dp3. (6.23)
</p>
<p>Due to the form of (6.19), the integrals in (6.21) and (6.23) are products of one-
dimensional integrals over p1, p2, and p3. As a consequence, in the ratio between
(6.23) and (6.21) the integrals over p2 and p3 cancel each other, to yield
</p>
<p>Pï¿½
</p>
<p>N
= 2
</p>
<p>m
</p>
<p>&int; +&infin;
0 p
</p>
<p>2
1 exp [ &minus; Î² p21/(2m)] dp1
</p>
<p>&int; +&infin;
&minus;&infin; exp [ &minus; Î² p21/(2m)] dp1
</p>
<p>. (6.24)
</p>
<p>Letting Y indicate the integral at the denominator of (6.24), the integral at the
numerator is found to be &minus;m dY/dÎ². Using (C.27) one finds
</p>
<p>Pï¿½ = &minus;2 d
&radic;
</p>
<p>2Ï m/Î²/dÎ²&radic;
2Ï m/Î²
</p>
<p>= N
Î²
. (6.25)
</p>
<p>The assumption that the gas used in the derivation of (6.25) is dilute makes it possible
to consider it as a perfect gas, for which the phenomenological relationPï¿½ = NkBT
holds, with kB = 1.38&times;10&minus;23 J/K the Boltzmann constant andT the gas temperature.
Comparing with (6.25) yields
</p>
<p>Î² = 1
kB T
</p>
<p>. (6.26)</p>
<p/>
</div>
<div class="page"><p/>
<p>6.5 Boltzmann Transport Equation 119
</p>
<p>It can be shown that the validity of (6.26) is not limited to the case where the simple
derivation shown here applies. Actually, (6.26) is found to hold for any system that
follows the Maxwell-Boltzmann distribution law ([110], Sect. 32) and also, as shown
in Sects. 15.9.1, 15.9.5, for quantum systems in equilibrium.
</p>
<p>6.5 Boltzmann Transport Equation
</p>
<p>The expressions worked out in Sect. 6.4 show the important role of the distribution
function. It is then necessary to determine the equation fulfilled by it when the system
is not in an equilibrium condition. The derivation is made of two steps; in the first
one the interactions between molecules are neglected, in the second one they are
accounted for. To start with the first step one observes that, due to the neglect of
collisions, the only force acting on the molecules is that of an external field. To
denote the position in the phase space it is convenient to use the symbol s introduced
in Sect. 1.8. Here the symbol has a slightly different meaning, because the space is
6-dimensional instead of being 2n-dimensional. However, the relations (1.57, 1.58,
1.59) still hold. Applying to the &micro;-space the same reasoning used in Sect. 23.2 to
find the continuity equation (23.3), and considering the case where no particles are
generated or destroyed, yields
</p>
<p>&part;f&micro;
</p>
<p>&part;t
+ divs
</p>
<p>(
</p>
<p>sÌ f&micro;
)
</p>
<p>= 0. (6.27)
</p>
<p>From (1.58, 1.59) it follows divs(sÌ f&micro;) = sÌ &middot; gradsf&micro;. Replacing the latter into (6.27)
and using the Cartesian coordinates yields the Boltzmann collisionless equation5
</p>
<p>&part;f&micro;
</p>
<p>&part;t
+ rÌ &middot; gradrf&micro; + pÌ &middot; gradpf&micro; = 0. (6.28)
</p>
<p>From the meaning of a continuity equation it follows that &minus;divs
(
</p>
<p>sÌ f&micro;
)
</p>
<p>is the time
variation of f&micro; per unit volume dÏ of the &micro;-space. As f&micro; depends on r, p, and t ,
(6.28) is recast in compact form as dfÎ¼/dt = 0.
</p>
<p>To accomplish the second step, namely, adding the effects of collisions, one
observes that the latter produce a further time change in f&micro;. In principle, one might
incorporate such effects into &minus;divs
</p>
<p>(
</p>
<p>sÌ f&micro;
)
</p>
<p>; however, it is more convenient to keep
the effects of collisions separate from those of the external field. In fact, assuming
as before that the system under consideration is dilute, each molecule spends a
relatively large fraction of time far enough from the other molecules not to suffer
any interaction; in other terms, the time during which a molecule is subjected to the
external field is much longer than that involved in a collision. For this reason it is
preferable to write the continuity equation, when the collisions are accounted for, as
</p>
<p>&part;f&micro;
</p>
<p>&part;t
+ rÌ &middot; gradrf&micro; + pÌ &middot; gradpf&micro; = C, (6.29)
</p>
<p>5 In plasma physics, (6.28) is also called Vlasov equation ([85], Sect. 13.2).</p>
<p/>
</div>
<div class="page"><p/>
<p>120 6 Classical Distribution Function and Transport Equation
</p>
<p>called Boltzmann Transport Equation. In (6.29), term C indicates the time variation
of f&micro; per unit volume dÏ due to collisions, whereas &minus;divs
</p>
<p>(
</p>
<p>sÌ f&micro;
)
</p>
<p>keeps the meaning
of variation due to the external field. The compact form of (6.29) reads in this case
</p>
<p>df&micro;
dt
</p>
<p>= C,
&int;
</p>
<p>C dÏ = 0. (6.30)
</p>
<p>where the second relation is due to the normalization condition (6.2). In the equi-
librium condition the distribution function has no explicit dependence on time
(&part;f&micro;/&part;t = 0) and depends on constants of motion only, so that C = 0. The condition
C = 0 does not prevent collisions from happening; in fact, in the equilibrium con-
dition the change in the state of two colliding particles is balanced by simultaneous
state changes of other particles, that occur in the same elementary volume dÏ, in such
a way that the distribution function is left unchanged (principle of detailed balance).
</p>
<p>In the calculation of C it is assumed that collisions are of the binary type, namely,
that they involve only two particles at the time because the probability of a simul-
taneous interaction of more than two particles is negligibly small. This hypothesis,
along with the assumption of a short duration of the interactions, greatly simplifies
the calculation of C. This issue will not be pursued further here, because it will be
developed directly in the quantum case (Sect. 19.3.1). It is worth observing that in
a general non-equilibrium condition it is C ï¿½= 0; the second relation in (6.30) then
indicates that the form of C must be such, that in the integration over the &micro;-space
every elementary contribution to the integral is balanced by an opposite contribution.
</p>
<p>When the system under consideration is made of charged particles, the external
field that matters is the electromagnetic one; if the particles are identical to each
other, (6.29) takes the form
</p>
<p>&part;f&micro;
</p>
<p>&part;t
+ u &middot; gradrf&micro; + e (E + u &and; B) &middot; gradpf&micro; = C, (6.31)
</p>
<p>with E(r, t) the electric field, B(r, t) the magnetic induction, e the common value of
the particles&rsquo; charge, and u the velocity (Sect. 1.3.2).
</p>
<p>6.6 Complements
</p>
<p>6.6.1 Momentum and Angular Momentum at Equilibrium
</p>
<p>In the introductory discussion about statistical equilibrium, carried out in Sect. 6.3,
it has been assumed that the total momentum and angular momentum of the system
vanish. To discuss this issue, consider the box-shaped container whose cross section
is shown in Fig. 6.1, filled with molecules identical to each other, having initial
positions near the right wall of the container. If the initial velocities are normal to
the wall and equal to each other, as schematically indicated by the arrows, the total
momentum P of the particles at t = 0 is different from zero. If the left and right
walls are perfectly reflecting and parallel to each other, the particles keep bouncing</p>
<p/>
</div>
<div class="page"><p/>
<p>6.6 Complements 121
</p>
<p>Fig. 6.1 Schematic picture
used for discussing the issue
of the total momentum of
identical molecules within a
container
</p>
<p>back and forth between the two walls, and the total momentum alternates between
P and &minus;P. As the container&rsquo;s mass is large, absorbing the momentum 2 P leaves the
stationary condition of the container unaltered. On the other hand, as remarked in
Sect. 1.3, this picture should not be regarded as describing a &ldquo;system of particles",
because the latter have no mutual interaction. To establish the interaction one must
assume that the initial velocities are slightly misaligned, or the walls are not exactly
parallel, or both; in this way the molecules will start colliding with each other and,
after some time, their velocities will not be parallel any more. If each collision,
and reflection at the walls, is energy conserving, the total energy of the system
does not change; in contrast, opposite velocity components of different molecules
compensate each other in the calculation of the total momentum, so that the latter
will vanish after a sufficiently large number of collisions.6 A similar argument is
applicable to the case of the cylindrical container whose cross section is shown in
Fig. 6.2, where the initial positions and velocities of the molecules are such that all
molecules would move along the square described by the arrows. In this case the
total angular momentum with respect to the cylinder&rsquo;s axis is different from zero. A
slight misalignment of the initial conditions, or a deviation of the container&rsquo;s wall
from the perfectly-cylindrical form, or both, will eventually make the molecules to
collide with each other.
</p>
<p>6.6.2 Averages Based on the Maxwell-Boltzmann Distribution
</p>
<p>In a system made of classical particles in equilibrium at temperature T , each having
R degrees of freedom, the average occupation number at energyEr is given by (6.14).
In general, the number of energy levels is large and their separation small, so that one
</p>
<p>6 If the walls are perfectly reflecting, and the collisions are elastic (Sect. 3.5), the molecular motions
are reversible so that, in both examples of this section, the initial condition is recovered by reversing
the direction of time. More comments about this are made in Sect. 6.6.4.</p>
<p/>
</div>
<div class="page"><p/>
<p>122 6 Classical Distribution Function and Transport Equation
</p>
<p>Fig. 6.2 Schematic picture
used for discussing the issue
of the total angular
momentum of identical
molecules within a container
</p>
<p>disposes of the index and considers the number of particles belonging to the infinites-
imal interval dq1 dp1 . . . dqR dpR centered at (q1,p1, . . . , qR ,pR). After dropping
the index, the energy becomes a function of the position (q1,p1, . . . , qR ,pR) of the
interval&rsquo;s center, E = E(q1,p1, . . . , qR ,pR); in turn, the Maxwell&ndash;Boltzmann dis-
tribution (6.14) takes the form exp (&minus;Î±&minus;Î²E). Given these premises, and extending
to the case of R degrees of freedom the definitions of Sect. 6.2, the statistical average
over the Maxwell&ndash;Boltzmann distribution of a function Î¶ (q1,p1, . . . , qR ,pR) is
</p>
<p>Î¶ =
&int;
</p>
<p>. . .
&int;
</p>
<p>Î¶ exp ( &minus; Î²E) dq1 dp1 . . . dqR dpR
&int;
</p>
<p>. . .
&int;
</p>
<p>exp ( &minus; Î²E) dq1 dp1 . . . dqR dpR
, (6.32)
</p>
<p>where the factor exp ( &minus; Î±) has been canceled out. An interesting case occurs when
Î¶ depends on the generalized coordinates through the total energy only (Î¶ = Î¶ (E))
and, in turn, the energy is a positive-definite quadratic form of the coordinates,
</p>
<p>E = a1 q21 + b1 p21 + . . .+ aR q2R + bR p2R , ai , bi &gt; 0. (6.33)
</p>
<p>Letting n = 2R and using the Herring&ndash;Vogt transformation (17.66) yields
</p>
<p>E = Î·/Î², Î· = u21 + . . .+ u2n, (6.34)
</p>
<p>where
</p>
<p>u1 =
&radic;
</p>
<p>Î² a1 q1, u2 =
&radic;
</p>
<p>Î² b1 p1, . . . , un&minus;1 =
&radic;
</p>
<p>Î² aR qR , un =
&radic;
</p>
<p>Î² bR pR. (6.35)
</p>
<p>In turn it is du1 . . . dun = c dq1 dp1 . . . dqR dpR , with c = Î²R
&radic;
a1 b1 . . . aR bR .
</p>
<p>Using the procedure involving the density of states illustrated in Sect. B.5 yields
</p>
<p>Î¶ =
&int; +&infin;
</p>
<p>0 Î¶ (Î·) exp ( &minus; Î·) b(Î·) dÎ·
&int; +&infin;
</p>
<p>0 exp ( &minus; Î·) b(Î·) dÎ·
=
</p>
<p>&int; +&infin;
0 Î¶ (Î·) exp ( &minus; Î·) Î·n/2&minus;1 dÎ·
&int; +&infin;
</p>
<p>0 exp ( &minus; Î·) Î·n/2&minus;1 dÎ·
, (6.36)
</p>
<p>where the last expression is obtained after canceling out the numerical factors ap-
pearing in (B.40). An important case of (6.36) is Î¶ = E = Î·/Î², which yields the</p>
<p/>
</div>
<div class="page"><p/>
<p>6.6 Complements 123
</p>
<p>average energy of the particles. Remembering (C.88, C.89), and using (6.26), one
finds
</p>
<p>E = kB T
Î (n/2 + 1)
Î (n/2)
</p>
<p>= n
2
kB T = R kB T . (6.37)
</p>
<p>The physical systems where the energy is a quadratic form of the type (6.33) are
made of linear-harmonic oscillators, like those deriving from the diagonalization of
the Hamiltonian function of a system of particles near the mechanical-equilibrium
point (Sect. 3.10), or from the expression of the energy of the electromagnetic field
in vacuo in terms of modes (Sect. 5.6). For systems of this type the average energy of
the particles equals kB T times the number R of degrees of freedom of each particle.
</p>
<p>Another important system is the dilute one, where the energy is essentially kinetic.
In this case the form of the latter is found by letting ai &rarr; 0 in (6.33), so that the
energy is made of a sum of R terms instead of n = 2R. Thus, the average energy of
the particles is given by an expression of the form (6.37) where n/2 is replaced with
R/2:
</p>
<p>E = kB T
Î (R/2 + 1)
Î (R/2)
</p>
<p>= R kB T
2
</p>
<p>. (6.38)
</p>
<p>The above shows that in a dilute system the average energy of the particles equals
kB T/2 times the number R of degrees of freedom of each particle. The result
expressed by (6.37) or (6.38) is called principle of equipartition of energy.
</p>
<p>6.6.3 Boltzmann&rsquo;s H-Theorem
</p>
<p>A measure of the extent by which the condition of a system departs from the equilib-
rium case is given by Boltzmann&rsquo;s HB quantity, whose definition is that of statistical
average of log f&micro;. The case considered here refers to a spatially-homogeneous sys-
tem in the absence of external forces, so that df&micro;/dt = &part;f&micro;/&part;t . Remembering (6.4)
one finds
</p>
<p>HB(t) = Av [ log f&micro;] =
1
</p>
<p>N
</p>
<p>&int;
</p>
<p>f&micro; log f&micro; dÏ, (6.39)
</p>
<p>whose time derivative, using (6.30), reads
</p>
<p>dHB
dt
</p>
<p>= 1
N
</p>
<p>&int; (
&part;f&micro;
</p>
<p>&part;t
log f&micro; +
</p>
<p>&part;f&micro;
</p>
<p>&part;t
</p>
<p>)
</p>
<p>dÏ =
&int;
</p>
<p>C log f&micro; dÏ. (6.40)
</p>
<p>As indicated in Sect. 6.5, the collision term will be worked out directly in the quantum
case. However, it is worth anticipating that the analysis of the collision term C
leads, both in the classical and quantum cases, to an important conclusion: the time
derivative dHB/dt is negative for any distribution function f&micro; different from the
equilibrium one, while it vanishes in the equilibrium case. This result is the Boltzmann</p>
<p/>
</div>
<div class="page"><p/>
<p>124 6 Classical Distribution Function and Transport Equation
</p>
<p>H-theorem. It implies that if a uniform system is initially set in a condition described
by a non-equilibrium distribution function, and the external forces are removed, then
the initial distribution can not be stationary: an equilibration process occurs, that
brings the distribution to the equilibrium one, and whose duration is dictated by the
time constants typical ofC. The decrease ofHB with respect to time while the system
reaches the equilibrium condition reminds one of the behavior of entropy. In fact, it
can be shown that HB is the entropy apart from a negative multiplicative factor and
an additive constant ([113], Sect. 18.3).7
</p>
<p>6.6.4 Paradoxes &mdash; Kac-Ring Model
</p>
<p>It is known that the Boltzmann Transport Equation (6.29), and theH -theorem derived
from it, bring about two apparent paradoxes: the first one is that the equation contains
irreversibility, because any initial distribution function, different from the equilib-
rium one, evolves towards the equilibrium distribution when the external forces are
removed, whereas an opposite evolution never occurs. This outcome is in contrast
with the symmetry of the laws of mechanics with respect to time reversal (Sect.
2.6.1). The second paradox is the violation of Poincar&eacute;&rsquo;s time recurrence, which
states that every finite mechanical system returns to a state arbitrarily close to the
initial one after a sufficiently long time (called Poincar&eacute; cycle); this is forbidden by
the H -theorem, that prevents entropy from decreasing back to the initial value.
</p>
<p>A thorough discussion about the mathematical origin of the paradoxes can be
found, e.g., in ([113], Sect. 18.4); a qualitative insight into the question is given by a
simple model, called Kac&rsquo;s ring model, also reported in [113] and taken from [60].
In the model, N objects are uniformly distributed over a circle, so that at time t = 0
each object is ascribed to a specific arc. The objects have two possible states, say,
either &ldquo;0&rdquo; or &ldquo;1&rdquo;. The time variable is discrete so that, when time evolves from k ï¿½t
to (k+ 1)ï¿½t , k = 0, 1, 2, . . . , each object moves clockwise from the arc it occupied
at time k ï¿½t to the next arc. A number n &lt; N of markers is present along the circle:
specifically, the markers&rsquo;positions are at the junctions between two neighboring arcs.
The objects that cross the position of a marker change the state from &ldquo;0&rdquo; to &ldquo;1&rdquo; or
vice versa; those that do not cross the position of a marker keep their state.
</p>
<p>Given the number of objects and markers, the initial state of each object, and the
markers&rsquo; positions along the circle, one wants to investigate the time evolution of
the states. Such an evolution is obviously time reversible and fulfills Poincar&eacute;&rsquo;s time
recurrence; in fact, the set of objects goes back into the initial condition after N time
steps if n is even, and after 2N time steps if n is odd.
</p>
<p>Providing the time evolution of the individual object&rsquo;s state is in fact a mi-
croscopic description of the system; as remarked in Sect. 6.2, such a description
</p>
<p>7 Compare with the definition of entropy given in Sect. 15.9.1 which, at first sight, looks different.
The equivalence between the two definitions is justified in Sects. 47 and 102 of [110].</p>
<p/>
</div>
<div class="page"><p/>
<p>6.6 Complements 125
</p>
<p>Fig. 6.3 Kac-ring model:
computer calculation of the
time evolution of the number
of &ldquo;0&rdquo; states in two samples
made of N = 4,000 objects,
which at time t = 0 were all
set to &ldquo;0&rdquo;. The markers of the
two samples are n = 4 and
n = 8, respectively, and the
number of time steps is much
smaller than N
</p>
<p>0 20 40 60 80 100
</p>
<p>Time step
</p>
<p>3925
</p>
<p>3950
</p>
<p>3975
</p>
<p>4000
</p>
<p>N
u
</p>
<p>m
b
er
</p>
<p> o
f 
</p>
<p> "
0
" 
</p>
<p> s
ta
</p>
<p>te
s
</p>
<p>No of markers: 4
No of markers: 8
</p>
<p>becomes impossible when the number of objects in the system is large. A less de-
tailed, macroscopic description of the Kac ring consists, for instance, in providing
the time evolution of the number of &ldquo;0&rdquo; states. However, the outcome of the lat-
ter analysis seems to indicate that an irreversible process takes place; for instance,
Fig. 6.3 shows a computer calculation of the time evolution of the number of &ldquo;0&rdquo;
states in two samples made of N = 4000 objects, which at time t = 0 were all set
to &ldquo;0&rdquo;. The markers of the two samples are n = 4 and n = 8, respectively, and the
number of time steps is much smaller than N . Both curves tend to decrease and,
after some fluctuations (that depend on the markers&rsquo; positions), stabilize to a con-
stant value; the same behavior occurs at a larger numbers of markers, although the
number of time steps necessary to reach a constant value increases (curve n = 16 in
Fig. 6.4). A further increase in the number of markers makes the fluctuations more
pronounced (curve n = 32 in the same figure).
</p>
<p>On the other hand, a similar calculation using a number of time steps larger than
the number of objects shows that the stabilization at or around a constant value is
eventually lost: the system fulfills Poincar&eacute;&rsquo;s time recurrence and recovers the initial
condition (Fig. 6.5). Such an outcome is not detectable in real many-body systems,
because the Poincar&eacute; cycle is enormously long with respect to the typical time scales
of experiments.8
</p>
<p>6.6.5 Equilibrium Limit of the Boltzmann Transport Equation
</p>
<p>As remarked in Sect. 6.5, in the equilibrium condition the distribution function has
no explicit dependence on time (&part;f&micro;/&part;t = 0) and depends on constants of motion
</p>
<p>8 A crude estimate of the Poincar&eacute; cycle yields &sim; exp (N ), with N the total number of molecules in
the system ([50], Sect. 4.5). In typical situations such a time is longer than the age of the universe.</p>
<p/>
</div>
<div class="page"><p/>
<p>126 6 Classical Distribution Function and Transport Equation
</p>
<p>Fig. 6.4 Kac-ring model:
computer calculation of the
time evolution of the number
of &ldquo;0&rdquo; states in two samples
made of N = 4000 objects,
which at time t = 0 were all
set to &ldquo;0&rdquo;. The markers of the
two samples are n = 16 and
n = 32, respectively, and the
number of time steps is much
smaller than N
</p>
<p>0 500 1000 1500 2000
</p>
<p>Time step
</p>
<p>2000
</p>
<p>2500
</p>
<p>3000
</p>
<p>3500
</p>
<p>4000
</p>
<p>N
u
</p>
<p>m
b
</p>
<p>er
 o
</p>
<p>f 
"0
</p>
<p>" 
st
</p>
<p>at
es
</p>
<p>No of markers: 16
No of markers: 32
</p>
<p>Fig. 6.5 Kac-ring model:
computer calculation of the
time evolution of the number
of &ldquo;0&rdquo; states in two samples
made of N = 4000 objects,
which at time t = 0 were all
set to &ldquo;0&rdquo;. The markers of the
two samples are n = 16 and
n = 32, respectively, and the
number of time steps is larger
than N
</p>
<p>0 1000 2000 3000 4000 5000
Time step
</p>
<p>2750
</p>
<p>3000
</p>
<p>3250
</p>
<p>3500
</p>
<p>3750
</p>
<p>4000
</p>
<p>N
u
</p>
<p>m
b
</p>
<p>er
 o
</p>
<p>f 
"0
</p>
<p>" 
st
</p>
<p>at
es
</p>
<p>No of markers: 16
No of markers: 32
</p>
<p>only, so that C = 0. From (6.29) it then follows rÌ &middot; gradrf&micro; + pÌ &middot; gradpf&micro; = 0.
In case of a conservative system, energy is the most natural constant of motion to
be used; in fact it is H (r, p) = E = const, with H the Hamiltonian function (Sect.
1.5). From f&micro; = f&micro;(H ) one derives gradrf&micro; = (df&micro;/dH ) gradrH and gradpf&micro; =
(df&micro;/dH ) gradpH , so that the equilibrium limit of the Boltzmann Transport Equation
reads
</p>
<p>df&micro;
dH
</p>
<p>(
</p>
<p>rÌ &middot; gradrH + pÌ &middot; gradpH
)
</p>
<p>= 0, (6.41)
</p>
<p>Apart from the trivial case f&micro; = const, it is df&micro;/dH ï¿½= 0. On the other hand, re-
casting the Hamilton equations (1.42) as rÌ = gradpH , pÌ = &minus;gradrH , and replacing
them in (6.41), reduces the term in parentheses to &minus;rÌ &middot; pÌ+ pÌ &middot; rÌ, this showing that the
equation is fulfilled identically regardless of the explicit form of f&micro;(H ). This result
implies that the equilibrium distribution (6.14) can not be extracted solely from the
equilibrium limit of (6.29); its derivation requires also the maximization procedure
described in Sects. 6.3 and 6.4.</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 127
</p>
<p>The equilibrium limit of the Boltzmann Transport Equation described in this
section applies in general; as a consequence, it includes also cases like that of (6.31),
where a magnetic force is involved. This seems to contradict one of the hypotheses
used in Sect. 6.3 to derive the equilibrium distribution, namely, that the system is acted
upon by conservative forces. To clarify the issue one uses the concepts illustrated in
Sects. 1.5,1.6; first, one notes that the equilibrium limit is achieved by making the
external force independent of time, so that the scalar and vector potentials whence E
and B derive are independent of time as well: Ï = Ï(r), A = A(r) (the dependence
on space is kept to account for the possibility that the system under consideration is
not uniform). It follows that the Hamiltonian function, which in this case is given
by (1.35), is still a constant of motion; as a consequence, the procedure leading to
(6.41) is applicable. One notes in passing that each summand in the resulting identity
&minus;rÌ &middot; pÌ + pÌ &middot; rÌ becomes in this case
</p>
<p>pÌ &middot; u = e (E + u &and; B) &middot; u = eE &middot; u, (6.42)
</p>
<p>where the mixed product vanishes due to (A.32).
</p>
<p>Problems
</p>
<p>6.1 Calculate the average energy like in (6.37) assuming that energy, instead of
being a continuous variable, has the discrete form En = nhÎ½, n = 0, 1, 2, . . . ,
hÎ½ = const. This is the hypothesis from which Planck deduced the black-body&rsquo;s
spectral energy density (Sect. 7.4.1).</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 7
</p>
<p>From Classical Mechanics to Quantum
Mechanics
</p>
<p>7.1 Introduction
</p>
<p>The chapter tackles the difficult problem of bridging the concepts of Classical Me-
chanics and Electromagnetism with those of Quantum Mechanics. The subject, which
is fascinating per se, is illustrated within a historical perspective, covering the years
from 1900, when Planck&rsquo;s solution of the black-body radiation was given, to 1926,
when Schr&ouml;dinger&rsquo;s paper was published.
</p>
<p>At the end of the 1800s, the main branches of physics (mechanics, thermody-
namics, kinetic theory, optics, electromagnetic theory) had been established firmly.
The ability of the physical theories to interpret the experiments was such, that many
believed that all the important laws of physics had been discovered: the task of
physicists in the future years would be that of clarifying the details and improving
the experimental methods. Fortunately, it was not so: the elaboration of the theo-
retical aspects and the refinement in the experimental techniques showed that the
existing physical laws were unable to explain the outcome of some experiments,
and could not be adjusted to incorporate the new experimental findings. In some
cases, the theoretical formulations themselves led to paradoxes: a famous example
is the Gibbs entropy paradox [70]. It was then necessary to elaborate new ideas,
that eventually produced a consistent body generally referred to as modern physics.
The elaboration stemming from the investigation of the microscopic particles led
to the development of Quantum Mechanics, that stemming from investigations on
high-velocity dynamics led to Special Relativity.
</p>
<p>The chapter starts with the illustration of the planetary model of the atom, showing
that the model is able to justify a number of experimental findings; this is followed
by the description of experiments that can not be justified in full by the physical
theories existing in the late 1800s: stability of the atoms, spectral lines of excited
atoms, photoelectric effect, spectrum of the black-body radiation, Compton effect.
The solutions that were proposed to explain such phenomena are then illustrated;
they proved to be correct, although at the time they were suggested a comprehensive
theory was still lacking. This part is concluded by a heuristic derivation of the time-
independent Schr&ouml;dinger equation, based upon the analogy between the variational
principles of Mechanics and Geometrical Optics.
</p>
<p>&copy; Springer Science+Business Media New York 2015 129
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_7</p>
<p/>
</div>
<div class="page"><p/>
<p>130 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>In the final part of the chapter the meaning of the wave function is given: for this,
an analysis of the measuring process is carried out first, showing the necessity of
describing the statistical distribution of the measured values of dynamical quantities
when microscopic particles are dealt with; the connection with the similar situations
involving massive bodies is also analyzed in detail. The chapter is concluded with
the illustration of the probabilistic interpretation of the wave function.
</p>
<p>7.2 Planetary Model of the Atom
</p>
<p>Several experiments were carried out in the late 1800s and early 1900s, whose out-
come was the determination of a number of fundamental constants of atomic physics;
among them, the electron charge-to-mass ratio was measured by J. J. Thomson in
1897, and the electron charge was measured by R. Millikan in 1909 (Table D.1). A
theory of the atom was proposed by E. Rutherford after a series of experiments in
1909&ndash;1914, that led to the measurement of the atomic radius ra . The experiments
consisted in measuring the broadening of beams of finely collimated Î± particles1
</p>
<p>passing through thin metal foils. The latter were typically made of gold sheets with a
thickness of a few thousand atomic layers; the dynamics of the interaction between
an Î± particle and the metal foil was treated by Classical Mechanics, using an interac-
tion of the Coulomb type (Sect. 3.8). The outcome of the experiments led Rutherford
to conceive the planetary model of the atom; this model depicts the atom as made
of a small nucleus of atomic charge Z q surrounded by Z electrons, where q is the
absolute value of the electron charge and Z indicates the position of the element
in the periodic table. The model assumes that, as the Î±-particles are rather heavy,
they are deflected mainly by the nuclei2 of the foil; the type of deflection implies
that the majority of the Î± particles is deflected only once when crossing the foil, this
indicating that the foil&rsquo;s atoms are placed far apart from each other. In fact, the de-
flection experiments made it possible to estimate3 the atom&rsquo;s and nucleus&rsquo;diameters,
respectively, as
</p>
<p>ra &asymp; 0.1 nm, re &asymp; 2 &times; 10&minus;6
&radic;
Z nm, Z = 1, 2, . . . . (7.1)
</p>
<p>As Z ranges from 1 to about 100, the second relation in (7.1) shows that re âª ra
(compare with Table D.1).
</p>
<p>The simplest atom is that of hydrogen. The planetary model depicts it as an
electron moving nearby the proton under the effect of a Coulomb potential V , where
the energy reference is chosen in such a way as to make V (&infin;) = 0. Then, the theory
</p>
<p>1 These particles are obtained by ionizing helium atoms.
2 The meaning of term &ldquo;nucleus&rdquo; in this context is clarified in Sect. 7.8.1.
3 The estimate means that for scale lengths equal or larger than those indicated in (7.1), an atom
or a nucleus can be considered as geometrical points having no internal structure. The electron&rsquo;s
radius can be determined in a similar way using X-ray diffusion.</p>
<p/>
</div>
<div class="page"><p/>
<p>7.2 Planetary Model of the Atom 131
</p>
<p>Fig. 7.1 Classical description
of the electron&rsquo;s orbit for
E &ge; 0
</p>
<p>r
E
</p>
<p>V
</p>
<p>rm
</p>
<p>m
</p>
<p>Tm
</p>
<p>rm
</p>
<p>V
</p>
<p>of the Coulomb interaction in the attractive case applies (Sect. 3.13.6). As the proton
is much more massive than the electron, its position can be approximated with that
of the atom&rsquo;s center of mass, and placed in the origin; in summary, it is
</p>
<p>V (r) = V (r) = &minus; q
2
</p>
<p>4Ï Îµ0 r
, T + V = 1
</p>
<p>2
mu2 &minus; q
</p>
<p>2
</p>
<p>4Ï Îµ0 r
= E = const, (7.2)
</p>
<p>where r is the electron position, u its velocity&rsquo;s module, T and E its kinetic and
total energies, respectively, and Îµ0 the permittivity of vacuum. The planetary model
is extended to more complicated atoms by considering an outer electron moving
nearby a core of net charge q embedding Z protons and Z &minus; 1 electrons, or to even
more complicated cases (hydrogenic-like systems). Observing that T = E &minus; V =
E+|V | &ge; 0, and remembering the analysis of Sect. 3.8, one finds that two cases are
possible: the first one, shown in Fig. 7.1, is E &ge; 0, corresponding to V &le; 0 &le; E and
rmax = &infin; (free electron). The second case is E &lt; 0, corresponding to V &le; E &lt; 0
and rmax &lt; &infin; (bound electron). For the qualitative reasoning to be carried out here,
it is sufficient to consider the simpler case of a bound electron whose trajectory is
circular (Fig. 7.2). In such a case, using the results of Sects. 3.7 and 3.13.6 after letting
Z1 = Z2 = 1 and replacing s with r , yields r = 4Ï Îµ0 M2B/(mq2) = const, where
M2B = m2 r2 u2. Combining these relations with the first one in (7.2) shows that
F = |F| = m |a| = m u2/r = 2 T/r whence, using F = q2/(4Ï Îµ0 r2) = &minus;V/r ,
one finds
</p>
<p>T = &minus;V
2
</p>
<p>, E = T + V = V
2
</p>
<p>= &minus; q
2
</p>
<p>8Ï Îµ0 r
= const &lt; 0. (7.3)
</p>
<p>It follows dE/dr = |E|/r &gt; 0, that is, the total energy is larger at larger orbits (this
is a particular case of the general theory worked out in Prob. 3.2).</p>
<p/>
</div>
<div class="page"><p/>
<p>132 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>Fig. 7.2 Classical
description of the electron&rsquo;s
orbit for E &lt; 0. For
simplicity, a circular orbit is
considered
</p>
<p>E
</p>
<p>V
</p>
<p>Ta
</p>
<p>ra
</p>
<p>Va
</p>
<p>ra
</p>
<p>r
</p>
<p>Fig. 7.3 Schematic
description of the potential
energy in a linear monatomic
chain
</p>
<p>E3
</p>
<p>E2
</p>
<p>EÎ±
</p>
<p>E1
</p>
<p>E0
</p>
<p>Despite its simplicity, the planetary model is able to explain phenomena like
the excitation and ionization of atoms; excitation corresponds to the absorption of
energy from an external electromagnetic field, such that an initially-bound electron
increases its energy from E1 to E2, where E1 &lt; E2 &lt; 0: the electron in the final
state is still bound. The inverse process is the emission of energy in form of an
electromagnetic radiation, so that the electron&rsquo;s total energy decreases from E2 to
E1. In turn, ionization corresponds to the absorption of energy such that an initially-
bound electron becomes free: E1 &lt; 0 and E2 &ge; 0. The inverse process is the capture
of a free electron by an ionized atom, with an energy emission equal to E2 &minus; E1.
</p>
<p>The above reasoning can also be used to explain the behavior of systems more
complicate than single atoms. For instance, consider a finite linear monatomic chain,
namely, a system made of a finite number of identical atoms placed along a line, at
equal mutual distances (Fig. 7.3), which can be thought of as a rudimental version
of a crystal. The positions of the atoms are marked by the dots visible in the upper
part of the figure. Let the chain be aligned with the x axis; if each nucleus is made
to coincide with a local origin of the reference, the distance r =
</p>
<p>&radic;
</p>
<p>x2 + y2 + z2 in
the expression of the potential energy becomes |x|; the potential energy pertaining
to each nucleus is proportional to 1/|x| and is indicated with a dashed line in the
figure. An electron placed at some position in the chain is subjected to the sum of</p>
<p/>
</div>
<div class="page"><p/>
<p>7.2 Planetary Model of the Atom 133
</p>
<p>Fig. 7.4 The same structure
of Fig. 7.3, where the peaks
are replaced with the envelope
</p>
<p>(vacuum level)
</p>
<p>free electrons
</p>
<p>bound electrons
</p>
<p>E0
</p>
<p>EÎ²
</p>
<p>EÎ±
</p>
<p>W
</p>
<p>the potential energies; being the latter negative, the sum is lower than the individual
contributions: in the figure, it is indicated by the continuous line, which for simplicity
is drawn by adding up the contributions of the nearest-neighboring nuclei only. The
chain, however, has a finite length; when the leftmost nucleus is considered, the
potential energy on its left does not suffer any lowering: this creates the energy step
visible in the figure. The same happens on the right side of the righmost nucleus. The
shape of the potential energy thus obtained is able to qualitatively explain several
features of crystals. For instance, consider the case where the only force acting on
an electron inside the crystal derives from the potential energy of Fig. 7.3, namely,
it is a conservative force. If the total energy of the electron under consideration is
E1, the electron&rsquo;s position is confined within the potential well dictated by the initial
position of its motion. Thus, the electron oscillates within the well like in the example
of Prob. 3.2, and its motion can not extend out of it; if all electrons of the crystal are
bound, the material is an insulator. This reasoning implies that the situation where all
electrons are bound is maintained also under the application of an external voltage;
due to this, no electric current ensues.
</p>
<p>If the total energy of the electron under consideration is E2, the electron can move
within the whole crystal; finally, if the total energy is E3, the electron overcomes one
or the other of the energy steps and moves into vacuum: for this reason, the minimum
energy E0 necessary for the electron to leave the crystal is called vacuum level. If
the two ends of the crystal are connected to a voltage generator by suitable contacts,
and an external voltage is applied, the material can carry an electric current, whose
amplitude depends also on the number of electrons whose energy is sufficiently
high.4 It is worth noting that, although this is prohibited in the frame of Classical
Mechanics, the electrons whose energy is of the type E2 may also contribute to the
current; in fact, Quantum Mechanics shows that they have a finite probability to
penetrate the energy step and reach the contact. This phenomenon is called tunnel
effect (Sect. 11.3.1).
</p>
<p>To proceed it is convenient to give Fig. 7.3 a simpler appearance: in fact, consid-
ering that the interatomic distance is a fraction of a nanometer, the spatial extent in
the x direction where each peak is placed is hardly visible in a macroscopic repre-
sentation; for this reason, it is sufficient to graphically indicate the envelope EÎ± of
the peaks. By the same token, the steps on the sides are described as discontinuities
(Fig. 7.4). The electrons with E &lt; EÎ± or E &ge; EÎ± are called, respectively, bound
</p>
<p>4 The combination of the number of such electrons with other factors also determines whether the
material is a conductor or a semiconductor (Chap. 18).</p>
<p/>
</div>
<div class="page"><p/>
<p>134 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>electrons and free electrons.5 In the equilibrium condition the total energy of the
electrons is prescribed; it follows that the majority of the electrons has an energy
E lower than a given value EÎ² (which is not necessarily larger than EÎ±). Thus, the
difference W = E0 &minus; EÎ² is a measure of the energy that is necessary to extract an
electron from the material: among other things, the model explains the existence of
a minimum extraction energy of the electrons.6
</p>
<p>7.3 Experiments Contradicting the Classical Laws
</p>
<p>About 1900, experimental evidence was found for a number of phenomena that
contradict the calculations based on the known physical laws of the time, that is,
the laws of Analytical Mechanics, Electromagnetism, and Statistical Mechanics. A
number of such phenomena are listed in this section.
</p>
<p>Stability of the Atom
</p>
<p>The solution of the electromagnetic equations shows that an accelerated electron
radiates a power given by (5.72), namely, q2vÌ2/(6Ï Îµ0 c3), with vÌ the electron&rsquo;s
acceleration. As discussed in Sect. 5.11.2, this is in contradiction with the planetary
model of the atom (7.3), in which T + V = E = const: due to the radiated power,
the electron should lose energy and, as a consequence, the atom should shrink. The
possibility of an extremely slow, non-detectable shrinking must be ruled out: in fact,
a perturbative calculation (Sect. 5.11.3) shows that due to the energy loss the atomic
radius should decrease from the initial value, say, r , to the value r/e in about 10&minus;8 s.
This, however, is not observed (Sect. 9.7.2).
</p>
<p>Spectral Lines of Excited Atoms
</p>
<p>The planetary model explains the emission of electromagnetic radiation by excited
atoms. The explanation, however, is qualitative only, because the model does not
impose any constraint on the frequency of the emitted waves. In contrast, the exper-
iments show that the waves emitted by, e.g., hydrogen atoms have frequencies Î½ of
the form (Balmer law, 1885),7
</p>
<p>Î½nm = Î½R
(
</p>
<p>1
</p>
<p>n2
&minus; 1
</p>
<p>m2
</p>
<p>)
</p>
<p>, Î½R â 3.3 &times; 1015 s&minus;1, (7.4)
</p>
<p>5 The description is qualitative; for instance, it does not consider the band structure of the solid
(Sect. 17.6).
6 When the material is a conductor, EÎ² coincides with the Fermi level (Sect. 15.8.1), and W is
called work function; in a semiconductor, EÎ² coindices with the lower edge EC of the conduction
band (Sect. 17.6.5) and the minimum extraction energy (typically indicated with a symbol different
from W ) is called electron affinity (Sect. 22.2).
7 The ratio R = Î½R/c â 1.1 &times; 105 cm&minus;1 is called Rydberg constant. The formula was generalized
in the 1880s to the hydrogenic-like atoms by Rydberg: the expression (7.4) of the frequencies must
be multiplied by a constant that depends on the atom under consideration.</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3 Experiments Contradicting the Classical Laws 135
</p>
<p>Fig. 7.5 Designation of the
lower series of spectral lines
(7.4)
</p>
<p>2
</p>
<p>1
</p>
<p>3
</p>
<p>4
</p>
<p>Lyman (ultraviolet)
</p>
<p>Balmer (visible)
</p>
<p>Brackett (far infrared)
</p>
<p>Paschen (infrared)
</p>
<p>Fig. 7.6 Schematic
cross-section of the apparatus
used for measuring the
photoelectric effect
</p>
<p>I
</p>
<p>V
AK
</p>
<p>Î£
</p>
<p>K
</p>
<p>A
</p>
<p>where n,m are integers, m &gt; n &ge; 1. The emissions described by (7.4) are also called
spectral lines. The lower series of spectral lines are shown in Fig. 7.5 along with
their designations; the numbers in the figure correspond to n, m in (7.4). Another
experimental finding shows that, instead of occurring with a single emission of fre-
quency Î½nm, the release of electromagnetic energy by the atom may be accomplished
in steps; if that happens, the frequencies associated to the individual steps fulfill a
relation called Ritz emission rule: considering, e.g., two steps, it reads
</p>
<p>Î½nm = Î½nk + Î½km, (7.5)
</p>
<p>with Î½nk , Î½km the frequencies of the individual steps.
</p>
<p>Photoelectric Effect
</p>
<p>It is found that an impinging electromagnetic radiation extracts charges from a metal
(H. Hertz, 1887) and that these charges are electrons (J. J. Thomson, 1899). The
phenomenon is ascribed to the absorption of energy from the radiation: the electron
absorbs an energy sufficiently large to be extracted from the metal. An electron thus
extracted is also called photoelectron. A sketch of the measuring apparatus is given in
Fig. 7.6, where two electrodes, anode (A) and cathode (K), are placed inside a vacuum</p>
<p/>
</div>
<div class="page"><p/>
<p>136 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>Fig. 7.7 The I = I (VAK )
curves, in arbitrary units,
obtained from the
photoelectric effect at
constant frequency of the
radiation, with the spectral
power used as a parameter
</p>
<p>-5 0 5 10
V
</p>
<p>AK
      (a. u.)
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>1.5
</p>
<p>2
</p>
<p>2.5
</p>
<p>3
</p>
<p>I 
  
  
 (
</p>
<p>a.
 u
</p>
<p>.) Î  = 1.0
Î  = 1.5
Î  = 2.0
Î  = 2.5
</p>
<p>Constant frequency Î½
</p>
<p>-V
R
</p>
<p>tube in order to prevent interactions between the photoelectrons and the atmosphere.
A voltage VAK is applied to the electrodes, such that VAK &gt; 0 when the electric
potential at the anode is larger than that at the cathode. A monochromatic radiation
of a given intensity is made to impinge on the cathode, whose surface is marked with
ï¿½, and the current I flowing in the tube is recorded. Important parameters are the
radiation&rsquo;s frequency Î½, the spectral intensity of the radiation, Î· = dE/(dï¿½ dt dÎ½),
where dï¿½ is the surface element of the cathode, and the spectral power8
</p>
<p>ï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>Î· dï¿½ = dE
dt dÎ½
</p>
<p>. (7.6)
</p>
<p>The outcome of the experiment is shown in arbitrary units in Figs. 7.7 and 7.8. The
first one shows a set of the I = I (VAK ) curves at constant Î½, with ï¿½ a parameter.
WhenVAK is positive and sufficiently high, it is expected that practically all electrons
extracted from the cathode be driven to the anode; as a consequence, the slope of the
curves should be negligible. Also, when the intensity of the radiation increases, the
number of extracted electrons, and the current with it, should also increase. This is
in fact confirmed by the curves of Fig. 7.7. When, instead, VAK is negative, only the
electrons leaving the cathode with a sufficiently high kinetic energy are able to reach
the anode, whereas those whose initial kinetic energy is low are repelled towards the
cathode by the electric field imposed by the reverse bias.9 Considering for simplicity
a one-dimensional case, energy conservation yields for an electron traveling from
cathode to anode,
</p>
<p>1
</p>
<p>2
m u2A &minus;
</p>
<p>1
</p>
<p>2
m u2K = qVAK , (7.7)
</p>
<p>8 The units of Î· and ï¿½ are [Î·] = J cm&minus;2 and [ï¿½] = J, respectively.
9 The concentration of electrons in the vacuum tube is small enough not to influence the electric
field; thus, the latter is due only to the value of VAK and to the form of the electrodes.</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3 Experiments Contradicting the Classical Laws 137
</p>
<p>Fig. 7.8 The I = I (VAK )
curves, in arbitrary units,
obtained from the
photoelectric effect at
constant spectral power of the
radiation, with frequency
used as a parameter
</p>
<p>-5 0 5 10
V
AK
</p>
<p>      (a. u.)
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>1.5
</p>
<p>2
</p>
<p>2.5
</p>
<p>3
</p>
<p>I 
  
</p>
<p>  
 (
</p>
<p>a.
 u
</p>
<p>.) Î½ = 0.1
Î½ = 0.2
Î½ = 0.3
Î½ = 0.4
</p>
<p>Constant spectral power Î 
</p>
<p>where uK is the electron&rsquo;s velocity at the cathode and uA that at the anode. The
blocking voltage VR &gt; 0 is the value VAK = &minus;VR such that uA = 0; from (7.7) one
obtains the relation
</p>
<p>1
</p>
<p>2
m u2K = q VR , (7.8)
</p>
<p>which allows one to measure the kinetic energy of the most energetic electrons that are
extracted from the cathode at given spectral power and frequency of the radiation.10
</p>
<p>Such electrons are those that inside the cathode have an energy in the vicinity of EÎ²
(Fig. 7.4) and do not suffer energy losses while being extracted. If EL is the energy
that the most energetic electron absorbs from the radiation, its kinetic energy at the
cathode is (1/2)m u2K = EL &minus;W , with W the metal&rsquo;s work function, whence
</p>
<p>q VR = EL &minus;W , (7.9)
so that the photoelectric effect provides in fact a method for measuring EL. The
classical model predicts that the blocking voltage should increase with ï¿½; this,
however, does not happen: as shown in Fig. 7.7, at a given frequency the blocking
voltage is the same for all values of ï¿½.
</p>
<p>In addition, it is unexpectedly found that both I and VR depend on the frequency
Î½ (Fig. 7.8). In fact, the comparison between the experimental blocking voltages and
(7.9) shows that the energy EL that the electron absorbs from the electromagnetic
field is proportional to the frequency,
</p>
<p>EL = h Î½, (7.10)
with h â 6.626&times;10&minus;34 J s the Planck constant. If h Î½ &lt; W , no current is measured;
this provides a threshold value for the frequency to be used in the experiment.
</p>
<p>10 The most energetic electrons succeed in overcoming the effect of the reverse bias and reach the
vicinity of the anode; they constantly slow down along the trajectory, to the point that their velocity
at the anode vanishes. Then, their motion reverses and they are driven back to the cathode.</p>
<p/>
</div>
<div class="page"><p/>
<p>138 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>Fig. 7.9 The approximation
to a black body consisting in
a small hole in the wall of an
enclosure kept at constant
temperature. If a thermometer
(represented by the shaded
area) were suspended within
the enclosure, it would
indicate the same temperature
T as the walls, irrespective of
its position or orientation
</p>
<p>T
</p>
<p>Spectrum of the Black-Body Radiation
</p>
<p>Consider a body at temperature T in equilibrium with an electromagnetic field. Due
to the detailed-balance principle, the spectral intensity Î·B emitted by the body, that
is, the electromagnetic power emitted by it per unit surface element dï¿½ and unit
frequency dÎ½, in the direction normal to dï¿½, fulfills the relation
</p>
<p>Î·B = Î± Î·, (7.11)
</p>
<p>where Î· is the spectral intensity of the radiation (compare with (7.6)), and 0 &le; Î± &le; 1
the fraction of Î· absorbed by the body at frequency Î½. By Kirchhoff&rsquo;s law (1859),
for any body in thermal equilibrium with radiation it is
</p>
<p>Î·B
</p>
<p>Î±
= K(Î½, T ), (7.12)
</p>
<p>where K is a universal function of Î½ and T [85, Sect. 9&ndash;15]. A black body is a body
such that Î± = 1 at all frequencies; thus, for a black body at equilibrium with radiation
it is Î·B = K . A good approximation to a black body is a small hole in the wall of an
enclosure kept at constant temperature, like that illustrated in Fig. 7.9: any radiation
entering the hole has a negligible probability of escaping, due to multiple reflections at
the walls; as a consequence, the hole acts like a perfect absorber. Thanks to Î·B = K ,
the spectral intensity emitted by any black body has the same characteristics: in
particular, it is not influenced by the form of the enclosure, the material of which
the walls are made, or other bodies present in the enclosure. As a consequence, Î·B ,
or any other function related to it, can be calculated by considering a convenient
geometry of the problem and assuming that the radiation propagates in vacuo.
</p>
<p>To proceed, consider a surface element dï¿½ of the black body, and connect a local
Cartesian reference to it such that dx and dy belong to dï¿½; it follows
</p>
<p>Î·B =
dE
</p>
<p>dx dy dt dÎ½
= c dE
</p>
<p>dx dy dz dÎ½
= c u, (7.13)</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3 Experiments Contradicting the Classical Laws 139
</p>
<p>where u is the spectral energy density of the black body, that is, the energy per
unit volume and frequency. The integral of u over the frequencies yields the energy
density; remembering that equilibrium is assumed, one finds11
</p>
<p>weqem(T ) =
&int; &infin;
</p>
<p>0
u(Î½, T ) dÎ½. (7.14)
</p>
<p>In turn, the integral of u over the coordinates gives the equilibrium value of the
spectral energy, whose general definition is given by (5.47). It is found experimentally
(Stefan&rsquo;s law, 1879) that
</p>
<p>&int; &infin;
</p>
<p>0
Î·B(Î½, T ) dÎ½ = Ï T 4, (7.15)
</p>
<p>where Ï = 5.67&times;10&minus;12 W cm&minus;2 K&minus;4 is the Stefan-Boltzmann constant. Combining
(7.15) with (7.13) and (7.14) yields weqem(T ) = Ï T 4/c.
</p>
<p>The spectral energy density u can be calculated as the product of the number
of monochromatic components of the electromagnetic field per unit volume and
frequency, times the energy of each monochromatic component. The first factor is
readily found by taking an enclosure of prismatic form like that of Sect. 15.9.4; the
calculation yields 8Ï Î½2/c3, which is obtained by dividing both sides of (15.74) by
the enclosure&rsquo;s volume V . As for the energy of each monochromatic component, the
only assumption possible in the frame of Classical Mechanics is that the energy of
the electromagnetic field at equilibrium is distributed over the frequencies according
to the Maxwell&ndash;Bolzmann distribution (6.14). Assuming that each monochromatic
component is equivalent to a one-dimensional linear-harmonic oscillator, the energy
to be associated to it is the average energy of a system with one degree of freedom;
thus, letting R = 1 in (6.37), yields for the average energy the value kB T . The
product of the two factors thus found yields for the spectral energy density of the
black body the expression
</p>
<p>u(Î½, T ) = 8Ï kBT
c3
</p>
<p>Î½2, (7.16)
</p>
<p>called Rayleigh-Jeans law. Experimental results for u as a function of frequency are
shown in Fig. 7.10, with temperature a parameter. The comparison with experiments
shows that the parabolic behavior of (7.16) approximates the correct form of the
curves only at low frequencies; clearly the result expressed by (7.16) can not be
correct, because it makes the equilibrium energy density (7.14) to diverge.12
</p>
<p>11 Compare with the general definition (5.10) of wem , where the assumption of equilibrium is not
made.
12 This unphysical outcome is also called ultraviolet catastrophe.</p>
<p/>
</div>
<div class="page"><p/>
<p>140 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>0.0 5.0&times;10
14
</p>
<p>1.0&times;10
15
</p>
<p>1.5&times;10
15
</p>
<p>2.0&times;10
15
</p>
<p>Î½      (s
-1
</p>
<p>)
</p>
<p>0.0
</p>
<p>5.0&times;10
-16
</p>
<p>1.0&times;10
-15
</p>
<p>1.5&times;10
-15
</p>
<p>2.0&times;10
-15
</p>
<p>u
  
  
  
(J
</p>
<p> s
 m
</p>
<p>-3
)
</p>
<p>T = 3,800 K
T = 4,800 K
T = 5,800 K
</p>
<p>Range of visible light
</p>
<p>Fig. 7.10 Spectral energy density of the black body at different temperatures. The value T = 5800
K corresponds to the surface temperature of the sun
</p>
<p>Compton Effect
</p>
<p>When X-rays of a given frequency interact with atoms and are scattered with an
angle Ï with respect to the direction of incidence, the frequency of the emerging
rays is found to depend on Ï . This outcome is in contrast with the prediction of
the electromagnetic theory, according to which the frequency of the scattered rays
should be equal to that of the impinging ones. The dependence of frequency on the
scattering angle is also called Compton effect.
</p>
<p>The experimental setup for measuring the Compton effect is schematically shown
in Fig. 7.11. The gray box in the middle of the figure is a piece of solid material, onto
which the radiation impinges from the left (dark arrows); the vertical lines are the
intersections of the constant-phase planes with the plane of the figure. The gray arrows
on the right represent the part of the radiation that does not interact with the material
and exits from it unaltered, while the white arrows indicate some of the directions
of the rays scattered by the material. The circumferences are the intersections with
the figure&rsquo;s plane of the spherical waves produced by the scattering. The origin of
the measuring angle is aligned with the direction of the incoming radiation, so that
Ï = 0 corresponds to the absence of scattering, Ï = 2Ï to reflection.
</p>
<p>7.4 Quantum Hypotheses
</p>
<p>In the early 1900s, a number of hypotheses were made to solve the contradictions
between the experimental evidence and the calculations based on the physical laws
known at that time. The solutions thus found and the new concepts originating
from them were eventually combined into a unified and coherent theory, Quantum
Mechanics.</p>
<p/>
</div>
<div class="page"><p/>
<p>7.4 Quantum Hypotheses 141
</p>
<p>Fig. 7.11 Scheme of the
experimental setup for
measuring the Compton effect
</p>
<p>Ï
</p>
<p>In essence, the contradictions with the physical laws known in the early 1900s
were found thanks to the refinement of the experimental techniques. Such refinements
were in turn made available by the general advancement of science that had taken
place in the preceding decades. Thanks to them, it was possible to start investigating
the microscopic world, namely, the dynamics of elementary particles. A parallel
improvement took place in the same years in the investigation of the dynamics at
high velocities, and led to the concepts of Special Relativity (1905).13
</p>
<p>7.4.1 Planck&rsquo;s Solution of the Black-Body Problem
</p>
<p>To explain the features of the black-body radiation, Planck made in 1900 the hy-
pothesis that a monochromatic electromagnetic energy is absorbed or emitted only
in quantities that are integer multiples of a fixed quantity hÎ½, where h is a suitable
constant [82]. The occupation number then becomes
</p>
<p>Pn = P0 exp ( &minus; nÎ² h Î½), Î² = 1/(kB T ). (7.17)
</p>
<p>As a consequence, using the same procedure as in Sect. 6.6.2 after replacing the
integrals with sums, yields for the average energy n h Î½ the expression 14
</p>
<p>n h Î½ =
&sum;&infin;
</p>
<p>n=0 n h Î½ Pn
&sum;&infin;
</p>
<p>n=0 Pn
= h Î½
</p>
<p>exp (Î² h Î½) &minus; 1 . (7.18)
</p>
<p>In contrast with the constant value kB T used in the determination of the Rayleigh-
Jeans law, here the average energy of each monochromatic component depends on the
</p>
<p>13 As the particles&rsquo; velocities that occur in solid-state physics are low, Special Relativity is not used
in this book; the only exception is in the explanation of the Compton effect, illustrated in Sect.
7.4.3.
14 The detailed calculation leading to (7.18) is shown in Prob. 6.1.</p>
<p/>
</div>
<div class="page"><p/>
<p>142 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>component&rsquo;s frequency. Multiplying (7.18) by the number 8Ï Î½2/c3 of monochro-
matic components of the electromagnetic field per unit volume and frequency, found
in Sect. 7.3, yields for the spectral energy density of the black body the expression
</p>
<p>u(Î½, T ) = 8Ï h Î½
3/c3
</p>
<p>exp [h Î½/(kB T )] &minus; 1
, (7.19)
</p>
<p>called Planck law (1900). The derivation of (7.19) involves one undetermined param-
eter, h. If the latter is made equal to the Planck constant introduced in the description
of the photoelectric effect (Sect. 7.3), the resulting expression fits perfectly the exper-
imental data like those of Fig. 7.10. Remembering that the spectral energy density of
a black body in equilibrium is a universal function, it follows that h does not depend
on the specific experiment, namely, it is a universal constant.
</p>
<p>The low-frequency limit of (7.19), h Î½ âª kB T , is independent of h and renders
the Rayleigh&ndash;Jeans law (7.16).
</p>
<p>7.4.2 Einstein&rsquo;s Solution of the Photoelectric Effect
</p>
<p>In 1905, Einstein proposed the following explanation of the photoelectric effect:
the transport of electromagnetic energy is quantized; specifically, a monochromatic
electromagnetic wave of frequency Î½ is made of the flux of identical objects, called
photons, each carrying the energy h Î½. In the interaction with a photon, an electron
may absorb an energy up to h Î½. If the absorbed energy is exactly hÎ½, the photon
is annihilated [34].15 This theory provides a correct explanation of the photoelectric
effect: with reference to Fig. 7.7, the photoelectric current increases as the spectral
power ï¿½ increases at constant Î½, because the number of photons is larger: as a
consequence, the number of photoelectrons is larger as well. In turn, with reference
to Fig. 7.8, the blocking voltageVR increases as Î½ increases at constantï¿½, because the
photons are more energetic; however, they are fewer, which explains why the curves
intersect each other: the spectral power, in fact, can be written as ï¿½ = dE/(dt dÎ½) =
h Î½ [dN/(dt dÎ½)], where the quantity in brackets is the number of photons per unit
time and frequency; as a consequence, the constraint ï¿½ = const of the experiment
of Fig. 7.8 makes the quantity in brackets to decrease when the photon energy h Î½
increases.
</p>
<p>7.4.3 Explanation of the Compton Effect
</p>
<p>The concept of photon, introduced in Sect. 7.4.2, explains the Compton effect by
describing the interaction of the electron with the electromagnetic field as the collision
</p>
<p>15 Einstein&rsquo;s hypothesis is more general than Planck&rsquo;s: the latter, in fact, assumes that energy is
quantized only in the absorption or emission events.</p>
<p/>
</div>
<div class="page"><p/>
<p>7.4 Quantum Hypotheses 143
</p>
<p>between the electron and a photon [19]. As the photon&rsquo;s velocity is c, its rest mass
is zero (Sect. 3.13.7); in turn, the modulus of the photon&rsquo;s momentum is p = E/c,
which is consistent with classical electromagnetism (compare with (5.43)).
</p>
<p>The analysis of the electron-phonon collision is worked out assuming that the
system made of the two particles under consideration is isolated; thus, the calculation
is based upon the energy- and momentum-conservation equations, and the results of
Sect. 3.13.8 hold. The dynamical quantities for the photon are given by
</p>
<p>E = h Î½, p = E
c
</p>
<p>= h Î½
c
</p>
<p>= h
Î»
</p>
<p>, (7.20)
</p>
<p>the second of which derives from (5.55) expressed in vacuo. Defining the reduced
Planck constant hÌ = h/(2Ï ) â 1.055 &times; 10&minus;34 J s, and using the modulus k of the
wave vector, (7.20) becomes
</p>
<p>E = hÌ 2Ï Î½ = hÌ Ï, p = hÌ
Î»/(2Ï )
</p>
<p>= hÌ k. (7.21)
</p>
<p>The second relation of (7.21) in vector form reads
</p>
<p>p = hÌ k. (7.22)
</p>
<p>Here the useful outcome of the analysis of Sect. 3.13.8 is (3.92), that relates the
photon&rsquo;s energies prior and after the collision (Ea and Eb, respectively) with the
deflection angle Ï (Fig. 3.7). Using E = c h/Î» in (3.92) yields
</p>
<p>Î»b &minus; Î»a = 2 Î»0 sin2
(
Ï
</p>
<p>2
</p>
<p>)
</p>
<p>, Î»0 =
h
</p>
<p>m0 c
, (7.23)
</p>
<p>with Î»0 â 2.43 &times; 10&minus;12 m the Compton wavelength (1923). The frequency corre-
sponding to it is Î½0 = c/Î»0 â 1.2&times;1020 Hz. The maximum difference in wavelength
corresponds to the case of reflection, max(Î»b &minus; Î»a) = 2 Î»0. Even in this case, the
smallness of Î»0 makes the effect difficult to measure; in practice, the shift in wave-
length is detectable only for sufficiently small values of Î»a , typically in the range of
10&minus;10 m corresponding to the X-ray frequencies (Î½ &sim; 1018 s&minus;1). Due to the large
energy of the photon, the energy transferred to the electron brings the latter into a
high-velocity regime; this, in turn, imposes the use of the relativistic expressions for
describing the electron&rsquo;s dynamics.
</p>
<p>7.4.4 Bohr&rsquo;s Hypothesis
</p>
<p>The description of the monochromatic components of the electromagnetic field as a
flow of identical photons with energy h Î½ lends itself to the explanation of the Balmer
law (7.4). Such an explanation (Bohr&rsquo;s hypothesis, 1913) is based on the idea that, if</p>
<p/>
</div>
<div class="page"><p/>
<p>144 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>Î½nm is the frequency of the emitted radiation, the corresponding energy of the emitted
photon is h Î½nm; multiplying (7.4) by h and remembering that m &gt; n then yields
</p>
<p>h Î½nm = h Î½R
(
</p>
<p>1
</p>
<p>n2
&minus; 1
</p>
<p>m2
</p>
<p>)
</p>
<p>=
(
</p>
<p>&minus;h Î½R
m2
</p>
<p>)
</p>
<p>&minus;
(
</p>
<p>&minus;hÎ½R
n2
</p>
<p>)
</p>
<p>. (7.24)
</p>
<p>As the left hand side is the energy of the emitted photon, the terms on right hand side
can be recast as
</p>
<p>Em = &minus;
hÎ½R
</p>
<p>m2
, En = &minus;
</p>
<p>hÎ½R
</p>
<p>n2
, En &lt; Em &lt; 0 ; (7.25)
</p>
<p>then, ifEm (En) is interpreted as the atom&rsquo;s energy before (after) emitting the photon,
Balmer&rsquo;s law becomes the expression of energy conservation. From this, the emission
rule of Ritz is easily explained; in fact, (7.5) is equivalent to
</p>
<p>Em &minus; En = (Em &minus; Ek) + (Ek &minus; En). (7.26)
</p>
<p>Bohr&rsquo;s hypothesis is expressed more precisely by the following statements:
</p>
<p>1. The energy variations of the atom are due to the electrons of the outer shell, that
exchange energy with the electromagnetic field.
</p>
<p>2. The total energy of a non-radiative state is quantized, namely, it is associated
to an integer index: En = &minus;h Î½R/n2, n = 1, 2, . . . ; the values of energy thus
identified are called energy levels. The lowest level corresponds to n = 1 and is
called ground level or ground state.
</p>
<p>3. The total energy can vary only between the quantized levels by exchanging with
the electromagnetic field a photon of energy Î½nm = (Em &minus; En)/h.
</p>
<p>It is interesting to note that, by combining Bohr&rsquo;s hypothesis with the planetary
model of the atom, the quantization of the other dynamical quantities follows from
that of energy; again, the case of a circular orbit is considered. By way of example,
using En = &minus;h Î½R/n2 in the second relation of (7.3) provides the quantization of
the orbit&rsquo;s radius:
</p>
<p>r = rn = &minus;
q2
</p>
<p>8Ï Îµ0 En
= q
</p>
<p>2
</p>
<p>8Ï Îµ0
</p>
<p>n2
</p>
<p>h Î½R
. (7.27)
</p>
<p>The smallest radius r1 corresponds to the ground state n = 1; taking Î½R from (7.4)
and the other constants from Table D.1 one finds r1 â 0.05 nm; despite the simplicity
of the model, r1 is fairly close to the experimental value ra given in (7.1).
</p>
<p>In turn, the velocity is quantized by combining (7.3) to obtain T = &minus;V/2 = &minus;E;
replacing the expressions of T and E then yields
</p>
<p>1
</p>
<p>2
m u2 = h Î½R
</p>
<p>n2
, u = un =
</p>
<p>&radic;
</p>
<p>2 h Î½R
mn2
</p>
<p>. (7.28)
</p>
<p>The largest velocity is found from (7.28) by letting n = 1 and using the minimum
value for the mass, that is, the rest mass m = m0. It turns out u1 â 7 &times; 10&minus;3 c;</p>
<p/>
</div>
<div class="page"><p/>
<p>7.4 Quantum Hypotheses 145
</p>
<p>as a consequence, the velocity of a bound electron belonging to the outer shell of
the atom can be considered non relativistic. Thanks to this result, from now on
the electron&rsquo;s mass will be identified with the rest mass. Finally, for the angular
momentum M = r p = r m u one finds
</p>
<p>M = Mn =
q2 n2
</p>
<p>8Ï Îµ0 h Î½R
m
</p>
<p>&radic;
</p>
<p>2 h Î½R
mn2
</p>
<p>= 1
2Ï
</p>
<p>[
q2
</p>
<p>Îµ0
</p>
<p>&radic;
m
</p>
<p>8h Î½R
</p>
<p>]
</p>
<p>n. (7.29)
</p>
<p>The quantity in brackets in (7.29) has the same units as M , namely, an action (Sect.
1.5) and, replacing the constants, it turns out16 to be equal to h. Using the reduced
Planck constant it follows
</p>
<p>Mn = n hÌ. (7.30)
The Bohr hypothesis provides a coherent description of some atomic properties; yet
it does not explain, for instance, the fact that the electron belonging to an orbit of
energy En = &minus;h Î½R/n2 does not radiate, in contrast to what is predicted by the elec-
tromagnetic theory (compare with the discussion in Sect. 7.3). Another phenomenon
not explained by the hypothesis is the fact that only the ground state of the atom is
stable, whereas the excited states are unstable and tend to decay to the ground state.
</p>
<p>7.4.5 De Broglie&rsquo;s Hypothesis
</p>
<p>The explanation of the Compton effect (Sect. 7.4.3) involves a description of the
photon&rsquo;s dynamics in which the latter is treated like a particle having energy and
momentum. Such mechanical properties are obtained from the wave properties of a
monochromatic component of the electromagnetic field: the relations involved are
(7.20) (or (7.21)), by which the photon energy is related to the frequency, and its
momentum to the wave vector. It is worth specifying that such relations are applied
to the asymptotic part of the motion, namely, when the photon behaves like a free
particle. In 1924, de Broglie postulated that analogous relations should hold for the
free motion of a real particle: in this case, the fundamental dynamic properties are
energy and momentum, to which a frequency and a wavelength (or a wave vector)
are associated by relations identical to (7.20), (7.21),17
</p>
<p>Ï = 2Ï Î½ = 2Ï E
h
</p>
<p>= E
hÌ
</p>
<p>, k = 2Ï
Î»
</p>
<p>= 2Ï
h/p
</p>
<p>= p
hÌ
</p>
<p>, k = p
hÌ
. (7.31)
</p>
<p>The usefulness of associating, e.g., a wavelength to a particle&rsquo;s motion lies in the
possibility of qualitatively justifying the quantization of the mechanical properties
</p>
<p>16 This result shows that the physical constants appearing in (7.29) are not independent from each
other. Among them, Î½R is considered the dependent one, while q, m = m0, Îµ0, and h are considered
fundamental.
17 The wavelength associated to the particle&rsquo;s momentum is called de Broglie&rsquo;s wavelength.</p>
<p/>
</div>
<div class="page"><p/>
<p>146 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>illustrated in Sect. 7.4.4. For this, consider the case of the circular orbit of the
planetary motion, and associate a wavelength to the particle&rsquo;s momentum, Î» = h/p.
Such an association violates the prescription that (7.31) apply only to a free motion;
however, if the orbit&rsquo;s radius is very large, such that Î» âª r , the orbit may be
considered as locally linear and the concept of wavelength is applicable. Replacing
Î» = h/p in (7.30) yields
</p>
<p>2Ï r = n Î», (7.32)
</p>
<p>namely, the quantization of the mechanical properties implies that the orbit&rsquo;s length
is an integer multiple of the wavelength associated to the particle. This outcome
suggests that the formal description of quantization should be sought in the field of
eigenvalue equations.
</p>
<p>De Broglie also postulated that a function Ï = Ï(r, t), containing the parameters
Ï, k defined in (7.31), and called wave function, is associated to the particle&rsquo;s motion.
Its meaning is provisionally left indefinite; as for its form, it is sensible to associate
to the free motion, which is the simplest one, the simplest wave function, that is, the
planar monochromatic wave. The latter is conveniently expressed in complex form as
</p>
<p>Ï = A exp [i (k &middot; r &minus; Ï t)], (7.33)
</p>
<p>where A ï¿½= 0 is a complex constant, not specified. Due to (7.31), the constant wave
vector k identifies the momentum of the particle, and the angular frequency Ï iden-
tifies its total energy, which in a free motion coincides with the kinetic energy. It is
worth pointing out that, despite its form, the wave function is not of electromagnetic
nature; in fact, remembering that in a free motion it is H = p2/(2m) = E, with H
the Hamiltonian function, it follows
</p>
<p>hÌ Ï = 1
2m
</p>
<p>hÌ2 k2, Ï(k) = hÌ
2m
</p>
<p>k2, (7.34)
</p>
<p>which is different from the electromagnetic relation Ï = c k. By the same token it
would not be correct to identify the particle&rsquo;s velocity with the phase velocity uf
derived from the electromagnetic definition; in fact, one has
</p>
<p>uf =
Ï
</p>
<p>k
= E/hÌ
</p>
<p>p/hÌ
= p
</p>
<p>2/(2m)
</p>
<p>p
= p
</p>
<p>2m
. (7.35)
</p>
<p>The proper definition of velocity is that deriving from Hamilton&rsquo;s Eqs. (1.42); its
ith component reads in this case
</p>
<p>ui = xÌi =
&part;H
</p>
<p>&part;pi
= 1
</p>
<p>hÌ
</p>
<p>&part;H
</p>
<p>&part;ki
= &part;Ï
</p>
<p>&part;ki
= hÌki
</p>
<p>m
= pi
</p>
<p>m
. (7.36)
</p>
<p>The concepts introduced so far must now be extended to motions of a more general
type. A sensible generalization is that of the conservative motion of a particle
subjected to the force deriving from a potential energy V (r). In this case the
association described by (7.31) works only partially, because in a conservative</p>
<p/>
</div>
<div class="page"><p/>
<p>7.5 Heuristic Derivation of the Schr&ouml;dinger Equation 147
</p>
<p>motion the total energy is a constant, whereas momentum is generally not so. As a
consequence, letting Ï = E/hÌ yields for the wave function the form
</p>
<p>Ï = w(r) exp ( &minus; iÏ t), (7.37)
</p>
<p>which is still monochromatic but, in general, not planar. Its spatial part w(r) reduces
to A exp (i k &middot; r) for the free motion. The function of the form (7.37) is postulated
to be the wave function associated with the motion of a particle at constant energy
E = hÌÏ. While the time dependence of Ï is prescribed, its space dependence must
be worked out, likely by solving a suitable equation involving the potential energy
V , the particle&rsquo;s mass and, possibly, other parameters.
</p>
<p>7.5 Heuristic Derivation of the Schr&ouml;dinger Equation
</p>
<p>The concept of wave function introduced in Sect. 7.4.5 has been extended from the
case of a free motion, where the wave function is fully prescribed apart from the
multiplicative constant A, to the case of a conservative motion (7.37), where only
the time dependence of the wave function is known. It is then necessary to work
out a general method for determining the spatial part w(r). The starting point is
the observation that w is able at most to provide information about the particle&rsquo;s
trajectory, not about the particle&rsquo;s dynamics along the trajectory. One of the methods
used in Classical Mechanics to determine the trajectories is based on the Maupertuis
principle (Sect. 2.7); moreover, from the discussion carried out in Sect. 5.11.6 it turns
out that the analogy between the Maupertuis principle and the Fermat principle of
Geometrical Optics (compare with (5.80)) provides the basis for a generalization of
the mechanical laws. The first of the two principles applies to a particle (or system of
particles) subjected to a conservative force field prescribed by a potential energyV (r),
with E a given constant; the second one applies to a monochromatic ray (Î½ = const)
propagating in a medium whose properties are prescribed by the refraction index
n(r). The latter is related to frequency and wavelength by n = c/(Î» Î½) (compare
with (5.55)); as a consequence, (5.80) can be rewritten as
</p>
<p>Î´
</p>
<p>&int;
</p>
<p>AB
</p>
<p>&radic;
E &minus; V ds = 0, Î´
</p>
<p>&int;
</p>
<p>AB
</p>
<p>1
</p>
<p>Î»
ds = 0. (7.38)
</p>
<p>Considering that the variational principles hold apart from a multiplicative constant,
the two expressions in (7.38) transform into each other by letting
</p>
<p>&radic;
E &minus; V = Î±
</p>
<p>Î»
, (7.39)
</p>
<p>where Î± is a constant that must not depend on the form of V or Î», nor on other
parameters of the problem. For this reason, Î± is left unchanged also after removing
the Geometrical-Optics approximation; when this happens, the Fermat principle is
replaced with the Maxwell equations or, equivalently, with the wave equations for</p>
<p/>
</div>
<div class="page"><p/>
<p>148 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>the electric field (4.64) and magnetic field (4.65). For simplicity, the latter equations
are solved in a uniform medium with no charges in it, on account of the fact that Î± is
not influenced by the medium&rsquo;s properties. Also, considering that in the uniform case
(4.64) and (4.65) have the same structure, and that the function w under investigation
is scalar, the analysis is limited to any scalar component C of E or H; such a
component fulfills the equation
</p>
<p>&nabla;2C &minus; 1
u2f
</p>
<p>&part;2C
</p>
<p>&part;t2
= 0, (7.40)
</p>
<p>with uf = const the medium&rsquo;s phase velocity. Solving (7.40) by separation with
C(r, t) = Î· (r) Î¸ (t) yields
</p>
<p>Î¸ &nabla;2Î· = 1
u2f
</p>
<p>Î¸Ì Î·,
&nabla;2Î·
Î·
</p>
<p>= 1
u2f
</p>
<p>Î¸Ì
</p>
<p>Î¸
= &minus;k2, (7.41)
</p>
<p>where the separation constant &minus;k2 must be negative to prevent Î¸ from diverging. As
a consequence, k is real and can be assumed to be positive. The solution for the time
factor is Î¸ = cos (Ït + Ï), where the phase Ï depends on the initial conditions, and
Ï = 2Ï Î½ = uf k &gt; 0. It follows k = 2Ï Î½/uf = 2Ï/Î», whence the spatial part of
(7.40) reads
</p>
<p>&nabla;2Î· + (2Ï )
2
</p>
<p>Î»2
Î· = 0, (7.42)
</p>
<p>namely, a Helmholtz equation (Sect. 4.7). By analogy, the equation for the spatial
part w of the wave function is assumed to be
</p>
<p>&nabla;2w + (2Ï )
2
</p>
<p>Î±2
E w = 0, (7.43)
</p>
<p>which is obtained from (7.42) by replacing Î·with w and using (7.39) withV = 0. The
value of Î± is determined by expressing E in (7.43) in terms of the de Broglie wave-
length; using the symbolÎ»dB for the latter to avoid confusion with the electromagnetic
counterpart, one finds E = p2/(2m) = h2/(2mÎ»2dB), namely,
</p>
<p>&nabla;2w + (2Ï )
2
</p>
<p>Î±2
</p>
<p>h2
</p>
<p>2m
</p>
<p>1
</p>
<p>Î»2dB
w = 0. (7.44)
</p>
<p>Equation (7.44) becomes identical to (7.42) by letting Î±2 = h2/(2m) whence, using
the reduced Planck constant hÌ, (7.43) becomes &nabla;2w + (2mE/hÌ2) w = 0. Such
a differential equation holds in a uniform medium; hence, the dynamical property
involved is the kinetic energy of the particle. The extension to the case of a non-
uniform medium is then obtained by using the general form E &minus; V of the kinetic
energy in terms of the coordinates; in conclusion, the equation for the spatial part of
the wave function in a conservative case is
</p>
<p>&nabla;2w + 2m
hÌ2
</p>
<p>(E &minus; V ) w = 0, &minus; hÌ
2
</p>
<p>2m
&nabla;2w + V w = E w. (7.45)</p>
<p/>
</div>
<div class="page"><p/>
<p>7.6 Measurement 149
</p>
<p>The above is the time-independent Schr&ouml;dinger equation. It is a homogenous equa-
tion, with E the eigenvalue and w the eigenfunction.18 Although the derivation based
on the analogy between mechanical and optical principles is easy to follow, it must
be remarked that the step leading from (7.44) to (7.45) is not rigorous; in the electro-
magnetic case, in fact, Eq. (7.42) for the spatial part holds only in a uniform medium;
when the latter is non uniform, instead, the right hand side of (7.42) is different from
zero, even in a charge-free case, because it contains the gradient of the refraction
index. As shown in Sect. 1.10.4, the actual method used in 1926 by Schr&ouml;dinger for
deriving (7.45) consists in seeking the constrained extremum of a functional gen-
erated by the Hamilton&ndash;Jacobi equation; in such a procedure, the hypothesis of a
uniform medium is not necessary.
</p>
<p>It is also worth noting that in the analogy between mechanical and optical prin-
ciples the spatial part of the wave function, and also the wave function as a whole,
is the analogue of a component of the electromagnetic field. From this standpoint,
the analogue of the field&rsquo;s intensity is the wave function&rsquo;s square modulus. In the
monochromatic case, the latter reads |Ï |2 = |w|2. This reasoning is useful in the
discussion about the physical meaning of Ï .
</p>
<p>7.6 Measurement
</p>
<p>To make the wave function a useful tool for the description of the particles&rsquo;dynamics
it is necessary to connect the value taken by Ï , at a specific position and time, with
some physical property of the particle (or system of particles) under investigation.
To make such a connection it is in turn necessary to measure the property of interest;
otherwise, the hypotheses illustrated in the previous sections would be relegated to a
purely abstract level. In other terms, the meaning of the wave function can be given
only by discussing the measuring process in some detail. The analysis is carried
out below, following the line of [69]; in particular, a general formalism is sought
which applies to both the macroscopic and microscopic bodies; the specific features
brought about by the different size of the objects that are being measured are made
evident by suitable examples.
</p>
<p>The measurement of a dynamical variable A pertaining to a physical body is
performed by making the body to interact with a measuring apparatus and recording
the reading shown by the latter. For simplicity it is assumed that there is a finite
number of possible outcomes of the measurement, say, A1, . . . ,AM . The extension
to the case of a continuous, infinitely extended set of outcomes can be incorporated
into the theory at the cost of a more awkward notation. Letting Ai be the outcome
of the measurement of A, consider the case where the body is later subjected to the
measurement of another dynamical variable B. Assume that the outcome of such
a measurement is Bj , out of the possible outcomes B1, . . . ,BN . Next, the body is
subjected to the measurement of a third variable C, this yielding the value Ck , and
so on.
</p>
<p>18 The structure of (7.45) is illustrated in detail in Chap. 8.</p>
<p/>
</div>
<div class="page"><p/>
<p>150 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>As in general the dynamical variables depend on time, it is necessary to specify
the time of each measurement. The most convenient choice is to assume that the time
interval between a measurement and the next one is negligibly small, namely, that
the measurement of B takes place immediately after that of A, similarly for that of
C, and so on. The duration of each measurement is considered negligible as well. A
special consequence of this choice is the following: if the measurement of A yielded
Ai , and the measurement is repeated (namely, B = A), the outcome of the second
measurement is again Ai .
</p>
<p>Consider now the case where, after finding the numbers Ai , Bj , and Ck from the
measurements of A, B, and C, respectively, the three variables are measured again,
in any order. The experiments show that the results depend on the size of the body
being measured. For a massive body the three numbers Ai , Bj , and Ck are always
found. One concludes that the dynamical state of a massive body is not influenced
by the interaction with the measuring apparatus or, more precisely, that if such an
influence exists, it is so small that it can not be detected. As a consequence one may
also say that the values of the dynamical variables are properties of the body that
exist prior, during, and after each measurement.
</p>
<p>The situation is different for a microscopic body. By way of example, consider
the case of a measurement of B followed by a measurement of A, the first one
yielding Bn, the second one yielding Ai . If the measurement of B is carried out
again after that of A, the result is still one of the possible outcomes B1, . . . ,BN , but
it is not necessarily equal to Bn. In other terms, the individual outcome turns out
to be unpredictable. For a microscopic body one concludes that the interaction with
the measuring apparatus is not negligible. It is worth observing that the apparatus
able to measure the dynamical variable A may also be conceived in such a way as to
block all outcomes that are different from a specific one, say, Ai . In such a case the
apparatus is termed filter. Using the concept of filter one may build up the statistical
distribution of the outcomes, for instance by repeating a large number of times the
experiment in which the measurement of B is carried out after filtering Ai . The
statistics is built up by recording the fraction of cases in which the measurement of
B carried out on an Ai-filtered body yields the result Bj , j = 1, . . . ,N .
</p>
<p>7.6.1 Probabilities
</p>
<p>The fraction of measurements of the type described above, namely, of those that
yield Bj after a measurement of A that has yielded Ai , will be indicated with the
symbol P (Ai &rarr; Bj ). Obviously the following hold:
</p>
<p>0 &le; P (Ai &rarr; Bj ) &le; 1,
N
&sum;
</p>
<p>j=1
P (Ai &rarr; Bj ) = 1. (7.46)
</p>
<p>The first relation in (7.46) is due to the definition of P (Ai &rarr; Bj ), the second one to
the fact that the set of valuesB1, . . . ,BN encompasses all the possible outcomes of the</p>
<p/>
</div>
<div class="page"><p/>
<p>7.6 Measurement 151
</p>
<p>measurement ofB. It follows thatP (Ai &rarr; Bj ) is the probability that a measurement
of the dynamical variableB, made on a particle that prior to the measurement is in the
state Ai of the dynamical variable A, yields the value Bj . The possible combinations
of P (Ai &rarr; Bj ) are conveniently arranged in the form of an M-row&times;N -column
matrix:
</p>
<p>PAB =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â£
</p>
<p>P (A1 &rarr; B1) . . . P (A1 &rarr; BN )
...
</p>
<p>...
</p>
<p>P (Ai &rarr; B1) . . . P (Ai &rarr; BN )
...
</p>
<p>...
</p>
<p>P (AM &rarr; B1) . . . P (AM &rarr; BN )
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¦
</p>
<p>. (7.47)
</p>
<p>Due to (7.46), each row of PAB adds up to unity. As the number of rows is M , the
sum of all entries of matrix (7.47) is M . The same reasoning can also be made when
the measurement of B is carried out prior to that of A. In this case the following
N -row&times;M-column matrix is obtained:
</p>
<p>PBA =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â£
</p>
<p>P (B1 &rarr; A1) . . . P (B1 &rarr; AM )
...
</p>
<p>...
</p>
<p>P (Bj &rarr; A1) . . . P (Bj &rarr; AM )
...
</p>
<p>...
</p>
<p>P (BN &rarr; A1) . . . P (BN &rarr; AM )
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¦
</p>
<p>, (7.48)
</p>
<p>with
</p>
<p>0 &le; P (Bj &rarr; Ai) &le; 1,
M
&sum;
</p>
<p>i=1
P (Bj &rarr; Ai) = 1. (7.49)
</p>
<p>As the number of rows in (7.49) is N , the sum of all entries of matrix PBA is N . It
can be proven that it must be
</p>
<p>P (Bj &rarr; Ai) = P (Ai &rarr; Bj ) (7.50)
</p>
<p>for any pair of indices ij . In fact, if (7.50) did not hold, thermodynamic equilibrium
would not be possible [69, Ch. V-21]. Equality (7.50) makes PBA the transpose of
PAB . As a consequence, the sum of all entries of the two matrices must be the same,
namely, N = M . In other terms the outcomes of the measurements have the same
multiplicity, and the matrices (7.47), (7.48) are square matrices of order N = M .
Combining (7.50) with the second of (7.49) yields
</p>
<p>M
&sum;
</p>
<p>i=1
P (Ai &rarr; Bj ) =
</p>
<p>M
&sum;
</p>
<p>i=1
P (Bj &rarr; Ai) = 1, (7.51)</p>
<p/>
</div>
<div class="page"><p/>
<p>152 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>showing that in the matrices (7.47), (7.48) not only each row, but also each column
adds up to unity. A square matrix where all entries are non negative and all rows and
columns add up to unity is called doubly stochastic matrix. Some properties of this
type of matrices are illustrated in [76, Ch. II-1.4] and in Sect. A.11.
</p>
<p>Note that (7.50) does not imply any symmetry of PAB . In fact, symmetry would
hold if P (Aj &rarr; Bi) = P (Ai &rarr; Bj ). If the filtered state is Ai and the measurement
of the dynamical variable A is repeated, the result is Ai again. In other terms,
</p>
<p>P (Ai &rarr; Ai) = 1, P (Ai &rarr; Ak) = 0, k ï¿½= i. (7.52)
</p>
<p>This result can be recast in a more compact form as PAA = I, with I the identity
matrix.
</p>
<p>7.6.2 Massive Bodies
</p>
<p>It is useful to consider the special case where the measurement of B does not change
the outcome of a previous measurement of A, and viceversa. In other terms, assume
that the measurement of A has yielded Ai and the subsequent measurement of B
has yielded Bj ; then, another measure of A yields Ai again, a later measure of B
yields Bj again, and so on. It follows that in P&prime;AB it is P
</p>
<p>&prime;(Ai &rarr; Bj ) = 1, while all
remaining entries in the ith row and j th column are equal to zero. This situation is
typical of the bodies that are sufficiently massive, such that the interference suffered
during the measurement of a dynamical variable is not detectable. For the sake of
clarity an apex is used here to distinguish the probabilities from those of the general
case where the body&rsquo;s mass can take any value. Considering a 4 &times; 4 matrix by way
of example, a possible form of the matrix would be
</p>
<p>P&prime;AB =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â¢
â¢
â£
</p>
<p>0 1 0 0
</p>
<p>0 0 1 0
</p>
<p>1 0 0 0
</p>
<p>0 0 0 1
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¥
â¥
â¦
</p>
<p>, (7.53)
</p>
<p>that is, one of the 4! possible permutation matrices of order 4. Clearly all the other
permutation matrices of order 4 different from (7.53) are equally possible. The mean-
ing of a matrix like (7.53) is that the successive measurements ofA andB yield either
the pairA1,B2, or the pairA2,B3, orA3,B1, orA4,B4. Matrix (7.53) may be thought
of as a limiting case: starting from a microscopic body described by a 4&times; 4, doubly
stochastic matrix whose entries are in general different from zero, the size of the
body is increased by adding one atom at a time, and the set of measurements of A
and B is repeated at each time. As the reasoning that prescribes the doubly-stochastic
nature of the matrix holds at each step, the successive matrices must tend to the limit
of a permutation matrix. Which of the 4! permutation matrices will be reached by</p>
<p/>
</div>
<div class="page"><p/>
<p>7.7 Born&rsquo;s Interpretation of the Wave Function 153
</p>
<p>this process depends on the initial preparation of the experiments. One may wonder
why a matrix like
</p>
<p>P&prime;AB =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â¢
â¢
â£
</p>
<p>0 1 0 0
</p>
<p>0 1 0 0
</p>
<p>1 0 0 0
</p>
<p>0 0 0 1
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¥
â¥
â¦
</p>
<p>, (7.54)
</p>
<p>should not be reached. In fact, such a matrix is not acceptable because it is not dou-
bly stochastic: its transpose implies that the outcomes B1 and B2 are simultaneously
associated to A2 with certainty, which is obviously impossible not only for a massive
body, but for any type of body. This reasoning is associated to another argument,
based on the theorem mentioned in Sect. A.11, stating that a doubly-stochastic matrix
is a convex combination of permutation matrices. Letting Î¸1, . . . , Î¸M be the com-
bination&rsquo;s coefficients as those used in (A.42), in the process of transforming the
microscopic body into a macroscopic one all the coefficients but one vanish, and the
non-vanishing one tends to unity. As a consequence, out of the original combination,
only one permutation matrix is left.
</p>
<p>7.6.3 Need of a Description of Probabilities
</p>
<p>The non-negligible influence of the measuring apparatus on the dynamical state of
a microscopic body makes it impossible to simultaneously measure the dynamical
variables that constitute the initial conditions of the motion. As a consequence, the
possibility of using the Hamiltonian theory for describing the dynamics is lost. As
outlined in the above sections, the distinctive mark of experiments carried out on
microscopic objects is the statistical distribution of the outcomes; thus, a theory that
adopts the wave function as the basic tool must identify the connection between the
wave function and such a statistical distribution. The theory must also contain the
description of the massive bodies as a limiting case.
</p>
<p>7.7 Born&rsquo;s Interpretation of the Wave Function
</p>
<p>Basing on the optical analogy and the examination of experiments, the probabilistic
interpretation of the wave function introduced by Born states that the integral
</p>
<p>&int;
</p>
<p>Ï
</p>
<p>|Ï(r, t)|2 d3r (7.55)</p>
<p/>
</div>
<div class="page"><p/>
<p>154 7 From Classical Mechanics to Quantum Mechanics
</p>
<p>is proportional to the probability that a measuring process finds the particle within
the volume Ï at the time t .19 Note that the function used in (7.55) is the square
modulus of Ï , namely, as noted in Sect. 7.5, the counterpart of the field&rsquo;s intensity
in the optical analogy. Also, considering that by definition the integral of (7.55) is
dimensionless, the units20 of Ï are m&minus;3/2.
</p>
<p>When Ï &rarr; &infin; the integral in (7.55) may, or may not, converge. In the first case,
Ï is said to be normalizable, and a suitable constant Ï can be found such that the
integral of |ÏÏ |2 over the entire space equals unity. The new wave function provides
a probability proper,
</p>
<p>&int;
</p>
<p>Ï
</p>
<p>|Ï Ï |2 d3r &le; 1, Ï&minus;2 =
&int;
</p>
<p>&infin;
|Ï |2 d3r. (7.56)
</p>
<p>In the second case Ï is not normalizable:21 a typical example is the wave function
of a free particle, Ï = A exp [i (k &middot; r &minus; Ït)]; however, it is still possible to define a
probability ratio
</p>
<p>&int;
</p>
<p>Ï1
</p>
<p>|Ï |2 d3r
(&int;
</p>
<p>Ï2
</p>
<p>|Ï |2 d3r
)&minus;1
</p>
<p>, (7.57)
</p>
<p>where both volumes Ï1 and Ï2 are finite. Relation (7.57) gives the ratio between the
probability of finding the particle within Ï1 and that of finding it within Ï2.
</p>
<p>Consider a particle whose wave function at time t differs from zero within some
volume Ï , and assume that a process of measuring the particle&rsquo;s position is initiated
at t and completed at some later time t &prime;; let the outcome of the experiment be an
improved information about the particle&rsquo;s location, namely, at t &prime; the wave function
differs from zero in a smaller volume Ï &prime; &sub; Ï . This event is also called contraction
of the wave function.
</p>
<p>7.8 Complements
</p>
<p>7.8.1 Core Electrons
</p>
<p>Throughout this book the term &ldquo;nucleus&rdquo; is used to indicate the system made of
protons, neutrons, and core electrons, namely, those electrons that do not belong to
the outer shell of the atom and therefore do not participate in the chemical bonds. In
solid-state materials, core electrons are negligibly perturbed by the environment, in
contrast to the electrons that belong to the outer shell (valence electrons).
</p>
<p>19 From this interpretation it follows that |Ï |2 d3r is proportional to an infinitesimal probability,
and |Ï |2 to a probability density.
20 A more detailed discussion about the units of the wave function is carried out in Sect. 9.7.1.
21 This issue is further discussed in Sect. 8.2.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 8
</p>
<p>Time-Independent Schr&ouml;dinger Equation
</p>
<p>8.1 Introduction
</p>
<p>The properties of the time-independent Schr&ouml;dinger equation are introduced step
by step, starting from a short discussion about its boundary conditions. Consider-
ing that the equation is seldom amenable to analytical solutions, two simple cases
are examined first: that of a free particle and that of a particle in a box. The deter-
mination of the lower energy bound follows, introducing more general issues that
build up the mathematical frame of the theory: norm of a function, scalar product
of functions, Hermitean operators, eigenfunctions and eigenvalues of operators, or-
thogonal functions, and completeness of a set of functions. The chapter is concluded
with the important examples of the Hamiltonian operator and momentum operator.
The complements provide examples of Hermitean operators, a collection of oper-
ators&rsquo; definitions and properties, examples of commuting operators, and a further
discussion about the free-particle case.
</p>
<p>8.2 Properties of the Time-Independent Schr&ouml;dinger Equation
</p>
<p>A number of properties of the time-independent Schr&ouml;dinger equation are discussed
in this section. The form (7.45) holds only when the force is conservative, so it is not
the most general one. However, as will be shown later, many of its properties still
hold in more complicated cases. Equation (7.45) is a linear, homogeneous partial-
differential equation of the second order, with the zero-order coefficient depending on
r.As shown in Prob. 8.1, it is a very general form of linear, second-order equation. The
boundary conditions are specified on a case-by-case basis depending on the problem
under consideration. More details about the boundary conditions are discussed below.
One notes that:
</p>
<p>1. The coefficients of (7.45) are real. As a consequence, the solutions are real.
In same cases, however, it is convenient to express them in complex form. An
example is given in Sect. 8.2.1.
</p>
<p>&copy; Springer Science+Business Media New York 2015 155
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_8</p>
<p/>
</div>
<div class="page"><p/>
<p>156 8 Time-Independent Schr&ouml;dinger Equation
</p>
<p>2. The equation is linear and homogeneous and, as shown below, its boundary
conditions are homogeneous as well. It follows that its solution is defined apart
from a multiplicative constant. The function w = 0 is a solution of (7.45), however
it has no physical meaning and is not considered.
</p>
<p>3. As the equation is of the second order, its solution w and first derivatives &part;w/&part;xi
are continuous. These requirements are discussed from the physical standpoint
in Sect. 9.4. The second derivatives may or may not be continuous, depending
on the form of the potential energy V .
</p>
<p>4. The solution of (7.45) may contain terms that diverge as |r| &rarr; &infin;. In this case
such terms must be discarded because they are not compatible with the physical
meaning of w (examples are given in Sect. 8.2.1).
</p>
<p>Given the above premises, to discuss the boundary conditions of (7.45) it is convenient
to distinguish a few cases:
</p>
<p>A. The domainï¿½ of w is finite; in other terms, some information about the problem in
hand is available, from which it follows that w vanishes identically outside a finite
domain ï¿½. The continuity of w (see point 3 above) then implies that w vanishes
over the boundary of ï¿½, hence the boundary conditions are homogeneous. After
discarding possible diverging terms from the solution, the integral
</p>
<p>&int;
</p>
<p>ï¿½
|w|2 dï¿½ is
</p>
<p>finite (the use of the absolute value is due to the possibility that w is expressed in
complex form, see point 1 above).
</p>
<p>B. The domain of w is infinite in all directions, but the form of w is such that
&int;
</p>
<p>ï¿½
|w|2 dï¿½ is finite. When this happens, w necessarily vanishes as |r| &rarr; &infin;.
</p>
<p>Thus, the boundary conditions are homogeneous also in this case.1
</p>
<p>C. The domain of w is infinite, and the form of w is such that
&int;
</p>
<p>ï¿½
|w|2 dï¿½ diverges.
</p>
<p>This is not due to the fact that |w|2 diverges (in fact, divergent terms in w must be
discarded beforehand), but to the fact that w, e.g., asymptotically tends to a con-
stant different from zero, or oscillates (an example of asymptotically-oscillating
behavior is given in Sect. 8.2.1). These situations must be tackled separately; one
finds that w is still defined apart from a multiplicative constant.
</p>
<p>As remarked above, the time-independent Schr&ouml;dinger equation is a second-order
differential equation of a very general form. For this reason, an analytical solution
can seldom be obtained, and in the majority of cases it is necessary to resort to
numerical-solution methods. The typical situations where the problem can be tackled
analytically are those where the equation is separable (compare with Sect. 10.3),
so that it can be split into one-dimensional equations. Even when this occurs, the
analytical solution can be found only for some forms of the potential energy. The
rest of this chapter provides examples that are solvable analytically.
</p>
<p>1 It may happen that the domain is infinite in some direction and finite in the others. For instance,
one may consider the case where w vanishes identically for x &ge; 0 and differs from zero for x &lt; 0.
Such situations are easily found to be a combination of cases A and B illustrated here.</p>
<p/>
</div>
<div class="page"><p/>
<p>8.2 Properties of the Time-Independent Schr&ouml;dinger Equation 157
</p>
<p>8.2.1 Schr&ouml;dinger Equation for a Free Particle
</p>
<p>The equation for a free particle is obtained by letting V = const in (7.45). Without
loss of generality one may let V = 0, this yielding &nabla;2w = &minus;(2mE/hÌ2) w. As the
above can be solved by separating the variables, it is sufficient to consider here only
the one-dimensional form
</p>
<p>d2w
</p>
<p>dx2
= &minus;2mE
</p>
<p>hÌ2
w. (8.1)
</p>
<p>The case E &lt; 0 must be discarded as it gives rise to divergent solutions, which are
not acceptable from the physical standpoint. The case E = 0 yields w = a1x + a2,
where a1 must be set to zero to prevent w from diverging. As a consequence, the
value E = 0 yields w = a2 = const, that is one of the possibilities anticipated at
point C of Sect. 8.2. The integral of |w|2 diverges. Finally, the case E &gt; 0 yields
</p>
<p>w = c1 exp (i k x) + c2 exp ( &minus; i k x), k =
&radic;
</p>
<p>2mE/hÌ2 = p/hÌ &gt; 0, (8.2)
</p>
<p>where c1, c2 are constants to be determined. Thus, the value E &gt; 0 yields the
asymptotically-oscillating behavior that has also been anticipated at point C of
Sect. 8.2. The integral of |w|2 diverges. One notes that w is written in terms of
two complex functions; it could equally well be expressed in terms of the real func-
tions cos (k x) and sin (k x). The time-dependent, monochromatic wave function
Ï = w exp ( &minus; iÏ t) corresponding to (8.2) reads
</p>
<p>Ï = c1 exp [i (k x &minus; Ï t)] + c2 exp [ &minus; i (k x + Ï t)], Ï = E/hÌ. (8.3)
</p>
<p>The relations k = p/hÌ, Ï = E/hÌ stem from the analogy described in Sect. 7.4.5.
The total energy E and momentum&rsquo;s modulus p are fully determined; this outcome
is the same as that found for the motion of a free particle in Classical Mechanics: for
a free particle the kinetic energy equals the total energy; if the latter is prescribed,
the momentum&rsquo;s modulus is prescribed as well due to E = p2/(2m). The direction
of the motion, instead, is not determined because both the forward and backward
motions, corresponding to the positive and negative square root of p2 respectively,
are possible solutions. To ascertain the motion&rsquo;s direction it is necessary to acquire
more information; specifically, one should prescribe the initial conditions which, in
turn, would provide the momentum&rsquo;s sign.
</p>
<p>The quantum situation is similar, because the time-dependent wave function (8.2)
is a superposition of a planar wave c1 exp [i (k x &minus; Ï t)] whose front moves in the
positive direction, and of a planar wave c2 exp [ &minus; i (k x + Ï t)] whose front moves
in the negative direction. Here to ascertain the motion&rsquo;s direction one must acquire
the information about the coefficients in (8.2): the forward motion corresponds to
c1 ï¿½= 0, c2 = 0, the backward motion to c1 = 0, c2 ï¿½= 0. Obviously (8.2) in itself does
not provide any information about the coefficients, because such an expression is the
general solution of (8.1) obtained as a combination of the two linearly-independent,
particular solutions exp (i k x) and exp (&minus;i k x); so, without further information about
c1 and c2, both the forward and backward motions are possible.</p>
<p/>
</div>
<div class="page"><p/>
<p>158 8 Time-Independent Schr&ouml;dinger Equation
</p>
<p>Another similarity between the classical and quantum cases is that no constraint is
imposed on the total energy, apart from the prescription E &ge; 0. From this viewpoint
one concludes that (8.1) is an eigenvalue equation with a continuous distribution of
eigenvalues in the interval E &ge; 0.
</p>
<p>8.2.2 Schr&ouml;dinger Equation for a Particle in a Box
</p>
<p>Considering again the one-dimensional case of (7.45),
</p>
<p>d2w
</p>
<p>dx2
= &minus;2m
</p>
<p>hÌ2
(E &minus; V ) w, V = V (x), (8.4)
</p>
<p>let V = const = 0 for x &isin; [0, a] and V = V0 &gt; 0 elsewhere. The form of the
potential energy is that of a square well whose counterpart of Classical Mechanics is
illustrated in Sect. 3.2. Here, however, the limit V0 &rarr; &infin; is considered for the sake
of simplicity. This limiting case is what is referred to with the term box. As shown
in Sect. 11.5, here w vanishes identically outside the interval [0, a]: this is one of
the possibilities that were anticipated in Sect. 8.2 (point A). The continuity of w then
yields w(0) = w(a) = 0. It is easily found that if E &le; 0 the only solution of (8.4) is
w = 0, which is not considered because it has no physical meaning. When E &gt; 0,
the solution reads
</p>
<p>w = c1 exp (i k x) + c2 exp ( &minus; i k x), k =
&radic;
</p>
<p>2mE/hÌ2 &gt; 0. (8.5)
</p>
<p>Letting w(0) = 0 yields c1 + c2 = 0 and w = 2 i c1 sin (k x). Then, w(a) = 0 yields
k a = nÏ with n an integer whence, using the relation k = kn = nÏ/a within those
of E and w,
</p>
<p>E = En =
hÌ2 Ï2
</p>
<p>2ma2
n2, w = wn = 2 i c1 sin
</p>
<p>(nÏ
</p>
<p>a
x
)
</p>
<p>. (8.6)
</p>
<p>This result shows that (8.4) is an eigenvalue equation with a discrete distribution of
eigenvalues, given by the first relation in (8.6). For this reason, the energy is said to be
quantized. To each index n it corresponds one and only one eigenvalue En, and one
and only one eigenfunction wn; as a consequence, this case provides a one-to-one-
correspondence between eigenvalues and eigenfunctions.2 Not every integer should
be used in (8.6) though; in fact, n = 0 must be discarded because the corresponding
eigenfunction vanishes identically. Also, the negative indices are to be excluded
because E&minus;n = En and |w&minus;n|2 = |wn|2, so they do not add information with respect
to the positive ones. In conclusion, the indices to be used are n = 1, 2, . . .
</p>
<p>2 The one-to-one correspondence does not occur in general. Examples of the Schr&ouml;dinger equation
are easily given (Sect. 9.6) where to each eigenvalue there corresponds more than one&mdash;even
infinite&mdash; eigenfunctions.</p>
<p/>
</div>
<div class="page"><p/>
<p>8.2 Properties of the Time-Independent Schr&ouml;dinger Equation 159
</p>
<p>Fig. 8.1 The first
eigenfunctions of the
Schr&ouml;dinger equation in the
case of a particle in a box
</p>
<p>0 0.2 0.4 0.6 0.8 1
x / a
</p>
<p>-1
</p>
<p>-0.5
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>(a
 /
</p>
<p> 2
)1
</p>
<p>/2
w
</p>
<p>n
</p>
<p>n = 1
n = 2
n = 3
n = 4
</p>
<p>As expected, each eigenfunction contains a multiplicative constant; here the inte-
gral of |w|2 converges, so the constant can be exploited to normalize the eigenfunction
by letting
</p>
<p>&int; a
</p>
<p>0 |wn|2 dx = 1. One finds
&int; a
</p>
<p>0
|wn|2 dx = 4 |c1|2
</p>
<p>&int; a
</p>
<p>0
sin2
</p>
<p>(nÏ
</p>
<p>a
x
)
</p>
<p>dx = 4 |c1|
2a
</p>
<p>nÏ
</p>
<p>&int; nÏ
</p>
<p>0
sin2 (y) dy. (8.7)
</p>
<p>Integrating by parts shows that the last integral equals nÏ/2, whence the normal-
ization condition yields 4 |c1|2 = 2/a. Choosing 2 c1 = &minus;j
</p>
<p>&radic;
2/a provides the
</p>
<p>eigenfunctions
</p>
<p>wn =
&radic;
</p>
<p>2
</p>
<p>a
sin
</p>
<p>(nÏ
</p>
<p>a
x
)
</p>
<p>. (8.8)
</p>
<p>The first eigenfunctions are shown in Fig. 8.1. Remembering that w = 0 outside
the interval [0, a], one notes that dw/dx is discontinuous at x = 0 and x = a.
This apparently contradicts the continuity property of the first derivative mentioned
in Sect. 8.2, point 3. However, in the case considered here the limit V0 &rarr; &infin; has
introduced a discontinuity of the second kind into the potential energy; for this reason,
the property mentioned above does not apply.
</p>
<p>8.2.3 Lower Energy Bound in the Schr&ouml;dinger Equation
</p>
<p>In the example of Sect. 8.2.1, where the free particle is considered, the lower bound
for the particle&rsquo;s total energy is E &ge; Vmin, with Vmin the minimum3 of the potential
energy; in contrast, in the example of the particle in a box illustrated in Sect. 8.2.2,
the lower bound is E &gt; Vmin. A more general analysis of the lower bound for the
total energy in the Schr&ouml;dinger equation is carried out here.
</p>
<p>3 Such a minimum is set to zero in the example of Sect. 8.2.1.</p>
<p/>
</div>
<div class="page"><p/>
<p>160 8 Time-Independent Schr&ouml;dinger Equation
</p>
<p>Consider the time-independent Schr&ouml;dinger equation in a conservative case,
(7.45), and let ï¿½ be the domain of w (which may extend to infinity), with ï¿½ the
boundary of ï¿½. Recasting (7.45) as &minus;&nabla;2w = 2m (E &minus; V ) w/hÌ2 and integrating it
over ï¿½ after multiplying both sides by w&lowast; yields
</p>
<p>&minus;
&int;
</p>
<p>ï¿½
</p>
<p>w&lowast; &nabla;2w dï¿½ = 2m
hÌ2
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>(E &minus; V ) |w|2 dï¿½. (8.9)
</p>
<p>It is implied that w is a physically meaningful solution of (7.45), whence w does
not vanish identically within ï¿½. Thanks to the identity (A.17) and the divergence
theorem (A.23) the above becomes
</p>
<p>2m
</p>
<p>hÌ2
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>(E &minus; V ) |w|2 dï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>|gradw|2 dï¿½&minus;
&int;
</p>
<p>ï¿½
</p>
<p>w&lowast;
&part;w
</p>
<p>&part;n
dï¿½, (8.10)
</p>
<p>with &part;w/&part;n the derivative of w in the direction normal to ï¿½. Consider now the case
where w vanishes over ï¿½; as w&lowast; vanishes as well, the boundary integral in (8.10) is
equal to zero. In contrast, the other integral at the right hand side of (8.10) is strictly
positive: in fact, as w vanishes at the boundary while it is different from zero inside
the domain, its gradient does not vanish identically in ï¿½. It follows
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>(E &minus; V ) |w|2 dï¿½ &gt; 0, E &gt;
&int;
</p>
<p>ï¿½
V |w|2 dï¿½
</p>
<p>&int;
</p>
<p>ï¿½
|w|2 dï¿½ &ge; Vmin, (8.11)
</p>
<p>where the last inequality stems from the fact that |w|2 is strictly positive. In con-
clusion, when V is such that w vanishes at the boundary, then the strict inequality
E &gt; Vmin holds. When V does not vanish at the boundary, the reasoning leading to
(8.11) does not apply and the lower bound for E must be sought by a direct exam-
ination of the solutions. An example of this examination is that of the free-particle
case shown in Sect. 8.2.1.
</p>
<p>8.3 Norm of a Function&mdash;Scalar Product
</p>
<p>The functions f , g, . . . that are considered in this section are square-integrable
complex functions, namely, they have the property that the integrals
</p>
<p>||f ||2 =
&int;
</p>
<p>ï¿½&prime;
|f |2 dï¿½&prime;, ||g||2 =
</p>
<p>&int;
</p>
<p>ï¿½&prime;&prime;
|g|2 dï¿½&prime;&prime;, . . . (8.12)
</p>
<p>converge. In (8.12), ï¿½&prime; is the domain of f , ï¿½&prime;&prime; that of g, and so on. The variables in
the domains ï¿½&prime;, ï¿½&prime;&prime;, . . . are real. The positive numbers ||f || and ||g|| are the norm
of f and g, respectively. If f , g are square integrable over the same domain ï¿½, a
linear combination Î» f + Î¼g, with Î», Î¼ arbitrary complex constants, is also square
integrable over ï¿½ ([78], Chap. V.2).</p>
<p/>
</div>
<div class="page"><p/>
<p>8.3 Norm of a Function&mdash;Scalar Product 161
</p>
<p>If a square-integrable function f is defined apart from a multiplicative constant,
for instance because it solves a linear, homogeneous differential equation with ho-
mogeneous boundary conditions, it is often convenient to choose the constant such
that the norm equals unity. This is accomplished by letting Ï = c f and ||Ï|| = 1,
whence |c|2 = 1/||Ï||2.
</p>
<p>Consider two square-integrable functions f and g defined over the same domain
ï¿½; their scalar product is defined as
</p>
<p>ãg|f ã =
&int;
</p>
<p>ï¿½
</p>
<p>g&lowast; f dï¿½. (8.13)
</p>
<p>From (8.13) it follows
</p>
<p>ãf |gã =
&int;
</p>
<p>ï¿½
</p>
<p>f &lowast; g dï¿½ =
(&int;
</p>
<p>ï¿½
</p>
<p>f g&lowast; dï¿½
</p>
<p>)&lowast;
= ãg|f ã&lowast;. (8.14)
</p>
<p>It is implied that f , g are regular enough to make the integral in (8.13) to exist; in
fact, this is proved by observing that for square-integrable functions the Schwarz
inequality holds, analogous to that found in the case of vectors (Sect. A.2): if f and
g are square integrable, then
</p>
<p>|ãg|f ã| &le; ||f || &times; ||g||, (8.15)
</p>
<p>where the equality holds if and only if f is proportional to g (compare with (A.5)).
In turn, to prove (8.15) one observes that Ï = f + Î¼g, where Î¼ is an arbitrary
constant, is also square integrable. Then [47],
</p>
<p>||Ï ||2 = ||f ||2 + |Î¼|2 ||g||2 + Î¼ ãf |gã + Î¼&lowast; ãg|f ã &ge; 0. (8.16)
</p>
<p>The relation (8.15) is obvious if f = 0 or g = 0. Let g ï¿½= 0 and choose Î¼ =
&minus;ãg|f ã/||g||2. Replacing in (8.16) yields (8.15). For the equality to hold it must be
Ï = 0, which implies that f and g are proportional to each other; conversely, from
f = c g the equality follows.
</p>
<p>The symbol ãg|f ã for the scalar product is called Dirac&rsquo;s notation.4 If ãg|f ã = 0,
the functions f , g are called orthogonal. For any complex constants b, b1, b2 the
following hold:
</p>
<p>ãg|b f ã = b ãg|f ã, ãg|b1 f1 + b2 f2ã = b1 ãg|f1ã + b2 ãg|f2ã, (8.17)
</p>
<p>ãb g|f ã = b&lowast; ãg|f ã, ãb1 g1 + b2 g2|f ã = b&lowast;1 ãg1|f ã + b&lowast;2 ãg2|f ã, (8.18)
</p>
<p>namely, the scalar product is distributive and bilinear. The properties defined here
are the counterpart of those defined in Sect. A.1 for vectors.
</p>
<p>4 The two terms ãg| and |f ã of the scalar product ãg|f ã are called bra vector and ket vector,
respectively.</p>
<p/>
</div>
<div class="page"><p/>
<p>162 8 Time-Independent Schr&ouml;dinger Equation
</p>
<p>8.3.1 Adjoint Operators and Hermitean Operators
</p>
<p>A function appearing within a scalar product may result from the application of a
linear operator, say, A, onto another function.5 For instance, if s = Af , then from
(8.13, 8.14) it follows
</p>
<p>ãg|sã =
&int;
</p>
<p>ï¿½
</p>
<p>g&lowast; Af dï¿½, ãs|gã =
&int;
</p>
<p>ï¿½
</p>
<p>(Af )&lowast; g dï¿½ = ãg|sã&lowast;. (8.19)
</p>
<p>Given an operator A it is possible to find another operator, typically indicated with
A&dagger;, having the property that, for any pair f , g of square-integrable functions,
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>(
</p>
<p>A&dagger;g
)&lowast;
</p>
<p>f dï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>g&lowast; Af dï¿½ (8.20)
</p>
<p>or, in Dirac&rsquo;s notation, ãA&dagger;g|f ã = ãg|Af ã. Operator A&dagger; is called the adjoint6 of A.
In general it is A&dagger; ï¿½= A; however, for some operators it happens that A&dagger; = A. In
this case, A is called Hermitean. Thus, for Hermitean operators the following holds:
</p>
<p>ãg|Af ã = ãAg|f ã = ãg|A|f ã. (8.21)
</p>
<p>The notation on the right of (8.21) indicates that one can consider the operator as
applied onto f or g. Examples of Hermitean operators are given in Sect. 8.6.1. It
is found by inspection that, for any operator C, the operators S = C + C&dagger; and
D = &minus;i (C &minus; C&dagger;) are Hermitean.
</p>
<p>The following property is of use: a linear combination of Hermitean operator with
real coefficients is Hermitean; considering, e.g., two Hermitean operators A, B and
two real numbers Î», Î¼, one finds
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>g&lowast; (Î»A + Î¼B) f dï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>[(Î»A + Î¼B) g]&lowast; f dï¿½. (8.22)
</p>
<p>8.4 Eigenvalues and Eigenfunctions of an Operator
</p>
<p>A linear operator A may be used to generate a homogeneous equation (eigenvalue
equation) in the unknown v, having the form
</p>
<p>Av = A v, (8.23)
</p>
<p>5 In this context the term operator has the following meaning: if an operation brings each function
f of a given function space into correspondence with one and only one function s of the same space,
one says that this is obtained through the action of a given operator A onto f and writes s = Af .
A linear operator is such that A (c1 f1 + c2 f2) = c1 Af1 + c2 Af2 for any pair of functions f1, f2
and of complex constants c1, c2 ([78], Chap. II.11).
6 The adjoint operator is the counterpart of the conjugate-transpose matrix in vector algebra.</p>
<p/>
</div>
<div class="page"><p/>
<p>8.4 Eigenvalues and Eigenfunctions of an Operator 163
</p>
<p>withA a parameter. Clearly (8.23) admits the solution v = 0 which, however, is of no
interest; it is more important to find whether specific values of A exist (eigenvalues),
such that (8.23) admits non-vanishing solutions (eigenfunctions). In general (8.23)
must be supplemented with suitable boundary or regularity conditions on v.
</p>
<p>The set of the eigenvalues of an operator found from (8.23) is the operator&rsquo;s
spectrum. It may happen that the eigenvalues are distinguished by an index, or a set
of indices, that take only discrete values; in this case the spectrum is called discrete.
If, instead, the eigenvalues are distinguished by an index, or a set of indices, that
vary continuously, the spectrum is continuous. Finally, it is mixed if a combination
of discrete and continuous indices occurs.
</p>
<p>An eigenvalue is simple if there is one and only one eigenfuction corresponding to
it, while it is degenerate of order s if there are s linearly independent eigenfuctions
corresponding to it. The order of degeneracy may also be infinite. By way of example,
the Schr&ouml;dinger equation for a free particle in one dimension discussed in Sect. 8.2.1
has a continuous spectrum of eigenvalues E = hÌ2 k2/(2m) of index k, namely, E =
Ek . Each eigenvalue is degenerate of order 2 because to each E there correspond two
linearly-independent eigenfunctions exp (i k x), exp ( &minus; i k x), with k =
</p>
<p>&radic;
2mE/hÌ.
</p>
<p>Instead, the Schr&ouml;dinger equation for a particle in a box discussed in Sect. 8.2.2
has a discrete spectrum of eigenvalues En given by the first relation in (8.6). Each
eigenvalue is simple as already indicated in Sect. 8.2.2.
</p>
<p>Let v(1), . . . , v(s) be the linearly-independent eigenfunctions belonging to an eigen-
value A degenerate of order s; then a linear combination of such eigenfunctions is
also an eigenfunction belonging to A. In fact, letting Î±1, . . . ,Î±s be the coefficients
of the linear combination, from Av(k) = A v(k) it follows
</p>
<p>A
</p>
<p>s
&sum;
</p>
<p>k=1
Î±k v
</p>
<p>(k) =
s
</p>
<p>&sum;
</p>
<p>k=1
Î±kAv
</p>
<p>(k) =
s
</p>
<p>&sum;
</p>
<p>k=1
Î±k A v
</p>
<p>(k) = A
s
</p>
<p>&sum;
</p>
<p>k=1
Î±k v
</p>
<p>(k). (8.24)
</p>
<p>8.4.1 Eigenvalues of Hermitean Operators
</p>
<p>A fundamental property of the Hermitean operators is that their eigenvalues are real.
Consider, first, the case where the eigenfunctions are square integrable, so that ãv|vã
is different from zero and finite. To proceed one considers the discrete spectrum,
where the eigenvalues are An. Here n indicates a single index or also a set of indices.
If the eigenvalue is simple, let vn be the eigenfunction belonging to An; if it is
degenerate, the same symbol vn is used here to indicate any eigenfunction belonging
to An. Then, two operations are performed: in the first one, the eigenvalue equation
Avn = An vn is scalarly multiplied by vn on the left, while in the second one the
conjugate equation (Avn)&lowast; = A&lowast;n v&lowast;n is scalarly multiplied by vn on the right. The
operations yield, respectively,
</p>
<p>ãvn|Avnã = An ãvn|vnã, ãAvn|vnã = A&lowast;n ãvn|vnã. (8.25)
The left hand sides in (8.25) are equal to each other due to the hermiticity of A; as a
consequence, A&lowast;n = An, that is, An is real.</p>
<p/>
</div>
<div class="page"><p/>
<p>164 8 Time-Independent Schr&ouml;dinger Equation
</p>
<p>Another fundamental property of the Hermitean operators is that two eigenfunc-
tions belonging to different eigenvalues are orthogonal to each other. Still considering
the discrete spectrum, let Am, An be two different eigenvalues and let vm (vn) be an
eigenfunction belonging to Am (An). The two eigenvalues are real as demonstrated
earlier. Then, the eigenvalue equation Avn = An vn is scalarly multiplied by vm on
the left, while the conjugate equation for the other eigenvalue, (Avm)&lowast; = Am v&lowast;m, is
scalarly multiplied by vn on the right. The operations yield, respectively,
</p>
<p>ãvm|Avnã = An ãvm|vnã, ãAvm|vnã = Am ãvm|vnã. (8.26)
The left hand sides in (8.26) are equal to each other due to the hermiticity of A; as a
consequence, (Am &minus; An) ãvm|vnã = 0. But An ï¿½= Am, so it is ãvm|vnã = 0.
</p>
<p>8.4.2 Gram&ndash;Schmidt Orthogonalization
</p>
<p>When two eigenfunctions belonging to a degenerate eigenvalue are considered, the
reasoning that proves their orthogonality through (8.26) is not applicable because
An = Am. In fact, linearly-independent eigenfunctions of an operator A belong-
ing to the same eigenvalue are not mutually orthogonal in general. However, it is
possible to form mutually-orthogonal linear combinations of the eigenfunctions. As
shown by (8.24), such linear combinations are also eigenfunctions, so their norm is
different from zero. The procedure (Gram&ndash;Schmidt orthogonalization) is described
here with reference to the case of the nth eigenfunction of a discrete spectrum, with a
degeneracy of order s. Let the non-orthogonal eigenfunctions be v(1)n , . . . , v
</p>
<p>(s)
n , and let
</p>
<p>u(1)n , . . . , u
(s)
n be the linear combinations to be found. Then one prescribes u
</p>
<p>(1)
n = v(1)n ,
</p>
<p>u(2)n = v(2)n + a21 u(1)n where a21 is such that ãu(1)n |u(2)n ã = 0; thus
</p>
<p>ãu(1)n |v(2)n ã + a21 ãu(1)n |u(1)n ã = 0, a21 = &minus;
ãu(1)n |v(2)n ã
ãu(1)n |u(1)n ã
</p>
<p>. (8.27)
</p>
<p>The next function is found be letting u(3)n = v(3)n +a31 u(1)n +a32 u(2)n , with ãu(1)n |u(3)n ã =
0, ãu(2)n |u(3)n ã = 0, whence
</p>
<p>ãu(1)n |v(3)n ã + a31 ãu(1)n |u(1)n ã = 0, a31 = &minus;
ãu(1)n |v(3)n ã
ãu(1)n |u(1)n ã
</p>
<p>, (8.28)
</p>
<p>ãu(2)n |v(3)n ã + a32 ãu(2)n |u(2)n ã = 0, a32 = &minus;
ãu(2)n |v(3)n ã
ãu(2)n |u(2)n ã
</p>
<p>. (8.29)
</p>
<p>Similarly, the kth linear combination is built up recursively from the combinations
of indices 1, . . . , k &minus; 1:
</p>
<p>u(k)n = v(k)n +
k&minus;1
&sum;
</p>
<p>i=1
aki u
</p>
<p>(i)
n , aki = &minus;
</p>
<p>ãu(i)n |v(k)n ã
ãu(i)n |u(i)n ã
</p>
<p>. (8.30)
</p>
<p>The denominators in (8.30) are different from zero because they are the squared
norms of the previously-defined combinations.</p>
<p/>
</div>
<div class="page"><p/>
<p>8.4 Eigenvalues and Eigenfunctions of an Operator 165
</p>
<p>8.4.3 Completeness
</p>
<p>As discussed in Sect. 8.2.1, the eigenfunctions of the Schr&ouml;dinger equation for a
free particle, for a given k =
</p>
<p>&radic;
2mE/hÌ and apart from a multiplicative constant,
</p>
<p>are w+k = exp (i k x) and w&minus;k = exp ( &minus; i k x). They may be written equivalently
as w(x, k) = exp (i k x), with k = &plusmn;
</p>
<p>&radic;
2mE/hÌ. Taking the multiplicative constant
</p>
<p>equal to 1/
&radic;
</p>
<p>2Ï , and considering a function f that fulfills the condition (C.19) for
the Fourier representation, one applies (C.16) and (C.17) to find
</p>
<p>f (x) =
&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>exp (i k x)&radic;
2Ï
</p>
<p>c(k) dk, c(k) =
&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>exp ( &minus; i k x)&radic;
2Ï
</p>
<p>f (x) dx. (8.31)
</p>
<p>Using the definition (8.13) of scalar product one recasts (8.31) as
</p>
<p>f (x) =
&int; +&infin;
</p>
<p>&minus;&infin;
c(k) w(x, k) dk, c(k) = ãw|f ã. (8.32)
</p>
<p>In general the shorter notation wk(x), ck is used instead of w(x, k), c(k). A set of
functions like wk(x) that allows for the representation of f given by the first relation
in (8.32) is said to be complete. Each member of the set is identified by the value of
the continuous parameter k ranging from &minus;&infin; to +&infin;. To each k it corresponds a
coefficient of the expansion, whose value is given by the second relation in (8.32).
</p>
<p>Expressions (8.31) and (8.32) hold true because they provide the Fourier transform
or antitransform of a function that fulfills (C.19). On the other hand, wk(x) is also
the set of eigenfunctions of the free particle. In conclusion, the eigenfunctions of the
Schr&ouml;dinger equation for a free particle form a complete set.
</p>
<p>The same conclusion is readily found for the eigenfunctions of the Schr&ouml;dinger
equation for a particle in a box. To show this, one considers a function f (x) defined
in an interval [ &minus; Î±/2,+Î±/2] and fulfilling
</p>
<p>&int; +Î±/2
&minus;Î±/2 |f (x)| dx &lt; &infin;. In this case the
</p>
<p>expansion into a Fourier series holds:
</p>
<p>f (x) = 1
2
a0 +
</p>
<p>&infin;
&sum;
</p>
<p>n=1
[an cos (2Ï n x/Î±) + bn sin (2Ï n x/Î±)] , (8.33)
</p>
<p>with a0/2 = fÌ = (1/Î±)
&int; +Î±/2
&minus;Î±/2 f (x) dx the average of f over the interval, and
</p>
<p>{
an
</p>
<p>bn
</p>
<p>}
</p>
<p>= 2
Î±
</p>
<p>&int; +Î±/2
</p>
<p>&minus;Î±/2
</p>
<p>{cos
</p>
<p>sin
</p>
<p>}
(
</p>
<p>2Ï n x
</p>
<p>Î±
</p>
<p>)
</p>
<p>f (x) dx, n = 1, 2, . . . (8.34)
</p>
<p>Equality (8.33) indicates convergence in the mean, namely, using g = f &minus; fÌ for the
sake of simplicity, (8.33) is equivalent to
</p>
<p>lim
N&rarr;&infin;
</p>
<p>&int; +Î±/2
</p>
<p>&minus;Î±/2
</p>
<p>{
</p>
<p>g &minus;
N
&sum;
</p>
<p>n=1
[an cos (2Ï n x/Î±) + bn sin (2Ï n x/Î±)]
</p>
<p>}2
</p>
<p>dx = 0.
</p>
<p>(8.35)</p>
<p/>
</div>
<div class="page"><p/>
<p>166 8 Time-Independent Schr&ouml;dinger Equation
</p>
<p>Defining the auxiliary functions
</p>
<p>Ïn =
&radic;
</p>
<p>2/Î± cos (2Ï n x/Î±), Ïn =
&radic;
</p>
<p>2/Î± sin (2Ï n x/Î±), (8.36)
</p>
<p>a more compact notation is obtained, namely, f = fÌ + &sum;&infin;n=1 (ãÏn|f ãÏn + ãÏn|
f ã Ïn) or, observing that ãÏn|constã = ãÏn|constã = 0,
</p>
<p>g =
&infin;
&sum;
</p>
<p>n=1
(ãÏn|gãÏn + ãÏn|gã Ïn) . (8.37)
</p>
<p>The norm of the auxiliary functions (8.36) is unity, ãÏn|Ïnã = ãÏn|Ïnã = 1 for n =
1, 2, . . . , and all auxiliary functions are mutually orthogonal: ãÏm|Ïnã = ãÏm|Ïnã = 0
for n,m = 0, 1, 2, . . . , m ï¿½= n, and ãÏm|Ïnã = 0 for n,m = 0, 1, 2, . . . A set
whose functions have a norm equal to unity and are mutually orthogonal is called
orthonormal. Next, (8.37) shows that the set Ïn, Ïn, n = 0, 1, 2, . . . is complete in
[ &minus; Î±/2,+Î±/2] with respect to any g for which the expansion is allowed. Letting
c2n&minus;1 = ãÏn|gã, c2n = ãÏn|gã, w2n&minus;1 = Ïn, w2n = Ïn, (8.37) takes the even more
compact form
</p>
<p>g =
&infin;
&sum;
</p>
<p>m=1
cm wm, cm = ãwm|gã. (8.38)
</p>
<p>From the properties of the Fourier series it follows that the set of the Ïn functions
alone is complete with respect to any function that is odd in [ &minus; Î±/2,+Î±/2], hence
it is complete with respect to any function over the half interval [0,+Î±/2]. On the
other hand, letting a = Î±/2 and comparing with (8.8) shows that Ïn (apart from
the normalization coefficient) is the eigenfunction of the Schr&ouml;dinger equation for a
particle in a box. In conclusion, the set of eigenfunctions of this equation is complete
within [0, a].
</p>
<p>One notes the striking resemblance of the first relation in (8.38) with the vector-
algebra expression of a vector in terms of its components cm. The similarity is
completed by the second relation in (8.38), that provides each component as the
projection of g over wm. The latter plays the same role as the unit vector in algebra,
the difference being that the unit vectors here are functions and that their number is
infinite. A further generalization of the same concept is given by (8.32), where the
summation index k is continuous.
</p>
<p>Expansions like (8.32) or (8.38) hold because wk(x) and wm(x) are complete sets,
whose completeness is demonstrated in the theory of Fourier&rsquo;s integral or series;
such a theory is readily extended to the three-dimensional case, showing that also
the three-dimensional counterparts of wk(x) or wm(x) form complete sets (in this case
the indices k or m are actually groups of indices, see, e.g., (9.5)). One may wonder
whether other complete sets of functions exist, different from those considered in
this section; the answer is positive: in fact, completeness is possessed by many</p>
<p/>
</div>
<div class="page"><p/>
<p>8.4 Eigenvalues and Eigenfunctions of an Operator 167
</p>
<p>other sets of functions,7 and those of interest in Quantum Mechanics are made of the
eigenfunctions of equations like (8.23). A number of examples will be discussed later.
</p>
<p>8.4.4 Parseval Theorem
</p>
<p>Consider the expansion of a complex function f with respect to a complete and
orthonormal set of functions wn,
</p>
<p>f =
&sum;
</p>
<p>n
</p>
<p>cn wn, cn = ãwn|f ã, ãwn|wmã = Î´nm, (8.39)
</p>
<p>where the last relation on the right expresses the set&rsquo;s orthonormality. As before, m
indicates a single index or a group of indices. The squared norm of f reads
</p>
<p>||f ||2 =
&int;
</p>
<p>ï¿½
</p>
<p>|f |2 dï¿½ =
&lang;
</p>
<p>&sum;
</p>
<p>n
</p>
<p>cn wn|
&sum;
</p>
<p>m
</p>
<p>cm wm
</p>
<p>&rang;
</p>
<p>. (8.40)
</p>
<p>Applying (8.17, 8.18) yields
</p>
<p>||f ||2 =
&sum;
</p>
<p>n
</p>
<p>c&lowast;n
&sum;
</p>
<p>m
</p>
<p>cmãwn|wmã =
&sum;
</p>
<p>n
</p>
<p>c&lowast;n
&sum;
</p>
<p>m
</p>
<p>cm Î´nm =
&sum;
</p>
<p>n
</p>
<p>|cn|2, (8.41)
</p>
<p>namely, the norm of the function equals the norm of the vector whose components
are the expansion&rsquo;s coefficients (Parseval theorem). The result applies irrespective
of the set that has been chosen for expanding f . The procedure leading to (8.41)
must be repeated for the continuous spectrum, where the expansion reads
</p>
<p>f =
&int;
</p>
<p>Î±
</p>
<p>cÎ± wÎ± dÎ±, cÎ± = ãwÎ±|f ã. (8.42)
</p>
<p>Here a difficulty seems to arise, related to expressing the counterpart of the third
relation in (8.39). Considering for the sake of simplicity the case where a single
index is present, the scalar product ãwÎ±|wÎ²ã must differ from zero only for Î² = Î±,
while it must vanish for Î² ï¿½= Î± no matter how small the difference Î± &minus; Î² is. In
other terms, for a given value of Î± such a scalar product vanishes for any Î² apart
from a null set. At the same time, it must provide a finite value when used as a
factor within an integral. An example taken from the case of a free particle shows
that the requirements listed above are mutually compatible. In fact, remembering the
analysis of Sect. 8.4.3, the scalar product corresponding to the indices Î± and Î² reads
</p>
<p>ãwÎ±|wÎ²ã =
1
</p>
<p>2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
exp [i (Î² &minus; Î±) x] dx = Î´(Î± &minus; Î²), (8.43)
</p>
<p>7 The completeness of a set of eigenfunctions must be proven on a case-by-case basis.</p>
<p/>
</div>
<div class="page"><p/>
<p>168 8 Time-Independent Schr&ouml;dinger Equation
</p>
<p>where the last equality is taken from (C.43). As mentioned in Sect. C.4, such an
equality can be used only within an integral. In conclusion,8
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>|f |2 dï¿½ = ãf |f ã =
&int; +&infin;
</p>
<p>&minus;&infin;
c&lowast;Î± dÎ±
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
cÎ² Î´(Î± &minus; Î²) dÎ² =
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
|cÎ±|2 dÎ±.
</p>
<p>(8.44)
</p>
<p>One notes that (8.44) generalizes a theorem of Fourier&rsquo;s analysis that states that the
norm of a function equals that of its transform.
</p>
<p>8.5 Hamiltonian Operator and Momentum Operator
</p>
<p>As mentioned in Sect. 7.5, the form (7.45) of the time-independent Schr&ouml;dinger
equation holds only when the force is conservative. It is readily recast in the more
compact form (8.23) by defining the Hamiltonian operator
</p>
<p>H = &minus; hÌ
2
</p>
<p>2m
&nabla;2 + V , (8.45)
</p>
<p>that is, a linear, real operator that gives (7.45) the form
</p>
<p>Hw = E w. (8.46)
</p>
<p>The term used to denote H stems from the formal similarity of (8.46) with the classical
expression H (p, q) = E of a particle&rsquo;s total energy in a conservative field, where
H = T + V is the Hamiltonian function (Sect. 1.5). By this similarity, the classical
kinetic energy T = p2/(2m) corresponds to the kinetic operator T = &minus;hÌ2/(2m)&nabla;2;
such a correspondence reads
</p>
<p>T = 1
2m
</p>
<p>(
</p>
<p>p21 + p22 + p23
)
</p>
<p>&lArr;&rArr; T = &minus; hÌ
2
</p>
<p>2m
</p>
<p>(
&part;2
</p>
<p>&part;x21
+ &part;
</p>
<p>2
</p>
<p>&part;x22
+ &part;
</p>
<p>2
</p>
<p>&part;x23
</p>
<p>)
</p>
<p>. (8.47)
</p>
<p>The units of T are those of an energy, hence hÌ2 &nabla;2 has the units of a momentum
squared. One notes that to transform T into T one must replace each component of
momentum by a first-order operator as follows:
</p>
<p>pi &lArr; pÌi = &minus;i hÌ
&part;
</p>
<p>&part;xi
, (8.48)
</p>
<p>where pÌi is called momentum operator. The correspondence (8.47) would still hold
if the minus sign in (8.48) were omitted. However, the minus sign is essential for
</p>
<p>8 The relation (8.44) is given here with reference to the specific example of the free particle&rsquo;s
eigenfunctions. For other cases of continuous spectrum the relation ãwÎ± |wÎ²ã = Î´(Î± &minus; Î²) is proven
on a case-by-case basis.</p>
<p/>
</div>
<div class="page"><p/>
<p>8.6 Complements 169
</p>
<p>a correct description of the particle&rsquo;s motion.9 From the results of Sect. 8.6.1 one
finds that the momentum operator and its three-dimensional form pÌ = &minus;i hÌ grad are
Hermitean for square-integrable functions. Their units are those of a momentum.
The Hamiltonian operator (8.45) is a real-coefficient, linear combination of &nabla;2 and
V ; combining (8.22) with the findings of Sect. 8.6 shows that (8.45) is Hermitean
for square-integrable functions.
</p>
<p>The one-dimensional form of the momentum operator yields the eigenvalue
equation
</p>
<p>&minus;i hÌ dv
dx
</p>
<p>= pÌ v, (8.49)
</p>
<p>where pÌ has the units of a momentum. The solution of (8.49) is v = const &times;
exp (i pÌ/hÌ), where pÌ must be real to prevent the solution from diverging. Letting
const = 1/
</p>
<p>&radic;
2Ï , k = pÌ/hÌ yields v = vk(x) = exp (i k x)/
</p>
<p>&radic;
2Ï , showing that
</p>
<p>the eigenfunctions of the momentum operator form a complete set (compare with
(8.31)) and are mutually orthogonal (compare with (8.43)). As |vk(x)|2 = 1/(2Ï ),
the eigenfunctions are not square integrable; the spectrum is continuous because the
eigenvalue hÌ k can be any real number.
</p>
<p>8.6 Complements
</p>
<p>8.6.1 Examples of Hermitean Operators
</p>
<p>A real function V , depending on the spatial coordinates over the domain ï¿½, and
possibly on other variables Î±,Î², . . . , may be thought of as a purely multiplicative
operator. Such an operator is Hermitean; in fact,
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>g&lowast; V f dï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>V g&lowast; f dï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>(Vg)&lowast; f dï¿½. (8.50)
</p>
<p>In contrast, an imaginary function W = iV , with V real, is not Hermitean because
</p>
<p>ãg|W f ã = &minus;ãW g|f ã. (8.51)
</p>
<p>Any operator that fulfills a relation similar to (8.51) is called anti-Hermitean or
skew-Hermitean.
</p>
<p>As a second example consider a one-dimensional case defined over a domain ï¿½
belonging to the x axis. It is easily shown that the operator (i d/dx) is Hermitean: in
</p>
<p>9 Consider for instance the calculation of the expectation value of the momentum of a free particle
based on (10.18). If the minus sign were omitted in (8.48), the direction of momentum would be
opposite to that of the propagation of the wave front associated to it.</p>
<p/>
</div>
<div class="page"><p/>
<p>170 8 Time-Independent Schr&ouml;dinger Equation
</p>
<p>fact, integrating by parts and observing that the integrated part vanishes because f
and g are square integrable, yields
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>g&lowast; i
df
</p>
<p>dx
dï¿½ =
</p>
<p>[
</p>
<p>g&lowast; i f
]
</p>
<p>ï¿½
&minus;
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>i
dg&lowast;
</p>
<p>dx
f dï¿½ =
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>(
</p>
<p>i
dg
</p>
<p>dx
</p>
<p>)&lowast;
f dï¿½. (8.52)
</p>
<p>By the same token one shows that the operator d/dx is skew-Hermitean. The three-
dimensional generalization of (i d/dx) is (i grad). Applying the latter onto the product
g&lowast; f yields g&lowast; i gradf &minus; (i gradg)&lowast; f . Integrating over ï¿½ with ï¿½ the boundary of ï¿½
and n the unit vector normal to it, yields
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>g&lowast; i gradf dï¿½&minus;
&int;
</p>
<p>ï¿½
</p>
<p>(i gradg)&lowast; f dï¿½ = i
&int;
</p>
<p>ï¿½
</p>
<p>g&lowast; f n dï¿½. (8.53)
</p>
<p>The form of the right hand side of (8.53) is due to (A.25). As f , g vanish over the
boundary, it follows ãg|i gradf ã = ãi gradg|f ã, namely, (i grad) is Hermitean.
</p>
<p>Another important example, still in the one-dimensional case, is that of the op-
erator d2/dx2. Integrating by parts twice shows that the operator is Hermitean. Its
three-dimensional generalization in Cartesian coordinates is &nabla;2. Using the second
Green theorem (A.25) and remembering that f , g vanish over the boundary provides
ãg|&nabla;2f ã = ã&nabla;2g|f ã, that is, &nabla;2 is Hermitean.
</p>
<p>8.6.2 A Collection of Operators&rsquo; Definitions and Properties
</p>
<p>A number of definitions and properties of operator algebra are illustrated in this
section. The identity operator I is such that If = f for all f ; the null operator
O is such that Of = 0 for all f . The product of two operators, AB, is an operator
whose action on a function is defined as follows: s = ABf is equivalent to g = Bf ,
s = Ag; in other terms, the operators A and B act in a specific order. In general,
BA ï¿½= AB. The operators AA, AAA, . . . are indicated with A2, A3, . . .
</p>
<p>An operator A may or may not have an inverse, A&minus;1. If the inverse exists, it is
unique and has the property A&minus;1Af = f for all f . Left multiplying the above by
A and letting g = Af yields AA&minus;1g = g for all g. The two relations just found can
be recast as
</p>
<p>A&minus;1A = AA&minus;1 = I. (8.54)
</p>
<p>From (8.54) it follows (A&minus;1)&minus;1 = A. If A and B have an inverse, letting C =
B&minus;1A&minus;1 one finds, for all f and using the associative property, the two relations
BCf = BB&minus;1A&minus;1f = A&minus;1f and ABCf = AA&minus;1f = f , namely, ABC = I; in
conclusion,
</p>
<p>(AB)&minus;1 = B&minus;1A&minus;1. (8.55)</p>
<p/>
</div>
<div class="page"><p/>
<p>8.6 Complements 171
</p>
<p>From (8.55) one defines the inverse powers of A as
</p>
<p>A&minus;2 = (A2)&minus;1 = (AA)&minus;1 = A&minus;1A&minus;1, (8.56)
</p>
<p>and so on. Let Av = Î»v be the eigenvalue equation of A. Successive left
multiplications by A yield
</p>
<p>A2v = Î»2 v, A3v = Î»3 v, . . . (8.57)
</p>
<p>As a consequence, an operator of the polynomial form
</p>
<p>Pn(A) = c0 An + c1 An&minus;1 + c2 An&minus;2 + . . .+ cn (8.58)
</p>
<p>fulfills the eigenvalue equation
</p>
<p>Pn(A) v = Pn(Î») v, Pn(Î») = c0 Î»n + . . .+ cn. (8.59)
</p>
<p>By definition, an eigenfunction can not vanish identically. If A has an inverse, left-
multiplying the eigenvalue equation Av = Î»v by A&minus;1 yields v = Î»A&minus;1v ï¿½= 0,
whence Î» ï¿½= 0. Dividing the latter by Î» and iterating the procedure shows that
</p>
<p>A&minus;2v = Î»&minus;2v, A&minus;3v = Î»&minus;3v, . . . (8.60)
</p>
<p>An operator may be defined by a series expansion, if the latter converges:
</p>
<p>C = Ï (A) =
+&infin;
&sum;
</p>
<p>k=&minus;&infin;
ck A
</p>
<p>k. (8.61)
</p>
<p>By way of example,
</p>
<p>C = exp (A) = I + A + 1
2! A
</p>
<p>2 + 1
3! A
</p>
<p>3 + . . . (8.62)
</p>
<p>Given an operator A, its adjoint A&dagger; is defined as in Sect. 8.3.1. Letting C = A&dagger;,
applying the definition of adjoint operator to C, and taking the conjugate of both
sides shows that (A&dagger;)&dagger; = A. From the definition of adjoint operator it also follows
</p>
<p>(AB)&dagger; = B&dagger;A&dagger;. (8.63)
</p>
<p>An operator is unitary if its inverse is identical to its adjoint for all f :
</p>
<p>A&minus;1f = A&dagger;f. (8.64)
</p>
<p>Left multiplying (8.64) by A, and left multiplying the result by A&dagger;, yields for a
unitary operator
</p>
<p>AA&dagger; = A&dagger;A = I. (8.65)</p>
<p/>
</div>
<div class="page"><p/>
<p>172 8 Time-Independent Schr&ouml;dinger Equation
</p>
<p>The application of a unitary operator to a function f leaves the norm of the latter
unchanged. In fact, using definition (8.12), namely, ||f ||2 = ãf | f ã, and letting
g = Af with A unitary, yields
</p>
<p>||g||2 =
&int;
</p>
<p>ï¿½
</p>
<p>(Af )&lowast; Af dï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>(A&dagger;Af )&lowast; f dï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>f &lowast; f dï¿½ = ||f ||2, (8.66)
</p>
<p>where the second equality holds due to the definition of adjoint operator, and the
third one holds because A is unitary. The inverse also holds true: if the application
of A leaves the function&rsquo;s norm unchanged, that is, if ||Af || = ||f || for all f , then
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>(A&dagger;Af &minus; f )&lowast; f dï¿½ = 0. (8.67)
</p>
<p>As a consequence, the quantity in parenthesis must vanish, whence the operator is
unitary. The product of two unitary operators is unitary:
</p>
<p>(AB)&minus;1 = B&minus;1A&minus;1 = B&dagger;A&dagger; = (AB)&dagger;, (8.68)
</p>
<p>where the second equality holds because A and B are unitary. The eigenvalues of
a unitary operator have the form exp (i Î½), with Î½ a real number. Let an eigenvalue
equation be Av = Î»v, with A unitary. The following hold,
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>|Av|2 dï¿½ = |Î»|2
&int;
</p>
<p>ï¿½
</p>
<p>|v|2 dï¿½,
&int;
</p>
<p>ï¿½
</p>
<p>|Av|2 dï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>|v|2 dï¿½, (8.69)
</p>
<p>the first one because of the eigenvalue equation, the second one because A is unitary.
As an eigenfunction can not vanish identically, it follows |Î»|2 = 1 whence Î» =
exp (i Î½). It is also seen by inspection that, if the eigenvalues of an operator have the
form exp (i Î½), with Î½ a real number, then the operator is unitary.
</p>
<p>It has been anticipated above that in general it is BA ï¿½= AB. Two operators A, B
are said to commute if
</p>
<p>BAf = ABf (8.70)
</p>
<p>for all f . The commutator of A, B is the operator C such that
</p>
<p>i Cf = (AB &minus; BA) f (8.71)
</p>
<p>for all f . The definition (8.71) is such that, if both A and B are Hermitean, then C is
Hermitean as well. The commutator of two commuting operators is the null operator.
A very important example of non-commuting operators is the pair q, &minus;i d/dq, where
q is any dynamical variable. One finds
</p>
<p>i Cf = &minus;i q df
dq
</p>
<p>+ i d(q f )
dq
</p>
<p>= i f , (8.72)
</p>
<p>namely, the commutator is in this case the identity operator I.</p>
<p/>
</div>
<div class="page"><p/>
<p>8.6 Complements 173
</p>
<p>8.6.3 Examples of Commuting Operators
</p>
<p>Operators that contain only spatial coordinates commute; similarly, operators that
contain only momentum operators commute. The operators A, B, C defined in (10.4)
commute because they act on different coordinates; note that the definition of A is
such that it may contain both x and pÌx = &minus;i hÌ &part;/&part;x, and so on.
</p>
<p>As an example of operators containing only momentum operators one may con-
sider the Hamiltonian operator&minus;(hÌ2/2m)&nabla;2 of a free particle discussed in Sect. 8.2.1
and the momentum operator &minus;i hÌ&nabla; itself (Sect. 8.5). As for a free particle they
commute, a measurement of momentum is compatible in that case with a measure-
ment of energy (Sect. 8.6.4). Considering a one-dimensional problem, the energy
is E = p2/(2m), where the modulus of momentum is given by p = hÌ k; for a
free particle, both energy and momentum are conserved. The eigenfunctions are
const &times; exp ( &plusmn; ip x/hÌ) for both operators.
</p>
<p>Remembering (8.72) one concludes that two operators do not commute if one of
them contains one coordinate q, and the other one contains the operator &minus;i hÌ &part;/&part;q
associated to the momentum conjugate to q.
</p>
<p>8.6.4 Momentum and Energy of a Free Particle
</p>
<p>The eigenfunctions of the momentum operator are the same as those of the
Schr&ouml;dinger equation for a free particle. More specifically, given the sign of pÌ,
the solution of (8.49) concides with either one or the other of the two linearly-
independent solutions of (8.1). This outcome is coherent with the conclusions reached
in Sect. 8.2.1 about the free particle&rsquo;s motion. For a free particle whose momentum is
prescribed, the energy is purely kinetic and is prescribed as well, whence the solution
of (8.49) must be compatible with that of (8.1). However, prescribing the momentum,
both in modulus and direction, for a free particle, provides the additional information
that allows one to eliminate one of the two summands from the linear combination
(8.2) by setting either c1 or c2 to zero. For a given eigenvalue pÌ, (8.49) has only
one solution (apart from the multiplicative constant) because it is a first-order equa-
tion; in contrast, for a given eigenvalue E, the second-order equation (8.1) has two
independent solutions and its general solution is a linear combination of them.
</p>
<p>In a broader sense the momentum operator pÌx = &minus;i hÌ d/dx is Hermitean also for
functions of the form vk(x) = exp (i k x)/
</p>
<p>&radic;
2Ï , which are not square integrable. In
</p>
<p>fact, remembering (C.43) one finds
</p>
<p>ãvk&prime; |pÌxvkã = &minus;
i hÌ
</p>
<p>2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
exp ( &minus; i k&prime; x) d
</p>
<p>dx
exp (i k x) dx = hÌ k Î´(k&prime; &minus; k). (8.73)
</p>
<p>Similarly it is ãpÌxvk&prime; |vkã = hÌ k&prime; Î´(k&prime;&minus;k). As mentioned in Sect. C.4, the two equalities
just found can be used only within an integral over k or k&prime;. In that case, however,
they yield the same result hÌ k. By the same token one shows that
</p>
<p>ãvk&prime; |pÌ2xvkã = hÌ2 k2 Î´(k&prime; &minus; k), ãpÌ2xvk&prime; |vkã = hÌ2 (k&prime;)2 Î´(k&prime; &minus; k), (8.74)</p>
<p/>
</div>
<div class="page"><p/>
<p>174 8 Time-Independent Schr&ouml;dinger Equation
</p>
<p>hence the Laplacian operator is Hermitean in a broader sense for non-square-
integrable functions of the form vk(x) = exp (i k x)/
</p>
<p>&radic;
2Ï .
</p>
<p>Problems
</p>
<p>8.1 The one-dimensional, time-independent Schr&ouml;dinger equation is a homogeneous
equation of the form
</p>
<p>w&prime;&prime; + q w = 0, q = q(x), (8.75)
</p>
<p>where primes indicate derivatives. In turn, the most general, linear equation of the
second order with a non-vanishing coefficient of the highest derivative is
</p>
<p>f &prime;&prime; + a f &prime; + b f = c, a = a(x), b = b(x), c = c(x). (8.76)
</p>
<p>Assume that a is differentiable. Show that if the solution of (8.75) is known, then the
solution of (8.76) is obtained from the former by simple integrations.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 9
</p>
<p>Time-Dependent Schr&ouml;dinger Equation
</p>
<p>9.1 Introduction
</p>
<p>The time-dependent Schr&ouml;dinger equation is derived from the superposition prin-
ciple, in the conservative case first, then in the general case. The derivation of the
continuity equation follows, leading to the concept of wave packet and density of
probability flux. Then, the wave packet for a free particle is investigated in detail,
and the concept of group velocity is introduced. The first complement deals with an
application of the semiclassical approximation; through it one explains why an elec-
tron belonging to a stationary state emits no power, namely, why the radiative decay
predicted by the classical model does not occur. The polar form of the time-dependent
Schr&ouml;dinger equation is then shown, that brings about an interesting similarity with
the Hamilton&ndash;Jacobi equation of Classical Mechanics. The last complement deals
with the Hamiltonian operator of a particle subjected to an electromagnetic field, and
shows the effect of a gauge transformation on the wave function.
</p>
<p>9.2 Superposition Principle
</p>
<p>Following De Broglie&rsquo;s line of reasoning (Sect. 7.4.5) one associates the monochro-
matic wave function w(r) exp (&minus;iÏ t) to the motion of a particle with definite and
constant energy E = hÌ Ï. The analogy with the electromagnetic case then suggests
that a more general type of wave function&mdash;still related to the conservative case&mdash;can
be expressed as a superposition, that is, a linear combination with constant coeffi-
cients, of monochromatic wave functions. This possibility is one of the postulates
of De Broglie&rsquo;s theory, and is referred to as Superposition Principle. To vest it with
a mathematical form one must distinguish among the different types of spectrum;
for the discrete spectrum, indicating with cn the complex coefficients of the linear
combination, the general wave function reads
</p>
<p>Ï(r, t) =
&sum;
</p>
<p>n
</p>
<p>cn wn exp (&minus;iÏn t), (9.1)
</p>
<p>&copy; Springer Science+Business Media New York 2015 175
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_9</p>
<p/>
</div>
<div class="page"><p/>
<p>176 9 Time-Dependent Schr&ouml;dinger Equation
</p>
<p>withEn, wn the eigenvalues and eigenfunctions of the time-independent Schr&ouml;dinger
equation Hwn = En wn, and Ïn = En/hÌ. As usual, n stands for a single index or
a set of indices. The form of (9.1) is such that the spatial coordinates are separated
from the time coordinate; fixing the latter by letting, say, t = 0, and remembering
that the set of eigenfunctions wn is complete, yields
</p>
<p>Ït=0 = Ï(r, 0) =
&sum;
</p>
<p>n
</p>
<p>cn wn, cn = ãwn|Ït=0ã. (9.2)
</p>
<p>The above shows that the coefficients cn are uniquely determined by the initial con-
dition Ït=0. On the other hand, once the coefficients cn are known, the whole time
evolution of Ï is determined, because the angular frequencies appearing in the time-
dependent terms exp (&minus;iÏn t) are also known. In other terms, Ï is determined by
the initial condition and by the time-independent Hamiltonian operator whence En,
wn derive.
</p>
<p>An important aspect of (9.1) is that it allows one to construct a wave function of
a given form; for such a construction, in fact, it suffices to determine the coefficients
by means of the second relation in (9.2). In particular it is possible to obtain a wave
function that is square integrable at all times, even if the eigenfunctions wn are
not square integrable themselves. Thanks to this property the wave function (9.1) is
localized in space at each instant of time, hence it is suitable for describing the motion
of the particle associated to it. Due to the analogy with the electromagnetic case, were
the interference of monochromatic waves provides the localization of the field&rsquo;s
intensity, a wave function of the form (9.1) is called wave packet. Remembering that
the wave function provides the probability density |Ï |2 used to identify the position
of the particle, one can assume that the wave packet&rsquo;s normalization holds:
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>|Ï |2 d3r =
&sum;
</p>
<p>n
</p>
<p>|cn|2 = 1, (9.3)
</p>
<p>where the second equality derives from Parseval&rsquo;s theorem (8.41). From (9.3) it
follows that the coefficients are subjected to the constraint 0 &le; |cn|2 &le; 1.
</p>
<p>As all possible energies En appear in the expression (9.1) of Ï , the wave packet
does not describe a motion with a definite energy. Now, assume that an energy
measurement is carried out on the particle, and let t = tE be the instant at which the
measurement is completed. During the measurement the Hamiltonian operator of
(8.46) does not hold because the particle is interacting with the measuring apparatus,
hence the forces acting on it are different from those whence the potential energyV of
(8.45) derives. Instead, for t &gt; tE the original Schr&ouml;dinger equation (8.46) is restored,
so the expression of Ï is again given by a linear combination of monochromatic
waves; however, the coefficients of the combination are expected to be different
from those that existed prior to the measurement, due to the perturbation produced
by the latter. In particular, the form of Ï for t &gt; tE must be compatible with the fact
that the energy measurement has found a specific value of the energy; this is possible
only if the coefficients are set to zero, with the exception of the one corresponding
to the energy that is the outcome of the measurement. The latter must be one of the</p>
<p/>
</div>
<div class="page"><p/>
<p>9.2 Superposition Principle 177
</p>
<p>eigenvalues of (8.46) due to the compatibility requirement; if it is, say, Em, then the
form of the wave function for t &gt; tE is
</p>
<p>Ï(r, t) = wm exp [&minus;iEm (t &minus; tE)/hÌ], (9.4)
</p>
<p>where the only non-vanishing coefficient, cm, has provisionally been set to unity.
The reasoning leading to (9.4) can be interpreted as follows: the interaction with
</p>
<p>the measuring apparatus filters out from (9.1) the term corresponding to Em; as a
consequence, the coefficients cn whose values were previously set by the original Ï
are modified by the measurement and become cn = Î´nm. If the filtered eigenfunction
wm is square integrable, then (9.3) holds, whence
</p>
<p>&sum;
</p>
<p>n |cn|2 = |cm|2 = 1, cm =
exp (iÎ¦). As the constant phase Î¦ does not carry any information, it can be set
to zero to yield cm = 1. If wm is not square integrable, the arbitrariness of the
multiplicative constant still allows one to set cm = 1.
</p>
<p>As the energy measurement forces the particle to belong to a definite energy
state (in the example above, Em), for t &gt; tE the particle&rsquo;s wave function keeps the
monochromatic form (9.4). If, at a later time, a second energy measurement is carried
out, the only possible outcome isEm; as a consequence, after the second measurement
is completed, the form of the wave function is still (9.4), whence |cm|2 = 1. One notes
that the condition |cm|2 = 1 is associated with the certainty that the outcome of the
energy measurement is Em whereas, when the general superposition (9.1) holds, the
coefficients fulfill the relations
</p>
<p>&sum;
</p>
<p>n |cn|2 = 1, 0 &le; |cn|2 &le; 1, and the measurement&rsquo;s
outcome may be any of the eigenvalues. It is then sensible to interpret |cn|2 as the
probability that a measurement of energy finds the result En. This interpretation, that
has been worked out here with reference to energy, is extended to the other dynamical
variables (Sect. 10.2).
</p>
<p>When the spectrum is continuous the description of the wave packet is
</p>
<p>Ï(r, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
ck wk exp (&minus;iÏk t) d3k, (9.5)
</p>
<p>with Ek, wk the eigenvalues and eigenfunctions of Hwk = Ek wk, and Ïk = Ek/hÌ.
Such symbols stand for Ek = E(k), wk = w(r, k), and so on, with k a three-
dimensional vector whose components are continuous. The relations corresponding
to (9.2, 9.3) are
</p>
<p>Ït=0 = Ï(r, 0) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
ck wk d
</p>
<p>3k, ck = ãwk|Ït=0ã, (9.6)
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>|Ï |2 d3r =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
|ck|2 d3k = 1. (9.7)
</p>
<p>The expression ofÏt=0 in (9.6) lends itself to providing an example of a wave function
that is square integrable, while the eigenfunctions that build up the superposition
are not. Consider, in fact, the relation (C.82) and let ck = Ï exp ( &minus; Ï 2 k2/2),</p>
<p/>
</div>
<div class="page"><p/>
<p>178 9 Time-Dependent Schr&ouml;dinger Equation
</p>
<p>wk = exp (i k x)/
&radic;
</p>
<p>2Ï in it, with Ï a length; in this way (C.82) becomes the one-
dimensional case of (9.6) and yieldsÏt=0 = exp [&minus;x2/(2 Ï 2)], showing that a square-
integrable function like the Gaussian one can be expressed as a combination of the
non-square-integrable spatial parts of the plane waves.
</p>
<p>The extraction of the probabilities in the continuous-spectrum case accounts for
the fact theE(k) varies continuously with k. To this purpose one takes the elementary
volume d3k centered on some k and considers the product |ck|2 d3k. Such a product
is given the meaning of infinitesimal probability that the outcome of an energy mea-
surement belongs to the range of E(k) values whose domain is d3k (more comments
are made in Sect. 9.7.1).
</p>
<p>9.3 Time-Dependent Schr&ouml;dinger Equation
</p>
<p>The Superposition Principle illustrated in Sect. 9.2 prescribes the form of the
wave packet in the conservative case. Considering for simplicity a discrete set of
eigenfunctions, the time derivative of Ï reads
</p>
<p>&part;Ï
</p>
<p>&part;t
=
</p>
<p>&sum;
</p>
<p>n
</p>
<p>cn wn
En
</p>
<p>i hÌ
exp (&minus;iEn t/hÌ). (9.8)
</p>
<p>Using the time-independent Schr&ouml;dinger equation Hwn = Enwn transforms the
above into
</p>
<p>i hÌ
&part;Ï
</p>
<p>&part;t
=
</p>
<p>&sum;
</p>
<p>n
</p>
<p>cn Hwn exp (&minus;iEn t/hÌ), i hÌ
&part;Ï
</p>
<p>&part;t
= HÏ. (9.9)
</p>
<p>The second relation in (9.9) is a linear, homogeneous partial-differential equation,
of the second order with respect to the spatial coordinates and of the first order with
respect to time, whose solution is the wave function Ï . It is called time-dependent
Schr&ouml;dinger equation; as its coefficients are complex, so isÏ . To solve the equation it
is necessary to prescribe the initial conditionÏ(r, t = 0) and the boundary conditions.
For the latter the same discussion as in Sect. 8.2 applies, because the spatial behavior
of Ï is prescribed by the Hamiltonian operator.
</p>
<p>The reasoning leading to the second relation in (9.9) is based on the Superposition
Principle, namely, once the form of Ï is given, the equation fulfilled by Ï is readily
extracted. Such a reasoning is not applicable in the non-conservative cases, because
the time-independent equation Hwn = Enwn does not hold then, so the eigenvalues
and eigenfunctions upon which the superposition is based are not available. How-
ever, another line of reasoning shows that the time-dependent Schr&ouml;dinger equation
holds also for the non-conservative situations [69]. Although in such cases the wave
function Ï is not expressible as a superposition of monochromatic waves, it can still
be expanded using an orthonormal set. If the set is discrete, vn = vn(r), the expansion
reads
</p>
<p>Ï(r, t) =
&sum;
</p>
<p>n
</p>
<p>bn vn(r), bn(t) = ãvn|Ïã, (9.10)</p>
<p/>
</div>
<div class="page"><p/>
<p>9.4 Continuity Equation and Norm Conservation 179
</p>
<p>whereas for a continuous set vk = v(r, k) one finds
</p>
<p>Ï(r, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
bk vk d
</p>
<p>3k, bk(t) = ãvk|Ïã. (9.11)
</p>
<p>9.4 Continuity Equation and Norm Conservation
</p>
<p>Remembering that the square modulus of the wave function provides the localization
of the particle, it is of interest to investigate the time evolution of |Ï |2, starting from
the time derivative of Ï given by the time-dependent Schr&ouml;dinger equation (9.9).
Here it is assumed that the wave function is normalized to unity and that the Hamil-
tonian operator is real, H&lowast; = H = &minus;hÌ2/(2m)&nabla;2 + V ; a case where the operator is
complex is examined in Sect. 9.5. Taking the time derivative of |Ï |2 yields
</p>
<p>&part;|Ï |2
&part;t
</p>
<p>= Ï&lowast; &part;Ï
&part;t
</p>
<p>+ Ï &part;Ï
&lowast;
</p>
<p>&part;t
= Ï&lowast; HÏ
</p>
<p>i hÌ
&minus; Ï HÏ
</p>
<p>&lowast;
</p>
<p>i hÌ
, (9.12)
</p>
<p>with Ï&lowast; HÏ &minus; Ï HÏ&lowast; = &minus;hÌ2/(2m) (Ï&lowast; &nabla;2Ï &minus; Ï &nabla;2Ï&lowast;). Identity (A.17) then
yields
</p>
<p>&part;|Ï |2
&part;t
</p>
<p>+ divJÏ = 0, JÏ =
i hÌ
</p>
<p>2m
(Ï gradÏ&lowast; &minus; Ï&lowast; gradÏ). (9.13)
</p>
<p>The first relation in (9.13) has the form of a continuity equation (compare with (23.3)
and (4.23)). As |Ï |2 is the probability density, JÏ takes the meaning of density of the
probability flux;1 it is a real quantity because the term in parentheses in the second
relation of (9.13) is imaginary.
</p>
<p>Relations (9.13) provide a physical explanation of the continuity requirements that
were discussed from the mathematical standpoint in Sect. 8.2. Such requirements,
namely, the continuity of the wave function and of its first derivatives in space,
were introduced in Sect. 8.2 with reference to the solutions of the time-independent
Schr&ouml;dinger equation; however, they hold also for the time-dependent one because
the spatial behavior of Ï is prescribed by the Hamiltonian operator. Their physical
explanation is that they provide the spatial continuity of the probability density and
of the probability-flux density. Integrating (9.13) over a volume ï¿½&prime; whose surface is
ï¿½&prime; yields
</p>
<p>d
</p>
<p>dt
</p>
<p>&int;
</p>
<p>ï¿½&prime;
|Ï |2 dï¿½&prime; = &minus;
</p>
<p>&int;
</p>
<p>ï¿½&prime;
JÏ &middot; n dï¿½&prime;, (9.14)
</p>
<p>with n the unit vector normal to ï¿½&prime;, oriented in the outward direction. The integral
at the left hand side of (9.14) is the probability of localizing the particle within ï¿½&prime;,
</p>
<p>1 Remembering that [|Ï |2] = m&minus;3, one finds [JÏ ] = m&minus;2 t&minus;1.</p>
<p/>
</div>
<div class="page"><p/>
<p>180 9 Time-Dependent Schr&ouml;dinger Equation
</p>
<p>that at the right hand side is the probability flux across ï¿½&prime; in the outward direction;
as a consequence, the meaning of (9.14) is that the time variation of the localization
probability within ï¿½&prime; is the negative probability flux across the surface. If ï¿½&prime; &rarr; &infin;
the surface integral vanishes because Ï is square integrable and, as expected,
</p>
<p>d
</p>
<p>dt
</p>
<p>&int;
</p>
<p>&infin;
|Ï |2 dï¿½ = 0. (9.15)
</p>
<p>The above is another form of the normalization condition and is also termed norm-
conservation condition. Note that the integral in (9.15) does not depend on time
although Ï does.
</p>
<p>The density of the probability flux can be given a different form that uses the
momentum operator pÌ = &minus;i hÌ grad introduced in Sect. 8.5; one finds
</p>
<p>JÏ =
1
</p>
<p>2m
</p>
<p>[
</p>
<p>Ï (pÌÏ)&lowast; + Ï&lowast; pÌÏ
]
</p>
<p>= 1
m
</p>
<p>&real;
(
</p>
<p>Ï&lowast; pÌÏ
)
</p>
<p>. (9.16)
</p>
<p>Although this form is used less frequently than (9.13), it makes the analogy with the
classical flux density much more intelligible.
</p>
<p>When the wave function is of the monochromatic type (9.4), the time-dependent
factors cancel each other in (9.13), to yield
</p>
<p>divJÏ = 0, JÏ =
i hÌ
</p>
<p>2m
(w gradw&lowast; &minus; w&lowast; gradw). (9.17)
</p>
<p>If w is real, then JÏ = 0.
</p>
<p>9.5 Hamiltonian Operator of a Charged Particle
</p>
<p>The Hamiltonian function of a particle of mass m and charge e, subjected to an
electromagnetic field, is given by (1.35), namely,
</p>
<p>H =
3
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>1
</p>
<p>2m
(pi &minus; e Ai)2 + e Ï, (9.18)
</p>
<p>where the scalar potentialÏ and the components of the vector potentialAi may depend
on the spatial coordinates and time. To find the Hamiltonian operator corresponding
to H one could apply the same procedure as in (8.48), that consists in replacing
pi with pÌi = &minus;i hÌ &part;/&part;xi . In this case, however, a difficulty arises if Ai depends
on the coordinates; in fact, the two equivalent expansions of (pi &minus; e Ai)2, namely,
p2i + e2 A2i &minus; 2pi e Ai and p2i + e2 A2i &minus; 2 e Ai pi yield two different operators: the
first of them contains the summand &part;(Ai Ï)/&part;xi , the other one contains Ai &part;Ï/&part;xi ,
and neither one is Hermitean. If, instead, one keeps the order of the factors in the</p>
<p/>
</div>
<div class="page"><p/>
<p>9.6 Approximate Form of the Wave Packet for a Free Particle 181
</p>
<p>expansion, namely, (pi &minus; e Ai)2 = p2i + e2 A2i &minus; e Ai pi &minus; pi e Ai , the resulting
Hamiltonian operator reads H = HR + i HI , with
</p>
<p>HR = &minus;
hÌ2
</p>
<p>2m
&nabla;2 + e Ï + e
</p>
<p>2
</p>
<p>2m
A &middot; A, HI =
</p>
<p>hÌ e
</p>
<p>2m
</p>
<p>3
&sum;
</p>
<p>i=1
</p>
<p>(
</p>
<p>Ai
&part;
</p>
<p>&part;xi
+ &part;
</p>
<p>&part;xi
Ai
</p>
<p>)
</p>
<p>,
</p>
<p>(9.19)
</p>
<p>and is Hermitean (compare with Sect. 10.2). The particle dynamics is determined by
the time-dependent Schr&ouml;dinger equation i hÌ &part;Ï/&part;t = HÏ . The continuity equation
fulfilled by Ï is found following the same reasoning as in Sect. 9.4, starting from
</p>
<p>&part;|Ï |2
&part;t
</p>
<p>= Ï&lowast; (HR + i HI )Ï
i hÌ
</p>
<p>&minus; Ï (HR &minus; i HI )Ï
&lowast;
</p>
<p>i hÌ
. (9.20)
</p>
<p>The terms related to HR yield &minus;div&real;(Ï&lowast; pÌÏ)/m as in Sect. 9.4. Those related to HI
yield div(eA |Ï |2)/m. In conclusion, the continuity equation for the wave function
of a charged particle reads
</p>
<p>&part;|Ï |2
&part;t
</p>
<p>+ divJÏ = 0, JÏ =
1
</p>
<p>m
&real;
[
</p>
<p>Ï&lowast;
(
</p>
<p>pÌ &minus; eA
)
</p>
<p>Ï
]
</p>
<p>. (9.21)
</p>
<p>It is worth noting that the transformation from the Hamiltonian function (9.18) to
the Hamiltonian operator (9.19) produced by replacing pi with pÌi is limited to the
dynamics of the particle; the electromagnetic field, instead, is still treated through the
scalar and vector potentials, and no transformation similar to that used for the particle
is carried out. The resulting Hamiltonian operator (9.19) must then be considered
as approximate; the term semiclassical approximation is in fact used to indicate
the approach based on (9.19), where the electromagnetic field is treated classically
whereas Quantum Mechanics is used in the description of the particle&rsquo;s dynamics.
The procedure by which the quantum concepts are extended to the electromagnetic
field is described in Sect. 12.3.
</p>
<p>The semiclassical approximation is useful in several instances, among which there
is the calculation of the stationary states of atoms. As shown in Sect. 9.7.2, it explains
why the radiative decay predicted in Sect. 5.11.3 using the classical (planetary) model
does not actually occur.
</p>
<p>9.6 Approximate Form of the Wave Packet for a Free Particle
</p>
<p>The energy spectrum of a free particle is continuous, and the wave packet is given
by (9.5), with
</p>
<p>wk(r) =
1
</p>
<p>(2Ï )3/2
exp (i k &middot; r), Ek =
</p>
<p>hÌ2
</p>
<p>2m
</p>
<p>(
</p>
<p>k21 + k22 + k23
)
</p>
<p>= hÌ Ïk. (9.22)
</p>
<p>As &minus;&infin; &lt; ki &lt; +&infin;, here the order of degeneracy of Ek is infinite. Now, remem-
bering that the wave packet is normalized to unity, it follows that |Ï(r, t)|2 d3r is</p>
<p/>
</div>
<div class="page"><p/>
<p>182 9 Time-Dependent Schr&ouml;dinger Equation
</p>
<p>the infinitesimal probability that at time t the particle is localized within d3r ; also,
from the analysis carried out in Sect. 9.2, the product |ck|2 d3k is the infinitesimal
probability that the outcome of an energy measurement belongs to the range of E(k)
values whose domain is d3k. Note that ck does not depend on time.
</p>
<p>Considering the example of a Gaussian wave packet given at the end of Sect. 9.2,
one can assume that |Ï(r, t)|2 is localized in the r space and |ck|2 is localized in the k
space. This means that |Ï(r, t)|2 and |ck|2 become vanishingly small when r departs
from its average value r0(t) and respectively, k departs from its average value k0.
Such average values are given by2
</p>
<p>r0(t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
r |Ï(r, t)|2 d3r , k0 =
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
k |ck|2 d3k. (9.23)
</p>
<p>An approximate expression of the wave packet is obtained by observing that, due
to the normalization condition (9.7), the main contribution to the second integral
in (9.7) is given by the values of k that are in the vicinity of k0. From the identity
k2i = (k0i &minus; k0i + ki)2 = k20i + 2 k0i (ki &minus; k0i) + (ki &minus; k0i)2 it then follows
</p>
<p>Ïk =
hÌ
</p>
<p>2m
k20 +
</p>
<p>hÌ
</p>
<p>m
k0 &middot; (k &minus; k0) +
</p>
<p>hÌ
</p>
<p>2m
|k &minus; k0|2 (9.24)
</p>
<p>where, for k close to k0, one neglects the quadratic term to find
</p>
<p>Ïk â Ï0 + u &middot; (k &minus; k0), Ï0 =
hÌ
</p>
<p>2m
k20 , u =
</p>
<p>hÌ
</p>
<p>m
k0 =
</p>
<p>(
</p>
<p>gradkÏk
)
</p>
<p>k0
, (9.25)
</p>
<p>with u the group velocity. The neglect of terms of order higher than the first used to
simplify (9.24) could not be applied to ck; in fact, ck has typically a peak for k = k0,
so its first derivatives would vanish there. Using (9.25) and letting Î¦0 = k0 &middot; r&minus;Ï0 t
transform (9.5) intoÏ(r, t) â exp (iÎ¦0)A (r &minus; u t ; k0), where the envelope function
A is defined as
</p>
<p>A (r &minus; u t ; k0) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>ck
</p>
<p>(2Ï )3/2
exp [i (r &minus; u t) &middot; (k &minus; k0)] d3k. (9.26)
</p>
<p>Within the limit of validity of (9.25), the envelope function contains the whole
information about the particle&rsquo;s localization: |Ï |2 = |A|2. Also, the dependence of
A on r and t is such that, for any two pairs (r1, t1), (r2, t2) fulfilling r2&minus;u t2 = r1&minus;u t1
the form of A(r2, t2) is the same as that of A(r1, t1). In other terms, A moves without
distortion in the direction of u, and its velocity is (r2 &minus; r1)/(t2 &minus; t1) = u. As time
evolves, the approximation leading to (9.25) becomes less and less accurate; taking by
way of example t1 = 0 as the initial time, and observing that the summands in (9.25)
belong to the phase&minus;iÏk t , the approximation holds as long as hÌ |k&minus;k0|2 t/(2m) âª
2Ï .
</p>
<p>2 Definitions (9.23) provide the correct weighed average of r and k thanks to the normalization
condition (9.7). A more exhaustive treatment is carried out in Sect. 10.5.</p>
<p/>
</div>
<div class="page"><p/>
<p>9.7 Complements 183
</p>
<p>9.7 Complements
</p>
<p>9.7.1 About the Units of the Wave Function
</p>
<p>Consider the wave functionÏ associated to a single particle. When the wave function
is square integrable and normalized to unity, its units are [Ï] = m&minus;3/2 due to
&int;
</p>
<p>|Ï |2 d3r = 1. Then, if the eigenvalues of the Hamiltonian operator are discrete,
the second equality in (9.3) shows that |cn|2, cn are dimensionless and, finally, (9.2)
shows that wn has the same units as Ï . If the eigenvalues are continuous, the second
equality in (9.7) shows that |ck|2 has the dimensions of a volume of the real space,
so that [ck] = m3/2 and, finally, (9.6) shows that wk has the same units as Ï .
</p>
<p>There are situations, however, where units different from those illustrated above
are ascribed to the eigenfunctions. One example is that of the eigenfunctions of the
form wk = exp (i k &middot; r)/(2Ï )3/2, worked out in Sect. 8.2.1, which are dimension-
less; another example is that of eigenfunctions of the form (10.7), whose units are
[Î´(r &minus; r0)] = m&minus;3. When such eigenfunctions occur, the units of the expansion&rsquo;s
coefficients must be modified in order to keep the correct units of Ï (compare with
the calculation shown in Sect. 14.6).
</p>
<p>The considerations carried out here apply to the single-particle case. When
the wave function describes a system of two or more particles, its units change
accordingly (Sect. 15.2).
</p>
<p>9.7.2 An Application of the Semiclassical Approximation
</p>
<p>As indicated in Sect. 9.5 for the case of a particle subjected to an electromagnetic
field, the semiclassical approximation consists in using the Hamiltonian operator
(9.19), which is derived from the Hamiltonian function (9.18) by replacing pi with
pÌi . The electromagnetic field, instead, is still treated through the scalar and vector
potentials. Experiments show that the approximation is applicable in several cases
of interest. For instance, consider again the problem of the electromagnetic field
generated by a single electron, discussed in classical terms in Sect. 5.11.2. If Ï is
the wave function (assumed to be square integrable) associated to the electron in the
quantum description, the electron&rsquo;s localization is given by |Ï |2. It is then sensible
to describe the charge density and the current density produced by the electron as
</p>
<p>Ï = &minus;q |Ï |2, J = &minus;q JÏ , (9.27)
</p>
<p>where q is the elementary charge and JÏ is defined in (9.13). If the electron is in a
stationary state, namely, Ï(r, t) = w(r) exp ( &minus; iÏ t), then Ï and J are independent
of time. From (4.58, 4.59) it follows that the potentials Ï, A are independent of time
as well. As a consequence, the distribution of charge and current density associated
to the electron&rsquo;s motion is stationary (compare with (9.17)), which also yields that
the acceleration uÌ vanishes. From Larmor&rsquo;s formula (5.72) one finally finds that in</p>
<p/>
</div>
<div class="page"><p/>
<p>184 9 Time-Dependent Schr&ouml;dinger Equation
</p>
<p>this situation the electron emits no power; thus, the radiative decay predicted in
Sect. 5.11.3 using the classical model does not occur.
</p>
<p>9.7.3 Polar Form of the Schr&ouml;dinger Equation
</p>
<p>The time-dependent Schr&ouml;dinger equation (9.9) is easily split into two real equations
by considering the real and imaginary part of Ï . However, in this section the wave
function will rather be written in polar form, Ï = Î±(r, t) exp [i Î²(r, t)], Î± &ge; 0,
which reminds one of that used to derive the eikonal equation (5.51) of Geometrical
Optics. Despite the fact that the resulting relations are non linear, the outcome of
this procedure is interesting. Considering a Hamiltonian operator of the type H =
&minus;hÌ2 &nabla;2/(2m) + V , replacing the polar expression of Ï in (9.9), and separating the
real and imaginary parts, yields two coupled, real equations; the first of them reads
</p>
<p>&part;Î±
</p>
<p>&part;t
= &minus; hÌ
</p>
<p>2m
</p>
<p>(
</p>
<p>Î±&nabla;2Î² + 2gradÎ± &middot; gradÎ²
)
</p>
<p>, (9.28)
</p>
<p>where the units of Î±2 are those of the inverse of a volume. As for the second equation
one finds
</p>
<p>&part;(hÌ Î²)
</p>
<p>&part;t
+ 1
</p>
<p>2m
|grad(hÌÎ²)|2 + V +Q = 0, Q = &minus; hÌ
</p>
<p>2
</p>
<p>2m
</p>
<p>&nabla;2Î±
Î±
</p>
<p>, (9.29)
</p>
<p>where the units of grad(hÌ Î²) are those of a momentum. Using the short-hand notation
</p>
<p>P = Î±2 = |Ï |2, S = hÌ Î², ve =
gradS
</p>
<p>m
, HQ =
</p>
<p>1
</p>
<p>2
mv2e +Q+ V , (9.30)
</p>
<p>and multiplying (9.28) by 2Î±, transforms (9.28, 9.29) into
</p>
<p>&part;P
</p>
<p>&part;t
+ div(P ve) = 0,
</p>
<p>&part;S
</p>
<p>&part;t
+HQ = 0. (9.31)
</p>
<p>The wave function is assumed to be square integrable, so that
&int;
</p>
<p>ï¿½
P d3r = 1. It
</p>
<p>is easily found that the first of (9.31) is the continuity equation (9.13): from the
expression (9.16) of the current density one finds in fact
</p>
<p>JÏ =
1
</p>
<p>m
&real;
(
</p>
<p>Ï&lowast; pÌÏ
)
</p>
<p>= hÌ
m
</p>
<p>&real;
(
</p>
<p>Î±2 gradÎ² &minus; i Î± gradÎ±
)
</p>
<p>= P ve. (9.32)
</p>
<p>The two differential equations (9.31), whose unknowns are Î±, Î², are coupled with
each other. The second of them is similar to the Hamilton&ndash;Jacobi equation (1.51)
of Classical Mechanics, and becomes equal to it in the limit hÌ &rarr; 0, that makes Q
to vanish and S to become the Hamilton principal function (Sect. 1.7). Note that
the limit Q &rarr; 0 decouples (9.31) from each other. In the time-independent case
(9.31) reduce to div(P ve) = 0 and m v2e/2 +Q+ V = E, coherently with the fact</p>
<p/>
</div>
<div class="page"><p/>
<p>9.7 Complements 185
</p>
<p>that in this case Hamilton&rsquo;s principal function becomes S = W &minus; E t , with W the
(time-independent) Hamilton characteristic function. Although ve plays the role of
an average velocity in the continuity equation of (9.31), determining the expectation
value needs a further averaging: in fact, taking definition of (10.13) expectation value
and observing that the normalization makes the integral of gradÎ±2 to vanish, yields
</p>
<p>m ãveã =
&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast; pÌÏ d3r =
&int;
</p>
<p>ï¿½
</p>
<p>Î±2 &nabla;(hÌ Î²) d3r = m
&int;
</p>
<p>ï¿½
</p>
<p>Î±2 ve d
3r. (9.33)
</p>
<p>The last relation in (9.30) seems to suggest that Q is a sort of potential energy to
be added to V . In fact this is not true, as demonstrated by the calculation of the
expectation value of the kinetic energy T ,
</p>
<p>ãT ã = &minus; hÌ
2
</p>
<p>2m
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast;&nabla;2Ï d3r =
&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast;
(
</p>
<p>1
</p>
<p>2
m v2e +Q
</p>
<p>)
</p>
<p>Ï d3r , (9.34)
</p>
<p>showing that Q enters the expectation value of T , not V . To better investigate the
meaning of Q it is useful to consider alternative expressions of ãQã, like
</p>
<p>ãQã = hÌ
2
</p>
<p>2m
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>|&nabla;Î±|2 d3r = 1
2m
</p>
<p>(
</p>
<p>ãpÌ &middot; pÌã &minus; ãp2e ã
)
</p>
<p>, (9.35)
</p>
<p>where pÌ = &minus;i hÌ grad and pe = m ve. The derivation of (9.34, 9.35) follows the
same pattern as that of (9.28, 9.29). The first form of (9.35) shows that ãQã is
positive definite irrespective of the shape of Î±. The second one is the analogue of
the definition of dispersion around the average: the analogy with the treatment used
in statistical mechanics (compare with (19.79)) suggests that p2e/(2m) provides the
analogue of the convective part of the kinetic energy, while Q provides the analogue
of the thermal part of it [87].
</p>
<p>It is interesting to note that the analogy between the Schr&ouml;dinger equation and a set
of a continuity and a Hamilton&ndash;Jacobi-like equations had been noted by de Broglie,
who introduced the concept of pilot wave in [24]. This cost him severe criticism by
Pauli at the Fifth Solvay Conference in 1927. He resumed the idea more than 20
years later, stimulated by the papers by Bohm introducing the concept of quantum
potential, see, e.g., [8]. The most recent paper by de Broglie on the subject is [25],
published when the author was 79 years old.
</p>
<p>9.7.4 Effect of a Gauge Transformation on the Wave Function
</p>
<p>The Hamiltonian function (1.35) of a particle of mass m and charge e, subjected to
an electromagnetic field, has been derived in Sect. 1.5 and reads H = &sum;3i=1 (pi &minus;
e Ai)2/(2m)+e Ï, withpi the ith component of momentum in Cartesian coordinates,
Ï the electric potential, andAi the ith component of the magnetic potential. If a gauge
transformation (Sect. 4.5) is carried out, leading to the new potentials
</p>
<p>Ï &larr; Ï&prime; = Ï &minus; &part;Ï
&part;t
</p>
<p>, A &larr; A&prime; = A + gradÏ , (9.36)</p>
<p/>
</div>
<div class="page"><p/>
<p>186 9 Time-Dependent Schr&ouml;dinger Equation
</p>
<p>the resulting Hamiltonian function H &prime; differs from the original one. In other terms,
the Hamiltonian function is not gauge invariant. However, the Lorentz force e (E +
rÌ &and; B) is invariant, whence the dynamics of the particle is not affected by a gauge
transformation.
</p>
<p>Also in the quantum case it turns out that the Hamiltonian operator is not gauge
invariant, H&prime; ï¿½= H. As consequence, the solution of the Schr&ouml;dinger equation is not
gauge invariant either: Ï &prime; ï¿½= Ï . However, the particle&rsquo;s dynamics cannot be affected
by a gauge transformation because the Lorentz force is invariant. It follows that, if
the initial condition is the same, |Ï &prime;|2t=0 = |Ï |2t=0, then it is |Ï &prime;|2 = |Ï |2 at all times;
for this to happen, there must exist a real function Ï such that
</p>
<p>Ï &prime; = Ï exp (i Ï ), Ï = Ï (r, t). (9.37)
</p>
<p>From the gauge invariance of |Ï |2 at all times it follows &part;|Ï &prime;|2/&part;t = &part;|Ï |2/&part;t
whence, from the continuity equation (9.21), one obtains divJ&prime;Ï = divJÏ with
JÏ = &real;[Ï&lowast;(pÌ &minus; eA)Ï]/m. Gauge transforming the quantities in brackets yields
(Ï &prime;)&lowast; pÌÏ &prime; = Ï&lowast; pÌÏ + |Ï |2 hÌ gradÏ and (Ï &prime;)&lowast; eA&prime; Ï &prime; = |Ï |2 eA + |Ï |2 e gradÏ ,
whose difference provides
</p>
<p>J&prime;Ï &minus; JÏ =
1
</p>
<p>m
|Ï |2 grad (hÌ Ï &minus; e Ï) . (9.38)
</p>
<p>In (9.38) it is |Ï |2 ï¿½= 0 and grad|Ï |2 ï¿½= 0; also, hÌ Ï &minus; e Ï is independent of Ï . It
follows that, for div(J&prime;Ï &minus;JÏ ) = 0 to hold, from (A.17) it must be grad (hÌÏ &minus; eÏ) =
0, namely, hÌÏ &minus; eÏ is an arbitrary function of time only. Setting the latter to zero
finally yields the expression for the exponent in (9.37), that reads3
</p>
<p>Ï = e
hÌ
Ï. (9.39)
</p>
<p>Problems
</p>
<p>9.1 Using the one-dimensional form of (9.26) determine the envelope functionA(x&minus;
u t) corresponding to ck =
</p>
<p>&radic;
</p>
<p>Ï/
&radic;
Ï exp ( &minus; Ï 2 k2/2), with Ï a length. Noting
</p>
<p>that
&int; +&infin;
&minus;&infin; |ck|2 dk = 1, show that A is normalized to 1 as well.
</p>
<p>9.2 Using the envelope function A(x &minus; u t) obtained from Prob. 9.1 and the one-
dimensional form of definition (9.23), show that x0(t) = u t .
</p>
<p>3 The units of Ï are [Ï] = V s.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 10
</p>
<p>General Methods of Quantum Mechanics
</p>
<p>10.1 Introduction
</p>
<p>The preceding chapters have provided the introductory information about Quantum
Mechanics. Here the general principles of the theory are illustrated, and the methods
worked out for the Hamiltonian operator are extended to the operators associated
to dynamical variables different from energy. The important concept of separable
operator is introduced, and the property of some operators to commute with each
other is related to the mutual compatibility of measurements of the corresponding
dynamical variables. Then, the concepts of expectation value and uncertainty are
introduced, and the Heisenberg uncertainty principle is worked out. This leads in
turn to the analysis of the time derivative of the expectation values, showing that
the latter fulfill relations identical to those of Classical Mechanics. The form of the
minimum-uncertainty wave packet is worked out in the complements.
</p>
<p>10.2 General Methods
</p>
<p>The discussion carried out in Sect. 9.2 has led to a number of conclusions regarding
the eigenvalues of the time-independent Schr&ouml;dinger equation (7.45). They are:
</p>
<p>&bull; The energy of a particle subjected to a conservative force is one of the eigenval-
ues of the time-independent equation Hw = Ew, where H is derived from the
corresponding Hamiltonian function by replacing pi with &minus;i hÌ &part;/&part;xi . Any other
energy different from an eigenvalue is forbidden.
</p>
<p>&bull; The wave function of a conservative case (taking by way of example the discrete-
eigenvalue case) is Ï = &sum;n cn wn exp ( &minus; iEn t/hÌ). The particle&rsquo;s localization
is given by |Ï |2, where it is assumed that Ï is normalized to unity. The proba-
bility that a measurement of energy finds the eigenvalue Em is |cm|2; an energy
measurement that finds the eigenvalues Em forces cn to become Î´nm.
</p>
<p>&bull; The time evolution ofÏ is found by solving the time-dependent Schr&ouml;dinger equa-
tion i hÌ &part;Ï/&part;t = HÏ . The latter holds also in the non-conservative situations;
although in such cases the wave function Ï is not expressible as a superposition
of monochromatic waves, it can still be expanded using an orthonormal set like
in (9.10) or (9.11).
</p>
<p>&copy; Springer Science+Business Media New York 2015 187
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_10</p>
<p/>
</div>
<div class="page"><p/>
<p>188 10 General Methods of Quantum Mechanics
</p>
<p>An important issue is now extending the conclusions listed above to the dynamical
quantities different from energy (e.g., momentum, angular momentum, and so on).
The extension is achieved by analogy, namely, it is assumed that for any dynamical
variable one can construct an eigenvalue equation whose solution provides the pos-
sible values of the variable itself. This line of reasoning yields the procedures listed
below, that are called general methods of Quantum Mechanics:
</p>
<p>1. Given a dynamical variable A, an operator A is associated to it. It is found, first,
by expressing A in terms of canonical coordinates qi ,pi (Sect. 1.6), then, by
replacing the momentum&rsquo;s components pi with pÌi = &minus;i hÌ &part;/&part;qi in such a way
that A is Hermitean.
</p>
<p>2. It is checked whether the eigenvalue equation Av = Av possesses a complete,
orthonormal set of eigenfunctions. If the check fails, the operator is not con-
sidered; otherwise it is accepted, and is called observable [78, Chap. V.9]. The
eigenvalue equation is subjected to the same boundary or asymptotic conditions
as Hw = Ew.
</p>
<p>3. Let An or AÎ² be the eigenvalues of Av = Av, with n (Î²) a set of discrete
(continuous) indices. Such eigenvalues are the only values that a measure of the
dynamical variable A can find.
</p>
<p>4. Thanks to completeness, the wave function Ï describing the particle&rsquo;s
localization can be written, respectively for discrete or continuous spectra,
</p>
<p>Ï =
&sum;
</p>
<p>n
</p>
<p>an(t) vn(r), Ï =
&int;
</p>
<p>Î²
</p>
<p>aÎ²(t) vÎ²(r) dÎ², (10.1)
</p>
<p>with an = ãvn|Ïã, aÎ² = ãvÎ² |Ïã.
5. If the wave function in (10.1) is normalizable, then
</p>
<p>&sum;
</p>
<p>n |an|2 = 1,
&int;
</p>
<p>Î²
|aÎ² |2 dÎ² = 1
</p>
<p>at all times. For a discrete spectrum, Pn = |an(tA)|2 is the probability that a
measurement of A finds the eigenvalue An at t = tA. For a continuous spectrum,
the infinitesimal probability that at t = tA the domain of AÎ² is found in the
interval dÎ² around Î² is dP = |aÎ²(tA)|2 dÎ².
</p>
<p>6. When the measurement is carried out at t = tA and an eigenvalue, say, Am,
is found, the coefficients of the first expansion in (10.1) are forced by the
measurement to become |an(t+A )|2 = Î´mn, and the wave function at that instant1
becomesÏ(r, t+A ) = vm(r). The time evolution ofÏ starting from t+A is prescribed
by the time-dependent Schr&ouml;dinger equation i hÌ &part;Ï/&part;t = HÏ , with Ï(r, t+A )
as the initial condition. In this respect there is a neat parallel with Classical
Mechanics, where the time evolution of the canonical variables starting from the
initial conditions is prescribed by the Hamilton equations (1.42).
</p>
<p>According to the general methods listed above, the eigenvalues of A are the only
possible outcome of a measurement of the dynamical variable A. As the eigenvalues
</p>
<p>1 Measurements are not instantaneous (refer to the discussion in Sect. 9.2). Here it is assumed that
the duration of a measurement is much shorter than the time scale of the whole experiment.</p>
<p/>
</div>
<div class="page"><p/>
<p>10.3 Separable Operators 189
</p>
<p>represent a physical quantity, they must be real; this makes the requirement that A
must be Hermitean easily understood: if an operator is Hermitean, then its eigenvalues
are real (Sect. 8.4.1). The inverse is also true: if the eigenfunctions of A form a
complete set and its eigenvalues are real, then A is Hermitean. In fact, for any pair
of functions f , g, considering the discrete spectrum by way of example, one has
</p>
<p>ãg|Af ã &minus; ãAg|f ã =
&sum;
</p>
<p>n
</p>
<p>&sum;
</p>
<p>m
</p>
<p>g&lowast;n fm [ãvn|Avmã &minus; ãAvn|vmã] =
</p>
<p>=
&sum;
</p>
<p>n
</p>
<p>&sum;
</p>
<p>m
</p>
<p>g&lowast;n fm ãvn|vmã
(
</p>
<p>Am &minus; A&lowast;n
)
</p>
<p>=
&sum;
</p>
<p>n
</p>
<p>g&lowast;n fn
(
</p>
<p>An &minus; A&lowast;n
)
</p>
<p>= 0, (10.2)
</p>
<p>which holds for all f , g because the eigenfunctions vn are mutually orthogonal and
the eigenvalues An are real.
</p>
<p>As indicated at point 1 above, the dynamical variable A is transformed into the
operator A by replacingpi with pÌi . The operator obtained from such a replacement is
not necessarily Hermitean: its hermiticity must be checked on a case-by-case basis.
For instance, the dynamical variable A = x px can be written in equivalent ways as
x px , px x, and (x px + px x)/2. However, their quantum counterparts
</p>
<p>&minus;i hÌx &part;
&part;x
</p>
<p>, &minus;i hÌ &part;
&part;x
</p>
<p>x, &minus;i hÌ
2
</p>
<p>(
</p>
<p>x
&part;
</p>
<p>&part;x
+ &part;
</p>
<p>&part;x
x
</p>
<p>)
</p>
<p>(10.3)
</p>
<p>are different from each other, and only the third one is Hermitean (compare with
Sect. 9.5).
</p>
<p>10.3 Separable Operators
</p>
<p>Let A be an operator acting only on the x coordinate. Similarly, let B and C two
operators acting only on y and z, respectively. The eigenvalue equations for the
discrete-spectrum case read
</p>
<p>Auk = Ak uk , Bvm = Bm vm, Cwn = Cn wn, (10.4)
where uk(x), vm(y), and wn(z) are three complete and orthonormal sets of eigenfunc-
tions. Given a function f (x, y, z), thanks to the completeness of the three sets the
following expansion holds:
</p>
<p>f (x, y, z) =
&sum;
</p>
<p>n
</p>
<p>an(x, y) wn =
&sum;
</p>
<p>n
</p>
<p>[
</p>
<p>&sum;
</p>
<p>m
</p>
<p>bmn(x) vm
</p>
<p>]
</p>
<p>wn =
</p>
<p>=
&sum;
</p>
<p>n
</p>
<p>{
</p>
<p>&sum;
</p>
<p>m
</p>
<p>[
</p>
<p>&sum;
</p>
<p>k
</p>
<p>ckmn uk
</p>
<p>]
</p>
<p>vm
</p>
<p>}
</p>
<p>wn =
&sum;
</p>
<p>kmn
</p>
<p>ckmn uk vm wn, (10.5)
</p>
<p>showing that the set made of the products uk vm wn is complete. Also, for any linear
combination of the above operators, with a, b, c constant vectors, it is
</p>
<p>(a A + b B + c C) uk vm wn = (aAk + bBm + cCn) uk vm wn, (10.6)</p>
<p/>
</div>
<div class="page"><p/>
<p>190 10 General Methods of Quantum Mechanics
</p>
<p>that is, uk vm wn is an eigenfunction corresponding to eigenvalue aAk+bBm+cCn.
It is important to add that in (10.4) it is implied that the boundary conditions of
Auk = Ak uk depend on x alone, those of Bvm = Bm vm on y alone, and the
like for the third equation. In other terms, separability means that at least one set of
coordinates exists, such that both the equation and boundary conditions are separable.
</p>
<p>As a first example of application of (10.6), consider the classical position of
a particle, r = x1 i1 + x2 i2 + x3 i3. Such a dynamical variable does not contain
the components of momentum; as a consequence, the operator associated to it is
r itself, and generates the eigenvalue equation r g(r) = r0 g(r). Separating the
latter and considering the eigenvalue equation for xi , one finds xi vi(xi) = xi0 vi(xi),
namely, (xi &minus; xi0) vi(xi) = 0 for all xi ï¿½= xi0. It follows vi = Î´(xi &minus; xi0), whence
r0 = x10 i1 + x20 i2 + x30 i3, and
</p>
<p>gr0 (r) = Î´(x1 &minus; x10) Î´(x2 &minus; x20) Î´(x3 &minus; x30) = Î´(r &minus; r0). (10.7)
</p>
<p>As a second example consider the classical momentum of a particle, p = p1 i1 +
p2 i2 + p3 i3. Remembering the discussion of Sect. 8.5 one finds for the operator
associated to p,
</p>
<p>"Ìp = &minus;i hÌ
(
</p>
<p>i1
&part;
</p>
<p>&part;x1
+ i2
</p>
<p>&part;
</p>
<p>&part;x2
+ i3
</p>
<p>&part;
</p>
<p>&part;x3
</p>
<p>)
</p>
<p>= &minus;i hÌ grad, (10.8)
</p>
<p>whose eigenvalue equation reads &minus;i hÌ gradf = p0 f . Separation yields for the ith
eigenvalue equation, with vi = vi(xi), the first-order equation &minus;i hÌ dvi/dxi = pi0 vi
(compare with (8.49)), whence vi = (2Ï )&minus;1/2 exp (i ki xi), with ki = pi0/hÌ, so that
k = p/hÌ = k1 i1 + k2 i2 + k3 i3, and
</p>
<p>fk(r) = (2Ï )&minus;3/2 exp (i k &middot; r). (10.9)
</p>
<p>Neither (10.7) nor (10.9) are square integrable. The indices of the eigenvalues (r0 in
(10.7) and k in (10.9)) are continuous in both cases.Also, from the results of Sects. C.2
and C.5 one finds that gr0 (r) = g(r, r0) is the Fourier transform of fk(r) = f (r, k).
</p>
<p>10.4 Eigenfunctions of Commuting Operators
</p>
<p>It has been shown in Sect. 10.2 that a measurement of the dynamical variable A at
time tA yields one of the eigenvalues of the equation Aa = Aa. Considering for
instance a discrete spectrum, let the eigenvalue be Am. The initial condition Ï(r, t
</p>
<p>+
A )
</p>
<p>for the time evolution of the particle&rsquo;s wave function after the measurement is one of
the eigenfunctions of A corresponding toAm. If a measurement of another dynamical
variable B is carried out at a later time tB , the wave function at t = tB is forced to
become one of the eigenfunctions of Bb = B b, say, bk . The latter can in turn be
expanded in terms of the complete set derived from A, namely, bk =
</p>
<p>&sum;
</p>
<p>nãan|bkã an.
As the coefficients of the expansion are in general different from zero, there is a finite</p>
<p/>
</div>
<div class="page"><p/>
<p>10.4 Eigenfunctions of Commuting Operators 191
</p>
<p>probability that a new measurement ofA at tC &gt; tB finds a value different fromAm. In
principle this could be due to the fact that, ifA is not conserved, its value has evolved,
from the outcome Am of the measurement carried out at t = tA, into something
different, as prescribed by the time-dependent Schr&ouml;dinger equation having Ï(r, t+A )
as initial condition.2 However, the instant tB of the second measurement can in
principle be brought as close to tA as we please, so that the two measurements can be
thought of as simultaneous. As a consequence, the loss of information about the value
of A must be ascribed to the second measurement, specifically, to its interference
with the wave function, rather than to a natural evolution3 of the value of A: the gain
in information about the eigenvalue of B produces a loss of information about that
of A; for this reason, the two measurements are said to be incompatible.
</p>
<p>From the discussion above one also draws the conclusion that, if it were bk = am,
the two measurements of outcome Am and Bk would be compatible. This is in itself
insufficient for stating that the measurements of A and B are compatible in all cases;
for this to happen it is necessary that the whole set of eigenfunctions of A coincides
with that of B: in this case, in fact, the condition bk = am is fulfilled no matter what
the outcome of the two measurements is.
</p>
<p>It would be inconvenient to check the eigenfunctions to ascertain whether two
observables A, B are compatible or not. In fact, this is not necessary thanks to
the following property: if two operators A and B have a common, complete set of
eigenfunctions, then they commute, and vice versa (as indicated in Sect. 8.6.2, two
operators commute if their commutator (8.71) is the null operator). Still assuming
a discrete spectrum, for any eigenfunction vn it is ABvn = ABn vn = BnAvn =
Bn An vn. Similarly, BAvn = BAn vn = AnBvn = An Bn vn, showing that A and B
commute for all eigenfunctions. Then, using the completeness of the common set vn
to expand any function f as f = &sum;n fn vn, one finds
</p>
<p>ABf =
&sum;
</p>
<p>n
</p>
<p>fnABvn =
&sum;
</p>
<p>n
</p>
<p>fnBAvn = BA
&sum;
</p>
<p>n
</p>
<p>fn vn = BAf. (10.10)
</p>
<p>This proves that if two operators have a complete set of eigenfunctions in common,
then they commute. Conversely, assume that A and B commute and let vn be an
eigenfunction of A; then, ABvn = BAvn and Avn = An vn. Combining the latter
relations yields ABvn = BAn vn which, letting gn = Bvn, is recast as Agn =
Angn. In conclusion, both vn and gn are eigenfunctions of A belonging to the same
eigenvalue An.
</p>
<p>If An is not degenerate, the eigenfunctions vn and gn must be the same function,
apart from a multiplicative constant due to the homogeneity of the eigenvalue equa-
tion. Let such a constant be Bn; combining gn = Bn vn with the definition gn = Bvn
yields Bvn = Bn vn, this showing that vn is an eigenfunction of B as well. The
</p>
<p>2 By way of example one may think of A as the position x, that typically evolves in time from the
original value xA = x(tA) even if the particle is not perturbed.
3 In any case, the evolution would be predicted exactly by the Schr&ouml;dinger equation. Besides, the
eigenvalue would not change if A were conserved.</p>
<p/>
</div>
<div class="page"><p/>
<p>192 10 General Methods of Quantum Mechanics
</p>
<p>property holds also when An is degenerate, although the proof is somewhat more
involved [77, Chap. 8-5]. This proves that if two operators commute, then they have
a complete set of eigenfunctions in common. Examples are given in Sect. 8.6.3.
</p>
<p>10.5 Expectation Value and Uncertainty
</p>
<p>The discussion carried out in Sect. 10.2 has led to the conclusion that the wave func-
tionÏ describing the particle&rsquo;s localization can be expanded as in (10.1), where vn or
vÎ² are the eigenfunctions of a Hermitean operator A that form a complete, orthonor-
mal set. Considering a discrete spectrum first, the coefficients of the expansion are
an = ãvn|Ïã; assuming that the wave function is normalizable, it is
</p>
<p>&sum;
</p>
<p>n |an|2 = 1.
The meaning of the coefficients is that Pn = |an(t)|2 is the probability that a
</p>
<p>measurement ofA finds the eigenvalueAn at t . From this it follows that the statistical
average of the eigenvalues is
</p>
<p>ãAã(t) =
&sum;
</p>
<p>n
</p>
<p>Pn An. (10.11)
</p>
<p>The average (10.11) is called expectation value.4 It can be given a different form by
observing that Pn = a&lowast;n an = (
</p>
<p>&sum;
</p>
<p>m a
&lowast;
m Î´mn) an and that, due to the orthonormality of
</p>
<p>the eigenfunctions of A, it is Î´mn = ãvm|vnã; then,
</p>
<p>&sum;
</p>
<p>n
</p>
<p>(
</p>
<p>&sum;
</p>
<p>m
</p>
<p>a&lowast;m ãvm|vnã
)
</p>
<p>an An = ã
&sum;
</p>
<p>m
</p>
<p>amvm|
&sum;
</p>
<p>n
</p>
<p>anAnvnã = ã
&sum;
</p>
<p>m
</p>
<p>amvm|
&sum;
</p>
<p>n
</p>
<p>anAvnã.
</p>
<p>(10.12)
</p>
<p>Combining (10.12) with (10.11) and remembering that A is Hermitean yields
</p>
<p>ãAã = ãÏ |A|Ïã. (10.13)
</p>
<p>The same result holds for a continuous spectrum:
</p>
<p>ãAã =
&int;
</p>
<p>Î±
</p>
<p>PÎ± AÎ± dÎ± =
&int;
</p>
<p>Î±
</p>
<p>|aÎ±|2 AÎ± dÎ± = ãÏ |A|Ïã, (10.14)
</p>
<p>where
&int;
</p>
<p>Î±
</p>
<p>|aÎ±|2 AÎ± dÎ± =
&int;
</p>
<p>Î±
</p>
<p>(&int;
</p>
<p>Î²
</p>
<p>a&lowast;Î² Î´(Î² &minus; Î±) dÎ²
)
</p>
<p>aÎ± AÎ± dÎ±, (10.15)
</p>
<p>and
&int;
</p>
<p>Î²
|aÎ² |2 dÎ² = 1 at all times. The expectation values of Hermitean operators
</p>
<p>are real because they are the statistical averages of the eigenvalues, themselves real.
</p>
<p>4 If the wave function is normalized to a number different from unity, the definition of the expectation
value is
</p>
<p>&sum;
</p>
<p>n Pn An/
&sum;
</p>
<p>n Pn, and the other definitions are modified accordingly.</p>
<p/>
</div>
<div class="page"><p/>
<p>10.6 Heisenberg Uncertainty Relation 193
</p>
<p>Using (8.57) one extends the definition of expectation value to the powers of the
eigenvalues; for instance,
</p>
<p>ãA2ã = ãÏ |A2|Ïã =
&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast; AAÏ dï¿½ = ãAÏ |AÏã = ||AÏ ||2 &ge; 0, (10.16)
</p>
<p>where the hermiticity of A is exploited. The variance of the eigenvalues is given by
</p>
<p>(ï¿½A)2 =
&lang;
</p>
<p>(A&minus; ãAã)2
&rang;
</p>
<p>=
&lang;
</p>
<p>A2 &minus; 2 ãAãA+ ãAã2
&rang;
</p>
<p>= ãA2ã &minus; ãAã2, (10.17)
real and non negative by construction; as a consequence, ãA2ã &ge; ãAã2. The general
term used to indicate the positive square root of the variance, ï¿½A =
</p>
<p>&radic;
</p>
<p>(ï¿½A)2 &ge; 0,
is standard deviation. When it is used with reference to the statistical properties of
the eigenvalues, the standard deviation is called uncertainty.
</p>
<p>Assume by way of example that the wave function at t = tA coincides with one
of the eigenfunctions of A. With reference to a discrete spectrum (first relation in
(10.1)), let Ï(tA) = vm. From (10.13) and (10.17) it then follows ãAã(tA) = Am,
ï¿½A(tA) = 0. The standard deviation of the eigenvalues is zero in this case, because
the measurement ofA can only find the eigenvalueAm. As a second example consider
a continuous spectrum in one dimension, and let Ï(tA) = exp (i k x)/
</p>
<p>&radic;
2Ï , namely,
</p>
<p>an eigenfunction of the momentum operator. In this case the wave function is not
square integrable, so one must calculate the expectation value as
</p>
<p>ãAã(tA) = lim
x0&rarr;&infin;
</p>
<p>&int; +x0
&minus;x0 Ï
</p>
<p>&lowast;(tA) AÏ(tA) dx
&int; +x0
&minus;x0 Ï
</p>
<p>&lowast;(tA)Ï(tA) dx
. (10.18)
</p>
<p>If one lets A = pÌ = &minus;i hÌ d/dx, the result is ãpã(tA) = hÌ k, ï¿½p(tA) = 0. In fact, like
in the previous example, the wave function coincides with one of the eigenfunctions
of the operator. If, however, one applies another operator to the same wave function,
its variance does not necessarily vanish. A remarkable outcome stems from applying
xÌ = x, that is, the operator associated to the dynamical variable canonically conjugate
to p: one finds ãxã(tA) = 0, ï¿½x(tA) = &infin;.
</p>
<p>In conclusion, the examples above show that the term &ldquo;uncertainty&rdquo; does not refer
to an insufficient precision of the measurements (which in principle can be made as
precise as we please), but to the range of eigenvalues that is covered by the form
of Ï(tA). In the last example above all positions x are equally probable because
|Ï(tA)|2 = const, whence the standard deviation of position diverges.
</p>
<p>10.6 Heisenberg Uncertainty Relation
</p>
<p>Consider the wave function Ï describing the dynamics of a particle, and let A and
B be Hermitean operators. A relation exists between the standard deviations of these
operators, calculated with the same wave function. Defining the complex functions
f = (A &minus; ãAã)Ï and g = (B &minus; ãBã)Ï yields
</p>
<p>||f ||2 = (ï¿½A)2, ||g||2 = (ï¿½B)2, ãf |gã &minus; ãg|f ã = i ãCã, (10.19)</p>
<p/>
</div>
<div class="page"><p/>
<p>194 10 General Methods of Quantum Mechanics
</p>
<p>where the first two relations derive from (10.17) while ãCã in the third one is the
expectation value of the commutator C = &minus;i (AB &minus;BA). Letting Î¼ = i Î½ in (8.16),
with Î½ real, and using (10.19) provides
</p>
<p>(ï¿½A)2 + Î½2 (ï¿½B)2 &minus; Î½ ãCã &ge; 0, (10.20)
</p>
<p>namely, a second-degree polynomial in the real parameter Î½. In turn, the coefficients
of the polynomial are real because they derive from Hermitean operators. For the
polynomial to be non negative for all Î½, the discriminant ãCã2&minus;4 (ï¿½A)2 (ï¿½B)2 must
be non positive. The relation between the standard deviations then reads
</p>
<p>ï¿½Aï¿½B &ge; 1
2
|ãCã|. (10.21)
</p>
<p>The interpretation of this result follows from the discussion carried out at the end of
Sect. 10.5. If A and B commute, then their commutator is the null operator, whose
eigenvalue is zero. As a consequence it is ï¿½Aï¿½B &ge; 0, namely, the minimum of the
product is zero. Remembering the result of Sect. 10.4, when two operators commute
they have a common, complete set of eigenfunctions. If the wave function used for
calculating the variance (10.17) is an eigenfunction of A and B, then both standard
deviationsï¿½A andï¿½B vanish andï¿½Aï¿½B = 0, namely, the minimum can in fact be
attained. If, instead, A and B do not commute, the minimum of the product ï¿½Aï¿½B
must be calculated on a case-by-case basis. The most interesting outcome is found
when the two operators are associated to conjugate dynamical variables: A = qi and
B = &minus;i hÌ &part;/&part;qi . Remembering (8.72) one finds C = hÌ I, C = hÌ, ãCã = hÌ, whence
</p>
<p>ï¿½Aï¿½B &ge; hÌ
2
. (10.22)
</p>
<p>Inequality (10.22) is also called Heisenberg principle or uncertainty principle, be-
cause it was originally deduced by Heisenberg from heuristic arguments [48].5 The
more formal deduction leading to (10.21) was given shortly after in [61] and [116].
</p>
<p>10.7 Time Derivative of the Expectation Value
</p>
<p>The expectation value (10.11) of a Hermitean operator is a real function of time. In
Classical Mechanics, the generalized coordinates and momenta are also functions of
time, whose evolution is given by the Hamilton equations (1.42); the latter express the
time derivatives of coordinates and momenta in terms of the Hamiltonian function.
Then, for an arbitrary function Ï of the canonical coordinates, the total derivative
with respect of time is expressed through the Poisson bracket as in (1.53). A relation
</p>
<p>5 Namely, (10.22) is a theorem rather than a principle. A similar comment applies to the Pauli
principle (Sect. 15.6). The English translation of [48] is in [117].</p>
<p/>
</div>
<div class="page"><p/>
<p>10.8 Ehrenfest Theorem 195
</p>
<p>of the same form as (1.53) is found in Quantum Mechanics by calculating the time
derivative of the expectation value (10.13). It is assumed that operator A depends on
time, but does not operate on it; as a consequence, the symbol &part;A/&part;t indicates the
operator resulting from differentiating A with respect to its functional dependence
on t . With these premises one finds
</p>
<p>d
</p>
<p>dt
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast; AÏ dï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>(
&part;Ï&lowast;
</p>
<p>&part;t
AÏ + Ï&lowast; &part;A
</p>
<p>&part;t
Ï + Ï&lowast; A&part;Ï
</p>
<p>&part;t
</p>
<p>)
</p>
<p>dï¿½. (10.23)
</p>
<p>The time derivative of Ï is obtained from the time-dependent Schr&ouml;dinger equa-
tion (9.9). Considering the case where H is real yields &part;Ï/&part;t = &minus;i HÏ/hÌ and
&part;Ï&lowast;/&part;t = i HÏ&lowast;/hÌ, whence
</p>
<p>d
</p>
<p>dt
ãAã =
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast;
&part;A
</p>
<p>&part;t
Ï dï¿½+ i
</p>
<p>hÌ
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast; (HA &minus; AH) Ï dï¿½, (10.24)
</p>
<p>which has the same structure as (1.53). Other relations similar to those of Sect. 1.8
are also deduced from (10.24). For instance, letting A = H yields
</p>
<p>d
</p>
<p>dt
ãH ã =
</p>
<p>&lang;
&part;H
</p>
<p>&part;t
</p>
<p>&rang;
</p>
<p>, (10.25)
</p>
<p>similar to (1.44). If ãAã is a constant of motion, then
&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast;
&part;A
</p>
<p>&part;t
Ï dï¿½+ i
</p>
<p>hÌ
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast; (HA &minus; AH) Ï dï¿½ = 0, (10.26)
</p>
<p>similar to (1.54) while, if A does not depend on time, (10.24) yields
</p>
<p>d
</p>
<p>dt
ãAã = i
</p>
<p>hÌ
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast; (HA &minus; AH) Ï dï¿½, (10.27)
</p>
<p>similar to (1.55). Finally, if A does not depend on time and commutes with H, (10.24)
yields dãAã/dt = 0, namely, the expectation value ãAã is a constant of motion.
</p>
<p>10.8 Ehrenfest Theorem
</p>
<p>An important application of (10.27) is found by replacing A with either a position
operator or a momentum operator. The calculation is shown here with reference to
the Hamiltonian operator H = &minus;hÌ2/(2m)&nabla;2 + V , where the potential energy V is
independent of time. Letting first A = x yields
</p>
<p>(H x &minus; x H) Ï = hÌ
2
</p>
<p>2m
</p>
<p>(
</p>
<p>x
&part;2Ï
</p>
<p>&part;x2
&minus; &part;
</p>
<p>2x Ï
</p>
<p>&part;x2
</p>
<p>)
</p>
<p>= hÌ
2
</p>
<p>2m
</p>
<p>(
</p>
<p>&minus;2&part;Ï
&part;x
</p>
<p>)
</p>
<p>(10.28)
</p>
<p>whence, using pÌx = &minus;i hÌ &part;/&part;x, it follows
d
</p>
<p>dt
ãxã = i
</p>
<p>hÌ
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast;
hÌ2
</p>
<p>2m
</p>
<p>(
</p>
<p>&minus;2&part;Ï
&part;x
</p>
<p>)
</p>
<p>dï¿½ = 1
m
</p>
<p>ãÏ |pÌx |Ïã =
ãpxã
m
</p>
<p>. (10.29)</p>
<p/>
</div>
<div class="page"><p/>
<p>196 10 General Methods of Quantum Mechanics
</p>
<p>In conclusion, the relation dãxã/dt = ãpxã/m holds, similar to the one found in
a classical case when the Hamiltonian function has the form H = p2/(2m) + V
(compare with the second relation in (1.33)). Still with H = &minus;hÌ2/(2m)&nabla;2 + V ,
consider as a second example A = pÌx = &minus;i hÌ &part;/&part;x, to find
</p>
<p>(
</p>
<p>H pÌx &minus; pÌx H
)
</p>
<p>Ï = &minus;i hÌ
(
</p>
<p>V
&part;Ï
</p>
<p>&part;x
&minus; &part;(V Ï)
</p>
<p>&part;x
</p>
<p>)
</p>
<p>= i hÌ Ï &part;V
&part;x
</p>
<p>. (10.30)
</p>
<p>From this, letting Fx = &minus;&part;V/&part;x be the component of the force along x, it follows
</p>
<p>d
</p>
<p>dt
ãpxã =
</p>
<p>i
</p>
<p>hÌ
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast; i hÌ Ï
&part;V
</p>
<p>&part;x
dï¿½ = ãFxã, (10.31)
</p>
<p>also in this case similar to the classical one. Combining (10.29) and (10.31) shows
that the expectation values fulfill a relation similar to Newton&rsquo;s law,
</p>
<p>m
d2
</p>
<p>dt2
ãxã = ãFxã. (10.32)
</p>
<p>This result is called Ehrenfest theorem. If the dependence of Fx on position is weak
in the region where Ï is significant, the normalization of the wave function yields
</p>
<p>d
</p>
<p>dt
ãpxã â Fx
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast; Ï dï¿½ = Fx . (10.33)
</p>
<p>In this case, called Ehrenfest approximation, the expectation value of position fulfills
Newton&rsquo;s law exactly. If, on the contrary, Fx depends strongly on position in the
region where Ï is significant (as happens, e.g., when the potential energy has the
form of a step or a barrier), then the outcome of the quantum calculation is expected
to be different from the classical one (see, e.g., Sects. 11.2 and 11.3).
</p>
<p>10.9 Complements
</p>
<p>10.9.1 Minimum-Uncertainty Wave Function
</p>
<p>It has been shown in Sect. 10.6 that when the two operators are associated to conjugate
dynamical variables, A = q and B = &minus;i hÌ d/dq, the relation between their standard
deviations is given by (10.22). It is interesting to seek a form of the wave function
such that the equality ï¿½Aï¿½B = hÌ/2 holds. If it exists, such a form is called
minimum-uncertainty wave function. To proceed one notes that the equality yields
the value Î½m = (|ãCã|/2)/(ï¿½B)2 corresponding to the minimum of the polynomial
(10.20); moreover, such a minimum is zero. On the other hand, imposing the equality
in (8.16) after letting Î¼ = i Î½m yields the more compact form ||f + i Î½m g||2 = 0,
equivalent to f + i Î½m g = 0. Remembering the definitions given in Sect. 10.6, it is
f = (A &minus; ãAã)Ï , g = (B &minus; ãBã)Ï . Now, letting q0 = ãAã, p0 = hÌ k0 = ãBã,</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 197
</p>
<p>from the relation f + i Î½m g = 0 one obtains the first-order differential equation
Î½m hÌ dÏ/dq = [i Î½m p0 &minus; (q &minus; q0)]Ï , whose solution is
</p>
<p>Ï(q) = Ï0 exp
[
</p>
<p>i k0 q &minus; (q &minus; q0)2/(2 Î½m hÌ)
]
</p>
<p>. (10.34)
</p>
<p>The normalization condition ãÏ |Ïã = 1 yields Ï0 = (Ï Î½m hÌ)&minus;1/4. Using ãCã = hÌ
and combining the expression of Î½m with the equality ï¿½Aï¿½B = hÌ/2 provides
Î½m = 2 (ï¿½A)2/hÌ whence, letting ï¿½q = ï¿½A,
</p>
<p>Ï(q) = 1
4
&radic;
</p>
<p>2Ï
&radic;
ï¿½q
</p>
<p>exp
</p>
<p>[
</p>
<p>i k0 q &minus;
(q &minus; q0)2
(2ï¿½q)2
</p>
<p>]
</p>
<p>. (10.35)
</p>
<p>The minimum-uncertainty wave function turns out to be proportional to a Gaussian
function centered at q0. The factor exp (i k0 q) disappears from |Ï |2, whose peak
value and width are determined byï¿½q. Note that this calculation leaves the individual
values of ï¿½q and ï¿½p = ï¿½B unspecified.
</p>
<p>Problems
</p>
<p>10.1 Starting from the wave packet (9.5) describing a free particle, determine the
time evolution of its position without resorting to the approximation used in
Sect. 9.6.
</p>
<p>10.2 Using the results of Prob. 10.1, determine the time evolution of the standard
deviation of position.
</p>
<p>10.3 Starting from the wave packet (9.5) describing a free particle, determine the
time evolution of its momentum without resorting to the approximation used
in Sect. 9.6.
</p>
<p>10.4 Using the results of Prob. 10.3, determine the time evolution of the standard
deviation of momentum.
</p>
<p>10.5 Consider a one-dimensional wave function that at some instant of time is given
by a minimum-uncertainty packet (10.35) whose polar form is
</p>
<p>Î± = 1
4
&radic;
</p>
<p>2Ï
&radic;
Ï
</p>
<p>exp
</p>
<p>[
</p>
<p>&minus; (x &minus; x0)
2
</p>
<p>4 Ï 2
</p>
<p>]
</p>
<p>, Î² = k0 x. (10.36)
</p>
<p>The wave packet is normalized to 1. Using the concepts introduced in Sect. 9.7.3, find
the &ldquo;convective&rdquo; and &ldquo;thermal&rdquo; parts of the expectation value of the kinetic energy.</p>
<p/>
</div>
<div class="page"><p/>
<p>Part III
</p>
<p>Applications of the Schr&ouml;dinger Equation</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 11
</p>
<p>Elementary Cases
</p>
<p>11.1 Introduction
</p>
<p>The time-independent Schr&ouml;dinger equation is a linear, second-order equation with
a coefficient that depends on position. An analytical solution can be found in a
limited number of cases, typically, one-dimensional ones. This chapter illustrates
some of these cases, starting from the step-like potential energy followed by the
potential-energy barrier. In both of them, the coefficient of the Schr&ouml;dinger equation
is approximated with a piecewise-constant function. Despite their simplicity, the step
and barrier potential profiles show that the quantum-mechanical treatment may lead
to results that differ substantially from the classical ones: a finite probability of trans-
mission may be found where the classical treatment would lead to a reflection only,
or vice versa. The transmission and reflection coefficients are defined by considering
a plane wave launched towards the step or barrier. It is shown that the definition of
the two coefficients can be given also for a barrier of a general form, basing on the
formal properties of the second-order linear equations in one dimension. Finally, the
case of a finite well is tackled, showing that in the limit of an infinite depth of the
well one recovers the results of the particle in a box illustrated in a preceding chapter.
</p>
<p>11.2 Step-Like Potential Energy
</p>
<p>Consider a one-dimensional, step-like potential energy as shown in Fig. 11.1, with
V = 0 for x &lt; 0 and V = V0 &gt; 0 for x &gt; 0. From the general properties of the
time-independent Schr&ouml;dinger equation (Sect. 8.2.3) it follows E &ge; 0. To proceed,
it is convenient to consider the two cases 0 &lt; E &lt; V0 and E &gt; V0 separately.
</p>
<p>&copy; Springer Science+Business Media New York 2015 201
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_11</p>
<p/>
</div>
<div class="page"><p/>
<p>202 11 Elementary Cases
</p>
<p>Fig. 11.1 The example of the
step-like potential energy
analyzed in Sect. 11.2. Only
the case 0 &le; E &le; V0 is shown
</p>
<p>V
0
</p>
<p>x
</p>
<p>E
</p>
<p>V
</p>
<p>11.2.1 Case A: 0 &lt; E &lt; V0
</p>
<p>The Schr&ouml;dinger equation is split over the two partial domains to yield
â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>x &lt; 0 : &minus;w&prime;&prime; = k2w, k =
&radic;
</p>
<p>2mE/hÌ
</p>
<p>x &gt; 0 : w&prime;&prime; = Î±2w, Î± = &radic;2m(V0 &minus; E)/hÌ
(11.1)
</p>
<p>where the derivatives are indicated with primes. The solutions on the left and right
of the origin are respectively given by
</p>
<p>w =
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>w&minus; = a1 exp(ikx) + a2 exp(&minus; ikx), x &lt; 0
w+ = a3 exp(&minus; Î±x) + a4 exp(Î±x), x &gt; 0
</p>
<p>(11.2)
</p>
<p>where it must be set a4 = 0 to prevent w+ from diverging. Using the continuity of w
and w&prime; in the origin yields
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>w+(0) = w&minus;(0), a1 + a2 = a3
w&prime;+(0) = w&prime;&minus;(0), ik(a2 &minus; a1) = Î±a3
</p>
<p>(11.3)
</p>
<p>Eliminating a3 provides the relation Î±(a1 + a2) = ik(a2 &minus; a1) whence
a2
</p>
<p>a1
= ik + Î±
</p>
<p>ik &minus; Î± =
k &minus; iÎ±
k + iÎ± ,
</p>
<p>a3
</p>
<p>a1
= 1 + a2
</p>
<p>a1
= 2k
</p>
<p>k + iÎ± , (11.4)
</p>
<p>that determine a2, a3 apart from the arbitrary constant a1. This should be expected as
w is not normalizable. From |a2/a1| = |k&minus; iÎ±|/|k+ iÎ±| = 1 one finds a2/a1 = exp
(&minus; iÏ), with Ï = 2 arctan (Î±/k). The solution of the time-independent Schr&ouml;dinger
equation is then recast as
</p>
<p>w =
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>w&minus; = 2a1 exp(&minus; iÏ/2) cos (kx + Ï/2), x &lt; 0
w+ = [2k/(k + iÎ±)]a1 exp(&minus; Î±x), x &gt; 0
</p>
<p>(11.5)</p>
<p/>
</div>
<div class="page"><p/>
<p>11.2 Step-Like Potential Energy 203
</p>
<p>The eigenvalues E are continuous in the range 0 &le; E &lt; V0. The monochromatic
wave function corresponding to wk is Ïk(x, t) = w(x) exp(&minus; iEkt/hÌ), with Ek =
hÌ2k2/(2m).
</p>
<p>The quantity R = |a2/a1|2 is called reflection coefficient of the monochromatic
wave. As shown in Sect. 11.4 from a more general point of view, R is the probability
that the wave is reflected by the step. In the case investigated here, where a particle
with 0 &lt; E &lt; V0 is launched towards a step, it is a2/a1 = exp(&minus; iÏ) whence R = 1.
</p>
<p>The solution (11.3) or (11.5) shows that w becomes vanishingly small on the right
of the origin as x &rarr; +&infin;. When a wave packet is built up using a superposition of
monochromatic solutions, chosen in such a way that each energy Ek is smaller than
V0, its behavior is similar; as a consequence, the probability of finding the particle
on the right of the origin becomes smaller and smaller as the distance from the origin
increases. In conclusion, if a particle described by such a packet is launched from
x &lt; 0 towards the step, the only possible outcome is the same as in a calculation based
on Classical Mechanics, namely, a reflection. A difference between the classical and
quantum treatment exists though: in the former the reflection occurs at x = 0,
whereas in the latter the reflection abscissa is not defined. This is better understood
by considering a wave packet of standard deviation ï¿½x approaching the origin from
x &lt; 0. Considering the approximate form of the packet described in Sect. 9.6, the
incident envelope has the form Ai = A(x &minus; ut), and the localization of the incident
particle is described by |Ïi |2 = |Ai |2. Due to its finite width, the packet crosses the
origin during a time ï¿½t &sim; ï¿½x/u starting, e.g., at t = 0. At a later instant ï¿½t + t0,
where t0 &ge; 0 is the time that the wave packet takes to move away from the step to the
extent that the interaction with it is practically completed, only the reflected packet
exists, described by |Ïr |2 = |Ar |2, with Ar = A[x+ u(t &minus; t0)]. For 0 &le; t &le; ï¿½t + t0
both incident and reflected packets exist. One could think that the reflection abscissa
is given by the product ut0; however, t0 depends on the form of the packet, so the
reflection abscissa is not well defined. Before the particle starts interacting with
the step, only the incident packet exists and the normalization
</p>
<p>&int; 0
&minus;&infin; |Ïi |2dx = 1
</p>
<p>holds; similarly, after the interaction is completed, only the reflected packet exists
and
</p>
<p>&int; 0
&minus;&infin; |Ïr |2dx = 1. For 0 &le; t &le; ï¿½t + t0 the normalization is achieved by a
</p>
<p>superposition of the incident and reflected packets.
</p>
<p>11.2.2 Case B: E &gt; V0
</p>
<p>Still considering the one-dimensional step of Fig. 11.1, let E &gt; V0. In this case the
time-independent Schr&ouml;dinger equation reads
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>x &lt; 0 : &minus;w&prime;&prime; = k2w, k =
&radic;
</p>
<p>2mE/hÌ
</p>
<p>x &gt; 0 : &minus;w&prime;&prime; = k21w, k1 =
&radic;
</p>
<p>2m(E &minus; V0)/hÌ
(11.6)</p>
<p/>
</div>
<div class="page"><p/>
<p>204 11 Elementary Cases
</p>
<p>whose solution is
</p>
<p>w =
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>w&minus; = a1 exp(ikx) + a2 exp(&minus; ikx), x &lt; 0
w+ = a3 exp(ik1x) + a4 exp(&minus; ik1x), x &gt; 0
</p>
<p>(11.7)
</p>
<p>Remembering the discussion of Sect. 9.6, function w&minus; in (11.7) describes a super-
position of two planar and monochromatic waves, belonging to the x &lt; 0 region,
that propagate in the forward and backward direction, respectively; a similar mean-
ing holds for w+ with reference to the x &gt; 0 region. Now one assumes that an
extra information is available, namely, that the particle was originally launched from
x &lt; 0 towards the origin; it follows that one must set a4 = 0, because a wave that
propagates in the backward direction can not exist in the region x &gt; 0. By the same
token one should set a1 = 0 if the particle were launched from x &gt; 0 towards the
origin. From the continuity of w and w&prime; in the origin it follows
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>w+(0) = w&minus;(0), a1 + a2 = a3
w&prime;+(0) = w&prime;&minus;(0), k(a1 &minus; a2) = k1a3
</p>
<p>(11.8)
</p>
<p>Eliminating a3 yields k1(a1 + a2) = k(a1 &minus; a2) whence
</p>
<p>a2
</p>
<p>a1
= k &minus; k1
</p>
<p>k + k1
,
</p>
<p>a3
</p>
<p>a1
= 1 + a2
</p>
<p>a1
= 2k
</p>
<p>k + k1
, (11.9)
</p>
<p>that determine a2, a3 apart from the arbitrary constant a1. The eigenvalues are contin-
uous in the range E &gt; V0. The monochromatic, time-dependent wavefunction reads
</p>
<p>Ï =
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>Ï&minus; = w&minus; exp(&minus; iE&minus;t/hÌ), x &lt; 0
Ï+ = w+ exp(&minus; iE+t/hÌ), x &gt; 0
</p>
<p>(11.10)
</p>
<p>where E&minus; = E(k) = hÌ2k2/(2m) and E+ = E(k1) = hÌ2k21/(2m) + V0. Note that
k &gt; k1 &gt; 0, namely, the modulus of the particle&rsquo;s momentum in the x &gt; 0 region
is smaller than in the x &lt; 0 region; this is similar to what happens in the classical
treatment. On the other hand, from k &gt; k1 it follows a2 ï¿½= 0, showing that a
monochromatic plane wave propagating in the backward direction exists in the
x &lt; 0 region. In other term, a finite probability of reflexion is present, which whould
be impossible in the classical treatment. As before, the reflection coefficient of the
monochromatic wave is defined as R = |a2/a1|2 &lt; 1. In turn, the transmission
coefficient is defined as T = 1 &minus; R whence, from (11.9),
</p>
<p>R =
â£
â£
â£
â£
</p>
<p>a2
</p>
<p>a1
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>= (k &minus; k1)
2
</p>
<p>(k + k1)2
, T = 4kk1
</p>
<p>(k + k1)2
= k1
</p>
<p>k
</p>
<p>â£
â£
â£
â£
</p>
<p>a3
</p>
<p>a1
</p>
<p>â£
â£
â£
â£
. (11.11)
</p>
<p>Like in the 0 &lt; E &lt; V0 case one may build up a wave packet of standard deviation
ï¿½x. Still considering a packet approaching the origin from x &lt; 0, the envelope</p>
<p/>
</div>
<div class="page"><p/>
<p>11.2 Step-Like Potential Energy 205
</p>
<p>has the form Ai = A(x &minus; ut). Before the particle starts interacting with the step,
its localization is given by |Ïi |2 = |Ai |2. The packet crosses the origin in a time
ï¿½t &sim; ï¿½x/u and, using the symbols k0, k10 to indicate the center of the packet in
the momentum space for x &lt; 0 and x &gt; 0, respectively, from the first of (11.11)
the reflected packet is described by
</p>
<p>|Ïr |2 =
(k0 &minus; k10)2
(k0 + k10)2
</p>
<p>|A(x + ut)|2. (11.12)
</p>
<p>It has the same group velocity, hence the same width, as |Ïi |2. The transmitted
packet has the form
</p>
<p>|Ït |2 =
(2k0)2
</p>
<p>(k0 + k10)2
|A(k0x/k10 &minus; ut)|2, (11.13)
</p>
<p>and its group velocity is u1 = dx/dt = k10u/k0 &lt; u. As all packets cross the origin in
the same time interval ï¿½t it follows ï¿½x/u = ï¿½x1/u1 whence ï¿½x1 = (k10/k0)ï¿½x &lt;
ï¿½x. This result shows that the transmitted packet is slower and narrower than the
incident packet (if the incident packet were launched from x &gt; 0 towards the origin,
the transmitted packet would be faster and wider). From
</p>
<p>&int; 0
&minus;&infin; |Ïi |2dx = 1 it follows
</p>
<p>Pr =
&int; 0
</p>
<p>&minus;&infin;
|Ïr |2dx =
</p>
<p>(k0 &minus; k10)2
(k0 + k10)2
</p>
<p>, (11.14)
</p>
<p>Pt =
k10
</p>
<p>k0
</p>
<p>&int; &infin;
</p>
<p>0
|Ït |2d
</p>
<p>k0x
</p>
<p>k10
= k10
</p>
<p>k0
</p>
<p>(2k0)2
</p>
<p>(k0 + k10)2
= 4k0 k10
</p>
<p>(k0 + k10)2
. (11.15)
</p>
<p>The two numbers Pr , Pt fulfill the relations 0 &lt; Pr ,Pt &lt; 1, Pr + Pt = 1, and
are the reflection and transmission probabilities of the wave packet. The treatment
outlined above for the case E &gt; V0 still holds when V0 &lt; 0, E &gt; 0. In particular,
if V0 &lt; 0 and |V0| â« E, like in Fig. 11.2, from (11.16) it turns out Pr â 1. This
result is quite different from that obtained from a calculation based on Classical
Mechanics; in fact, its features are similar to those of the propagation of light across
the interface between two media of different refraction index [9, Sects. 1.5,1.6].
The oddity of the result lies, instead, in the fact that term
</p>
<p>&radic;
2m/hÌ cancels out in the
</p>
<p>expressions of Pr and Pt , so that one finds
</p>
<p>Pr =
(
&radic;
E0 &minus;
</p>
<p>&radic;
E0 &minus; V0)2
</p>
<p>(
&radic;
E0 +
</p>
<p>&radic;
E0 &minus; V0)2
</p>
<p>, Pt =
&radic;
E0(E0 &minus; V0)
</p>
<p>(
&radic;
E0 +
</p>
<p>&radic;
E0 &minus; V0)2
</p>
<p>, (11.16)
</p>
<p>with E0 the total energy corresponding to k0 and k10. Thus, the classical result
Pr = 0, Pt = 1 cannot be recovered by making, e.g., m to increase: the discontinuity
in the potential energy makes it impossible to apply the Ehrenfest approximation
(10.33) no matter what the value of the mass is. The same happens for the
monochromatic wave: in fact, using (11.6) and replacing E0 with E in (11.16)
makes the latter equal to (11.11). To recover the classical result it is necessary to
consider a potential energy whose asymptotic values 0 and V0 are connected by a
smooth function, and solve the corresponding Schr&ouml;dinger equation. The classical
case is then recovered by letting m increase (Prob. 11.1).</p>
<p/>
</div>
<div class="page"><p/>
<p>206 11 Elementary Cases
</p>
<p>Fig. 11.2 Another example of
the step-like potential energy
analyzed in Sect. 11.2, with
V0 &lt; 0 and |V0| â« E
</p>
<p>V
0
</p>
<p>V
E
</p>
<p>x
</p>
<p>11.3 Energy Barrier
</p>
<p>Consider a one-dimensional energy barrier as shown in Fig. 11.3, with V = V0 &gt; 0
for 0 &lt; x &lt; s and V = 0 elsewhere. From the general properties of the time-
independent Schr&ouml;dinger equation (Sect. 8.2.3) it follows E &ge; 0. To proceed, it is
convenient to consider the two cases 0 &lt; E &lt; V0 and E &gt; V0 separately.
</p>
<p>11.3.1 Case A: 0 &lt; E &lt; V0
</p>
<p>The Schr&ouml;dinger equation is split over the three domains to yield
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>x &lt; 0 : &minus;w&prime;&prime; = k2w, k =
&radic;
</p>
<p>2mE/hÌ
</p>
<p>0 &lt; x &lt; s : w&prime;&prime; = Î±2w, Î± = &radic;2m(V0 &minus; E)/hÌ
s &lt; x : &minus;w&prime;&prime; = k2w, k =
</p>
<p>&radic;
2mE/hÌ
</p>
<p>(11.17)
</p>
<p>where the derivatives are indicated with primes. The solutions of (11.17) are,
respectively,
</p>
<p>w =
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>w&minus; = a1 exp(ikx) + a2 exp(&minus; ikx), x &lt; 0
wB = a3 exp(Î±x) + a4 exp(&minus; Î±x), 0 &lt; x &lt; s
w+ = a5 exp(ikx) + a6 exp(&minus; ikx), s &lt; x
</p>
<p>(11.18)
</p>
<p>Using the continuity of w and w&prime; in the origin,
â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>w&minus;(0) = wB(0), a1 + a2 = a3 + a4
w&prime;&minus;(0) = w&prime;B(0), ik(a1 &minus; a2) = Î±(a3 &minus; a4)
</p>
<p>(11.19)</p>
<p/>
</div>
<div class="page"><p/>
<p>11.3 Energy Barrier 207
</p>
<p>Fig. 11.3 The example of the
one-dimensional energy
barrier analyzed in Sect. 11.3.
Only the case 0 &le; E &le; V0 is
shown V0
</p>
<p>x
</p>
<p>E
</p>
<p>V
</p>
<p>s
</p>
<p>Solving for a1, a2 and letting Ï = 1 + i Î±/k yields 2 a1 = Ï a4 + Ï&lowast; a3, 2 a2 =
Ï a3 + Ï&lowast; a4. Using the same reasoning as in Sect. 11.2.2, one now assumes that an
extra information is available, namely, that the particle was originally launched from
x &lt; 0 towards the barrier; it follows that one must set a6 = 0 in (11.18), because
a wave that propagates in the backward direction can not exist in the region x &gt; s.
By the same token one should set a1 = 0 if the particle were launched from x &gt; s
towards the barrier. Taking the first case (a6 = 0) and using the continuity of w and
w&prime; at x = s provides
â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>wB(s) = w+(s), a3 exp(Î±s) + a4 exp(&minus; Î±s) = a5 exp(iks)
w&prime;B(s) = w&prime;+(s), Î±[a3 exp(Î±s) &minus; a4 exp(&minus; Î±s)] = ika5 exp(iks)
</p>
<p>(11.20)
</p>
<p>whence 2a3 = a5Ï exp(iks&minus;Î±s), 2a4 = a5Ï &lowast; exp(iks+Î±s), with Ï = 1+ ik/Î±. In
summary, a1, a2 are linear combinations of a3, a4; the latter, in turn, are proportional
to a5. It follows that, if it were a5 = 0, then it would also be a3 = a4 = 0 and
a1 = a2 = 0. However, this is impossible because w&minus; can not vanish identically; as
a consequence it is necessarily a5 ï¿½= 0. This shows that w+ = a5 exp(ikx) differs
from zero, namely, that a wave propagating in the forward direction exists for x &gt; s.
</p>
<p>As the relations involving the coefficients ai are homogeneous, they determine
a2, a3, a4, a5 apart from the arbitrary constant a1. This should be expected as w
is not normalizable. As shown below, the determination of the ratios between the
coefficient does not impose any constraint on the total energy; as a consequence, the
eigenvalues 0 &le; E &lt; V0 are continuous. The ratio a5/a1 is found from
</p>
<p>4
a1
</p>
<p>a5
= 2 a3
</p>
<p>a5
Ï&lowast; + 2 a4
</p>
<p>a5
Ï = Ï exp(iks &minus; Î±s)Ï&lowast; + Ï &lowast; exp(iks + Î±s)Ï. (11.21)
</p>
<p>Letting Î¼ = Ï Ï &lowast; = 2 + i(Î±/k &minus; k/Î±) one finds 4a1/a5 exp(&minus; iks) = Î¼ exp(Î±s) +
Î¼&lowast; exp(&minus; Î±s), whence a1/a5 exp(&minus; iks) = cosh (Î±s) + i(Î±/k &minus; k/Î±) sinh (Î±s)/2.
Using the identity cosh2 Î¶&minus;sinh2 Î¶ = 1 finally yields for the transmission coefficient</p>
<p/>
</div>
<div class="page"><p/>
<p>208 11 Elementary Cases
</p>
<p>of the monochromatic wave
</p>
<p>1
</p>
<p>T
=
</p>
<p>â£
â£
â£
â£
</p>
<p>a1
</p>
<p>a5
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>= 1 + 1
4
</p>
<p>(
Î±
</p>
<p>k
+ k
</p>
<p>Î±
</p>
<p>)2
</p>
<p>sinh2(Î±s). (11.22)
</p>
<p>A similar calculation provides the ratio a2/a1; it is found
</p>
<p>R =
â£
â£
â£
â£
</p>
<p>a2
</p>
<p>a1
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>= (Î±/k + k/Î±)
2 sinh2(Î±s)/4
</p>
<p>1 + (Î±/k + k/Î±)2 sinh2(Î±s)/4
= 1 &minus;
</p>
<p>â£
â£
â£
â£
</p>
<p>a5
</p>
<p>a1
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>= 1 &minus; T . (11.23)
</p>
<p>In the classical treatment, if a particle with 0 &lt; E &lt; V0 is launched from the left
towards the barrier, it is reflected at x = 0; similarly, it is reflected at x = s if it
is launched from the right. In the quantum treatment it is T &gt; 0: in contrast to the
classical case, the particle can cross the barrier. For a given width s of the barrier
and total energy E of the particle, the transmission coefficient T decreases when
V0 increases; for E and V0 fixed, T becomes proportional to exp(&minus; 2Î±s) when s
increases to the extent that Î±s â« 1. Finally, T &rarr; 1 as s &rarr; 0; this was expected
because the potential energy becomes equal to zero everywhere.1
</p>
<p>The interaction of the particle with the barrier is better understood by considering
a wave packet approaching the origin from x &lt; 0. The incident envelope has the form
Ai = A(x&minus;ut). Before reaching the origin the particle&rsquo;s localization is described by
|Ïi |2 = |Ai |2. After the interaction with the barrier is completed, both the reflected
and transmitted packet exist, that move in opposite directions with the same velocity.
Letting Pr =
</p>
<p>&int; 0
&minus;&infin; |Ïr |2dx, Pt =
</p>
<p>&int;&infin;
s
</p>
<p>|Ït |2dx, and observing that
&int; 0
&minus;&infin; |Ïi |2dx = 1,
</p>
<p>it follows that the two numbersPr ,Pt fulfill the relations 0 &lt; Pr ,Pt &lt; 1,Pr+Pt = 1,
and are the reflection and transmission probabilities of the wave packet. In summary,
the solution of the Schr&ouml;dinger equation for the energy barrier shows that a particle
with 0 &lt; E &lt; V0 has a finite probability of crossing the barrier, which would be
impossible in the classical treatment. The same result holds when the form of the
barrier is more complicated than the rectangular one (Sect. 11.4). The phenomenon
is also called tunnel effect.
</p>
<p>11.3.2 Case B: 0 &lt; V0 &lt; E
</p>
<p>Still considering the one-dimensional barrier of Fig. 11.3, let 0 &lt; V0 &lt; E. The
Schr&ouml;dinger equation over the three domains reads
</p>
<p>1 If the potential energy were different on the two sides of the barrier, namely, V = V0 &gt; 0 for
0 &lt; x &lt; s, V = VL for x &lt; 0, and V = VR ï¿½= VL for x &gt; s, with V0 &gt; VL,VR , the limit s &rarr; 0
would yield the case discussed in Sect. 11.2 (compare also with Sects. 11.4 and 17.8.4).</p>
<p/>
</div>
<div class="page"><p/>
<p>11.3 Energy Barrier 209
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>x &lt; 0 : &minus;w&prime;&prime; = k2w, k =
&radic;
</p>
<p>2mE/hÌ
</p>
<p>0 &lt; x &lt; s : &minus;w&prime;&prime; = k21 w, k1 =
&radic;
</p>
<p>2m (E &minus; V0)/hÌ
s &lt; x : &minus;w&prime;&prime; = k2 w, k =
</p>
<p>&radic;
2mE/hÌ
</p>
<p>(11.24)
</p>
<p>where the derivatives are indicated with primes. The solutions of (11.24) are,
respectively,
</p>
<p>w =
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>w&minus; = a1 exp(ikx) + a2 exp(&minus; ikx), x &lt; 0
wB = a3 exp(ik1x) + a4 exp(&minus; ik1x), 0 &lt; x &lt; s
w+ = a5 exp(ikx) + a6 exp(&minus; ikx), s &lt; x
</p>
<p>(11.25)
</p>
<p>As in Sect. 11.3.1 one assumes that the particle was originally launched from x &lt; 0,
so that a6 = 0. The calculation follows the same line as in Sect. 11.3.1, and yields
that w&minus; and w+ are the same as in (11.18), whereas wB is found by replacing Î± with
ik1 there. The determination of the ratios between the coefficient ai does not impose
any constraint on the total energy; as a consequence, the eigenvalues E &gt; V0 are
continuous. Using cosh (iÎ¶ ) = cos (Î¶ ), sinh (iÎ¶ ) = i sin (Î¶ ) then yields
</p>
<p>1
</p>
<p>T
=
</p>
<p>â£
â£
â£
â£
</p>
<p>a1
</p>
<p>a5
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>= 1 + 1
4
</p>
<p>(
k
</p>
<p>k1
&minus; k1
</p>
<p>k
</p>
<p>)2
</p>
<p>sin2 (k1s) (11.26)
</p>
<p>where, from (11.24), k1/k =
&radic;
</p>
<p>1 &minus; V0/E. Similarly,
</p>
<p>R =
â£
â£
â£
â£
</p>
<p>a2
</p>
<p>a1
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>= (k/k1 &minus; k1/k)
2 sin2(k1s)/4
</p>
<p>1 + (k/k1 &minus; k/k1)2 sin2(k1s)/4
= 1 &minus;
</p>
<p>â£
â£
â£
â£
</p>
<p>a5
</p>
<p>a1
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>. (11.27)
</p>
<p>In the classical treatment, if a particle with 0 &lt; V0 &lt; E is launched towards the
barrier, it is always transmitted. In the quantum treatment it may be R &gt; 0: in
contrast to the classical case, the particle can be reflected.2 The barrier is transparent
(R = 0) for k1s = iÏ , with i any integer. Letting Î»1 = 2Ï/k1 yields s = iÎ»1/2,
which is equivalent to the optical-resonance condition in a sequence of media of
refractive indices n1, n2, n1 [9, Sect. 1.6].
</p>
<p>2 The reflection at the barrier for k1s ï¿½= iÏ explains why the experimental value of the Richardson
constant A is lower than the theoretical one. Such a constant appears in the expression Js =
AT 2 exp[&minus;EW /(kBT )] of the vacuum-tube characteristics [21]. This is one of the cases where
the tunnel effect is evidenced in macroscopic-scale experiments. Still considering the vacuum
tubes, another experimental evidence of the tunnel effect is the lack of saturation of the forward
current-voltage characteristic at increasing bias.</p>
<p/>
</div>
<div class="page"><p/>
<p>210 11 Elementary Cases
</p>
<p>11.4 Energy Barrier of a General Form
</p>
<p>The interaction of a particle with an energy barrier has been discussed in Sect. 11.3
with reference to the simple case of Fig. 11.3. Here it is extended to the case of a
barrier of a general form&mdash;still considering the one-dimensional, time-independent
Schr&ouml;dinger equation for a particle of mass m, to the purpose of calculating the
transmission coefficient T . The equation reads
</p>
<p>d2w
</p>
<p>dx2
+ qw = 0, q(x) = 2m
</p>
<p>hÌ2
(E &minus; V ) , (11.28)
</p>
<p>where the potential energy V (x) is defined as follows:
</p>
<p>V = VL = const., x &lt; 0; V = VR = const., 0 &lt; s &lt; x. (11.29)
</p>
<p>In the interval 0 &le; x &le; s the potential energy is left unspecified, with the only
provision that its form is such that (11.28) is solvable. It will also be assumed that
E &gt; VL,VR; as a consequence, the total energy is not quantized and all values of E
larger than VL and VR are allowed. For a given E the time-dependent wave function
takes the form Ï(x, t) = w(x) exp(&minus; iEt/hÌ), where
</p>
<p>w(x) = a1 exp(ikLx) + a2 exp(&minus; ikLx), x &lt; 0, (11.30)
w(x) = a5 exp(ikRx) + a6 exp(&minus; ikRx), s &lt; x. (11.31)
</p>
<p>The real parameters kL, kR &gt; 0 are given by kL =
&radic;
</p>
<p>2m (E &minus; VL)/hÌ and, respec-
tively, kR =
</p>
<p>&radic;
2m (E &minus; VR)/hÌ. Like in the examples of Sect. 11.3 it is assumed
</p>
<p>that the particle is launched from &minus;&infin;, so that the plane wave corresponding to the
term multiplied by a6 in (11.31) does not exist. As a consequence one lets a6 = 0,
whereas a1, a2, a5 are left undetermined. In the interval 0 &le; x &le; s the general
solution of (11.28) is
</p>
<p>w(x) = a3 u(x) + a4 v(x), 0 &le; x &le; s, (11.32)
</p>
<p>where u, v are two linearly-independent solutions. The continuity equation for the
wave function, (9.13), becomes in this case dJÏ/dx = 0, namely, JÏ = const. In
turn, the density of the probability flux reads
</p>
<p>JÏ =
ihÌ
</p>
<p>2m
</p>
<p>(
</p>
<p>w
dw&lowast;
</p>
<p>dx
&minus; w&lowast; dw
</p>
<p>dx
</p>
<p>)
</p>
<p>. (11.33)
</p>
<p>Applying (11.33) to (11.30) and (11.31) yields, respectively,
</p>
<p>JÏ =
hÌkL
</p>
<p>m
</p>
<p>(
</p>
<p>|a1|2 &minus; |a2|2
)
</p>
<p>, x &lt; 0; JÏ =
hÌkR
</p>
<p>m
|a5|2, s &lt; x. (11.34)
</p>
<p>As JÏ is constant, one may equate the two expressions in (11.34) to obtain
</p>
<p>â£
â£
â£
â£
</p>
<p>a2
</p>
<p>a1
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>+ kR
kL
</p>
<p>â£
â£
â£
â£
</p>
<p>a5
</p>
<p>a1
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>= 1. (11.35)</p>
<p/>
</div>
<div class="page"><p/>
<p>11.4 Energy Barrier of a General Form 211
</p>
<p>The division by |a1|2 leading to (11.35) is allowed because, by hypotesis, the particle
is launched from &minus;&infin;, so that a1 ï¿½= 0. From (11.35) one defines the reflection and
transmission coefficients
</p>
<p>R =
â£
â£
â£
â£
</p>
<p>a2
</p>
<p>a1
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>, T = kR
kL
</p>
<p>â£
â£
â£
â£
</p>
<p>a5
</p>
<p>a1
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>. (11.36)
</p>
<p>Given E, VL, VR , and a1, the transmission and reflection coefficients depend on
the form of the potential energy in the interval 0 &le; x &le; s. By way of example, if
VL = 0 and the potential energy in the interval 0 &le; x &le; s is equal to some constant
VB &ge; 0, then R is expected to vary from 0 to 1 as VB varies from 0 to +&infin;. On
the other hand, R and T can not vary independently from each other because of the
relation R + T = 1. As a consequence, it suffices to consider only one coefficient,
say, T . From the discussion above it follows that the coefficient T depends on the
shape of the potential energy that exists within the interval 0 &le; x &le; s, namely, it is a
functional of V : 0 &le; T = T [V ] &le; 1. One may also note that the relation R+T = 1
derives only from the constancy of JÏ due to the one-dimensional, steady-state
condition. In other terms, the relation R+T = 1 does not depend on the form of the
potential energy within the interval 0 &le; x &le; s. It must then reflect some invariance
property intrinsic to the solution of the problem. In fact, the invariance is that of the
density of the probability flux JÏ , which is intrinsic to the form of the Schr&ouml;dinger
equation and leads to the relation (11.35).
</p>
<p>For the sake of generality one provisionally considers a slightly more general
equation than (11.28), built by the linear operator
</p>
<p>L = d
2
</p>
<p>dx2
+ p(x) d
</p>
<p>dx
+ q(x), (11.37)
</p>
<p>where the functions p and q are real. If u is a solution of the differential equation
Lw = 0 in the interval 0 &le; x &le; s, let P (x) be any function such that p = dP/dx,
and define
</p>
<p>v(x) = u(x)
&int; x
</p>
<p>a
</p>
<p>exp[&minus; P (Î¾ )]
u2(Î¾ )
</p>
<p>dÎ¾ , (11.38)
</p>
<p>where a, x belong to the same interval. It is found by inspection that Lv = 0 in the
interval 0 &le; x &le; s, namely, v is also a solution. Moreover, the Wronskian of u and
v (Sect. A.12) reads
</p>
<p>W (x) = uv&prime; &minus; u&prime;v = exp(&minus;P ). (11.39)
</p>
<p>As the Wronskian never vanishes, u and v are linearly independent. This shows that,
for any solution u of the differential equation Lw = 0 in a given interval, (11.38)
provides another solution which is linearly independent from u. As the differential
equation is linear and of the second order, the general solution is then given by a
linear combination of u and v.
</p>
<p>Being the equation Lw = 0 homogeneous, the solution u may be replaced by
Î»u, with Î» ï¿½= 0 a constant. In this case v must be replaced by v/Î» due to (11.38).</p>
<p/>
</div>
<div class="page"><p/>
<p>212 11 Elementary Cases
</p>
<p>It follows that the Wronskian (11.39) is invariant under scaling of the solutions.
Another consequence of the homogeneity of Lw = 0 is that the dimensions of w
may be chosen arbitrarily. The same holds for the dimensions of u. Once the latter
have been chosen, the dimensions of v follow from (11.38); in fact, the product uv
has the dimensions of a length. From (11.32) it then follows that the products a3u
and a4v have the same dimensions.
</p>
<p>The linear independency allows one to choose for u and v the two fundamental
solutions, namely, those having the properties [51, Sect. 5.2]
</p>
<p>u(0) = 1, u&prime;(0) = 0, v(0) = 0, v&prime;(0) = 1, (11.40)
</p>
<p>so that the Wronskian W equals 1 everywhere. Then, letting a6 = 0 in (11.31) and
prescribing the continuity of the solution and its derivative at x = 0 and x = s yields,
from (11.32),
</p>
<p>a3 = a1 + a2, a4 = ikL(a1 &minus; a2), (11.41)
a5 exp(jkRs) = a3us + a4vs , ikRa5 exp(ikRs) = a3u&prime;s + a4v&prime;s , (11.42)
</p>
<p>where suffix s indicates that the functions are calculated at x = s. Eliminating
a5 exp(i kR s) yields (i kR us &minus; u&prime;s) a3 = (v&prime;s &minus; i kR vs) a4 whence, from (11.41),
</p>
<p>a2
</p>
<p>a1
= kLkRvs + u
</p>
<p>&prime;
s + j (kL v&prime;s &minus; kR us)
</p>
<p>kLkRvs &minus; u&prime;s + j (kL v&prime;s + kR us)
= A+ jB
</p>
<p>C + jD . (11.43)
</p>
<p>In conclusion, T = 1&minus;|a2/a1|2 = (C2 &minus;A2 +D2 &minus;B2)/(C2 +D2). Using W = 1
transforms the numerator intoC2&minus;A2+D2&minus;B2 = 4kLkR(usv&prime;s&minus;vsu&prime;s) = 4kLkR . In
turn, the denominator readsC2+D2 = 2kLkR+(kRus)2+(u&prime;s)2+(kLv&prime;s)2+(kLkRvs)2,
whence
</p>
<p>T = 4kLkR
2kLkR + (kRus)2 + (u&prime;s)2 + (kLv&prime;s)2 + (kLkRvs)2
</p>
<p>. (11.44)
</p>
<p>The expression of the transmission coefficient may be recast as T = 1/(1+F ), with
</p>
<p>F = 1
4kLkR
</p>
<p>[
(
</p>
<p>u&prime;s
)2 + (kRus)2
</p>
<p>]
</p>
<p>+ kL
4kR
</p>
<p>[
(
</p>
<p>v&prime;s
)2 + (kRvs)2
</p>
<p>]
</p>
<p>&minus; 1
2
. (11.45)
</p>
<p>It is easily shown that F &gt; 0; in fact, this condition is equivalent to (kRus &minus;kLv&prime;s)2 +
(u&prime;s + kLkRvs)2 &gt; 0. In conclusion, (11.44) is the expression of the transmission
coefficient across a barrier of any form, with no approximation [88]. To calculate T
it is necessary to determine the four quantities us , u&prime;s , vs , and v
</p>
<p>&prime;
s . Actually only three
</p>
<p>of them suffice thanks to the condition usv&prime;s &minus; u&prime;svs = 1.
Repeating the calculation of this section after letting a1 = 0, a6 ï¿½= 0 provides the
</p>
<p>known result that, for a given barrier, the transmission probability for a particle of
energy E is the same whether the particle is launched from the left or from the right.
The property holds also in the relativistic case [79].</p>
<p/>
</div>
<div class="page"><p/>
<p>11.5 Energy Well 213
</p>
<p>Fig. 11.4 The example of the
one-dimensional energy well
analyzed in Sect. 11.5. Only
the case V0 &lt; E &lt; 0 is shown
</p>
<p>V
0
</p>
<p>E
</p>
<p>xs
</p>
<p>V
</p>
<p>11.5 Energy Well
</p>
<p>Taking a one-dimensional case, letV = V0 &lt; 0 for 0 &lt; x &lt; s andV = 0 elsewhere.
From the general properties of the time-independent Schr&ouml;dinger equation it follows
E &gt; V0. The case E &gt; 0 is treated in the same way as that of Sect. 11.3.2 and leads
to similar results. The case V0 &lt; E &lt; 0, shown in Fig. 11.4, is instead different
from those investigated above: the total energy is quantized and the wave function
is square integrable. The Schr&ouml;dinger equation over the three domains reads
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>x &lt; 0 : w&prime;&prime; = Î±2w, Î± =
&radic;
&minus;2mE/hÌ
</p>
<p>0 &lt; x &lt; s : &minus;w&prime;&prime; = k2 w, k = &radic;2m (E &minus; V0)/hÌ
s &lt; x : w&prime;&prime; = Î±2 w, Î± =
</p>
<p>&radic;
&minus;2mE/hÌ
</p>
<p>(11.46)
</p>
<p>where the derivatives are indicated with primes. The solutions of (11.46) are,
respectively,
</p>
<p>w =
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>w&minus; = a1 exp(Î±x) + a5 exp(&minus; Î±x), x &lt; 0
wW = a2 exp(ikx) + a3 exp(&minus; ikx), 0 &lt; x &lt; s
w+ = a4 exp(&minus; Î±x) + a6 exp(Î±x), s &lt; x
</p>
<p>(11.47)
</p>
<p>where it must be set a5 = a6 = 0 to prevent w&minus; and w+ from diverging. Using the
continuity of w and w&prime; in the origin,
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>w&minus;(0) = wW (0), a1 = a2 + a3
w&prime;&minus;(0) = w&prime;W (0), Î±a1 = ik(a2 &minus; a3)
</p>
<p>(11.48)
</p>
<p>Solving for a2, a3 and letting Ï = 1 + iÎ±/k yields 2a2 = Ï&lowast;a1, 2a3 = Ïa1 whence
a2/a3 = Ï&lowast;/Ï . Then, using the continuity of w and w&prime; at x = s yields</p>
<p/>
</div>
<div class="page"><p/>
<p>214 11 Elementary Cases
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>wW (s) = w+(s), a4 exp(&minus; Î±s) = a2 exp(iks) + a3 exp(&minus; iks)
w&prime;W (s) = w&prime;+(s), &minus;Î±a4 exp(&minus; Î±s) = ik[a2 exp(iks) &minus; a3 exp(&minus; iks)]
</p>
<p>Solving for a2, a3 yields 2a2 = a4Ï exp(&minus; Î±s &minus; iks), 2a3 = a4Ï&lowast; exp(&minus; Î±s + iks),
whence a2/a3 = (Ï/Ï&lowast;) exp(&minus; 2iks). In summary, a2, a3 are proportional to a1
and to a4. It follows that, if it were a1 = 0 or a4 = 0, then it would also be
a2 = a3 = 0. However, this is impossible because w can not vanish identically; as
a consequence it is necessarily a1 ï¿½= 0, a4 ï¿½= 0. This shows that, in contrast to the
classical case, the particle penetrates the boundaries of the well. The relations found
so far determine two different expressions for a2/a3. For them to be compatible, the
equality Ï2 exp(&minus; iks) = (Ï&lowast;)2 exp(iks) must hold, which represents the condition
of a vanishing determinant of the 4 &times; 4, homogeneous algebraic system whose
unknowns are a1, a2, a3, and a4. Using Ï = 1 + iÎ±/k, the equality is recast as
</p>
<p>(
</p>
<p>1 &minus; Î±
2
</p>
<p>k2
</p>
<p>)
</p>
<p>sin(ks) = 2Î±
k
</p>
<p>cos(ks),
k2 &minus; Î±2
</p>
<p>2Î±k
= cot(ks). (11.49)
</p>
<p>Finally, replacing the expressions of Î± and k provides the transcendental equation
</p>
<p>E &minus; V0/2&radic;&minus;E(E &minus; V0)
= cot
</p>
<p>(
</p>
<p>s
</p>
<p>&radic;
2m
</p>
<p>hÌ
</p>
<p>&radic;
</p>
<p>E &minus; V0
)
</p>
<p>, V0 &lt; E &lt; 0, (11.50)
</p>
<p>in the unknown E, whose roots fulfill the compatibility condition. As a consequence,
such roots are the eigenvalues of E. Given m, s, and V0, let n &ge; 1 be an integer such
that
</p>
<p>(n&minus; 1)Ï &lt; s
&radic;
</p>
<p>&minus;(2m/hÌ2)V0 &le; nÏ. (11.51)
</p>
<p>Such an integer always exists, and indicates the number of branches of cot (ks)
that belong (partially or completely) to the interval V0 &lt; E &lt; 0. In such an
interval the left hand side of (11.50) increases monotonically from &minus;&infin; to +&infin;;
as a consequence, (11.50) has n roots V0 &lt; E1,E2, . . . ,En &lt; 0. An example with
five roots is shown in Fig. 11.5; the corresponding calculation is carried out in Prob.
11.2. When an eigenvalue, say Ei , is introduced into (11.46), it provides Î±i , ki , and
Ïi = 1 + iÎ±i/ki ; in conclusion,
</p>
<p>ai2 =
1
</p>
<p>2
Ï&lowast;i ai1, ai3 =
</p>
<p>1
</p>
<p>2
Ïiai1, ai4 =
</p>
<p>Ï&lowast;i
Ïi
</p>
<p>exp(Î±is + ikis)ai1. (11.52)
</p>
<p>The ith eigenfunction wi can thus be expressed, from (11.50), in terms of ai1 alone.
The latter, in turn, is found from the normalization condition
</p>
<p>&int; +&infin;
&minus;&infin; |wi |2dx = 1.
</p>
<p>The case of the box treated in Sect. 8.2.2 is obtained by letting V0 &rarr; &minus;&infin; here;
at the same time one lets E &rarr; &minus;&infin; in such a way that the difference E&minus;V0 is kept
finite. In this way, w&minus; and w+ in (11.47) vanish identically and yield the boundary
conditions for wW used in Sect. 8.2.2.</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 215
</p>
<p>Fig. 11.5 Graphic solution of
(11.50) using the auxiliary
variable Î·. The solutions
Î·1, . . . , Î·5 are the intercepts
of the left hand side (thicker
line) with the branches of the
right hand side. The data are
given in Prob. 11.2
</p>
<p>0.0 0.2 0.4 0.6 0.8 1.0
</p>
<p>Î· = (1 - E / V
0
)
1/2
</p>
<p>-40
</p>
<p>-20
</p>
<p>0
</p>
<p>20
</p>
<p>40
</p>
<p>L
ef
</p>
<p>t-
 a
</p>
<p>n
d
</p>
<p> r
ig
</p>
<p>h
t-
</p>
<p>h
an
</p>
<p>d
 s
</p>
<p>id
e
</p>
<p>Fig. 11.6 The smooth
potential energy considered in
Prob. 11.1, with V0 = 2 and
E = 2.5 (arbitrary units).
</p>
<p>-4 -2 0 2 4
x / a
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>1.5
</p>
<p>2
</p>
<p>2.5
</p>
<p>3
</p>
<p>E
 ,
</p>
<p>V
(x
</p>
<p>) 
  
 (
</p>
<p>a.
 u
</p>
<p>.)
</p>
<p>a = 0.8
a = 0.6
a = 0.4
</p>
<p>Problems
</p>
<p>11.1 Consider a smooth potential energy described by
</p>
<p>V (x) = V0
1 + exp(&minus; x/a) , (11.53)
</p>
<p>with V0 &gt; 0, a &gt; 0 (Fig. 11.6). The limit of V (x) for a &rarr; 0 yields the
discontinuous step of Sect. 11.2. Considering a monochromatic wave with
E &gt; V0 launched from the left towards the barrier, the reflection coefficient is
found to be [41, Sect. 2.2].
</p>
<p>R(a) = sinh
2 [Ïa
</p>
<p>&radic;
2m(
</p>
<p>&radic;
E &minus;&radic;E &minus; V0)/hÌ]
</p>
<p>sinh2 [Ïa
&radic;
</p>
<p>2m(
&radic;
E +&radic;E &minus; V0)/hÌ]
</p>
<p>. (11.54)</p>
<p/>
</div>
<div class="page"><p/>
<p>216 11 Elementary Cases
</p>
<p>Discuss the limiting cases a &rarr; 0 and m &rarr; &infin; and compare the results with
those found in Sect. 11.2.
</p>
<p>11.2 Find the eigenvalues of the Schr&ouml;dinger equation for an energy well like that
of Fig. 11.5, having a width s = 15 &Aring; = 1.5 &times; 10&minus;9 m and a depth3 &minus;V0 =
3 eV â 4.81 &times; 10&minus;19 J. Use m â 9.11 &times; 10&minus;31 kg, hÌ â 1.05 &times; 10&minus;34 J s.
</p>
<p>3 The electron Volt (eV) is a unit of energy obtained by multiplying 1 J by a number equal to the
modulus of the electron charge expressed in C (Table D.1).</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 12
</p>
<p>Cases Related to the Linear Harmonic Oscillator
</p>
<p>12.1 Introduction
</p>
<p>The chapter is devoted to the solution of the Schr&ouml;dinger equation for the linear
harmonic oscillator, and to a number of important application of the results. The
importance of the problem has already been outlined in the sections devoted to the
classical treatment: its results can in fact be applied, with little or no modification,
to mechanical situations where the positional force acting on the particle can be
replaced with a first-order expansion, or to more complicate systems whose degrees of
freedom can be separated into a set of Hamiltonian functions of the linear-harmonic-
oscillator type. Such systems are not necessarily mechanical: for instance, the energy
of the electromagnetic field in vacuo is amenable to such a separation, leading to
the formal justification of the concept of photon. Similarly, a system of particles
near a mechanical-equilibrium point can be separated in the same manner, providing
the justification of the concept of phonon. An interesting property of the Fourier
transform of the Schr&ouml;dinger equation for the linear harmonic oscillator is shown in
the complements.
</p>
<p>12.2 Linear Harmonic Oscillator
</p>
<p>An example of paramount importance is that of the linear harmonic oscillator, whose
classical treatment is given in Sect. 3.3. The potential energy is shown in Fig. 12.1.
From the general properties of the time-independent Schr&ouml;dinger equation (Sect.
8.2.3) it follows E &gt; 0. Also, the time-independent wave function w is expected
to be square integrable. The Hamiltonian operator is found by replacing p with
pÌ = &minus;i hÌ d/dx in (3.1), yielding the Schr&ouml;dinger equation
</p>
<p>&minus; hÌ
2
</p>
<p>2m
</p>
<p>d2w
</p>
<p>dx2
+ 1
</p>
<p>2
mÏ2 x2 w = E w, Ï =
</p>
<p>&radic;
</p>
<p>c/m, (12.1)
</p>
<p>&copy; Springer Science+Business Media New York 2015 217
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_12</p>
<p/>
</div>
<div class="page"><p/>
<p>218 12 Cases Related to the Linear Harmonic Oscillator
</p>
<p>Fig. 12.1 The potential
energy of the linear harmonic
oscillator (Sect. 12.2)
</p>
<p>2c x  / 2
</p>
<p>x
</p>
<p>V
</p>
<p>E
</p>
<p>with c the elastic constant. The equation is conveniently recast in normalized form
by defining the dimensionless quantities Îµ = E/(hÌÏ), Î¾ = (mÏ/hÌ)1/2 x:
</p>
<p>H&prime;w = Îµ w, H&prime; = 1
2
</p>
<p>(
</p>
<p>Î¾ 2 &minus; d
2
</p>
<p>dÎ¾ 2
</p>
<p>)
</p>
<p>. (12.2)
</p>
<p>The eigenvalues and eigenfunctions of (12.2) are found by means of the factorization
method illustrated in Sect. 13.3. To begin, one defines the first-order operator
</p>
<p>aÌ = 1&radic;
2
</p>
<p>(
</p>
<p>Î¾ + d
dÎ¾
</p>
<p>)
</p>
<p>, (12.3)
</p>
<p>whence, for all f and g vanishing at infinity, an integration by parts yields
&int; +&infin;
</p>
<p>&minus;&infin;
g&lowast;aÌf dÎ¾ =
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>(
</p>
<p>aÌ&dagger;g
)&lowast;
f dÎ¾ , (12.4)
</p>
<p>with aÌ&dagger; = (Î¾ &minus; d/dÎ¾ )/
&radic;
</p>
<p>2 the adjoint operator of aÌ. As aÌ&dagger; ï¿½= aÌ, aÌ is not Hermitean.
Also, aÌ and aÌ&dagger; do not commute; using the definitions of aÌ and aÌ&dagger; yields
</p>
<p>aÌaÌ&dagger; &minus; aÌ&dagger;aÌ = I, aÌaÌ&dagger; + aÌ&dagger;aÌ = 2H&prime;, (12.5)
</p>
<p>with I the identity operator. From (12.5), after defining the operator N = aÌ&dagger;aÌ, called
number operator, one finds 2 H&prime; = (I + aÌ&dagger;aÌ) + aÌ&dagger;aÌ = 2 N + I, whence
</p>
<p>H&prime;w = N w + Iw/2 = Îµw, N w =
(
</p>
<p>Îµ &minus; 1
2
</p>
<p>)
</p>
<p>w = Î½w, (12.6)
</p>
<p>where Î½ = Îµ &minus; 1/2. The second relation in (12.6) shows that H&prime; and N have the
same eigenfunctions, while their eigenvalues differ by 1/2. Using the same relation
and observing that aÌ and aÌ&dagger; are real, one finds
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
w&lowast;aÌ&dagger;aÌw dÎ¾ =
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
|aÌw|2 dÎ¾ = Î½
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
|w|2dÎ¾ , (12.7)</p>
<p/>
</div>
<div class="page"><p/>
<p>12.2 Linear Harmonic Oscillator 219
</p>
<p>showing that N = aÌ&dagger;aÌ, in contrast to aÌ and aÌ&dagger;, is Hermitean, hence its eigenvalues
Î½ are real. Moreover, they are non negative: in fact, the integral of |w|2 in (12.7)
is strictly positive because an eigenfunction can not vanish identically, whereas the
integral of |aÌw|2 is strictly positive if aÌw ï¿½= 0, whereas it vanishes if aÌw = 0
identically. As a consequence it is Î½ = 0 if and only if aÌw = 0, otherwise it is Î½ &gt; 0.
Another relation is found by left multiplying by aÌ&dagger; the first relation in (12.5), to find
N aÌ&dagger; &minus; aÌ&dagger;N = aÌ&dagger;, whence a new operator is defined: N aÌ&dagger; = aÌ&dagger; (N + I). The
action of the latter upon an eigenfunction w of N results in
</p>
<p>N aÌ&dagger;w = aÌ&dagger; (N + I)w = aÌ&dagger;Î½w + aÌ&dagger;w = (Î½ + 1) aÌ&dagger;w. (12.8)
</p>
<p>In other terms, if Î½ is an eigenvalue of N and w is an eigenfunction belonging to
Î½, then Î½ + 1 is also an eigenvalue of N , with eigenfunction aÌ&dagger;w. This reasoning
can be repeated indefinitely: N aÌ&dagger;aÌ&dagger;w = (Î½ + 2) aÌ&dagger;aÌ&dagger;w, . . . ; its conclusion is that,
if a number Î½ &ge; 0 is known to be an eigenvalue of N , then all numbers Î½ + 1,
Î½ + 2, . . . belonging to the unlimited ladder1 beginning with Î½ are also eigenvalues
of N . Also, if w is an eigenfunction belonging to Î½, the eigenfunctions belonging to
Î½ + 1, Î½ + 2, . . . are aÌ&dagger;w, aÌ&dagger;aÌ&dagger;w, . . . .
</p>
<p>One may argue that the same kind of reasoning should be applicable in the back-
ward direction as well, to check whether Î½ &minus; 1, Î½ &minus; 2 are eigenvalues of N . In fact,
right multiplying by aÌ the first relation in (12.5) yields aÌN &minus; N aÌ = aÌ, whence
aÌ (N &minus; I) = N aÌ. The action of N aÌ upon an eigenfunction w of N results in
</p>
<p>N aÌw = aÌ (N &minus; I)w = aÌÎ½w &minus; aÌw = (Î½ &minus; 1) aÌw . (12.9)
</p>
<p>Remembering that the eigenvalues of N are non negative, (12.9) shows that, if Î½ is
an eigenvalue of N and Î½ &ge; 1, than Î½ &minus; 1 is also an eigenvalue of N , to which aÌw
belongs. By induction, N aÌaÌw = (Î½ &minus; 2) aÌaÌw, and so on. However, the backward
process cannot be repeated indefinitely because one of the numbers Î½&minus; 2, Î½&minus; 3, . . .
will eventually be found to be negative: this result contradicts (12.7), that shows
that the eigenvalues can not be negative. The contradiction is due to the implicit
assumption that the eigenvalue Î½ can be any real number, and is readily eliminated
by specifying that Î½ = n = 0, 1, 2, . . . ; consider in fact the eigenvalue n = 1 and
let w be an eigenfunction belonging to it. Applying (12.9) shows that w0 = aÌw is
an eigenfunction of N belonging to n = 0, namely, N w0 = 0. The next step in the
backward process would yield aÌw0 which, however, is not an eigenfunction because
it vanishes identically: this is easily found by combining ãw0|N w0ã = ||aÌw0||2 with
N w0 = 0. In other terms, the backward process comes automatically to an end when
the eigenvalue n = 0 is reached.
</p>
<p>The above reasoning shows that only the numbers n = 0, 1, 2, . . . are eigenvalues
of N . It also provides an easy method to calculate the eigenfunctions, that starts
from the result aÌw0 = 0 just found. Such a relation is a differential equation of the
</p>
<p>1 The term &ldquo;ladder&rdquo; is introduced in Sect. 13.3.</p>
<p/>
</div>
<div class="page"><p/>
<p>220 12 Cases Related to the Linear Harmonic Oscillator
</p>
<p>form
</p>
<p>1&radic;
2
</p>
<p>(
</p>
<p>Î¾ + d
dÎ¾
</p>
<p>)
</p>
<p>w0 = 0,
dw0
w0
</p>
<p>= &minus;Î¾dÎ¾ , w0 = c0 exp
(
</p>
<p>&minus;Î¾
2
</p>
<p>2
</p>
<p>)
</p>
<p>. (12.10)
</p>
<p>The normalization constant is found from (C.27), which yields c0 = Ï&minus;1/4. The
eigenfunctions corresponding to n = 1, 2, . . . are found recursively with w1 = aÌ&dagger;w0,
w2 = aÌ&dagger;w1 = aÌ&dagger;aÌ&dagger;w0, . . . For example,
</p>
<p>w1 =
1&radic;
2
</p>
<p>(
</p>
<p>Î¾w0 &minus;
dw0
dÎ¾
</p>
<p>)
</p>
<p>= w0&radic;
2
</p>
<p>2Î¾. (12.11)
</p>
<p>From this construction it is easily found that the eigenvalues are not degenerate, and
that wn is even (odd) if n is even (odd). Also, it can be shown that wn has the form
[78, Chap. XII.7]
</p>
<p>wn(Î¾ ) =
(
</p>
<p>n!2n&radic;Ï
)&minus;1/2
</p>
<p>exp (&minus;Î¾ 2/2)Hn(Î¾ ), (12.12)
</p>
<p>where Hn is the nth Hermite polynomial
</p>
<p>Hn(Î¾ ) = ( &minus; 1)n exp (Î¾ 2)
dn
</p>
<p>dÎ¾n
exp (&minus;Î¾ 2). (12.13)
</p>
<p>The eigenfunctions of the linear harmonic oscillator form a real, orthonormal set:
&int; +&infin;
</p>
<p>&minus;&infin;
wnwmdx = Î´nm. (12.14)
</p>
<p>By remembering that Î½ = Îµ&minus; 1/2 = n and Îµ = E/(hÌÏ), one finds for the energy E
of the linear harmonic oscillator the eigenvalues
</p>
<p>En =
(
</p>
<p>n+ 1
2
</p>
<p>)
</p>
<p>hÌÏ, n = 0, 1, 2, . . . (12.15)
</p>
<p>In conclusion, the energy of the linear harmonic oscillator is the sum of the minimum
energy E0 = hÌ Ï/2 &gt; 0, also called zero point energy, and of an integer number
of elementary quanta of energy hÌÏ. The paramount importance of the example of
the linear harmonic oscillator has already been emphasized in the classical treatment
of Sect. 3.13.1. Examples of application of the quantization of the linear harmonic
oscillator are given in Sects. 12.3, 12.4, and 12.5.
</p>
<p>The Hermite polynomials (12.13) fulfill the recursive relation [44]
</p>
<p>Hn+1 &minus; 2Î¾ Hn + 2nHn&minus;1 = 0, n = 1, 2, . . . , (12.16)
</p>
<p>which is useful to determine some properties of the aÌ, aÌ&dagger; operators. For instance,
combining the definition of aÌ&dagger; with (12.12) one obtains
</p>
<p>aÌ&dagger;wn =
1/
&radic;
</p>
<p>2
(
</p>
<p>n!2n&radic;Ï
)1/2 exp
</p>
<p>(
</p>
<p>&minus;Î¾ 2/2
)
(
</p>
<p>2Î¾Hn &minus;
dHn
dÎ¾
</p>
<p>)
</p>
<p>. (12.17)</p>
<p/>
</div>
<div class="page"><p/>
<p>12.3 Quantization of the Electromagnetic Field&rsquo;s Energy 221
</p>
<p>On the other hand one finds from (12.13) that dHn/dÎ¾ = 2 Î¾ Hn &minus;Hn+1. Replacing
the derivative in (12.17) yields
</p>
<p>aÌ&dagger;wn =
1/
&radic;
</p>
<p>2
(
</p>
<p>n!2n&radic;Ï
)1/2 exp
</p>
<p>(
</p>
<p>&minus;Î¾ 2/2
)
</p>
<p>Hn+1 =
&radic;
n+ 1wn+1. (12.18)
</p>
<p>This result shows that, apart from the multiplicative constant, aÌ&dagger; transforms the state
of index n into that of index n + 1. Due to (12.15), the transformation corresponds
to an increase En+1 &minus; En = hÌ Ï in the total energy of the oscillator. Since its
action &ldquo;creates&rdquo; a quantum of energy, aÌ&dagger; is called creation operator. Using the same
procedure, combined with the recursive relation (12.16), one finds
</p>
<p>aÌwn =
&radic;
nwn&minus;1. (12.19)
</p>
<p>Due to the above, aÌ is called destruction operator or annihilation operator. Note
that, due to (12.18, 12.19), the successive application of aÌ and aÌ&dagger; to wn is equivalent
to N wn = nwn.
</p>
<p>12.3 Quantization of the Electromagnetic Field&rsquo;s Energy
</p>
<p>The energy of the electromagnetic field within a finite volume V free of charge has
been calculated in Sect. 5.6 in terms of the field&rsquo;s modes. In such a calculation the
shape of V was chosen as that of a box whose sides d1, d2, d3 are aligned with the
coordinate axes and start from the origin (Fig. 5.1), so that V = d1 d2 d3. The energy
reads
</p>
<p>Wem =
&sum;
</p>
<p>kÏ
</p>
<p>WkÏ , WkÏ = 2Îµ0VÏ2skÏ s&lowast;kÏ , (12.20)
</p>
<p>where Îµ0 is the vacuum permittivity, k =
&sum;3
</p>
<p>i=1 2Ï ni ii/di , ni = 0,&plusmn;1,&plusmn;2, . . . ,
Ï = 1, 2, and Ï = c |k|, with c the speed of light and ii the unit vector of the ith
axis. Finally, skÏ (t) is one of the two components of the complex vector defined by
(5.29). The energy WkÏ of the degree of freedom k, Ï is written in Hamiltonian form
by introducing the canonical coordinates qkÏ ,pkÏ such that
</p>
<p>2
&radic;
</p>
<p>Îµ0VÏskÏ = ÏqkÏ + ipkÏ . (12.21)
</p>
<p>Using (12.21) transforms (12.20) into
</p>
<p>WkÏ =
1
</p>
<p>2
(ÏqkÏ + ipkÏ ) (ÏqkÏ &minus; ipkÏ ) =
</p>
<p>1
</p>
<p>2
</p>
<p>(
</p>
<p>p2kÏ + Ï2q2kÏ
)
</p>
<p>. (12.22)
</p>
<p>The Hamiltonian operator is obtained by replacing qkÏ with qÌkÏ = qkÏ and pkÏ with
pÌkÏ = &minus;i hÌ d/dqkÏ in the last expression on the right of (12.22):
</p>
<p>H0kÏ = &minus;
hÌ2
</p>
<p>2
</p>
<p>d2
</p>
<p>dq2kÏ
+ Ï
</p>
<p>2
</p>
<p>2
q2kÏ . (12.23)</p>
<p/>
</div>
<div class="page"><p/>
<p>222 12 Cases Related to the Linear Harmonic Oscillator
</p>
<p>It should be noted, however, that if the intermediate expression in (12.22), instead
of that on the right, is used for the replacement of the classical coordinates with the
corresponding operators, a different result is obtained. In fact, qÌkÏ and pÌkÏ do not
commute so that, from (8.72), one obtains
</p>
<p>H&minus;kÏ = H0kÏ &minus;
1
</p>
<p>2
hÌÏ. (12.24)
</p>
<p>A third form of the Hamiltonian operator, different from the two above, is obtained
by exchanging the order of factors in the intermediate expression in (12.22) prior to
the replacement of the coordinates with operators:
</p>
<p>H+kÏ = H0kÏ +
1
</p>
<p>2
hÌÏ. (12.25)
</p>
<p>To proceed one considers H0kÏ first. The Schr&ouml;dinger equation generated by it,
</p>
<p>H0kÏw
0
kÏ = E0kÏw0kÏ (12.26)
</p>
<p>is the Eq. (12.1) of the linear harmonic oscillator, whose eigenvalues (12.15) read
E0(nkÏ ) = (nkÏ + 1/2)hÌÏ, with nkÏ = 0, 1, 2 . . . , and are non degenerate. The
second form (12.24) of the Hamiltonian operator generates the Schr&ouml;dinger equation
H&minus;kÏw
</p>
<p>&minus;
kÏ = E&minus;kÏw&minus;kÏ , namely,
</p>
<p>H0kÏ w
&minus;
kÏ =
</p>
<p>(
</p>
<p>E&minus;kÏ +
1
</p>
<p>2
hÌÏ
</p>
<p>)
</p>
<p>w&minus;kÏ , (12.27)
</p>
<p>again the equation for the linear harmonic oscillator, whose operator is identi-
cal to that of (12.26). As a consequence, its eigenvalues are E&minus;(nkÏ ) + hÌÏ/2 =
(nkÏ + 1/2)hÌÏ, whence E&minus;(nkÏ ) = nkÏ hÌ Ï. By the same token the eigenvalues of
(12.25) are found to be E+(nkÏ ) = (nkÏ + 1) hÌÏ. From (12.20), the energy of the
electromagnetic field is the sum of the energy of the single modes; the three cases
considered above then yield:
</p>
<p>W 0em =
&sum;
</p>
<p>kÏ
</p>
<p>(
</p>
<p>nkÏ +
1
</p>
<p>2
</p>
<p>)
</p>
<p>hÌÏ, W&minus;em =
&sum;
</p>
<p>kÏ
</p>
<p>nkÏ hÌÏ, W
+
em =
</p>
<p>&sum;
</p>
<p>kÏ
</p>
<p>(nkÏ + 1) hÌÏ,
</p>
<p>with Ï = c|k|. In the expression of W 0em and W+em the sum over k of the terms hÌÏ/2
and, respectively, hÌÏ, diverges. This is not acceptable because the total energy within
V is finite. On the contrary, for the expression of W&minus;em to converge it is sufficient that
nkÏ vanishes from some |k| on; the correct Hamiltonian is thus H&minus;kÏ . Grouping for
each k the summands corresponding to Ï = 1 and Ï = 2, and letting nk = nk1+nk2,
provides
</p>
<p>W&minus;em =
&sum;
</p>
<p>k
</p>
<p>nkhÌÏ. (12.28)</p>
<p/>
</div>
<div class="page"><p/>
<p>12.4 Quantization of the Electromagnetic Field&rsquo;s Momentum 223
</p>
<p>In conclusion, the energy of each mode of oscillation is a multiple (0 included) of the
elementary quantum of energy hÌ Ï(k). This result provides the formal justification
of the concept of photon. The integer nkÏ is the occupation number of the pair k, Ï ,
whereas nk is the number of photons2 of the mode corresponding to k. Like in the
classical treatment, the energy of the electromagnetic field is the sum of the energies
of each mode of oscillation.
</p>
<p>12.4 Quantization of the Electromagnetic Field&rsquo;s Momentum
</p>
<p>The momentum of the electromagnetic field within a finite volume V free of charge
has been calculated in Sect. 5.7 in terms of the field&rsquo;s modes. Premises and symbols
here are the same as in Sect. 12.3. The momentum reads
</p>
<p>&int;
</p>
<p>V
</p>
<p>S
</p>
<p>c2
dV = 2Îµ0V
</p>
<p>&sum;
</p>
<p>k
</p>
<p>Ï sk &middot; s&lowast;kk =
&sum;
</p>
<p>kÏ
</p>
<p>1
</p>
<p>c
WkÏ
</p>
<p>k
</p>
<p>k
, (12.29)
</p>
<p>with S the Poynting vector and k = |k|. For each pair k, Ï , the same quantization
procedure used for the energy in Sect. 12.3 is applicable here, and yields the operator
H&minus;kÏ k/(ck). As the latter differs by a constant vector from the Hamiltonian operator
(12.24) corresponding to the same pair k, Ï , the eigenvalues of the ith component
of momentum turn out to be
</p>
<p>1
</p>
<p>c
nkÏ hÌÏ
</p>
<p>ki
</p>
<p>k
= nkÏ hÌki , nkÏ = 0, 1, 2, . . . (12.30)
</p>
<p>In conclusion, the eigenvalues of momentum corresponding to k, Ï are nkÏ hÌk. Let-
ting as in Sect. 12.3 nk = nk1 + nk2, the momentum of the electromagnetic field
is expressed in quantum terms as
</p>
<p>&sum;
</p>
<p>k nkhÌ k. This result shows that the momentum
of each mode of oscillation is a multiple (0 included) of the elementary quantum
of momentum hÌ k, and completes the formal justification of the concept of photon
started in Sect. 12.3. Each photon has energy and momentum, given by hÌÏ and hÌk
respectively. Like in the classical treatment, the momentum of the electromagnetic
field is the sum of the momenta of each mode of oscillation.
</p>
<p>2 To complete the description of the photon it is necessary to work out also the quantum expression
of its momentum. This is done in Sect. 12.4. The concept of photon was introduced by Einstein in
1905 [34] (the English translation of [34] is in [107]). The quantization procedure shown here is
given in [30].</p>
<p/>
</div>
<div class="page"><p/>
<p>224 12 Cases Related to the Linear Harmonic Oscillator
</p>
<p>12.5 Quantization of a Diagonalized Hamiltonian Function
</p>
<p>A system of particles near an equilibrium point has been investigated in Sects. 3.9
and 3.10. The analysis led to the separation of the Hamiltonian function, that reads
</p>
<p>Ha &minus; Va0 =
3N
&sum;
</p>
<p>Ï=1
HÏ , HÏ =
</p>
<p>1
</p>
<p>2
bÌ2Ï +
</p>
<p>1
</p>
<p>2
Ï2Ïb
</p>
<p>2
Ï . (12.31)
</p>
<p>In (12.31), 3N is the number of degrees of freedom, bÏ the normal coordinate of
index Ï , ÏÏ the angular frequency corresponding to bÏ , and Va0 the minimum of
the system&rsquo;s potential energy. Apart from the constant Va0, the Hamiltonian function
Ha is given by a sum of terms, each associated with a single degree of freedom. In
turn, each summand HÏ is identical to the Hamiltonian function of a linear harmonic
oscillator with m = 1. As a consequence, the quantum operator corresponding to
(12.31) takes the form
</p>
<p>Ta + Va =
3N
&sum;
</p>
<p>Ï=1
HÏ + Va0, HÏ = &minus;
</p>
<p>hÌ2
</p>
<p>2
</p>
<p>&part;2
</p>
<p>&part;b2Ï
+ 1
</p>
<p>2
Ï2Ïb
</p>
<p>2
Ï , (12.32)
</p>
<p>and generates the eigenvalue equation (Ta + Va)v = Ev, where
(
</p>
<p>3N
&sum;
</p>
<p>Ï=1
HÏ
</p>
<p>)
</p>
<p>v = E&prime;v, E&prime; = E &minus; Va0. (12.33)
</p>
<p>Being Ha the sum of operators acting on individual degrees of freedom, the
Schr&ouml;dinger equation is separable (Sect. 10.3) and splits into 3N equations of the
form
</p>
<p>HÏ vÏÎ¶ (Ï ) = EÏÎ¶ (Ï ) vÏÎ¶ (Ï ), E&prime; =
3N
&sum;
</p>
<p>Ï=1
EÏÎ¶ (Ï ), (12.34)
</p>
<p>where Ï = 1, 2, . . . , 3N refers to the degrees of freedom, whereas Î¶ (Ï ) =
0, 1, 2, . . . counts the set of eigenvalue indices corresponding to a given Ï . Re-
membering the solution of the Schr&ouml;dinger equation for a linear harmonic oscillator
(Sect. 12.2), the energy of the individual degree of freedom is
</p>
<p>EÏÎ¶ (Ï ) =
[
</p>
<p>Î¶ (Ï ) + 1
2
</p>
<p>]
</p>
<p>hÌÏÏ , Î¶ (Ï ) = 0, 1, 2, . . . . (12.35)
</p>
<p>The total energy of the system then reads
</p>
<p>E = Va0 +
3N
&sum;
</p>
<p>Ï=1
</p>
<p>[
</p>
<p>Î¶ (Ï ) + 1
2
</p>
<p>]
</p>
<p>hÌÏÏ . (12.36)
</p>
<p>As indicated in Sect. 3.10, the oscillation of the normal coordinate of index Ï is called
mode of the vibrating system. The classical expression of the energy associated to</p>
<p/>
</div>
<div class="page"><p/>
<p>12.6 Complements 225
</p>
<p>each mode has the same form as that of a mode of the electromagnetic field (compare
(12.31) with (12.22)). By analogy with the electromagnetic case, a particle of energy
hÌ ÏÏ , called phonon, is introduced in the quantum description, and the energy of the
mode is ascribed to the set of phonons belonging to the mode. The integers Î¶ (Ï ) are
the occupation numbers of the normal modes of oscillation.
</p>
<p>Note that the quadratic form (12.31) of the total energy HÏ of each degree of
freedom of the oscillating system was derived directly, in contrast with that of the
electromagnetic field where the product of two linear forms was involved (compare
with (12.22)). For this reason, the discussion about three possible forms of the
Hamiltonian operator, carried out in Sect. 12.3, is not necessary here. The total
energy (12.36) does not diverge because the number of degrees of freedom is finite.
</p>
<p>12.6 Complements
</p>
<p>12.6.1 Comments About the Linear Harmonic Oscillator
</p>
<p>The normalized form (12.2) of the Schr&ouml;dinger equation for the linear harmonic
oscillator is &minus;d2wn/dÎ¾ 2 + Î¾ 2 wn = 2 Îµnwn. Due to the exponential decay at infinity,
the Fourier transform (C.16) of the eigenfunction exists. Let
</p>
<p>un(Î·) = Fwn =
1&radic;
2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
wn(Î¾ ) exp ( &minus; iÎ·Î¾ ) dÎ¾. (12.37)
</p>
<p>Thanks to the property (C.22) of the Fourier transform it is Fd2wn/dÎ¾ 2 = &minus;Î·2un,
FÎ¾ 2 wn = &minus;d2un/dÎ·2. Fourier transforming (12.2) thus yields
</p>
<p>1
</p>
<p>2
Î·2un &minus;
</p>
<p>1
</p>
<p>2
</p>
<p>d2un
dÎ·2
</p>
<p>= Îµnun, (12.38)
</p>
<p>namely, an equation identical to (12.2), having the same eigenvalue. As Îµn is not
degenerate, it follows un &prop; wn, namely, the eigenfunctions of the harmonic oscillator
are equal to their own Fourier transforms apart from a multiplicative constant at most.3
</p>
<p>3 Compare with (C.82), where the property is demonstrated for the Gaussian function; the lat-
ter, apart from scaling factors, coincides with the eigenfunction of the linear harmonic oscillator
belonging to the eigenvalue corresponding to n = 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 13
</p>
<p>Other Examples of the Schr&ouml;dinger Equation
</p>
<p>13.1 Introduction
</p>
<p>A number of properties of the one-dimensional, time-independent Schr&ouml;dinger equa-
tion can be worked out without specifying the form of the coefficient. To this purpose
one examines the two fundamental solutions, which are real because the coefficient
is such. One finds that the fundamental solutions do not have multiple zeros and do
not vanish at the same point; more precisely, the zeros of the first and second funda-
mental solution separate each other. It is also demonstrated that the character of the
fundamental solutions within an interval is oscillatory or non oscillatory depending
on the sign of the equation&rsquo;s coefficient in such an interval. After completing this
analysis, the chapter examines an important and elegant solution method, consisting
in factorizing the operator. The theory is worked out for the case of localized states,
corresponding to discrete eigenvalues. The procedure by which the eigenfunctions&rsquo;
normalization is embedded into the solution scheme is also shown. The chapter con-
tinues with the analysis of the solution of a Schr&ouml;dinger equation whose coefficient
is periodic; this issue finds important applications in the case of periodic structures
like, e.g., crystals. Finally, the solution of the Schr&ouml;dinger equation for a particle
subjected to a central force is worked out; the equation is separated and the angular
part is solved first, followed by the radial part whose potential energy is specified
in the Coulomb case. The first complements deal with the operator associated to the
angular momentum and to the solution of the angular and radial equations by means
of the factorization method. The last complement generalizes the solution method for
the one-dimensional Schr&ouml;dinger equation in which the potential energy is replaced
with a piecewise-constant function, leading to the concept of transmission matrix.
</p>
<p>13.2 Properties of the One-Dimensional Schr&ouml;dinger Equation
</p>
<p>In the general expression (11.44) for the transmission coefficient, the fundamental
solutions u, v appear in the denominator. It is then necessary to investigate the zeros
of the solutions of (11.28). Due to the u(0) = 1 prescription, the possible zeros of u
belong to the interval 0 &lt; x &le; s, while those of v belong to the interval 0 &le; x &le; s.
</p>
<p>&copy; Springer Science+Business Media New York 2015 227
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_13</p>
<p/>
</div>
<div class="page"><p/>
<p>228 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>If one or more zero exist, they can not be multiple. In fact, if u had a multiple zero
at xm it would be u(xm) = 0, u&prime;(xm) = 0, hence u = 0 would be a solution of (11.28)
compatible with such conditions. In fact, because of the uniqueness of the solution,
u = 0 would be the only solution. Observing that u is continuous, this would contra-
dict the condition u(0) ï¿½= 0. Similarly, if v had a multiple zero it would vanish identi-
cally. Remembering that the derivative of the solution is continuous, this would con-
tradict the condition v&prime;(0) = 1 of (11.40). Another property is that u and v cannot van-
ish at the same point. This is apparent from the relationW (x) = u v&prime;&minus;u&prime; v = 1 demon-
strated in Sect. A.12. For the same reason, u&prime; and v&prime; cannot vanish at the same point.
</p>
<p>If one of the solutions, say u, has more than one zero in 0 &lt; x &le; s, then the
following property holds: between two consecutive zeros of u there is one and only
one zero of v. Let xL, xR be two consecutive zeros of u, with 0 &lt; xL &lt; xR &le; s. The
property is demonstrated by showing, first, that a contradiction would arise if there
were no zeros of v between xL and xR (that is to say, at least one zero must exist
there) and, second, that if a zero of v exists between xL and xR , it must be unique
[102]. To proceed one considers the function u/v in the interval xL &le; x &le; xR . By
definition u/v vanishes at the boundaries of such an interval while, as shown above, v
cannot vanish at the boundaries. If one assumes that there are no zeros of v inside the
interval, then u/v exists everywhere in the interval, and is also everywhere continuous
with a continuous first derivative because u and v are solutions of the second-order
differential Eq. (11.28). As u/v vanishes at xL and xR , its derivative must vanish at
least once in the open interval xL &lt; x &lt; xR . However, this is impossible because
d(u/v)/dx = &minus;W/v2 = &minus;1/v2 ï¿½= 0. This shows that v must have at least one
zero between xL and xR . Such a zero is also unique because, if v had two zeros in
xL &lt; x &lt; xR , then by the same reasoning u would have one zero between them, so
xL and xR would not be consecutive. The property may be restated as the zeros of
two real linearly-independent solutions of a second-order linear differential equation
</p>
<p>separate each other. The property does not hold for complex solutions.
So far the properties demonstrated in this section did not consider the sign of the
</p>
<p>coefficient q(x) = 2m (E &minus; V )/hÌ2 of (11.28). The coefficient separates the interval
0 &le; x &le; s into subintervals where q is alternatively positive or negative. If q is
continuous the extrema of the subintervals are the zeros of q, otherwise they may
be discontinuity points of q. In either case the behavior of the solution u within
each subinterval depends on the sign of q there. To show this, consider the function
d(u u&prime;)/dx = (u&prime;)2 &minus;q u2, where the expression at the right hand side has been found
by means of (11.28). If q &le; 0 in the subinterval, then d(u u&prime;)/dx is non negative.
It follows that u u&prime; is a non-decreasing function in the subinterval, hence it has one
zero at most. Remembering that u and u&prime; can not vanish at the same point, one of the
following holds: i) neither u nor u&prime; vanish in the subinterval, ii) either u or u&prime; vanishes
once in the subinterval. For a given interval a function is called non oscillatory if
its derivative vanishes at most once. It follows that the solution u is non oscillatory
in those subintervals where q &le; 0. The case V = V0 &gt; E &gt; 0 in the interval
0 &lt; x &lt; s, considered in Sect. 11.3.1, is of this type.</p>
<p/>
</div>
<div class="page"><p/>
<p>13.3 Localized States&mdash;Operator&rsquo;s Factorization 229
</p>
<p>Fig. 13.1 Form of the
potential energy that gives
rise to localized states
(Sect. 13.3). Only one state E
is shown
</p>
<p>-5 0 5
x  (a. u.)
</p>
<p>-1.5
</p>
<p>-1
</p>
<p>-0.5
</p>
<p>0
</p>
<p>V
(x
</p>
<p>),
E
</p>
<p>  
 (
</p>
<p>a.
 u
</p>
<p>.)
</p>
<p>E
V (x)
</p>
<p>13.3 Localized States&mdash;Operator&rsquo;s Factorization
</p>
<p>It may happen that the form of the potential energy V in the interval 0 &le; x &le; s
is such that V has one or more negative minima (Fig. 13.1). In this case negative
eigenvalues of E may exist, giving rise to localized states. To treat this case one
must preliminarily observe that the eigenfunctions do not vanish identically outside
the interval 0 &le; x &le; s, because the minima of V are finite. As a consequence, it is
convenient to replace the above interval with x1 &le; x &le; x2, where the two boundaries
may be brought (independently from each other) to&minus;&infin; or+&infin;, respectively. Letting
</p>
<p>Î» = 2m
hÌ2
</p>
<p>E, rl(x) = &minus;
2m
</p>
<p>hÌ2
V , (13.1)
</p>
<p>the Schr&ouml;dinger Eq. (11.28) becomes
</p>
<p>w&prime;&prime; + rl w + Î»w = 0. (13.2)
The integer index l = 0, 1, . . . is attached to r(x) for convenience. In fact, in typical
applications the form of the potential energy in (13.1) may be prescribed by a previ-
ous separation procedure in which the index is involved. As will be shown after the
analysis of the solution procedure, index l may eventually be disposed of. For the
time being, the solutions of (13.2) must be considered as dependent on the eigenvalue
Î» and on the index l, namely, w = wÎ»l(x). Also, for a given pair Î», l the eigenfunc-
tions are non degenerate due to the normalization condition. As a consequence, two
eigenfunctions belonging to the same pair differ by a multiplicative constant at most.
</p>
<p>13.3.1 Factorization Method
</p>
<p>A possible method for solving (13.2) is expanding w into a power series, replacing the
series into (13.2), collecting the terms of equal power, and letting their coefficients</p>
<p/>
</div>
<div class="page"><p/>
<p>230 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>vanish. This provides a recurrence relation involving the coefficients of the series;
then, the latter is suitably truncated to obtain a square-integrable solution. Another
method for solving (13.2), that greatly reduces the calculation effort and brings about
a procedure of supreme elegance, is the operator&rsquo;s factorization. The conditions that
make the factorization possible are illustrated in [52] and are briefly reported here. In
essence they amount to finding a function gl(x) and a parameter Ll such that (13.2)
may be recast as
</p>
<p>(
</p>
<p>gl+1 +
d
</p>
<p>dx
</p>
<p>)(
</p>
<p>gl+1 &minus;
d
</p>
<p>dx
</p>
<p>)
</p>
<p>wÎ»l = (Î»&minus; Ll+1) wÎ»l , (13.3)
(
</p>
<p>gl &minus;
d
</p>
<p>dx
</p>
<p>)(
</p>
<p>gl +
d
</p>
<p>dx
</p>
<p>)
</p>
<p>wÎ»l = (Î»&minus; Ll) wÎ»l . (13.4)
</p>
<p>Note that both (13.3) and (13.4) must be identical to (13.2). An additional constraint
is that, for a given integer n, it must be Ln+1 &gt; Ll+1, l = 0, 1, . . . , n &minus; 1. To
proceed, the boundary conditions wÎ»l(x1) = wÎ»l(x2) = 0 will be assumed. If one or
both boundaries are at infinity, the condition
</p>
<p>&int;
</p>
<p>|wÎ»l|2 dx &lt; &infin; will also be assumed.
Now, imposing that (13.3) is identical to (13.2) yields g2l+1 + g&prime;l+1 + Ll+1 = &minus;rl
whence, letting l &larr; l &minus; 1,
</p>
<p>g2l + g&prime;l + Ll = &minus;rl&minus;1. (13.5)
</p>
<p>Similarly, imposing that (13.4) is identical to (13.2) leads to
</p>
<p>g2l &minus; g&prime;l + Ll = &minus;rl . (13.6)
</p>
<p>Adding (13.6) to (13.5) and subtracting (13.6) from (13.5) yields, respectively,
</p>
<p>g2l + Ll = &minus;
1
</p>
<p>2
(rl&minus;1 + rl), g&prime;l = &minus;
</p>
<p>1
</p>
<p>2
(rl&minus;1 &minus; rl). (13.7)
</p>
<p>Differentiating the first relation of (13.7) with respect to x and replacing g&prime;l from the
second one provides
</p>
<p>gl =
1
</p>
<p>2
</p>
<p>r &prime;l&minus;1 + r &prime;l
&minus;2 g&prime;l
</p>
<p>= 1
2
</p>
<p>r &prime;l&minus;1 + r &prime;l
rl&minus;1 &minus; rl
</p>
<p>. (13.8)
</p>
<p>Finally, replacing (13.8) into the first relation of (13.7),
</p>
<p>Ll = &minus;
1
</p>
<p>2
(rl&minus;1 + rl) &minus;
</p>
<p>1
</p>
<p>4
</p>
<p>(
r &prime;l&minus;1 + r &prime;l
rl&minus;1 &minus; rl
</p>
<p>)2
</p>
<p>. (13.9)
</p>
<p>In conclusion, the factorization is possible if Ll given by (13.9) is independent of x.
In this case, gl is given by (13.8). As rl is real, both Ll and gl are real as well.</p>
<p/>
</div>
<div class="page"><p/>
<p>13.3 Localized States&mdash;Operator&rsquo;s Factorization 231
</p>
<p>13.3.2 First-Order Operators
</p>
<p>If the factorization (13.3, 13.4) succeeds, it is useful to define the first-order, real
operators
</p>
<p>A+l = gl +
d
</p>
<p>dx
, A&minus;l = gl &minus;
</p>
<p>d
</p>
<p>dx
, (13.10)
</p>
<p>so that (13.3, 13.4) are rewritten as
</p>
<p>A+l+1A
&minus;
l+1wÎ»l = (Î»&minus; Ll+1) wÎ»l , A&minus;l A+l wÎ»l = (Î»&minus; Ll) wÎ»l . (13.11)
</p>
<p>The two operators (13.10) are mutually adjoint. In fact, for any pair of functions f1,
f2 fulfilling the same boundary conditions as wÎ»l one finds
</p>
<p>&int; x2
</p>
<p>x1
</p>
<p>f &lowast;1 A
+
l f2 dx =
</p>
<p>[
</p>
<p>f &lowast;1 f2
]x2
</p>
<p>x1
+
</p>
<p>&int; x2
</p>
<p>x1
</p>
<p>(A&minus;l f1)
&lowast; f2 dx, (13.12)
</p>
<p>where the integrated part vanishes due to the boundary conditions. From the above
result one finds a property of the eigenvalue Î». In fact, multiplying (13.11) by w&lowast;Î»l
and integrating, one finds
</p>
<p>&int; x2
</p>
<p>x1
</p>
<p>|A&minus;l+1wÎ»l|2 dx = (Î»&minus; Ll+1)
&int; x2
</p>
<p>x1
</p>
<p>|wÎ»l|2 dx, (13.13)
</p>
<p>where (13.12) has been used after letting f1 = wÎ»l , f2 = A&minus;l+1wÎ»l . From (13.13) it
follows that, if wÎ»l is an eigenfunction, that is, if wÎ»l does not vanish identically, then
the case Î» &lt; Ll+1 is impossible. In fact, the integral at the right hand side of (13.13)
is strictly positive, while that at the left hand side is non negative. There remain two
possibilities, namely:
</p>
<p>1. A&minus;l+1wÎ»l does not vanish identically, whence both integrals of (13.13) are stricly
positive. It follows that Î» &gt; Ll+1. Also, as will be shown later, A
</p>
<p>&minus;
l+1wÎ»l is another
</p>
<p>eigenfunction of (13.2). The opposite is also true, namely, Î» &gt; Ll+1 implies that
A&minus;l+1wÎ»l does not vanish identically.
</p>
<p>2. A&minus;l+1wÎ»l vanishes identically, whenceÎ» = Ll+1. The opposite is also true, namely,
Î» = Ll+1 implies that A&minus;l+1wÎ»l vanishes identically. In this case A&minus;l+1wÎ»l is not
an eigenfunction of (13.2).
</p>
<p>The discussion above allows one to identify the eigenvalue Î». In fact, there must be
a value of the index l, say l = n, such that the equality Î» = Ln+1 holds. It follows
that the eigenvalue is identified by the index n, Î» = Î»n.
</p>
<p>As mentioned before the condition Ln+1 &gt; Ll+1, l = 0, 1, . . . , n&minus; 1 holds. As a
consequence, the eigenfunction corresponding to the pair Î»n, l may be indicated with
wnl instead of wÎ»l . In particular, the eigenfunction corresponding to l = n is wnn. As
shown in case 2 above, such an eigenfunction corresponds to the equality Î»n = Ln+1
which, in turn, implies the condition A&minus;n+1wnn = 0. Remembering the second relation</p>
<p/>
</div>
<div class="page"><p/>
<p>232 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>of (13.10), such a condition yields the first-order equation (gn+1 &minus; d/dx) wnn = 0,
whose solution is real and reads
</p>
<p>wnn = cnn exp
[&int; x
</p>
<p>x1
</p>
<p>gn+1(Î¾ ) dÎ¾
</p>
<p>]
</p>
<p>,
1
</p>
<p>c2nn
=
</p>
<p>&int; x2
</p>
<p>x1
</p>
<p>exp
</p>
<p>[&int; x
</p>
<p>x1
</p>
<p>2 gn+1(Î¾ ) dÎ¾
</p>
<p>]
</p>
<p>dx,
</p>
<p>(13.14)
</p>
<p>with cnn =
&radic;
</p>
<p>c2nn &gt; 0.
</p>
<p>13.3.3 The Eigenfunctions Corresponding to l &lt; n
</p>
<p>The result given in (13.14) shows that, if the factorization is achieved, the eigenfunc-
tion corresponding to l = n is found by solving a first-order equation. It remains
to determine the eigenfunctions corresponding to l = 0, 1, . . . , n &minus; 1. For this, left
multiplying the first relation in (13.11) by A&minus;l+1, letting l &larr; l + 1 in the second
relation of (13.11), and remembering that Î» = Ln+1, one finds
</p>
<p>A&minus;l+1A
+
l+1A
</p>
<p>&minus;
l+1wnl = (Ln+1 &minus; Ll+1) A&minus;l+1wnl , (13.15)
</p>
<p>A&minus;l+1A
+
l+1wÎ»,l+1 = (Ln+1 &minus; Ll+1) wn,l+1. (13.16)
</p>
<p>The above show that both wn,l+1 and A
&minus;
l+1wnl are eigenfunctions of the opera-
</p>
<p>tor A&minus;l+1A
+
l+1 belonging to the same eigenvalue. As the eigenfunctions are non
</p>
<p>degenerate, it must be
</p>
<p>A&minus;l+1wnl = const &times; wn,l+1, (13.17)
</p>
<p>where the constant may be determined by imposing the normalization condition. The
result shows that, if wn0 is known, one may calculate a sequence of eigenfunctions
belonging to Î»n = Ln+1 (apart from the normalization constant) by successive appli-
cations of first-order operators: A&minus;1 wn0 = const &times; wn1, A&minus;2 wn1 = const&times;wn2, . . . .
The process stops for l = n because, as shown earlier, A&minus;n+1wnn = 0 is not an eigen-
function anymore, so any further application of the operator beyond l = n provides a
sequence of zeros. In a similar manner, left multiplying the second relation in (13.11)
by A+l and letting l &larr; l &minus; 1 in the first relation of (13.11), one finds
</p>
<p>A+l A
&minus;
l wn,l&minus;1 = (Ln+1 &minus; Ll) wn,l&minus;1, (13.18)
</p>
<p>A+l A
&minus;
l A
</p>
<p>+
l wnl = (Ln+1 &minus; Ll) A+l wnl . (13.19)
</p>
<p>From the above one finds that both wn,l&minus;1 and A
+
l wnl are eigenfunctions of the
</p>
<p>operator A+l A
&minus;
l belonging to the same eigenvalue, whence
</p>
<p>A+l wnl = const &times; wn,l&minus;1. (13.20)</p>
<p/>
</div>
<div class="page"><p/>
<p>13.3 Localized States&mdash;Operator&rsquo;s Factorization 233
</p>
<p>The result shows that, if wnn is known, one may calculate a sequence of
eigenfunctions belonging to Î»n = Ln+1 (apart from the normalization constant)
by successive applications of first-order operators: A+n wnn = const &times; wn,n&minus;1,
A+n&minus;1wn,n&minus;1 = const &times; wn,n&minus;2, . . . . The process stops for l = 0 which, by hy-
pothesis, is the minimum of l. The derivation also shows that, since wnn and the
operators are real, all the eigenfunctions found using the factorization method are
real as well.
</p>
<p>13.3.4 Normalization
</p>
<p>The results of this section may be summarized as follows: (13.17) shows that the
application of the first-order operator A&minus;l+1 to an eigenfunction of indicesn, l provides
an eigenfunction of indicesn, l+1. Similarly, (13.20) shows that the application of the
first-order operator A+l to an eigenfunction of indices n, l provides an eigenfunction
of indices n, l &minus; 1. These results may be described as a process of going up or
down along a ladder characterized by an index n &ge; 0, whose steps are numbered
by a second index l = 0, 1, . . . , n. It follows that by applying two suitably-chosen
operators one may go up and down (or down and up) one step in the ladder and return
to the same eigenfunction apart from a multiplicative constant. This is indeed true,
as shown by (13.11), that also indicate that the multiplicative constant to be used at
the end of the two steps starting from wnl is Ln+1 &minus;Ll when the operators&rsquo; index is l.
It follows that the constants in (13.17, 13.20) must be chosen as
</p>
<p>&radic;
Ln+1 &minus; Ll+1 and&radic;
</p>
<p>Ln+1 &minus; Ll , respectively. This provides a method for achieving the normalization
of the eigenfunctions, starting from an eigenfunction wnn normalized to unity as in
(13.14). For this one defines the auxiliary, mutually adjoint operators
</p>
<p>B+nl =
A+l&radic;
</p>
<p>Ln+1 &minus; Ll
, B&minus;nl =
</p>
<p>A&minus;l&radic;
Ln+1 &minus; Ll
</p>
<p>, (13.21)
</p>
<p>so that (13.11) become
</p>
<p>B+n,l+1B
&minus;
n,l+1wnl = wnl , B&minus;nlB+nlwnl = wnl . (13.22)
</p>
<p>Thanks to the auxiliary operators the multiplicative constant at the end of the two
steps becomes unity. Remembering that the eigenfunctions and operators are real,
multiplying both of (13.22) by wnl and integrating yields
</p>
<p>&int; x2
</p>
<p>x1
</p>
<p>(B&minus;n,l+1wnl)
2 dx =
</p>
<p>&int; x2
</p>
<p>x1
</p>
<p>(B+nlwnl)
2 =
</p>
<p>&int; x2
</p>
<p>x1
</p>
<p>w2nl dx, (13.23)
</p>
<p>On the other hand, replacing the constant in (13.17), (13.20) with
&radic;
Ln+1 &minus; Ll+1,&radic;
</p>
<p>Ln+1 &minus; Ll , respectively, one derives
</p>
<p>B&minus;n,l+1wnl = wn,l+1, B+nlwnl = wn,l&minus;1. (13.24)</p>
<p/>
</div>
<div class="page"><p/>
<p>234 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>Comparing (13.24) with (13.23) shows that, if one of the eigenfunctions of the ladder
is normalized to unity, all the others have the same normalization. In particular,
if wnn is normalized to unity as in (13.14), then the whole ladder of normalized
eigenfunction is found by repeatedly applying the same procedure:
</p>
<p>B+nnwnn = wn,n&minus;1, B+n,n&minus;1wn,n&minus;1 = wn,n&minus;2, . . . , B+n1wn1 = wn0. (13.25)
</p>
<p>13.4 Schr&ouml;dinger Equation with a Periodic Coefficient
</p>
<p>An important case of (11.28) occurs when the coefficient q is periodic [37], with
a period that will be denoted with 2Ï. The independent variable (not necessarily a
Cartesian one) will be denoted with z:
</p>
<p>w&prime;&prime;(z) + q(z) w(z) = 0, q(z + 2Ï) = q(z), (13.26)
</p>
<p>where primes indicate derivatives. Here the variable z is considered real; the theory,
however, can be extended to the case of a complex variable. Let u(z), v(z) be fun-
damental solutions (Sect. 11.4), with u(0) = 1, u&prime;(0) = 0, v(0) = 0, v&prime;(0) = 1. As
(13.26) holds for any z, it holds in particular for z + 2Ï. From the periodicity of q
it follows
</p>
<p>w&prime;&prime;(z + 2Ï) + q(z) w(z + 2Ï) = 0, (13.27)
</p>
<p>namely, w(z + 2Ï) is also a solution. Similarly, u(z + 2Ï), v(z + 2Ï) are solutions.
As the equation has only two independent solutions it must be
</p>
<p>u(z + 2Ï) = a11 u(z) + a12 v(z), v(z + 2Ï) = a21 u(z) + a22 v(z), (13.28)
</p>
<p>with aij suitable constants. The values of the latter are readily related to those of
u, v by letting z = 0 and using the initial conditions: u(2Ï) = a11, u&prime;(2Ï) =
a12, v(2Ï) = a21, v&prime;(2Ï) = a22. As the Wronskian of u, v equals unity it follows
a11a22 &minus; a12a21 = 1. One now seeks a constant s such that
</p>
<p>u(z + 2Ï) = s u(z), v(z + 2Ï) = s v(z). (13.29)
</p>
<p>This is equivalent to diagonalizing (13.28), namely, s must fulfill for any z the
following relations:
</p>
<p>(a11 &minus; s) u(z) + a12 v(z) = 0, a21 u(z) + (a22 &minus; s) v(z) = 0. (13.30)
</p>
<p>Equating to zero the determinant of the coefficients in (13.30) yields
</p>
<p>s = a0
2
</p>
<p>&plusmn;
&radic;
</p>
<p>a20
</p>
<p>4
&minus; 1, a0 = a11 + a22. (13.31)
</p>
<p>If a0 = 2 the two solutions of (13.31) are real and take the common value s&minus; = s+ =
1. In this case, as shown by (13.29), the functions u, v are periodic with period 2Ï.</p>
<p/>
</div>
<div class="page"><p/>
<p>13.4 Schr&ouml;dinger Equation with a Periodic Coefficient 235
</p>
<p>Similarly, if a0 = &minus;2 the two solutions of (13.31) are real and take the common value
s&minus; = s+ = &minus;1. In this case, as shown by (13.29), the functions u, v are periodic with
period 4Ï, whereas their moduli |u|, |v| are periodic with period 2Ï. As the moduli
|u|, |v| do not diverge as further and further periods are added to z, the case a0 = &plusmn;2
is stable. If a0 &gt; 2 the two solutions of (13.31) are real and range over the intervals
0 &lt; s&minus; &lt; 1 and, respectively, s+ &gt; 1. In particular it is s&minus; &rarr; 0 for a0 &rarr; &infin;. If
a0 &lt; &minus;2 the two solutions of (13.31) are real and range over the intervals s+ &lt; &minus;1
and, respectively, &minus;1 &lt; s&minus; &lt; 0. In particular it is s&minus; &rarr; 0 for a0 &rarr; &minus;&infin;. From
the relations (13.29) it follows that the moduli of the solutions corresponding to s+
</p>
<p>diverge: in fact one has u(z + n 2Ï) = (s+)n u(z) and v(z + n 2Ï) = (s+)n v(z), so
the case |a0| &gt; 2 is unstable. When |a0| &lt; 2 the two solutions are complex, namely,
s&plusmn; = exp ( &plusmn; iÎ¼) with tan2 Î¼ = 4/a20 &minus; 1. As the modulus of the solutions is unity,
the case |a0| &lt; 2 is stable.
</p>
<p>The discussion about stability may seem incomplete because the possible cases
depend on the value of a0 = a11 + a22 = u(2Ï) + v&prime;(2Ï), which depends on the
fundamental solutions that are yet to be found. On the other hand, the analysis of
stability must eventually reduce to considering only the properties of the coefficient
of (13.26). In fact, it can be shown that if q(z) is positive for all values of z and the
absolute value of 2Ï
</p>
<p>&int; 2Ï
0 q(z) dz is not larger than 4, then |a0| &lt; 2 [74]. Multiplying
</p>
<p>both sides of the first relation in (13.29) by exp [&minus;Î± (z+2Ï)], withÎ± an undetermined
constant, yields
</p>
<p>uÌ(z + 2Ï) = s exp ( &minus; 2ÏÎ±) uÌ(z), uÌ(z) = exp ( &minus; Î± z) u(z). (13.32)
</p>
<p>A similar treatment is applied to v(z), to yield another auxiliary function vÌ. Now one
exploits the undetermined constant to impose that the auxiliary functions be periodic
of period 2Ï: for this one lets s exp ( &minus; 2Ï Î±) = 1, whence
</p>
<p>Î± = log s
2Ï
</p>
<p>. (13.33)
</p>
<p>The constant Î± defined by (13.33) is termed characteristic exponent or Floquet
exponent. Three of the cases listed in the discussion above about stability, namely,
s&plusmn; = exp ( &plusmn; iÎ¼), s&plusmn; = 1, and s&plusmn; = &minus;1 lead now to the single expression Î±&plusmn; =
&plusmn;iÎ¼/(2Ï), with 0 &le; Î¼ &le; Ï , showing that Î± is purely imaginary. The cases 0 &lt;
s&minus; &lt; 1 and s+ &gt; 1 lead to real values of Î± (negative and positive, respectively)
and, finally, the cases s+ &lt; &minus;1 and &minus;1 &lt; s&minus; &lt; 0 lead to complex values of Î±.
Considering the stable cases only, one transforms (13.26) by replacing w(z) with,
e.g., uÌ(z) exp [ &plusmn; iÎ¼ z/(2Ï)] to find
</p>
<p>uÌ&prime;&prime;(z) &plusmn; 2 i Î¼
2Ï
</p>
<p>uÌ&prime;(z) +
[
</p>
<p>q(z) &minus; Î¼
2
</p>
<p>4Ï2
</p>
<p>]
</p>
<p>uÌ(z) = 0. (13.34)
</p>
<p>The coefficients and the unknown function of (13.34) are periodic functions of period
2Ï. As a consequence it suffices to solve the equation within the single period, say,
0 &le; z &le; 2Ï. An example is given in Sect. 17.8.4; a different approach leading to
the generalization to three dimensions is shown in Sect. 17.6.</p>
<p/>
</div>
<div class="page"><p/>
<p>236 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>13.5 Schr&ouml;dinger Equation for a Central Force
</p>
<p>In the investigation about the properties of atoms it is important to analyze the
dynamics of particle subjected to a central force in the case where the motion is
limited. The treatment based on the concepts of Classical Mechanics is given in
Sects. 3.4 (where the general properties are illustrated), 3.7 (for the two-particle
interaction), 3.8 (for a Coulomb field in the repulsive case), and 3.13.6 (for a Coulomb
field in the attractive case). To proceed one considers a particle of mass1 m0 acted
upon by a force deriving from a potential energy of the central type, V = V (r), and
expresses the time-independent Schr&ouml;dinger equation &minus;hÌ2/(2m0)&nabla;2w + V (r) w =
E w in spherical coordinates r , Ï , Ï (Sect. B.1). Remembering the transformation
(B.25) of the &nabla;2 operator one obtains
</p>
<p>1
</p>
<p>r
</p>
<p>&part;2(r w)
</p>
<p>&part;r2
+ 1
</p>
<p>r2
ï¿½Ìw + 2m0
</p>
<p>hÌ2
[E &minus; V (r)] w = 0, (13.35)
</p>
<p>where operator ï¿½Ì is defined as
</p>
<p>ï¿½Ì = 1
sin2 Ï
</p>
<p>[
</p>
<p>sin Ï
&part;
</p>
<p>&part;Ï
</p>
<p>(
</p>
<p>sin Ï
&part;
</p>
<p>&part;Ï
</p>
<p>)
</p>
<p>+ &part;
2
</p>
<p>&part;Ï2
</p>
<p>]
</p>
<p>. (13.36)
</p>
<p>The r coordinate is separated by letting w = Ìº(r)Y (Ï ,Ï) in (13.35) and dividing
both sides by w/r2:
</p>
<p>r2
[
</p>
<p>1
</p>
<p>r Ìº
</p>
<p>d2(r Ìº)
</p>
<p>dr2
+ 2m0
</p>
<p>hÌ2
(E &minus; V )
</p>
<p>]
</p>
<p>= &minus; 1
Y
ï¿½ÌY. (13.37)
</p>
<p>Each side of (13.37) must equal the same dimensionless constant, say, c, whence the
original Schr&ouml;dinger equation separates into the pair
</p>
<p>ï¿½ÌY = &minus;c Y ,
[
</p>
<p>&minus; hÌ
2
</p>
<p>2m0
</p>
<p>d2
</p>
<p>dr2
+ Ve(r)
</p>
<p>]
</p>
<p>r Ìº = E r Ìº, Ve = V +
c hÌ2
</p>
<p>2m0 r2
.
</p>
<p>(13.38)
</p>
<p>The first equation in (13.38), called angular equation, does not depend on any
parameter specific to the problem in hand. As a consequence, its eigenvalues c and
eigenfunctions Y can be calculated once and for all. Being the equation&rsquo;s domain
two dimensional, the eigenfunctions Y are expected to depend onto two indices,
say, l, m. After the angular equation is solved, inserting each eigenvalue c into the
second equation of (13.38), called radial equation, provides the eigenvalues and
eigenfunctions of the latter. For the radial equation, the solution depends on the form
</p>
<p>1 To avoid confusion with the azimuthal quantum number m, the particle&rsquo;s mass is indicated with
m0 in the sections dealing with the angular momentum in the quantum case.</p>
<p/>
</div>
<div class="page"><p/>
<p>13.5 Schr&ouml;dinger Equation for a Central Force 237
</p>
<p>of V (r). It is also worth noting the similarity ofVe with its classical counterpart (3.5),
that reads
</p>
<p>Ve = V +
M2
</p>
<p>2m0 r2
, M2 = const. (13.39)
</p>
<p>To tackle the solution of the angular equation ï¿½ÌY = &minus;c Y one associates an opera-
tor Lx , Ly , Lz to each component of the classical angular momentum M = r &and; p,
and another operator L2 to its square modulus M2. The procedure, illustrated in
Sect. 13.6.1, shows that the three operators Lx , Ly , Lz do not commute with each
other, whereas L2 commutes with each of them. Also, it is found that L2 is propor-
tional to ï¿½Ì, specifically, L2 = &minus;hÌ2 ï¿½Ì. In conclusion, the Schr&ouml;dinger equation in
the case of a central force reads
</p>
<p>Hw = E w, H = &minus; hÌ
2
</p>
<p>2mr
</p>
<p>&part;2
</p>
<p>&part;r2
r + L
</p>
<p>2
</p>
<p>2m0 r2
+ V (r). (13.40)
</p>
<p>As the r coordinate does not appear in L2, the latter commutes with H; moreover,
L2 does not depend on time. As a consequence, its expectation value is a constant of
motion (Sect. 10.7). Similarly, Lz commutes with L2 and does not contain r or t , so
it commutes with H as well and its expectation value is also a constant of motion. As
H, L2, and Lz commute with each other, they have a common set of eigenfunctions.
</p>
<p>13.5.1 Angular Part of the Equation
</p>
<p>The conservation of the expectation values of L2 and Lz is the counterpart of the clas-
sical result of the conservation of M2 and Mz (Sect. 2.8). In contrast, the expectation
values of Lx and Ly are not constants of motion. To determine the eigenfunctions w
of H, L2 and Lz it is convenient to solve the eigenvalue equation for Lz first:
</p>
<p>Lzw = Lz w, &minus;i hÌ
&part;w
</p>
<p>&part;Ï
= Lz w, w = v(r ,Ï) exp (iLz Ï/hÌ), (13.41)
</p>
<p>with v yet undetermined. For an arbitrary value of Lz, the exponential part of w is a
multi-valued function of Ï. This is not acceptable because w should not vary when Ï
is changed by integer multiples of 2Ï . A single-valued function is achieved by letting
Lz/hÌ = m, with m an integer. In conclusion, the eigenvalues and eigenfunctions of
Lz are
</p>
<p>Lz = m hÌ, w = v(r ,Ï) exp (imÏ). (13.42)
</p>
<p>Combining (13.42) with (13.36) provides
</p>
<p>ï¿½Ìw = exp (imÏ)
sin2 Ï
</p>
<p>[
</p>
<p>sin Ï
&part;
</p>
<p>&part;Ï
</p>
<p>(
</p>
<p>sin Ï
&part;
</p>
<p>&part;Ï
</p>
<p>)
</p>
<p>&minus;m2
]
</p>
<p>v(r ,Ï). (13.43)</p>
<p/>
</div>
<div class="page"><p/>
<p>238 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>Table 13.1 The lowest-order
spherical harmonics
</p>
<p>Yml Form of the function
</p>
<p>Y 00 1/
&radic;
</p>
<p>4Ï
</p>
<p>Y&minus;11
&radic;
</p>
<p>3/(8Ï ) sin Ï exp ( &minus; i Ï)
Y 01 &minus;
</p>
<p>&radic;
3/(4Ï ) cosÏ
</p>
<p>Y 11 &minus;
&radic;
</p>
<p>3/(8Ï ) sin Ï exp (i Ï)
</p>
<p>This result shows that in (13.40) the factor exp (imÏ) cancels out, so that ï¿½Ì actually
involves the angular coordinate Ï only. This suggests to seek the function v(r ,Ï) by
separation. Remembering that w was originally separated as w = Ìº(r)Y (Ï ,Ï) one
finds
</p>
<p>v(r ,Ï) = Ìº(r)P (Ï), Y (Ï ,Ï) = P (Ï) exp (imÏ). (13.44)
</p>
<p>As the separation transforms ï¿½ÌY = &minus;cY into ï¿½ÌP = &minus;cP, the equation to be solved
for a given integer m reduces to
</p>
<p>1
</p>
<p>sin2 Ï
</p>
<p>[
</p>
<p>sin Ï
d
</p>
<p>dÏ
</p>
<p>(
</p>
<p>sin Ï
d
</p>
<p>dÏ
</p>
<p>)
</p>
<p>&minus;m2
]
</p>
<p>P = &minus;cP. (13.45)
</p>
<p>From L2 = &minus;hÌ2 ï¿½Ì, it follows that the eigenvalue of L2 is Î» = hÌ2 c. The eigenvalues
c of (13.45) are found by the factorization method described in Sect. 13.3.1; they
have the form c = l (l + 1), with l a non-negative integer, called orbital (or total)
angular momentum quantum number. For a given l, the allowed values of m, called
azimuthal (or magnetic) quantum number, are the 2 l + 1 integers &minus;l, . . . , 0, . . . , l.
The details of the eigenvalue calculation are given in Sect. 13.6.2.
</p>
<p>The factorization method provides also the eigenfunctions of L2 and Lz, that are
called spherical harmonics and, as expected, depend on the two indices l, m. The
details of the calculation of the eigenfunctions Yml are given in Sect. 13.6.3. The
lowest-order spherical harmonics are shown in Table 13.1. As the eigenfunctions
fulfill the equations
</p>
<p>L2Yml = hÌ2 l (l + 1)Yml , LzYml = hÌ m Yml , (13.46)
</p>
<p>the only possible results of a measurement of M2 are hÌ2 l (l+1), with l = 0, 1, 2, . . .
and, for a given l, the only possible results of a measurement ofMz are hÌ m, withm =
&minus;l, . . . ,&minus;1, 0, 1, . . . , l. It follows that the only possible results of a measurement
of M are hÌ
</p>
<p>&radic;
l (l + 1). For any l &gt; 0 it is max (|Mz|) = hÌ l &lt; hÌ
</p>
<p>&radic;
l (l + 1) = M;
</p>
<p>as a consequence, for l &gt; 0 the angular momentum M lies on a cone centered on
the z axis. The half amplitude Î± = arccos [m/&radic;l(l + 1)] of such a cone is strictly
positive, showing that the other two components Mx , My can not vanish together
when M ï¿½= 0. A geometrical construction describing the relation between M and
Mz is given in Fig. 13.2. The groups of states corresponding to the orbital quantum
numbers l = 0, 1, 2, 3 are denoted with special symbols and names, that originate
from spectroscopy [7, Chap. 15] and are listed in Table 13.2. For l &ge; 4 the symbols
continue in alphabetical order (&ldquo;g&rdquo;, &ldquo;h&rdquo;, . . . ), while no special names are used.</p>
<p/>
</div>
<div class="page"><p/>
<p>13.5 Schr&ouml;dinger Equation for a Central Force 239
</p>
<p>Fig. 13.2 Geometrical
construction showing the
relation between M and Mz.
The l = 3 is case considered,
whence one finds
m = &minus;3, . . . , 0, . . . , 3 and&radic;
l (l + 1) â 3.46
</p>
<p>&minus;1
</p>
<p>2&minus;
</p>
<p>3&minus;
</p>
<p>= 0m
</p>
<p>Î±
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>z
</p>
<p>Table 13.2 Symbols and
names for the states
corresponding to l = 0, 1, 2, 3 l m Symbol Name
</p>
<p>0 0 s Sharp
</p>
<p>1 &minus;1, 0, 1 p Principal
2 &minus;2, &minus;1, 0, 1, 2 d Diffuse
3 &minus;3, &minus;2, &minus;1, 0, 1, 2, 3 f Fundamental
</p>
<p>13.5.2 Radial Part of the Equation in the Coulomb Case
</p>
<p>To solve the radial part of the Schr&ouml;dinger equation (second and third relation in
(13.38)) one uses the eigenvalue c = l (l + 1) to find
</p>
<p>[
</p>
<p>&minus; hÌ
2
</p>
<p>2m0
</p>
<p>d2
</p>
<p>dr2
+ Ve(r)
</p>
<p>]
</p>
<p>r Ìº(r) = E r Ìº(r), Ve = V +
hÌ2 l (l + 1)
</p>
<p>2m0 r2
. (13.47)
</p>
<p>As anticipated above, the solution of (13.47) depends on the form of V (r). Of
particular interest is the Coulomb potential (3.31), that is considered here in the
attractive case
</p>
<p>V (r) = &minus; Z q
2
</p>
<p>4Ï Îµ0 r
, (13.48)
</p>
<p>with Îµ0 the vacuum permittivity, q &gt; 0 the elementary electric charge, and Z q the
charge whence the central force originates. This form of the potential energy is typical
of the case of an electron belonging to a hydrogen or hydrogen-like atom. As usual,
the arbitrary constant inherent in the definition of the potential energy is such that
limr&rarr;&infin; V = 0. As a consequence, the electron is bound if E &lt; 0 (in other terms,
according to the definition given in Sect. 3.13.6, the classical motion is limited).
</p>
<p>The eigenvalues E of (13.47, 13.48) are found by the factorization method
described in Sect. 13.3.1; they have the form
</p>
<p>E = En = &minus;
m0
</p>
<p>2 hÌ2
</p>
<p>(
Z q2
</p>
<p>4Ï Îµ0
</p>
<p>)2 1
</p>
<p>n2
, (13.49)</p>
<p/>
</div>
<div class="page"><p/>
<p>240 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>where n is an integer, called principal quantum number, fulfilling the relation n &ge;
l + 1. The details of the eigenvalue calculation are given in Sect. 13.6.4. As l &ge; 0,
the minimum value of n is 1. For a given n the possible values of the orbital quantum
number are l = 0, 1, . . . , n&minus; 1; also, as found earlier, for each l the possible values
of the azimuthal quantum number are m = &minus;l, . . . , 0, . . . , l. It follows that, for a
given n the number of different pairs l,m is
</p>
<p>n&minus;1
&sum;
</p>
<p>l=0
(2 l + 1) = n2, (13.50)
</p>
<p>namely, each eigenvalue En of the energy corresponds to n2 possible combinations2
</p>
<p>of the eigenvalues of M and Mz. As for the radial part of the equation, the factor-
ization method provides also the eigenfunctions of (13.47); the details are given in
Sect. 13.6.5.
</p>
<p>13.6 Complements
</p>
<p>13.6.1 Operators Associated to Angular Momentum
</p>
<p>Consider the classical angular momentum M = r&and;p (Sect. 2.6), whose components
in rectangular coordinates are given by (2.38), namely,
</p>
<p>Mx = y pz &minus; z py , My = z px &minus; x pz, Mz = x py &minus; y px . (13.51)
</p>
<p>The operators corresponding to (13.51) are
â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>Lx = &minus;i hÌ (y &part;/&part;z &minus; z &part;/&part;y)
Ly = &minus;i hÌ (z &part;/&part;x &minus; x &part;/&part;z)
Lz = &minus;i hÌ (x &part;/&part;y &minus; y &part;/&part;x)
</p>
<p>(13.52)
</p>
<p>It is easily found that Lx , Ly , Lz are Hermitean and fulfill the relations
â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>Lx Ly &minus; Ly Lx = i hÌLz
Ly Lz &minus; Lz Ly = i hÌLx
Lz Lx &minus; Lx Lz = i hÌLy
</p>
<p>(13.53)
</p>
<p>namely, Lx , Ly , Lz do not commute with each other. Left multiplying the third
relation in (13.53) by Lx and the second one by Ly provides, respectively,
</p>
<p>L2x Lz = Lx Lz Lx &minus; i hÌLx Ly , L2y Lz = Ly Lz Ly + i hÌLy Lx . (13.54)
</p>
<p>2 The actual degree of degeneracy of En is 2 n2, where factor 2 is due to spin (Sect. 15.5.1).</p>
<p/>
</div>
<div class="page"><p/>
<p>13.6 Complements 241
</p>
<p>Similarly, right multiplying the third relation in (13.53) by Lx and the second one
by Ly ,
</p>
<p>Lz L
2
x = Lx Lz Lx + i hÌLy Lx , Lz L2y = Ly Lz Ly &minus; i hÌLx Ly . (13.55)
</p>
<p>The operator associated to M2 = M2x +M2y +M2z is L2 = L2x + L2y + L2z whence,
using (13.54, 13.55),
</p>
<p>L2 Lz &minus; Lz L2 = (L2x + L2y) Lz &minus; Lz (L2x + L2y) = 0. (13.56)
</p>
<p>Similarly,
</p>
<p>L2 Lx &minus; Lx L2 = 0, L2 Ly &minus; Ly L2 = 0. (13.57)
</p>
<p>In conclusion, the components Lx , Ly , Lz do not commute with each other, while
the square modulus of the angular momentum commutes with any single component
of it. To check whether L2 or any of the components Lx , Ly , Lz commute with the
Hamiltonian operator of a central force, it is necessary to express all operators in
spherical coordinates. To this purpose, using Lz by way of example, one finds
</p>
<p>&minus;Lz
i hÌ
</p>
<p>= x &part;
&part;y
</p>
<p>&minus; y &part;
&part;x
</p>
<p>= r sin Ï cosÏ &part;
&part;y
</p>
<p>&minus; r sin Ï sin Ï &part;
&part;x
</p>
<p>. (13.58)
</p>
<p>The partial derivatives &part;/&part;x and &part;/&part;y in terms of the spherical coordinates are
extracted from (B.4); in particular, the first one reads &part;/&part;x = sin Ï cosÏ &part;/&part;r +
(1/r) cosÏ cosÏ &part;/&part;Ï &minus; (1/r) ( sin Ï/ sin Ï) &part;/&part;Ï, while the expression of &part;/&part;y
is obtained from that of &part;/&part;x by replacing cosÏ with sin Ï and sin Ï with &minus; cosÏ.
When such expressions of the partial derivatives are used within (13.58), several
terms cancel out to finally yield the relation
</p>
<p>Lz = &minus;i hÌ
&part;
</p>
<p>&part;Ï
(13.59)
</p>
<p>which, consistently with the classical one, Mz = pÏ (Sect. 2.8), shows that the
operator associated to the z component of the angular momentum is conjugate to the
generalized coordinate Ï. The quantum relation can thus be derived directly from
the classical one by letting Lz = pÌÏ = &minus;i hÌ &part;/&part;Ï. As already noted in Sect. 2.8, the
remaining components of Mx , My are not conjugate momenta. The expression of Lx
in spherical coordinates reads
</p>
<p>Lx = i hÌ
(
</p>
<p>sin Ï
&part;
</p>
<p>&part;Ï
+ cosÏ
</p>
<p>sin Ï
cosÏ
</p>
<p>&part;
</p>
<p>&part;Ï
</p>
<p>)
</p>
<p>, (13.60)
</p>
<p>while that of Ly is obtained from (13.60) by replacing cosÏ with sin Ï and sin Ï
with &minus; cosÏ. Combining the above finding, one calculates the expression of L2 =
L2x + L2y + L2z , that turns out to be
</p>
<p>L2 = &minus; hÌ
2
</p>
<p>sin2 Ï
</p>
<p>[
</p>
<p>sin Ï
&part;
</p>
<p>&part;Ï
</p>
<p>(
</p>
<p>sin Ï
&part;
</p>
<p>&part;Ï
</p>
<p>)
</p>
<p>+ &part;
2
</p>
<p>&part;Ï2
</p>
<p>]
</p>
<p>= &minus;hÌ2 ï¿½Ì. (13.61)</p>
<p/>
</div>
<div class="page"><p/>
<p>242 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>13.6.2 Eigenvalues of the Angular Equation
</p>
<p>The solution of the angular equation is found by the factorization method described
in Sect. 13.3.1. Remembering that Lz and L2 commute, the whole eigenfunction
Y = P (Ï) exp (imÏ), introduced in Sect. 13.5 and common to both operators, will
be used here. The following hold:
</p>
<p>LzY = Lz Y , L2Y = Î» Y , (13.62)
</p>
<p>with Lz = m hÌ, m an integer. Applying the operator Lx &plusmn; i Ly to the first equation
in (13.62) yields
</p>
<p>(
</p>
<p>Lx &plusmn; i Ly
)
</p>
<p>LzY = m hÌ
(
</p>
<p>Lx &plusmn; i Ly
)
</p>
<p>Y , where the upper (lower)
signs hold together. Due to the commutation rules (13.53) the left hand side of the
above transforms into
</p>
<p>(
</p>
<p>LzLx &minus; i hÌLy
)
</p>
<p>Y &plusmn; i
(
</p>
<p>LzLy + i hÌLx
)
</p>
<p>Y = Lz
(
</p>
<p>Lx &plusmn; i Ly
)
</p>
<p>Y â hÌ
(
</p>
<p>Lx &plusmn; i Ly
)
</p>
<p>Y ,
</p>
<p>whence the first eigenvalue equation in (13.62) becomes
</p>
<p>Lz
(
</p>
<p>Lx &plusmn; i Ly
)
</p>
<p>Y = (m&plusmn; 1) hÌ
(
</p>
<p>Lx &plusmn; i Ly
)
</p>
<p>Y. (13.63)
</p>
<p>Iterating the above reasoning shows that, if Y is an eigenfunction of Lz belonging to
the eigenvalue m hÌ, then (Lx + i Ly)Y , (Lx + i Ly)2Y , . . . are also eigenfunctions
of Lz which belong, respectively, to (m+ 1) hÌ, (m+ 2) hÌ, . . . , and so on. Similarly,
(Lx&minus;i Ly)Y , (Lx&minus;i Ly)2Y , . . . are also eigenfunctions of Lz belonging, respectively,
to (m&minus; 1) hÌ, (m&minus; 2) hÌ, . . . , and so on. At the same time, due to the commutativity
of L2 with Lx and Ly , it is
</p>
<p>(
</p>
<p>Lx &plusmn; i Ly
)
</p>
<p>L2Y = L2
(
</p>
<p>Lx &plusmn; i Ly
)
</p>
<p>Y = Î»
(
</p>
<p>Lx &plusmn; i Ly
)
</p>
<p>Y , (13.64)
</p>
<p>showing that (Lx &plusmn; i Ly)Y is also an eigenfunction of L2, belonging to the same
eigenvalue as Y . By induction, (Lx &plusmn; i Ly)2Y , . . . are also eigenfunctions of L2,
belonging to the same eigenvalue as Y . To summarize, if Y = P (Ï) exp (imÏ)
is an eigenfunction common to operators Lz and L2, belonging to the eigenvalues
Lz = m hÌ and Î», respectively, then,
1. (Lx + i Ly)Y is another eigenfunction of L2 still belonging to Î», and is also
</p>
<p>an eigenfunction of Lz belonging to (m + 1) hÌ. Similarly, (Lx + i Ly)2Y is still
another eigenfunction of L2 belonging to Î», and is also an eigenfunction of Lz
belonging to (m+ 2) hÌ, and so on.
</p>
<p>2. (Lx &minus; i Ly)Y is another eigenfunction of L2 still belonging to Î», and is also
an eigenfunction of Lz belonging to (m &minus; 1) hÌ. Similarly, (Lx &minus; i Ly)2Y is still
another eigenfunction of L2 belonging to Î», and is also an eigenfunction of Lz
belonging to (m&minus; 2) hÌ, and so on.
</p>
<p>By this reasoning, starting from a given pair Î», Y it seems possible to construct
as many degenerate eigenfunctions of L2 as we please. This, however, leads to</p>
<p/>
</div>
<div class="page"><p/>
<p>13.6 Complements 243
</p>
<p>unbounded eigenvalues of Lz, which are not admissible as shown below. As a con-
sequence, the procedure depicted here can be applied only a finite number of times.
To demonstrate that the eigenvalues of Lz are bounded one starts from the relation
L2 = L2x + L2y + L2z and from a given pair Î», Y . As Y is also an eigenfunction
of Lz belonging to, say, m hÌ, an application of L2 to Y followed by a left scalar
multiplication by Y &lowast; yields, thanks to (13.62),
</p>
<p>Î»&minus;m2hÌ2 = ãLxY |LxY ã + ãLyY |LyY ããY |Y ã &ge; 0, (13.65)
</p>
<p>where the hermiticity of Lx , Ly has been exploited. Inequality (13.65) provides the
upper bound for |m|. To find the acceptable values of m one defines m+ = max(m),
and lets Y+ be an eigenfunction of L2 and Lz belonging to Î» and m+ hÌ, respectively.
From (13.63) one obtains Lz (Lx + i Ly)Y+ = (m+ + 1) hÌ (Lx + i Ly)Y+ but, as the
eigenvalue (m+ + 1)hÌ is not acceptable, it must be (Lx + i Ly)Y+ = 0. Similarly,
letting m&minus; = min(m), and letting Y&minus; be an eigenfunction of L2 and Lz belonging
to Î» and m&minus; hÌ, respectively, it must be (Lx &minus; i Ly)Y&minus; = 0. Due to the commutation
rules it is (Lx &minus; i Ly) (Lx + i Ly) = L2x + L2y &minus; hÌLz, whence
</p>
<p>L2 = (Lx &minus; i Ly) (Lx + i Ly) + hÌLz + L2z . (13.66)
</p>
<p>Application of (13.66) to Y+ and Y&minus; yields
â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>L2Y+ =
(
</p>
<p>L2z + hÌLz
)
</p>
<p>Y+ = hÌ2 m+
(
</p>
<p>m+ + 1
)
</p>
<p>Y+
</p>
<p>L2Y&minus; =
(
</p>
<p>L2z &minus; hÌLz
)
</p>
<p>Y&minus; = hÌ2 m&minus;
(
</p>
<p>m&minus; &minus; 1
)
</p>
<p>Y&minus;
(13.67)
</p>
<p>By construction, Y+ and Y&minus; belong to the same eigenvalue of L2; as a consequence
it must be m+
</p>
<p>(
</p>
<p>m+ + 1
)
</p>
<p>= m&minus;
(
</p>
<p>m&minus; &minus; 1
)
</p>
<p>. A possible integer solution of the above
is m&minus; = m+ + 1 which, however, is not acceptable because m+ = max(m). The
only acceptable solution left is m&minus; = &minus;m+. In conclusion, letting l = m+ (so that
m&minus; = &minus;l) and using (13.67), the eigenvalues of L2 take the form
</p>
<p>Î» = hÌ2 l (l + 1), (13.68)
</p>
<p>with l a non-negative integer. For a given l, the allowed values of m are the 2 l + 1
integers &minus;l, . . . , 0, . . . , l.
</p>
<p>13.6.3 Eigenfunctions of the Angular Equation
</p>
<p>Due to the findings illustrated in Sect. 13.6.2, the eigenfunctions of ï¿½Ì, whose form is
Y (Ï ,Ï) = P (Ï) exp (imÏ), depend on the two indices l,m and, for this reason, will
be indicated with Yml . In particular, the eigenfunction Y
</p>
<p>+ introduced in Sect. 13.6.2,
which belongs to l = max(m) and fulfills the equation (Lx + i Ly)Y = 0, will be</p>
<p/>
</div>
<div class="page"><p/>
<p>244 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>indicated with Y ll . Similarly, as P depends on l and may depend on m as well, it
will be indicated with Pml . The eigenfunction Y
</p>
<p>l
l is readily found by solving the
</p>
<p>first-order equation (Lx + i Ly)Y ll = 0, where operator Lx is expressed in terms of
Ï, Ï through (13.60), and Ly is obtained from (13.60) by replacing cosÏ with sin Ï
and sin Ï with &minus; cosÏ. After eliminating the factor hÌ exp [i (l + 1)Ï] one finds a
differential equation for P ll , that reads
</p>
<p>dP ll
dÏ
</p>
<p>&minus; l cosÏ
sin Ï
</p>
<p>P ll = 0,
1
</p>
<p>P ll
</p>
<p>dP ll
dÏ
</p>
<p>= l
sin Ï
</p>
<p>d sin Ï
</p>
<p>dÏ
. (13.69)
</p>
<p>In conclusion it is found, with a an arbitrary constant,
</p>
<p>P ll = a (sin Ï)l , Y ll = a exp (i l Ï) (sin Ï)l . (13.70)
Then, remembering the discussion of Sect. 13.6.2, the remaining 2 l eigenfunctions
Y l&minus;1l , . . . ,Y
</p>
<p>0
l , . . . ,Y
</p>
<p>&minus;l
l are found by successive applications of
</p>
<p>Lx &minus; i Ly = &minus;hÌ exp ( &minus; i Ï)
(
</p>
<p>&part;
</p>
<p>&part;Ï
&minus; i cosÏ
</p>
<p>sin Ï
</p>
<p>&part;
</p>
<p>&part;Ï
</p>
<p>)
</p>
<p>, (13.71)
</p>
<p>with the help of the auxiliary relations &minus;i &part;Y ll /&part;Ï = l Y ll and
(
</p>
<p>&part;
</p>
<p>&part;Ï
+ l cosÏ
</p>
<p>sin Ï
</p>
<p>)
</p>
<p>Y ll =
&part;[( sin Ï)l Y ll ]/&part;Ï
</p>
<p>( sin Ï)l
= a exp (i l Ï)
</p>
<p>( sin Ï)l
d
</p>
<p>dÏ
(sin Ï)2l . (13.72)
</p>
<p>In fact, combining Lz
[(
</p>
<p>Lx &minus; i Ly
)
</p>
<p>Yml
]
</p>
<p>= (m &minus; 1) hÌ
[(
</p>
<p>Lx &minus; i Ly
)
</p>
<p>Yml
]
</p>
<p>with
Lz Y
</p>
<p>m
l = m hÌ Yml provides the recursive relation Ym&minus;1l =
</p>
<p>(
</p>
<p>Lx &minus; i Ly
)
</p>
<p>Yml . In
particular, letting m = l, m = l &minus; 1, . . . yields
</p>
<p>Y l&minus;1l =
(
</p>
<p>Lx &minus; i Ly
)
</p>
<p>Y ll , Y
l&minus;2
l =
</p>
<p>(
</p>
<p>Lx &minus; i Ly
)
</p>
<p>Y l&minus;1l , . . . (13.73)
</p>
<p>where Y ll is given by (13.70) while
</p>
<p>(
</p>
<p>Lx &minus; i Ly
)
</p>
<p>Y ll = Y l&minus;1l = a
exp [i (l &minus; 1)Ï]
</p>
<p>( sin Ï)l&minus;1
&minus;hÌ
</p>
<p>sin Ï
</p>
<p>d
</p>
<p>dÏ
(sin Ï)2l . (13.74)
</p>
<p>The denominator ( sin Ï)l in the above has been split into two parts for the sake of
convenience. The next functions are found from
</p>
<p>Y l&minus;s&minus;1l =
(
</p>
<p>Lx &minus; i Ly
)
</p>
<p>Y l&minus;sl =
&minus;hÌ
</p>
<p>exp (i Ï)
</p>
<p>[
&part;
</p>
<p>&part;Ï
+ (l &minus; s) cosÏ
</p>
<p>sin Ï
</p>
<p>]
</p>
<p>Y l&minus;sl =
</p>
<p>= exp ( &minus; i Ï)
( sin Ï)l&minus;s&minus;1
</p>
<p>&minus;hÌ
sin Ï
</p>
<p>&part;
</p>
<p>&part;Ï
</p>
<p>[
</p>
<p>( sin Ï)l&minus;s Y l&minus;sl
]
</p>
<p>, (13.75)
</p>
<p>where the product ( sin Ï)l&minus;s Y l&minus;sl is taken from the previously-calculated expression
of Y l&minus;sl . Iterating the procedure yields
</p>
<p>Y l&minus;sl = a
exp [i (l &minus; s)Ï]
</p>
<p>( sin Ï)l&minus;s
&minus;hÌ
</p>
<p>sin Ï
</p>
<p>d
</p>
<p>dÏ
. . .
</p>
<p>&minus;hÌ
sin Ï
</p>
<p>d
</p>
<p>dÏ
ï¸¸ ï¸·ï¸· ï¸¸
</p>
<p>s times
</p>
<p>( sin Ï)2l . (13.76)</p>
<p/>
</div>
<div class="page"><p/>
<p>13.6 Complements 245
</p>
<p>As Y l&minus;sl is a solution of the linear, homogeneous equations LzY = Lz Y and L2Y =
Î» Y , the constanta hÌs that builds up in the derivation can be dropped. Lettingm = l&minus;s
one finds
</p>
<p>Yml = clm
exp (imÏ)
</p>
<p>( sin Ï)m
&minus;1
</p>
<p>sin Ï
</p>
<p>d
</p>
<p>dÏ
. . .
</p>
<p>&minus;1
sin Ï
</p>
<p>d
</p>
<p>dÏ
ï¸¸ ï¸·ï¸· ï¸¸
</p>
<p>l&minus;m times
</p>
<p>( sin Ï)2l , (13.77)
</p>
<p>where the coefficient clm has been added for normalization purposes. One may recast
(13.77) in a more compact form by letting Î¶ = cosÏ , whence &minus;1 &le; Î¶ &le; 1 and
dÎ¶ = &minus; sin Ï dÏ . As a consequence,
</p>
<p>Yml = clm
exp (imÏ)
</p>
<p>(1 &minus; Î¶ 2)m/2
dl&minus;m
</p>
<p>dÎ¶ l&minus;m
(1 &minus; Î¶ 2)l . (13.78)
</p>
<p>The eigenfunctions Yml are square integrable and mutually orthogonal [78, App.
B.10]. To examine some of their properties it is convenient to introduce some special
functions; to begin with, the associate Legendre functions are defined in the interval
&minus;1 &le; Î¶ &le; 1 by
</p>
<p>Pml (Î¶ ) =
( &minus; 1)m
</p>
<p>2l l ! (1 &minus; Î¶
2)m/2
</p>
<p>dl+m
</p>
<p>dÎ¶ l+m
(Î¶ 2 &minus; 1)l , (13.79)
</p>
<p>with l = 0, 1, . . . and, for each l, m = &minus;l, . . . ,&minus;1, 0, 1, . . . , l. As (1 &minus; Î¶ 2)m/2
and (Î¶ 2 &minus; 1)l are even functions of Î¶ , Pml is even (odd) if l + m is even (odd):
Pml ( &minus; Î¶ ) = ( &minus; 1)l+m Pml (Î¶ ). Furthermore, it is
</p>
<p>Pml (Î¶ ) = ( &minus; 1)m
(l +m) !
(l &minus;m) ! P
</p>
<p>&minus;m
l . (13.80)
</p>
<p>Replacing m with &minus;m in (13.79) shows that Yml is proportional to P&minus;ml which, in
turn, is proportional to Pml due to (13.80). In conclusion, using Î¶ = cosÏ ,
</p>
<p>Yml (Ï ,Ï) = clm exp (imÏ)Pml ( cosÏ), (13.81)
</p>
<p>with 0 &le; Ï &le; Ï and 0 &le; Ï &le; 2Ï . As for the indices it is l = 0, 1, . . . and m =
&minus;l, . . . ,&minus;1, 0, 1, . . . , l. The functions Yml defined by (13.81) are called spherical
harmonics. Combining the definition of Yml with the properties of P
</p>
<p>m
l shown above
</p>
<p>yieldsY&minus;ml = (&minus;1)m (Yml )&lowast;. Note thatYml andY&minus;ml are linearly independent, whereas
Pml and P
</p>
<p>&minus;m
l are not. Letting
</p>
<p>clm =
[
</p>
<p>(2l + 1) (l &minus;m) !
4Ï (l +m) !
</p>
<p>]1/2
</p>
<p>, (13.82)
</p>
<p>the set made of the spherical harmonics is orthonormal, namely,
</p>
<p>&int; 2Ï
</p>
<p>0
</p>
<p>&int; Ï
</p>
<p>0
</p>
<p>(
</p>
<p>Y
Î¼
Î»
</p>
<p>)&lowast;
Yml dÏ dÏ =
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>1, Î» = l and Î¼ = m
0, otherwise
</p>
<p>(13.83)</p>
<p/>
</div>
<div class="page"><p/>
<p>246 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>and complete (Sect. 8.4.3), namely,
</p>
<p>F (Ï ,Ï) =
&infin;
&sum;
</p>
<p>l=0
</p>
<p>l
&sum;
</p>
<p>m=&minus;l
alm Y
</p>
<p>m
l (Ï ,Ï), alm =
</p>
<p>&int; 2Ï
</p>
<p>0
</p>
<p>&int; Ï
</p>
<p>0
</p>
<p>(
</p>
<p>Yml
)&lowast;
</p>
<p>F dÏ dÏ, (13.84)
</p>
<p>where F is a sufficiently regular function of the angles. The inner sum of (13.84),
</p>
<p>Yl(Ï ,Ï) =
l
</p>
<p>&sum;
</p>
<p>m=&minus;l
alm Y
</p>
<p>m
l (Ï ,Ï) (13.85)
</p>
<p>is also called general spherical harmonic of order l, whereas the special case m = 0
of the associate Legendre function,
</p>
<p>P 0l (Î¶ ) =
1
</p>
<p>2l l !
dl
</p>
<p>dÎ¶ l
(Î¶ 2 &minus; 1)l , (13.86)
</p>
<p>is a polynomial of degree l called Legendre polynomial.
</p>
<p>13.6.4 Eigenvalues of the Radial Equation&mdash;Coulomb Case
</p>
<p>The caseE &lt; 0 of the radial Eq. (13.47) is considered here, corresponding to a limited
motion. As a consequence, the eigenvectors are expected to depend on a discrete
index, and the eigenfunctions are expected to be square integrable. Calculating the
derivative and multiplying both sides of (13.47) by &minus;2m0/(hÌ2 r) yields
</p>
<p>d2Ìº
</p>
<p>dr2
+ 2
</p>
<p>r
</p>
<p>dÌº
</p>
<p>dr
&minus; 2m0
</p>
<p>hÌ2
Ve Ìº +
</p>
<p>2m0
hÌ2
</p>
<p>E Ìº = 0. (13.87)
</p>
<p>To proceed one scales the independent variable by multiplying both sides of (13.87)
by a2, where a is a length. The term involving Ve becomes
</p>
<p>&minus;a2 2m0
hÌ2
</p>
<p>Ve Ìº =
[
</p>
<p>2m0 Z q2 a
</p>
<p>4Ï Îµ0 hÌ2 (r/a)
&minus; l (l + 1)
</p>
<p>(r/a)2
</p>
<p>]
</p>
<p>Ìº, (13.88)
</p>
<p>where both fractions in brackets are dimensionless. As a may be chosen arbitrarily,
it is convenient to select for it a value that makes the first fraction equal to 2/(r/a),
namely,
</p>
<p>a = 4Ï Îµ0 hÌ
2
</p>
<p>m0 Z q2
. (13.89)
</p>
<p>As a consequence, the term involving E becomes
</p>
<p>a2
2m0
hÌ2
</p>
<p>E Ìº = Î» Ìº, Î» =
(
</p>
<p>4Ï Îµ0
Z q2
</p>
<p>)2 2 hÌ2
</p>
<p>m0
E. (13.90)</p>
<p/>
</div>
<div class="page"><p/>
<p>13.6 Complements 247
</p>
<p>Adopting the dimensionless variable x = r/a and using the relations a2 d2Ìº/dr2 =
d2Ìº/dx2, (2 a2/r) dÌº/dr = (2/x) dÏ/dx yields the radial equation in scaled form,
</p>
<p>d2Ìº
</p>
<p>dx2
+ 2
</p>
<p>x
</p>
<p>dÌº
</p>
<p>dx
+
</p>
<p>[
2
</p>
<p>x
&minus; l (l + 1)
</p>
<p>x2
</p>
<p>]
</p>
<p>Ìº + Î» Ìº = 0. (13.91)
</p>
<p>The range of the independent variable is 0 &le; x &lt; &infin;, so the equation has a double
pole in the origin: it is necessary to select solutions that vanish in the origin in such
a way as to absorb the pole (more on this in Sect. 13.6.5). The replacement Ìº = Ï/x
gives (13.91) the simpler form
</p>
<p>d2Ï
</p>
<p>dx2
+
</p>
<p>[
2
</p>
<p>x
&minus; l (l + 1)
</p>
<p>x2
</p>
<p>]
</p>
<p>Ï + Î» Ï = 0, (13.92)
</p>
<p>which is identical to (13.2). The factorization of (13.92) is then accomplished follow-
ing the scheme shown in Sect. 13.3, and is based upon the function gl = l/x &minus; 1/l;
in this case operators (13.10) and parameter (13.9) read, respectively,
</p>
<p>A+l =
l
</p>
<p>x
&minus; 1
</p>
<p>l
+ d
</p>
<p>dx
, A&minus;l =
</p>
<p>l
</p>
<p>x
&minus; 1
</p>
<p>l
&minus; d
</p>
<p>dx
, Ll = &minus;1/l2. (13.93)
</p>
<p>The latter depends only on l and fulfills the relationLn+1 &gt; Ll+1, l = 0, 1, . . . , n&minus;1.
As a consequence, remembering the second relation in (13.90), the eigenvalues3
</p>
<p>Î» = Î»n = Ln+1 of (13.92) and those of (13.87) are, respectively,
</p>
<p>Î»n = &minus;
1
</p>
<p>(n+ 1)2 , En = &minus;
(
</p>
<p>Z q2
</p>
<p>4Ï Îµ0
</p>
<p>)2
m0/(2 hÌ2)
</p>
<p>(n+ 1)2 , n = 0, 1, . . . . (13.94)
</p>
<p>13.6.5 Eigenfunctions of the Radial Equation&mdash;Coulomb Case
</p>
<p>The eigenfunction corresponding to l = n is found by applying (13.14). As the
eigenfunction is indicated here with Ïnn, one must solve A
</p>
<p>&minus;
n+1Ïnn = 0, namely,
</p>
<p>using (13.93), [(n+ 1)/x &minus; 1/(n+ 1) &minus; d/dx] Ïnn = 0, whose solution is
</p>
<p>Ïnn = cnn xn+1 exp
(
</p>
<p>&minus; x
n+ 1
</p>
<p>)
</p>
<p>, n = 0, 1, . . . , (13.95)
</p>
<p>which vanishes both in the origin and at infinity, this fulfilling the requirements stated
in Sect. 13.6.4. The eigenfunction (13.95) is also square integrable with, from (C.88,
C.90),
</p>
<p>1
</p>
<p>c2nn
=
</p>
<p>&int; &infin;
</p>
<p>0
x2n+2 exp
</p>
<p>(
</p>
<p>&minus; 2x
n+ 1
</p>
<p>)
</p>
<p>dx = (2n+ 2) !
(
n+ 1
</p>
<p>2
</p>
<p>)2n+3
. (13.96)
</p>
<p>3 In (13.49) a more convenient notation is used, obtained from (13.94) through the replacements
n+ 1 &larr; n&prime; &larr; n, with n&prime; = 1, 2, . . . .</p>
<p/>
</div>
<div class="page"><p/>
<p>248 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>Combining the first definition in (13.21) with the third relation in (13.93), the
auxiliary operator B+nl reads
</p>
<p>B+nl =
l (n+ 1)&radic;
</p>
<p>(n+ 1 &minus; l)(n+ 1 + l) A
+
l . (13.97)
</p>
<p>Then, from the second of (13.24), the normalized eigenfunctions corresponding to
l &lt; n are found recursively from
</p>
<p>Ïn,n&minus;1 = B+nnÏnn, Ïn,n&minus;2 = B+n,n&minus;1Ïn,n&minus;1, . . . (13.98)
</p>
<p>The last eigenfunction found by the recursive procedure is Ïn0 = B+n1Ïn1 as expected.
In fact, a further iteration would not yield an eigenfunction because B+n0 = 0.
</p>
<p>The eigenfunction of (13.87) corresponding to the lowest total energy Emin =
E(n = 0) is found by combining (13.95, 13.96) with Ï = Ìº/x and x = r/a, this
yielding Ìº(r) = (1/2) exp (&minus;r/a). There is only one spherical harmonic compatible
with this energy eigenvalue, specifically, Y 00 = 1/
</p>
<p>&radic;
4Ï (Table 13.1). Thus, the
</p>
<p>product w(Emin) = (c/2) exp ( &minus; r/a)/
&radic;
</p>
<p>4Ï , with c a normalization constant, is
the eigenfunction of the Schr&ouml;dinger Eq. (13.35) corresponding to the lowest total
energy. The normalization constant is necessary because Ìº is obtained from scaling
another function Ï , originally normalized to unity. Taking the Jacobian determinant
J = r2 sin Ï from (B.3) one finds
</p>
<p>1
</p>
<p>c2
= 1
</p>
<p>16Ï
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>&int; Ï
</p>
<p>0
</p>
<p>&int; 2Ï
</p>
<p>0
exp
</p>
<p>(
</p>
<p>&minus;2 r
a
</p>
<p>)
</p>
<p>r2 sin Ï dr dÏ dÏ = a
3
</p>
<p>16
, (13.99)
</p>
<p>whence w(Emin) = exp ( &minus; r/a)/
&radic;
Ï a3.
</p>
<p>13.6.6 Transmission Matrix
</p>
<p>The one-dimensional, time-independent Schr&ouml;dinger Eq. (11.28) is solvable ana-
lytically in a limited number of cases, some of which have been illustrated in the
sections above. When the analytical solution is not known one must resort to ap-
proximate methods; an example is given here, with reference to a finite domain
0 &le; x &le; s. The latter is tessellated by selecting N points x1 &lt; x2 &lt; . . . &lt; xN ,
internal to the domain, called nodes. The boundaries of the domain are indicated with
0 = x0 &lt; x1 and s = xN+1 &gt; xN . The segment bounded by xi and xi+1 is indicated
with hi+1 and is called element. The same symbol indicates the length of the element,
hi+1 = xi+1&minus;xi . Finally, a subdomainï¿½i , called cell, is associated to each node. For
the internal nodes x1, . . . , xN the cell is bounded by xi &minus; hi/2 and xi + hi+1/2. The
same symbol is used to indicate also the cell length, ï¿½i = (hi + hi+1)/2 (Fig. 13.3).
The left boundary x0 is associated to the cell ï¿½0 of length h1/2 placed on the right
of x0, while the right boundary xN+1 is associated to the cell ï¿½N+1 of length hN+1/2
placed on the left of xN+1.</p>
<p/>
</div>
<div class="page"><p/>
<p>13.6 Complements 249
</p>
<p>Fig. 13.3 Illustration of the
concepts of node, element,
and cell (Sect. 13.6.6)
</p>
<p>i 1+hh i
</p>
<p>Î© i
x i&minus;i 1x i 1+x
</p>
<p>The approximation methods that are applicable to a given tessellation are numer-
ous. The method depicted in this section replaces the coefficient q(x) of (11.28) over
each element hi with an approximating function qi(x) such that the solution wi(x) to
(11.28) over hi can be found analytically. The approximating functions qi may differ
from an element to another, this yielding different analytical solutions. Then, the
continuity of the analytical solutions and their derivatives is imposed at each node;
finally, the same continuity is imposed at the boundaries 0 and s, where the form of
the wave function is supposed to be known.
</p>
<p>To proceed, consider an internal node i = 1, 2, . . . ,N and the two elements hi ,
hi+1 adjacent to it. The solutions wi , wi+1 over the two elements is expressed in
terms of the fundamental solutions u, v (compare with Sect. 11.4):
</p>
<p>wi(x) = aui ui(x) + avi vi(x), wi+1(x) = aui+1ui+1(x) + avi+1vi+1(x), (13.100)
</p>
<p>with aui , a
v
i , a
</p>
<p>u
i+1, a
</p>
<p>v
i+1 undetermined constants. The fundamental solutions fulfill the
</p>
<p>boundary conditions
</p>
<p>ui+1(xi) = 1, u&prime;i+1(xi) = 0, vi+1(xi) = 0, v&prime;i+1(xi) = 1, (13.101)
</p>
<p>i = 1, 2, . . . ,N , where primes indicate derivatives. Imposing the continuity of w, w&prime;
at xi yields
</p>
<p>aui+1 = aui ui(xi) + avi vi(xi), avi+1 = aui u&prime;i(xi) + avi v&prime;i(xi). (13.102)
</p>
<p>Letting
</p>
<p>ai =
</p>
<p>â¡
</p>
<p>â£
aui
</p>
<p>avi
</p>
<p>â¤
</p>
<p>â¦ , Ni =
</p>
<p>â¡
</p>
<p>â£
ui(xi) vi(xi)
</p>
<p>u&prime;i(xi) v
&prime;
i(xi)
</p>
<p>â¤
</p>
<p>â¦ , (13.103)
</p>
<p>the relations (13.102) take the form
</p>
<p>ai+1 = Ni ai . (13.104)
</p>
<p>Matrix Ni is known by construction, and provides the link between the unknown
vectors ai and ai+1. Vector ai belongs to element hi only, whereas matrix Ni belongs
to element hi (due to ui , vi) and also to node xi (because ui , vi are calculated at xi).
Iterating (13.104) yields
</p>
<p>aN+1 = NIa1, NI = NNNN&minus;1 . . .N2N1. (13.105)</p>
<p/>
</div>
<div class="page"><p/>
<p>250 13 Other Examples of the Schr&ouml;dinger Equation
</p>
<p>Remembering the discussion in Sect. A.12 one finds detNi = W = 1, whence
detNI = detNN . . . detN1 = 1. Now it is necessary to link the solution over
h1 with that over x &lt; 0, which is given by (11.30). Although the two functions
exp (&plusmn; i kL x) in the latter are not fundamental solutions, it is convenient to keep the
form (11.30) because a2/a1 provides the information about the reflection coefficient
directly. Letting
</p>
<p>aL =
</p>
<p>â¡
</p>
<p>â£
a1
</p>
<p>a2
</p>
<p>â¤
</p>
<p>â¦ , NL =
</p>
<p>â¡
</p>
<p>â£
1 1
</p>
<p>i kL &minus;i kL
</p>
<p>â¤
</p>
<p>â¦ , (13.106)
</p>
<p>the continuity of w and w&prime; at x = 0 yields a1 = NL aL. Similarly, it is necessary to
link the solution over hN+1 with that over x &gt; s, which is given by (11.31). Again,
the two functions exp (&plusmn; i kR x) in the latter are not fundamental solutions, however,
they are kept here because a5/a1 provides the information about the transmission
coefficient directly. Letting
</p>
<p>aR =
</p>
<p>â¡
</p>
<p>â£
a5
</p>
<p>a6
</p>
<p>â¤
</p>
<p>â¦ , NR =
</p>
<p>â¡
</p>
<p>â£
exp (i kR s) exp ( &minus; i kR s)
</p>
<p>i kR exp (i kR s) &minus;i kR exp ( &minus; i kR s)
</p>
<p>â¤
</p>
<p>â¦ , (13.107)
</p>
<p>the continuity of w and w&prime; at x = s yields NR aR = NN+1 aN+1, with detNN+1 = 1,
detNL = &minus;2 i kL, detNR = &minus;2 i kR . Combining the relations found so far,
</p>
<p>aR = N aL, N = N&minus;1R NN+1 NI NL, (13.108)
</p>
<p>where
</p>
<p>N&minus;1R =
</p>
<p>â¡
</p>
<p>â£
exp ( &minus; i kR s)/2 exp ( &minus; i kR s)/(2 i kR)
</p>
<p>exp (i kR s)/2 i exp (i kR s)/(2 kR)
</p>
<p>â¤
</p>
<p>â¦ , det N&minus;1R = &minus;
1
</p>
<p>2 i kR
.
</p>
<p>(13.109)
</p>
<p>whence detN = detN&minus;1R detNN+1 detNI detNL = kL/kR . Matrix N (also called
transmission matrix in [15]) provides the link between aL and aR . Splitting the first
relation of (13.108) into its components gives
</p>
<p>a5 = N11 a1 +N12 a2, a6 = N21 a1 +N22 a2. (13.110)
</p>
<p>If the particle is launched, e.g., from &minus;&infin; one lets a6 = 0, whence
a2
</p>
<p>a1
= &minus;N21
</p>
<p>N22
,
</p>
<p>a5
</p>
<p>a1
= detN
</p>
<p>N22
= kL/kR
</p>
<p>N22
. (13.111)
</p>
<p>Combining (13.111) with (11.35) yields4 |N21|2 + kL/kR = |N22|2.
</p>
<p>4 Within a numerical solution of the Schr&ouml;dinger equation, the relation |N21|2 + kL/kR = |N22|2
may be exploited as a check for the quality of the approximation.</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 251
</p>
<p>Fig. 13.4 Example of a
potential energy V (x)
replaced with a
piecewise-constant function
Vi (Sect. 13.6.6) Vi
</p>
<p>h i
</p>
<p>E
</p>
<p>V(x)
</p>
<p>The derivation of the transmission matrix has been carried out here without spec-
ifying the form of the fundamental solutions ui , vi over the corresponding element
hi . In the practical cases, to easily find an analytical solution over each element one
approximates the coefficient q(x) of (11.28) with a constant, qi = const in hi ; this is
equivalent to replacing the potential energy V (x) with a piecewise-constant function
Vi (Fig. 13.4). Depending on the sign of qi = 2m (E&minus;Vi)/hÌ2 the possible cases for
ui , vi are:
â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>qi = &minus;Î±2i &lt; 0 ui = cosh [Î±i (x &minus; xi&minus;1)] vi = sinh [Î±i (x &minus; xi&minus;1)]/Î±i
qi = k2i &gt; 0 ui = cos [ki (x &minus; xi&minus;1)] vi = sin [ki (x &minus; xi&minus;1)]/ki
qi = 0 ui = 1 vi = x &minus; xi&minus;1
</p>
<p>(13.112)
</p>
<p>withÎ±i , ki real.As the potential energy is replaced with a piecewise-constant function,
the accuracy of the approximation is not very high.
</p>
<p>Problems
</p>
<p>13.1 Letting Z = 1 in (13.49) one finds the expression of the energy levels of
the hydrogen atom in a bound state, consistently with that obtained from the
Bohr hypothesis (Sect. 7.4.4). Use the same equation to calculate the minimum
energy that must be given to the electron to extract it from the hydrogen atom
(ionization energy).
</p>
<p>13.2 With reference to the hydrogen atom, calculate the expectation value of the
radius r corresponding to the eigenfunction w(Emin) = exp ( &minus; r/a)/
</p>
<p>&radic;
Ï a3
</p>
<p>found in Sect. 13.6.5.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 14
</p>
<p>Time-Dependent Perturbation Theory
</p>
<p>14.1 Introduction
</p>
<p>In many physical problems it is necessary to consider the collision of a particle with
another particle or system of particles. The treatment based on Classical Mechanics is
given in Sects. 3.5, 3.6 with reference to the motion&rsquo;s asymptotic conditions, without
considering the form of the interaction, while Sect. 3.8 shows a detailed treatment
of the Coulomb interaction. Here the approach based on Quantum Mechanics is
shown, dealing with the following problem: a particle in a conservative motion
enters at t = 0 an interaction with another particle or system of particles; such an
interaction has a finite duration tP , at the end of which the particle is in a conservative
motion again. The perturbation produced by the interaction, which is described by
a suitable Hamiltonian operator, may change the total energy of the particle; the
analysis carried out here, called time-dependent perturbation theory, allows one to
calculate such an energy change. The other particle or system, with which the particle
under consideration interacts, is left unspecified. However, it is implied that the larger
system, made of the particle under consideration and the entity with which it interacts,
form an isolated system, so that the total energy is conserved: if the particle&rsquo;s energy
increases due to the interaction, then such an energy is absorbed from the other
entity, or vice versa. As in Classical Mechanics, other dynamical properties of an
isolated system are conserved; an example of momentum conservation is given in
Sect. 14.8.3.
</p>
<p>The discussion is carried out first for the case where the eigenvalues prior and after
the perturbation are discrete and non degenerate. Starting from the general solution
of the perturbed problem, a first-order approximation is applied, which holds for
small perturbations, and the probability per unit time of the transition from a given
initial state to another state is found. The analysis is repeated for the degenerate case
(still for discrete eigenvalues) and, finally, for the situation where both the initial
and final state belong to a continuous set. The last section shows the calculation
of the perturbation matrix for a screened Coulomb perturbation. The complements
deal with the important problems of a perturbation constant in time and a harmonic
perturbation; a short discussion about the Fermi golden rule and the transitions from
discrete to continuous levels follows.
</p>
<p>&copy; Springer Science+Business Media New York 2015 253
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_14</p>
<p/>
</div>
<div class="page"><p/>
<p>254 14 Time-Dependent Perturbation Theory
</p>
<p>14.2 Discrete Eigenvalues
</p>
<p>Let H be the Hamiltonian operator that describes the dynamics of the particle when
the perturbation is absent. Such an operator is assumed to be conservative, namely,
H = &minus;hÌ2 &nabla;2/(2m) + V (r). When the perturbation is present, namely, for 0 &le; t &le;
tP , the Hamiltonian operator is referred to as H&prime;. The two operators, respectively
called unperturbed Hamiltonian and perturbed Hamiltonian, are Hermitean, so their
difference Î´H = H&prime; &minus; H, called perturbation Hamiltonian, is Hermitean as well.
Also, it is assumed that H and H&prime; are real, and that Î´H does not act on time; however,
it is Î´H = Î´H(t) because the perturbation is present only when 0 &le; t &le; tP .
</p>
<p>For t &lt; 0 and t &gt; tP the wave function is unperturbed; remembering the concepts
introduced in Sect. 9.2 and considering the case of discrete eigenvalues, it reads
</p>
<p>Ï =
&sum;
</p>
<p>n
</p>
<p>cn wn(r) exp ( &minus; iEn t/hÌ), (14.1)
</p>
<p>with wn the solutions of Hwn = En wn. As usual, n stands for a single index or a
set of indices. For the sake of simplicity, here it is assumed provisionally that the
energy eigenvalues are not degenerate, so that a one-to-one correspondence exists
between En and wn; this assumption will be removed later (Sect. 14.5). The wave
function is assumed to be square integrable and normalized to unity, whence |cn|2
is the probability that the particle under consideration is found in the nth state,
and ãws |wnã = Î´sn. As noted above, expansion (14.1) holds for both t &lt; 0 and
t &gt; tP . However, prior to the perturbaton and as a consequence of a measurement,
the additional information about the energy state is available; assuming that the
outcome of the measurement was the rth state, it follows (Sect. 9.2) that for t &lt; 0 it
is cn = 0 when n ï¿½= r , and1
</p>
<p>|cr |2 = 1, cr = 1, Ï = wr (r) exp ( &minus; iEr t/hÌ). (14.2)
</p>
<p>When t &rarr; 0 the last relation in (14.2) yields Ï(r, t = 0) = wr which, by continuity,
provides the initial condition for the time-dependent Schr&ouml;dinger equation to be
solved in the interval 0 &le; t &le; tP ; such an equation reads
</p>
<p>(H + Î´H) Ï = i hÌ &part;Ï
&part;t
</p>
<p>. (14.3)
</p>
<p>Thanks to the completeness of the wns one expands the wave function as Ï =
&sum;
</p>
<p>n bn(t) wn(r), where functions bn are unknown (compare with (9.10)). However,
it is convenient to transfer the role of unknowns to a new set of functions an(t) =
bn(t) exp (iEn t/hÌ), so that the expansion reads
</p>
<p>Ï =
&sum;
</p>
<p>n
</p>
<p>an(t) wn(r) exp ( &minus; iEn t/hÌ). (14.4)
</p>
<p>1 The phase of cr is irrelevant and is set to zero.</p>
<p/>
</div>
<div class="page"><p/>
<p>14.3 First-Order Perturbation 255
</p>
<p>By this token, the initial condition yields an(0) = Î´nr . Replacing (14.4) in (14.3),
&sum;
</p>
<p>n
</p>
<p>an exp ( &minus; iEn t/hÌ) (Hwn + Î´Hwn) =
</p>
<p>= i hÌ
&sum;
</p>
<p>n
</p>
<p>wn exp ( &minus; iEn t/hÌ) (dan/dt &minus; iEn an/hÌ) , (14.5)
</p>
<p>where the first and last terms cancel out due to Hwn = En wn. The next step
is a scalar multiplication of the remaining terms by one of the eigenfunctions of
the unperturbed problem, say, ws . The sum i hÌ
</p>
<p>&sum;
</p>
<p>n wn exp ( &minus; iEn t/hÌ) dan/dt at
the right hand side of (14.5) transforms, due to ãws |wnã = Î´sn, into the single
term i hÌ exp ( &minus; iEs t/hÌ) das/dt . In conclusion, the time-dependent Schr&ouml;dinger
equation (14.3) becomes a set of infinite, coupled linear equations in the unknownsas :
</p>
<p>das
dt
</p>
<p>= 1
i hÌ
</p>
<p>&sum;
</p>
<p>n
</p>
<p>an hns exp ( &minus; iÏns t), as(0) = Î´sr , (14.6)
</p>
<p>with
</p>
<p>hns(t) =
&int;
</p>
<p>ï¿½
</p>
<p>w&lowast;s Î´Hwn d
3r , Ïns = (En &minus; Es)/hÌ. (14.7)
</p>
<p>The coefficients of (14.6) embed the eigenvalues and eigenfunctions of the unper-
turbed problem. Due to its form, the set of elements hns(t) is called perturbation
matrix; remembering that Î´H is real, the definition (14.7) of the elements shows
that hsn = h&lowast;ns .
</p>
<p>14.3 First-Order Perturbation
</p>
<p>The differential equations (14.6) are readily transformed into a set of integral
equations by integrating from t = 0 to t &le; tP and using the initial condition:
</p>
<p>as = Î´sr +
1
</p>
<p>i hÌ
</p>
<p>&int; t
</p>
<p>0
</p>
<p>&sum;
</p>
<p>n
</p>
<p>an(t
&prime;)hns(t
</p>
<p>&prime;) exp ( &minus; iÏns t &prime;) dt &prime;. (14.8)
</p>
<p>As mentioned above, the solution of the Schr&ouml;dinger equation for t &gt; tP is (14.1),
with |cn|2 the probability that a measurement carried out at t = tP yields the eigen-
value En. The coefficients cn are found by observing that, after the solution of (14.6)
or (14.8) is calculated, the time-continuity of Ï and the uniqueness of the expansion
yield cn = an(tP ). It follows that the probability that at t = tP an energy mea-
surement finds the eigenvalue Es is |as(tP )|2. On the other hand, the energy state
prior to the perturbation was assumed to be Er , and the functions an(t) inherit this
assumption through the initial condition an(0) = Î´nr ; as a consequence, the quantity</p>
<p/>
</div>
<div class="page"><p/>
<p>256 14 Time-Dependent Perturbation Theory
</p>
<p>|as(tP )|2 = |bs
(
</p>
<p>tP
)
</p>
<p>|2 can be thought of as the probability that the perturbation
brings the particle from the initial state Er to the final state Es : for this reason,
Prs = |as
</p>
<p>(
</p>
<p>tP
)
</p>
<p>|2 is called transition probability from state r to state s. Thanks
to the normalization condition it is
</p>
<p>&sum;
</p>
<p>s Prs =
&int;
</p>
<p>ï¿½
|Ï
</p>
<p>(
</p>
<p>tP
)
</p>
<p>|2 d3r = 1; the term of
equal indices, Prr , is the probability that the perturbation leaves the particle&rsquo;s state
unchanged.
</p>
<p>The two forms (14.6) and (14.8) are equivalent to each other; however, the second
one is better suited for an iterative-solution procedure, that reads
</p>
<p>a(k+1)s = Î´sr +
1
</p>
<p>i hÌ
</p>
<p>&int; t
</p>
<p>0
</p>
<p>&sum;
</p>
<p>n
</p>
<p>a(k)n hns exp
(
</p>
<p>&minus; iÏns t &prime;
)
</p>
<p>dt &prime;, (14.9)
</p>
<p>where a(k)n (t) is the kth iterate. The iterations are brought to an end when ||a(k+1)s &minus;
a(k)s || &lt; Îµ, where the bars indicate a suitable norm and Îµ is a small positive constant.
To start the procedure it is necessary to choose the iterate of order zero, a(0)n (t), which
is typically done by letting a(0)n (t) = a(0)n (0) = Î´nr ; in other terms, the initial iterate
of an is selected as a constant equal to the initial condition of an. Replacing this value
into the integral of (14.9) yields the first-order iterate
</p>
<p>a(1)r = 1 +
1
</p>
<p>i hÌ
</p>
<p>&int; t
</p>
<p>0
hrr dt
</p>
<p>&prime;, a(1)s =
1
</p>
<p>i hÌ
</p>
<p>&int; t
</p>
<p>0
hrs exp
</p>
<p>(
</p>
<p>&minus; iÏrs t &prime;
)
</p>
<p>dt &prime;, (14.10)
</p>
<p>s ï¿½= r . If the perturbation is small enough, the first-order iterate is already close
to the solution, so that ar â a(1)r , as â a(1)s . This case happens when the norm of
the integrals in (14.10) is much smaller than unity; it follows Prr â 1, Prs âª 1.
The approximate solution thus found is called first-order solution, or first-order
perturbation. Note that, as hrr is real, the iterate a(1)r is a complex number whose
real part equals unity; as a consequence it is |a(1)r |2 &gt; 1. This non-physical result is
due to the approximation.
</p>
<p>14.4 Comments
</p>
<p>Considering the case where the initial and final states are different, and observing
that the entries of the perturbation matrix vanish for t &lt; 0 and t &gt; tP , one can
calculate as
</p>
<p>(
</p>
<p>tP
)
</p>
<p>by replacing the integration limits 0 and tP with &minus;&infin; and +&infin;,
respectively. This shows that a(1)s is proportional to the Fourier transform (C.16) of
hrs evaluated at Ïrs = (Er &minus; Es)/hÌ,
</p>
<p>a(1)s =
1
</p>
<p>i hÌ
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
hrs exp ( &minus; iÏrs t &prime;) dt &prime; =
</p>
<p>&radic;
2Ï
</p>
<p>i hÌ
Fhrs |Ï=Ïrs . (14.11)
</p>
<p>In conclusion, the first-order solution of the time-dependent Schr&ouml;dinger equation
(14.3) yields the following probability of a transition from state r to state s:
</p>
<p>Prs =
2Ï
</p>
<p>hÌ2
|Fhrs |2 . (14.12)</p>
<p/>
</div>
<div class="page"><p/>
<p>14.5 Degenerate Energy Levels 257
</p>
<p>The units of hns are those of an energy. It follows that the units of Fhrs are those
of an action, and Prs is dimensionless, as expected. Some important consequences
derive from (14.12):
</p>
<p>1. It may happen that for a given perturbation Hamiltonian Î´H the eigenfunctions
wr , ws (s ï¿½= r) are such that hrs = 0. In this case Î´H is not able to induce
the transition from state r to state s: the transition is forbidden. Basing on this
observation one can determine the pairs of indices for which the transitions are
permitted, thus providing the so-called transition rules or selection rules. For this
analysis it is sufficient to consider the symmetry of the integrand in the definition
(14.7) of hrs , without the need of calculating the integral itself.
</p>
<p>2. By exchanging r and s one finds hsr = h&lowast;rs , while Ïrs becomes &minus;Ïrs . From
(14.11) it follows that Fhsr = (Fhrs)&lowast;, whence Psr = Prs : for a given perturba-
tion Hamiltonian Î´H the probability of the r &rarr; s and s &rarr; r transitions are the
same.
</p>
<p>The transition from an energy state to a different one entails a change in the total
energy of the particle under consideration. Such a change is due to the interaction
with another particle or system of particles whence Î´H originates. Examples are
given in Sects. 14.8.1 and 14.8.2.
</p>
<p>The replacement of the integration limits 0 and tP with &minus;&infin; and +&infin;, carried out
above, has the advantage of making the presence of the Fourier transform clearer;
however, remembering that the duration tP of the perturbation is finite, one observes
that the probability Prs is a function of tP proper. From this, the probability per unit
time of the transition is defined as
</p>
<p>PÌrs =
dPrs
dtP
</p>
<p>. (14.13)
</p>
<p>14.5 Degenerate Energy Levels
</p>
<p>In Sect. 14.2 non-degenerate energy levels have been assumed for the sake of sim-
plicity. The case of degenerate levels is considered here, still assuming that the
indices are discrete. By way of example, let each energy value En correspond to a
set wn1, . . . , wnÎ³ , . . . of linearly-independent, mutually-orthogonal eigenfunctions.
An example of this is given by the eigenvalues (13.49) of the Schr&ouml;dinger equation
for a central force of the Coulomb type, whose degree of degeneracy in the spinless
case is given by (13.50). Expression (14.1) of the unperturbed wave function, that
holds for t &lt; 0 and t &gt; tP , becomes in this case
</p>
<p>Ï =
&sum;
</p>
<p>nÎ³
</p>
<p>cnÎ³ wnÎ³ (r) exp ( &minus; iEn t/hÌ), (14.14)
</p>
<p>with wnÎ³ the solutions of HwnÎ³ = En wnÎ³ . As before, the wave function is
assumed to be square integrable and normalized to unity, whence |cnÎ³ |2 is the</p>
<p/>
</div>
<div class="page"><p/>
<p>258 14 Time-Dependent Perturbation Theory
</p>
<p>probability that the particle under consideration is found in the state labeled by
n, Î³ , and ãwsÎ² |wnÎ³ ã = Î´sn Î´Î²Î³ . Prior to the perturbaton and as a consequence
of measurements, the additional information about the energy state is available,
along with that of the observable associated to index Î³ , whose measurement is
compatible with that of energy (compare with Sect. 10.4); assuming that the out-
come of the measurements was the state labeled r ,Î±, it follows that for t &lt; 0
it is crÎ± = 1, Ï = wrÎ±(r) exp ( &minus; iEr t/hÌ), while all other coefficients vanish.
As a consequence, the initial condition for the time-dependent Schr&ouml;dinger equa-
tion to be solved in the interval 0 &le; t &le; tP is Ï(r, t = 0) = wrÎ± . Following
the same reasoning as in Sect. 14.2 shows that in such an interval the expansion
Ï = &sum;nÎ³ anÎ³ (t) wnÎ³ (r) exp (&minus;iEn t/hÌ) holds, and the time-dependent Schr&ouml;dinger
equation transforms into the set of infinite, coupled linear equations
</p>
<p>dasÎ²
dt
</p>
<p>= 1
i hÌ
</p>
<p>&sum;
</p>
<p>nÎ³
</p>
<p>anÎ³ h
Î³Î²
ns exp ( &minus; iÏns t), asÎ²(0) = Î´sr Î´Î²Î± , (14.15)
</p>
<p>with
</p>
<p>hÎ³Î²ns (t) =
&int;
</p>
<p>ï¿½
</p>
<p>w&lowast;sÎ² Î´HwnÎ³ d
3r , Ïns = (En &minus; Es)/hÌ. (14.16)
</p>
<p>The first-order perturbative solution of (14.15) is obtained following the same path as
in Sect. 14.3. Within this approximation, and considering a final state s,Î² different
from the initial one, the probability of a r ,Î± &rarr; s,Î² transition induced by the
perturbation is
</p>
<p>P Î±Î²rs =
1
</p>
<p>hÌ2
</p>
<p>â£
â£
â£
â£
</p>
<p>&int; tP
</p>
<p>0
hÎ±Î²rs (t) exp ( &minus; iÏns t) dt
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>. (14.17)
</p>
<p>Thanks to the normalization condition it is
&sum;
</p>
<p>sÎ² P
Î±Î²
rs =
</p>
<p>&int;
</p>
<p>ï¿½
|Ï(tP )|2 d3r = 1, which
</p>
<p>can be expressed as
</p>
<p>&sum;
</p>
<p>s
</p>
<p>P Î±rs = 1, P Î±rs =
&sum;
</p>
<p>Î²
</p>
<p>P Î±Î²rs . (14.18)
</p>
<p>This shows that the inner sum P Î±rs is the probability that the perturbation induces a
transition from the initial state r ,Î± to any final state whose energy is Es ï¿½= Er .
</p>
<p>14.6 Continuous Energy Levels
</p>
<p>When the spectrum is continuous, the wave packet describing a particle in a three-
dimensional space and in a conservative case is given by (9.5), namely
</p>
<p>Ï(r, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
ck wk(r) exp ( &minus; iEk t/hÌ) d3k, (14.19)</p>
<p/>
</div>
<div class="page"><p/>
<p>14.6 Continuous Energy Levels 259
</p>
<p>with Ek, wk the eigenvalues and eigenfunctions of Hwk = Ek wk, and k a three-
dimensional vector whose components are continuous. If the wave function is square
integrable and normalized to unity, (9.7) holds:
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>|Ï |2 d3r =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
|ck|2 d3k = 1. (14.20)
</p>
<p>Remembering the discussion of Sects. 9.2, 9.6, and 10.2, the product |Ï(r, t)|2 d3r is
the infinitesimal probability that at time t the particle is localized within d3r around
r, and the product |ck|2 d3k is the infinitesimal probability that the outcome of an
energy measurement belongs to the range of E(k) values whose domain is d3k.
</p>
<p>To proceed one assumes that the unperturbed Hamiltonian operator is that of
a free particle, H = &minus;(hÌ2/2m)&nabla;2; it follows that the wave function and energy
corresponding to a wave vector k read (Sect. 9.6)
</p>
<p>wk(r) =
1
</p>
<p>(2Ï )3/2
exp (i k &middot; r), Ek =
</p>
<p>hÌ2
</p>
<p>2m
</p>
<p>(
</p>
<p>k21 + k22 + k23
)
</p>
<p>= hÌ Ïk. (14.21)
</p>
<p>Thanks to the completeness of the eigenfunctions (14.21), during the perturbation
the wave function is given by
</p>
<p>Ï(r, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
ak(t) wk(r) exp ( &minus; iEk t/hÌ) d3k. (14.22)
</p>
<p>Due to (14.20), the units of |ck|2 and, consequently, of |ak|2, are those of a volume.
The same reasoning as in Sect. 14.2 yields in this case
</p>
<p>&int;
dak
dt
</p>
<p>wk(r) exp (&minus;iEk t/hÌ) d3k =
&int;
</p>
<p>ak
</p>
<p>i hÌ
Î´Hwk(r) exp (&minus;iEk t/hÌ) d3k
</p>
<p>(14.23)
</p>
<p>(for the sake of simplicity, the symbol of triple integral over k or r is replaced with
&int;
</p>
<p>in (14.23) and in the relations below). Considering a state g, a scalar multiplication
of (14.23) by the corresponding eigenfunction wg is carried out; performing the
integration over r first, yields at the right hand side the entry of the perturbation
matrix of labels k and g:
</p>
<p>hkg(t) =
1
</p>
<p>(2Ï )3
</p>
<p>&int;
</p>
<p>exp ( &minus; i g &middot; r) Î´H exp (i k &middot; r) d3r , (14.24)
</p>
<p>where the units of hkg(t) are those of an energy times a volume. At the left hand side
of (14.23), still performing the integration over r first, and using (C.56), provides
</p>
<p>&int;
dak
dt
</p>
<p>Î´(k &minus; g) exp (&minus;iEk t/hÌ) d3k =
dag
dt
</p>
<p>exp
(
</p>
<p>&minus;iEg t/hÌ
)
</p>
<p>(14.25)
</p>
<p>which, combined with (14.24) and (14.23), yields
</p>
<p>dag
dt
</p>
<p>= 1
i hÌ
</p>
<p>&int;
</p>
<p>ak hkg exp
[
</p>
<p>&minus;i (Ek &minus; Eg) t/hÌ
]
</p>
<p>d3k, (14.26)</p>
<p/>
</div>
<div class="page"><p/>
<p>260 14 Time-Dependent Perturbation Theory
</p>
<p>the analogue of (14.6) and (14.15). However, a difference with respect to the discrete
case exists, because an in (14.6) and anÎ³ in (14.15) are dimensionless quantities,
whereas ak in (14.26) is not. As a consequence, when the first-order perturbation
method is used, and ak within the integral of (14.26) is replaced with the initial
condition, its expression contains one or more parameters whose values enter the
final result. Given these premises, choose for the initial condition, e.g., a Gaussian
function centered on some vector b ï¿½= g,
</p>
<p>ak(0) = Ï&minus;3/4 Î»3/2 exp ( &minus; Î»2 |k &minus; b|2/2), (14.27)
</p>
<p>with Î» &gt; 0 a length. Inserting (14.27) into (14.22) yields the initial condition for the
wave function (compare with (C.82)),
</p>
<p>Ï(r, 0) = Ï&minus;3/4 Î»&minus;3/2 exp [ &minus; r2/(2 Î»2) + i b &middot; r]. (14.28)
</p>
<p>Both (14.27) and (14.28) are square integrable and normalized to unity for any
positive Î»; when the latter becomes large, Ï(r, 0) becomes more and more similar
to a plane wave, while the peak of ak(0) around b becomes narrower and higher.
Assuming that the k-dependence of hkg is weaker than that of ak(0), one replaces k
with b in hkg and Ek, so that in (14.26) only the integral of ak(0) is left, which yields
(2
</p>
<p>&radic;
Ï/Î»)3/2. Completing the calculation as in Sects. 14.4 and 14.5, and remembering
</p>
<p>that g ï¿½= b, provides
</p>
<p>ag(tP ) â
(2
</p>
<p>&radic;
Ï/Î»)3/2
</p>
<p>i hÌ
</p>
<p>&int; tP
</p>
<p>0
hbg(t) exp
</p>
<p>(
</p>
<p>&minus;iÏbg t
)
</p>
<p>dt , Ïbg =
Eb &minus; Eg
</p>
<p>hÌ
.
</p>
<p>(14.29)
</p>
<p>The product dPbg = |ag(tP )|2 d3g is the infinitesimal probability that at the end of
the perturbation the outcome of an energy measurement belongs to the range of E(g)
values whose domain is d3g.
</p>
<p>Typical applications of (14.26) are encountered in the cases where the perturbation
matrix is independent of time, hbg = h(0)bg = const ï¿½= 0. A calculation similar to that
of Sect. 14.8.1 yields in this case
</p>
<p>dPbg =
8Ï3/2 |h(0)bg |2
</p>
<p>Î»3 hÌ2
f (Ïbg) d
</p>
<p>3g, f (Ïbg) =
[
</p>
<p>sin (Ïbg tP /2)
</p>
<p>Ïbg/2
</p>
<p>]2
</p>
<p>. (14.30)
</p>
<p>In place of the domain d3g one can consider the corresponding range of en-
ergy dEg; for this, one profits by the concept of density of states introduced
in Sect. B.5. Here the calculation is simple because the E = E(g) relation is
given by (14.21) so that, by the same calculation leading to (B.34), one obtains
d3g = (1/2) sin Ï dÏ dÏ (2m/hÌ2)3/2
</p>
<p>&radic;
</p>
<p>Eg dEg. Considering that the initial state b
and the duration tP are prescribed, the factor f (Ïbg) in (14.30) depends only on Eg,
while h(0)bg may depend on the angles Ï , Ï (compare with Prob. 14.1). Integrating
(14.30) over the angles and letting
</p>
<p>H
(0)
b (Eg) =
</p>
<p>&int; Ï
</p>
<p>0
</p>
<p>&int; 2Ï
</p>
<p>0
|h(0)bg |2 sin Ï dÏ dÏ, (14.31)</p>
<p/>
</div>
<div class="page"><p/>
<p>14.7 Screened Coulomb Perturbation 261
</p>
<p>yields the infinitesimal probability that a perturbation constant in time induces a
transition from the initial condition (14.28) to a final state whose energy belongs to
the range dEg:
</p>
<p>dPb =
&int; Ï
</p>
<p>0
</p>
<p>&int; 2Ï
</p>
<p>0
dPbg sin Ï dÏ dÏ =
</p>
<p>(
2Ï m
</p>
<p>hÌ2
</p>
<p>)3/2 4 f (Ïbg)H
(0)
b
</p>
<p>Î»3 hÌ2
</p>
<p>&radic;
</p>
<p>Eg dEg.
</p>
<p>(14.32)
</p>
<p>14.7 Screened Coulomb Perturbation
</p>
<p>An important case of perturbation is that of a charged particle deflected by another
charged particle fixed in the origin. The perturbation Hamiltonian is independent of
time and, in vacuo, takes the form (3.31) of the Coulomb potential energy.2 Though,
the perturbation matrix (14.24) calculated using (3.31) diverges. Such an outcome
is explained by observing that, as the vanishing behavior of the Coulomb potential
energy away from the origin is weak, the particle is actually subjected to it at large
distances from the origin; as a consequence, using the free particle&rsquo;s eigenfunctions
exp (i k &middot; r)/(2Ï )3/2 as solutions of the unperturbed Schr&ouml;dinger equation is too
strong an approximation. A more appropriate approach adopts for the perturbation
Hamiltonian the screened Coulomb potential energy
</p>
<p>Î´H = A
4Ï r
</p>
<p>exp ( &minus; qc r), r &gt; 0, A =
Îº Z e2
</p>
<p>Îµ0
, (14.33)
</p>
<p>with e &gt; 0 the elementary electric charge, Z a positive integer, Îµ0 the vacuum
permittivity, qc &gt; 0 the inverse screening length and, finally, Îº = 1 ( &minus; 1) in the
repulsive (attractive) case. The asymptotic vanishing of (14.33) is much stronger than
that of the pure Coulomb case, and the resulting matrix elements are finite, as shown
below. Although the choice of a screened potential energy is not realistic in vacuo,
an expression like (14.33) is more appropriate than (3.31) when a solid material is
considered (Sect. 20.5).
</p>
<p>To calculate (14.24) one lets q = k &minus; g and chooses a Cartesian reference such
that q is aligned with the z axis: turning to spherical coordinates (B.1) transforms
d3r into r2 sin Ï dÏ dÏ dr and q &middot;r into q r cosÏ . Letting Î¼ = cosÏ , and observing
that the integration over Ï yields a 2Ï factor, one gets
</p>
<p>h
(0)
kg =
</p>
<p>A/2
</p>
<p>(2Ï )3
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>[&int; +1
</p>
<p>&minus;1
exp ( &minus; i q r Î¼) dÎ¼
</p>
<p>]
</p>
<p>exp ( &minus; qc r) r dr =
A/(2Ï )3
</p>
<p>q2c + q2
.
</p>
<p>(14.34)
</p>
<p>2 This case is the quantum analogue of that treated in classical terms in Sect. 3.8.</p>
<p/>
</div>
<div class="page"><p/>
<p>262 14 Time-Dependent Perturbation Theory
</p>
<p>Fig. 14.1 Form of f (Ïrs )/tP ,
with f given by the second
expression in (14.36), for
different values of tP (in
arbitrary units)
</p>
<p>-10 0 10
Ï
</p>
<p>rs
    (a.u.)
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>1.5
</p>
<p>f
(Ï
</p>
<p>rs
 )
</p>
<p> /
 t
</p>
<p>P
  
  
(a
</p>
<p>.u
.)
</p>
<p>t
p
 = 1
</p>
<p>t
p
 = 1.5
</p>
<p>14.8 Complements
</p>
<p>14.8.1 Perturbation Constant in Time
</p>
<p>The simplest example of the time-dependent perturbation theory of Sect. 14.1 occurs
when the matrix elements hrs are constant in time during the perturbation. In this
case one lets hrs = h(0)rs = const ï¿½= 0 for 0 &le; t &le; tP , and hrs = 0 elsewhere. From
(14.10) it follows
</p>
<p>h(0)rs
</p>
<p>&int; tP
</p>
<p>0
exp ( &minus; iÏrs t) dt = h(0)rs exp ( &minus; iÏrs tP /2)
</p>
<p>sin (Ïrs tP /2)
</p>
<p>Ïrs/2
, (14.35)
</p>
<p>Prs =
|h(0)rs |2
hÌ2
</p>
<p>f (Ïrs), f (Ïrs) =
[
</p>
<p>sin (Ïrs tP /2)
</p>
<p>Ïrs/2
</p>
<p>]2
</p>
<p>. (14.36)
</p>
<p>The form of f (Ïrs)/tP is shown in Fig. 14.1 in arbitrary units. The zeros of f
nearest to Ïrs = 0 are Ï+ = 2Ï/tP and Ï&minus; = &minus;2Ï/tP , which provides the width
Ï+ &minus; Ï&minus; = 4Ï/tP of the peak; in turn, the height of the peak is f (Ïrs = 0) = t2P ,
this indicating that the area of the peak is proportional to tP . In fact, from (C.15) one
obtains
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
f (Ïrs) dÏrs = 2Ï tP . (14.37)
</p>
<p>The form of f (Ïrs)/tP suggests that, if tP is sufficiently large, such a ratio may be
approximated with a Dirac delta (Sect. C.4), namely, f (Ïrs) &asymp; 2Ï tP Î´(Ïrs), where
the coefficient 2Ï tP is chosen for consistency with (14.37). To this purpose one also
notes that, due to the smallness of hÌ, the modulus of Ïrs = (Er &minus;Es)/hÌ is very large</p>
<p/>
</div>
<div class="page"><p/>
<p>14.8 Complements 263
</p>
<p>(whence f (Ïrs) is very small) unless Es = Er . Using the approximate form within
the probability&rsquo;s definition (14.36) yields
</p>
<p>Prs &asymp; 2Ï
|h(0)rs |2
hÌ2
</p>
<p>tP Î´(Ïrs) = 2Ï
|h(0)rs |2
hÌ
</p>
<p>tP Î´(Er &minus; Es). (14.38)
</p>
<p>As expected, Prs is invariant when r and s are interchanged (compare with (C.55) and
comments therein). Differentiating (14.38) with respect to tP yields the probability3
</p>
<p>per unit time of the transition from state r to state s:
</p>
<p>PÌrs &asymp; 2Ï
|h(0)rs |2
hÌ2
</p>
<p>Î´(Ïrs) = 2Ï
|h(0)rs |2
hÌ
</p>
<p>Î´(Er &minus; Es). (14.39)
</p>
<p>This shows that the particle&rsquo;s energy is approximately conserved when the pertur-
bation lasts for a long time. The result is intuitive, because in the limit tP &rarr; &infin; a
constant perturbation is equivalent to a shift in the potential energy, which makes the
Hamiltonian operator conservative at all times. On the other hand, the conservation
of energy does not imply the conservation of other dynamic quantities like, e.g.,
momentum (compare with the analysis of the two-particle collision carried out in
classical terms in Sect. 3.6 and in quantum terms in Sect. 14.6).
</p>
<p>14.8.2 Harmonic Perturbation
</p>
<p>Another important example is that of the harmonic perturbation at an angular fre-
quency Ï0 &gt; 0: in this case the matrix elements read hrs = h(0)rs cos (Ï0 t) for
0 &le; t &le; tP , h(0)rs = const ï¿½= 0, and hrs = 0 elsewhere. From (14.10) it follows
</p>
<p>&int; tP
</p>
<p>0
hrs exp ( &minus; iÏrs t) dt =
</p>
<p>h(0)rs
</p>
<p>2
</p>
<p>[
</p>
<p>exp
</p>
<p>(
StP
</p>
<p>2 i
</p>
<p>)
</p>
<p>Ï (S) + exp
(
DtP
</p>
<p>2 i
</p>
<p>)
</p>
<p>Ï (D)
</p>
<p>]
</p>
<p>,
</p>
<p>(14.40)
</p>
<p>with S = Ïrs + Ï0, D = Ïrs &minus; Ï0, Ï (Î·) = sin (Î· tP /2)/(Î·/2). Comparing the
definition of Ï with (14.36) shows that f = Ï 2, whence
</p>
<p>Prs =
|h(0)rs |2
4 hÌ2
</p>
<p>F (Ïrs), F = f (S) + f (D) + 2 Ï (S) Ï (D) cos (Ï0 tP ). (14.41)
</p>
<p>The form of F (Ïrs)/tP is shown in Fig. 14.2 in arbitrary units. The largest peaks
correspond to Ïrs = Ï0 and Ïrs = &minus;Ï0; if tP â« 1/Ï0 holds, the two peaks are
practically separate whence, using as in Sect. 14.8.1 the approximation f â 2Ï tP Î´,
one finds
</p>
<p>Prs â 2Ï
|h(0)rs |2
4 hÌ2
</p>
<p>[Î´(Ïrs + Ï0) + Î´(Ïrs &minus; Ï0)] tP . (14.42)
</p>
<p>3 The expressions in terms of energy in (14.38, 14.39) are obtained from Î´(Ï) dÏ = Î´(E) dE =
Î´(E) dhÌÏ. Compare with the comments about the dimension of Dirac&rsquo;s Î´ made in Sect. C.5.</p>
<p/>
</div>
<div class="page"><p/>
<p>264 14 Time-Dependent Perturbation Theory
</p>
<p>Fig. 14.2 Form of F (Ïrs )/tP ,
with F given by the second
expression in (14.41), with
tP = 1, Ï0 = 5 (in arbitrary
units)
</p>
<p>-20 -10 0 10 20
Ï
</p>
<p>rs
 = S - Ï
</p>
<p>0
 = D + Ï
</p>
<p>0
      (a. u.)
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>F
 (
</p>
<p> Ï
rs
</p>
<p> )
 /
</p>
<p> t
P
  
  
  
(a
</p>
<p>.u
.)
</p>
<p>Remembering that Ïrs = (Er &minus; Es)/hÌ, the transition probability per unit time due
to the harmonic perturbation is finally found to be
</p>
<p>PÌrs = 2Ï
|h(0)rs |2
</p>
<p>4 hÌ
[Î´(Er &minus; Es + hÌ Ï0) + Î´(Er &minus; Es &minus; hÌ Ï0)] . (14.43)
</p>
<p>When r and s are interchanged, the two summands between brackets replace each
other. As Ï0 ï¿½= 0, the arguments of Î´ in (14.42) or (14.43) cannot vanish simul-
taneously. If the first vanishes it is Es = Er + hÌ Ï0 &gt; Er , namely, the final
energy Es is larger than the initial one: the particle acquires the quantum of en-
ergy hÌ Ï0 from the perturbing entity (absorption). If the second argument vanishes it
is Es = Er &minus; hÌÏ0 &lt; Er : the particle releases the energy quantum to the perturbing
entity (emission). For example, the energy can be absorbed from, or emitted towards,
an electromagnetic field; in this case the particle interacts with the mode at angular
frequency Ï0 by absorbing or emitting a photon (Sect. 12.28). The total energy of
the particle and field is conserved in both cases.4 The same description applies to
the interaction with a vibrational field; in this case the particle absorbs or emits a
phonon (Sect. 12.5).
</p>
<p>4 The spatial dependence of the field is embedded in h(0)rs .</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 265
</p>
<p>14.8.3 Fermi&rsquo;s Golden Rule
</p>
<p>Expression (14.32) gives the infinitesimal probability that a perturbation constant in
time induces a transition from the initial state b to a final state whose energy belongs
to the range dEg; it is an example of a more general expression denoted with Fermi&rsquo;s
Golden Rule. Remembering from Sect. 14.8.1 that, for a sufficiently large value of
tP , it is f (Ïbg) &asymp; 2Ï tP Î´(Ïbg), one finds from (14.32)
</p>
<p>dPb &asymp;
(
</p>
<p>2Ï m
</p>
<p>hÌ2
</p>
<p>)3/2 8Ï tP Î´(Eb &minus; Eg)H (0)b
Î»3 hÌ
</p>
<p>&radic;
</p>
<p>Eg dEg. (14.44)
</p>
<p>Dividing (14.44) by tP provides the infinitesimal probability per unit time. Factor
Î´(Eb &minus; Eg) entails the conservation of energy; as the unperturbed Hamiltonian op-
erator, upon which the derivation of (14.44) is based, is that of a free particle, the
relation Eg = Eb combined with the second relation in (14.21) implies g2 = b2,
namely, the modulus of momentum is also conserved. The result is the same as in the
case of the classical treatment of a particle&rsquo;s collision with another particle having a
much larger mass (Sect. 3.6).
</p>
<p>14.8.4 Transitions from Discrete to Continuous Levels
</p>
<p>The transition probability is calculated following a reasoning similar to that of
Sect. 14.5 also in the case where the initial state is labeled by a discrete index and
the final state belongs to a continuous set. A physical situation where such a tran-
sition may occur is that of a particle initially trapped within a well: with reference
to Sect. 11.5, the energy levels are discrete if E &lt; 0, whereas they are continuous
for E &gt; 0, namely, the spectrum is mixed (Sect. 8.4). A particle whose initial state
belongs to the discrete set may absorb from the perturbation an amount of energy
sufficient for reaching the continuous set of states, thus leaving the well. As the final
energy belongs to a continuous set, the outcome of the calculation is the expression
of an infinitesimal probability like in Sect. 14.6.
</p>
<p>Problems
</p>
<p>14.1 Using (14.31) and (14.34), find H (0)b for the screened Coulomb perturbation.
Assume for simplicity that the condition g = b holds (Sect. 14.8.3).</p>
<p/>
</div>
<div class="page"><p/>
<p>Part IV
</p>
<p>Systems of Interacting Particles&mdash;
Quantum Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 15
</p>
<p>Many-Particle Systems
</p>
<p>15.1 Introduction
</p>
<p>The chapter illustrates the properties of many-particle systems. The quantum-
mechanical description of the latter is obtained by solving the time-dependent
Schr&ouml;dinger equation. After commenting the simplifications that occur when the
Hamiltonian operator is separable, the important issue of the symmetry or antisym-
metry of the wave function is introduced, to the purpose of illustrating the peculiar
properties possessed by the systems of identical particles. Then, the concept of spin
and the exclusion principle are introduced. After a general discussion, the above con-
cepts are applied to the important case of a conservative system, and further properties
related to the separability of the Hamiltonian operator are worked out. The remain-
ing part of the chapter is devoted to the derivation of the equilibrium statistics in the
quantum case (Fermi&ndash;Dirac and Bose&ndash;Einstein statistics). The connection between
the microscopic statistical concepts and the macroscopic thermodynamic properties
is illustrated in the complements, where two important examples of calculation of
the density of states are also given.
</p>
<p>15.2 Wave Function of a Many-Particle System
</p>
<p>The quantum-mechanical concepts outlined in Parts II and III dealt with wave func-
tions Ï describing a single particle. In such a case, if Ï is normalized to unity, the
product |Ï(r, t)|2 d3r is the infinitesimal probability that at time t the particle&rsquo;s po-
sition belongs to the elementary volume d3r = dx dy dz centered on r; specifically,
the x coordinate belongs to dx, and so on. It is now necessary to extend the treatment
to the case of many-particle systems. This is readily accomplished by considering,
first, a system made of two particles: the wave function Ï describing such a system
depends on two sets of coordinates, r1, r2, and time. The first set labels one of the
</p>
<p>&copy; Springer Science+Business Media New York 2015 269
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_15</p>
<p/>
</div>
<div class="page"><p/>
<p>270 15 Many-Particle Systems
</p>
<p>particles, the second set labels the other particle. Assume that Ï is normalized to
unity,
</p>
<p>&int;
</p>
<p>|Ï(r1, r2, t)|2 d3r1 d3r2 = 1, (15.1)
</p>
<p>where
&int;
</p>
<p>is a short-hand notation for a six-fold integral over dx1 . . . dz2. Then, the
product |Ï(r1, r2, t)|2 d3r1 d3r2 is the infinitesimal probability that, at time t , set r1
belongs to d3r1 and set r2 belongs to d3r2. The wave function in (15.1) is the solution
of the time-dependent Schr&ouml;dinger equation
</p>
<p>i hÌ
&part;Ï
</p>
<p>&part;t
= HÏ , Ï(r1, r2, 0) = Ï0(r1, r2), (15.2)
</p>
<p>where the initial condition Ï0 is prescribed. In turn, the Hamiltonian operator in
(15.2) is derived, following the procedure illustrated in Sect. 10.2, from the Hamilto-
nian function that describes the two-particle system in the classical case. Considering
by way of example a case where the forces acting on the two particles derive from
a potential energy V = V (r1, r2, t), the Hamiltonian function and the Hamiltonian
operator read, respectively,
</p>
<p>H = p
2
1
</p>
<p>2m1
+ p
</p>
<p>2
2
</p>
<p>2m2
+ V , H = &minus; hÌ
</p>
<p>2
</p>
<p>2m1
&nabla;21 &minus;
</p>
<p>hÌ2
</p>
<p>2m2
&nabla;22 + V , (15.3)
</p>
<p>where m1, m2 are the particles&rsquo;masses, while p21 = p2x1+p2y1+p2z1, &nabla;21 = &part;2/&part;x21 +
&part;2/&part;y21 + &part;2/&part;z21, and the same for label 2.
</p>
<p>It may happen that the Hamiltonian operator is separable with respect to the two
sets r1, r2, namely, H = H1 + H2 such that H1 does not contain any component
of r2 and H2 does not contain any component1 of r1. Also, let Ï1 = Ï1(r1, t),
Ï2 = Ï2
</p>
<p>(
</p>
<p>r2, t
)
</p>
<p>be solutions, respectively, of
</p>
<p>i hÌ
&part;Ï1
</p>
<p>&part;t
= H1Ï1, i hÌ
</p>
<p>&part;Ï2
</p>
<p>&part;t
= H2Ï2, (15.4)
</p>
<p>with the initial conditions Ï10 = Ï1
(
</p>
<p>r1, 0
)
</p>
<p>, Ï20 = Ï2
(
</p>
<p>r2, 0
)
</p>
<p>. Letting Ï = Ï1 Ï2
and using (15.4) yields
</p>
<p>i hÌ
&part;Ï
</p>
<p>&part;t
&minus; HÏ = Ï2
</p>
<p>(
</p>
<p>i hÌ
&part;Ï1
</p>
<p>&part;t
&minus; H1Ï1
</p>
<p>)
</p>
<p>+ Ï1
(
</p>
<p>i hÌ
&part;Ï2
</p>
<p>&part;t
&minus; H2Ï2
</p>
<p>)
</p>
<p>= 0, (15.5)
</p>
<p>showing that Ï1 Ï2 solves the Schr&ouml;dinger equation for the particles&rsquo; system, with
Ï10 Ï20 as initial condition. The concepts introduced in this section are readily ex-
tended to the case of larger systems. Letting N &gt; 2 be the number of particles, and
still assuming that the system&rsquo;s wave function is normalized to unity,
</p>
<p>&int;
</p>
<p>|Ï
(
</p>
<p>r1, r2, . . . , rN , t
)
</p>
<p>|2 d3r1 d3r2 . . . d3rN = 1, (15.6)
</p>
<p>1 By way of example, (15.3) is separable if V = V1
(
</p>
<p>r1, t
)
</p>
<p>+ V2
(
</p>
<p>r2, t
)
</p>
<p>.</p>
<p/>
</div>
<div class="page"><p/>
<p>15.3 Symmetry of Functions and Operators 271
</p>
<p>the product |Ï
(
</p>
<p>r1, r2, . . . , rN , t
)
</p>
<p>|2 d3r1 d3r2 . . . d3rN is the infinitesimal probability
that, at time t , set ri belongs to d3ri , with i = 1, 2, . . . ,N . If the Hamiltonian
operator is separable, the solution of the time-dependent Schr&ouml;dinger equation of
the system has the form Ï = Ï1
</p>
<p>(
</p>
<p>r1, t
)
</p>
<p>. . . ÏN
(
</p>
<p>rN , t
)
</p>
<p>. From (15.6) one also notes
that the units of Ï depend on the number of particles involved; specifically, in (15.6)
it is [Ï] = cm&minus;3N/2 (compare with the discussion of Sect. 9.7.1).
</p>
<p>15.3 Symmetry of Functions and Operators
</p>
<p>The Hamiltonian operator and the wave function describing a many-particle system
contain sets of coordinates like r1, r2 . . . . It is important to introduce a number of
properties related to the exchange of two such sets within the operator or the wave
function. The problem is tackled first in a rather abstract way; the applications to
specific cases of interest are shown in Sect. 15.6.
</p>
<p>Consider a function f = f
(
</p>
<p>q1, q2, . . . , qn
)
</p>
<p>, where qk represents a group of
coordinates.2 Let Sij be an operator such that [78, Chap. XIV.3]
</p>
<p>Sijf
(
</p>
<p>q1, . . . , qi , . . . , qj , . . . , qn
)
</p>
<p>= f
(
</p>
<p>q1, . . . , qj , . . . , qi , . . . , qn
)
</p>
<p>, (15.7)
</p>
<p>namely, Sij exchanges the names of the ith and j th group, leaving the rest unchanged.
From the definition it follows S2ij = Sij Sij = I. Now, let Î» be an eigenvalue of
Sij , and w an eigenfunction corresponding to it: Sijw = Î»w. The following relations
hold together:
</p>
<p>S2ijw = w, S2ijw = Î»2w, (15.8)
</p>
<p>the first due to the general property shown before, the second to the definition of
Î» and w. As a consequence, Î» = &plusmn;1, namely, Sij has two eigenvalues. As their
modulus equals unity, Sij is unitary (Sect. 8.6.2), namely, S
</p>
<p>&minus;1
ij = S&dagger;ij .
</p>
<p>The properties of the operator&rsquo;s eigenfunctions are found by letting ws = Sijw,
so that ws is the function that results from exchanging the names of the ith and j th
group of coordinates. Depending on the eigenvalue, two cases are possible: the first
one is Î» = +1, whence Sijw = +1 &times; w and Sijw = ws hold together, so that
ws = w; the second case is Î» = &minus;1, whence Sijw = &minus;1 &times; w and Sijw = ws hold
together, so that ws = &minus;w. A function such that ws = w is called symmetric with
respect to indices ij , while a function such that ws = &minus;w is called antisymmetric
with respect to indices ij . In conclusion,
</p>
<p>&bull; all symmetric functions are eigenfunctions of Sij belonging to Î» = +1;
&bull; all antisymmetric functions are eigenfunctions of Sij belonging to Î» = &minus;1.
</p>
<p>2 A &ldquo;group&rdquo; of coordinates may also consist of a single coordinate.</p>
<p/>
</div>
<div class="page"><p/>
<p>272 15 Many-Particle Systems
</p>
<p>The set of eigenfunctions of Sij is complete; in fact, for any function f it is
</p>
<p>f = 1
2
</p>
<p>(
</p>
<p>f + Sijf
)
</p>
<p>+ 1
2
</p>
<p>(
</p>
<p>f &minus; Sijf
)
</p>
<p>, (15.9)
</p>
<p>where the first term at the right hand side is symmetric and the second one is antisym-
metric, so that both terms at the right hand side are eigenfunctions of Sij . This shows
that any function is expressible as a linear combination of eigenfunctions of Sij .
</p>
<p>Only a specific pair ij of coordinate group has been considered so far. On the
other hand it may happen that a function is symmetric (antisymmetric) with respect
to all pairs of indices; in this case it is called symmetric (antisymmetric) with no
further specification.
</p>
<p>The definitions above extend to operators. For instance, an operator A is symmet-
ric with respect to ij if As = SijA = A; it is symmetric without further specification
if As = A for any pair ij . Given a function f and an operator A, and letting
f s = Sijf , it is for all f ,
</p>
<p>(Af )s = SijAf = SijAS&minus;1ij Sijf = Asf s . (15.10)
If A is symmetric, replacing As = A in (15.10) shows that SijAf = ASijf namely,
Sij commutes with all symmetric operators.
</p>
<p>The operator whose symmetry properties are of interest is typically the Hamil-
tonian one. Considering for instance a system of N particles interacting with each
other through Coulomb interactions in vacuo, one has
</p>
<p>H = &minus;
N
&sum;
</p>
<p>k=1
</p>
<p>hÌ2
</p>
<p>2mk
&nabla;2k +
</p>
<p>1
</p>
<p>2
</p>
<p>N
&sum;
</p>
<p>k=1
</p>
<p>N
&sum;
</p>
<p>s=1
s ï¿½=k
</p>
<p>ek es
</p>
<p>4Ï Îµ0 |rk &minus; rs |
(15.11)
</p>
<p>with Îµ0 the vacuum permittivity,&nabla;2k = &part;2/&part;x2k+&part;2/&part;y2k+&part;2/&part;z2k , andmk , ek the mass
and charge of the kth particle, respectively. In general, this operator has no particular
symmetry property; however, it is symmetric with respect to the groups of coordinates
xk , yk , zk when the particles are identical to each other
</p>
<p>(
</p>
<p>m1 = m2 = . . . = mN ,
e1 = e2 = . . . = eN
</p>
<p>)
</p>
<p>.
</p>
<p>15.4 Conservation of Symmetry in Time
</p>
<p>Consider a wave function Ï expanded into a complete set of orthonormal functions
wk . Using as in Sect. 15.3 the symbols qi for the groups of coordinates, one has
</p>
<p>Ï
(
</p>
<p>q1, . . . , qn, t
)
</p>
<p>=
&sum;
</p>
<p>k
</p>
<p>ak(t) wk
(
</p>
<p>q1, . . . , qn
)
</p>
<p>. (15.12)
</p>
<p>The wave function is assumed to be normalized to unity, so that from Parseval theorem
(8.41) it follows
</p>
<p>ãÏ |Ïã =
&sum;
</p>
<p>k
</p>
<p>|ak|2 = 1 (15.13)</p>
<p/>
</div>
<div class="page"><p/>
<p>15.5 Identical Particles 273
</p>
<p>at all times. Now assume that Ï is the solution of a Schr&ouml;dinger equation deriving
from a symmetric Hamiltonian operator, and thatÏ itself is symmetric at some instant
t &prime; with respect to the pair ij . As the functions wk of (15.12) are linearly independent,
the symmetry of Ï entails that of wk for all k. As a consequence, for the pair ij , wk
is an eigenfunction of the operator Sij corresponding to Î» = 1. Combining (15.13)
with the definition (10.13) of the expectation value of the eigenvalues yields ãÎ»ã = 1
at t = t &prime;. In turn, due to symmetry, H commutes with Sij ; this yields, for the time
derivative (10.27) of the average value of the eigenvalues of Sij ,
</p>
<p>d
</p>
<p>dt
ãÎ»ã = &minus;i hÌ
</p>
<p>&int;
</p>
<p>Ï&lowast;
(
</p>
<p>HSij &minus; SijH
)
</p>
<p>Ï dq1 . . . dqn = 0, (15.14)
</p>
<p>namely, ãÎ»ã is conserved in time. The above calculation can be summarized as
follows:
</p>
<p>&bull; Given a symmetric Hamiltonian H, select a pair of indices ij . Due to commuta-
tivity, a complete set of eigenfuctions wk of H exists, that belongs also to operator
Sij .
</p>
<p>&bull; The eigenfunctions wk of H can thus be separated into two sets, made of symmetric
and antisymmetric functions, respectively.
</p>
<p>&bull; Let Ï(q1, . . . , t) =
&sum;
</p>
<p>k ak(t)wk
(
</p>
<p>q1, . . .
)
</p>
<p>be the wave function of the system de-
scribed by H, and let Ï be symmetric at some instant t &prime;. It follows that the non
vanishing coefficients ak
</p>
<p>(
</p>
<p>t &prime;
)
</p>
<p>in the expansion of Ï
(
</p>
<p>q1, . . . , qn, t &prime;
)
</p>
<p>are only those
multiplying the symmetric eigenfunctions.
</p>
<p>As ãÎ»ã =
&int;
</p>
<p>Ï&lowast; Sij Ï dq1 . . . qn = 1 at all times, the expansion of Ï is made in terms
of the symmetric wks at all times. Hence, Ï is always symmetric with respect to the
groups of coordinates of indices ij . The above reasoning can be repeated for all pairs
of indices for whichÏ is symmetric. Note that, in order to repeat the reasoning for dif-
ferent pairs of indices, say, ij and jk, one needs not assume that the corresponding op-
erators Sij , Sjk commute with each other (in fact, they typically do not commute). The
analysis holds equally for the case whereÏ , at time t &prime;, is antisymmetric with respect to
two indices. In such a case, it remains antisymmetric at all times with respect to them.
</p>
<p>15.5 Identical Particles
</p>
<p>It is interesting to ascertain whether the mathematical properties related to symmetry
or antisymmetry, briefly discussed in Sects. 15.3 and 15.4, correspond to some
physical property. This is indeed so, and is especially important when a system of
identical particles is considered.
</p>
<p>Take for instance a system of two identical particles interacting with each other.3
</p>
<p>In classical terms, the two identical objects that form the system can always be
</p>
<p>3 The reasoning outlined here does not apply to systems where the particles are different: they can
be distinguished in |Ï |2, e.g., by the mass or electric charge.</p>
<p/>
</div>
<div class="page"><p/>
<p>274 15 Many-Particle Systems
</p>
<p>Fig. 15.1 Schematic
description of a system made
of two identical particles
</p>
<p>1 2 2
</p>
<p>1 2 1 1
</p>
<p>2
</p>
<p>a b c
</p>
<p>made distinguishable from each other, without disturbing their motion. The typical
example is that of two identical billiard balls, that are made distinguishable by a
different coloring; although the latter has no influence on the balls&rsquo; dynamics, it
allows one to distinguish them from each other irrespective of the number of collisions
they undergo. As a consequence, the conjugate variables describing the motion of
each particle (e.g., position and momentum) are exactly known at each instant of
time. By way of example consider the collision of two identical, charged particles
schematically illustrated in Fig. 15.1: it is assumed that the particles are initially far
apart, with equal moduli of the initial velocities; the initial velocity of the particle
labeled 1 is described by the upper-left arrow visible in cases a and b of the figure,
while the initial velocity of the particle labeled 2 is described by the lower-right arrow.
As they come closer, the particles repel each other due to the Coulomb interaction,
and their classical motion is described as in Sects. 3.5&ndash;3.8. If the initial velocities
were exactly aligned (this case is not shown in the figure), the two particles would
bounce back along the same direction; if, however, the initial velocity of particle
1 were slightly misaligned to the left, the collision would yield case a, whereas it
would yield case b for a right misalignment. Even if the misalignment is made as
small as we please, either case a or b occurs, and the two possible outcomes are
distinguishable from each other.
</p>
<p>In the quantum-mechanical description, instead, it is not possible to track each
particle separately, because the dynamical information about the system derives from
the wave function; when the particles come closer, the norm of the wave function
in (15.1) is significantly different from zero in a finite region of space, which is
schematically indicated by the circle of case c in Fig. 15.1. Due to the Heisenberg
principle (10.22), it is impossible to determine the position and momentum of each
particle at the same time with arbitrary precision. It follows that, for identical par-
ticles, the collision is described as an event where two particles enter the circle and
two particles eventually leave it, without the possibility of distinguishing between
cases a and b: the two cases must in fact be counted as one, and the wave function
describing the system must be consistent with it. This requires |Ï |2 be symmetric</p>
<p/>
</div>
<div class="page"><p/>
<p>15.5 Identical Particles 275
</p>
<p>with respect to the groups r1, r2:
</p>
<p>|Ï s |2 = |S12Ï |2 = |Ï |2, (15.15)
</p>
<p>which implies Ï s = exp (iÎ±)Ï with Î± a real constant. On the other hand,
remembering the first equation in (15.8),
</p>
<p>S212Ï = exp (2 iÎ±)Ï , S212Ï = Ï , (15.16)
</p>
<p>whence exp (jÎ±) = &plusmn;1. In conclusion, when the two particles of the system are
indistinguishable from each other, the system&rsquo;s wave function is either symmetric
or antisymmetric. One may argue that, when the system is made of more than two
identical particles, its wave function could be symmetric with respect to some pairs of
indices and antisymmetrical with respect to other pairs. However this is not possible,
as the simple case of three identical particles shows [69, Sect. 26]. Assume that Ï is
symmetric with respect to r1, r2 and antisymmetric with respect to r1, r3; it follows
</p>
<p>Ï
(
</p>
<p>r1, r2, r3, t
)
</p>
<p>= Ï
(
</p>
<p>r2, r1, r3, t
)
</p>
<p>= &minus;Ï
(
</p>
<p>r2, r3, r1, t
)
</p>
<p>= &minus;Ï
(
</p>
<p>r1, r3, r2, t
)
</p>
<p>=
(15.17)
</p>
<p>= Ï
(
</p>
<p>r3, r1, r2, t
)
</p>
<p>= Ï
(
</p>
<p>r3, r2, r1, t
)
</p>
<p>= &minus;Ï
(
</p>
<p>r1, r2, r3, t
)
</p>
<p>, (15.18)
</p>
<p>that is, a contradiction. In other terms, Ï can either be symmetric with respect to all
the identical particles of the system, or antisymmetric with respect to all of them.
This result has a far-reaching consequence, namely, the class of all particles is made
of two subclasses: the first one collects the types of particles whose systems are
described by symmetric wave functions; they are called Bose particles or bosons.
The second subclass collects the types of particles whose systems are described by
antisymmetric wave functions; they are called Fermi particles or fermions. This
applies to all known particles, including composite ones (e.g., atoms) and particles
describing collective motions (e.g., phonons, photons).4
</p>
<p>15.5.1 Spin
</p>
<p>The properties discussed so far in this section bring about an interesting question:
consider a single particle, e.g., an electron. Although electrons are fermions,5 here the
concept of symmetry or antisymmetry does not apply because the wave function of a
</p>
<p>4 The names &ldquo;bosons&rdquo;, &ldquo;fermions&rdquo; of the two subclasses have this origin: when a system of identical
particles is in thermodynamic equilibrium, the particles&rsquo; energy follows a statistical distribution
whose expression is named after Bose and Einstein (Sect. 15.8.2) and, respectively, Fermi and
Dirac (Sect. 15.8.1).
5 It must be noted, however, that in condensed-matter physics two electrons or other fermions may
bind together at low temperatures to form a so-called Cooper pair, which turns out to have an integer
spin, namely, it is a composite boson [20].</p>
<p/>
</div>
<div class="page"><p/>
<p>276 15 Many-Particle Systems
</p>
<p>single electron contains only one group of coordinates. Then add a second electron,
so that a system of two identical particles is formed: how do these electrons &ldquo;know&rdquo;
that, when paired, the wave function of their system must be antisymmetric? It is
reasonable to assume that each particle in itself must possess a property that makes it
to behave like a fermion or a boson within a system of particles identical to it. Such a
property, called spin, does in fact exist; as its existence can be proven only within the
frame of the relativistic quantum theory [31], [32], [99, Sect. 15], which is beyond
the scope if this book, only a brief illustration of spin&rsquo;s properties of interest will be
given.
</p>
<p>In contrast with the other dynamic quantities considered so far, there is no classical
counterpart of spin. Therefore, the latter can not be derived from the expression of
a dynamic variable by replacing conjugate coordinates with suitable operators. It
can be shown that the eigenvalues of spin are derived in a manner similar to that
of angular momentum: this leads, like in Sect. 13.5.1, to determining the square
modulus of spin, Ï 2, and its component along one of the coordinate axes, say, Ïz.
Their values are given by expressions similar to (13.46), specifically,
</p>
<p>S2 = hÌ2 s (s + 1), Sz = hÌ sz. (15.19)
</p>
<p>The important difference with (13.46) is that s, instead of being a non-negative
integer, is a non-negative half integer: s = 0, 12 , 1, 32 , 2, . . . ; in turn, sz can take the
2 s + 1 values &minus;s,&minus;s + 1, . . . , s &minus; 1, s.
</p>
<p>The introduction of spin must be accounted for in the expression of the wave
function: the latter, in the case of a single particle, must be indicated with Ï(r, sz, t),
and its normalization to unity, if existing, is expressed by
</p>
<p>&sum;
</p>
<p>sz
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>|Ï
(
</p>
<p>r, sz, t)|2 d3r = 1. (15.20)
</p>
<p>If (15.20) holds, the product |Ï(r, sz, t)|2 d3r is the probability that at time t the
particle is in the elementary volume d3r centered on r, and the component of its spin
along the z axis is Sz = hÌ sz.
</p>
<p>The connection between spin and boson-like or fermion-like behavior is the fol-
lowing: the quantum number s is integer for bosons, half integer for fermions [81]. It
is then meaningful to use the terms &ldquo;boson&rdquo; or &ldquo;fermion&rdquo; for an individual particle.
All known fermions have s = 1/2, whence 2 s + 1 = 2. It follows that for fermions
the z-component of spin has two possible values, hÌ/2 (spin up) and &minus;hÌ/2 (spin
down). As anticipated above, electrons are fermions. Photons are bosons with s = 1.
</p>
<p>The similarity between the expressions of the quantum numbers for spin and those
of the angular momentum (Eqs. (13.46) cited above) is the origin of the qualitative
visualization of spin in classical terms: spin is described as an intrinsic angular
momentum of the particle, as if the particle were a sphere spinning on its axis.</p>
<p/>
</div>
<div class="page"><p/>
<p>15.6 Pauli Exclusion Principle 277
</p>
<p>15.6 Pauli Exclusion Principle
</p>
<p>Consider a system of identical particles, so that its Hamiltonian operator H is sym-
metric with respect to each pair of particle labels ij . Its wave function, in turn, is
either symmetric or antisymmetric depending on the nature of the particles forming
the system. It may happen that, when solving the Schr&ouml;dinger equation of the system,
a solution is found, say Ï, that does not possess the necessary symmetry properties.
One can then exploit a relation like (15.9) to construct from Ï another solution which
is either symmetric or antisymmetric. For this, one must remember that Ï depends on
the groups of coordinates
</p>
<p>(
</p>
<p>r1, sz1
)
</p>
<p>,
(
</p>
<p>r2, sz2
)
</p>
<p>, . . . which, for the sake of conciseness,
will be indicated with the symbol qi =
</p>
<p>(
</p>
<p>ri , szi
)
</p>
<p>. Remembering from Sect. 15.3 that
the Hamiltonian operator, due to its symmetries, commutes with any operator Sij ,
one finds
</p>
<p>Sij
</p>
<p>(
</p>
<p>H &minus; i hÌ &part;
&part;t
</p>
<p>)
</p>
<p>Ï =
(
</p>
<p>H &minus; i hÌ &part;
&part;t
</p>
<p>)
</p>
<p>Ïs , (15.21)
</p>
<p>where Sij exchanges qi with qj . The parenthesis on the left hand side of (15.21) is
zero because Ï solves the Schr&ouml;dinger equation; it follows that Ïs is also a solution.
Due to the linearity of the Schr&ouml;dinger equation, the two functions
</p>
<p>Ï + Ïs , Ï &minus; Ïs , (15.22)
</p>
<p>are solutions of the Schr&ouml;dinger equation, which are also symmetric and, respectively,
antisymmetric with respect to the pair ij . The procedure is easily generalized to
obtain a wave function that is symmetric or antisymmetric with respect to all pairs
of indices. To this purpose, one considers the N ! permutations of the system&rsquo;s N
particles; let Î½ be an index representing the order of each permutation with respect
to the fundamental one (1 &le; Î½ &le; N !), and SÎ½ the operator that achieves the Î½th
permutation of the particles&rsquo; coordinates within Ï. The functions
</p>
<p>Ï = a
&sum;
</p>
<p>Î½
</p>
<p>SÎ½Ï, Ï = b
&sum;
</p>
<p>Î½
</p>
<p>( &minus; 1)Î½SÎ½Ï (15.23)
</p>
<p>are solutions of the Schr&ouml;dinger equation, which are also symmetric and, respectively,
antisymmetric with respect to all particles&rsquo; permutations. Symbols a and b denote
two constants, that can be used to normalize Ï if Ï is normalizable. The above
constructions can be worked out at any instant, as the symmetry or antisymmetry of
the wave function is conserved in time (Sect. 15.4). The second relation in (15.23)
lends itself to an interesting derivation. Considering for simplicity the case N = 2
one finds
</p>
<p>Ï = b
[
</p>
<p>Ï
(
</p>
<p>r1, sz1, r2, sz2, t
)
</p>
<p>&minus; Ï
(
</p>
<p>r2, sz2, r1, sz2, t
)]
</p>
<p>, (15.24)
</p>
<p>If it were r2 = r1, sz2 = sz1, the wave function (15.24) would vanish, which is not
acceptable. The same unphysical results is found by letting rj = ri , szj = szi in the
second expression in (15.23). The conclusion is that in a system of identical fermions,</p>
<p/>
</div>
<div class="page"><p/>
<p>278 15 Many-Particle Systems
</p>
<p>two (or more) particles with the same spin can not occupy the same position; this
finding derives solely from the antisymmetry of the wave function for a system of
identical fermions, and is called Pauli principle or exclusion principle.6 As shown
in Sect. 15.7 it can be restated in different forms depending on the system under
consideration. No similar restriction applies to system of identical bosons, as the
form of the first relation in (15.23) shows.
</p>
<p>15.7 Conservative Systems of Particles
</p>
<p>An important example of a system of N interacting particles occurs when the forces
are conservative. To begin, the general case of non-identical particles is consid-
ered. The Hamiltonian function and the corresponding Hamiltonian operator read,
respectively:
</p>
<p>H =
N
&sum;
</p>
<p>i=1
</p>
<p>p2i
</p>
<p>2mi
+ V , H = &minus;
</p>
<p>N
&sum;
</p>
<p>i=1
</p>
<p>hÌ2
</p>
<p>2mi
&nabla;2i + V , (15.25)
</p>
<p>where the symbols are the same as in (15.3). Here the potential energy depends only
on the spatial coordinates, V = V
</p>
<p>(
</p>
<p>r1, . . . , rN
)
</p>
<p>. If the system is in a state of definite
and constant energy ES , its wave function reads
</p>
<p>Ï = W exp (&minus; iES t/hÌ), W = W
(
</p>
<p>q1, . . .qN
)
</p>
<p>, (15.26)
</p>
<p>where ES is an eigenvalue of HW = EW . Extending to this case the definition of
Sect. 15.2, the system is separable if V = &sum;i Vi(ri), which gives the Hamiltonian
operator the form
</p>
<p>H =
N
&sum;
</p>
<p>i=1
Hi , Hi = &minus;
</p>
<p>hÌ2
</p>
<p>2mi
&nabla;2i + Vi
</p>
<p>(
</p>
<p>ri
)
</p>
<p>. (15.27)
</p>
<p>Assuming that the eigenvalues are discrete, the ith Hamiltonian yields the single-
particle equations
</p>
<p>Hiwn(i) = En(i)wn(i), (15.28)
</p>
<p>where index n(i) denotes the nth eigenvalue of the ith particle. From the general
properties of operators (Sect. 10.3) it follows that each eigenfunction of the whole
system is the product of eigenfunctions like wn(i),
</p>
<p>W = wn(1)
(
</p>
<p>q1
)
</p>
<p>wn(2)
(
</p>
<p>q2
)
</p>
<p>. . . wn(N )
(
</p>
<p>qN
)
</p>
<p>, (15.29)
</p>
<p>6 Like the Heisenberg principle illustrated in Sect. 10.6, that of Pauli was originally deduced from
heuristic arguments. The analysis of this section shows in fact that it is a theorem rather than a
principle.</p>
<p/>
</div>
<div class="page"><p/>
<p>15.7 Conservative Systems of Particles 279
</p>
<p>and the eigenvalue of H is the sum of eigenvalues like En(i):
</p>
<p>ES = En(1) + En(2) + . . .+ En(N ). (15.30)
</p>
<p>If the particles are identical, m1 = m2 = . . . = mN , then the single-particle Hamilto-
nian operators Hi become identical to each other; as a consequence, each eigenvalue
Eq. (15.28) produces the same set of eigenvalues and eigenfunctions. It follows
that all N ! permutations of the indices 1, 2, . . . ,N in (15.30) leave the total energy
unchanged. On the other hand, as for any pair of groups qr , qs it is
</p>
<p>wn(r)
(
</p>
<p>qr
)
</p>
<p>wn(s)
(
</p>
<p>qs
)
</p>
<p>ï¿½= wn(s)
(
</p>
<p>qr
)
</p>
<p>wn(r)
(
</p>
<p>qs
)
</p>
<p>, (15.31)
</p>
<p>the total eigenfuction is changed by a permutation of the coordinate indices. Thus, to
ES there correspond N ! eigenfunctions w, namely, the eigenvalues of HW = EW
for a system of identical particles are N !-fold degenerate.
</p>
<p>As noted in Sect. 15.6, the solution (15.26) of the system&rsquo;s Schr&ouml;dinger equation
is not necessarily symmetric or antisymmetric. A solution with the correct symmetry
property is found from (15.23) and has the form
</p>
<p>Ï = a exp (&minus; iES t/hÌ)
&sum;
</p>
<p>Î½
</p>
<p>SÎ½wn(1)
(
</p>
<p>q1
)
</p>
<p>. . .wn(N )
(
</p>
<p>qN
)
</p>
<p>(15.32)
</p>
<p>in the symmetric case, and
</p>
<p>Ï = b exp (&minus; iES t/hÌ)
&sum;
</p>
<p>Î½
</p>
<p>(&minus; 1)Î½ SÎ½wn(1)
(
</p>
<p>q1
)
</p>
<p>. . .wn(N )
(
</p>
<p>qN
)
</p>
<p>(15.33)
</p>
<p>in the antisymmetric one. It is worth specifying that SÎ½ acts on the coordinate groups
q1, . . . , qN , not on the indices n(1), . . . , n(N ).
</p>
<p>When the wave function has the form (15.32) or (15.33), and the eigenfunctions
wn(1), . . . , wn(N ) are normalized to unity, the constants a and b are readily found.
Considering the symmetric case with N = 2, the wave function reads
</p>
<p>Ï = a exp (&minus; iES t/hÌ)
[
</p>
<p>wn(1)(q1) wn(2)(q2) + wn(2)(q1) wn(1)(q2)
]
</p>
<p>, (15.34)
</p>
<p>where it is assumed that the single-particle eigenfunctions are normalized to unity:
</p>
<p>&sum;
</p>
<p>sz1
</p>
<p>&int;
</p>
<p>|wn(i)(r1, sz1)|2 d3r1 = 1,
&sum;
</p>
<p>sz2
</p>
<p>&int;
</p>
<p>|wn(i)(r2, sz2)|2 d3r2 = 1. (15.35)
</p>
<p>In (15.35) it is i = 1, 2, and the indication of the domain of r1, r2 is omitted. As
n(2) ï¿½= n(1), the pairs of eigenfunctions with such indices are mutually orthogonal
(Sect. 8.4.1), whence
</p>
<p>&sum;
</p>
<p>sz1
</p>
<p>&sum;
</p>
<p>sz2
</p>
<p>&int;&int;
</p>
<p>|Ï
(
</p>
<p>r1, sz1, r2, sz2
)
</p>
<p>|2 d3r1 d3r2 = 2 |a|2. (15.36)
</p>
<p>Imposing the normalization of Ï to unity, and observing that the phase factor in a
is irrelevant, yields a = 1/
</p>
<p>&radic;
2. The treatment of (15.33) is identical and yields the</p>
<p/>
</div>
<div class="page"><p/>
<p>280 15 Many-Particle Systems
</p>
<p>same result for b. By the same token, one finds a = b = 1/
&radic;
N ! in the N -particle
</p>
<p>case. Still with reference to the antisymmetric wave function (15.33), one notes that
its spatial part can be recast as a determinant,
</p>
<p>&sum;
</p>
<p>Î½
</p>
<p>(&minus; 1)Î½ SÎ½wn(1)
(
</p>
<p>q1
)
</p>
<p>. . .wn(N )
(
</p>
<p>qN
)
</p>
<p>=
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â£
</p>
<p>wn(1)
(
</p>
<p>q1
)
</p>
<p>&middot; &middot; &middot; wn(N )
(
</p>
<p>q1
)
</p>
<p>...
. . .
</p>
<p>...
</p>
<p>wn(1)
(
</p>
<p>qN
)
</p>
<p>&middot; &middot; &middot; wn(N )
(
</p>
<p>qN
)
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¦
</p>
<p>,
</p>
<p>(15.37)
</p>
<p>that is called Slater determinant. A transposition of two particles involves the ex-
change of the corresponding coordinate sets, but not of the eigenfunction indices; this
is equivalent to exchanging two rows of the determinant, whence the change of sign.
Also, if two or more particles belonged to the same state (including spin), two or more
columns of the Slater determinant would be equal to each other and the wave function
(15.33) would vanish. This is another form of the proof of Pauli&rsquo;s exclusion principle.
</p>
<p>15.8 Equilibrium Statistics in the Quantum Case
</p>
<p>This section illustrates the quantum-mechanical treatment of a system of particles in
a condition of macroscopic equilibrium. The approach is the same as that outlined
in Sect. 6.3 for the classical case; however, the constraints to which the particles
are subjected are different. Here the term &ldquo;particle&rdquo; is used in a broader meaning,
incorporating, e.g., also the case of photons (Sect. 12.3) and phonons (Sect. 16.6).
As in Sect. 6.3 one considers a conservative system of identical particles, having a
total energy ES , enclosed in a stationary container of volume ï¿½. The conservation
of the total energy introduces a first constraint, identical to (6.10):
</p>
<p>FE
(
</p>
<p>N1,N2, . . .
)
</p>
<p>= 0, FE = &minus;ES +
&sum;
</p>
<p>i
</p>
<p>Ni Ei . (15.38)
</p>
<p>The constraint identical to (6.9),
</p>
<p>FN
(
</p>
<p>N1,N2, . . .
)
</p>
<p>= 0, FN = &minus;N +
&sum;
</p>
<p>i
</p>
<p>Ni , (15.39)
</p>
<p>describing the conservation of the total number of particles, may, instead, be fulfilled
or not depending on the type of particles. For instance, a system of photons does
not fulfill it: in fact, a photon may be absorbed by the container&rsquo;s wall and, say,
two photons may be emitted by it, such that the energy of the emitted photons
equals that of the absorbed one. In this way, constraint (15.38) applies, whereas
constraint (15.39) does not. Another difference from the classical treatment is that,
as remarked in Sect. 15.5, identical quantum particles belonging to a system are
not distinguishable from each other; as a consequence, the method of counting their</p>
<p/>
</div>
<div class="page"><p/>
<p>15.8 Equilibrium Statistics in the Quantum Case 281
</p>
<p>Î·
0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>Fig. 15.2 Placement of three identical particles into equally-spaced energy states. The particles&rsquo;
total energy equals three energy units Î·. Different graphic symbols are used for the particles to
make the classical treatment clearer
</p>
<p>placement into the cells of the phase space (illustrated in Sect. 6.3 for the classical
case), is different here. A further distinction must be made between the cases of
systems made of fermions, to which the exclusion principle applies, and systems
made of bosons, to which it does not apply. To appreciate the strong differences
that are introduced by the constraints due to indistinguishability and exclusion, the
example below is of help.
</p>
<p>Consider a system made of three identical particles, whose total energy ES is,
in some units Î·, equal to 3 Î·. For simplicity, the particles are considered spinless
and, instead of the phase space, a space made of energy cells7 is used, where the
energies of the particles are assumed to be quantized starting from a ground level. As
a consequence, the energies allowed to the particles are 0, Î·, 2 Î·, 3 Î·, . . . ; the energy
levels are shown in Fig. 15.2, where the particles are drawn with different graphics to
make them provisionally distinguishable. If the system is considered as classical, it
is easily found that there are ten possible ways of placing the three particles into the
available states in such a way as to fulfill the energy constraint ES = 3 Î·. One way
is to place all three particles in the Î· state. Another choice is to place one particle in
the 3 Î· state and the remaining two in the ground state; this provides three different
ways, as there are three distinct possibilities to choose the particle to be placed in the
3 Î· state. The last choice is to place one particle in the ground state, another particle
in the Î· state, and the remaining one in the 2 Î· state; this yields 3! ways as shown in
the figure. If, instead, the particles are bosons, the three former combinations with
energies (0, 0, 3Î·) reduce to a single one because of the particles&rsquo;indistinguishability;
by the same token, the six former combinations with energies (0, Î·, 2Î·) reduce to a
single one as well. This gives a total of three ways for bosons, in contrast with the ten
ways of the classical particles. Finally, if the particles are fermions, the combinations
(Î·, Î·, Î·) and (0, 0, 3Î·) must be excluded because the exclusion principle forbids one
or more fermions to occupy the same state; as a consequence, the only way left for
fermions is (0, Î·, 2Î·), that fulfills both indistinguishability and exclusion.
</p>
<p>Coming back to the general case, consider a system in thermodynamic equilibrium
at temperature T , with ES the system&rsquo;s total energy. As in the classical case outlined
in Sect. 6.3, the system is considered dilute, namely such that the mutual interaction
</p>
<p>7 The use of energy intervals does not entail a loss of generality, as the subsequent treatment of the
general case will show.</p>
<p/>
</div>
<div class="page"><p/>
<p>282 15 Many-Particle Systems
</p>
<p>among the particles, albeit necessary for the existence of the system, is weak enough
to assume that the energy of the interaction among the particles is negligible within
the Hamiltonian operator. It follows that the latter is separable, and the expressions
found in Sect. 15.7 are applicable. As the particles are identical, the single-particle
eigenvalues En(i) and eigenfunctions wn(i)(qi) obtained by solving (15.28) are the
same for all particles. Also, the indices8 n(i) are those of an energy, so that the
procedure of placing the particles into the available states can be carried out directly
in the energy space. To account for spin, states corresponding to the same energy and
different spin are to be considered as distinct. The minimum eigenvalue of (15.28)
is fixed by the form of the potential energy within the Hamiltonian operator. Given
these premises, the energy axis is divided into equal intervals of length ï¿½E; as in the
classical case, the partitioning has the advantage that the set of intervals is countable.
The intervals are numbered starting from the one containing the minimum eigenvalue
mentioned above, and their size ï¿½E is such that each of them contains a number of
eigenvalues of (15.28). Let gr be the number of eigenvalues within the rth interval,
r = 1, 2 . . . , and Nr the number of particles whose eigenvalues belong to the same
interval; if the size ï¿½E is taken small, one can approximate the energy of the Nr
particles with the product Nr Er , where Er is the energy at the interval&rsquo;s center.
Following the same procedure as in Sect. 6.4, one then constructs the function
</p>
<p>F
(
</p>
<p>N1,N2, . . . ,Î±,Î²
)
</p>
<p>= logW + Î± FN + Î² FE , (15.40)
</p>
<p>where Î±, Î² are the Lagrange multipliers, respectively related to the total number of
particles and total energy of the system, and the form of W depends on the type of
particles, as shown below. If the constraint on the total number of particles is not
applicable, one lets Î± = 0. Using the numbers N1, N2, . . . as continuous variables,
taking the derivative of F with respect to Nr and equating it to zero yields
</p>
<p>&part;
</p>
<p>&part;Nr
logW = Î± + Î² Er . (15.41)
</p>
<p>On the other hand it is W = W1 W2 . . . ,Wr . . . , where Wr is the number of ways
in which Nr particles can be placed into the gr states of the rth interval, subjected to
the constraints of the type of particles under consideration. As in the left hand side
of (15.41) only the rth summand depends on Nr , the relation to be worked out is
eventually
</p>
<p>&part;
</p>
<p>&part;Nr
logWr = Î± + Î² Er . (15.42)
</p>
<p>The expression of Wr depends on the type of particles; it is given in Sect. 15.8.1 for
the case of fermions and in Sect. 15.8.2 for that of bosons.
</p>
<p>8 Here the eigenvalues of the Hamiltonian operator are discrete because the system is enclosed in
a container, hence the wave function is normalizable. As usual, the notation n(i) stands for a group
of indices.</p>
<p/>
</div>
<div class="page"><p/>
<p>15.8 Equilibrium Statistics in the Quantum Case 283
</p>
<p>15.8.1 Fermi&ndash;Dirac Statistics
</p>
<p>For a system of fermions it is Nr &le; gr due to the exclusion principle. To calculate the
number of ways of placing Nr particles into gr states one provisionally assumes that
the particles are distinguishable. There are gr possibilities to place the first particle;
after the latter has been placed, there remain gr &minus; 1 states due to the exclusion
principle, hence the different ways of placing the first two (distinct) particles are
gr
</p>
<p>(
</p>
<p>gr &minus; 1
)
</p>
<p>. The process continues until all Nr particles are used up, this leading to
gr
</p>
<p>(
</p>
<p>gr &minus; 1
)
</p>
<p>. . .
(
</p>
<p>gr &minus;Nr + 1
)
</p>
<p>ways of placing them. On the other hand the particles
are not distinct; as a consequence, after the placement is completed, any of the Nr !
permutations of the particles corresponds to the same placement. In conclusion, the
product above must be divided by Nr !, this leading to
</p>
<p>Wr =
gr
</p>
<p>(
</p>
<p>gr &minus; 1
)
</p>
<p>. . .
(
</p>
<p>gr &minus;Nr + 1
)
</p>
<p>Nr !
= gr !
</p>
<p>Nr !
(
</p>
<p>gr &minus;Nr
)
</p>
<p>! =
(
gr
</p>
<p>Nr
</p>
<p>)
</p>
<p>. (15.43)
</p>
<p>Using the same procedure as in Sect. 6.4 yields
</p>
<p>d logWr
dNr
</p>
<p>= d log
[(
</p>
<p>gr &minus;Nr
)
</p>
<p>!
]
</p>
<p>d
(
</p>
<p>&minus;Nr
) &minus; d log
</p>
<p>(
</p>
<p>Nr !
)
</p>
<p>dNr
â log
</p>
<p>(
</p>
<p>gr &minus;Nr
)
</p>
<p>&minus; log
(
</p>
<p>Nr
)
</p>
<p>(15.44)
</p>
<p>which, combined with (15.42), provides Nr = gr/[ exp (Î± + Î²Er ) + 1]. For con-
venience, the total number of particles is indicated here with NS instead of N ; the
constraints then read
</p>
<p>U
&sum;
</p>
<p>r=1
</p>
<p>gr
</p>
<p>exp
(
</p>
<p>Î± + Î² Er
)
</p>
<p>+ 1 = NS ,
U
&sum;
</p>
<p>r=1
</p>
<p>grEr
</p>
<p>exp
(
</p>
<p>Î± + Î² Er
)
</p>
<p>+ 1 = ES , (15.45)
</p>
<p>by which the two Lagrange multipliers Î± and Î² are determined. The sums are carried
out up to a maximum energy EU ; in fact, being the total energy of the system
prescribed, there exists a maximum energy that the single particle can not exceed.
As outlined in Sect. 15.9.1, a comparison with the findings of Thermodynamics
shows that, in full analogy with the classical case treated in Sect. 6.4, it is
</p>
<p>Î² = 1
kBT
</p>
<p>, (15.46)
</p>
<p>where kB â 1.38 &times; 10&minus;23 J K&minus;1 is Boltzmann&rsquo;s constant and T the system temper-
ature. As a consequence it is Î± = Î±(T ). Defining the Fermi energy or Fermi level
EF (T ) = &minus;kB T Î±(T ), the expression of Nr becomes
</p>
<p>Nr =
gr
</p>
<p>exp [(Er &minus; EF ) / (kB T )] + 1
. (15.47)
</p>
<p>In general the number of energy levels is large and their separation small so that,
instead of using the number gr of states at energy Er , one disposes of the index and</p>
<p/>
</div>
<div class="page"><p/>
<p>284 15 Many-Particle Systems
</p>
<p>Fig. 15.3 The Fermi&ndash;Dirac
statistics as a function of
energy for different values of
the system&rsquo;s temperature. For
simplicity the temperature
dependence of the Fermi level
EF is not considered
</p>
<p>-0.4 -0.2 0 0.2 0.4
E - E
</p>
<p>F
   (eV)
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>P
 (
</p>
<p>E
)
</p>
<p>T = 200 K
T = 300 K
T = 400 K
</p>
<p>considers the number g(E) dE of states in the infinitesimal interval dE around E.
Thus, g(E) indicates the number of states per unit energy, and is called density of
states in energy (compare with Sect. B.5). The constraints now read
</p>
<p>&int; EU
</p>
<p>E1
</p>
<p>g(E) dE
</p>
<p>exp
(
</p>
<p>Î± + Î²E
)
</p>
<p>+ 1 = NS ,
&int; EU
</p>
<p>E1
</p>
<p>E g(E) dE
</p>
<p>exp
(
</p>
<p>Î± + Î²E
)
</p>
<p>+ 1 = ES , (15.48)
</p>
<p>with Î² = 1/(kBT ). Consistently, Nr is replaced with N (E) dE, where N (E) is
the number of particles per unit energy.9 As a consequence, the relation N (E) =
g(E)P (E) is fulfilled, where function
</p>
<p>P (E) = 1
exp [(E &minus; EF ) / (kB T )] + 1
</p>
<p>(15.49)
</p>
<p>is called Fermi&ndash;Dirac statistics. As 0 &lt; P (E) &lt; 1, the Fermi&ndash;Dirac statistics bears
also the meaning of occupation probability of a state at energy E. Its high-energy tail
(
</p>
<p>E &minus; EF â« kB T
)
</p>
<p>identifies with the Maxwell&ndash;Boltzmann distribution law (6.14).
The dependence of (15.49) on E is shown in Fig. 15.3 at different temperatures. The
states whose energy is substantially lower than the Fermi level
</p>
<p>(
</p>
<p>E&minus;EF âª &minus;kB T
)
</p>
<p>are mostly filled with particles, those whose energy is substantially higher than the
Fermi level are mostly empty. The energy states in the vicinity of the Fermi level have
a probability around 1/2 of being filled. For the sake of simplicity the dependence
of EF on T is not considered in the figure; in fact, it is influenced by the form of
g(E) and must therefore be determined on a case-by-case basis. In the limit T &rarr; 0
the function becomes discontinuous, specifically it is P = 1 for E &lt; EF and P = 0
for E &gt; EF .
</p>
<p>9 The units are [g], [N ] = J&minus;1.</p>
<p/>
</div>
<div class="page"><p/>
<p>15.8 Equilibrium Statistics in the Quantum Case 285
</p>
<p>15.8.2 Bose&ndash;Einstein Statistics
</p>
<p>For a system of Bosons the exclusion principle does not hold, hence it may be
Nr &ge; gr . Also in this case, to calculate the number of ways of placing Nr particles,
not subject to the exclusion principle, into gr states, one provisionally assumes
that the particles are distinguishable. This yields a number of ways equal to
</p>
<p>(
</p>
<p>gr +
Nr &minus; 1
</p>
<p>)(
</p>
<p>gr +Nr &minus; 2
)
</p>
<p>. . . gr . Then, to account for indistinguishability one divides
the result by Nr !, to find
</p>
<p>Wr =
(
</p>
<p>gr +Nr &minus; 1
)
</p>
<p>. . . gr
</p>
<p>Nr !
=
</p>
<p>(
</p>
<p>gr +Nr &minus; 1
)
</p>
<p>!
Nr !
</p>
<p>(
</p>
<p>gr &minus; 1
)
</p>
<p>! =
(
gr +Nr &minus; 1
</p>
<p>Nr
</p>
<p>)
</p>
<p>. (15.50)
</p>
<p>Using the same procedure as in Sect. 6.4 yields
</p>
<p>d logWr
dNr
</p>
<p>= d log
[
</p>
<p>(gr +Nr &minus; 1)!
]
</p>
<p>dNr
&minus; d log
</p>
<p>(
</p>
<p>Nr !
)
</p>
<p>dNr
â log
</p>
<p>(
</p>
<p>gr +Nr &minus; 1
)
</p>
<p>&minus; logNr
(15.51)
</p>
<p>which, combined with (15.42) after neglecting the unity in gr + Nr &minus; 1, yields
Nr = gr/
</p>
<p>[
</p>
<p>exp (Î±+Î²Er )&minus;1
]
</p>
<p>. As in the latter it isNr , gr &gt; 0, it followsÎ±+Î²Er &gt; 0.
Still indicating the number of particles with NS instead of N , the constraints read
</p>
<p>U
&sum;
</p>
<p>r=1
</p>
<p>gr
</p>
<p>exp
(
</p>
<p>Î± + Î² Er
)
</p>
<p>&minus; 1 = NS ,
U
&sum;
</p>
<p>r=1
</p>
<p>gr Er
</p>
<p>exp
(
</p>
<p>Î± + Î² Er
)
</p>
<p>&minus; 1 = ES , (15.52)
</p>
<p>by which the two Lagrange multipliers Î± and Î² are determined. The explanation
of the upper summation limit U in (15.52) is similar to that given in Sect. 15.8.1.
As outlined in Sect. 15.9.5, a comparison with the findings of Thermodynamics
shows that, in full analogy with the cases of Sects. 6.4 and 15.8.1, Î² is given by
(15.46), whence it is Î± = Î±(T ). Defining EB(T ) = &minus;kB T Î±(T ), the expression of
Nr becomes
</p>
<p>Nr =
gr
</p>
<p>exp [(Er &minus; EB) / (kB T )] &minus; 1
. (15.53)
</p>
<p>The inequality Î± + Î² Er &gt; 0 found above implies Er &gt; EB . If the constraint on
the number of particles does not hold, one lets Î± = 0 whence EB = 0, Er &gt; 0.
In general the number of energy levels is large and their separation small so that,
instead of using the number gr of states at energy Er , one disposes of the index and
considers the number g(E) dE of states in the infinitesimal interval dE around E.
The constraints now read
</p>
<p>&int; EU
</p>
<p>E1
</p>
<p>g(E) dE
</p>
<p>exp (Î± + Î² E) &minus; 1 = NS ,
&int; EU
</p>
<p>E1
</p>
<p>E g(E) dE
</p>
<p>exp (Î± + Î² E) &minus; 1 = ES , (15.54)</p>
<p/>
</div>
<div class="page"><p/>
<p>286 15 Many-Particle Systems
</p>
<p>with Î² = 1/(kB T ). Consistently, Nr is replaced with N (E) dE, where N (E) is
the number of particles per unit energy. As a consequence, the relation N (E) =
g(E)P (E) is fulfilled, where function
</p>
<p>P (E) = 1
exp [(E &minus; EB) / (kB T )] &minus; 1
</p>
<p>(15.55)
</p>
<p>is called Bose&ndash;Einstein statistics. As P (E) may be larger than unity, the Bose&ndash;
Einstein statistics is not a probability; rather, it represents the occupation number
of a state at energy E. Its high-energy tail
</p>
<p>(
</p>
<p>E &minus; EB â« kB T
)
</p>
<p>identifies with the
Maxwell&ndash;Boltzmann distribution law (6.14).
</p>
<p>15.9 Complements
</p>
<p>15.9.1 Connection with Thermodynamic Functions
</p>
<p>The calculation of the equilibrium distribution carried out in Sects. 6.4, 15.8.1, and
15.8.2 respectively for classical particles, fermions, and bosons, entails the maxi-
mization of the function logW , subjected to suitable constraints. On the other hand,
from the second principle of Thermodynamics one derives that the equilibrium state
of a system corresponds to the condition that the system&rsquo;s entropy S has a maximum.
For this reason one expects that a functional dependence W (S) exists; to identify
its form one notes that, if W1 and W2 indicate the value of W of two independent
systems, the value for the composite system is W1 W2 due to the definition of W . On
the other hand, entropy is additive, so that the functional dependence sought must be
such that S
</p>
<p>(
</p>
<p>W1 W2
)
</p>
<p>= S
(
</p>
<p>W1
)
</p>
<p>+ S
(
</p>
<p>W2
)
</p>
<p>, namely, of the logarithmic type. In fact it is
</p>
<p>S = kB logW , (15.56)
</p>
<p>with kB = 1.38 &times; 10&minus;23 J K&minus;1 the Boltzmann constant. The choice of the constant
makes (15.56) consistent with the definition dS = dQ/T of entropy in Thermody-
namics, with dQ the heat absorbed during an infinitesimal transformation.10
</p>
<p>Now, consider a system subjected to both constraints (15.38) and (15.39), and
assume that the container where the system is placed undergoes an infinitesimal
volume change11 dï¿½ which, in turn, makes all variables Nr and gr to change; due to
(15.41) it is &part; logW/&part;Nr = Î± + Î² Er so that [27]
</p>
<p>1
</p>
<p>kB
dS = d logW =
</p>
<p>U
&sum;
</p>
<p>r=1
</p>
<p>[
</p>
<p>(Î± + Î² Er) dNr +
&part; logW
</p>
<p>&part;gr
dgr
</p>
<p>]
</p>
<p>. (15.57)
</p>
<p>10 Compare with the non-equilibrium definition of entropy introduced in Sect. 6.6.3 and the note
therein.
11 The geometrical configuration is kept similar to the original one during the change in volume.</p>
<p/>
</div>
<div class="page"><p/>
<p>15.9 Complements 287
</p>
<p>Using the constraints and the relation dS = dQ/T transforms (15.57) into
</p>
<p>dQ = kB T Î± dN + kB T Î² dES + kB T
U
&sum;
</p>
<p>r=1
</p>
<p>(
&part; logW
</p>
<p>&part;gr
</p>
<p>dgr
dï¿½
</p>
<p>)
</p>
<p>dï¿½. (15.58)
</p>
<p>Assuming that during the change in volume there is no exchange of matter with the
environment, one lets dN = 0 in (15.58); the first principle of Thermodynamics
shows that for this type of transformation it is dQ = dES + P dï¿½, with P the
pressure at the boundary of ï¿½. A comparison with (15.58) then yields
</p>
<p>kB T Î² = 1, kB T
U
&sum;
</p>
<p>r=1
</p>
<p>(
&part; logW
</p>
<p>&part;gr
</p>
<p>dgr
dï¿½
</p>
<p>)
</p>
<p>= P. (15.59)
</p>
<p>The first of (15.59) coincides with (6.26), and provides the expected relation between
one of the Lagrange multipliers of (15.45) and a state function of Thermodynamics.
</p>
<p>15.9.2 Density of States for a Particle in a Three-Dimensional Box
</p>
<p>The density of states g(E) that has been introduced in (15.48) and (15.54) is the
number of states per unit energy. Its form depends on the system under consideration.
Two examples of the derivation of g(E) are given here (with reference to the problem
of an electron in a box) and in Sect. 15.9.4 (with reference to photons).
</p>
<p>The problem of the particle confined within a one-dimensional box has been
tackled in Sect. 8.2.2. The set of eigenvalues is given by the first relation in (8.6), and
the corresponding eigenfunctions are (8.8). For a three-dimensional box whose sides
have lengths d1, d2, d3, due to the properties of separable operators (Sect. 10.3), the
eigenfunctions are products of one-dimensional eigenfunctions,
</p>
<p>wn1n2n3 (r) =
&radic;
</p>
<p>8/V sin
(
</p>
<p>kn1 x1
)
</p>
<p>sin
(
</p>
<p>kn2 x2
)
</p>
<p>sin
(
</p>
<p>kn3 x3
)
</p>
<p>, (15.60)
</p>
<p>where V = d1 d2 d3 is the volume of the box. In turn, the eigenvalues are
</p>
<p>En1n2n3 = En1 + En2 + En3 , Eni =
hÌ2 k2ni
</p>
<p>2m
, kni = ni
</p>
<p>Ï
</p>
<p>di
, (15.61)
</p>
<p>namely,
</p>
<p>E = hÌ
2 k2
</p>
<p>2m
, k = n1
</p>
<p>Ï
</p>
<p>d1
i1 + n2
</p>
<p>Ï
</p>
<p>d2
i2 + n3
</p>
<p>Ï
</p>
<p>d3
i3, ni = 1, 2, . . . (15.62)
</p>
<p>with i1, . . . the unit vectors of the Cartesian axes and k2 = k &middot; k. In contrast with
the one-dimensional case, the eigenvalues (15.61) are degenerate, because different
triads n1, n2, n3 correspond to the same energy.</p>
<p/>
</div>
<div class="page"><p/>
<p>288 15 Many-Particle Systems
</p>
<p>The density of states could be calculated by the procedure depicted in Sect. (B.5),
with the provision that in this case the variables kni belong to a discrete set whereas
those in Sect. B.5 are continuous. On the other hand, the relations involved here
are simple enough to be tackled by a direct calculation. One observes, first, that the
distance between two consecutive projections of k along the ith axis is Ï/di ; as a
consequence, one may partition the k1k2k3 space into equal volumes12 Ï3/V , so that
each k vector is associated to one and only one volume: this shows that the density
of k vectors in the k1 k2 k3 space is Qk = V/Ï3. Given the electron&rsquo;s energy E, from
the geometrical point of view the first relation in (15.62) describes a sphere of radius
(2mE/hÌ2)1/2 in the k1 k2 k3 space; thus, the total number Nk of Ï3/V volumes
contained within the sphere is obtained by multiplying the sphere&rsquo;s volume by the
densityQk . Clearly the volumes that are near the boundary produce a ragged surface;
the latter is identified with that of the sphere by assuming that the distribution of k
vectors belonging to the spherical surface is very dense. With this provision one finds
</p>
<p>Nk = Qk
4
</p>
<p>3
Ï k3 = V
</p>
<p>Ï3
</p>
<p>4
</p>
<p>3
Ï
</p>
<p>(
2mE
</p>
<p>hÌ2
</p>
<p>)3/2
</p>
<p>= V
Ï2
</p>
<p>8
&radic;
</p>
<p>2m3/2
</p>
<p>3 hÌ3
E3/2. (15.63)
</p>
<p>As indices n1, n2, n3 take only positive values, the k vectors belong to 1/8 of the
sphere only; it follows that their number is Nk/8. Each k vector is associated to
a triad of quantum numbers n1, n2, n3; however, to completely define the state of
the electron a fourth quantum number is necessary, related to spin (Sect. 15.5.1).
Remembering that electrons have two possible spin states, one finds that the number
of electron states within the sphere is twice the number of k vectors, namely, Nk/4.
Finally, the number of states per unit energy is found by differentiating the latter
with respect to energy,13
</p>
<p>d
Nk
</p>
<p>4
=
</p>
<p>&radic;
2Vm3/2
</p>
<p>Ï2hÌ3
E1/2 dE = g(E) dE, g(E) =
</p>
<p>&radic;
2V m3/2
</p>
<p>Ï2 hÌ3
E1/2. (15.64)
</p>
<p>Apart from the constants involved, this results is consistent with (B.34). Along with
the density of state in energy it is useful to define a combined density of states in
energy and coordinate space, that is indicated with Î³ . In the case of the electron
within a box one finds, from (15.64),
</p>
<p>Î³ (E) = g(E)
V
</p>
<p>=
&radic;
</p>
<p>2m3/2
</p>
<p>Ï2 hÌ3
E1/2. (15.65)
</p>
<p>12 Here the term &ldquo;volume&rdquo; is used in a broader meaning; in fact, the units of Ï3/V are m&minus;3.
13 As noted above the k vectors, hence the values of energy corresponding to them, are distributed
very densely. This makes it possible to treat E as a continuous variable.</p>
<p/>
</div>
<div class="page"><p/>
<p>15.9 Complements 289
</p>
<p>15.9.3 Density of States for a Two- or One-Dimensional Box
</p>
<p>As observed in Sect. B.5, the functional dependence of g on E is influenced by the
number of spatial dimensions: considering by way of example the case of an electron
within a two-dimensional box, one must associate to each vector k an area of the
k1k2 space equal to Ï2/
</p>
<p>(
</p>
<p>d1 d2
)
</p>
<p>= Ï2/A, where A = d1 d2 is the area of the box. The
density of the k vectors in the k1k2 space is Qk = A/Ï2, whence the total number
of Ï2/A areas in a circle of radius
</p>
<p>(
</p>
<p>2mE/hÌ2
)1/2
</p>
<p>is
</p>
<p>Nk = Qk Ï k2 =
A
</p>
<p>Ï2
Ï
</p>
<p>2mE
</p>
<p>hÌ2
. (15.66)
</p>
<p>As indices n1, n2 take only positive values, the k vectors belong to 1/4 of the circle
only; it follows that their number is Nk/4. Accounting for spin one finds that the
number of states within the circle is twice the number of k vectors, namely, Nk/2.
Finally, the number of states per unit energy is found by differentiating the latter
with respect to energy,
</p>
<p>g(E) = dNk/2
dE
</p>
<p>= Am
Ï hÌ2
</p>
<p>. (15.67)
</p>
<p>When the energy dependence on the k coordinates is quadratic, the density of states
of a two-dimensional case is constant (compare with (B.33)).
</p>
<p>Finally, considering the case of an electron within a one-dimensional box, one
must associate to each vector k a segment Ï/d1 of the k1 space, to find Qk = d1/Ï
for the density of the k vectors. The total number of Ï/d1 segments in a domain of
length
</p>
<p>(
</p>
<p>2mE/hÌ2
)1/2
</p>
<p>is
</p>
<p>Nk =
d1
</p>
<p>Ï
</p>
<p>(
2mE
</p>
<p>hÌ2
</p>
<p>)1/2
</p>
<p>. (15.68)
</p>
<p>Accounting for spin one finds that the number of states within the domain is twice
the number of k vectors, namely, 2Nk . Finally, the number of states per unit energy
is found by differentiating the latter with respect to energy,
</p>
<p>g(E) = d2Nk
dE
</p>
<p>= d1 (2m)
1/2
</p>
<p>Ï hÌE1/2
, (15.69)
</p>
<p>to be compared with (B.32). Expression (15.67) is useful, e.g., for treating the
problem of a two-dimensional charge layer in the channel of a semiconductor de-
vice (Sect. 17.6.7); in turn, expression (15.69) is used with reference to nanowires
(Sect. 17.6.7);</p>
<p/>
</div>
<div class="page"><p/>
<p>290 15 Many-Particle Systems
</p>
<p>15.9.4 Density of States for Photons
</p>
<p>Consider the case of the electromagnetic field within a box whose sides d1, d2, d3
are aligned with the coordinate axes and start from the origin. It is assumed that no
charge is present within the box, so that the calculation of the modes is the same as
that illustrated in Sect. 5.5. The wave vectors have the form
</p>
<p>k = n1
2Ï
</p>
<p>d1
i1 + n2
</p>
<p>2Ï
</p>
<p>d2
i2 + n3
</p>
<p>2Ï
</p>
<p>d3
i3, ni = 0,&plusmn;1,&plusmn;2, . . . , (15.70)
</p>
<p>the angular frequency of the mode corresponding to k is Ï = c k, with k the modulus
of k, and the energy of each photon of that mode is E = hÌ Ï = hÌ c k, with c the
speed of light. The calculation of the density of states associated to this case follows
the same line as that used in Sect. 15.9.2 for a particle in a three-dimensional box;
the differences are that the distance between two consecutive projections of k along
the ith axis is 2Ï/di instead of Ï/di , the indices ni are not limited to the positive
values, and the E(k) relation is linear instead of being quadratic.
</p>
<p>With these premises, and with reference to Fig. 15.4, the volume associated to
each k is (2Ï )3/(d1 d2 d3) = (2Ï )3/V , where V is the volume of the box, so that the
density of the k vectors in the k space is Qk = V/(2Ï )3; in turn, the total number
of k vectors within a sphere of radius k like that shown in the figure is14
</p>
<p>Nk = Qk
4
</p>
<p>3
Ï k3 = V
</p>
<p>(2Ï )3
4
</p>
<p>3
Ï
</p>
<p>E3
</p>
<p>hÌ3 c3
= V
</p>
<p>2Ï2
E3
</p>
<p>3 hÌ3 c3
. (15.71)
</p>
<p>Due to spin, the total number of states is 2Nk so that, differentiating with respect to
energy,
</p>
<p>d2Nk =
V
</p>
<p>Ï2
</p>
<p>E2
</p>
<p>hÌ3 c3
dE = g(E) dE, g(E) = V
</p>
<p>Ï2 hÌ3 c3
E2. (15.72)
</p>
<p>The result expressed by (15.72) can be recast in equivalent forms by using another
variable proportional to energy; for instance, lettingG(Ï) denote the density of states
with respect to angular frequency and gÌ(Î½) denote the density of states with respect
to frequency, from the relations
</p>
<p>gÌ(Î½) dÎ½ = G(Ï) dÏ = g(E) dE, E = hÌ Ï = hÌ 2Ï Î½ (15.73)
</p>
<p>one obtains
</p>
<p>G(Ï) = V
Ï2 c3
</p>
<p>Ï2, gÌ(Î½) = 8Ï V
c3
</p>
<p>Î½2. (15.74)
</p>
<p>14 The calculation shown here is equivalent to counting the number of elements of volume
(2Ï )3/
</p>
<p>(
</p>
<p>d1 d2 d3
)
</p>
<p>that belong to the spherical shell drawn in Fig. 15.4. The result is then multiplied
by 2 to account for spin.</p>
<p/>
</div>
<div class="page"><p/>
<p>15.9 Complements 291
</p>
<p>Fig. 15.4 Constant-energy
sphere of the k space
illustrating the procedure for
determining the density of
states
</p>
<p>32   / dÏ
</p>
<p>2   / d1Ï 2   / d2Ï
</p>
<p>k1
</p>
<p>k2
</p>
<p>k3
</p>
<p>15.9.5 Derivation of Planck&rsquo;s Law
</p>
<p>As illustrated in Sect. 7.4.1, Planck&rsquo;s law provides the black-body&rsquo;s spectral energy
density u at equilibrium. From its definition it follows that the product u dÎ½ is the
electromagnetic energy per unit volume in the elementary interval dÎ½; using the
quantum concepts, the electromagnetic energy in dÎ½ may, in turn, be written as
the product of the number dNph of photons belonging to dÎ½ by the energy h Î½ of
each photon. Considering that photons are bosons, and that the equilibrium case is
considered, the number dNph is given in turn by the product gÌ(Î½) dÎ½ P (E = h Î½),
with P the Bose&ndash;Einstein statistics (15.55). In summary, using the second relation
in (15.74), one finds
</p>
<p>u dÎ½ = 1
V
</p>
<p>h Î½ dNph =
h Î½
</p>
<p>V
</p>
<p>gÌ(Î½) dÎ½
</p>
<p>exp (Î² h Î½) &minus; 1 =
8Ï h Î½3/c3
</p>
<p>exp (Î² h Î½) &minus; 1 dÎ½. (15.75)
</p>
<p>The expression of the Bose&ndash;Einstein statistic used in (15.75) accounts for the fact that
the number of photons is not conserved, so that the only constraint to be considered
is that on the total electromagnetic energy within volume V . It follows that the Bose&ndash;
Einstein statistics has only one Lagrange multiplier, whose value is provisionally left
undetermined. From (15.75) one derives Planck&rsquo;s law
</p>
<p>u(Î½,Î²) = 8Ï h Î½
3/c3
</p>
<p>exp (Î² h Î½) &minus; 1 , (15.76)
</p>
<p>to be compared with (7.19). Like in Sect. 15.9.1, the undetermined parameter Î² is
obtained by comparing the result of the microscopic derivation carried out above
with those of Thermodynamics. Letting W eqem be the electromagnetic energy within
V at equilibrium, the following relations hold:
</p>
<p>W
eq
em
</p>
<p>V
=
</p>
<p>&int; &infin;
</p>
<p>0
u dÎ½,
</p>
<p>W
eq
em
</p>
<p>V
= 4
</p>
<p>c
Ï T 4, (15.77)</p>
<p/>
</div>
<div class="page"><p/>
<p>292 15 Many-Particle Systems
</p>
<p>with Ï â 5.67 10&minus;12 W cm&minus;2K&minus;4 the Stefan&ndash;Boltzmann constant. In fact, the first
one derives from the definition of spectral energy density, while the second one
(called Stefan&ndash;Boltzmann law) is found experimentally, On the other hand, using
(C.127) one finds
</p>
<p>&int; &infin;
</p>
<p>0
u dÎ½ = 8Ï h
</p>
<p>c3 (Î²h)4
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>(Î² h Î½)3
</p>
<p>exp (Î² h Î½) &minus; 1 d(Î² h Î½) =
8Ï
</p>
<p>c3 h3 Î²4
</p>
<p>Ï4
</p>
<p>15
. (15.78)
</p>
<p>Combining (15.78) with (15.77) yields 1/(Î²T )4 = 15 c2 h3 Ï/(2Ï5); replacing the
constants at the right hand side of the latter shows that the units and numerical value of
it are those of k4B ; it follows that 1/(Î²T )
</p>
<p>4 = k4B and the expected result Î² = 1/(kB T )
is found.
</p>
<p>Problems
</p>
<p>15.1 Estimate the extension of the energy region where the main variation of the
Fermi statistics (15.49) occurs.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 16
</p>
<p>Separation of Many-Particle Systems
</p>
<p>16.1 Introduction
</p>
<p>The chapter illustrates a number of steps that are necessary to reduce the many-
particle problem to a tractable form. The analysis starts from a system of interacting
electrons and nuclei; such a system is not made of identical particles and its Hamil-
tonian operator is not necessarily separable. Besides that, the number of particles
that are present in the typical volume of, e.g., a solid-state device is so huge that the
solution of the Schr&ouml;dinger equation of such a system in the original form is a hope-
less task. The first step consists in the application of the adiabatic approximation, by
which the system made of the electrons is separated from that of the nuclei. The way
in which such a separation is accomplished has the inconvenience that the nuclei
are kept fixed in the equilibrium positions; this approximation is too strong, because
it prevents the exchange of energy and momentum between the two systems from
occurring: in fact, it is used provisionally and is removed at a later stage. The next
step deals with the electron system which, despite the separation from the nuclei, is
still too complicate to be dealt with directly; using the Ritz method, the Schr&ouml;dinger
equation for the electron system is separated into single-particle equations, in which
each electron is subjected to the average field of the others. This step yields the
Hartree equations and greatly simplifies the problem; in fact, the equations, besides
being separated, are also identical to each other, so that the set of eigenvalues and
eigenfunction obtained from one of them is applicable to all electrons. The Hartree
equations do not comply with the exclusion principle, which must necessarily be
fulfilled because the system under consideration is made of identical particles; a fur-
ther modification, yielding the Hartree&ndash;Fock equations, provides the wave function
with the expected antisymmetry property. Finally, the system of nuclei is taken again
into consideration to the purpose of eliminating the simplification that the nuclei are
fixed in the equilibrium positions: considering the fact that the nuclei are strongly
bound together, so that their displacement from the equilibrium position is small,
the nuclei are treated as a system of linear harmonic oscillators. In this way, the
interaction between an electron and the nuclei is described (in a later chapter) using
the quantum-mechanical, first-order perturbation theory applied to the two-particle
collision of an electron with a phonon.
</p>
<p>&copy; Springer Science+Business Media New York 2015 293
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_16</p>
<p/>
</div>
<div class="page"><p/>
<p>294 16 Separation of Many-Particle Systems
</p>
<p>16.2 System of Interacting Electrons and Nuclei
</p>
<p>The analysis of a conservative system of identical particles, started in Sect. 15.7, is
based on the single-particle Hamiltonian operator (15.28). It must be noted, however,
that the typical systems to be dealt with are not made of identical particles but, rather,
of a mixture of subsystems; the particles of each subsystem are identical to each
other, but different from those of the other subsystems. Moreover, the Hamiltonian
operator of each subsystem is not necessarily separable. It follows that the existence
of a single-particle Hamiltonian operator like (15.28) is by no means obvious. It is
then necessary to tackle the problem from a more general point of view, starting from
the consideration of a mixture of systems, and determining the approximations that
may simplify the problem to a level that is practically affordable.
</p>
<p>To this purpose, consider a conservative system made of K electrons and N
nuclei, interacting with each other. The particles are bound together, so that the
system&rsquo;s wave function can be assumed to be normalized to unity. The coordinates
associated to the electrons are indicated with small letters and grouped into a single
vector r =
</p>
<p>(
</p>
<p>r1, . . . , rK
)
</p>
<p>; those of the nuclei are indicated with capital letters: R =
(
</p>
<p>R1, . . . , RN
)
</p>
<p>. The interaction among the particles is assumed to be of the Coulomb
type, so that the contributions to the potential energy due to the electron&ndash;electron
and nucleus&ndash;nucleus interactions are, respectively,
</p>
<p>Ue(r) =
1
</p>
<p>2
</p>
<p>K
&sum;
</p>
<p>i,j=1
</p>
<p>q2
</p>
<p>4ÏÎµ0|ri &minus; rj |
, Ua(R) =
</p>
<p>1
</p>
<p>2
</p>
<p>N
&sum;
</p>
<p>i,j=1
</p>
<p>ZiZjq
2
</p>
<p>4ÏÎµ0|Ri &minus; Rj |
, (16.1)
</p>
<p>with j ï¿½= i, where q &gt; 0 is the electron charge, Îµ0 the vacuum permittivity, and Zjq
the charge of the j th nucleus; factor 1/2 is introduced to avoid a double summation.
In addition one must consider the electron&ndash;nucleus interaction, whose contribution
to the potential energy is
</p>
<p>Uea(r, R) =
K
&sum;
</p>
<p>i=1
</p>
<p>N
&sum;
</p>
<p>j=1
</p>
<p>&minus;Zjq2
4ÏÎµ0|ri &minus; Rj |
</p>
<p>. (16.2)
</p>
<p>Remembering (15.3), letting ri =
(
</p>
<p>xi1, xi2, xi3
)
</p>
<p>, Ri =
(
</p>
<p>Xj1,Xj2,Xj3
)
</p>
<p>, and defining
</p>
<p>&nabla;2i =
&part;2
</p>
<p>&part;x2i1
+ &part;
</p>
<p>2
</p>
<p>&part;x2i2
+ &part;
</p>
<p>2
</p>
<p>&part;x2i3
, &nabla;2j =
</p>
<p>&part;2
</p>
<p>&part;X2j1
+ &part;
</p>
<p>2
</p>
<p>&part;X2j2
+ &part;
</p>
<p>2
</p>
<p>&part;X2j3
, (16.3)
</p>
<p>the kinetic parts of the system&rsquo;s Hamiltonian operator are
</p>
<p>Te = &minus;
K
&sum;
</p>
<p>i=1
</p>
<p>hÌ2
</p>
<p>2m
&nabla;2i , Ta = &minus;
</p>
<p>N
&sum;
</p>
<p>j=1
</p>
<p>hÌ2
</p>
<p>2mj
&nabla;2j . (16.4)
</p>
<p>The time-independent Schr&ouml;dinger equation of the system then reads
</p>
<p>Hw = Ew, H = Te + Ta + Ue + Ua + Uea + Uext, (16.5)</p>
<p/>
</div>
<div class="page"><p/>
<p>16.3 Adiabatic Approximation 295
</p>
<p>where the eigenfunctions depend on all variables, w = w(r, R). In (16.5), Uext =
Uext(r, R) is the potential energy due to an external, conservative field acting on the
system. If it were Uea +Uext = 0, the Hamiltonian would be separable with respect
to the two subsystems, H =
</p>
<p>(
</p>
<p>Te+Ue
)
</p>
<p>+
(
</p>
<p>Ta+Ua
)
</p>
<p>. The time-independent equations
resulting from the separation would be
</p>
<p>(
</p>
<p>Te + Ue
)
</p>
<p>u = Ee u,
(
</p>
<p>Ta + Ua
)
</p>
<p>v = Eav, (16.6)
</p>
<p>with u = u(r), v = v(R); due to the general properties of separable operators
(compare with Sect. 10.3), the eigenvalues and eigenfunctions of (16.5) would have
the form w = u v, E = Ee +Ea . As in general it is Uea +Uext ï¿½= 0, the Schr&ouml;dinger
Eq. (16.5) is not actually separable, and its solution may often present a formidable
challenge: considering by way of example that the concentration of atoms in solid
matter is of the order of 5 &times; 1022 cm&minus;3, and that to a nucleus there correspond Z
electrons, with Z the atomic number, the number of scalar coordinates necessary to
describe a cubic centimeter of solid matter is of the order of 15 (Z + 1) &times; 1022. It
is then necessary to make a number of approximations; they are introduced step by
step and, as illustrated in Sects. 16.3, 16.4, and 16.5, they are capable to bring the
problem back to the solution of single-particle equations.
</p>
<p>16.3 Adiabatic Approximation
</p>
<p>The problem of solving the Schr&ouml;dinger Eq. (16.5) for a system of interacting elec-
trons and nuclei is simplified by observing that the mass of a nucleus is much larger
than that of the electron. As a first consequence, one expects that the interaction with
an individual electron influences little the motion of a nucleus; rather, the latter is
expected to be influenced by the average interaction with many electrons. A second
consequence is that, if the particles&rsquo; dynamics is provisionally considered in clas-
sical terms, the motion of the nuclei is much slower than that of the electrons; as
a consequence, the classical positions R of the nuclei can be considered as slowly-
varying parameters when the electron dynamics is investigated. For this reason, the
procedure shown below, based on the latter observation, is called adiabatic approx-
imation or also Born-Oppenheimer approximation [62, Sect. 8]. In quantum terms,
the approximation leads to the splitting of the original Eq. (16.5) into a set of two
coupled equations. To this purpose, let
</p>
<p>He = Te + Ue + Uea + Uext, (16.7)
</p>
<p>where the dependence on R is algebraic only. Considering such a dependence, the
Hamiltonian operator He provides an eigenvalue equation whose eigenvalues and
eigenfunctions depend on R; they read
</p>
<p>He u = Eeu, Ee = Ee(R), u = u(r, R). (16.8)
</p>
<p>Also, from the Schr&ouml;dinger Eq. (16.8) one finds that, for any function v that depends
only on R, the following holds: Heu v = Ee u v. As v is undetermined, one may seek</p>
<p/>
</div>
<div class="page"><p/>
<p>296 16 Separation of Many-Particle Systems
</p>
<p>a form of v such that w = u v is also an eigenfunction of the full Hamiltonian operator
H of (16.5). From the definition of He it follows H = Ta + Ua + He, whence the
original Schr&ouml;dinger Eq. (16.5) is recast as
</p>
<p>(
</p>
<p>Ta + Ua + He
)
</p>
<p>uv = Euv. (16.9)
</p>
<p>The second relation in (16.4) shows that each Laplacian operator in Ta acts on both
u and v, specifically, &nabla;2j u v = u&nabla;2j v + v&nabla;2j u + 2&nabla;j u &middot; &nabla;j v. Multiplying the latter
by &minus;hÌ2/
</p>
<p>(
</p>
<p>2mj
)
</p>
<p>and adding over j transforms (16.9) into
</p>
<p>u
(
</p>
<p>Ta + Ua + Ee
)
</p>
<p>v + vTau + Gau v = Euv, (16.10)
</p>
<p>where the short-hand notation Gauv = &minus;
&sum;N
</p>
<p>j=1
(
</p>
<p>hÌ2/mj
)
</p>
<p>&nabla;ju &middot; &nabla;jv has been used.
To proceed one notes that the coefficients in the Schr&ouml;dinger Eq. (16.8) are real, so
that u can be taken real as well. Remembering that the particles described by u are
bound, one finds that u is normalizable so that, for any R,
</p>
<p>&int;
</p>
<p>u2(r, R)dr = 1, dr = d3r1 . . . d3rK , (16.11)
</p>
<p>with the integral extended to the whole K-dimensional space r. Remembering that
&nabla;j acts on Rj , from (16.11) one derives
</p>
<p>&int;
</p>
<p>u&nabla;judr =
1
</p>
<p>2
</p>
<p>&int;
</p>
<p>&nabla;j u2dr =
1
</p>
<p>2
&nabla;j
</p>
<p>&int;
</p>
<p>u2dr = 0, (16.12)
</p>
<p>whence
</p>
<p>&int;
</p>
<p>u Gauvdr = &minus;
N
&sum;
</p>
<p>j=1
</p>
<p>hÌ2
</p>
<p>mj
&nabla;jv &middot;
</p>
<p>&int;
</p>
<p>u&nabla;judr = 0. (16.13)
</p>
<p>Left multiplying (16.10) by u, integrating over r, and using (16.11, 16.13), yields
</p>
<p>(
</p>
<p>Ta + Ua + Ee + Uu
)
</p>
<p>v = Ev, Uu(R) =
&int;
</p>
<p>uTaudr. (16.14)
</p>
<p>In this way, the original Schr&ouml;dinger Eq. (16.5) is eventually split into two coupled
equations, (16.8) and (16.14); the former is written in extended form as
</p>
<p>(
</p>
<p>Te + Ue + Uea + Uext
)
</p>
<p>u = Eeu. (16.15)
</p>
<p>The first equation, (16.14), is the equation for the nuclei, in fact its kinetic operator
Ta acts on R only, and its potential-energy term Ua + Ee + Uu depends on R only;
this equation is coupled with the second one, (16.15), because Ee is an eigenvalue of
(16.15) and Uu is given by the integral in (16.14) that involves the eigenfunctions of
(16.15). In turn, (16.15) is the equation for the electrons, in fact its kinetic operator
Te acts on r only; in turn, the part Uea + Uext of its potential-energy term couples
(16.15) with (16.14) due to the dependence on R.</p>
<p/>
</div>
<div class="page"><p/>
<p>16.4 Hartree Equations 297
</p>
<p>In principle, one may solve (16.15) after fixing R and, from the solution, calculate
Ee and Uu to be used in (16.14). From v one then determines the expectation value
of R, that updates the starting point for the solution of (16.15). Considering the
case of solid matter, and still reasoning in classical terms, a zero-order solution
for the iterative procedure depicted above is found by observing that the nuclei,
being massive and tightly bound together, are expected to depart little from their
equilibrium positions R0. One then fixes R = R0 in (16.15) to find, for the electrons&rsquo;
Schr&ouml;dinger equation, the approximate form
</p>
<p>(
</p>
<p>Te + Ve
)
</p>
<p>u = Eeu, Ve(r) = Ue(r) + Uea
(
</p>
<p>r, R0
)
</p>
<p>+ Uext
(
</p>
<p>r, R0
)
</p>
<p>. (16.16)
</p>
<p>This separates completely the equation for the electrons, that may be thought of as
forming a separate system of total energy Ee. Admittedly, keeping the positions of
the nuclei fixed is rather crude an approximation; in this way, in fact, the nuclei can
not exchange momentum and energy with the electrons any more. On the other hand
it can be shown that the solution of (16.16) provides an acceptable approximation for
the energy of the electrons.Another advantage of keeping the nuclei in the equilibrium
positions occurs in the investigation of materials where the nuclei are arranged in
periodic structures; in fact, one exploits in this case the properties of differential
equations having periodic coefficients (compare with Sects. 13.4 and 17.5.1). In
conclusion, the present analysis will continue by provisionally considering only the
system of electrons as described by (16.16); obviously the problem of the exchange
of momentum and energy with the system of nuclei can not be dispensed with, and
will be resumed at a later stage (Sect. 16.6).
</p>
<p>16.4 Hartree Equations
</p>
<p>Equation (16.16), describing the separate system of K electrons after fixing the
nuclei to the equilibrium positions R0, lends itself to the application of the Ritz
method outlined in Sect. 16.7.1. For the sake of generality, one starts by assuming
that the K particles are distinguishable; for this reason, the symbols Te, Ve, u, and
Ee of (16.16) are not used. Also, the application of the Ritz method will be carried
out in the case where the external forces are absent, Uext = 0; such forces will be
introduced again into the problem in Sect. 19.2.1, where the single-particle dynamics
is described. Given these premises, the operator A, its minimum eigenvalue A1, and
the corresponding eigenfunction v1 used in Sect. 16.7.1 for describing the Ritz method
are indicated here with A = H, A1 = E1, v1 = w1, where
</p>
<p>H =
K
&sum;
</p>
<p>i=1
Ti +
</p>
<p>K
&sum;
</p>
<p>i=1
</p>
<p>&sum;
</p>
<p>j&lt;i
</p>
<p>Vij , Ti = &minus;
hÌ2 &nabla;2i
2mi
</p>
<p>, Vij =
Ïij q
</p>
<p>2 Zi Zj
</p>
<p>4ÏÎµ0 |ri &minus; rj |
,
</p>
<p>(16.17)
</p>
<p>with Ïij = &plusmn;1. The above describe a system of different particles interacting
through Coulomb potentials. Introducing the auxiliary function f as in (16.37),</p>
<p/>
</div>
<div class="page"><p/>
<p>298 16 Separation of Many-Particle Systems
</p>
<p>one minimizes the functional ãf1 . . . fK |H|f1 . . . fKã subjected to the K constraints
ãfi |fiã = 1. Using the method of Lagrange multipliers, this is equivalent to finding
the absolute minimum of
</p>
<p>FH
[
</p>
<p>f1, . . . , fK
]
</p>
<p>= ãf1 . . . fK |H|f1 . . . fKã &minus;
K
&sum;
</p>
<p>i=1
Îµiãfi |fiã, (16.18)
</p>
<p>with Îµi the multipliers. The terms related to Ti are separable, while those related to
Vij are separable in pairs. From the orthonormalization condition it follows
</p>
<p>FH =
K
&sum;
</p>
<p>i=1
</p>
<p>â
</p>
<p>âãfi |Ti |fiã &minus; Îµiãfi |fiã +
i&minus;1
&sum;
</p>
<p>j=1
ãfi fj |Vij |fi fj ã
</p>
<p>â
</p>
<p>â  . (16.19)
</p>
<p>The minimum of FH is found by letting Î´FH = FH
[
</p>
<p>f1 + Î´f1, . . . , fK + Î´fK
]
</p>
<p>&minus;
FH
</p>
<p>[
</p>
<p>f1, . . . , fK
]
</p>
<p>= 0 . Neglecting the second-order terms and observing that Ti is
Hermitean yields
</p>
<p>Î´ãfi |Ti |fiã = ãÎ´fi |Ti |fiã + ãfi |Ti |Î´fiã = 2&real;ãÎ´fi |Ti |fiã. (16.20)
By the same token one finds Î´Îµiãfi |fiã = Îµi 2&real;ãÎ´fi |fiã and Î´ãfi fj |Vij |fi fj ã =
2&real;ãfi Î´fj |Vij |fi fj ã + 2&real;ãfj Î´fi |Vij |fi fj ã. The symmetry of the Coulomb terms
yields Vji = Vij , whence
</p>
<p>i&minus;1
&sum;
</p>
<p>j=1
</p>
<p>(
</p>
<p>ãfi Î´fj |Vij |fi fj ã + ãfj Î´fi |Vij |fi fj ã
)
</p>
<p>=
K
&sum;
</p>
<p>j=1
ãfj Î´fi |Vij |fi fj ã, (16.21)
</p>
<p>with j ï¿½= i at the right hand side. The minimization condition of (16.19) then reads
</p>
<p>2&real;
K
&sum;
</p>
<p>i=1
</p>
<p>â
</p>
<p>âãÎ´fi |Ti |fiã &minus; Îµi ãÎ´fi |fiã +
K
&sum;
</p>
<p>j=1
ãfj Î´fi |Vij |fi fj ã
</p>
<p>â
</p>
<p>â  = 0, (16.22)
</p>
<p>with j ï¿½= i in the inner sum. As the variations Î´fi are independent of each other, the
term within parentheses in (16.22) must vanish for each i, this yielding a system of
K coupled equations. The inner sum has a double integral in it, and is recast as
</p>
<p>K
&sum;
</p>
<p>j=1
ãfj Î´fi |Vij |fi fj ã = ãÎ´fi |Ui |fiã, Ui(ri) =
</p>
<p>K
&sum;
</p>
<p>j=1
ãfj |Vij |fj ã, (16.23)
</p>
<p>still with j ï¿½= i. The ith equation of the system then reads
ãÎ´fi |Ti |fiã &minus; Îµi ãÎ´fi |fiã + ãÎ´fi |Ui |fiã = ãÎ´fi | (Ti + Ui &minus; Îµi) fiã = 0. (16.24)
</p>
<p>As the above holds for any Î´fi , the terms on the right hand side of the scalar products
of (16.24) must cancel each other. In conclusion, the minimization condition provides
a set of K single-particle equations coupled through the terms Ui :
</p>
<p>(Ti + Ui) fi = Îµi fi , i = 1, . . . ,K. (16.25)</p>
<p/>
</div>
<div class="page"><p/>
<p>16.5 Hartree&ndash;Fock Equations 299
</p>
<p>The above are called Hartree equations, and constitute a set of Schr&ouml;dinger equations
whose potential energy is given by the second relation in (16.23):
</p>
<p>Ui
(
</p>
<p>ri
)
</p>
<p>=
K
&sum;
</p>
<p>j=1
</p>
<p>&int;
Ïij q
</p>
<p>2 Zi Zj
</p>
<p>4Ï Îµ0 |ri &minus; rj |
|fj |2 drj , j ï¿½= i. (16.26)
</p>
<p>The potential energy of the ith particle is the sum of two-particle potential energies
averaged with the localization probabilities of the particles different from the ith.
The eigenvalue Îµi is then the energy of the ith particle in the field of the other K &minus; 1
particles (for this reason, the sum Îµ1 + . . .+ ÎµN is not the total energy of the system).
</p>
<p>The solution of (16.25) is found by iteration; one starts with i = 1 and provides an
initial guess for f2, . . . , fK , so that the initial guess for U1 is calculated from (16.26)
and used in (16.25). The solution of the latter yields the first iteration for f1 and,
remembering the Ritz method outlined in Sect. 16.7.1, the parameters embedded in
f1 are exploited at this stage to lower the eigenvalue; then, one proceeds with i = 2,
using the first iteration for f1 and the initial guess for f3, . . . , fK , and so on. It
must be noted that the initial guess is used within an integral, whose effect is that of
averaging the difference between the initial guess and the actual solution; therefore,
it may happen that the accuracy of the first iteration is sufficient, to the extent that the
iterative process may be brought to an end. In this case, the K Eqs. (16.25) become
independent of each other and the solution effort is greatly reduced.
</p>
<p>16.5 Hartree&ndash;Fock Equations
</p>
<p>It is now necessary to investigate the problem originally introduced in Sect. 16.3,
namely, that of Eq. (16.16), which describes the separate system of electrons after
fixing the nuclei to the equilibrium positions R0. The Hartree Eqs. (16.25) can not
be applied as they stand, because they have been deduced for a system made of
distinguishable particles. To treat a system of electrons, instead, it is necessary to
account for the particles&rsquo; spin, that was not considered in Sects. 16.3 and 16.4, and
ensure the antisymmetry of the wave function (Sect. 15.7). The procedure is similar
to that depicted in Sect. 16.4, the difference being that the auxiliary function f is not
expressed as a product like in (16.37), but is given by a Slater determinant (15.37),
whose entries depend on the position and spin coordinates of the corresponding
particle [62, Sect. 8], [99, Sect. 16.3].
</p>
<p>The calculations are rather involved and are not reported here. It is important to
mention that, like in Sect. 16.4, the derivation is carried out by assuming that the
external forces are absent (Uext = 0). The procedure yields a set of K equations,
coupled with each other, that generalize the Hartree Eqs. (16.25) and are called
Hartree&ndash;Fock equations. If the accuracy of the first iteration is sufficient, the original
Hamiltonian operator of (16.16), describing the system of electrons as a whole, is
separated into K single-particle, identical operators:
</p>
<p>Te + Ve =
K
&sum;
</p>
<p>i=1
</p>
<p>[
</p>
<p>&minus; hÌ
2
</p>
<p>2m
&nabla;2i + Vei(ri)
</p>
<p>]
</p>
<p>. (16.27)</p>
<p/>
</div>
<div class="page"><p/>
<p>300 16 Separation of Many-Particle Systems
</p>
<p>In this way the form (15.28) of the Schr&ouml;dinger equation for the electrons, sought
at the beginning of Sect. 16.2, is recovered.
</p>
<p>16.6 Schr&ouml;dinger Equation for the Nuclei
</p>
<p>In the process of separating the Schr&ouml;dinger equation for the electrons, (16.15), from
that of the nuclei, (16.14), that is carried out in Sect. 16.3, the positions of the nuclei
are fixed to the equilibrium values R = R0. This is done to the purpose of calculating
the coefficients Ee and Uu (compare with (16.6) and (16.14), respectively); such
coefficients depend on R and can be obtained only by solving the equation for the
electrons. After this step is accomplished, one turns to the equation for the nuclei,
in which Ee and Uu are fixed to constants from the previous iteration; the potential
energy of (16.14) then becomes
</p>
<p>Va( "R) = Ua( "R) + Ee( "R0) + Uu( "R0). (16.28)
</p>
<p>If the positions of the nuclei are kept fixed, that is, the iterative procedure outlined in
Sect. 16.3 is brought to an end without solving (16.14), the exchange of momentum
and energy between the system of electrons and that of nuclei can not take place. It
is then necessary to proceed to the solution of (16.14); such a solution is obtained by
means of an approximation shown below, and the iterative procedure for the solution
of (16.14) and (16.15) is stopped right after. In this way, one keeps for the energy
of the electrons the eigenvalues obtained with the nuclei fixed at R0, which is a
convenient choice due to the advantages illustrated in Sect. 16.3.
</p>
<p>As for the nuclei, it has already been observed in Sect. 16.3 with respect to the
case of solid matter, that the nuclei, being massive and tightly bound together, are
expected to depart little from their equilibrium positions R0. To improve with respect
to the zero-order approximation R = R0, and provisionally reasoning in classical
terms, one assumes that the instantaneous displacement R &minus; R0 with respect to the
equilibrium point is small, so that Va in (16.28) can be approximated with a second-
order Taylor expansion around R0. The classical form of the problem is thus brought
to the case already solved in Sects. 3.9 and 3.10: indicating with Ta+Va the classical
equivalent of the operator Ta + Va , the vibrational state of the nuclei is described in
terms of the normal coordinates bÏ , whose conjugate moments are bÌÏ , and the total
energy of the nuclei reads (compare with (3.50)):
</p>
<p>Ta + Va =
3N
&sum;
</p>
<p>Ï=1
HÏ + Va0, HÏ =
</p>
<p>1
</p>
<p>2
bÌ2Ï +
</p>
<p>1
</p>
<p>2
Ï2Ï b
</p>
<p>2
Ï , (16.29)
</p>
<p>with ÏÏ &gt; 0 the angular frequency of the mode. As a consequence, the quantum
operator takes the form
</p>
<p>Ta + Va =
3N
&sum;
</p>
<p>Ï=1
HÏ + Va0, HÏ = &minus;
</p>
<p>hÌ2
</p>
<p>2
</p>
<p>&part;2
</p>
<p>&part;b2Ï
+ 1
</p>
<p>2
Ï2Ï b
</p>
<p>2
Ï (16.30)</p>
<p/>
</div>
<div class="page"><p/>
<p>16.7 Complements 301
</p>
<p>which, introduced into (16.14), yields
</p>
<p>3N
&sum;
</p>
<p>Ï=1
HÏ v = E&prime;v, E&prime; = E &minus; Va0. (16.31)
</p>
<p>This procedure provides the separation of the degrees of freedom of the nuclei, and
completes the separation process whose usefulness was anticipated in Sect. 16.2.
The solution of (16.31) is illustrated in Sect. 12.5, and shows that the mode&rsquo;s energy
is ascribed to the set of phonons belonging to the mode itself. As the phonons are
bosons, the equilibrium distribution of their occupation numbers is given by the
Bose&ndash;Einstein statistics. The description of the interaction between an electron and
the nuclei is obtained from the quantum-mechanical, first-order perturbation theory
applied to the two-particle collision of an electron with a phonon.
</p>
<p>16.7 Complements
</p>
<p>16.7.1 Ritz Method
</p>
<p>Let A be a Hermitean operator with a discrete spectrum and a complete, orthonormal
set of eigenfunctions. For the sake of simplicity, the eigenvalues are assumed non
degenerate:
</p>
<p>Avn = Anvn, ãvm|vnã = Î´mn. (16.32)
Consider the expansion of a function f in terms of the eigenfunctions of A, f =
&sum;&infin;
</p>
<p>n=1 cn vn, with cn = ãvn|f ã. From Parseval theorem (8.41) one finds
</p>
<p>ãf |A|f ã =
&infin;
&sum;
</p>
<p>n=1
An |cn|2. (16.33)
</p>
<p>As the eigenvalues are real, one orders them in a non-decreasing sequence: A1 &le;
A2 &le; A3 &le; . . . , whence
</p>
<p>ãf |A|f ã &ge; A1
&infin;
&sum;
</p>
<p>n=1
|cn|2 = A1 ãf |f ã. (16.34)
</p>
<p>More generally, if f is orthogonal to the first s &minus; 1 eigenfunctions, then c1 = c2 =
. . . = cs&minus;1 = 0, and
</p>
<p>f =
&infin;
&sum;
</p>
<p>n=s
cn vn, ãf |A|f ã &ge; As ãf |f ã, (16.35)
</p>
<p>where the equality holds if and only if f = const&times; vs . In conclusion, the functional
</p>
<p>GA[f ] =
ãf |A|f ã
ãf |f ã (16.36)</p>
<p/>
</div>
<div class="page"><p/>
<p>302 16 Separation of Many-Particle Systems
</p>
<p>has a minimum for f = vs , whose value is As . The findings above are the basis
of the Ritz method, that provides approximations for the eigenvalues and eigen-
functions of A. For instance, the minimum eigenvalue A1 and the corresponding
eigenfunction v1(r) are approximated by letting v1 â f
</p>
<p>(
</p>
<p>r,Î±1,Î±2, . . .
)
</p>
<p>, where the
form of f is prescribed and Î±1,Î±2, . . . are parameters. The latter are then used to
minimize GA[f ]. The constraint ãf |f ã = 1 is imposed along the calculation, yield-
ing A1 â minÎ±GA[f ] = ãf |A|f ã. When A1, v1 have been found, the next pair
A2, v2 is determined by using an approximating function orthonormal to v1, and so
on. For a system made of N particles, the eigenfunctions depend on 3N coordi-
nates: vn = vn
</p>
<p>(
</p>
<p>r1, . . . , rN
)
</p>
<p>. It is convenient to approximate them by separating the
variables:
</p>
<p>f = f1(r1) . . . fN (rN ), (16.37)
</p>
<p>where each fi may also depend on parameters. The normalization constraint then
yields
</p>
<p>ãfi |fiã = 1, i = 1, . . . ,N. (16.38)</p>
<p/>
</div>
<div class="page"><p/>
<p>Part V
</p>
<p>Applications to Semiconducting Crystals</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 17
</p>
<p>Periodic Structures
</p>
<p>17.1 Introduction
</p>
<p>The chapter outlines a number of concepts that are useful in the description of pe-
riodic structures. The first sections describe the geometrical entities (characteristic
vectors, direct and reciprocal lattices, translation vectors, cells, and Brillouin zones)
used for describing a lattice. The analysis focuses on the lattices of cubic type, be-
cause silicon and other semiconductor materials used in the fabrication of integrated
circuits have this type of structure. The next sections introduce the mathematical
apparatus necessary for solving the Schr&ouml;dinger equation within a periodic struc-
ture, specifically, the translation operators, Bloch theorem, and periodic boundary
conditions. Basing on such tools, the Schr&ouml;dinger equation is solved, leading to the
dispersion relation of the electrons, whose properties are worked out and discussed.
The analogy between a wave packet in a periodic potential and in free space is also
outlined. Then, the parabolic-band approximation is introduced, leading to the con-
cept of effective mass and to the explicit calculation of the density of states. Examples
of the structure of the conduction and valence bands of silicon, germanium, and gal-
lium arsenide are provided. Considering the importance of two-dimensional and
one-dimensional structures in modern technological applications, a detailed deriva-
tion of the subbands and the corresponding density of states is also given. Then, the
same mathematical concepts used for solving the Schr&ouml;dinger equation (Bloch the-
orem and periodic boundary conditions) are applied to the calculation of the lattice&rsquo;s
vibrational spectrum in the harmonic approximation. The properties of the eigen-
values and eigenfunctions of the problem are worked out, leading to the expression
of the vibrational modes. The complements provide a number of details about the
description of crystal planes and directions, and about the connection between the
symmetries of the Hamiltonian operator and the properties of its eigenvalues. A num-
ber of examples of application of the concepts outlined in the chapter are given in
the last part of the complements; specifically, the Kronig&ndash;Penney model, showing a
one-dimensional calculation of the electrons&rsquo; dispersion relation, and the derivation
of the dispersion relation of the one-dimensional monatomic and diatomic chains.
The complements are concluded by a discussion about some analogies between the
energy of the electromagnetic field and that of the vibrating lattice, and between the
dispersion relation of the electrons and that of the lattice.
</p>
<p>&copy; Springer Science+Business Media New York 2015 305
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_17</p>
<p/>
</div>
<div class="page"><p/>
<p>306 17 Periodic Structures
</p>
<p>Fig. 17.1 Schematic
description of a
two-dimensional Bravais
lattice of the oblique type.
Three atoms have been
removed to better show the
characteristic vectors. The
latter are not orthogonal to
each other, and their lengths
are different
</p>
<p>1
a
</p>
<p>a
2
</p>
<p>17.2 Bravais Lattice
</p>
<p>The concepts illustrated in the previous chapters will now be applied to study the
properties of a specific class of materials, the crystals. In fact, in the majority of cases
the solid-state devices are manufactured using a crystal as basic material.1 A crystal
is made of a periodic arrangement of an atom, or a group of atoms, called basis.
As a periodic structure is unlimited in all spatial directions, the general properties
of crystals are derived using the provisional hypothesis that the material extends to
infinity. The more realistic case of a finite crystal is considered at a later stage.
</p>
<p>To describe the properties of a crystal it is convenient to superimpose to it a
geometric structure, called Bravais lattice, made of an infinite array of discrete
points generated by translation operations of the form [10]
</p>
<p>l = m1 a1 +m2 a2 +m3 a3, (17.1)
</p>
<p>with m1, m2, m3 any integers. In (17.1), l is called translation vector while a1, a2,
a3 are the characteristic vectors; the discrete points generated by (17.1) are called
nodes. The set of vectors l is closed under vector addition. Although the characteristic
vectors are not necessarily of equal length, nor are they orthogonal to each other,
they form a complete set; it follows that any vector r of the three-dimensional space
is expressible as
</p>
<p>r = Î¼1 a1 + Î¼2 a2 + Î¼3 a3, (17.2)
</p>
<p>with Î¼1, Î¼2, Î¼3 real numbers. In a zero-dimensional or one-dimensional space only
one Bravais lattice is possible. In a two-dimensional space there are five Bravais
lattices, respectively called oblique, rectangular, centered rectangular (rhombic),
hexagonal, and square [63]. An example of oblique lattice is shown in Fig. 17.1.
</p>
<p>1 Some important exceptions exist. Thin-Film Transistors (TFT), commonly used in flat-screen or
liquid-crystal displays, are obtained by depositing a semiconductor layer (typically, silicon) over a
non-conducting substrate; due to the deposition process, the structure of the semiconductor layer
is amorphous or polycrystalline. Phase-Change Memories (PCM) exploit the property of specific
materials like chalcogenides (for example, Ge2Sb2Te5), that switch from the crystalline to the
amorphous state, and vice versa, in a controlled way when subjected to a suitable electric pulse.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.2 Bravais Lattice 307
</p>
<p>Fig. 17.2 Examples of cells
in a two-dimensional Bravais
lattice of the oblique type
</p>
<p>a
</p>
<p>b
</p>
<p>c
</p>
<p>Another important concept is that of cell. Still considering a two-dimensional
lattice of the oblique type, a cell is a two-dimensional surface that is associated to
each node and has the following properties: (i) the association is one-to-one, (ii) the
cells are equal to each other, and (iii) the union of the cells covers the lattice exactly.
The cell so defined is not unique; by way of examples, all the shaded surfaces shown
in Fig. 17.2 fulfill the properties listed above. It may seem that the cell of case (c)
is not correct, because it touches four nodes; however, each node is shared by four
cells, so that the one-to-one correspondence is maintained. In fact, the type of cell
shown in case (c) is most useful to extend the definitions given so far to the more
realistic three-dimensional case. One notes in passing that the common value of the
area of the cells depicted in Fig. 17.2 is A = |a1 &and; a2|, with a1, a2 the characteristic
vectors indicated in Fig. 17.1.
</p>
<p>In a three-dimensional space the simplest cells are three-dimensional volumes,
that fulfill the same properties as in the two-dimensional case and have the atoms
placed at the corners. Such an arrangement is called primitive. It can be shown that
seven primitive arrangements are possible; each of them may further by enriched in
five possible ways, by adding (a) one atom at the center of the cell, or (b) one atom
at the center of each face of the cell, or (c) one atom at the center of each pair of
cell faces (this can be done in three different ways). The addition of extra atoms to
the primitive arrangement is called centering. The total number of three-dimensional
arrangements, including the primitive ones, is thus 7 &times; 6 = 42; however, it is found
that not all of them are distinct, so that the actual number of distinct three-dimensional
cells reduces to 14 [63].
</p>
<p>A three-dimensional lattice whose characteristic vectors are mutually orthogonal
and of equal length is called cubic. Besides the primitive one, other two arrangements
of cubic type are possible: the first one has one additional atom at the cell&rsquo;s center
and is called body-centered cubic (BCC), the second one has one additional atom at
the center of each cell&rsquo;s face and is called face-centered cubic (FCC). A portion of a
lattice of the FCC type is shown in Fig. 17.3. Examples of chemical species whose
crystalline phase has a cubic cell are carbon (C) in the diamond phase, silicon (Si),
and germanium (Ge); in fact, this type of crystallization state is also collectively
indicated with diamond structure. Elements like C, Si, and Ge belong to the fourth
column of the periodic table of elements; Si and Ge are semiconductors, while C in</p>
<p/>
</div>
<div class="page"><p/>
<p>308 17 Periodic Structures
</p>
<p>a
2
</p>
<p>1
a
</p>
<p>3
a
</p>
<p>Fig. 17.3 Schematic description of a three-dimensional Bravais lattice of the FCC type. Four atoms
have been removed to better show the characteristic vectors. The latter are orthogonal to each other,
and of equal length
</p>
<p>Table 17.1 Crystal constants
of silicon and germanium Material Lattice constant (nm) Interatomic distance (nm)
</p>
<p>Si 0.543 0.233
</p>
<p>Ge 0.566 0.244
</p>
<p>the diamond phase is an insulator.2 The FCC cell is also exhibited by some compound
materials, an example of which is gallium arsenide (GaAs), a semiconductor of the
so-called III-V type.3 Some properties of GaAs, along with those of other III-V
semiconductors, are listed in Tables 17.1 and 17.2. The type of crystallization state
of GaAs and the other materials of the table is called zincblende structure.4
</p>
<p>2 The meaning of &ldquo;insulator&rdquo; or &ldquo;semiconductor&rdquo;, as well as that of &ldquo;conductor&rdquo;, is specified in
Sect. 18.2.
3 The term &ldquo;III-V&rdquo; derives from the fact the Ga and As belong, respectively, to the third and fifth
column of the periodic table of elements.
4 Zincblende is another name for Sphalerite, an economically important mineral whence zinc is
extracted. It consists of zinc sulphide in crystalline form with some contents of iron, (Zn,Fe)S.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.3 Reciprocal Lattice 309
</p>
<p>Table 17.2 Crystal constants
of some III-V semiconductors Material Lattice constant (nm) Interatomic distance (nm)
</p>
<p>GaAs 0.563 0.244
</p>
<p>GaP 0.545 0.236
</p>
<p>GaSb 0.609 0.264
</p>
<p>InAs 0.605 0.262
</p>
<p>InP 0.586 0.254
</p>
<p>InSb 0.647 0.280
</p>
<p>AlSb 0.613 0.265
</p>
<p>17.3 Reciprocal Lattice
</p>
<p>As indicated in Sect. 17.2, the type of cell having the nodes at the corners is the most
useful one for introducing a number of definitions. For instance, observing that the
characteristic vectors coincide with the cell&rsquo;s edges (this property is evident for the
FCC cell as shown in Fig. 17.3, however, it applies also to the other types of cells),
one obtains for the cell&rsquo;s volume
</p>
<p>Ïl = a1 &middot; a2 &and; a3 = a2 &middot; a3 &and; a1 = a3 &middot; a1 &and; a2, (17.3)
</p>
<p>where the orientation of the characteristic vectors is chosen in such a way as to make
Ïl positive.
</p>
<p>The major advantage of dealing with a periodic structure is the possibility of
using the Fourier series. In fact, the functions describing the physical properties of
the structure are expected to be periodic, so that one can take advantage of the Fourier
expansion. The latter, in turn, entails a transformation from the coordinate space to
another space reciprocal to it. Considering, for instance, the one-dimensional case
of the Fourier transform given in (C.17), there the k space is the reciprocal of the
x space; similarly, in an n-dimensional space like that considered in (C.20), the k
space is the reciprocal of the x space: both vectors k, x are linear combinations of the
same set of mutually-orthogonal, unit vectors i1, . . . , in, so that the scalar product
k &middot;x yields k1 x1 +&middot; &middot; &middot;+kn xn. In the case considered here, instead, one must account
for the fact that the reference a1, a2, a3 of the space under consideration is made of
vectors that, in general, are neither mutually orthogonal nor of equal length. For this
reason it is necessary to introduce a reciprocal lattice by defining its characteristic
vectors as
</p>
<p>b1 =
a2 &and; a3
</p>
<p>Ïl
, b2 =
</p>
<p>a3 &and; a1
Ïl
</p>
<p>, b3 =
a1 &and; a2
</p>
<p>Ïl
. (17.4)
</p>
<p>From the definition (17.3) of Ïl and the mixed-product property (A.32) one finds that
the characteristic vectors fulfill the orthogonality and normalization relation
</p>
<p>ai &middot; bj = Î´ij , (17.5)</p>
<p/>
</div>
<div class="page"><p/>
<p>310 17 Periodic Structures
</p>
<p>with Î´ij the Kronecker symbol (A.18). The translation vectors and the general vectors
of the reciprocal lattice are linear combinations of b1, b2, b3 whose coefficients are,
respectively, integer numbers or real numbers. To distinguish the lattice based on b1,
b2, b3 from the one based on a1, a2, a3, the latter is also called direct lattice. The
common value of the cells&rsquo; volume in the reciprocal lattice is
</p>
<p>ÏG = b1 &middot; b2 &and; b3 = b2 &middot; b3 &and; b1 = b3 &middot; b1 &and; b2. (17.6)
</p>
<p>Observing that ai is a length, from (17.4) it follows that bj is the inverse of a length; as
a consequence, the units of ÏG are m&minus;3, and the product Î³ = Ïl ÏG is a dimensionless
constant. The value of Î³ is found by combining the first relation in (17.4), which
yields Ïl b1 = a2 &and; a3, with (17.6), so that
</p>
<p>Î³ = Ïl ÏG = Ïl b1 &middot; b2 &and; b3 = a2 &and; a3 &middot; (b2 &and; b3) = a2 &middot; a3 &and; (b2 &and; b3) , (17.7)
</p>
<p>where the last equality is due to the invariance of the mixed product upon interchange
of the &ldquo;wedge&rdquo; and &ldquo;dot&rdquo; symbols (Sect. A.7). Then, using (A.33) to resolve the
double vector product,
</p>
<p>Ïl ÏG = a2 &middot; (a3 &middot; b3 b2 &minus; a3 &middot; b2 b3) = a2 &middot; (Î´33 b2 &minus; Î´32 b3) = a2 &middot; b2 = 1. (17.8)
</p>
<p>Also, after defining e1 = b2 &and; b3/ÏG one finds, by a similar calculation,
</p>
<p>e1 =
b2 &and; b3
</p>
<p>ÏG
= b2 &and; (a1 &and; a2)
</p>
<p>Ïl ÏG
= b2 &middot; a2 a1 &minus; b2 &middot; a1 a2 = a1. (17.9)
</p>
<p>From the properties that provide the definition of cell (Sect. 17.2) it follows that, for
a given lattice, the volume of the cell does not depend on its form. It follows that
Ïl ÏG = 1 no matter what the cell&rsquo;s form is and, from (17.9), that the direct lattice is
the reciprocal of the reciprocal lattice.
</p>
<p>Given a direct lattice of characteristic vectors a1, a2, a3, it is convenient to in-
troduce, besides the reciprocal lattice of characteristic vectors b1, b2, b3 defined by
(17.4), another lattice called scaled reciprocal lattice, whose characteristic vectors
are 2Ï b1, 2Ï b2, 2Ïb3. A translation vector of the scaled reciprocal lattice has the
form
</p>
<p>g = n1 2Ï b1 + n2 2Ï b2 + n3 2Ï b3, (17.10)
</p>
<p>with n1, n2, n3 any integers, whereas a general vector of the scaled reciprocal lattice
has the form
</p>
<p>k = Î½1 2Ï b1 + Î½2 2Ï b2 + Î½3 2Ï b3, (17.11)
</p>
<p>with Î½1, Î½2, Î½3 any real numbers. From the definitions (17.1, 17.10) of l and g one
finds
</p>
<p>l &middot; g =
3
</p>
<p>&sum;
</p>
<p>is=1
mi ai &middot; ns 2Ï bs = 2Ï
</p>
<p>3
&sum;
</p>
<p>is=1
mi ns Î´is = 2Ï
</p>
<p>3
&sum;
</p>
<p>i=1
mi ni , (17.12)</p>
<p/>
</div>
<div class="page"><p/>
<p>17.4 Wigner&ndash;Seitz Cell&mdash;Brillouin Zone 311
</p>
<p>namely, l &middot; g = 2Ï M with M an integer. It follows that
</p>
<p>exp
[
</p>
<p>i g &middot; (r + l)
]
</p>
<p>= exp (i g &middot; r) exp (i 2Ï M) = exp (i g &middot; r) , (17.13)
</p>
<p>that is, exp (i g &middot; r) is periodic in the r space. This shows the usefulness of the scaled
reciprocal lattice for treating problems related to periodic structures. In fact, given a
periodic function in the r space,F (r+l) = F (r), the Fourier expansion is generalized
to the non-orthogonal case as
</p>
<p>F (r) =
&sum;
</p>
<p>g
</p>
<p>Fg exp (i g &middot; r) , Fg =
1
</p>
<p>Ïl
</p>
<p>&int;
</p>
<p>Ïl
</p>
<p>F (r) exp (&minus;i g &middot; r) d3r , (17.14)
</p>
<p>with
&sum;
</p>
<p>g =
&sum;
</p>
<p>n1
</p>
<p>&sum;
</p>
<p>n2
</p>
<p>&sum;
</p>
<p>n3
. The property holds also in reverse, namely,
</p>
<p>exp [i l &middot; (k + g)] = exp (i l &middot; k), (17.15)
</p>
<p>so that, given a periodic function in the k space, Î¦(k + g) = Î¦(k), the following
expansion holds:
</p>
<p>Î¦(k) =
&sum;
</p>
<p>l
</p>
<p>Î¦l exp (i l &middot; k) , Î¦l =
1
</p>
<p>Ïg
</p>
<p>&int;
</p>
<p>Ïg
</p>
<p>Î¦(k) exp (&minus;i l &middot; k) d3k, (17.16)
</p>
<p>with
&sum;
</p>
<p>l =
&sum;
</p>
<p>m1
</p>
<p>&sum;
</p>
<p>m2
</p>
<p>&sum;
</p>
<p>m3
. From (17.8) one also finds that in the scaled reciprocal
</p>
<p>lattice the volume of the cell is given by
</p>
<p>Ïg = (2Ï )3 ÏG =
(2Ï )3
</p>
<p>Ïl
. (17.17)
</p>
<p>The origin of the reference of the direct or reciprocal space has not been identified so
far. After selecting the origin, consider the cell of the r space whose sides emanate
from it; these sides are made to coincide with the characteristic vectors (compare,
e.g., with Fig. 17.3), so that, to any point r = Î¼1 a1 + Î¼2 a2 + Î¼3 a3 that belongs to
the interior or the boundary of the cell, the following restriction apply: 0 &le; Î¼i &le; 1.
Similarly, if one considers the cell of the k space whose sides emanate from the
origin, for any point k = Î½1 2Ï b1 +Î½2 2Ï b2 +Î½3 2Ï b3 that belongs to the interior
or the boundary of the cell it is 0 &le; Î½i &le; 1.
</p>
<p>17.4 Wigner&ndash;Seitz Cell&mdash;Brillouin Zone
</p>
<p>It has been mentioned in Sect. 17.2 that the cell properties do not identify the cell
uniquely. Cells of a form different from that shown, e.g., in the two-dimensional
example of Fig. 17.2 can be constructed. Among them, of particular interest is the
Wigner&ndash;Seitz cell, whose construction is shown in Fig. 17.4 still considering a two-
dimensional lattice of the oblique type. First, the node to be associated to the cell is
connected to its nearest neighbors as shown in the figure (the connecting segments are</p>
<p/>
</div>
<div class="page"><p/>
<p>312 17 Periodic Structures
</p>
<p>Fig. 17.4 A Wigner&ndash;Seitz
cell in a two-dimensional,
oblique lattice
</p>
<p>the continuous lines); then, the axis of each segment is drawn (dashed lines). As the
axis is the locus of points having the same distance from the extrema of the connecting
segment, one can select a contour, made of portions of the axes (thick line), such
that the following property holds: any point inside the contour is closer to the node
associated to the cell than to any other lattice node. From the construction described
above it also follows that the shaded surface so obtained fulfills the requisites listed
in Sect. 17.2, so it is a cell proper; such a cell, named after Wigner and Seitz, fulfills
the additional property of the closeness of the internal points. Its construction in the
three-dimensional case is similar, the only difference being that the axis is replaced
with the plane normal to the connecting segment at the midpoint.
</p>
<p>The concept of Wigner&ndash;Seitz cell, that has been introduced above using the direct
lattice by way of example, is applicable also to the reciprocal and scaled-reciprocal
lattices. In the scaled reciprocal lattice, the Wigner-Seitz cell associated to the ori-
gin is called first Brillouin zone. The set of Wigner-Seitz cells adjacent to the first
Brilluoin zone is called second Brillouin zone, and so on. The first Brillouin zone of
the FCC lattice is shown in Fig. 17.5; its boundary is made of six square faces and
eight hexagonal faces. The center of the zone is called Î point; the k1 axis belongs to
the [100] crystal direction5 and intercepts the boundary of the Brilluoin zone at two
opposite positions called X points, that coincide with the center of square faces; the
k2, k3 axes belong to the [010] and [001] directions, respectively, and intercept the
boundary at X points as well. In turn, the {111} directions intercept the boundary at
positions called L points, that coincide with the center of the hexagonal faces. There
is a total of eight L points, because the set {111} is made of the [111], [1Ì11], [1Ì1Ì1],
[11Ì1] directions along with those of complementary signs.
</p>
<p>17.5 Translation Operators
</p>
<p>The typical procedure by which the physical properties of periodic structures, like
crystals, are investigated, entails the solution of eigenvalue equations generated by
quantum-mechanical operators. In this respect it is useful to introduce a class of
</p>
<p>5 The symbols indicating the crystal directions are illustrated in Sect. 17.8.1.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.5 Translation Operators 313
</p>
<p>Fig. 17.5 The first Brillouin
zone of the FCC lattice
</p>
<p>k1
</p>
<p>k3
</p>
<p>2k
</p>
<p>Î
</p>
<p>Î§
</p>
<p>Î§
</p>
<p>L
</p>
<p>Î§
</p>
<p>operators, called translation operators, that are associated to the direct-lattice vectors
l defined by (17.1). To ease the notation, the translation operator associated to the
ith lattice vector li is indicated with Ti = T (li). A translation operator is defined by
the property
</p>
<p>Tif (r) = f (r + li) (17.18)
</p>
<p>for all functions f defined over the direct lattice. It is easily found that translation
operators are linear and non-Hermitean. Also, they commute with each other; in fact,
</p>
<p>TiTsf (r) = f (r + li + ls) = TsTif (r) (17.19)
</p>
<p>for all functions f and all indices i, s. Remembering the property derived in
Sect. 10.4, it follows that all translation operators have a common set of eigen-
functions v. Combining this result with definition (17.18) provides the form of the
eigenvalues Î± of the translation operators. For this, consider the operators associated
to three arbitrary vectors li , ls , and lu, and generate the eigenvalue equations
</p>
<p>Ti v = Î±(li) v, Ts v = Î±(ls) v, Tu v = Î±(lu) v. (17.20)
</p>
<p>If one now lets lu = li + ls , it follows TiTs v(r) = v(r + li + ls) = Tu v(r), that is,
TiTs = Tu. On the other hand, the first two eigenvalue equations in (17.20) provide
TiTs v = Ti Î±(ls) v = Î±(li)Î±(ls) v which, combined with the third one, yields
</p>
<p>Î±(li)Î±(ls) = Î±(lu) = Î±(li + ls). (17.21)</p>
<p/>
</div>
<div class="page"><p/>
<p>314 17 Periodic Structures
</p>
<p>The result shows that the functional dependence of Î± on the translation vector must
be of the exponential type:
</p>
<p>Î±(l) = exp (c &middot; l), c =
3
</p>
<p>&sum;
</p>
<p>s=1
(&real;Ïs + i&image;Ïs) 2Ï bs , (17.22)
</p>
<p>where c is a complex vector whose units are the inverse of a length. For this reason c is
given the general form shown in the second relation of (17.22), with bs a characteristic
vector of the reciprocal lattice, s = 1, 2, 3, and Ïs a dimensionless complex number
that is provisionally left unspecified.
</p>
<p>17.5.1 Bloch Theorem
</p>
<p>The expression (17.22) of the eigenvalues of the translation operators makes it
possible to specify some property of the eigenfunctions; in fact, combining the
definition of translation operator, T v(r) = v(r + l), with the eigenvalue equation
T v(r) = exp (c &middot; l) v(r) yields
</p>
<p>vc(r + l) = exp (c &middot; l) vc(r), (17.23)
</p>
<p>called Bloch&rsquo;s theorem (first form). The importance of this result can be appreciated
by observing that, if v is known within a lattice cell, and c is given, then the eigen-
function can be reconstructed everywhere else. The index in (17.23) reminds one that
the eigenfunction depends on the choice of c. The theorem can be recast differently
by defining an auxiliary function uc(r) = vc(r) exp ( &minus; c &middot; r), so that
</p>
<p>vc(r + l) = exp (c &middot; l) vc(r) = exp (c &middot; l) uc(r) exp (c &middot; r). (17.24)
</p>
<p>In turn, from the definition of uc one draws vc(r + l) = uc(r + l) exp [c &middot; (r + l)]
which, combined with (17.24), yields the Bloch theorem (second form):
</p>
<p>vc(r) = uc(r) exp (c &middot; r), uc(r + l) = uc(r). (17.25)
</p>
<p>The second form of Bloch&rsquo;s theorem shows that the auxiliary function uc is periodic
in the direct lattice, so that the eigenfunctions of the translation operators are the
product of an exponential function times a function having the lattice periodicity.
One notes the similarity of this result with that expressed by (13.32); in fact, the
Bloch theorem is a form of the Floquet theorem (Sect. 13.4).
</p>
<p>The eigenfunctions of the translation operators play an important role in the
description of the physical properties of periodic structures. For this reason, vec-
tors c of the general form are not acceptable because their real part would make
vc(r) = uc(r) exp (c &middot; r) to diverge as r departs more and more from the origin.6
</p>
<p>6 This aspect is further elaborated in Sect. 17.5.3.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.5 Translation Operators 315
</p>
<p>It is then necessary to impose the restriction c = i k, with k real. This is achieved
by letting &real;Ïs = 0 and &image;Ïs = Î½s in the second relation of (17.22), so that the
eigenvalues of the translation operators become
</p>
<p>Î±(l) = exp (i k &middot; l), k =
3
</p>
<p>&sum;
</p>
<p>s=1
Î½s 2Ï bs . (17.26)
</p>
<p>Remembering (17.15), such eigenvalues are periodic in the scaled reciprocal lattice.
In turn, the first and second form of the Bloch theorem become, respectively,
</p>
<p>vk(r + l) = exp (i k &middot; l) vk(r), (17.27)
</p>
<p>vk(r) = uk(r) exp (i k &middot; r), uk(r + l) = uk(r). (17.28)
Eigenfunctions of the form (17.27, 17.28) are also called Bloch functions. They fulfill
the eigenvalue equation T vk(r) = exp (i k &middot; l) vk(r) so that, observing that T is real
and taking the conjugate of the eigenvalue equation yields
</p>
<p>T v&lowast;k(r) = exp ( &minus; i k &middot; l) v&lowast;k(r). (17.29)
If, instead, one replaces k with &minus;k in the original equation, the following is found:
</p>
<p>T v&minus;k(r) = exp ( &minus; i k &middot; l) v&minus;k(r). (17.30)
Comparing (17.30) with (17.29) shows that v&lowast;k and v&minus;k belong to the same eigenvalue.
Moreover, comparing the second expression in (17.26) with (17.11) shows that k is
a vector of the scaled reciprocal lattice.
</p>
<p>A further reasoning demonstrates that the variability of k in (17.27, 17.28) can
be limited to a single cell of the scaled reciprocal lattice; for instance, to the first
Brillouin zone or, alternatively, to the cell of the k space whose sides emanate from
the origin, so that the coefficients of (17.11) fulfill the relation 0 &le; Î½i &le; 1 as shown
in Sect. 17.3. The property derives from the periodicity of the eigenvalues in the
scaled reciprocal lattice, exp [i (k + g) &middot; l] = exp (i k &middot; l), due to which the values of
exp (i k &middot; l), with k ranging over a single cell, provide the whole set of the operator&rsquo;s
eigenvalues. As exp [i (k + g) &middot; l] is the same eigenvalue as exp (i k &middot; l), the Bloch
function vk+g(r) is the same as vk(r). Note that the reasoning does not prevent the
eigenvalue from being degenerate: if this is the case, one finds
</p>
<p>v
(1)
k+g = v(1)k , v(2)k+g = v(2)k , . . . (17.31)
</p>
<p>17.5.2 Periodic Operators
</p>
<p>An operator A is periodic in the direct lattice if A(r + l) = A(r) for all vectors r
and all translation vectors l of the direct lattice. Periodic operators commute with
translation operators: this is shown by letting v&prime; = Av, so that
</p>
<p>T (l)A(r)v(r) = T (l)v&prime;(r) = v&prime;(r + l) =</p>
<p/>
</div>
<div class="page"><p/>
<p>316 17 Periodic Structures
</p>
<p>Fig. 17.6 A finite block of
material obtained by
sectioning a crystal by means
of three pairs of parallel
crystal planes
</p>
<p>a2
</p>
<p>a3 a1
</p>
<p>Q
</p>
<p>P
</p>
<p>= A(r + l)v(r + l) = A(r)v(r + l) = A(r)T (l)v(r). (17.32)
</p>
<p>From the commutativity property T A = AT it follows that T and A have a common
set of eigenfunctions, so that the eigenfunctions of a periodic operator are Bloch
functions; letting Ak be the eigenvalue, one has
</p>
<p>Avk = Ak vk, (17.33)
</p>
<p>with k belonging to a single cell of the scaled reciprocal lattice, and vk+g = vk. Since
an eigenfunction belongs to one eigenvalue only, it follows
</p>
<p>Ak+g = Ak, (17.34)
</p>
<p>namely, if an operator is periodic in the direct lattice, its eigenvalues are periodic in
the scaled reciprocal lattice.
</p>
<p>17.5.3 Periodic Boundary Conditions
</p>
<p>In the derivation of the Bloch theorem, carried out in Sect. 17.5.1, it has been observed
that complex vectors c in the expression vc(r) = uc(r) exp (c&middot;r) of the eigenfunctions
are not acceptable because their real part would make the function to diverge. In
fact, as noted in Sect. 17.5.2, such eigenfunctions belong also to the operators that
commute with the translation operators and may describe physical properties of the
crystal, so that diverging solutions must be discarded. On the other hand, such a
divergence is due to the assumption that the crystal is unlimited; in the more realistic
case of a finite block of material, diverging solutions would not appear. Unfortunately,
a finite block of material is not periodic, hence the useful concepts and properties
worked out so far in this chapter are not applicable to it.
</p>
<p>To further investigate on the subject one notes that a finite block may be thought of
as derived from the original crystal by sectioning the latter using three pairs of parallel
crystal planes, as shown in Fig. 17.6. One of the vertices of the block coincides with</p>
<p/>
</div>
<div class="page"><p/>
<p>17.5 Translation Operators 317
</p>
<p>the origin of the reference of the direct lattice, and the block&rsquo;s sides are aligned with
the characteristic vectors. Also, the type of cell chosen here is the one whose sides
coincide with the characteristic vectors themselves. The relation between the total
number Nc of the block&rsquo;s cells, the block&rsquo;s volume ï¿½, and that of the cell is easily
found to be
</p>
<p>Nc = N1 N2 N3 =
ï¿½
</p>
<p>Ïl
, (17.35)
</p>
<p>with Ns the number of cell sides that match the side of the block in the sth direction.
In a finite volume of material, the number of cells that belong to the interior is
typically much larger than the number of cells that are adjacent to the boundaries;
when solving a single-electron Schr&ouml;dinger equation within such a structure, it is
found that in the interior of it the eigenfunctions practically coincide with Bloch
functions, whereas the effect of the real part of vector c in vc(r) = uc(r) exp (c &middot; r)
becomes relevant only when the position under investigation is close to a boundary.
In fact, the real part of c is such that the eigenfunctions become vanishingly small
far away from the volume considered [15, Sects. F-XI, O-III].
</p>
<p>The considerations above show that for practical purposes one may keep the
analysis based on the original periodicity of the unlimited structure by replacing the
vanishing boundary conditions with a different type of conditions, able to formally
restore periodicity in a finite structure. This is accomplished by imposing the identity
of the Bloch functions corresponding to two boundary points facing each other along
the direction of a characteristic vector. This prescription, called periodic boundary
condition or Born&ndash;Von Karman boundary condition, is illustrated with the aid of
Fig. 17.6. Consider for instance point r = Î¼1 a1 + Î¼2 a2 (labeled P in the figure),
that belongs to the boundary plane defined by a1, a2. Point Q facing P on the
opposite boundary plane is such that Q&minus; P = l = N3 a3 whence, applying the first
form (17.23) of Bloch&rsquo;s theorem, one obtains vc(r + N3 a3) = exp (N3 c &middot; a3) vc(r).
Imposing vc(r + N3 a3) = vc(r) yields N3 c &middot; a3 = i n3 2Ï , with n3 any integer, so
that, using expression (17.22) for c,
</p>
<p>N3 c &middot; a3 = 2Ï N3 (&real;Ï3 + i&image;Ï3) = i n3 2Ï. (17.36)
</p>
<p>In conclusion, &real;Ï3 = 0 and &image;Ï3 = 2Ï n3/N3. The same reasoning is repeated
along the other directions, to finally yield
</p>
<p>c = i k, k =
3
</p>
<p>&sum;
</p>
<p>s=1
</p>
<p>ns
</p>
<p>Ns
2Ï bs . (17.37)
</p>
<p>In summary, the application of the periodic boundary conditions gives c the same
imaginary form c = i k that was found in an unlimited structure, the difference being
that in a finite structure the components of k are discrete instead of being continuous:
given the size of the structure, which is prescribed by N1, N2, N3, each k vector of
the scaled reciprocal lattice is associated to a triad of integers n1, n2, n3.
</p>
<p>Note that the reasoning carried out at the end of Sect. 17.5.1 about the variability
of k still holds; as a consequence, k can be restricted to a single cell of the scaled</p>
<p/>
</div>
<div class="page"><p/>
<p>318 17 Periodic Structures
</p>
<p>reciprocal lattice, so that its coefficients Î½s = ns/Ns fulfill the relation 0 &le; Î½s &le; 1
as shown in Sect. 17.3. In fact, as Î½s = 0 and Î½s = 1 are redundant, the above
relation must more appropriately be recast as 0 &le; ns/Ns &lt; 1, corresponding to
ns = 0, 1, . . . ,Ns &minus; 1 or, alternatively, 0 &lt; ns/Ns &le; 1, corresponding to ns =
1, 2, . . . ,Ns . In both cases, ns can take Ns distinct values, so that the total number
of distinct k vectors in a cell of the scaled reciprocal lattice is N1 N2 N3 = Nc. From
(17.35) one finds that such a number equals the number of the structure&rsquo;s cells in
the direct lattice. Also, as the k vectors are equally spaced in each direction, their
density in the reciprocal scaled lattice is uniform; it is given by the ratio Nc/Ïg , with
Ïg the cell&rsquo;s volume. Remembering that the latter is invariant (Sect. 17.3), one may
think of k as restricted to the first Brillouin zone. Combining (17.8) with (17.17) and
(17.35) yields for the density
</p>
<p>Nc
</p>
<p>Ïg
= ï¿½/Ïl
</p>
<p>Ïg
= ï¿½
</p>
<p>(2Ï )3
. (17.38)
</p>
<p>One can also define a combined density of the k vectors in the r, k space, which
is obtained by dividing (17.38) by the volume ï¿½. This yields the dimensionless
combined density
</p>
<p>1
</p>
<p>ï¿½
</p>
<p>Nc
</p>
<p>Ïg
= 1
</p>
<p>(2Ï )3
. (17.39)
</p>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice
</p>
<p>The concepts introduced in the previous sections of this chapter are applied here to the
solution of the Schr&ouml;dinger equation in a periodic lattice. It is assumed provisionally
that the lattice is unlimited; as a consequence, the components of the k vector are
continuous. The Schr&ouml;dinger equation to be solved derives from the single-electron
operator (16.27) obtained from the separation procedure outlined in Sects. 16.2&ndash;16.5.
This means the nuclei are kept fixed and the force acting on the electron derives from
a potential energy7 having the periodicity of the direct lattice: V (r+ l) = V (r), with
l given by (17.1). As mentioned in Sects. 16.4 and 16.5, the external forces are absent
(Uext = 0). The equation then reads
</p>
<p>Hw = E w, H = &minus; hÌ
2
</p>
<p>2m
&nabla;2 + V. (17.40)
</p>
<p>Replacing r with r + l is equivalent to add a constant to each component of r,
say, xi &larr; xi + li , hence the partial derivatives in (17.40) are unaffected. As a
</p>
<p>7 The indices of (16.27) are dropped for simplicity.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 319
</p>
<p>consequence, the Hamiltonian operator as a whole has the lattice periodicity, so that
its eigenfunctions are Bloch functions. Remembering (17.28), they read
</p>
<p>wk(r) = uk(r) exp (i k &middot; r), uk(r + l) = uk(r), (17.41)
</p>
<p>with k belonging to the first Brillouin zone (Sect. 17.5.3). Letting k2 = |k|2, (17.41)
yields&nabla;2wk = exp (i k&middot;r) (&minus;k2+&nabla;2+2 i k&middot;grad) uk whence, ifEk is the eigenvalue
corresponding to wk, the Schr&ouml;dinger equation (17.40) becomes
</p>
<p>V uk =
[
</p>
<p>Ek +
hÌ2
</p>
<p>2m
</p>
<p>(
</p>
<p>&minus;k2 + &nabla;2 + 2 i k &middot; grad
)
]
</p>
<p>uk. (17.42)
</p>
<p>As both V and uk have the periodicity of the lattice, they can be expanded in terms
of the translation vectors of the scaled reciprocal lattice g = n1 2Ï b1 + n2 2Ï b2 +
n3 2Ï b3:
</p>
<p>V (r) =
&sum;
</p>
<p>g
</p>
<p>Vg exp (i g &middot; r), uk(r) =
&sum;
</p>
<p>g
</p>
<p>skg exp (i g &middot; r), (17.43)
</p>
<p>where
&sum;
</p>
<p>g =
&sum;
</p>
<p>n1
</p>
<p>&sum;
</p>
<p>n2
</p>
<p>&sum;
</p>
<p>n3
and
</p>
<p>Vg =
1
</p>
<p>Ïl
</p>
<p>&int;
</p>
<p>Ïl
</p>
<p>V (r) exp ( &minus; i g &middot; r) d3r , skg =
1
</p>
<p>Ïl
</p>
<p>&int;
</p>
<p>Ïl
</p>
<p>uk(r) exp ( &minus; i g &middot; r) d3r.
(17.44)
</p>
<p>Letting g2 = |g|2, from the expansion of uk it follows (&nabla;2 + 2 i k &middot; grad)uk =
&minus;&sum;g (g2 + 2 k &middot; g) skg exp (i g &middot; r) whence, using g2 + 2 k &middot; g + k2 = |g + k|2,
</p>
<p>V uk =
&sum;
</p>
<p>g
</p>
<p>[
</p>
<p>Ek &minus;
hÌ2
</p>
<p>2m
|g + k|2
</p>
<p>]
</p>
<p>skg exp (i g &middot; r). (17.45)
</p>
<p>In turn, the left hand side of (17.45) reads
</p>
<p>V uk =
&sum;
</p>
<p>g&prime;
</p>
<p>&sum;
</p>
<p>g&prime;&prime;
Vg&prime; skg&prime;&prime; exp [i (g
</p>
<p>&prime; + g&prime;&prime;) &middot; r] =
&sum;
</p>
<p>g&prime;
</p>
<p>&sum;
</p>
<p>g&minus;g&prime;
Vg&prime; sk,g&minus;g&prime; exp (i g &middot; r),
</p>
<p>(17.46)
</p>
<p>with g = g&prime;+g&prime;&prime;. Note that the last expression on the right of (17.46) is left unchanged
if
&sum;
</p>
<p>g&minus;g&prime; is replaced with
&sum;
</p>
<p>g. In fact, as for each vector g
&prime; the indices ni of g span
</p>
<p>from &minus;&infin; to +&infin;, all &infin;6 combinations of indices of g and g&prime; are present in either
form of the expansion; using
</p>
<p>&sum;
</p>
<p>g instead of
&sum;
</p>
<p>g&minus;g&prime; merely changes the order of
summands. Combining (17.45) with (17.46) then yields
</p>
<p>&sum;
</p>
<p>g
</p>
<p>exp (i g &middot; r)
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>&sum;
</p>
<p>g&prime;
Vg&prime; sk,g&minus;g&prime; &minus;
</p>
<p>[
</p>
<p>Ek &minus;
hÌ2
</p>
<p>2m
|g + k|2
</p>
<p>]
</p>
<p>skg
</p>
<p>â«
</p>
<p>â¬
</p>
<p>â­
= 0. (17.47)</p>
<p/>
</div>
<div class="page"><p/>
<p>320 17 Periodic Structures
</p>
<p>As the factors exp (i g &middot; r) are linearly independent from each other for all r, to
fulfill (17.47) it is necessary that the term in braces vanishes. To proceed it is useful
to associate8 a single index b to the triad (n1, n2, n3) defining g, and another single
index b&prime; to the triad (n&prime;1, n
</p>
<p>&prime;
2, n
</p>
<p>&prime;
3) defining g
</p>
<p>&prime;. Remembering that at the beginning of this
section the assumption of an unlimited lattice has been made, k must be considered
a continuous variable, so that s and E become functions of k proper. In conclusion,
(17.47) transforms into
</p>
<p>&sum;
</p>
<p>b&prime;
sb&minus;b&prime; (k)Vb&prime; = [E(k) &minus; Tb(k)] sb(k), b = 0,&plusmn;1,&plusmn;2, . . . , (17.48)
</p>
<p>with Tb(k) the result of the association b &harr; (n1, n2, n3) in hÌ2 |g + k|2/(2m). For
each k, (17.48) is a linear, homogeneous algebraic system in the infinite unknowns
sb and coefficients Vb&prime; , E(k) &minus; Tb(k), with E(k) yet undetermined.
</p>
<p>The solution of (17.48) provides an infinite set of eigenvalues E1(k), E2(k),
. . . ,Ei(k), . . . associated to the given k. As the latter ranges over the first Brillouin
zone, the functions Ei(k) are thought of as branches9 of a many-valued function.
For each branch-index i, the function Ei(k) is called dispersion relation, and the set
of values spanned by Ei(k) as k runs over the Brillouin zone is called energy band
of index i. Being an eigenvalue of a periodic operator, Ei(k) is periodic within the
reciprocal, scaled lattice (compare with (17.34)); also, it can be shown that Ei(k) is
even with respect to k (Sect. 17.8.3):
</p>
<p>Ei(k + g) = Ei(k), Ei( &minus; k) = Ei(k). (17.49)
When a finite structure is considered, supplemented with the periodic boundary
condition discussed in Sect. 17.5.3, vector k is discrete. On the other hand, for the
derivation of (17.47) it is irrelevant whether k is continuous or discrete; hence, the
analysis carried out in this section still holds for a discrete k, provided the additional
relations derived in Sect. 17.5.3, that describe the form of k and the corresponding
densities, are accounted for. It must be remarked that the number Ns of cells along
each direction in the direct lattice is typically very large.10 As a consequence, a change
by one unity of ns in (17.37) is much smaller than the corresponding denominatorNs ,
so that for all practical purposes Ei(k) is treated as a function of continuous variables
when the derivatives with respect to the components of k enter the calculations.
</p>
<p>8 The association b &harr; (n1, n2, n3) can be accomplished in a one-to-one fashion by, first, dis-
tributing the triads into groups having a common value of d = |n1| + |n2| + |n3|, then ordering
the groups in ascending order of d: for example, d = 0 corresponds to (0, 0, 0), d = 1 to
[(0, 0, 1), (0, 1, 0), (1, 0, 0), (0, 0,&minus;1), (0,&minus;1, 0), ( &minus; 1, 0, 0)], and so on. As each group is made by
construction of a finite number of triads, the latter are numbered within each group using a finite
set of values of b; in order to have b ranging from &minus;&infin; to +&infin;, one associates a positive (negative)
value of b to the triads in which the number of negative indices is even (odd).
9 Typically, a graphic representation ofEi (k) is achieved by choosing a crystal direction and drawing
the one-dimensional restriction of Ei along such a direction. Examples are given in Sect. 17.6.5.
10 For instance, in a cube of material with an atomic density of 6.4 &times; 1027 m&minus;3, the number of
atoms per unit length in each direction is 4000 &micro;m&minus;1.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 321
</p>
<p>The analysis carried out in this section clarifies the role of k. In fact, for a given
band index i, k labels the energy eigenvalue; for this reason, remembering the dis-
cussion about spin carried out in Sect. 15.5, k and the quantum number associated to
spin determine the state of the particle. For fermions, the quantum number associated
to spin has two possible values, so that two states with opposite spins are associated
to each k vector. When the periodic boundary conditions are considered, the density
of k vectors in the k space is given by (17.38), and the combined density of k vectors
in the r, k space is given by (17.39). As a consequence, the density of states in the k
space and in the r, k space are given, respectively, by
</p>
<p>Qk = 2
Nc
</p>
<p>Ïg
= ï¿½
</p>
<p>4Ï3
, Q = 2 1
</p>
<p>ï¿½
</p>
<p>Nc
</p>
<p>Ïg
= 1
</p>
<p>4Ï3
. (17.50)
</p>
<p>17.6.1 Wave Packet in a Periodic Potential
</p>
<p>From the solution of the Schr&ouml;dinger equation worked out from (17.48) one recon-
structs the periodic part of the Bloch function using the second relation in (17.43).
Such a function inherits the band index i, so that the Bloch functions11 read wi k =
Î¶i k exp (i k &middot;r); they form a complete set so that, letting Ïi k = Ïi(k) = Ei(k)/hÌ, the
expansion of the wave function Ï(r, t) in terms of the eigenfunctions of the periodic
Hamiltonian operator (17.40) reads
</p>
<p>Ï(r, t) =
&sum;
</p>
<p>i k
</p>
<p>ci k wi k(r) exp ( &minus; iÏi k t) =
&sum;
</p>
<p>i k
</p>
<p>ci k Î¶i k(r) exp [i (k &middot; r &minus; Ïi k t)],
</p>
<p>(17.51)
</p>
<p>with ci k = ãwi k|Ïãt=0 a set of constants. The expansion (17.51) bears a strong
similarity with that of the wave packet describing a free particle (compare with
(9.1)), the only difference between the two expansions being the periodic factor
Î¶i k(r). The similarity suggests that an approximate expression of the wave packet
is achieved by following the same reasoning as in Sect. 9.6, namely, by expanding
Ïi(k) around the average value k0 of the wave vector and retaining the first-order
term of the expansion:12
</p>
<p>Ïi(k) â Ïi(k0) + ui(k0) &middot; (k &minus; k0), ui(k0) =
(
</p>
<p>gradkÏi
)
</p>
<p>0 , (17.52)
</p>
<p>with ui the group velocity of the ith band. The approximation holds as long as
|Ri | t âª 2Ï , where Ri is the rest of the expansion. Letting Ïi 0 = Ïi(k0), Î¶i 0 =
Î¶i(k0), and Î¦i 0 = k0 &middot; r &minus; Ïi 0 t , the approximate expression of Ï reads
</p>
<p>Ï(r, t) â
&sum;
</p>
<p>i k
</p>
<p>ci k Î¶i 0 exp (iÎ¦i 0) exp [i (r &minus; ui t) &middot; (k &minus; k0)] . (17.53)
</p>
<p>11 Here the periodic part of wi k is indicated with Î¶i k to avoid confusion with the group velocity.
12 In the case of a free particle (Sect. 9.6) the approximation neglects only the second order because
Ï(k) has a quadratic dependence on the components of k. Here, instead, the expansion has in general
all terms due to the more complicate form of Ïi (k), so the neglected rest Ri contains infinite terms.</p>
<p/>
</div>
<div class="page"><p/>
<p>322 17 Periodic Structures
</p>
<p>Fig. 17.7 A one-dimensional
example of the periodic factor
Î¶n 0 of (17.56)
</p>
<p>-20 -10 0 10 20
x     (arbitrary units)
</p>
<p>-1
</p>
<p>-0.5
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>Î¶ n
 0
</p>
<p> (
x
) 
</p>
<p>  
  
(a
</p>
<p>rb
it
</p>
<p>ra
ry
</p>
<p> u
n
it
</p>
<p>s)
</p>
<p>The envelope function is now defined as in (9.26), the difference being that a sum is
used here instead of an integral:
</p>
<p>A (r &minus; ui t ; k0) =
&sum;
</p>
<p>k
</p>
<p>ci k exp [i (r &minus; ui t) &middot; (k &minus; k0)] , (17.54)
</p>
<p>so that
</p>
<p>Ï(r, t) â
&sum;
</p>
<p>i
</p>
<p>Î¶i 0 exp (iÎ¦i 0)A (r &minus; ui t ; k0) . (17.55)
</p>
<p>As a further approximation one considers the fact that the number of k vectors of
the first Brillouin zone is in general very large, because it equals the number Nc
of direct-lattice cells. It follows that, although the set of eigenfunctions belonging
to a single branch is not complete, such a set is still able to provide an acceptable
description of the wave packet. In this case one fixes the branch index, say, i = n,
so that Ï(r, t) â Î¶n 0 exp (iÎ¦n 0)A(r &minus; un t ; k0). It follows
</p>
<p>|Ï(r, t)|2 â |Î¶n 0(r)|2 |A (r &minus; un t ; k0) |2. (17.56)
</p>
<p>In (17.56), the periodic factor |Î¶n 0(r)|2 is a rapidly-oscillating term whose period is
of the order of the lattice constant; such a term does not provide any information
about the particle&rsquo;s localization. This information, in fact, is carried by the envelope
function, like in the case of a free particle outlined in Sect. 9.6. A one-dimensional
example about how (17.56) is built up is given in Figs. 17.7, 17.8, 17.9, and 17.10.
</p>
<p>17.6.2 Parabolic-Band Approximation
</p>
<p>The dispersion relation En(k) obtained from the solution of the Schr&ouml;dinger equa-
tion (17.40) in a periodic lattice fulfills the periodicity condition given by the</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 323
</p>
<p>Fig. 17.8 A one-dimensional
example of the envelope
function A(r &minus; un t ; k0) of
(17.56)
</p>
<p>-20 -10 0 10 20
x     (arbitrary units)
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>A
 (
</p>
<p> x
 -
</p>
<p> u
n
 t
</p>
<p> ;
k 0
</p>
<p> )
  
</p>
<p>  
 (
</p>
<p>ar
b
</p>
<p>it
ra
</p>
<p>ry
 u
</p>
<p>n
it
</p>
<p>s)
</p>
<p>Fig. 17.9 Product of the two
functions shown in Figs. 17.7
and 17.8
</p>
<p>-20 -10 0 10 20
x     (arbitrary units)
</p>
<p>-1
</p>
<p>-0.5
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>n
0
A
</p>
<p>(a
rb
</p>
<p>it
ra
</p>
<p>ry
 u
</p>
<p>n
it
</p>
<p>s)
Î¶
</p>
<p>Fig. 17.10 The function of
Fig. 17.9 squared
</p>
<p>-20 -10 0 10 20
x     (arbitrary units)
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>(
n
</p>
<p>0
A
</p>
<p> )
2
</p>
<p>(a
rb
</p>
<p>it
ra
</p>
<p>ry
 u
</p>
<p>n
it
</p>
<p>s)
Î¶</p>
<p/>
</div>
<div class="page"><p/>
<p>324 17 Periodic Structures
</p>
<p>first expression in (17.49). As a consequence, En(k) has necessarily a number of
extremum points within the first Brillouin zone or at the boundary of it.13
</p>
<p>In view of further developments of the theory it is useful to investigate the form of
En(k) in the vicinity of such extremum points. To this purpose, the absolute minima
are considered first; for a given branch index n assume that the number of such
minima is MC , and let ka be the value of k at the ath minimum, a = 1, . . . ,MC ,
with EC = En(ka). At k = ka the Hessian matrix of En(k) is symmetric and positive
definite, hence it can be diagonalized with positive real eigenvalues. In other terms,
the reference in the k space can be chosen in such a way as to make the Hessian
matrix of En(k) diagonal; using such a reference, the second-order expansion of
En(k) around ka reads
</p>
<p>En(k) â EC +
1
</p>
<p>2
</p>
<p>3
&sum;
</p>
<p>i=1
</p>
<p>(
&part;2En
</p>
<p>&part;k2i
</p>
<p>)
</p>
<p>a
</p>
<p>(ki &minus; kia)2 &ge; Ea , a = 1, . . . ,MC . (17.57)
</p>
<p>The first derivatives are missing from (17.57) because the expansion is carried out at
an extremum. The coefficients (&part;2En/&part;k2i )a are in general different from each other,
so that the sum in (17.57) may be thought of as a positive-definite quadratic form
generated by a 3 &times; 3 diagonal matrix. Noting the units of the matrix entries one
defines the inverse, effective-mass tensor of the ath minimum as
</p>
<p>(mÌa)
&minus;1 =
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>1/m1 a 0 0
</p>
<p>0 1/m2 a 0
</p>
<p>0 0 1/m3 a
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>,
1
</p>
<p>mia
= 1
</p>
<p>hÌ2
</p>
<p>(
&part;2En
</p>
<p>&part;k2i
</p>
<p>)
</p>
<p>a
</p>
<p>&gt; 0 (17.58)
</p>
<p>so that, using the notation Ene(k) = En(k) &minus; EC &ge; 0, Î´ki = ki &minus; kia , (17.57) takes
the form
</p>
<p>Ene =
3
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>hÌ2
</p>
<p>2mia
(ki &minus; kia)2 =
</p>
<p>1
</p>
<p>2
hÌ Î´k &middot; (mÌa)&minus;1 hÌ Î´k. (17.59)
</p>
<p>Being the inverse, effective-mass tensor diagonal, the effective-mass tensor mÌa is
given by
</p>
<p>mÌa =
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>m1 a 0 0
</p>
<p>0 m2 a 0
</p>
<p>0 0 m3 a
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
. (17.60)
</p>
<p>The approximation shown above, that consists in replacing the dispersion relation
with its second-order expansion near an extremum, is called parabolic-band approx-
imation. The group velocity to be associated with a k vector in the vicinity of a
</p>
<p>13 As mentioned in Sect. 17.6, En(k) is considered as a function of a continuous vector variable k
even when the periodic boundary conditions are assumed.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 325
</p>
<p>minimum is found by applying to (17.59) the second relation in (17.52):
</p>
<p>un(k) =
1
</p>
<p>hÌ
gradkEn(k) =
</p>
<p>1
</p>
<p>hÌ
gradkEne(k) = (mÌa)&minus;1 hÌ Î´k. (17.61)
</p>
<p>The calculation in the vicinity of an absolute maximum is similar.14 Assume that
the number of maxima in the nth branch of the dispersion relation is MV , and let
ka be the value of k at the ath maximum, a = 1, . . . ,MV , with EV = En(ka). The
second-order expansion of En(k) around ka reads
</p>
<p>En(k) â EV +
1
</p>
<p>2
</p>
<p>3
&sum;
</p>
<p>i=1
</p>
<p>(
&part;2En
</p>
<p>&part;k2i
</p>
<p>)
</p>
<p>a
</p>
<p>(ki &minus; kia)2 &le; Ea , a = 1, . . . ,MV , (17.62)
</p>
<p>where the Hessian matrix is negative definite. For this reason, the inverse, effective-
mass tensor at the ath maximum is defined as
</p>
<p>(mÌa)
&minus;1 =
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>1/m1 a 0 0
</p>
<p>0 1/m2 a 0
</p>
<p>0 0 1/m3 a
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>,
1
</p>
<p>mia
= &minus; 1
</p>
<p>hÌ2
</p>
<p>(
&part;2En
</p>
<p>&part;k2i
</p>
<p>)
</p>
<p>a
</p>
<p>&gt; 0
</p>
<p>(17.63)
</p>
<p>so that, using the notation Enh(k) = EV &minus; En(k) &ge; 0, (17.57) takes the form
</p>
<p>Enh =
3
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>hÌ2
</p>
<p>2mia
(ki &minus; kia)2 =
</p>
<p>1
</p>
<p>2
hÌ Î´k &middot; (mÌa)&minus;1 hÌ Î´k. (17.64)
</p>
<p>The group velocity to be associated with a k vector in the vicinity of a maximum
reads
</p>
<p>un(k) =
1
</p>
<p>hÌ
gradkEn(k) = &minus;
</p>
<p>1
</p>
<p>hÌ
gradkEnh(k) = &minus;(mÌa)&minus;1 hÌ Î´k. (17.65)
</p>
<p>It is important to note that the expressions of the parabolic-band approximation given
in this section have been worked out in a specific reference of the k space, namely,
the reference where the Hessian matrix is diagonal. In so doing, the reference of the
direct space r has been fixed as well, because the two references are reciprocal to
each other (Sect. 17.3). In other terms, when diagonal expressions like (17.59) or
(17.64) are used in a dynamical calculation, the reference in the r space can not be
chosen arbitrarily.
</p>
<p>14 The parabolic-band approximation is not necessarily limited to absolute minima or absolute
maxima; here it is worked out with reference to such cases because they are the most interesting
ones. However, it applies as well to relative minima and relative maxima. The different values of
the inverse, effective-mass tensor&rsquo;s entries between an absolute and a relative minimum of a branch
in GaAs give rise to interesting physical effects (Sect. 17.6.6).</p>
<p/>
</div>
<div class="page"><p/>
<p>326 17 Periodic Structures
</p>
<p>17.6.3 Density of States in the Parabolic-Band Approximation
</p>
<p>Calculations related to many-particle systems often involve the density of states in
energy (e.g., Sects. 15.8.1, 15.8.2). The calculation of this quantity is relatively simple
for the dispersion relation En(k) in the parabolic-band approximation, because the
dispersion relation is quadratic in the components of k and, in turn, the density of the
k vectors is constant. In fact, it is found from (B.34) that in the three-dimensional
case a quadratic expression A = u2 +v2 +w2 yields a density of states equal to A1/2.
It is then sufficient to reduce (17.59) and (17.64) to the quadratic expression above.
Taking (17.59) by way of example, one disposes with the multiplicative factors and
the shift in the origin by applying the Herring&ndash;Vogt transformation
</p>
<p>Î·i =
hÌ&radic;
</p>
<p>2mia
(ki &minus; kia), (17.66)
</p>
<p>to find
</p>
<p>Ene =
3
</p>
<p>&sum;
</p>
<p>i=1
Î·2i = Î·2, dki =
</p>
<p>&radic;
2mia
hÌ
</p>
<p>dÎ·i , (17.67)
</p>
<p>with Î· &gt; 0, and
</p>
<p>d3k = dk1 dk2 dk3 = 2
&radic;
</p>
<p>2
</p>
<p>hÌ3
m3/2ea d
</p>
<p>3Î·, mea = (m1a m2a m3a)1/3. (17.68)
</p>
<p>Turning to spherical coordinates Î·1 = Î· sin Ï cosÏ, Î·2 = Î· sin Ï sin Ï, Î·3 =
Î· cosÏ yields d3Î· = Î·2dÎ· sin Ï dÏ dÏ (Sect. B.1), where the product Î·2 dÎ· is
found by combining the relations 2 Î· dÎ· = dEne and dÎ· = dEne/(2
</p>
<p>&radic;
Ene):
</p>
<p>Î·2 dÎ· = 1
2
</p>
<p>&radic;
</p>
<p>Ene dEne. (17.69)
</p>
<p>The number of states belonging to the elementary volume d3k is dN = Qk d3k, with
Qk the density of states in the k space given by the first expression in (17.50). If the
elementary volume is centered on a k vector close to the ath minimum of En(k), so
that the parabolic-band approximation holds, one has
</p>
<p>dNa = Qk d3k =
ï¿½
</p>
<p>4Ï3
2
</p>
<p>&radic;
2
</p>
<p>hÌ3
m3/2ea
</p>
<p>1
</p>
<p>2
</p>
<p>&radic;
</p>
<p>Ene dEne sin Ï dÏ dÏ. (17.70)
</p>
<p>The integral over the angles yields 4Ï , whence
</p>
<p>&int; 2Ï
</p>
<p>Ï=0
</p>
<p>&int; Ï
</p>
<p>Ï=0
dNa = ï¿½
</p>
<p>&radic;
2
</p>
<p>Ï2 hÌ3
m3/2ea
</p>
<p>&radic;
</p>
<p>Ene dEea = ga(Ene) dEne (17.71)</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 327
</p>
<p>where, by construction, ga(Ene) is the density of states in energy around the ath
minimum. Adding ga over the MC absolute minima yields the total density of states
in energy,
</p>
<p>g(Ene) =
MC&sum;
</p>
<p>a=1
ga = ï¿½
</p>
<p>&radic;
2
</p>
<p>Ï2 hÌ3
MC m
</p>
<p>3/2
e
</p>
<p>&radic;
</p>
<p>Ene, me =
(
</p>
<p>1
</p>
<p>MC
</p>
<p>MC&sum;
</p>
<p>a=1
m3/2ea
</p>
<p>)2/3
</p>
<p>,
</p>
<p>(17.72)
</p>
<p>with me the average effective mass of the absolute minima. The combined density of
states in the energy and r spaces then reads
</p>
<p>Î³ (Ene) =
g(Ene)
</p>
<p>ï¿½
=
</p>
<p>&radic;
2
</p>
<p>Ï2 hÌ3
MC m
</p>
<p>3/2
e
</p>
<p>&radic;
</p>
<p>Ene. (17.73)
</p>
<p>Note that, apart from the different symbol used to indicate the volume in the r
space, and the replacement of m with MC m
</p>
<p>3/2
e , the relations (17.72) and (17.73) are
</p>
<p>identical, respectively, to (15.64) and (15.65), expressing the density of states and
combined density of states in a box.
</p>
<p>The calculation of the density of states in energy in the vicinity of theMV absolute
maxima is identical to the above, and yields
</p>
<p>g(Enh) =
MV&sum;
</p>
<p>a=1
ga = ï¿½
</p>
<p>&radic;
2
</p>
<p>Ï2hÌ3
MV m
</p>
<p>3/2
h
</p>
<p>&radic;
</p>
<p>Enh, mh =
(
</p>
<p>1
</p>
<p>MV
</p>
<p>MV&sum;
</p>
<p>a=1
m
</p>
<p>3/2
ha
</p>
<p>)2/3
</p>
<p>,
</p>
<p>(17.74)
</p>
<p>where mh is the average effective mass of the absolute maxima. In turn it is mha =
(m1a m2a m3a)1/3, with mia given by the second relation in (17.63).
</p>
<p>17.6.4 Crystals of Si, Ge, and GaAs
</p>
<p>Among semiconductors, silicon (Si), germanium (Ge), and gallium arsenide (GaAs)
are very important for the electronic industry. This section is devoted to illustrating
some properties of their crystal and energy-band structures. The crystals of silicon
and germanium are of the face-centered, cubic type; the reciprocal lattices have the
body-centered, cubic structure. The lattice constants, that is, the physical sizes of
the unit cell, are the same in the [100], [010], and [001] directions (Sect. 17.8.1).
Their values at T = 300 K are given in Table 17.1 [80]. The crystals of the materials
under consideration are formed by elementary blocks like that shown in Fig. 17.11.
Each atom has four electrons in the external shell, so that it can form four chemical
bonds with other identical atoms; the latter place themselves symmetrically in space,
to build up the tetrahedral structure shown in the figure. In this structure, which is
of the body-centered cubic type with a side equal to one half the lattice constant a,
the chemical bonds of the central atom are saturated, whereas the atoms placed at</p>
<p/>
</div>
<div class="page"><p/>
<p>328 17 Periodic Structures
</p>
<p>Fig. 17.11 Tetrahedral
organization of the
elementary, body-centered
cubic block of silicon or
germanium. The side of the
cube is one half the lattice
constant a
</p>
<p>/ 2a
</p>
<p>the vertices still have three bonds unsaturated; as a consequence, they may behave
as centers of new tetrahedral structures identical to the original one.
</p>
<p>An example of this is given in Fig. 17.12: the top half of the figure shows two
replicas of the elementary block of Fig. 17.11 sharing an atom belonging to an
upper corner, while the bottom half of the figure shows again two replicas, this time
sharing an atom belonging to a lower corner. The atoms drawn in white do not belong
to any of the elementary blocks considered in the figure, and serve the purpose of
demonstrating how the rest of the crystal is connected to them. Note that the structure
in the bottom half of Fig. 17.12 is identical to that of the top half, the difference being
simply that one structure is rotated by 90â¦ with respect to the other on a vertical axis.
The construction is now completed by bringing the two halves together, as shown
in Fig. 17.13; this provides the diamond structure mentioned in Sect. 17.2. Such a
structure is of the face-centered, cubic type, with an additional atom at the center of
each tetrahedral block.
</p>
<p>The minimum distance d among the atoms (interatomic distance) is the distance
from the atom in the center of the tetrahedral elementary block to any of the atoms
at its vertices; its relation with the lattice constant is easily found to be
</p>
<p>d =
&radic;
</p>
<p>3
</p>
<p>4
a. (17.75)
</p>
<p>The description is similar for gallium arsenide [80], and for a number of semicon-
ductors of the III-V type, whose crystal constants are listed in Table 17.2.
</p>
<p>17.6.5 Band Structure of Si, Ge, and GaAs
</p>
<p>Coming now to the description of the band structure, it is important to focus on the
bands that are able to contribute to the electric conduction of the material. In fact,
considering the aim of manufacturing electronic devices out of these materials, the</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 329
</p>
<p>Fig. 17.12 Diamond
structure. The top and bottom
halves are shown separately
</p>
<p>Fig. 17.13 Diamond
structure obtained by joining
together the top and bottom
halves shown separately in
Fig. 17.12
</p>
<p>a
</p>
<p>bands that do not contribute to the electric current are not relevant. It is intuitive
that a band with no electrons, that is, whose states have a zero probability of being
occupied, is not able to provide any conduction; it is less intuitive (in fact, this is
demonstrated in Sect. 19.3) that a band whose states are fully occupied does not
provide any conduction either. It follows that the only bands of interest are those</p>
<p/>
</div>
<div class="page"><p/>
<p>330 17 Periodic Structures
</p>
<p>Fig. 17.14 Calculation of the
particles&rsquo; population in the
conduction and valence bands
of a semiconductor. To make
them more visible, the
products g(E)P (E) and
g(E) [1 &minus; P (E)] have been
amplified with respect to g(E)
alone. The gap&rsquo;s extension is
arbitrary and does not refer to
any specific material
</p>
<p>-0.4 -0.2 0 0.2 0.4
(E - E
</p>
<p>F
) / (k
</p>
<p>B
 T)
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>P
(E
</p>
<p>)
[g
</p>
<p>(E
) 
</p>
<p>in
 a
</p>
<p>rb
it
</p>
<p>ra
ry
</p>
<p> u
n
it
</p>
<p>s]
</p>
<p>Fermi-Dirac statistic P(E)
g(E), conduction band
</p>
<p>g(E) P(E), cond. band
</p>
<p>g(E), valence band
</p>
<p>g(E) [1 - P(E)], val. band
</p>
<p>where only a fraction of the electronic states are occupied. Although a discussion
involving the electric current must necessarily refer to a non-equilibrium condition,
it is easier to base the reasoning upon the equilibrium condition at some temperature
T ; in fact, in this case the occupation probability of the electronic states is given
by the Fermi&ndash;Dirac statistics (15.49). As a consequence, the number of electrons
belonging to a band whose energy values range, say, from Ea to Eb, is given by the
first relation in (15.48) with Î± + Î² E = (E &minus; EF )/(kB T ), namely,
</p>
<p>Nab =
&int; Eb
</p>
<p>Ea
</p>
<p>g(E)
</p>
<p>exp [(E &minus; EF )/(kB T )] + 1
dE. (17.76)
</p>
<p>As mentioned in Sect. 17.6 each branch of the dispersion relation Ei(k) spans an
energy band. In many cases the bands are disjoint from each other, namely, energy
intervals exist that contain no eigenvalue of the Schr&ouml;dinger equation (17.40). Such
intervals are called forbidden bands or gaps. In the equilibrium condition the energy
of an electron can never belong to a gap, no matter what the value of the occupation
probability is, because the density of states is zero there. Also, at a given tempera-
ture the position of the Fermi level EF is either within a band (edges included), or
within a gap; the latter case, typical of semiconductors, is illustrated with the aid of
Fig. 17.14, where it is assumed (using the units of (E &minus; EF )/(kB T )) that a gap
exists between the energies EV , EC such that (EV &minus; EF )/(kB T ) = &minus;0.15 and
(EC &minus;EF )/(kB T ) = +0.15. In other terms, EV is the upper energy edge of a band,
and EC the lower energy edge of the next band. These assumptions also imply that
the Fermi level coincides with the gap&rsquo;s midpoint. As will become apparent below,
the two bands that are separated by the Fermi level are especially important; for this
reason they are given specific names: the band whose absolute maximum is EV is
called valence band, that whose absolute minimum is EC is called conduction band.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 331
</p>
<p>As shown in the figure, the case is considered (typical of Si, Ge, and GaAs) where
the gap&rsquo;s width contains the main variation of the Fermi&ndash;Dirac statistics;15 as a
consequence, the occupation probability becomes vanishingly small as the difference
E &minus; EC becomes larger, so that only the energy states near the absolute minimum
EC have a non-vanishing probability of being occupied. Thank to this reasoning, to
the purpose of calculating (17.76) one can replace the density of states g(E) with the
simplified expression (17.72) deduced from the parabolic-band approximation; such
an expression, g(E) &prop; &radic;E &minus; EC , is shown in Fig. 17.14 in arbitrary units, along
with the g(E)P (E) product (thick line), that represents the integrand of (17.76) with
reference to the conduction band. To make it more visible, the g(E)P (E) product is
drawn in a scale amplified by 103 with respect to that of g(E) alone. The number of
electrons belonging to the conduction band is proportional to the area subtended by
the g(E)P (E) curve.
</p>
<p>Coming now to the valence band, the probability 1 &minus; P (E) that a state at energy
E is empty becomes vanishingly small as the difference EV &minus; E becomes larger,
so that only the energy states near the absolute maximum EV have a non-vanishing
probability of being empty. Empty states are also called holes. The number of holes
is given by an integral similar to (17.76), where P (E) is replaced with 1 &minus; P (E).
This calculation is made easier by observing that, due to the form of the Fermi&ndash;Dirac
statistics, it is
</p>
<p>1 &minus; 1
exp [(E &minus; EF )/(kB T )] + 1
</p>
<p>= 1
exp [(EF &minus; E)/(kB T )] + 1
</p>
<p>. (17.77)
</p>
<p>Also in this case one can use for the density of states the parabolic-band approxi-
mation; such an expression, g(E) &prop; &radic;EV &minus; E, is shown in Fig. 17.14 in arbitrary
units, along with the g(E) [1 &minus; P (E)] product (thin line). As before, the product is
drawn in a scale amplified by 103 with respect to that of g(E) alone. The number
of holes belonging to the valence band is proportional to the area subtended by the
g(E) [1 &minus; P (E)] curve.
</p>
<p>Thanks to the spatial uniformity of the crystal, the concentration of the electrons
in the conduction band is obtained by dividing their number by the crystal volume
ï¿½ or, equivalently, by replacing the density of states in energy g with the combined
density of states in energy and volume Î³ given by (17.73). A similar reasoning holds
for holes. The explicit expressions of the concentrations are given in Sect. 18.3.
Here it is important to remark that the perfect symmetry of the curves g(E)P (E)
and g(E) [1 &minus; P (E)] in Fig. 17.14 is due to the simplifying assumptions that EF
coincides with the gap&rsquo;s midpoint and that MV m
</p>
<p>3/2
h = MC m
</p>
<p>3/2
e (compare with
</p>
<p>(17.73) and (17.74)). Neither hypothesis is actually true, so that in real cases the two
curves are not symmetric; however, as shown in Sect. 18.3, the areas subtended by
them are nevertheless equal to each other.
</p>
<p>15 The extension of the energy region where the main variation of the Fermi statistics occurs is
estimated in Prob. 15.1.</p>
<p/>
</div>
<div class="page"><p/>
<p>332 17 Periodic Structures
</p>
<p>Fig. 17.15 Schematic view of
the two branches of the
valence band of Si, Ge, or
GaAs in the [100] direction
</p>
<p>0
[100] direction
</p>
<p>0
</p>
<p>E
 (
</p>
<p>k 1
)
</p>
<p>Light holes
Heavy holes
</p>
<p>17.6.5.1 Valence Band
</p>
<p>The valence band of Si, Ge, and GaAs is made of two branches of E(k), having the
same absolute maximum EV at k = 0 (so that MV = 2), but different curvatures.
They are shown in Fig. 17.15, where the horizontal axis coincides with the [100]
direction in the k space, corresponding to the scalar variable k1. As a consequence,
the origin of the horizontal axis coincides with the Î point (Sect. 17.4); the axis
intersects the boundary of the first Brillouin zone at the X points (not shown in the
figure). The origin of the vertical axis coincides with EV . The two branches are not
spherically symmetric; in fact, letting EV = 0, the dependence of each of them on
the spherical coordinates k,Ï ,Ï has the form [54, Sect. 8.7]
</p>
<p>&minus;Î±
2
k2 [1 &plusmn; j (Ï ,Ï)] , Î± &gt; 0, (17.78)
</p>
<p>called warped. In the parabolic-band approximation the angular part j is neglected
with respect to unity, and the two branches become spherically symmetric around
k = 0; still with EV = 0, the dependence on k1 of each branch has the form
E = &minus;Î± k21/2, where the constant Î± is smaller in the upper branch (indicated by
the thick line in Fig. 17.15), and larger in the lower one. As a consequence, the
corresponding component of the effective-mass tensor (17.63), that reads in this
case m1 = hÌ2/Î±, is larger in the upper branch and smaller in the lower one. For this
reason, the holes associated to the energy states of the upper branch are called heavy
holes, those associated to the lower branch are called light holes.
</p>
<p>The analysis is identical in the other two directions [010] and [001] so that, for
each branch of the valence band, the diagonal entries of the effective-mass tensor
are equal to each other. Such tensors then read mhh I, mhl I, with I the identity
tensor; the first index of the scalar effective mass stands for &ldquo;hole&rdquo;, while the second
one stands for &ldquo;heavy&rdquo; or &ldquo;light&rdquo;. The second-order expansions around EV take</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 333
</p>
<p>Table 17.3 Normalized
effective masses of the
valence band of Si, Ge, and
GasAs
</p>
<p>Material mhh(Ta)/m0 mhl(Ta)/m0
</p>
<p>Si 0.5 0.16
</p>
<p>Ge 0.3 0.04
</p>
<p>GaAs 0.5 0.12
</p>
<p>respectively the form16
</p>
<p>EV &minus; Eh(k) =
hÌ2
</p>
<p>2mhh
</p>
<p>3
&sum;
</p>
<p>i=1
k2i , EV &minus; El(k) =
</p>
<p>hÌ2
</p>
<p>2mhl
</p>
<p>3
&sum;
</p>
<p>i=1
k2i . (17.79)
</p>
<p>Due to (17.79), the constant-energy surfaces EV &minus;Eh(k) = const and EV &minus;El(k) =
const are spheres, whose radius squared is 2mhh (EV &minus; Eh)/hÌ2 and 2mhl (EV &minus;
El)/hÌ2, respectively. The values of mhh and mhl at room temperature Ta are listed in
Table 17.3 [103, Sect. 2-3]; they are normalized to the rest mass of the free electron,
m0 â 9.11 &times; 10&minus;31 kg. The effective masses depend in general on temperature
because a change in the latter modifies the lattice constants: as a consequence, the
characteristic vectors of the reciprocal lattice change as well, this deforming the
dispersion relation E(k); on the other hand, the variation of the effective masses
with temperature is weak, so it is typically neglected.17
</p>
<p>17.6.5.2 Conduction Band
</p>
<p>The conduction band of Si, Ge, and GaAs has only one branch. However, the absolute
minima (also called valleys) are placed differently. In GaAs there is only one absolute
minimum at k = 0, with spherical symmetry. In the parabolic-band approximation,
the constant-energy surface is given by
</p>
<p>E(k) &minus; EC =
hÌ2
</p>
<p>2me
</p>
<p>3
&sum;
</p>
<p>i=1
k2i , (17.80)
</p>
<p>namely, a sphere whose radius squared is 2me (E&minus;EC)/hÌ2. The band exhibits also
secondary minima at EC +ÎE, with ÎE â 0.36 eV (Fig. 17.16).
</p>
<p>The conduction band of Si has six absolute minima (MC = 6), grouped into three
pairs. The latter belong to the [100], [010], and [001] directions, respectively, and
are symmetrically placed with respect to the Î point k = 0. Their coordinates are
</p>
<p>[100] : ( &plusmn; km, 0, 0), [010] : (0,&plusmn;km, 0), [001] : (0, 0,&plusmn;km), (17.81)
where km â 0.85 kB &gt; 0, with kB the distance between the Î and X points
(Fig. 17.17).
</p>
<p>16 From now on the band index n introduced in (17.56) is omitted from the notation.
17 In contrast, the temperature dependence of the energy gap, due to the deformation of the dispersion
relation, can not be neglected because of its strong effect on the carrier concentration (Sect. 18.3).</p>
<p/>
</div>
<div class="page"><p/>
<p>334 17 Periodic Structures
</p>
<p>Fig. 17.16 Schematic view of
the conduction band of GaAs
in the [100] direction
</p>
<p>0
[100] direction
</p>
<p>E
(k
</p>
<p>1
)
</p>
<p>Fig. 17.17 Schematic view of
the conduction band of Si in
the [100] direction
</p>
<p>0
[100] direction
</p>
<p>E
 (
</p>
<p>k 1
)
</p>
<p>In the parabolic-band approximation, the surfaces at constant energy of the con-
duction band of Si are ellipsoids of revolution about the [100], [010], or [001] axes.
Their expressions are
</p>
<p>[100] : Ee1 = E(k) &minus; EC =
hÌ2
</p>
<p>2
</p>
<p>[
(k1 &minus; km)2
</p>
<p>ml
+ k
</p>
<p>2
2
</p>
<p>mt
+ k
</p>
<p>2
3
</p>
<p>mt
</p>
<p>]
</p>
<p>, (17.82)
</p>
<p>[010] : Ee2 = E(k) &minus; EC =
hÌ2
</p>
<p>2
</p>
<p>[
k21
</p>
<p>mt
+ (k2 &minus; km)
</p>
<p>2
</p>
<p>ml
+ k
</p>
<p>2
3
</p>
<p>mt
</p>
<p>]
</p>
<p>, (17.83)
</p>
<p>[001] : Ee3 = E(k) &minus; EC =
hÌ2
</p>
<p>2
</p>
<p>[
k21
</p>
<p>mt
+ k
</p>
<p>2
2
</p>
<p>mt
+ (k3 &minus; km)
</p>
<p>2
</p>
<p>ml
</p>
<p>]
</p>
<p>. (17.84)
</p>
<p>Similarly, Ee4, Ee5, Ee6 are derived from Ee1, Ee2, Ee3, respectively, by letting
km &larr; &minus;km. The effective masses ml and mt are called longitudinal and transverse
mass, respectively.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 335
</p>
<p>Fig. 17.18 Schematic view of
the conduction band of Ge in
the [100] direction.
</p>
<p>0
[100] direction
</p>
<p>0
</p>
<p>E
(k
</p>
<p>1
)
</p>
<p>Table 17.4 Normalized
effective masses of the
conduction band of Si, Ge,
and GasAs
</p>
<p>Material ml(Ta)/m0 mt (Ta)/m0
</p>
<p>Si 0.97 0.19
</p>
<p>Ge 1.6 0.082
</p>
<p>GaAsa 0.068 0.068
</p>
<p>aThe effective masses of GaAs are equal to each
other due to the band&rsquo;s isotropy
</p>
<p>The conduction band of Ge has eight absolute minima, grouped into four pairs.
The pairs belong to the four {111} directions and are placed at the boundary of the first
Brillouin zone (Fig. 17.18); thus, only four absolute minima must be accounted for
(MC = 4). In the parabolic-band approximation, the surfaces at constant energy of
the conduction band of Ge are ellipsoids of revolution about the corresponding axis;
like in silicon, for each ellipsoid the longitudinal mass corresponds to the direction
of the axis itself, while the transverse masses correspond to the directions normal to
it. The values of ml and mt at room temperature Ta , normalized to the rest mass of
the free electron, are listed in Table 17.4 [103, Sect. 2-3].
</p>
<p>17.6.6 Further Comments About the Band Structure
</p>
<p>As better detailed in Sects. 19.5.2 and 19.5.3, among the coefficients of the equations
describing the transport phenomena in a semiconductor are the electron and hole
mobilities, that enter the relation between current density and electric field in a
uniform material. For the conduction band of the semiconductors considered here,
and in the parabolic-band approximation, the electron mobility Î¼n turns out to be
proportional to 1/mn = (2/mt + 1/ml)/3, that is, a weighed average of the entries</p>
<p/>
</div>
<div class="page"><p/>
<p>336 17 Periodic Structures
</p>
<p>of the inverse, effective-mass tensor.18 Table 17.4 shows that GaAs has the largest
value of 1/mn; thus, it is expected to have the largest mobility, which is indeed the
case. As far as holes are concerned, the effective masses of heavy holes of Si, Ge, and
GaAs are similar to each other; also the effective masses of light holes have the same
order of magnitude. Besides, considering that the valence band has two branches of
E(k), the effective masses do not combine in the simple way as for the conduction
band.
</p>
<p>The secondary minima of GaAs, placed at an energyEC+ÎE withÎE â 0.36 eV
(Fig. 17.16), have a larger effective mass than the absolute minimum; due to this,
the mobility of the electrons in the upper valleys is smaller than that of the electrons
populating the absolute minimum. As ÎE is relatively small, the population of the
secondary minima is not negligible; in a non-equilibrium condition, the scattering
events tend increase the electron population of the upper valleys at the expense of that
of the absolute minimum, with a ratio between the upper and lower population that
depends on the applied electric field. This gives rise to a negative differential resis-
tivity in the current-to-voltage curve of the material, i.e., an operating region exists
where the current density decreases as the electric field increases. The phenomenon
is called Ridley&ndash;Watkins&ndash;Hilsum mechanism [103, Sect. 14-3].
</p>
<p>In semiconductors, the absorption of energy from an electromagnetic field may
induce the transition of an electron from a state belonging to the valence band to
a state belonging to the conduction band. Such a transition increases by one the
number of electrons in the conduction band and, at the same time, increases by one
the number of holes in the valence band; for this reason it is called generation of an
electron-hole pair. The opposite phenomenon may also occur, namely, a release of
electromagnetic energy due the transition of an electron from a state belonging to the
conduction band to a state belonging to the valence band. Such a transition decreases
by one the number of electrons in the conduction band and, at the same time, decreases
by one the number of holes in the valence band (recombination of an electron-hole
pair). It is worth pointing out that generation and recombination events may also
occur with an energy absorption from, or release to, an external agent different from
the electromagnetic field (e.g., the agent could be a vibrational mode of the lattice);
for this reason, the phenomena considered here are better specified as generations-
recombinations of the radiative type. In GaAs, the minimum of the conduction band
and the maxima of the two branches of the valence band correspond to the same value
of k; semiconductors fulfilling this condition are called direct-gap semiconductors.
Instead, Si and Ge are indirect-gap semiconductors, because the maxima of the
valence band correspond to k = 0, whereas the minima of the conduction band
correspond to k ï¿½= 0. Direct- and indirect-gap semiconductors behave differently as
far as generations-recombinations of the radiative type are concerned; in fact, the
probability of such events is much higher in direct-gap semiconductors. This explains
</p>
<p>18 If the magnitudes of mt and ml are significantly different, the smaller effective mass dictates the
magnitude of mn.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 337
</p>
<p>why some classes of solid-state optical devices like, e.g., lasers, are manufactured
using direct-gap semiconductors.19
</p>
<p>17.6.7 Subbands
</p>
<p>The calculations of the density of states carried out so far have been based on the
assumption that all components of the k vector can be treated as continuous variables.
In particular, the adoption of the parabolic-band approximation in the case of a
periodic lattice (Sect. 17.6) leads to expressions for the density of states g(E) and
combined density of states Î³ (E) that are formally identical to those obtained for a
particle in a three-dimensional box (Sect. 15.9.2). However, in some situations it
happens that not all components of k may be treated as continuous. To describe this
case it is convenient to use the example of the box first; that of the periodic lattice is
worked out later, in the frame of the parabolic-band approximation.
</p>
<p>To proceed, consider like in Sect. 15.9.2 a three-dimensional box whose sides have
lengths d1, d2, d3, so that the eigenvalues of the Schr&ouml;dinger equation are En1n2n3 =
hÌ2k2/(2m), where k2 is the square of
</p>
<p>k = n1
Ï
</p>
<p>d1
i1 + n2
</p>
<p>Ï
</p>
<p>d2
i2 + n3
</p>
<p>Ï
</p>
<p>d3
i3, ni = 1, 2, . . . (17.85)
</p>
<p>The distance between two consecutive projections of k along the ith side is Îki =
Ï/di , and the volume associated to each k is Îk1 Îk2 Îk3 = Ï3/V , with V =
d1 d2 d3 the volume of the box in the r space. The density of the k vectors in the k
space is Qk = V/Ï3.
</p>
<p>17.6.7.1 Two-Dimensional Layer
</p>
<p>Now, in contrast to what was implicitly assumed in Sect. 15.9.2, let one side of the
box be much different from the others, for instance, d2 &sim; d1, d3 âª d1, d2. It follows
that Îk3 â« Îk1,Îk2. If the magnitudes involved are such that k1, k2 may still be
considered continuous variables, while k3 can not, one must calculate the density of
states by treating k1, k2 differently from k3. Considering k1 = n1 Ï/d1, k2 = n2 Ï/d2
as continuous, fix E and s in the relations
</p>
<p>2m
</p>
<p>hÌ2
E = k21 + k22 + n23
</p>
<p>Ï2
</p>
<p>d23
, n3 = s &lt;
</p>
<p>d3
</p>
<p>Ï
</p>
<p>&radic;
2mE
</p>
<p>hÌ
. (17.86)
</p>
<p>19 The reasoning seems to contradict the fact the large-area, solid-state optical sensors used in
cameras and video cameras, based on the CCD or CMOS architecture, are made of silicon. In fact,
the complex structure of these several-megapixel sensors and related signal-management circuitry
can be realized only with the much more advanced technology of silicon. The relative ease of
fabricating complex structures largely compensates for the poorer optical properties of the material.</p>
<p/>
</div>
<div class="page"><p/>
<p>338 17 Periodic Structures
</p>
<p>For each integer s = 1, 2, . . . the two relations (17.86) determine in the k1, k2 plane
a circumference of radius cs =
</p>
<p>&radic;
</p>
<p>c2s , with
</p>
<p>c2s = k21 + k22 , c2s =
2mE
</p>
<p>hÌ2
&minus; s2 Ï
</p>
<p>2
</p>
<p>d23
. (17.87)
</p>
<p>It is minscs &gt; 0 because smax &lt; d3
&radic;
</p>
<p>2mE/(Ï hÌ), and maxscs = c1 &gt; 0. For a fixed
s the states are distributed over the circumference of radius cs : such a set of states is
also called subband.
</p>
<p>The density of states in energy of the subband thus defined is calculated following
the same reasoning as in Sect. 15.9.3: in fact, one observes that the density of k
vectors in the two-dimensional space k1, k2 is d1d2/Ï2, namely, the inverse of the
area Ï2/(d1d2) associated to each k belonging to the given circumference. Then, the
total number of k vectors in a circle of radius cs is
</p>
<p>Nks =
d1 d2
</p>
<p>Ï2
Ï c2s =
</p>
<p>d1 d2
</p>
<p>Ï
</p>
<p>(
2mE
</p>
<p>hÌ2
&minus; s2 Ï
</p>
<p>2
</p>
<p>d23
</p>
<p>)
</p>
<p>. (17.88)
</p>
<p>Remembering that indices n1, n2 are positive, it is necessary to consider only the
first quadrant; as a consequence, Nks must be divided by 4. Further, it is necessary
to multiply it by 2 to account for electron spin. In conclusion, the density of states
of the two-dimensional subbands is
</p>
<p>g2D(E) =
d(2Nks/4)
</p>
<p>dE
= d1 d2m
</p>
<p>Ï hÌ2
= const, (17.89)
</p>
<p>to be compared with (15.67). Note that (17.89) is independent of index s. This result
is useful, e.g., for treating the problem of a two-dimensional charge layer in the
channel of a semiconductor device.
</p>
<p>17.6.7.2 Wire
</p>
<p>Now, assume that d2 &sim; d3, and d2, d3 âª d1. It follows that Îk2,Îk3 â« Îk1. If the
magnitudes involved are such that k1 may still be considered a continuous variable,
while k2, k3 can not, one must calculate the density of states by treating k1 differently
from k2, k3. Considering k1 = n1Ï/d1 as continuous, fix E, r , s in the relations
</p>
<p>2m
</p>
<p>hÌ2
E = k21 + n22
</p>
<p>Ï2
</p>
<p>d22
+ n23
</p>
<p>Ï2
</p>
<p>d23
, n2 = r , n3 = s, (17.90)
</p>
<p>with r2/d22 + s2/d23 &le; 2mE/(Ï2 hÌ2). For each pair of integers r , s = 1, 2, . . . ,
(17.90) determine in the k space two points given by the relation
</p>
<p>Îº2rs =
2mE
</p>
<p>hÌ2
&minus; r
</p>
<p>2 Ï2
</p>
<p>d22
&minus; s
</p>
<p>2 Ï2
</p>
<p>d23
, Îºrs =
</p>
<p>&radic;
</p>
<p>Îº2rs . (17.91)</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 339
</p>
<p>It is minrsÎºrs &gt; 0 and maxrsÎºrs = Îº11. For a fixed pair r , s the states are placed at
the ends of the segment [ &minus; Îºrs ,+Îºrs] parallel to k1. The density of states in energy
of such a segment is calculated following the same reasoning as in Sect. 15.9.3: in
fact, one observes that the density of k vectors in the one-dimensional space k1 is
d1/Ï , namely, the inverse of the length Ï/d1 associated to each k belonging to the
segment. Then, the total number of k vectors in the segment of length 2 Îºrs is
</p>
<p>Nkrs =
d1
</p>
<p>Ï
2Îºrs =
</p>
<p>2d1
Ï
</p>
<p>(
2mE
</p>
<p>hÌ2
&minus; r2 Ï
</p>
<p>2
</p>
<p>d22
&minus; s2 Ï
</p>
<p>2
</p>
<p>d23
</p>
<p>)1/2
</p>
<p>. (17.92)
</p>
<p>Remembering that index n1 is non negative, it is necessary to consider only the
positive half of the segment. As a consequence, Nkrs must be divided by 2. Further,
it is necessary to multiply it by 2 to account for electron spin. The density of states
of the one-dimensional case then reads
</p>
<p>g1D(E) =
d(2Nkrs/2)
</p>
<p>dE
= 2d1m
</p>
<p>Ï hÌ2 Îºrs
, (17.93)
</p>
<p>to be compared with (15.69). Note that, in contrast with the two-dimensional case
(17.89), here the result depends on both indices r , s. A device with d2, d3 âª d1 is
also called wire. When the device size is such that the transport of a particle in it
must be studied by means of Quantum Mechanics, it is also called quantum wire.
The E(Îºrs) relation may be recast as
</p>
<p>hÌ2
</p>
<p>2m
Îº2rs = E &minus; Ers , Ers =
</p>
<p>Ï2 hÌ2
</p>
<p>2m
</p>
<p>(
r2
</p>
<p>d22
+ s
</p>
<p>2
</p>
<p>d23
</p>
<p>)
</p>
<p>. (17.94)
</p>
<p>As Ers is an increasing function of the indices, its minimum is attained for r = s = 1
and represents the ground state in the variables k2, k3. It is interesting to note that,
if the total energy E is prescribed, e.g., by injecting the particle from an external
source, such that E11 &lt; E &lt; min(E12,E21), then the particle&rsquo;s wave function has
the form
</p>
<p>Ï =
&radic;
</p>
<p>8
</p>
<p>V
sin (Îº11 x1) sin (Ï x2/d2) sin (Ï x3/d3) exp ( &minus; iE t/hÌ) (17.95)
</p>
<p>(compare with (15.60)). Remembering the expression (15.64) of the density of states
in a box where d1 &sim; d2 &sim; d3, the results obtained so far are summarized as:
</p>
<p>g3D(E) =
V
&radic;
</p>
<p>2m3 E
</p>
<p>Ï2 hÌ3
, g2D(E) =
</p>
<p>d1 d2 m
</p>
<p>Ï hÌ2
, g1D(E) =
</p>
<p>d1
&radic;
</p>
<p>2m
</p>
<p>Ï hÌ
&radic;
E &minus; Ers
</p>
<p>.
</p>
<p>(17.96)
</p>
<p>17.6.8 Subbands in a Periodic Lattice
</p>
<p>The calculations leading to (17.96) consider the case of a box within which the
potential energy is zero (as a consequence, the total energy E is purely kinetic),</p>
<p/>
</div>
<div class="page"><p/>
<p>340 17 Periodic Structures
</p>
<p>and prescribe a vanishing wave function at the boundaries. If a periodic lattice is
present, with the provisions indicated in Sect. 17.5.3 one can apply the periodic
boundary conditions. In this case, the spacing between the components of k in each
direction doubles (ni Ï/di &larr; 2 ni Ï/di), but the number of components doubles
as well (ni = 1, 2, . . . &larr; ni = 0,&plusmn;1,&plusmn;2, . . . ), so the density of states remains the
same. In a semiconductor the calculation leading to the density of states is made more
complicated by the presence of the lattice. However, the analysis may be brought
to a simple generalization of that carried out in a box by means of the following
simplifications:
</p>
<p>&bull; It is assumed that a band structure exists even if the size of the device is small
in one or two spatial directions. In fact, it can be shown that the presence of a
number of atomic planes of the order of ten is sufficient to form a band structure.
</p>
<p>&bull; The analysis is limited to the case of parabolic bands.
</p>
<p>The case of the conduction band of silicon is considered by way of example, with the
k1, k2, k3 axes placed along the [100], [010], [001] directions. The parabolic-band
approximation yields for the kinetic energies Ee1, Ee2, Ee3 &ge; 0 the expressions
given in (17.82, 17.83, 17.84); the other three kinetic energies Ee4, Ee5, Ee6 are
derived from Ee1, Ee2, Ee3, respectively, by letting km &larr; &minus;km. Apart from the
constant EC , the energies Ee1,Ee2, . . . are simplified forms of the eigenvalues of
the Schr&ouml;dinger equation (17.40). Conversely, to the purpose of determining the
corresponding eigenfunctions, one may view Ee1,Ee2, . . . as the exact eigenvalues
of simplified forms of the original Hamiltonian operator (17.40), that hold near the
band&rsquo;s minima; such simplified forms are expected to be of the purely kinetic type.
They are found by replacing ki with &minus;i d/dxi in (17.82, 17.83, 17.84), this yielding
</p>
<p>[100] : He1 =
hÌ2
</p>
<p>2
</p>
<p>[
</p>
<p>+ 1
ml
</p>
<p>(
</p>
<p>i
&part;
</p>
<p>&part;x1
+ km
</p>
<p>)2
</p>
<p>&minus; 1
mt
</p>
<p>&part;2
</p>
<p>&part;x22
&minus; 1
</p>
<p>mt
</p>
<p>&part;2
</p>
<p>&part;x23
</p>
<p>]
</p>
<p>, (17.97)
</p>
<p>[010] : He2 =
hÌ2
</p>
<p>2
</p>
<p>[
</p>
<p>&minus; 1
mt
</p>
<p>&part;2
</p>
<p>&part;x21
+ 1
</p>
<p>ml
</p>
<p>(
</p>
<p>i
&part;
</p>
<p>&part;x2
+ km
</p>
<p>)2
</p>
<p>&minus; 1
mt
</p>
<p>&part;2
</p>
<p>&part;x23
</p>
<p>]
</p>
<p>, (17.98)
</p>
<p>[001] : He3 =
hÌ2
</p>
<p>2
</p>
<p>[
</p>
<p>&minus; 1
mt
</p>
<p>&part;2
</p>
<p>&part;x21
&minus; 1
</p>
<p>mt
</p>
<p>&part;2
</p>
<p>&part;x22
+ 1
</p>
<p>ml
</p>
<p>(
</p>
<p>i
&part;
</p>
<p>&part;x3
+ km
</p>
<p>)2
]
</p>
<p>, (17.99)
</p>
<p>with ml and mt the longitudinal and transverse masses. Considering He1 first, the
solution of the time-independent Schr&ouml;dinger equation generated by it,
</p>
<p>He1w1(r, n1, n2, n3) = E(n1, n2, n3) w1(r, n1, n2, n3), (17.100)
</p>
<p>is found by separation, specifically, by letting E = EÎ±(n1)+EÎ²(n2)+EÎ³ (n3), w1 =
exp (i km x1)Î±(x1, n1)Î²(x2, n2) Î³ (x3, n3). One finds for the k vector the expression
</p>
<p>k = n1
Ï
</p>
<p>d1
i1 + n2
</p>
<p>Ï
</p>
<p>d2
i2 + n3
</p>
<p>Ï
</p>
<p>d3
i3, (17.101)</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 341
</p>
<p>with ni = 1, 2, . . . , while the eigenfunctions and eigenvalues read
</p>
<p>w1 =
&radic;
</p>
<p>8
</p>
<p>V
exp (i km x1) sin
</p>
<p>(
n1 Ï
</p>
<p>d1
x1
</p>
<p>)
</p>
<p>sin
</p>
<p>(
n2 Ï
</p>
<p>d2
x2
</p>
<p>)
</p>
<p>sin
</p>
<p>(
n3 Ï
</p>
<p>d3
x3
</p>
<p>)
</p>
<p>, (17.102)
</p>
<p>E = hÌ
2
</p>
<p>2ml
n21
</p>
<p>Ï2
</p>
<p>d21
+ hÌ
</p>
<p>2
</p>
<p>2mt
n22
</p>
<p>Ï2
</p>
<p>d22
+ hÌ
</p>
<p>2
</p>
<p>2mt
n23
</p>
<p>Ï2
</p>
<p>d23
. (17.103)
</p>
<p>The eigenvalues and eigenfunctions of He2, He3 are found by a cyclic permutation
of the indices, 1 &larr; 2 &larr; 3 &larr; 1, while those of He4, He5, He6 are derived from
those of He1, He2, He3, respectively, by letting km &larr; &minus;km.
</p>
<p>One notes that the k vectors and the eigenfunctions are not influenced by the
effective masses, whereas the eigenvalues are. As a consequence, the density of
states is affected as well. In the case where d1 &sim; d2 &sim; d3 the density of states
associated to the minimum of index 1 is found by the same procedure as that leading
to the first relation in (17.96); the result is
</p>
<p>g
(1)
3D(E) =
</p>
<p>d1 d2 d3
&radic;
</p>
<p>2ml m2t
Ï2 hÌ3
</p>
<p>&radic;
E. (17.104)
</p>
<p>Such a density of states is not affected by interchanging the effective masses; thus,
the total density of states is found by adding over the densities of states of the MC
minima of the conduction band:
</p>
<p>g3D(E) = MC
d1 d2 d3
</p>
<p>&radic;
</p>
<p>2ml m2t
Ï2 hÌ3
</p>
<p>&radic;
E. (17.105)
</p>
<p>As in the case of a box, the distance between two consecutive projections of k along
the ith side is Îki = Ï/di , and the volume associated to each k is Îk1 Îk2 Îk3 =
Ï3/V , with V = d1d2d3. The density of the k vectors in the k space is Qk = V/Ï3.
</p>
<p>Consider now the case of a two-dimensional layer, namely, d2 &sim; d1, while
d3 âª d1, d2. Let k1 = n1Ï/d1, k2 = n2Ï/d2, and fix n3 = 1 whence, for the
minima of indices 1 and 4,
</p>
<p>E = hÌ
2
</p>
<p>2ml
k21 +
</p>
<p>hÌ2
</p>
<p>2mt
k22 +
</p>
<p>hÌ2
</p>
<p>2mt
</p>
<p>Ï2
</p>
<p>d23
, E &ge; hÌ
</p>
<p>2
</p>
<p>2mt
</p>
<p>Ï2
</p>
<p>d23
. (17.106)
</p>
<p>A calculation similar to that carried out in a box provides, for the minima of indices
1 and 4, an expression similar to that of the second relation in (17.96):
</p>
<p>g
(1)
2D = g(4)2D =
</p>
<p>d1 d2
&radic;
ml mt
</p>
<p>Ï hÌ2
. (17.107)
</p>
<p>For the other pairs of minima one finds
</p>
<p>g
(2)
2D = g(5)2D =
</p>
<p>d1 d2
&radic;
ml mt
</p>
<p>Ï hÌ2
, g(3)2D = g(6)2D =
</p>
<p>d1 d2 mt
</p>
<p>Ï hÌ2
. (17.108)</p>
<p/>
</div>
<div class="page"><p/>
<p>342 17 Periodic Structures
</p>
<p>Fig. 17.19 Normalized,
two-dimensional density of
states (17.109) for the
1, 2, 4, 5 valleys of silicon, as
a function of E/Et , in the
parabolic-band approximation
</p>
<p>0 5 10 15 20 25
E / E
</p>
<p>t
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>g
2
D
</p>
<p> /
 g
</p>
<p>2
D
</p>
<p>(n
3
=
</p>
<p>1
) 
</p>
<p>[v
al
</p>
<p>le
y
s 
</p>
<p>n
o
. 
1
,2
</p>
<p>,4
,5
</p>
<p>]
</p>
<p>In conclusion, for a two-dimensional layer with d3 âª d1, d2 and n3 = 1, within the
parabolic-band approximation, the density of states for the minima of indices 1, 2,
4, and 5 is the same constant for all energies E &ge; hÌ2 Ï2/(2mt d23 ). The total density
of states for these minima is
</p>
<p>g
(1,2,4,5)
2D = 4
</p>
<p>d1 d2
&radic;
ml mt
</p>
<p>Ï hÌ2
. E &ge; Et =
</p>
<p>hÌ2 Ï2
</p>
<p>2mt d23
, n3 = 1, (17.109)
</p>
<p>while g(1,2,4,5)2D,n3=1 = 0 for E &lt; Et . Similarly, still with n3 = 1, the density of states for
the minima of indices 3 and 6 is another constant for all energiesE &ge; hÌ2 Ï2/(2ml d23 ).
The total density of states for these minima is
</p>
<p>g
(3,6)
2D = 2
</p>
<p>d1 d2 mt
</p>
<p>Ï hÌ2
, E &ge; El =
</p>
<p>hÌ2 Ï2
</p>
<p>2ml d23
, n3 = 1, (17.110)
</p>
<p>while g(3,6)2D,n3=1 = 0 for E &lt; El . Now, let n3 = 2; it is easily found that the value of
g
</p>
<p>(1,2,4,5)
2D,n3=2 is the same as above, however, it holds for E &ge; 4Et . It adds up to the value
</p>
<p>found for n3 = 1, giving rise to a stair-like form of g(1,2,4,5)2D as a function of energy.
The same is obtained for g(3,6)2D,n3=2 when E &ge; 4El , and so on. An example of such a
density of states is sketched in Fig. 17.19, where the ratio g(1,2,4,5)2D /g
</p>
<p>(1,2,4,5)
2D,n3=1 is shown
</p>
<p>as a function of E/Et . The total density of states is found by adding up the two
stair-like functions. From Table 17.4 one finds that in silicon at room temperature it
is ml â 0.97m0, mt â 0.19m0, whence Et â 5.1El and g(1,2,4,5)2D,n3=1 â 4.47 g
</p>
<p>(3,6)
2D,n3=1.
</p>
<p>As shown by Fig. 17.19, the derivative of the density of states with respect to
energy diverges at some points. Such divergences are called Van Hove singularities
[2, Chap. 8].</p>
<p/>
</div>
<div class="page"><p/>
<p>17.6 Schr&ouml;dinger Equation in a Periodic Lattice 343
</p>
<p>Finally, consider the case of a wire, namely, d2 &sim; d3, while d2, d3 âª d1. Let
k1 = n1Ï/d1 and fix n2 = n3 = 1 whence, for the minima of indices 1 and 4,
</p>
<p>E = hÌ
2
</p>
<p>2ml
k21 +
</p>
<p>hÌ2
</p>
<p>2mt
</p>
<p>Ï2
</p>
<p>d22
+ hÌ
</p>
<p>2
</p>
<p>2mt
</p>
<p>Ï2
</p>
<p>d23
, E &ge; Ï
</p>
<p>2 hÌ2
</p>
<p>2mt
</p>
<p>(
1
</p>
<p>d22
+ 1
</p>
<p>d23
</p>
<p>)
</p>
<p>= E(1,4)11 .
(17.111)
</p>
<p>A calculation similar to that carried out in a box provides, for the minima of indices
1 and 4, an expression similar to that of the third relation in (17.96):
</p>
<p>g
(1)
1D = g(4)1D =
</p>
<p>2 d1 ml
</p>
<p>Ï hÌ2 Îº
(1,4)
11
</p>
<p>= d1
&radic;
</p>
<p>2ml
</p>
<p>Ï hÌ
</p>
<p>&radic;
</p>
<p>E &minus; E(1,4)11
, (17.112)
</p>
<p>while g(1,4)1D = 0 if E &lt; E(1,4)11 . For the other minima one finds
</p>
<p>g
(2,5)
1D =
</p>
<p>d1
&radic;
</p>
<p>2mt
</p>
<p>Ï hÌ
</p>
<p>&radic;
</p>
<p>E &minus; E(2,5)11
, E &ge; E(2,5)11 =
</p>
<p>Ï2 hÌ2
</p>
<p>2
</p>
<p>(
1
</p>
<p>ml d
2
2
</p>
<p>+ 1
mt d
</p>
<p>2
3
</p>
<p>)
</p>
<p>,
</p>
<p>(17.113)
</p>
<p>with g(2,5)1D = 0 if E &lt; E(2,5)11 , and
</p>
<p>g
(3,6)
1D =
</p>
<p>d1
&radic;
</p>
<p>2mt
</p>
<p>Ï hÌ
</p>
<p>&radic;
</p>
<p>E &minus; E(3,6)11
, E &ge; E(3,6)11 =
</p>
<p>Ï2 hÌ2
</p>
<p>2
</p>
<p>(
1
</p>
<p>mt d
2
2
</p>
<p>+ 1
ml d
</p>
<p>2
3
</p>
<p>)
</p>
<p>,
</p>
<p>(17.114)
</p>
<p>with g(3,6)1D = 0 if E &lt; E(3,6)11 . In conclusion, for a wire with d2, d3 âª d1 and
n2 = n3 = 1, within the parabolic-band approximation, the density of states of each
pair of minima is the sum of expressions of the form (17.112, 17.113, 17.114); the
latter are complicate because all possible pairs of indices r , s combine with the two
lengths d2, d3, that in general are not commensurable with each other. A somewhat
easier description is obtained by considering (17.112) alone and letting d2 = d3 in
it; this yields E21 = E12 = 2.5E11, E22 = 4E11, E31 = E13 = 5E11, and so on,
and
</p>
<p>g
(1,4)
1D =
</p>
<p>g
(1,4)
1D (E = 2E11)&radic;
</p>
<p>E/E11 &minus; 1
, E11 &lt; E &le; E21. (17.115)
</p>
<p>In the next interval E21 &lt; E &le; E22, the density of states is the sum of (17.115)
and 2/
</p>
<p>&radic;
E/E11 &minus; 2.5, where factor 2 accounts for the (r = 2, s = 1), (r = 1, s =
</p>
<p>2) degeneracy; in the interval E22 &lt; E &le; E31 one adds the further summand
1/
&radic;
E/E11 &minus; 4, and so on. The normalized density of states g1D(E)/g1D(2E11) is
</p>
<p>shown in Fig. 17.20 as a function of E/E11.</p>
<p/>
</div>
<div class="page"><p/>
<p>344 17 Periodic Structures
</p>
<p>Fig. 17.20 Normalized,
one-dimensional density of
states for the 1, 4 valleys of
silicon, as a function of
E/E11, in the parabolic-band
approximation and with
d2 = d3
</p>
<p>0 1 2 3 4 5
E / E
</p>
<p>11
</p>
<p>0
</p>
<p>5
</p>
<p>10
</p>
<p>15
</p>
<p>20
</p>
<p>25
</p>
<p>g
1
</p>
<p>D
 /
</p>
<p> g
1
</p>
<p>D
 (
</p>
<p>2
E
</p>
<p>1
1
) 
</p>
<p> [
v
al
</p>
<p>le
y
s 
</p>
<p>n
o
. 
1
,4
</p>
<p>]
</p>
<p>Also in this case the Van Hove singularities are present; in addition, the density
of states itself diverges at such points. However, such divergences are integrable;
consider for instance an integral of the form
</p>
<p>&int; &infin;
</p>
<p>E0
</p>
<p>c&radic;
E &minus; E0
</p>
<p>P (E) dE, (17.116)
</p>
<p>with c a constant and 0 &lt; P &lt; 1 a distribution function. Splitting the integration
domain into two intervals E0 &le; E &le; E&prime; and E&prime; &le; E &lt; &infin;, with E&prime; &gt; E0, one finds
for the first integral, that contains the singularity,
</p>
<p>&int; E&prime;
</p>
<p>E0
</p>
<p>c&radic;
E &minus; E0
</p>
<p>P (E) dE &le;
&int; E&prime;
</p>
<p>E0
</p>
<p>c&radic;
E &minus; E0
</p>
<p>dE &lt; &infin;. (17.117)
</p>
<p>17.7 Calculation of Vibrational Spectra
</p>
<p>The discussion carried out in Sect. 16.6 has led to the conclusion that in the case
of solid matter the nuclei, being massive and tightly bound together, are expected
to depart little from their equilibrium positions R0. The classical description of the
nuclear motion is thus brought to the case already solved in Sects. 3.9 and 3.10: the
vibrational state of the nuclei is described in terms of the normal coordinates bÏ ,
whose conjugate moments are bÌÏ , and the total energy of the nuclei reads (compare
with (3.50))
</p>
<p>Ta + Va =
3N
&sum;
</p>
<p>Ï=1
HÏ + Va0, HÏ =
</p>
<p>1
</p>
<p>2
bÌ2Ï +
</p>
<p>1
</p>
<p>2
Ï2Ï b
</p>
<p>2
Ï , (17.118)
</p>
<p>where each HÏ corresponds to one degree of freedom and ÏÏ &gt; 0 is the angular
frequency of the corresponding mode. The system is completely separable in the</p>
<p/>
</div>
<div class="page"><p/>
<p>17.7 Calculation of Vibrational Spectra 345
</p>
<p>Fig. 17.21 Definition of the
labels used to identify the
degrees of freedom in a
periodic lattice
</p>
<p>ln
</p>
<p>mÎ±s
</p>
<p>nÎ±0s
lm
</p>
<p>e Î±
</p>
<p>O
</p>
<p>h
</p>
<p>normal coordinates, and each normal coordinate evolves in time as a linear harmonic
oscillator. The calculation is based on Classical Mechanics; it is carried out in this
chapter because it exploits the periodicity properties of the material and, in this
respect, presents several analogies with the solution of the Schr&ouml;dinger equation in a
periodic lattice. To determine the vibrational frequencies ÏÏ it is necessary to solve
the eigenvalue equation (3.43), namely,
</p>
<p>C gÏ = Ï2Ï M gÏ , Ï = 1, . . . , 3N , (17.119)
</p>
<p>with gÏ the eigenvectors. The entries of C, M are given by
</p>
<p>ckn = [C]kn =
(
</p>
<p>&part;2Va
</p>
<p>&part;hk &part;hn
</p>
<p>)
</p>
<p>0
</p>
<p>, [M]kn = Î¼n Î´kn, (17.120)
</p>
<p>where Va is the potential energy, hk the displacement of the kth degree of freedom
with respect to the equilibrium position, Î¼k the mass associated to the kth degree of
freedom, and Î´kn the Kronecker delta.
</p>
<p>The calculation is in principle the same for any system of particles; however, if
the system has special properties, they reflect into the form of the eigenvalues and
eigenvectors. A particularly important case is that of a periodic structure, such as a
crystal. Considering this case, let the crystal be made of Nc elementary cells, with a
basis made of Nb nuclei (the definition of basis is in Sect. 17.2). It follows that the
total number of nuclei is N = Nb Nc, and the total number of degrees of freedom
is 3N . With respect to a given origin O (Fig. 17.21), the mth cell of the lattice is
identified by the corresponding translation vector of the direct lattice, lm; the latter
determines a local origin within the mth cell. In turn, the equilibrium position of the
Î±th nucleus of the mth cell with respect to the local origin is identified by a vector
eÎ± of the direct lattice.</p>
<p/>
</div>
<div class="page"><p/>
<p>346 17 Periodic Structures
</p>
<p>17.7.1 Labeling the Degrees of Freedom&mdash; Dynamic Matrix
</p>
<p>To proceed, it is convenient to label the degrees of freedom in such a way as to
distinguish the indices of the cells from those of the basis and of the coordinate axes.
To this purpose, one observes that the component along the uth coordinate axis of
the equilibrium position of the j th nucleus is
</p>
<p>Xju0 = sq0, q = u + 3 (j &minus; 1), j = Î± +Nb (m&minus; 1), (17.121)
</p>
<p>with u = 1, 2, 3; Î± = 1, . . . ,Nb; m = 1, . . . ,Nc. The same applies to the
displacements, which are more conveniently expressed in terms of three indices:
</p>
<p>hq &larr;&minus; hmÎ±u, hr &larr;&minus; hnÎ²w. (17.122)
</p>
<p>The entries of C are identified in the same manner:
</p>
<p>cqr =
(
</p>
<p>&part;2Va
</p>
<p>&part;hq&part;hr
</p>
<p>)
</p>
<p>0
</p>
<p>&larr;&minus; cnÎ²wmÎ±u =
(
</p>
<p>&part;2Va
</p>
<p>&part;hmÎ±u &part;hnÎ²w
</p>
<p>)
</p>
<p>0
</p>
<p>, (17.123)
</p>
<p>with
</p>
<p>m, n = 1, . . . ,Nc, Î±,Î² = 1, . . . ,Nb, u, w = 1, 2, 3. (17.124)
</p>
<p>The order of derivation is irrelevant, so that cnÎ²wmÎ±u = cmÎ±unÎ²w . As the number of nu-
clei is finite, the crystal is not actually periodic; as indicated above, periodicity is
recovered by imposing periodic boundary conditions to the quantities of interest
(Sect. 17.5.3).20 With this provision, the entries of C are invariant with respect to
the lattice translations. The latter are related only to the cell indices m, n and are
obtained by the replacements lm &larr; lm + lÎ½ , ln &larr; ln + lÎ½ , with Î½ any integer. In
particular, taking lÎ½ = &minus;ln yields
</p>
<p>cnÎ²wmÎ±u = cÎ²wÎ±u (lm, ln) = cÎ²wÎ±u (lm &minus; ln, 0) = cÎ²wÎ±u (lm &minus; ln). (17.125)
</p>
<p>The above shows that the entries of C depend on the relative positions of the cells.
Due to the invariance of C with respect to the lattice translations one sees that, given
Î±, u and Î², w, there are only Nc distinct entries of C out of N2c , namely, the distinct
entries are those such that m&minus; n = 0, m&minus; n = 1, . . . , m&minus; n = Nc &minus; 1. In fact, all
remaining N2c &minus;Nc entries are derived from the first Nc ones by suitable translations
of the indices. In turn, using the new indices (17.124) the entries of M read
</p>
<p>Î¼r Î´qr &larr;&minus; Î¼nÎ²w Î´nÎ²wmÎ±u = Î¼Î² Î´nÎ²wmÎ±u, (17.126)
</p>
<p>20 As mentioned in Sect. 17.5.3, the periodic boundary conditions are actually an approximation;
however, the interatomic interactions typically give rise to short-range forces, hence the above
reasoning holds for all the cells that are not too close to the boundaries.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.7 Calculation of Vibrational Spectra 347
</p>
<p>where the last equality is due to the fact that the mass of a given nucleus of the cell
does not depend on the cell position within the crystal nor on the coordinate axis. In
the new indices the eigenvalue equation (17.119) becomes
</p>
<p>&sum;
</p>
<p>nÎ²w
</p>
<p>cnÎ²wmÎ±u gnÎ²w = Ï2 Î¼Î± gmÎ±u, (17.127)
</p>
<p>where the indices&rsquo; ranges are given in (17.124). The indices of the eigenvalue and
eigenvector have been omitted for simplicity. Defining
</p>
<p>dnÎ²wmÎ±u =
c
nÎ²w
mÎ±u&radic;
Î¼Î± Î¼Î²
</p>
<p>, zmÎ±u =
&radic;
Î¼Î± gmÎ±u, znÎ²w = &radic;Î¼Î² gnÎ²w, (17.128)
</p>
<p>transforms (17.127) into
&sum;
</p>
<p>nÎ²w
</p>
<p>dnÎ²wmÎ±u znÎ²w = Ï2 zmÎ±u. (17.129)
</p>
<p>The latter form of the eigenvalue equation is more convenient because it eliminates
the coefficientÎ¼Î± from the right hand side. Matrix D of entries d
</p>
<p>nÎ²w
mÎ±u is called dynamic
</p>
<p>matrix and, due to the properties of C, is symmetric (dnÎ²wmÎ±u = dmÎ±unÎ²w ) and translationally
invariant:
</p>
<p>dnÎ²wmÎ±u = dÎ²wÎ±u (lm, ln) = dÎ²wÎ±u (lm &minus; ln, 0) = dÎ²wÎ±u (lm &minus; ln). (17.130)
</p>
<p>17.7.2 Application of the Bloch Theorem
</p>
<p>As a consequence of the translational invariance of D, Bloch&rsquo;s theorem (17.23) ap-
plies,21 namely, for any eigenvector of indices kÎ³ e, and letting l0 = 0, the following
holds:
</p>
<p>zÎ³ e(lk) = exp (c &middot; lk) zÎ³ e(0). (17.131)
</p>
<p>In (17.131), c is any complex vector of the reciprocal lattice, and k = 0, . . . ,Nc&minus;1;
Î³ = 1, . . . ,Nb; e = 1, 2, 3. The complex form of the eigenvectors is adopted for
convenience; at the end of the calculation, a set of real eigenvectors is recovered from
suitable combinations of the complex ones. Using the periodic boundary conditions,
the expression of c is found to be
</p>
<p>c = i q, q =
3
</p>
<p>&sum;
</p>
<p>s=1
</p>
<p>Î½s
</p>
<p>Ns
2Ï bs , (17.132)
</p>
<p>21 The Bloch theorem was derived in Sect. 17.5.1 with reference to the eigenfunctions of a translation
operator in the continuous case; the theorem equally holds for a translation operator in the discrete
case, like the dynamic matrix considered here.</p>
<p/>
</div>
<div class="page"><p/>
<p>348 17 Periodic Structures
</p>
<p>with N1,N2,N3 the number of cells along the directions of the characteristic vectors
of the direct lattice, b1, b2, b3 the characteristic vectors of the reciprocal lattice, and
Î½1, Î½2, Î½3 integers, with Î½s = 0, 1, . . . ,Ns &minus; 1. The total number of distinct q vectors
is thus N1 N2 N3 = Nc. Comparing (17.132) with (17.37) shows that the structure of
the q vector is the same as that of the k vector found in the solution of the Schr&ouml;dinger
equation (Sect. 17.5.3). Inserting (17.130) into (17.129) yields, for the line of indices
mÎ±u of the eigenvalue equation,
</p>
<p>&sum;
</p>
<p>nÎ²w
</p>
<p>AnÎ²wmÎ±u zÎ²w(0) = Ï2zÎ±u(0), (17.133)
</p>
<p>with
</p>
<p>AnÎ²wmÎ±u =
1
</p>
<p>&radic;
Î¼Î±Î¼Î²
</p>
<p>cÎ²wÎ±u (lm &minus; ln) exp [i q &middot; (ln &minus; lm)]. (17.134)
</p>
<p>As the eigenvalues Ï2 are real, the matrix made of the entries AnÎ²wmÎ±u must be
Hermitean; in fact, this is easily found by observing that D is real and symmetric:
</p>
<p>AmÎ±unÎ²w = dÎ±uÎ²w(ln &minus; lm) exp [i q &middot; (lm &minus; ln)] =
(
</p>
<p>AnÎ²wmÎ±u
)&lowast;
. (17.135)
</p>
<p>Another property stems from the expression at the left hand side of (17.133),
</p>
<p>&sum;
</p>
<p>nÎ²w
</p>
<p>AnÎ²wmÎ±u zÎ²w(0) =
&sum;
</p>
<p>Î²w
</p>
<p>(
</p>
<p>&sum;
</p>
<p>n
</p>
<p>AnÎ²wmÎ±u
</p>
<p>)
</p>
<p>zÎ²w(0), (17.136)
</p>
<p>where AnÎ²wmÎ±u is translationally invariant because it depends on the cell indices only
through the difference lm&minus; ln. It follows that
</p>
<p>&sum;
</p>
<p>n A
nÎ²w
mÎ±u does not depend on m. This is
</p>
<p>easily verified by carrying out the sum first with, say, m = 1, then with m = 2, and
observing that the terms of the second sum are the same as in the first one, displaced
by one position. In summary, letting A be the 3Nb &times; 3Nb, Hermitean matrix of
entries
</p>
<p>AÎ²wÎ±u (q) =
Nc&sum;
</p>
<p>n=1
dÎ²wÎ±u (lm &minus; ln) exp [i q &middot; (ln &minus; lm)], (17.137)
</p>
<p>(17.133) becomes
&sum;
</p>
<p>Î²w
</p>
<p>AÎ²wÎ±u (q) zÎ²w(0) = Ï2zÎ±u(0). (17.138)
</p>
<p>For a given q, (17.138) is an eigenvalue equation of order 3Nb, whose eigenvalues
are found by solving the algebraic equation
</p>
<p>det(A &minus; Ï2 I) = 0, (17.139)</p>
<p/>
</div>
<div class="page"><p/>
<p>17.7 Calculation of Vibrational Spectra 349
</p>
<p>with I the identity matrix. As the entries of A depend on q, the calculation of the 3Nb
eigenvalues of (17.138) must be repeated for each distinct value of q, namely, Nc
times. The total number of eigenvalues thus found is 3Nb&times;Nc = 3N , as should be.
This result shows that, while the translational invariance eliminates the dependence
on lm, it introduces that on q. As the number of different determinations of the two
vectors lm and q is the same, namely, Nc, the total number of eigenvalues is not
affected. Letting the Nc determinations of q be numbered as q1, q2 . . .qk . . . , the
algebraic system (17.138) is recast as
</p>
<p>&sum;
</p>
<p>Î²w
</p>
<p>AÎ²wÎ±u (qk) zÎ²w(0, qk) = Ï2(qk) zÎ±u(0, qk), k = 1, 2, . . . Nc (17.140)
</p>
<p>which, for each qk , yields 3Nb eigenvalues Ï2 and 3Nb eigenvectors of length 3Nb;
as a consequence, the set of column vectors made of the eigenvectors associated to
qk forms a 3Nb &times; 3Nb matrix, indicated here with Z1k . By letting qk span over all
its Nc determinations, the total number of eigenvalues turns out to be 3N , namely,
</p>
<p>Ï2Î³ e(q1), . . . , Ï
2
Î³ e(qNc ), Î³ = 1, . . . ,Nb, e = 1, 2, 3. (17.141)
</p>
<p>Similarly, the total number of eigenvectors (of order 3Nb) turns out to be 3N ,
</p>
<p>zÎ³ e(0, q1), . . . , zÎ³ e(0, qNc ), Î³ = 1, . . . ,Nb, e = 1, 2, 3. (17.142)
They provide the set ofNc square matrices of order 3Nb, indicated with Z11, Z12, . . . ,
Z1Nc . Finally, each zÎ³ e(0, qk) provides an eigenvector of order 3N whose entries are
</p>
<p>zÎ±uÎ³ e(lm, qk) = exp (i qk &middot; lm) zÎ±uÎ³ e(0, qk), (17.143)
where, as usual, Î±, Î³ = 1, . . . ,Nb; u, e = 1, 2, 3 and, in turn, m = 0, . . . ,Nc &minus; 1;
k = 1, . . . ,Nc. The first index of matrices Z11, Z12, . . . corresponds to m = 0.
Similarly, index m = 1 provides a new set of matrices Z21, Z22, . . . , and so on.
The whole set of N2c matrices Zmk is equivalent to the 3N &times; 3N matrix Z of the
eigenvectors of the dynamic matrix, according to the following scheme:
</p>
<p>Z =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â¢
â¢
â£
</p>
<p>Z11 Z12 . . . Z1Nc
</p>
<p>Z21 Z22 . . . Z2Nc
...
</p>
<p>...
. . .
</p>
<p>...
</p>
<p>ZNc1 ZNc2 . . . ZNcNc
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¥
â¥
â¦
</p>
<p>. (17.144)
</p>
<p>17.7.3 Properties of the Eigenvalues and Eigenvectors
</p>
<p>Remembering that A (defined in (17.137)) is Hermitean, and Ï2 is real, one finds
(A &minus; Ï2 I)&lowast; = A&lowast; &minus; Ï2 I = AT &minus; Ï2 I = (A &minus; Ï2 I)T , whence
</p>
<p>det[(A &minus; Ï2 I)&lowast;] = det[(A &minus; Ï2 I)T ] = det(A &minus; Ï2 I). (17.145)</p>
<p/>
</div>
<div class="page"><p/>
<p>350 17 Periodic Structures
</p>
<p>This shows that the eigenvalue equation A(qk) z(0, qk) = Ï2 (qk) z(0, qk), and its
conjugate, A&lowast;(qk) z&lowast;(0, qk) = Ï2 (qk) z&lowast;(0, qk) have the same eigenvalues. More-
over, as the entries (17.137) of A are polynomials in exp [i qk &middot; (ln &minus; lm)] with real
coefficients, the following hold:
</p>
<p>AÎ²wÎ±u ( &minus; qk) =
[
</p>
<p>AÎ²wÎ±u (qk)
]&lowast;
</p>
<p>, A( &minus; qk) = A&lowast;(qk). (17.146)
</p>
<p>The above properties give rise to other important consequences for the eigenvalues
and eigenvectors. In fact, from the property A( &minus; qk) = A&lowast;(qk) and the hermiticity
of A one finds
</p>
<p>det [A( &minus; qk) &minus; Ï2 I] = det{[A(qk) &minus; Ï2 I]T } = det [A(qk) &minus; Ï2 I], (17.147)
</p>
<p>showing that the eigenvalues calculated from A(&minus;qk) are the same as those calculated
from A(qk). It follows that Ï is an even function of qk:
</p>
<p>Ï( &minus; qk) = Ï(qk), A( &minus; qk) z(0,&minus;qk) = Ï2(qk) z(0,&minus;qk). (17.148)
</p>
<p>Taking the conjugate of the second equation in (17.148) and using again the rela-
tion A( &minus; qk) = A&lowast;(qk) yields A(qk) z&lowast;(0,&minus;qk) = Ï2(qk) z&lowast;(0,&minus;qk). Comparing
the above with the original eigenvalue equation A(qk) z(0, qk) = Ï2 (qk) z(0, qk)
provides a relation between the eigenvectors:
</p>
<p>z(0,&minus;q) = z&lowast;(0, q). (17.149)
</p>
<p>From Bloch&rsquo;s theorem (17.131) it follows zÎ±uÎ³ e(lm, qk) = exp (i qk &middot; lm) zÎ±uÎ³ e(0, qk)
which, combined with (17.149), allows one to recover a set of real eigenvectors of
the dynamic matrix:
</p>
<p>zÎ±uÎ³ e(lm, qk) + zÎ±uÎ³ e(lm,&minus;qk) = zÎ±uÎ³ e(0, qk) exp (i qk &middot; lm) + z&lowast; Î±uÎ³ e (0, qk) exp ( &minus; i qk &middot; lm)
</p>
<p>where, as usual, the indices kÎ³ e count the eigenvectors and the indices mÎ±u count
the entries. Using the results of Sect. 3.10, the displacements of the particles from the
equilibrium position are given by h = Gb, where G is the matrix of the eigenvalues
of (17.119) and the entries of b have the form (3.49), namely,
</p>
<p>bkÎ³ e(t) =
1
</p>
<p>2
</p>
<p>{
</p>
<p>bÌkÎ³ e0 exp [ &minus; iÏÎ³ e(qk) t] + bÌ&lowast;kÎ³ e0 exp [iÏÎ³ e(qk) t]
}
</p>
<p>, (17.150)
</p>
<p>with bÌkÎ³ e0 depending on the initial conditions bkÎ³ e0(0), bÌkÎ³ e0(0). In turn, the en-
tries of matrix g are gmÎ±ukÎ³ e , where the lower indices refer to the columns and count
the eigenvectors, the upper ones refer to the rows and count the entries of each
eigenvector. Due to (17.128), such entries equal the corresponding terms of the real
eigenvector of the dynamic matrix, divided by
</p>
<p>&radic;
Î¼Î± . In conclusion, from h = Gb,
</p>
<p>the displacements are given by
</p>
<p>hmÎ±u =
&sum;
</p>
<p>kÎ³ e
</p>
<p>gmÎ±ukÎ³ e bkÎ³ e =
&sum;
</p>
<p>kÎ³ e
</p>
<p>1&radic;
Î¼Î±
</p>
<p>zmÎ±ukÎ³ e bkÎ³ e. (17.151)</p>
<p/>
</div>
<div class="page"><p/>
<p>17.8 Complements 351
</p>
<p>Using (17.150) yields
</p>
<p>hmÎ±u =
1&radic;
Î¼Î±
</p>
<p>&real;
&sum;
</p>
<p>kÎ³ e
</p>
<p>zÎ±uÎ³ e (0, qk)
[
</p>
<p>bÌkÎ³ e0 exp (iÎ¦
m
kÎ³ e) + bÌ&lowast;kÎ³ e0 exp (iÎ¨ mkÎ³ e)
</p>
<p>]
</p>
<p>,
</p>
<p>(17.152)
</p>
<p>where the phases are defined by
</p>
<p>Î¦mkÎ³ e = qk &middot; lm &minus; ÏÎ³ e(qk) t , Î¨ mkÎ³ e = qk &middot; lm + ÏÎ³ e(qk) t. (17.153)
</p>
<p>The above result shows that, in the harmonic approximation, the displacements have
the form of a superposition of plane and monochromatic waves, whose wave vector
and angular frequency are qk , ÏÎ³ e(qk). The wave corresponding to a given qk is
called vibrational mode. Typically, the number of qk vectors is very large; in such
cases, the same reasoning made in Sect. 17.6 with reference to the k vectors holds,
and q is considered a continuous variable ranging over the first Brillouin zone.
</p>
<p>FunctionÏÎ³ e(q) is also called dispersion relation, and is viewed as a multi-valued
function of q having 3Nb branches. For each branch, letting q = |q|, the wavelength
is defined byÎ» = 2Ï/q and the phase velocity by uf = Ï/q = Î» Î½, with Î½ = Ï/(2Ï )
the frequency.
</p>
<p>The group velocity is defined by u = gradqÏ. As shown in Sect. 3.10, the total
energy of the system is the sum of the mode energies, and in the classical description
is expressed in terms of the initial conditions as
</p>
<p>Ta + Va = Va0 +
3N
&sum;
</p>
<p>Ï=1
EÏ , EÏ =
</p>
<p>1
</p>
<p>2
bÌ2Ï (0) +
</p>
<p>1
</p>
<p>2
Ï2Ï b
</p>
<p>2
Ï (0). (17.154)
</p>
<p>As remarked in Sect. 12.5, the classical expression of the energy associated to each
mode has the same form as that of a mode of the electromagnetic field. In turn,
the energy quantization shows that each mode energy is made of terms of the form
hÌÏÎ³ e(q), this leading to the concept of phonon (Eqs. (12.35, 12.36)).
</p>
<p>17.8 Complements
</p>
<p>17.8.1 Crystal Planes and Directions in Cubic Crystals
</p>
<p>From the general definition (17.1) of the translation vector, that provides the positions
of all nodes of the crystal, it follows that a crystal plane is defined by the set of all
triads of integers m1,m2,m3 such that, for a given vector g0 of the scaled reciprocal
lattice, the quantity (m1 a1 +m2 a2 +m3 a3) &middot; g0/(2Ï ) equals a fixed integer. Such
a plane is normal to g0. In turn, given two crystal planes defined as above using,
respectively, two non-parallel vectors g1 and g2, a crystal direction is defined by
the set of all triads of integers m1,m2,m3 that belong to the two crystal planes so</p>
<p/>
</div>
<div class="page"><p/>
<p>352 17 Periodic Structures
</p>
<p>Fig. 17.22 Example of node
labeling in the cubic lattice
</p>
<p>a
2
</p>
<p>1
a
</p>
<p>1,1,11,0,1
</p>
<p>3
a
</p>
<p>1,1,0
</p>
<p>0,0,0
</p>
<p>0,0,1
</p>
<p>1,0,0
</p>
<p>prescribed. In cubic crystals, the typical method by which the crystal planes are
identified is outlined below [103, Sect. 2.2].
</p>
<p>Let the plane be indicated withï¿½. After labeling the nodes by the respective triads
of integers m1,m2,m3, as shown in Fig. 17.22, one starts by finding the intercepts
of ï¿½ with the directions of the characteristic vectors. Letting such intercepts be
(m&lowast;1,m
</p>
<p>&lowast;
2,m
</p>
<p>&lowast;
3), the triad (r m
</p>
<p>&lowast;
1, r m
</p>
<p>&lowast;
2, r m
</p>
<p>&lowast;
3) with r ï¿½= 0 an integer, spans a set of planes
</p>
<p>parallel toï¿½. IfM is the largest divisor ofm&lowast;1,m
&lowast;
2,m
</p>
<p>&lowast;
3, then the new triadm
</p>
<p>&prime;
i = m&lowast;i /M
</p>
<p>identifies the plane ï¿½&prime; parallel to ï¿½ and closest to the origin. Then, the inverse of
the triad&rsquo;s elements are taken: 1/m&prime;1, 1/m
</p>
<p>&prime;
2, 1/m
</p>
<p>&prime;
3. This avoids the occurrence of
</p>
<p>infinities; in fact, if ï¿½ were parallel to one of the characteristic vectors, say, ai , then
m&lowast;i and m
</p>
<p>&prime;
i would become infinite. One the other hand, using the inverse indices may
</p>
<p>bring to fractional numbers, a circumstance that must be avoided as well; so, as the
last step, the new elements 1/m&prime;i are multiplied by the least multiple N of the m
</p>
<p>&prime;
i that
</p>
<p>are not infinite:
</p>
<p>(m&prime;&prime;1 ,m
&prime;&prime;
2 ,m
</p>
<p>&prime;&prime;
3) =
</p>
<p>(
N
</p>
<p>m&prime;1
,
N
</p>
<p>m&prime;2
,
N
</p>
<p>m&prime;3
</p>
<p>)
</p>
<p>. (17.155)
</p>
<p>The elements m&prime;&prime;i thus found are the Miller indices of ï¿½. They are enclosed in
parentheses as in (17.155). By way of example, if m&lowast;1 = &infin;, m&lowast;2 = 2, m&lowast;3 = 4, then
M = 2 so that m&prime;1 = &infin;, m&prime;2 = 1, m&prime;3 = 2. Calculating the inverse indices yields
1/m&prime;1 = 0, 1/m&prime;2 = 1, 1/m&prime;3 = 1/2; the least multiple is N = 2, so that the Miller
indices are found to be (0, 2, 1).
</p>
<p>The indices that turn out to be negative are marked with a bar; for instance, in
(hkÌl) the second index is negative. Some planes have the same symmetry; in cubic
crystals this happens, for instance, to planes (100), (010), (001), (1Ì00), (01Ì0), and
(001Ì). A set of planes with the same symmetry is indicated with braces, e.g., {100}.
Examples of the (111), (001), and (010) planes are given in Fig. 17.23. As remarked
in Sect. 24.4 about the silicon-oxidation process, the (111) plane has the highest
concentration of atoms, followed by the {100} planes.
</p>
<p>Symbols using three integers are also used to identify the crystal directions. To
distinguish them from the symbols introduced so far, such triads of integers are</p>
<p/>
</div>
<div class="page"><p/>
<p>17.8 Complements 353
</p>
<p>Fig. 17.23 Schematic
representation of the (111)
plane (top left) and of the
(001) and (010) planes
(bottom right) in a cubic
crystal
</p>
<p>(010)
</p>
<p>(001)
</p>
<p>(111)
</p>
<p>enclosed in brackets. Consider, for instance, the line connecting nodes P and Q,
oriented from P to Q. Letting m1P , m2P , m3P be the coordinates of P , and the like
for those of Q, one forms the new triad m&prime;1 = m1Q &minus; m1P , m&prime;2 = m2Q &minus; m2P , and
m&prime;3 = m2Q &minus;m2P . Then, the indices of the crystal direction are obtained as
</p>
<p>[m&prime;&prime;1 ,m
&prime;&prime;
2 ,m
</p>
<p>&prime;&prime;
3] =
</p>
<p>[
m&prime;1
M
</p>
<p>,
m&prime;2
M
</p>
<p>,
m&prime;3
M
</p>
<p>]
</p>
<p>, (17.156)
</p>
<p>with M the largest divisor of m&prime;1,m
&prime;
2,m
</p>
<p>&prime;
3. Also in this case, negative indices are
</p>
<p>marked with a bar. By way of examples, the characteristic vectors a1, a2, and a3 in
Fig. 17.22 are aligned, respectively, with the [100], [010], and [001] directions.
</p>
<p>17.8.2 Examples of Translation Operators
</p>
<p>A one-dimensional example of translation operator is easily found by considering
the Taylor expansion of a function f around some position x:
</p>
<p>f (x + l) =
&infin;
&sum;
</p>
<p>n=0
</p>
<p>ln
</p>
<p>n!
</p>
<p>(
dnf
</p>
<p>dxn
</p>
<p>)
</p>
<p>l=0
=
</p>
<p>&infin;
&sum;
</p>
<p>n=0
</p>
<p>ln
</p>
<p>n!
dn
</p>
<p>dxn
f (x) = exp
</p>
<p>(
</p>
<p>l
d
</p>
<p>dx
</p>
<p>)
</p>
<p>f (x), (17.157)
</p>
<p>where the expression on the right stems from a formal application of the Taylor
expansion of the exponential function, in which a numerical factor within the ex-
ponent is replaced with the operator d/dx. Extending the above reasoning to three
dimensions yields
</p>
<p>T (l) = exp (l &middot; grad). (17.158)</p>
<p/>
</div>
<div class="page"><p/>
<p>354 17 Periodic Structures
</p>
<p>17.8.3 Symmetries of the Hamiltonian Operator
</p>
<p>Given an operator R, a second operator A is associated to R in the following manner
[58, Sect. 1.5]:
</p>
<p>Af (r) = f (R&dagger;r) (17.159)
</p>
<p>for all functions f . Thus, the action of A on f at r is the same as calculating the
original function at r&prime; = R&dagger;r. Let R be unitary (Sect. 8.6.2), whence r = Rr&prime;. A
unitary operator acting on r leaves the norm r = |r| unchanged; as a consequence,
the unitary operations possible on the coordinates are only those that perform a
rotation or a reflexion of the coordinate axes, or both. It follows that the unit volume
dÏ = d3r is also invariant: d3Rr = d3r , this showing that A is unitary as well:
</p>
<p>&int;
</p>
<p>Ï
</p>
<p>|Af (r)|2 d3r =
&int;
</p>
<p>Ï &prime;
|f (r&prime;)|2 d3Rr &prime; =
</p>
<p>&int;
</p>
<p>Ï &prime;
|f (r&prime;)|2 d3r &prime;, (17.160)
</p>
<p>where Ï &prime; is the transformed domain. This reasoning does not apply to the transla-
tion operators T . In fact, the operation T r = r + l does not leave the norm of r
unchanged. This shows in passing that T is not unitary. Other consequences of the
above definitions and of the proof that A is unitary are
</p>
<p>Af (Rr&prime;) = f (r&prime;), A&dagger;f (r&prime;) = f (Rr&prime;). (17.161)
</p>
<p>Also, A commutes with the operators that are invariant under the transformation
r &larr; R&dagger;r. In fact, if B is such an operator,
</p>
<p>AB(r)f (r) = B(R&dagger;r)f (R&dagger;r) = B(r)Af (r) (17.162)
</p>
<p>for all functions f . As R&dagger; is the inverse of R, then B is also invariant under the
transformation r &larr; Rr. As a consequence, B commutes also with A&dagger;.
</p>
<p>Let Bvn = bn vn be the eigenvalue equation for B (a discrete spectrum is assumed
for the sake of simplicity). If bn is s-fold degenerate, and v(1)n , v
</p>
<p>(2)
n , . . . , v
</p>
<p>(s)
n are s
</p>
<p>linearly-independent eigenfunctions corresponding to bn, then
</p>
<p>B
</p>
<p>s
&sum;
</p>
<p>i=1
ci v
</p>
<p>(i)
n =
</p>
<p>s
&sum;
</p>
<p>i=1
ci Bv
</p>
<p>(i)
n =
</p>
<p>s
&sum;
</p>
<p>i=1
ci bn v
</p>
<p>(i)
n = bn
</p>
<p>s
&sum;
</p>
<p>i=1
ci v
</p>
<p>(i)
n , (17.163)
</p>
<p>namely, any non-vanishing linear combination of the formÏn =
&sum;s
</p>
<p>i=1ci v
(i)
n is also an
</p>
<p>eigenfunction of B belonging to bn. Let M be the space of all linear combinations of
the form of Ïn; from (17.163) it follows that all members of M are eigenfunctions of
B belonging to bn. Conversely, all eigenfunctions of B belonging to bn are members
of M: letting qn ï¿½= 0 be one such eigenfunction, if qn were not a member of M it
would be qn &minus;
</p>
<p>&sum;s
i=1 ci v
</p>
<p>(i)
n ï¿½= 0 for all choices of the coefficients ci . But this would
</p>
<p>imply that qn, v(1)n , v
(2)
n , . . . , v
</p>
<p>(s)
n are s + 1 linearly-independent eigenfunctions of bn,</p>
<p/>
</div>
<div class="page"><p/>
<p>17.8 Complements 355
</p>
<p>thus contradicting the hypothesis that the latter&rsquo;s degeneracy is of order s. Finally, if
A commutes with B it is
</p>
<p>BAÏn = ABÏn = AbnÏn = bnAÏn, (17.164)
</p>
<p>namely, AÏn belongs to M .
In crystals, the unitary coordinate transformations r&prime; = Rr that leave the Hamil-
</p>
<p>tonian operator H invariant are of particular interest. In fact, such coordinate
transformations provide a method to study the degenerate eigenvalues of H.
</p>
<p>Let B = H, and let H be invariant under a coordinate transformation Rr. If, in
addition, H is translationally invariant and the periodic boundary conditions apply
(Sect. 17.5.3), then the eigenfunctions w of H are Bloch functions, namely, they
fulfill the Bloch theorem
</p>
<p>wi(r + l, k) = exp (i k &middot; l) wi(r, k), (17.165)
</p>
<p>with l a translation vector and i the band index. Let A be the operator associated to
R. Then, from HA&dagger; = A&dagger;H,
</p>
<p>HA&dagger;wi(r, k) = Ei(k) A&dagger;wi(r, k), (17.166)
</p>
<p>with Ei(k) the eigenvalue. One infers from (17.166) that, if wi(r, k) and A&dagger;wi(r, k)
are linearly independent, then the eigenvalue is degenerate. Such a degeneracy does
not depend on the detailed form of the Hamiltonian operator, but only on its symmetry
properties. For this reason, the degeneracy is called essential. If further degeneracies
exist, that depend on the detailed form of H, they are called accidental.
</p>
<p>Let M(k) be the space made of the linearly-independent eigenfunctions of E(k),
and of any non-vanishing linear combination of them, and define
</p>
<p>vi(r, k
&prime;) = A&dagger;wi(r, k) = wi(Rr, k), (17.167)
</p>
<p>where symbol k&prime; accounts for a possible influence on k of the coordinate transfor-
mation Rr. Being an eigenfunction of H, vi(r, k&prime;) is a Bloch function,
</p>
<p>vi(r + l, k&prime;) = exp (i k&prime; &middot; l) vi(r, k&prime;), (17.168)
</p>
<p>where vi(r + l, k&prime;) = wi(Rr + Rl, k). On the other hand, Bloch&rsquo;s theorem applied
to wi(Rr + Rl, k) yields
</p>
<p>wi(Rr + Rl, k) = exp (jk &middot; Rl) wi(Rr, k), (17.169)
</p>
<p>where the equality k &middot; Rl = R&dagger;k &middot; l holds due to the definition of adjoint operator.
Comparison with the expression of the Bloch theorem applied to vi(r+l, k&prime;) provides
k&prime; = R&dagger;k, whence
</p>
<p>wi(Rr, k) = vi(r, R&dagger;k). (17.170)
</p>
<p>In conclusion, if wi(r, k) is a Bloch function belonging to M(k) and Rr a coordinate
transformation that leaves the Hamiltonian operator invariant, then the eigenfunction</p>
<p/>
</div>
<div class="page"><p/>
<p>356 17 Periodic Structures
</p>
<p>obtained by such a transformation also belongs to M(k) and is labeled by R&dagger;k. The
following also holds true,
</p>
<p>Hvi(r, R
&dagger;k) = Ei(R&dagger;k) vi(r, R&dagger;k) (17.171)
</p>
<p>which, compared with Hwi(r, k) = Ei(k) wi(r, k), shows that
</p>
<p>Ei(R
&dagger;k) = Ei(k). (17.172)
</p>
<p>The theory of this section is applied by way of example to the Hamiltonian operator
of a system of K electrons and N nuclei, interacting through electrostatic forces,
that was introduced in Sect. 16.2. The potential energy is (compare with (16.5))
</p>
<p>Ue(r) + Ua(r) + Uea(r, R) + Uext(r, R), (17.173)
</p>
<p>with
</p>
<p>Ue(r) =
K
&sum;
</p>
<p>i,j=1
</p>
<p>q2
</p>
<p>4Ï Îµ0 |ri &minus; rj |
, j ï¿½= i. (17.174)
</p>
<p>Similar expressions hold for Ua and Uea (the second relation in (16.1) and (16.2),
respectively). If Uext = 0, the potential energy is invariant upon the reflexion trans-
formation Rr = &minus;r, RR = &minus;R. Clearly, the kinetic part of the Hamiltonian
operator is also invariant. In the adiabatic approximation (Sect. 16.3), the coor-
dinates of the nuclei are fixed to the equilibrium positions R0, which preserves
the reflexion invariance. Finally, the reflexion invariance is still preserved in the
Hartree and Hartree&ndash;Fock approximations (Sects. 16.4 and 16.5, respectively), which
also provide single-electron Hamiltonian operators that are translationally invariant.
Due to lattice periodicity, the eigenfunctions of the Hamiltonian operator are Bloch
functions. Denoting now with r the coordinates associated to a single electron, the
transformation Rr = &minus;r corresponds to R&dagger;k = &minus;k whence, from (17.172),
</p>
<p>Ei( &minus; k) = Ei(k). (17.175)
</p>
<p>This type of degeneracy is accidental because it depends on the detailed form of the
Hamiltonian operator. If the crystal has also a reflection symmetry, then the reflexion
invariance of the single-electron Hamiltonian operators occurs irrespective of the
form of the interactions. In this case, the degeneracy is essential.
</p>
<p>17.8.4 Kronig&ndash;Penney Model
</p>
<p>The general method for solving the Schr&ouml;dinger equation in a periodic lattice, shown
in Sect. 17.6, is applied here to a one-dimensional case, where the potential energy
is described as the series of equal barriers shown in Fig. 17.24. The approach is</p>
<p/>
</div>
<div class="page"><p/>
<p>17.8 Complements 357
</p>
<p>Fig. 17.24 Potential energy
in the Kronig&ndash;Penney model
</p>
<p>V0
E
</p>
<p>x
</p>
<p>V
</p>
<p>a b
</p>
<p>called Kronig&ndash;Penney model; it is amenable to an analytical solution and, despite its
simplicity, is able to capture the main properties of the dispersion relation E(k).
</p>
<p>As shown in the figure, the potential energy is prescribed as V = 0 for n (a+b) &lt;
x &lt; n (a + b) + a, and V = V0 &gt; 0 for n (a + b) &minus; b &lt; x &lt; n (a + b),
with n = 0,&plusmn;1,&plusmn;2 . . . There is only one characteristic vector in the direct lattice,
a1 = (a + b) i1; the corresponding characteristic vector of the reciprocal lattice is
</p>
<p>b1 =
i1
</p>
<p>a + b . (17.176)
</p>
<p>As a consequence, the first Brillouin zone extends from &minus;Ï/(a + b) to +Ï/(a + b)
in the i1 direction. From the general properties of the time-independent Schr&ouml;dinger
equation (Sect. 8.2.3) it followsE &ge; 0. As shown in Fig. 17.24, the case 0 &lt; E &lt; V0
is considered. A non-localized wave function w is expected even in the E &lt; V0 case
due to the tunnel effect. From the Bloch theorem, the wave function has the form
</p>
<p>wk = uk exp (i k x), uk(x + a + b) = uk(x), (17.177)
</p>
<p>where k belongs to the first Brillouin zone. In the intervals where V = 0 the
Schr&ouml;dinger equation reads
</p>
<p>&minus;w&prime;&prime; = Î±2 w, Î± =
&radic;
</p>
<p>2mE/hÌ &gt; 0. (17.178)
</p>
<p>Replacing (17.177) into (17.178) yields
</p>
<p>u&prime;&prime;k + 2 i k u&prime;k &minus; (k2 &minus; Î±2) uk = 0, (17.179)
</p>
<p>whose associate algebraic equation has the roots
</p>
<p>s = &minus;i k &plusmn;
&radic;
</p>
<p>&minus;k2 + (k2 &minus; Î±2) = &minus;i k &plusmn; i Î±. (17.180)
</p>
<p>The solution of (17.178) then reads
</p>
<p>u+k = c1 exp [i (Î± &minus; k) x] + c2 exp [ &minus; i (Î± + k) x], (17.181)</p>
<p/>
</div>
<div class="page"><p/>
<p>358 17 Periodic Structures
</p>
<p>with c1, c2 undetermined coefficients. The procedure is similar in the intervals where
V = V0, and yields
</p>
<p>w&prime;&prime; = Î²2 w, Î² =
&radic;
</p>
<p>2m (V0 &minus; E)/hÌ, u&prime;&prime;k + 2 i k u&prime;k &minus; (k2 + Î²2) uk = 0,
(17.182)
</p>
<p>s = &minus;i k &plusmn;
&radic;
</p>
<p>&minus;k2 + (k2 + Î²2) = &minus;i k &plusmn; Î², (17.183)
whence
</p>
<p>u&minus;k = c3 exp [(Î² &minus; i k) x] + c4 exp [ &minus; (Î² + i k) x], (17.184)
with c3, c4 undetermined coefficients. The regional solutions u
</p>
<p>+
k , u
</p>
<p>&minus;
k must fulfill the
</p>
<p>continuity conditions imposed by the general properties of the Schr&ouml;dinger equation;
in addition, they must fulfill the periodicity condition prescribed by the Bloch theorem
(second relation in (17.177)). To proceed, one focuses on the period &minus;b &le; x &le; a,
so that the continuity conditions at x = 0 for the function, u+k (0) = u&minus;k (0), and first
derivative, (u+k )
</p>
<p>&prime;(0) = (u&minus;k )&prime;(0), provide
c1 + c2 = c3 + c4, iÎ± (c1 &minus; c2) = Î² (c3 &minus; c4). (17.185)
</p>
<p>Combining (17.185),
</p>
<p>c1 = Ïc3 + Ï &lowast; c4, c2 = Ï &lowast; c3 + Ïc4, 2 Ï = 1 &minus; i Î²/Î±. (17.186)
In turn, from the periodicity of u, namely, u+k (a) = u&minus;k ( &minus; b), and of u&prime;, namely,
(u+k )
</p>
<p>&prime;(a) = (u&minus;k )&prime;( &minus; b), one finds
</p>
<p>c1 A+
c2
</p>
<p>A
= K L
</p>
<p>(c3
</p>
<p>B
+ c4 B
</p>
<p>)
</p>
<p>, c1 A&minus;
c2
</p>
<p>A
= &minus;K L
</p>
<p>(c3
</p>
<p>B
&minus; c4 B
</p>
<p>)
</p>
<p>i
Î²
</p>
<p>Î±
,
</p>
<p>(17.187)
</p>
<p>with
</p>
<p>A = exp (iÎ± a), B = exp (Î² b), K = exp (i k a), L = exp (i k b). (17.188)
Combining (17.187),
</p>
<p>c1 =
KL
</p>
<p>A
</p>
<p>( Ï
</p>
<p>B
c3 + Ï &lowast; B c4
</p>
<p>)
</p>
<p>, c2 = AK L
(
Ï &lowast;
</p>
<p>B
c3 + Ï B c4
</p>
<p>)
</p>
<p>. (17.189)
</p>
<p>Eliminating c1, c2 between (17.186) and (17.189), finally provides an algebraic
system in the two unknowns c3, c4:
</p>
<p>Ï
</p>
<p>(
</p>
<p>1 &minus; KL
AB
</p>
<p>)
</p>
<p>c3 + Ï &lowast;
(
</p>
<p>1 &minus; BKL
A
</p>
<p>)
</p>
<p>c4 = 0, (17.190)
</p>
<p>Ï &lowast;
(
</p>
<p>1 &minus; AKL
B
</p>
<p>)
</p>
<p>c3 + Ï (1 &minus; ABKL) c4 = 0. (17.191)</p>
<p/>
</div>
<div class="page"><p/>
<p>17.8 Complements 359
</p>
<p>Fig. 17.25 Graphic solution
of (17.194), with Ï = 10. The
two vertical lines mark the
values of Î± a delimiting the
lowest band
</p>
<p>0 5 10 15 20
Î± a (arbitrary units)
</p>
<p>0
</p>
<p>5
</p>
<p>10
</p>
<p>15
</p>
<p>Î¸
 s
</p>
<p>in
 (
</p>
<p> Î±
a
</p>
<p> )
 /
</p>
<p> (
 Î±
</p>
<p>a
 )
</p>
<p> +
 c
</p>
<p>o
s 
</p>
<p>( 
Î±
</p>
<p>a
 )
</p>
<p>As expected, the system is homogeneous, so a solution is possible only if the deter-
minant vanishes. This in turn determines a relation between Î±(E), Î²(E), and k, that
eventually provides the dispersion relation E(k). The determinant vanishes if
</p>
<p>(Ï &lowast;2 &minus; Ï 2)
(
</p>
<p>KL+ 1
KL
</p>
<p>)
</p>
<p>= Ï &lowast;2
(
A
</p>
<p>B
+ B
</p>
<p>A
</p>
<p>)
</p>
<p>&minus; Ï 2
(
</p>
<p>AB + 1
AB
</p>
<p>)
</p>
<p>. (17.192)
</p>
<p>Introducing the expressions (17.186, 17.188) of Ï ,A,B,K ,L transforms (17.192)
into
</p>
<p>Î²2 &minus; Î±2
2 Î± Î²
</p>
<p>sin (Î± a) sinh (Î² b) + cos (Î± a) cosh (Î² b) = cos [k (a + b)], (17.193)
</p>
<p>which has the form F (E) = G(k). From this, the relation E = E(k) can be deter-
mined. Note thatG(&minus;k) = G(k) andG[k+2Ï/(a+b)] = G(k). As a consequence,
the function E(k) is even and has the periodicity of the reciprocal scaled lattice, as
should be.
</p>
<p>To the purpose of completing the analysis one may simplify (17.193) by consider-
ing a limiting case, namely,V0 â« E so that, from (17.178, 17.182), the limitÎ²2 â« Î±2
would result. This, however, would eliminate the tunnel effect and reduce the problem
to that of a series of boxes. To avoid this outcome, the proper limiting case is b &rarr; 0
and V0 &rarr; &infin;, in such a way as to leave the area b V0 of each barrier unchanged.22
In other terms, one lets b = const/V0, so that Î²2 b &rarr; const ï¿½= 0 while Î² b &rarr; 0.
It follows sinh (Î² b) &rarr; Î² b, cosh (Î² b) &rarr; 1 so that, letting Ï = lim (a b Î²2/2), the
F (E) = G(k) relation (17.193) simplifies to
</p>
<p>Ï
sin (Î± a)
</p>
<p>Î± a
+ cos (Î± a) = cos (k a), Ï &gt; 0, Î± =
</p>
<p>&radic;
2mE
</p>
<p>hÌ
. (17.194)
</p>
<p>22 The same type of limit is applicable to the single-barrier case, whose transmission coefficient is
given in (11.22).</p>
<p/>
</div>
<div class="page"><p/>
<p>360 17 Periodic Structures
</p>
<p>The function E = E(k) can be determined by inverting (17.194); alternatively, it
may be obtained in graphic form as shown in Fig. 17.25, where Ï has been fixed to
10: given k, the right hand side of (17.194) is fixed at some value&minus;1 &le; cos (k a) &le; 1.
The energy E is then found by seeking Î± a such that the two sides become equal. The
horizontal, dashed lines in the figure correspond to cos (ka) = 1 and cos (k a) = &minus;1;
they limit the interval where (17.194) has real solutions. The horizontal, continuous
line corresponds to cos (k a) = 0.4, while the oscillating curve represents the left
hand side of (17.194). The latter intercepts the cos (k a) = 0.4 line at infinite points
Î±1 a, Î±2 a, . . . ; from each Î±i thus found, one determines the energy corresponding
to the given k from the relation Î±i =
</p>
<p>&radic;
2mEi/hÌ. Each branch of the multi-valued
</p>
<p>function E(k) is then found by repeating the procedure for all values of k within the
first Brillouin zone, this making cos (k a) to range from &minus;1 to 1. In the figure, the
two vertical lines mark the values of Î± a delimiting the lowest band. The following
are also worth noting:
</p>
<p>&bull; Letting Î» indicate the left hand side of (17.194), there are no real solutions for
Î» &gt; 1 or Î» &lt; &minus;1; the intervals with no real solutions are the forbidden bands. In
fact, the k solutions in the forbidden bands are complex: it is k a = &plusmn;i log (Î» +&radic;
Î»2 &minus; 1) when Î» &gt; 1, and k a = Ï &plusmn; i log (|Î»| +
</p>
<p>&radic;
Î»2 &minus; 1) when Î» &lt; &minus;1.
</p>
<p>&bull; At large energies the (17.194) relation tends to cos (Î±a) = cos (ka), namely, to
the free-particle one: k = Î± =
</p>
<p>&radic;
2mE/hÌ.
</p>
<p>&bull; Like in the general case, for a finite structure where the periodic boundary
conditions are applied, the above calculation still holds, with k a discrete variable.
</p>
<p>17.8.5 Linear, Monatomic Chain
</p>
<p>The calculation of vibrational spectra has been carried out in general form in
Sect. 17.7. Simple examples of application, with reference to a one-dimensional
lattice, are given in this section and in the next one. Like the Kronig&ndash;Penney model
used in Sect. 17.8.4 for determining the dispersion relation of electrons, the one-
dimensional models of the lattice vibrations are amenable to analytical solutions; the
latter, as shown below, are able to provide the explicit expression of the dispersion
relation.
</p>
<p>To begin, consider a one-dimensional monatomic lattice made of Nc cells (linear,
monatomic chain). Let the lattice be aligned with the x axis, and the corresponding
characteristic vector be a = a i, a &gt; 0, with i the unit vector of the x axis. Finally,
let the positions of the Nc + 1 nodes be 0, a, 2 a, . . . , n a, . . . . The translation vector
associated to the nth node is ln = n a i. Finally, it is assumed that the motion of each
atom is constrained to the x axis, and the periodic boundary conditions are applied.
</p>
<p>Due to the periodic boundary conditions the nodes of indices n = 0 and n = Nc
are actually the same node. As a one-dimensional case is considered, with Nb = 1,
the total number of atoms is N = Nc. The number of the lattice&rsquo;s degrees of freedom
is Nc, and the correspondence with the indices used in the general theory (compare</p>
<p/>
</div>
<div class="page"><p/>
<p>17.8 Complements 361
</p>
<p>with (17.124)) is
</p>
<p>m, n = 1, . . . ,Nc, Î±,Î² = 1, u, w = 1. (17.195)
</p>
<p>As only one atom per cell is present, one may assume that the equilibrium position
of each nucleus coincides with that of a node. In the harmonic approximation the
force acting on the rth nucleus is a linear function of the displacements:
</p>
<p>Fr = &minus;
Nc&sum;
</p>
<p>k=1
crk hk , (17.196)
</p>
<p>where all coefficients crk in general differ from 0. In real crystals, however, the
interaction between nuclei becomes rapidly negligible as the distance increases. As
a consequence, the dynamics of a nucleus may be tackled in a simplified manner by
considering only the interaction with the neighboring nuclei to be effective. This is
equivalent to letting crk = 0 when |r &minus; k| &gt; 1, whence
</p>
<p>Fr = &minus;cr&minus;1r hr&minus;1 &minus; crr hr &minus; cr+1r hr+1 = Fr (hr&minus;1,hr ,hr+1). (17.197)
</p>
<p>In the coefficients of (17.197), the lower index refers to the node being acted upon by
the force at the left hand side, the upper index refers to the node whose displacement
contributes to such a force. When the nuclei of indices r &minus; 1, r , r + 1 are in the
equilibrium positions it is Fr (0, 0, 0) = 0 for all r . On the other hand, it is also
Fr (Î´, Î´, Î´) = 0, with Î´ ï¿½= 0 an arbitrary displacement. In fact, when all displacements
are equal, the interatomic distance remains the same as in the equilibrium condition.
From Fr (Î´, Î´, Î´) = 0 it follows that the coefficients are connected by the relation
</p>
<p>cr&minus;1r + crr + cr+1r = 0. (17.198)
</p>
<p>Moreover, on account of the fact that all atoms are identical and all equilibrium
distances are also identical, it is Fr ( &minus; Î´, 0, Î´) = 0, Î´ ï¿½= 0, whence
</p>
<p>cr&minus;1r = cr+1r . (17.199)
</p>
<p>From (17.198, 17.199) it follows
</p>
<p>crr = &minus;cr&minus;1r &minus; cr+1r = &minus;2 cr&minus;1r = &minus;2 cr+1r . (17.200)
</p>
<p>Finally, the relation Fr (0, Î´, 0) = &minus;crr Î´, on account of the fact that (0, 0, 0) is an
equilibrium condition, shows that crr &gt; 0. As shown in Sect. 17.7 for the general
case, due to the translational invariance the elastic coefficients do not depend on the
cell index, but on the difference between cell indices (compare with (17.125)); in
conclusion, letting
</p>
<p>Ï = &minus;cr&minus;1r = &minus;cr+1r &gt; 0, crr = 2Ï , (17.201)</p>
<p/>
</div>
<div class="page"><p/>
<p>362 17 Periodic Structures
</p>
<p>and letting Î¼ be the common mass of the nuclei, the dynamics of the rth nucleus is
described by the equation
</p>
<p>Î¼ hÌr = &minus;Ï (2 hr &minus; hr+1 &minus; hr&minus;1) . (17.202)
</p>
<p>The general theory shows that the displacement has the form
</p>
<p>hr = h0 exp (i q r a &minus; iÏ t) , (17.203)
</p>
<p>(compare with (17.152)), where h0 is a complex constant, q r a = q &middot; lr = q i &middot; r a i,
and Ï = Ï(q). Replacing (17.203) in (17.202) and dividing by hr yields
</p>
<p>Î¼Ï2 = Ï
[
</p>
<p>2 &minus; exp (i q a) &minus; exp ( &minus; i qa)
]
</p>
<p>= 4Ï sin2 (qa/2). (17.204)
</p>
<p>Defining ÏÌ = &radic;Ï/Î¼ and remembering that Ï is non negative, one finds the
dispersion relation
</p>
<p>Ï(q) = 2ÏÌ | sin (qa/2)|. (17.205)
</p>
<p>From the periodic boundary condition h(r = Nc) = h(r = 0) one finds, with Î½ an
integer,
</p>
<p>exp (i q Nc a) = 1, q Nc a = 2Ï Î½, q =
Î½
</p>
<p>Nc
</p>
<p>2Ï
</p>
<p>a
. (17.206)
</p>
<p>Replacing this form of q within (17.203) and (17.205) shows that using Î½+Nc instead
of Î½ leaves hr andÏ unchanged. As a consequence, it is sufficient to consider onlyNc
consecutive values of Î½, say, Î½ = 0, 1, . . . ,Nc &minus; 1, which in turn limit the possible
values of q to an interval of length 2Ï/a. This was expected, because the values
of the indices in (17.195) are such that the number of eigenvalues of the problem is
Nc. Thus, the dispersion relation has only one branch, given by (17.205). One also
notes that 2Ï/a is the size of the first Brillouin zone in the one-dimensional case.
Typically, the interval of q is made to coincide with the first Brillouin zone, namely,
&minus;Ï/a &le; q &lt; +Ï/a. Also, as mentioned in Sect. 17.7, in most cases q is treated as
a continuous variable. The phase and group velocities are
</p>
<p>uf =
Ï
</p>
<p>q
= &plusmn;a ÏÌ sin (q a/2)
</p>
<p>qa/2
, u = dÏ
</p>
<p>dq
= &plusmn;a ÏÌ cos (qa/2), (17.207)
</p>
<p>respectively, where the positive (negative) sign holds when q is positive (negative). At
the boundary of the Brillouin zone it is qa/2 = Ï/2, whenceÏ = 2 ÏÌ, uf = &plusmn;aÏÌ/Ï ,
u = 0. Near the center of the Brillouin zone it is Ï â aÏÌ |q|, uf â u â &plusmn;aÏÌ. At the
center it is Ï = 0.
</p>
<p>The dispersion relation (17.205) normalized to ÏÌ = &radic;Ï/Î¼ is shown in Fig. 17.26
as a function of qa/2. The range of the first Brillouin zone is&minus;Ï/2 &le; qa/2 &le; +Ï/2.
Remembering that the wavelength corresponding to q is Î» = 2Ï/q, the interval near
the origin, where the phase and group velocities are equal to each other and indepen-
dent of q, corresponds to the largest values of the vibrations&rsquo; wavelength. As some
of these wavelengths fall in the audible range, the branch is called acoustic branch.</p>
<p/>
</div>
<div class="page"><p/>
<p>17.8 Complements 363
</p>
<p>Fig. 17.26 Normalized
dispersion relation of a linear,
monatomic chain. The
vertical lines, placed at
a q/2 = &plusmn;Ï/2, are the limits
of the first Brillouin zone
</p>
<p>-2 -1 0 1 2
a q / 2
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>1.5
</p>
<p>2
</p>
<p>Ï
 /
</p>
<p> (
 Ï
</p>
<p> /
 Î¼
</p>
<p> )
1
</p>
<p>/2
</p>
<p>17.8.6 Linear, Diatomic Chain
</p>
<p>As a second example, consider a one-dimensional lattice made of Nc cells, with a
two-atom basis. Let the lattice be aligned with the x axis, and the corresponding
characteristic vector be a = a i, a &gt; 0, with i the unit vector of the x axis. Finally,
let the positions of the Nc + 1 nodes be 0, a, 2 a, . . . , n a, . . . . The translation vector
associated to the nth node is ln = n a i. Finally, it is assumed that the motion of each
atom is constrained to the x axis, and the periodic boundary conditions are applied.
</p>
<p>Due to the periodic boundary conditions the nodes of indices n = 0 and n = Nc
are actually the same node. As a one-dimensional case is considered, with Nb = 2,
the total number of atoms is N = 2Nc. The number of degrees of freedom of the
lattice is 2Nc, and the correspondence with the indices (17.124) used in the general
theory of Sect. 17.7 is
</p>
<p>m, n = 1, . . . ,Nc, Î±,Î² = 1, 2, u, w = 1. (17.208)
</p>
<p>As two atoms per cell are present, one may assume that the equilibrium position of
one type of nucleus coincides with that of a node. Such nuclei will be given the index
Î±,Î² = 1, while the other nuclei will be given the index Î±,Î² = 2. In the harmonic
approximation the force acting on a nucleus is a linear function of the displacements:
</p>
<p>Fr = &minus;
2Nc&sum;
</p>
<p>k=1
crk hk. (17.209)
</p>
<p>In real crystals, the interaction between nuclei becomes rapidly negligible as the
distance increases. Following the same reasoning as in Sect. 17.8.5, the dynamics
of a nucleus is tackled in a simplified manner by considering only the interaction
with the neighboring nuclei to be effective. This is equivalent to letting crk = 0 when
|r&minus;k| &gt; 1. For a nucleus of type 1 the neighboring nuclei are of type 2. It is assumed</p>
<p/>
</div>
<div class="page"><p/>
<p>364 17 Periodic Structures
</p>
<p>that the node numbering is such, that the neighbors of interest belong to the cells of
indices r &minus; 1 and r . It follows
</p>
<p>Fr ,1 = &minus;cr&minus;1,2r ,1 hr&minus;1,2 &minus; cr ,1r ,1 hr ,1 &minus; cr ,2r ,1 hr ,2 = Fr ,1(hr&minus;1,2,hr ,1,hr ,2). (17.210)
</p>
<p>In the coefficients of (17.210), the left-lower index refers to the node being acted
upon by the force at the left hand side, the left-upper index refers to the node whose
displacement contributes to such a force, the right-lower and right-upper indices
refer to the nucleus type. When the nuclei involved are in the equilibrium positions
it is Fr ,1(0, 0, 0) = 0. On the other hand, it is also Fr ,1(Î´, Î´, Î´) = 0, with Î´ ï¿½= 0
an arbitrary displacement. In fact, when all displacements are equal the interatomic
distance remains the same as in the equilibrium condition. From Fr ,1(Î´, Î´, Î´) = 0 it
follows
</p>
<p>c
r&minus;1,2
r ,1 + cr ,1r ,1 + cr ,2r ,1 = 0. (17.211)
</p>
<p>As on the other hand there is no special symmetry in the interaction of the nucleus
of indices r , 1 with the neighboring ones, it is in general (in contrast to the case of
a monatomic linear chain) cr&minus;1,2r ,1 ï¿½= cr ,2r ,1. Finally, the relation Fr ,1(0, Î´, 0) = &minus;cr ,1r ,1 Î´,
on account of the fact that (0, 0, 0) is an equilibrium condition, shows that cr ,1r ,1 &gt; 0.
</p>
<p>The calculation is then repeated for a nucleus of type 2, whose neighboring nuclei
are of type 1. Due to the node numbering chosen here, the neighbors of interest
belong to the cells of indices r and r + 1. As a consequence,
</p>
<p>Fr ,2 = &minus;cr ,1r ,2 hr ,1 &minus; cr ,2r ,2 hr ,2 &minus; cr+1,1r ,2 hr+1,1 = Fr ,2(hr ,1,hr ,2,hr+1,1). (17.212)
</p>
<p>By the same reasoning leading to (17.211) one finds
</p>
<p>c
r ,1
r ,2 + cr ,2r ,2 + cr+1,1r ,2 = 0, (17.213)
</p>
<p>where, like in the case of (17.211), it is in general cr ,1r ,2 ï¿½= cr+1,1r ,2 . Finally, the relation
Fr ,2(0, Î´, 0) = &minus;cr ,2r ,2 Î´, on account of the fact that (0, 0, 0) is an equilibrium condition,
shows that cr ,2r ,2 &gt; 0. Due to the lattice periodicity the coefficients do not depend on
the cell index, whence one lets
</p>
<p>&minus;Ï1 = cr&minus;1,2r&minus;1,1 = cr ,2r ,1 = cr+1,2r+1,1 = . . . &minus; Ï2 = cr&minus;1,2r ,1 = cr ,2r+1,1 = cr+1,2r+2,1 = . . .
(17.214)
</p>
<p>Remembering the invariance relation cnÎ²wmÎ±u = cmÎ±unÎ²w of the general theory one also
finds
</p>
<p>c
r ,1
r ,2 = cr ,2r ,1 = &minus;Ï1, cr+1,1r ,2 = cr ,2r+1,1 = cr&minus;1,2r ,1 = &minus;Ï2, (17.215)
</p>
<p>whence
</p>
<p>c
r ,1
r ,1 = cr ,2r ,2 = Ï1 + Ï2 &gt; 0. (17.216)</p>
<p/>
</div>
<div class="page"><p/>
<p>17.8 Complements 365
</p>
<p>Finally, from the relations Fr ,1(0, 0, Î´) = Ï1 Î´, Fr ,1(Î´, 0, 0) = Ï2 Î´, it follows that
Ï1 &gt; 0, Ï2 &gt; 0, on account of the fact that (0, 0, 0) is an equilibrium condition.
Letting Î¼1, Î¼2 be the masses of the two types of nuclei, the dynamics of the rth
nuclei is described by the equations
</p>
<p>Î¼1 hÌr ,1 = &minus;Ï1
(
</p>
<p>hr ,1 &minus; hr ,2
)
</p>
<p>&minus; Ï2
(
</p>
<p>hr ,1 &minus; hr&minus;1,2
)
</p>
<p>, (17.217)
</p>
<p>Î¼2 hÌr ,2 = &minus;Ï1
(
</p>
<p>hr ,2 &minus; hr ,1
)
</p>
<p>&minus; Ï2
(
</p>
<p>hr ,2 &minus; hr+1,1
)
</p>
<p>, (17.218)
</p>
<p>where the displacements have the form
</p>
<p>hr ,1(2) = h0,1(2) exp (i qra &minus; iÏt) , (17.219)
</p>
<p>thanks to the general theory. In (17.219), h0,1, h0,2 are complex constants, q r a =
q &middot; lr = q i &middot;r a i, and Ï = Ï(q). Replacing (17.219) in (17.217, 17.218) and dividing
by hr ,1, hr ,2, respectively, yields
</p>
<p>Î¼1 Ï
2 h0,1 = Ï1
</p>
<p>(
</p>
<p>h0,1 &minus; h0,2
)
</p>
<p>+ Ï2
[
</p>
<p>h0,1 &minus; h0,2 exp ( &minus; i qa)
]
</p>
<p>, (17.220)
</p>
<p>Î¼2 Ï
2 h0,2 = Ï1
</p>
<p>(
</p>
<p>h0,2 &minus; h0,1
)
</p>
<p>+ Ï2
[
</p>
<p>h0,2 &minus; h0,1 exp ( + i qa)
]
</p>
<p>. (17.221)
</p>
<p>Defining A11, A12, A21, A22 such that
</p>
<p>Î¼1 A11 = Ï1 + Ï2, &minus;Î¼1 A12 = Ï1 + Ï2 exp ( &minus; i qa), (17.222)
</p>
<p>Î¼2 A22 = Ï1 + Ï2, &minus;Î¼2 A21 = Ï1 + Ï2 exp ( + i qa), (17.223)
</p>
<p>the homogeneous algebraic system (17.220, 17.221) transforms into
(
</p>
<p>A11 &minus; Ï2
)
</p>
<p>h0,1 + A12 h0,2 = 0, A21 h0,1 +
(
</p>
<p>A22 &minus; Ï2
)
</p>
<p>h0,2 = 0. (17.224)
</p>
<p>The trace T = A11 + A22 and determinant D = A11 A22 &minus; A12 A21 of the matrix
formed by A11, A12, A21, A22 read
</p>
<p>T = Î¼1 + Î¼2
Î¼1Î¼2
</p>
<p>(Ï1 + Ï2) , D = 2
Ï1 Ï2
</p>
<p>Î¼1 Î¼2
[1 &minus; cos (qa)] . (17.225)
</p>
<p>The eigenvaluesÏ2 are found by solving the algebraic equation (Ï2)2&minus;T Ï2+D = 0,
whose discriminant is
</p>
<p>ï¿½(q) = T 2 &minus; 4D =
[
</p>
<p>(Ï1 + Ï2) (Î¼1 + Î¼2)
Î¼1 Î¼2
</p>
<p>]2
</p>
<p>+ 8 Ï1 Ï2
Î¼1 Î¼2
</p>
<p>[cos (qa) &minus; 1] .
(17.226)
</p>
<p>Remembering that Ï1,Ï2 &gt; 0, the minimum ï¿½m of (17.226) occurs for q = &plusmn;Ï/2.
Letting KÏ = (Ï1 &minus; Ï2)2/(4Ï1 Ï2) &ge; 0 and KÎ¼ = (Î¼1 &minus; Î¼2)2/(4Î¼1 Î¼2) &ge; 0, one
finds the relation
</p>
<p>ï¿½(q) &ge; ï¿½m = 16
Ï1 Ï2
</p>
<p>Î¼1 Î¼2
</p>
<p>[(
</p>
<p>1 +KÏ
) (
</p>
<p>1 +KÎ¼
)
</p>
<p>&minus; 1
]
</p>
<p>&ge; 0, (17.227)</p>
<p/>
</div>
<div class="page"><p/>
<p>366 17 Periodic Structures
</p>
<p>Fig. 17.27 Normalized
dispersion relation of a linear,
diatomic chain with
Î¼1 = Î¼2 = Î¼ and Ï1 = 3Ï2.
The vertical lines, placed at
a q/2 = &plusmn;Ï/2, are the limits
of the first Brillouin zone
</p>
<p>-2 -1 0 1 2
q a / 2
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>1.5
</p>
<p>Ï
 /
</p>
<p> [
 (
</p>
<p>Ï
1
 +
</p>
<p> Ï
2
) 
</p>
<p>/ 
Î¼
</p>
<p> ]
1
/2
</p>
<p>showing that the discriminant is non negative. It follows that the eigenvalues Ï2 are
real, as should be. The solution of the algebraic equation provides two branches of
the dispersion relation, to be found by taking the square root of
</p>
<p>Ï2 = T
2
&plusmn; 1
</p>
<p>2
</p>
<p>&radic;
</p>
<p>ï¿½(q). (17.228)
</p>
<p>Observing that ï¿½(0) = T 2, one finds that selecting the minus sign in (17.228)
provides the branch that contains Ï = 0. As in the case of the monatomic chain, this
branch is called acoustic branch. In the other branch it is always Ï &gt; 0; in ionic
crystals like, e.g., sodium chloride, the frequencies typical of this branch are excited
by infrared radiation. For this reason, the branch is called optical branch.
</p>
<p>The acoustic and optical branch of a linear, diatomic chain are shown in Fig. 17.27,
where Î¼1 = Î¼2 = Î¼ is assumed for simplicity. Letting ÏÌ =
</p>
<p>&radic;
(Ï1 + Ï2)/Î¼, one
</p>
<p>finds for the acoustic branch
</p>
<p>Ï2ac
</p>
<p>ÏÌ2
= 1 &minus;
</p>
<p>[
</p>
<p>1 &minus; 4 Ï1 Ï2
(Ï1 + Ï2)2
</p>
<p>sin2
(qa
</p>
<p>2
</p>
<p>)
]1/2
</p>
<p>. (17.229)
</p>
<p>At the center of the first Brillouin zone it is Ïac = 0, while the maximum of Ïac is
reached at the boundary qa/2 = &plusmn;Ï/2 of the zone. For the optical branch one finds
</p>
<p>Ï2op
</p>
<p>ÏÌ2
= 1 +
</p>
<p>[
</p>
<p>1 &minus; 4 Ï1 Ï2
(Ï1 + Ï2)2
</p>
<p>sin2
(qa
</p>
<p>2
</p>
<p>)
]1/2
</p>
<p>. (17.230)
</p>
<p>At the center of the first Brillouin zone Ïop reaches its maximum. The minimum of
Ïop is reached at the boundary qa/2 = &plusmn;Ï/2 of the zone. The discretization of q
due to the periodic boundary conditions, and the definitions of the phase and group
velocity, are the same as those already given for the monatomic lattice.
</p>
<p>From (17.229, 17.230), the distance G = Ïop(q = &plusmn;Ï/a) &minus; Ïac(q = &plusmn;Ï/a)
between the minimum of the optical branch and the maximum of the acoustic branch</p>
<p/>
</div>
<div class="page"><p/>
<p>17.8 Complements 367
</p>
<p>fulfills the relation
</p>
<p>G
</p>
<p>ÏÌ
=
</p>
<p>(
</p>
<p>1 + |Ï1 &minus; Ï2|
Ï1 + Ï2
</p>
<p>)1/2
</p>
<p>&minus;
(
</p>
<p>1 &minus; |Ï1 &minus; Ï2|
Ï1 + Ï2
</p>
<p>)1/2
</p>
<p>. (17.231)
</p>
<p>It is G &gt; 0 if Ï2 ï¿½= Ï1, whereas G = 0 if Ï2 = Ï1. The latter case is called
degenerate.
</p>
<p>17.8.7 Analogies
</p>
<p>It is interesting to note the analogy between the expression of the energy of the
electromagnetic field in vacuo, described as a superposition of modes (Eqs. (5.38,
5.40)), and that of a system of vibrating nuclei (Eqs. (3.48) and (17.118)). In essence,
the two expressions derive from the fact the in both cases the energy is a positive-
definite, symmetric quadratic form. In the case of the electromagnetic field the form
is exact because of the linearity of the Maxwell equations; for the vibrating nuclei the
form is approximate because of the neglect of the anharmonic terms (Sect. 3.13.1).
</p>
<p>Other analogies exist between the dispersion relation E(k) of the electrons sub-
jected to a periodic potential energy, worked out in Sect. 17.6, and the dispersion
relation Ï(q), worked out in Sect. (17.7). Both relations are even and periodic in the
reciprocal, scaled lattice; both have a branch structure, the difference being that the
number of branches of Ï(q) is finite because the number of degrees of freedom of
the vibrating lattice is finite, whereas that of E(k) is infinite.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 18
</p>
<p>Electrons and Holes in Semiconductors
at Equilibrium
</p>
<p>18.1 Introduction
</p>
<p>Purpose of this chapter is providing the equilibrium expressions of the electron and
hole concentrations in a semiconductor. For comparison, the cases of insulators and
conductors are discussed qualitatively, and the concepts of conduction band, valence
band, and generation of an electron-hole pair are introduced. The important issue
of the temperature dependence of the concentrations is also discussed. Then, the
general expressions of the concentrations in an intrinsic semiconductor are worked
out, followed by an estimate of the Fermi level&rsquo;s position. Next, the equilibrium ex-
pressions are worked out again, this time in the case where substitutional impurities
of the donor or acceptor type are present within the semiconductor. The mecha-
nism by which donor-type dopants provide electrons to the conduction band, and
acceptor-type dopants provide holes to the valence band, is explained. An important
outcome of the analysis is that the introduction of suitable dopants makes the con-
centration of majority carriers practically independent of temperature, at least in a
range of temperatures of practical interest for the functioning of integrated circuits.
The simplifications due to the complete-ionization and non-degeneracy conditions
are illustrated, along with the compensation effect. Finally, the theory is extended to
the case of a non-uniform doping distribution, where the concentrations must be cal-
culated self-consistently with the electric potential by solving the Poisson equation.
The last section illustrates the band-gap narrowing phenomenon. In the comple-
ments, after a brief description of the relative importance of germanium, silicon, and
gallium arsenide in the semiconductor industry, a qualitative analysis of the impurity
levels is carried out by an extension of the Kronig&ndash;Penney model, and the calculation
of the position of the impurity levels with respect to the band edges is carried out.
</p>
<p>&copy; Springer Science+Business Media New York 2015 369
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_18</p>
<p/>
</div>
<div class="page"><p/>
<p>370 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>Fig. 18.1 Description of the
particles&rsquo; population in the
conduction and valence bands
of an insulator. To make them
more visible, the products
g(E)P (E) and
g(E) [1 &minus; P (E)] have been
amplified, with respect to
g(E) alone, by a factor
2 &times; 1031 (compare with
Figs. 17.14 and 18.2). The
gap&rsquo;s extension is arbitrary
and does not refer to any
specific material
</p>
<p>-0.4 -0.2 0 0.2 0.4
(E - E
</p>
<p>F
) / (k
</p>
<p>B
 T)
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>P
(E
</p>
<p>)
[g
</p>
<p>(E
) 
</p>
<p>in
 a
</p>
<p>rb
it
</p>
<p>ra
ry
</p>
<p> u
n
it
</p>
<p>s]
</p>
<p>Fermi-Dirac statistics P(E)
</p>
<p>g(E), conduction band
</p>
<p>g(E) P(E), cond. band
</p>
<p>g(E), valence band
</p>
<p>g(E) [1 - P(E)], val. band
</p>
<p>18.2 Equilibrium Concentration of Electrons and Holes
</p>
<p>The expressions worked out in this chapter are obtained by combining the information
about the band structure of the crystal under investigation, given in Chap. 17, with
that of the equilibrium distribution of fermions (Chap. 15). A qualitative description
is given first, starting from the simplified case where the structures of the conduction
and valence band are symmetric (Fig. 17.14).
</p>
<p>Considering again a case where the Fermi level EF coincides with the gap&rsquo;s
midpoint andMV m
</p>
<p>3/2
h = MC m
</p>
<p>3/2
e , let the only difference with respect to the material
</p>
<p>of Fig. 17.14 be that the energy gap is larger (Fig. 18.1). Despite the fact that the
situations illustrated in the two figures may appear similar to each other, it must be
realized that a 2&times;1031 amplification factor, with respect to the scale of g(E) alone, is
necessary to make the products g(E)P (E), g(E) [1 &minus; P (E)] visible in Fig. 18.1, in
contrast to the 103 factor used in Fig. 17.14. In practice, for the material of Fig. 18.1
the states in the conduction band are empty and those of the valence band are full.1
</p>
<p>Remembering that a band whose states are empty and, similarly, a band whose states
are fully occupied, do not provide any conduction, it turns out that the electrical
conductivity of a material like that of Fig. 18.1 is expected to vanish: the material is
an insulator.
</p>
<p>A different case is found when the Fermi level is inside a band, like in the crystal
illustrated in Fig. 18.2. The name conduction band is given in this case to the band
where the Fermi level belongs; the band beneath is called valence band also in this
case. Due to the position of the Fermi level, the parabolic-band approximation is
</p>
<p>1 The curves of Figs. 17.14, 18.1 are drawn in arbitrary units. To better appreciate the difference in
a practical situation, one may use the equilibrium concentration of electrons in silicon at T = 300
K, which is about 1016 m&minus;3. Thus, if Fig. 17.14 is thought of as representing silicon, the ratio of the
amplification factors used in Figs. 17.14 and 18.1 produces, in the latter, a concentration of about
one electron in 1000 km3.</p>
<p/>
</div>
<div class="page"><p/>
<p>18.2 Equilibrium Concentration of Electrons and Holes 371
</p>
<p>Fig. 18.2 Description of the
electron population in the
conduction band of a
conductor. The product
g(E)P (E) is drawn in the
same scale as g(E) alone
(compare with Figs. 17.14
and 18.1). The gap&rsquo;s
extension is arbitrary and
does not refer to any specific
material
</p>
<p>-0.4 -0.2 0 0.2 0.4
(E - E
</p>
<p>F
) / (k
</p>
<p>B
 T)
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>P
(E
</p>
<p>) 
[g
</p>
<p>(E
) 
</p>
<p>in
 a
</p>
<p>rb
it
</p>
<p>ra
ry
</p>
<p> u
n
it
</p>
<p>s]
</p>
<p>Fermi-Dirac statistics P(E)
</p>
<p>g(E), conduction band
</p>
<p>g(E) P(E), cond. band
</p>
<p>g(E), valence band
</p>
<p>grossly mistaken, and is used for a qualitative discussion only. In the figure, the
g(E)P (E) product is drawn without using any amplification factor, this showing
that the electron concentration in the conduction band is much larger than for a
semiconductor; the latter band, in turn, is the only one that contributes to conduction,
because the concentration of holes in the valence band is negligible. Due to the much
larger concentration of charges one expects that the conductivity of the crystal under
investigation be large; in fact, this is found to be the case, and the crystal is a
conductor.
</p>
<p>In summary, the combination of a few factors: position of the Fermi level with
respect to the bands, gap&rsquo;s width, and structure of the density of states, dictates the
presence of partially-filled bands and the concentration of charges in them. Other
situations may occur besides those depicted in Figs. 17.14, 18.1, and 18.2, e.g., the
Fermi level may be positioned within the gap, but closer to one of the band edges
than to the other. They are illustrated in Sects. 18.4.1 and 18.4.2.
</p>
<p>Another important issue is the dependence of the electron and hole populations
on temperature. Considering the case of a semiconductor first, the discussion is car-
ried out with reference to Figs. 17.14 and 15.3; the latter illustrates the temperature
dependence of the Fermi-Dirac statistics, using the simplifying hypothesis that the
position of the Fermi level does not change with temperature.2 Following the reason-
ing carried out in Sect. 17.6.5, the temperature dependence of the effective masses
is neglected as well. When temperature increases, the occupation probability of the
conduction-band states increases, this making the concentration of electrons in the
conduction band to increase; at the same time, the occupation probability of the
valence-band states decreases, this making the concentration of holes in the valence
band to increase as well. This outcome is easily understood if one thinks that the
increase in temperature is achieved by transferring energy from an external reservoir
</p>
<p>2 The temperature dependence of the Fermi level is influenced by the shape of the density of states
[54]. Such a dependence can be neglected in the qualitative discussion carried out here.</p>
<p/>
</div>
<div class="page"><p/>
<p>372 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>to the semiconductor; part of this energy is absorbed by the nuclei and produces a
change in the equilibrium distribution of phonons (Sect. 16.6), while the other part
is absorbed by the electrons and produces a redistribution of the latter within the
available energy states. The absorption of energy by electrons that, prior to the tem-
perature increase, belonged to valence-band states, makes some of them to transit
to the conduction band. As each electron that makes a transition leaves a hole in the
valence band, this is an example of generation of an electron&ndash;hole pair (compare
with Sect. 17.6.6).
</p>
<p>As shown in Sect. 19.5.5, the conductivity of a semiconductor is proportional
to Î¼n n + Î¼p p, where n is the concentration of conduction-band electrons, p the
concentration of valence-band holes, and Î¼n, Î¼p the electron and hole mobilities,
respectively. Mobilities account for the scattering events undergone by electrons and
holes during their motion within the material, and are found to decrease when tem-
perature increases. It follows that the decrease in mobility competes with the increase
of the concentrations in determining the temperature dependence of conductivity in
a semiconductor. In practice, the increase in the concentrations is much stronger due
to the exponential form of the Fermi-Dirac statistics, so that the conductivity of a
semiconductor strongly increases with temperature.3
</p>
<p>The qualitative analysis of conductivity is the same for a conductor where, as
holes are absent, the conductivity is proportional to Î¼n n. However, the outcome is
different; in fact, while Î¼n, like that of a semiconductor, decreases when temper-
ature increases, the electron concentration n is unaffected by temperature. In fact,
from Fig. 18.2 one finds that the deformation of the Fermi-Dirac statistics due to a
temperature variation produces a rearrangement of the electron distribution within
the conduction band itself, and no electron-hole generation; as a consequence, the
energies of some electrons of the conduction band change, while the electron number
(hence the concentrationn) does not. As mobility depends weakly on temperature, the
conductivity of a conductor turns out to slightly decrease as temperature increases.
</p>
<p>The calculation of the equilibrium electron concentration in the conduction band of
a semiconductor is based on (17.76), where the density of states in energyg is replaced
with the combined density of states in energy and volume Î³ given by (17.73). The
concentration of electrons and the Fermi level are indicated here with ni , EFi instead
of n, EF to remark the fact that the semiconductor is free from impurities (for this
reason, the semiconductor is called intrinsic). From the discussion of Sect. 17.6.5,
the parabolic-band approximation is acceptable, so that the combined density of
states is given by (17.73).4 Remembering that the lower edge of the conduction band
is indicated with EC , and letting ECU be the upper edge of the same band, one finds
</p>
<p>ni =
&int; ECU
</p>
<p>EC
</p>
<p>Î³ (E)P (E) dE â
&int; +&infin;
</p>
<p>EC
</p>
<p>&radic;
2MC m
</p>
<p>3/2
e
</p>
<p>&radic;
E &minus; EC/(Ï2 hÌ3)
</p>
<p>exp [(E &minus; EFi)/(kB T )] + 1
dE, (18.1)
</p>
<p>3 This is a negative aspect because the electrical properties of the material are strongly influenced
by the ambient temperature. The drawback is absent in doped semiconductors, at least in the range
of temperatures that are typical of the operating conditions of semiconductor devices (Sect. 18.4.1).
4 As before, the band index is dropped from (17.73).</p>
<p/>
</div>
<div class="page"><p/>
<p>18.2 Equilibrium Concentration of Electrons and Holes 373
</p>
<p>where the upper integration limit has been replaced with +&infin; on account of the
fact that the integrand vanishes exponentially at high energies. Using the auxiliary
variables
</p>
<p>Î¶e = EC &minus; EFi , x =
E &minus; EC
kB T
</p>
<p>&ge; 0, Î¾e = &minus;
Î¶e
</p>
<p>kB T
, (18.2)
</p>
<p>with x, Î¾e dimensionless, transforms (18.1) into
</p>
<p>ni =
&radic;
</p>
<p>2
</p>
<p>Ï2hÌ3
MCm
</p>
<p>3/2
e (kB T )
</p>
<p>3/2
&int; +&infin;
</p>
<p>0
</p>
<p>&radic;
x
</p>
<p>exp (x &minus; Î¾e) + 1
dx. (18.3)
</p>
<p>From the definition (C.109) of the Fermi integral of order 1/2 it then follows
</p>
<p>ni = NC Î¦1/2(Î¾e), NC = 2MC
(
</p>
<p>me
</p>
<p>2Ï hÌ2
kB T
</p>
<p>)3/2
</p>
<p>, (18.4)
</p>
<p>with NC the effective density of states of the conduction band. Observing that Î¦1/2
is dimensionless, the units of NC are m&minus;3.
</p>
<p>The concentration of holes in the valence band is determined in a similar manner,
namely, starting from an integral of the form (17.76), where P (E) is replaced with
1&minus;P (E) and the density of states in energy g is replaced with the combined density
of states in energy and volume Î³ . The concentration of holes is indicated here with
pi and, as for the electrons, the parabolic-band approximation is adopted, so that the
combined density of states is obtained from (17.74). Finally, 1 &minus; P (E) is expressed
through (17.77). Remembering that the upper edge of the valence band is indicated
with EV , and letting EVL be the lower edge of the same band, one finds
</p>
<p>pi =
&int; Ev
</p>
<p>EVL
</p>
<p>Î³ (E) [1 &minus; P (E)] dE â
&int; EV
</p>
<p>&minus;&infin;
</p>
<p>&radic;
2MV m
</p>
<p>3/2
h
</p>
<p>&radic;
EV &minus; E/(Ï2 hÌ3)
</p>
<p>exp [(EFi &minus; E)/(kB T )] + 1
dE,
</p>
<p>(18.5)
</p>
<p>where the lower integration limit has been replaced with &minus;&infin; on account of the
fact that the integrand vanishes exponentially at low energies. Using the auxiliary
variables
</p>
<p>Î¶h = EFi &minus; EV , x =
EV &minus; E
kB T
</p>
<p>&ge; 0, Î¾h = &minus;
Î¶h
</p>
<p>kB T
, (18.6)
</p>
<p>transforms (18.5) into
</p>
<p>pi =
&radic;
</p>
<p>2
</p>
<p>Ï2hÌ3
MVm
</p>
<p>3/2
h (kB T )
</p>
<p>3/2
&int; +&infin;
</p>
<p>0
</p>
<p>&radic;
x
</p>
<p>exp (x &minus; Î¾h) + 1
dx, (18.7)
</p>
<p>whence, introducing the effective density of states of the valence band, NV ,
</p>
<p>pi = NV Î¦1/2(Î¾h), NV = 2MV
(
</p>
<p>mh
</p>
<p>2Ï hÌ2
kB T
</p>
<p>)3/2
</p>
<p>. (18.8)</p>
<p/>
</div>
<div class="page"><p/>
<p>374 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>Table 18.1 Gap and average effective masses of silicon, germanium, and gallium arsenidea
</p>
<p>Material EG0 (eV) Î± (eV/K) Î² (K) EG(Ta) me/m0 mh/m0
</p>
<p>Si 1.160 7.02 &times; 10&minus;4 1108 1.12 0.33 0.56
Ge 0.741 4.56 &times; 10&minus;4 210 0.66 0.22 0.31
GaAs 1.522 5.80 &times; 10&minus;4 300 1.43 0.68 0.50
</p>
<p>aSymbol Ta indicates the room temperature
</p>
<p>18.3 Intrinsic Concentration
</p>
<p>Equations (18.2, 18.4) and (18.6, 18.8) express the equilibrium concentrations of
electron and holes in a semiconductor in terms of temperature and of the distance of
the Fermi level from the edge EC of the conduction band or, respectively, from the
edge EV of the valence band. Obiouvsly the two distances are not independent from
each other; from (18.2, 18.6) one finds in fact
</p>
<p>&minus;(Î¾e + Î¾h) =
Î¶e + Î¶h
kB T
</p>
<p>= EC &minus; EFi + EFi &minus; EV
kB T
</p>
<p>= EG
kB T
</p>
<p>, (18.9)
</p>
<p>where EG = EC &minus;EV is the extension of the semiconductor&rsquo;s gap, known from the
calculation of the band structure, or also from electrical or optical measurements. As
the band structure is influenced by temperature, the gap depends on temperature as
well (Sect. 17.6.5); such a dependence is important because it strongly influences the
concentration of electrons and holes. The results of gap&rsquo;s calculations or measure-
ments, that show thatEG decreases when temperature increases, are usually rendered
in compact form by means of interpolating expressions, an example of which is
</p>
<p>EG(T ) &asymp; EG0 &minus; Î±
T 2
</p>
<p>T + Î² , (18.10)
</p>
<p>where EG0 is the gap&rsquo;s width extrapolated at T = 0 and Î± &gt; 0, Î² &gt; 0 are material&rsquo;s
parameters. Table 18.1 reports the parameters related to the gap&rsquo;s width for Si, Ge,
and GaAs, along with the values of the average effective masses normalized to the
rest mass of the free electron [103, Chap. 2&ndash;3]. The plot of EG(T ) is shown in
Fig. 18.3 for the three semiconductors of Table 18.1.
</p>
<p>Note that expressions (18.4, 18.8) can be used only if the position of the Fermi
level is known; in fact, the latter (which is unknown as yet) enters the definitions
(18.2, 18.6) of parameters Î¾e, Î¾h. To proceed one remembers that in the T &rarr; 0
limit the Fermi-Dirac statistics becomes discontinuous, specifically it is P = 1 for
E &lt; EFi and P = 0 for E &gt; EFi (Sect. 15.8.1); on the other hand, the experimental
evidence shows that in the T &rarr; 0 limit the conductivity of a semiconductor vanishes:
this corresponds to a situation where all states of the conduction band are empty while
those of the valence bands are filled. In conclusion, when T &rarr; 0 the Fermi level
is still positioned in the gap and it is ni = pi = 0. If, starting from this situation,
the temperature is brought again to some finite value T &gt; 0, such that some of the</p>
<p/>
</div>
<div class="page"><p/>
<p>18.3 Intrinsic Concentration 375
</p>
<p>Fig. 18.3 Plot of the gap
as a function of temperature
for Ge, Si, and GaAs. The
vertical line marks T = 300 K
</p>
<p>0 100 200 300 400 500 600
T (K)
</p>
<p>0
</p>
<p>0.4
</p>
<p>0.8
</p>
<p>1.2
</p>
<p>1.6
</p>
<p>2
</p>
<p>E
G
</p>
<p>(e
V
</p>
<p>)
</p>
<p>Ge
Si
GaAs
</p>
<p>valence-band electrons transit to the conduction band, the total number of holes thus
formed equals that of the transited electrons. Due to the spatial uniformity of the
material, the concentrations are equal to each other as well; in conclusion it is5
</p>
<p>ni = pi , MC m3/2e Î¦1/2(Î¾e) = MV m3/2h Î¦1/2(Î¾h), (18.11)
</p>
<p>the second of which has been obtained by deleting the common factors from (18.4)
and (18.8). Relations (18.9) and (18.11) are a set of two equations in the unknowns
Î¾e, Î¾h, whose solution allows one to determine the position of the Fermi level through
(18.2) or (18.6).
</p>
<p>The second relation in (18.11) can also be exploited for carrying out an estimate
of Î¾e, Î¾h, basing on the values of the masses given in Table 18.1. To this purpose
one observes6 that the ratio MC m
</p>
<p>3/2
e /(MV m
</p>
<p>3/2
h ) is about 1.4, 1.2, 0.8 for Si, Ge,
</p>
<p>and GaAs, respectively, so that a crude estimate is obtained by letting Î¦1/2(Î¾e) â
Î¦1/2(Î¾h). As the Fermi integral is a monotonic function of the argument (Sect. C.13),
it follows Î¾e â Î¾h. Replacing from (18.2, 18.6) yields EFi â (EC + EV )/2, and
Î¶e â Î¶h â EG/2 &gt; 0.
</p>
<p>The usefulness of this estimate actually lies in that it simplifies the Fermi integrals.
Taking for instance the case of room temperature, it is kB Ta â 26 meV; using the
values of EG(Ta) from Table 18.1 shows that EG â« kBTa , whence &minus;Î¾e â« 1 and
&minus;Î¾h â« 1, so that the approximate expression (C.105) applies: Î¦1/2(Î¾ ) â exp (Î¾ ). In
conclusion, (18.4, 18.8) simplify to ni â NC exp (Î¾e), pi â NV exp (Î¾h), namely,
</p>
<p>ni â NC exp
(
</p>
<p>&minus;EC &minus; EFi
kB T
</p>
<p>)
</p>
<p>, pi â NV exp
(
</p>
<p>&minus;EFi &minus; EV
kB T
</p>
<p>)
</p>
<p>. (18.12)
</p>
<p>5 Note that the reasoning leading to the first relation in (18.11) is not limited to the case of the
parabolic-band approximation, but holds for a general form of the densities of states.
6 Remembering the discussion carried out in Sect. 17.6.5 it is MC (Si) = 6, MC (Ge) = 4,
MC (GaAs) = 1, MV = 2.</p>
<p/>
</div>
<div class="page"><p/>
<p>376 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>As the two concentrations are equal to each other it is customary to use the same
symbol ni for both; the product of the two expressions (18.12) combined with (18.9)
yields
</p>
<p>ni pi = n2i â NC NV exp (Î¾e + Î¾h) = NC NV exp [ &minus; EG/(kB T )]. (18.13)
</p>
<p>The expression of the intrinsic concentration thus reads
</p>
<p>ni â
&radic;
</p>
<p>NC NV exp
</p>
<p>(
</p>
<p>&minus; EG
2 kB T
</p>
<p>)
</p>
<p>, NC NV =
MC MV
</p>
<p>2Ï3 hÌ6
(me mh)
</p>
<p>3/2 (kB T )
3 .
</p>
<p>(18.14)
</p>
<p>Its values at room temperature are listed in Table 18.2 along with those of the
effective densities of states, for Si, Ge, and GaAs. As for the temperature dependence
of ni one notes that, besides appearing in the exponent&rsquo;s denominator in the first
relation of (18.14), the lattice temperature also influences the numerator EG and the
NC NV factor. Among these dependencies, that of the exponent&rsquo;s denominator is by
far the strongest; it follows that a first-hand description of ni(T ) can be given by
considering only the latter. This yields the Arrhenius plots shown in Fig. 18.4, where
the relations ni(T ) reduce to straight lines. It is important to note that, despite the
similarity of the effective densities of states for the three semiconductors considered
here (Table 18.2), the intrinsic concentrations differ by orders of magnitude. This is
due to the exponential dependence of ni on EG, which amplifies the differences in
EG (visible in Table 18.1) of the three semiconductors.
</p>
<p>The estimate of the position of the Fermi level in an intrinsic semiconductor carried
out above has led to the conclusion that the Fermi integrals used for calculating the
intrinsic concentrations can be replaced with exponentials.7 Such a conclusion can
now be exploited for a more precise calculation of the Fermi level&rsquo;s position, where
the coefficients of (18.11) are kept. Using the exponentials in (18.11) one finds
</p>
<p>MC m
3/2
e exp (Î¾e) = MV m3/2h exp (Î¾h). (18.15)
</p>
<p>Taking the logarithm of both sides and using (18.9) yields Î¾h&minus; Î¾e = Î¾h+ Î¾e&minus;2 Î¾e =
log [MC m
</p>
<p>3/2
e /(MV m
</p>
<p>3/2
h )], whence
</p>
<p>EC &minus; EFi =
EG
</p>
<p>2
+ kB T
</p>
<p>2
log
</p>
<p>(
</p>
<p>MC m
3/2
e
</p>
<p>MV m
3/2
h
</p>
<p>)
</p>
<p>. (18.16)
</p>
<p>The second term at the right hand side of (18.16) is the correction with respect to
the estimate carried out earlier. In the T &rarr; 0 limit, the Fermi level in the intrinsic
semiconductors under consideration coincides with the gap&rsquo;s midpoint. When the
temperature increases, if MC m
</p>
<p>3/2
e &gt; MV m
</p>
<p>3/2
h the distance EC &minus; EFi becomes
</p>
<p>7 This is not necessarily true for an extrinsic semiconductor, where suitable impurity atoms are
introduced into the semiconductor lattice (Sects. 18.4.1, 18.4.2).</p>
<p/>
</div>
<div class="page"><p/>
<p>18.4 Uniform Distribution of Impurities 377
</p>
<p>Table 18.2 Intrinsic
concentrations of silicon,
germanium, and gallium
arsenidea
</p>
<p>Material NC (Ta) (cm&minus;3) NV (Ta) (cm&minus;3) ni (Ta) (cm&minus;3)
</p>
<p>Si 2.82 &times; 1019 1.05 &times; 1019 7.61 &times; 109
</p>
<p>Ge 1.04 &times; 1019 0.43 &times; 1019 1.39 &times; 1012
</p>
<p>GaAs 4.45 &times; 1019 0.99 &times; 1019 2.40 &times; 106
aIn this field it is customary to express the concentrations in cm&minus;3 instead of m&minus;3
</p>
<p>Fig. 18.4 Arrhenius plot
of the intrinsic concentration
in Ge, Si, and GaAs. The
vertical line marks T = 300 K
</p>
<p>2 4 6 8 10
</p>
<p>1000 / T      ( K
-1
</p>
<p> )
</p>
<p>10
2
</p>
<p>10
4
</p>
<p>10
6
</p>
<p>10
8
</p>
<p>10
10
</p>
<p>10
12
</p>
<p>10
14
</p>
<p>10
16
</p>
<p>n
i  
</p>
<p>  
  
( 
</p>
<p>cm
-3
</p>
<p> )
</p>
<p>Ge
Si
GaAs
</p>
<p>larger, that is, the Fermi level moves towards the valence band; the opposite happens
if MC m
</p>
<p>3/2
e &lt; MV m
</p>
<p>3/2
h . For all practical purposes, considering that the argument of
</p>
<p>the logarithm in (18.16) is close to unity and the coefficient kB T is always small
with respect to EG, the position of the Fermi level can be thought of as coinciding
with the gap&rsquo;s midpoint.
</p>
<p>18.4 Uniform Distribution of Impurities
</p>
<p>As described in Chap. 23, the fabrication of integrated circuits (IC) requires the
introduction into the semiconductor material of atoms (called impurities or dopants)
belonging to specifically-selected chemical species. Dopants are divided into two
classes, termed n-type and p-type. With reference to silicon (Si), the typical n-type
dopants are phosphorus (P), arsenic (As), and antimony (Sb), while the typical p-
type dopants are boron (B), aluminum (Al), gallium (Ga), and Indium (In). For a
qualitative introduction to the effects of dopants it is instructive to start with the
case of an intrinsic semiconductor; the analysis is based on the simplified picture in
which the original arrangement of the atoms in space, like that shown in Fig. 17.11, is
deformed in such a way as to become two-dimensional. This representation, shown
in Fig. 18.5 with reference to silicon, is convenient for the description carried out
below. Each silicon atom has four electrons in the external shell, so that it can form</p>
<p/>
</div>
<div class="page"><p/>
<p>378 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>Fig. 18.5 Two-dimensional
representation of the intrinsic
silicon lattice. The upper-left
part of the figure shows the
T &rarr; 0 limit
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>SiSi
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>four covalent bonds8 with other identical atoms; each pair of lines connecting two
atoms in Fig. 18.5 stands for a pair of shared electrons. In the T &rarr; 0 limit, the
electrons are permanently bound to the atoms because the energy necessary to ionize
is not available; this situation is drawn in the upper-left part of the figure. If, instead,
the temperature is brought to some finite value T &gt; 0 by transferring energy from an
external reservoir to the semiconductor, part of this energy is absorbed by some of
the electrons; the latter break the bond and become free to move within the material.9
</p>
<p>This situation is depicted in the lower-right part of Fig. 18.5, where the free electrons
are represented with black dots.
</p>
<p>When an electron becomes free and departs from an atom, the unbalanced positive
charge left behind in the nucleus deforms the shape of the potential energy in the
vicinity of the nucleus itself. The deformation is such that the potential-energy barrier
that separates the nucleus from the neighboring ones becomes lower and thinner;
this, in turn, enhances the probability of tunneling across the barrier by an electron
belonging to a shared pair. Such a tunneling event restores the original pair, but
leaves an unbalanced positive charge behind; instead of considering it as the motion
of an electron from a complete to an incomplete pair, the tunneling event is more
conveniently described as the opposite motion of an empty state, that is, a hole. This
is indicated in Fig. 18.5 by the combinations of arrows and white dots.
</p>
<p>The above description, based on a spatial picture of the material, is able to provide
a qualitative explanation of the existence of electrons and holes in a semiconductor,10
</p>
<p>and completes the description given in Sect. 18.3, that focuses on an energy picture. It
also constitutes the basis for analyzing the case of a doped semiconductor, as shown
in the following sections.
</p>
<p>8 In a covalent bond atoms share their outermost electrons.
9 Remembering that an equilibrium situation is considered here, the contributions to the electric
current of these electrons cancel each other.
10 A similar description could as well apply to a conductor. However, in such as case the barrier
deformation is small and tunneling does not occur.</p>
<p/>
</div>
<div class="page"><p/>
<p>18.4 Uniform Distribution of Impurities 379
</p>
<p>Fig. 18.6 Two-dimensional
representation of the n-doped
silicon lattice. The upper-left
part of the figure shows the
T &rarr; 0 limit
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>P
Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>P
</p>
<p>18.4.1 Donor-Type Impurities
</p>
<p>As shown in Chap. 23, when a dopant atom is introduced into the semiconductor lat-
tice, in order to properly act as a dopant it must replace an atom of the semiconductor,
namely, it must occupy a lattice position (substitutional impurity). The concentration
of the dopant atoms that are introduced into a semiconductor is smaller by orders
of magnitude than the concentration of the semiconductor atoms themselves. As a
consequence, the average distance between dopant atoms within the lattice is much
larger than that between the semiconductor atoms. Due to this, when the band struc-
ture is calculated, the modification in the potential energy introduced by the dopant
atoms can be considered as a perturbation with respect to the periodic potential en-
ergy of the lattice; the resulting band structure is therefore the superposition of that
of the intrinsic semiconductor and of a set of additional states, whose characteristics
will be described later. For the moment being, the spatial description is considered,
still using the two-dimensional picture, where it is assumed that phosphorus is used
as dopant material (Fig. 18.6).
</p>
<p>As the dopant concentration is small with respect to the semiconductor&rsquo;s, each
phosphorus atom is surrounded by silicon atoms. Phosphorus has five electrons in the
external shell: thus, it forms four covalent bonds with silicon, while the remaining
electron does not participate in any bond. In the T &rarr; 0 limit, the electrons are
permanently bound to the atoms as in the intrinsic case; this situation is drawn in
the upper-left part of the figure, where the electron that does not form any bond is
represented, in a particle-like picture, as orbiting around the phosphorus atom. The
orbit&rsquo;s radius is relatively large because the binding force is weak.11 The white dot
inside the phosphorus atom indicates the positive nuclear charge that balances the
orbiting electron. If, instead, the temperature is brought to some finite value T &gt; 0
by transferring energy from an external reservoir to the semiconductor, a fraction of
</p>
<p>11 In a more precise, quantum-mechanical description the electron is described as a stationary wave
function extending over several lattice cells.</p>
<p/>
</div>
<div class="page"><p/>
<p>380 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>Fig. 18.7 Density of states in
an n-doped semiconductor.
The gap&rsquo;s extension is
arbitrary and does not refer to
any specific material
</p>
<p>-0.4 -0.2 0 0.2 0.4
(E - E
</p>
<p>F
) / (k
</p>
<p>B
 T)
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>g
(E
</p>
<p>) 
  
  
 (
</p>
<p>ar
b
it
</p>
<p>ra
ry
</p>
<p> u
n
it
</p>
<p>s)
</p>
<p>the orbiting electrons break the bond and become free to move within the material.
At the same time, electrons belonging to shared pairs may also break their bonds,
like in intrinsic silicon. This situation is depicted in the lower-right part of Fig. 18.6,
where the free electrons are represented with black dots.
</p>
<p>The deformation in the shape of the potential energy in the vicinity of a phosphorus
nucleus is different from that near a silicon nucleus. In the latter case, the phenomenon
is the same as in the intrinsic material: a series of tunneling events takes place, leading
to the motion of holes from one site to a neighboring one. This is still represented by
the combinations of arrows and white dots in Fig. 18.6. In the case of phosphorus,
instead, the barrier deformation is small and tunneling does not occur: thus, the
phosphorus atoms provide free electrons to the lattice, but no holes.
</p>
<p>It is intuitive that the insertion of a prescribed amount of n-type dopants into the
semiconductor lattice provides a method for controlling the number of free electrons
and, through them, the material&rsquo;s conductivity. Moreover, if the ionization of the
dopant atoms is not influenced by temperature, at least in a range of temperatures
of practical interest, and the number of electrons made available by the dopant is
dominant with respect to that provided by the intrinsic semiconductor, the drawback
mentioned in Sect. 18.2 is eliminated: conductivity becomes temperature indepen-
dent and its value is controlled by the fabrication process. This analysis is better
specified below, starting from the consideration of the density of states in an n-type
semiconductor, shown in Fig. 18.7.
</p>
<p>18.4.1.1 Concentration of Ionized Impurities (Donor Type)
</p>
<p>Atoms like that of phosphorus contribute electrons to the lattice; for this reason they
are also called donors. The concentration of donors is indicated with ND and, in
this section, is assumed to be uniform in space. When donor atoms are present, the
equilibrium concentrations of electrons and holes are different from those of the</p>
<p/>
</div>
<div class="page"><p/>
<p>18.4 Uniform Distribution of Impurities 381
</p>
<p>intrinsic case; they are indicated with n and p, respectively, and are termed extrinsic
concentrations. Their derivation is identical to that of the intrisic case and yields
</p>
<p>n = NC Î¦1/2(Î¾e), p = NV Î¦1/2(Î¾h), (18.17)
</p>
<p>with NC , NV given by (18.4, 18.8), respectively, and
</p>
<p>Î¾e = &minus;
Î¶e
</p>
<p>kB T
= &minus;EC &minus; EF
</p>
<p>kB T
, Î¾h = &minus;
</p>
<p>Î¶h
</p>
<p>kB T
= &minus;EF &minus; EV
</p>
<p>kB T
. (18.18)
</p>
<p>The above expression of Î¾e, Î¾h are similar to (18.2, 18.6), the only difference
being that the intrinsic Fermi level EFi is replaced here with the extrinsic Fermi level
EF .
</p>
<p>In addition to the electrons of the conduction band and holes of the valence band,
a third population of particles must be accounted for, namely, that associated to
the dopants. Let N+D &le; ND be the spatially-constant concentration of the ionized
donors.12 The difference nD = ND &minus; N+D is the concentration of the donor atoms
that have not released the orbiting electron to the lattice. Equivalently, nD may be
thought of as the concentration of orbiting electrons that have not been released; such
a concentration is given by
</p>
<p>nD =
&int;
</p>
<p>ï¿½ED
</p>
<p>Î³D(E)PD(E) dE, (18.19)
</p>
<p>where Î³D(E) is the combined density of states produced by the donor atoms, ï¿½ED
the energy range where Î³D(E) ï¿½= 0, and PD(E) the occupation probability of such
states. The form of Î³D depends on the concentration ND; for low or moderately-
high values of the donor concentration, Î³D has the form shown in Fig. 18.7. Such
a density of states can be approximated by a Dirac delta centered at an energy ED ,
called donor level, positioned within the gap at a small distance from the edge EC
of the conduction band:
</p>
<p>Î³D(E) â ND Î´(E &minus; ED). (18.20)
</p>
<p>The coefficient in (18.20) is such that (18.19) yields nD = ND when PD = 1. The
distance of the donor level from the minimum of the conduction band is calculated in
Sect. 18.7.3; for the typical n-type dopants used with silicon it isEC&minus;ED â 0.033 eV.
Another important feature of the donor levels (still in the case of low or moderately-
high values of the impurity concentration) is that they are localized in space, as
schematically illustrated in Fig. 18.8. For this reason, the Fermi-Dirac statistics
describing the equilibrium distribution of the electrons within the donor states is
slightly different from that used for the band electrons, and reads
</p>
<p>12 A phosphorous atom that has not released the orbiting electron is electrically neutral; when the
orbiting electron breaks the bond and becomes free to move within the lattice, the atom becomes
positively ionized. The symbol N+D reminds one of that. A second ionization does not occur because
the energy necessary for it is too high.</p>
<p/>
</div>
<div class="page"><p/>
<p>382 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>Fig. 18.8 Schematic
representation of the donor
states
</p>
<p>E
D
</p>
<p>E
V
</p>
<p>E
C
</p>
<p>E
VL
</p>
<p>E
G
</p>
<p>E
CU
</p>
<p>PD(E) =
1
</p>
<p>(1/dD) exp [(E &minus; EF )/(kB T )] + 1
, (18.21)
</p>
<p>with dD the donors&rsquo; degeneracy coefficient [23, Sect. 3.4]. In silicon, germanium,
and gallium arsenide it is dD = 2 [103, Sect. 2.4]. Combining (18.19) with (18.20)
and (18.21) yields nD = ND PD(ED), namely,
</p>
<p>N+D = ND [1 &minus; PD(ED)] =
ND
</p>
<p>dD exp [(EF &minus; ED)/(kB T )] + 1
. (18.22)
</p>
<p>Like in the intrinsic case discussed in Sect. 18.3, expressions (18.17, 18.22) can
be used only if the position of the Fermi level is known. To proceed one considers
again the T &rarr; 0 limit, where the Fermi-Dirac statistics becomes discontinuous and
the experimental evidence shows that the conductivity of a doped semiconductor
vanishes: this corresponds to a situation where all states of the conduction band
are empty, those of the valence bands are filled, and the donor states are filled as
well (in other terms, no dopant atoms are ionized). In conclusion, when T &rarr; 0
the Fermi level of an n-doped semiconductor is positioned between ED and EC , so
that n = p = N+D = 0. If, starting from this situation, the temperature is brought
again to some finite value T &gt; 0, such that some of the valence-band electrons and
some of the electrons belonging to the dopant atoms transit to the conduction band,
the total number of holes and ionized donors thus formed is equal to that of the
transited electrons. Due to the spatial uniformity of the material, the same relation
holds among the concentrations, so that
</p>
<p>n = p +N+D , (18.23)
whose limit for ND &rarr; 0 yields (18.11) as should be. Now, inserting (18.17, 18.22)
into (18.23) after letting Î¾D = (ED &minus; EC)/(kB T ) &lt; 0, provides
</p>
<p>NC Î¦1/2(Î¾e) = NV Î¦1/2(Î¾h) +
ND
</p>
<p>dD exp (Î¾e &minus; Î¾D) + 1
. (18.24)</p>
<p/>
</div>
<div class="page"><p/>
<p>18.4 Uniform Distribution of Impurities 383
</p>
<p>The latter, along with the relation Î¾e + Î¾h = &minus;EG/(kB T ), form a system in the
two unknowns Î¾e, Î¾h, whose solution determines the position of EF with respect to
the band edges EC and EV at a given temperature T &gt; 0 and donor concentration
ND . It is easily found that, for a fixed temperature, the argument Î¾e = (EF &minus;
EC)/(kB T ) increases when ND increases. In fact, using the short-hand notation
f (Î¾e) = dD exp (Î¾e &minus; Î¾D) + 1 &gt; 1 one finds from (18.24)
</p>
<p>dND
dÎ¾e
</p>
<p>= ND
f &minus; 1
f
</p>
<p>+ f
[
</p>
<p>NC
dÎ¦1/2(Î¾e)
</p>
<p>dÎ¾e
&minus;NV
</p>
<p>dÎ¦1/2(Î¾h)
</p>
<p>dÎ¾h
</p>
<p>dÎ¾h
dÎ¾e
</p>
<p>]
</p>
<p>, (18.25)
</p>
<p>where the right hand side is positive because dÎ¾h/dÎ¾e = &minus;1 and Î¦1/2 is a mono-
tonically-increasing function of the argument (Sect. C.13). In the intrinsic caseND =
0 it is EF = EFi and Î¾e &lt; 0; as ND increases, the Fermi level moves towards
EC , this making Î¾e less and less negative. At extremely high concentrations of the
donor atoms, the Fermi level may reach EC and even enter the conduction band, this
making Î¾e positive. As n, p, and N
</p>
<p>+
D are non negative, it is intuitive that an increasing
</p>
<p>concentration of donor atoms makes n larger than p; for this reason, in an n-doped
semiconductor electrons are called majority carriers while holes are called minority
carriers.13
</p>
<p>The behavior of the Fermi level with respect to variations in temperature, at a fixed
dopant concentration, can not be discussed as easily as that with respect to the dopant
variations, because (18.24) is not expressible in the form T = T (EF ) or its inverse.
The analytical approach is made easier when some approximations are introduced
into (18.24), as shown below. From a qualitative standpoint, one may observe that
at very high temperatures the concentration of electron&ndash;hole pairs generated by the
semiconductor prevails over the concentration of electrons provided by the dopant
atoms, so that the position of the Fermi level must be close to the intrinsic one; in
contrast, when T &rarr; 0 the Fermi level is positioned betweenED andEC as remarked
above. In conclusion, for an n-doped semiconductor one expects that dEF /dT &lt; 0.
</p>
<p>In view of further elaborations it is convenient to associate to the Fermi level an
electric potential ÏF , called Fermi potential, defined by
</p>
<p>q ÏF = EFi &minus; EF , (18.26)
</p>
<p>with q &gt; 0 the elementary charge. In an n-type semiconductor it is EF &gt; EFi ; thus,
the Fermi potential is negative.
</p>
<p>18.4.1.2 Complete Ionization and Non-Degenerate Condition (Donor Type)
</p>
<p>When the Fermi level&rsquo;s position and temperature are such that
</p>
<p>Î¾e &minus; Î¾D &lt; &minus;1, EF &lt; ED &minus; kB T , (18.27)
</p>
<p>13 The electrons of the conduction band and the holes of the valence band are collectively indicated
as carriers.</p>
<p/>
</div>
<div class="page"><p/>
<p>384 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>the exponential term at the right hand side of (18.22) is negligible with respect to
unity, so that N+D â ND . This condition is indicated with complete ionization. Note
that, since Î¾D &lt; 0, the complete-ionization condition in an n-doped semiconductor
also implies Î¾e &lt; &minus;1; as a consequence, the approximation Î¦1/2(Î¾e) â exp (Î¾e) for
the Fermi integral holds (Sect. C.13). Moreover, it is Î¾h &lt; Î¾e &lt; &minus;1 because the
Fermi level belongs to the upper half of the gap; thus, the same approximation
applies to Î¦1/2(Î¾h) as well. When both equilibrium concentrations n and p are
expressible through the approximation Î¦1/2(Î¾ ) â exp (Î¾ ), the semiconductor is
called non degenerate and the balance relation (18.24) reduces to
</p>
<p>NC exp
</p>
<p>(
</p>
<p>&minus;EC &minus; EF
kB T
</p>
<p>)
</p>
<p>â NV exp
(
</p>
<p>&minus;EF &minus; EV
kB T
</p>
<p>)
</p>
<p>+ND. (18.28)
</p>
<p>From the exponential expressions of n and p it follows, using (18.13),
</p>
<p>np â NC NV exp
(
</p>
<p>&minus;EC &minus; EV
kB T
</p>
<p>)
</p>
<p>= NC NV exp
(
</p>
<p>&minus; EG
kB T
</p>
<p>)
</p>
<p>= n2i . (18.29)
</p>
<p>Letting N+D = ND in (18.23) and multiplying both sides of it by n provides, thanks
to (18.29), an easy algebraic derivation of the electron and hole concentrations in the
non-degenerate and spatially-uniform case:
</p>
<p>n2 &minus;ND n&minus; n2i = 0, n =
ND
</p>
<p>2
+
</p>
<p>&radic;
</p>
<p>N2D
</p>
<p>4
+ n2i , p =
</p>
<p>n2i
</p>
<p>n
. (18.30)
</p>
<p>The range of validity of (18.30) is quite vast; in silicon at room temperature the
approximation (18.28) holds up to ND â 1017 cm&minus;3; also, even for the lowest
doping concentrations (about 1013 cm&minus;3) it is ND â« ni , so that (18.30) can further
be approximated as n â ND , p â n2i /ND . Thus, the concentration of majority
carriers turns out to be independent of temperature, while that of minority carriers still
depends on temperature through ni . Assuming by way of example ND = 1015 cm&minus;3
and taking a temperature such that ni = 1010 cm&minus;3 (compare with Table 18.2),
one finds n â 1015 cm&minus;3, p â 105 cm&minus;3. This result is very important because it
demonstrates that the concentration of minority carriers is negligible; as anticipated
above, the inclusion of a suitable concentration of dopants makes the material&rsquo;s
conductivity independent of temperature. The Arrhenius plot of n(T ) for an n-type
semiconductor is shown in Fig. 18.9 in arbitrary units. The left part of the curve,
called intrinsic range, corresponds to the situation where the intrinsic concentration
prevails due to the high temperature; the plateau, called saturation range, corresponds
to the situation where n â ND; finally, the right part of the curve, called freeze-out
range, corresponds to the case where n â N+D &lt; ND , with N+D decreasing as
temperature decreases. From the practical standpoint, the important outcome is that
the saturation region covers the range of temperatures within which the integrated
circuits operate.14
</p>
<p>14 For instance, for silicon with ND = 1015 cm&minus;3 the saturation region ranges from Tmin â 125 K
to Tmax â 370 K [103, Sect. 2.4].</p>
<p/>
</div>
<div class="page"><p/>
<p>18.4 Uniform Distribution of Impurities 385
</p>
<p>Fig. 18.9 Arrhenius plot of
n(T ) for an n-type
semiconductor, in arbitrary
units
</p>
<p>0 2 4 6 8
1 / T      (arbitrary units)
</p>
<p>-6
</p>
<p>-4
</p>
<p>-2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>lo
g
</p>
<p>n
  
  
  
(n
</p>
<p> i
n
 a
</p>
<p>rb
it
</p>
<p>tr
ar
</p>
<p>y
 u
</p>
<p>n
it
</p>
<p>s)
</p>
<p>Coupling n = ND with the expression of n given by the left hand side of (18.28),
and considering the values of NC given in Table 18.2, yields
</p>
<p>EF = EC &minus; kB T log
(
NC
</p>
<p>ND
</p>
<p>)
</p>
<p>&lt; EC , (18.31)
</p>
<p>whence, as anticipated,
</p>
<p>dEF
dND
</p>
<p>= kB T
ND
</p>
<p>&gt; 0,
dEF
dT
</p>
<p>= kB log
(
ND
</p>
<p>NC
</p>
<p>)
</p>
<p>= &minus;EC &minus; EF
T
</p>
<p>&lt; 0. (18.32)
</p>
<p>From definition (18.26) of the Fermi potential it follows EC &minus;EF = EC &minus;EFi +
q ÏF ; replacing the latter in n = NC exp [&minus; (EC &minus;EF )/(kB T )] yields an alternative
expression of the equilibrium concentration and of the Fermi potential itself,
</p>
<p>n = ni exp
(
</p>
<p>&minus;q ÏF
kB T
</p>
<p>)
</p>
<p>, ÏF = &minus;
kB T
</p>
<p>q
log
</p>
<p>(
ND
</p>
<p>ni
</p>
<p>)
</p>
<p>&lt; 0. (18.33)
</p>
<p>18.4.2 Acceptor-Type Impurities
</p>
<p>The analysis carried out in Sect. 18.4.1 is repeated here in a shorter form with
reference to a substitutional impurity of the acceptor type like, e.g., boron
(Fig. 18.10).
</p>
<p>As the dopant concentration is small with respect to the semiconductor&rsquo;s, each
boron atom is surrounded by silicon atoms. Boron has three electrons in the external
shell: while these electrons form covalent bonds with silicon, the remaining unsat-
urated bond deforms the shape of the potential energy in the vicinity of the boron
atom. This attracts an electron from a shared pair of a neighboring silicon. In other
terms, to form four covalent bonds with silicon, boron generates an electron&ndash;hole
pair as shown in the figure. In the T &rarr; 0 limit, the holes are permanently bound to</p>
<p/>
</div>
<div class="page"><p/>
<p>386 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>Fig. 18.10 Two-dimensional
representation of the p-doped
silicon lattice. The upper-left
part of the figure shows the
T &rarr; 0 limit
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>B
Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>Si
</p>
<p>B
</p>
<p>Fig. 18.11 Density of states
in a p-doped semiconductor.
The gap&rsquo;s extension is
arbitrary and does not refer to
any specific material
</p>
<p>-0.4 -0.2 0 0.2 0.4
(E - E
</p>
<p>F
) / (k
</p>
<p>B
 T)
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>g
(E
</p>
<p>) 
  
  
 (
</p>
<p>ar
b
it
</p>
<p>ra
ry
</p>
<p> u
n
it
</p>
<p>s)
</p>
<p>the atoms as in the intrinsic case; this situation is drawn in the upper-left part of the
figure, where the hole is represented, in a particle-like picture, as orbiting around the
boron atom. The orbit&rsquo;s radius is relatively large because the binding force is weak.
The black dot inside the boron atom indicates the negative charge that balances the
orbiting hole. If, instead, the temperature is brought to some finite value T &gt; 0 by
transferring energy from an external reservoir to the semiconductor, a fraction of
the orbiting holes break the bond and become free to move within the material. At
the same time, electrons belonging to shared pairs may also break their bonds, like
in intrinsic silicon. This situation is depicted in the lower-right part of Fig. 18.10,
where the free holes are represented with white dots. The negative charge within the
boron atom remains trapped within the atom itself: thus, the boron atoms provide
free holes to the lattice, but no electrons.
</p>
<p>The analysis is better specified below, starting from the consideration of the density
of states in a p-type semiconductor, shown in Fig. 18.11.</p>
<p/>
</div>
<div class="page"><p/>
<p>18.4 Uniform Distribution of Impurities 387
</p>
<p>18.4.2.1 Concentration of Ionized Impurities (Acceptor Type)
</p>
<p>Atoms like that of boron trap electrons from the lattice; for this reason they are also
called acceptors. The concentration of acceptors is indicated with NA and, in this
section, is assumed to be uniform in space. When acceptor atoms are present, the
equilibrium concentrations of electrons and holes are different from those of the
intrinsic semiconductor; their derivation is identical to that of the intrisic or n-type
case and yields again (18.17), with NC , NV given by (18.4, 18.8), respectively, and
Î¾e, Î¾h given by (18.18).
</p>
<p>In addition to the electron of the conduction band and holes of the valence band,
a third population of particles must be accounted for, namely, that associated to the
dopants. Let N&minus;A &le; NA be the spatially-constant concentration of the acceptors that
have released the orbiting hole to the lattice.15 Equivalently, N&minus;A may be thought of
as the concentration of electrons that have been captured by the acceptor atoms;
</p>
<p>N&minus;A =
&int;
</p>
<p>ï¿½EA
</p>
<p>Î³A(E)PA(E) dE, (18.34)
</p>
<p>where Î³A(E) is the combined density of states produced by the acceptor atoms, ï¿½EA
the energy range where Î³A(E) ï¿½= 0, and PA(E) the occupation probability of such
states. The form of Î³A depends on the concentration NA; for low or moderately-high
values of the acceptor concentration, Î³A has the form shown in Fig. 18.11. Such a
density of states can be approximated by a Dirac delta centered at an energy EA,
called acceptor level, positioned within the gap at a small distance from the edge EV
of the conduction band:
</p>
<p>Î³A(E) â NA Î´(E &minus; EA). (18.35)
</p>
<p>The coefficient in (18.35) is such that (18.34) yields N&minus;A = NA when PA = 1. The
distance of the acceptor level from the maximum of the valence band is calculated in
Sect. 18.7.3; for the typical p-type dopants used with silicon it isEA&minus;EV â 0.05 eV
for the heavy holes and EA &minus;EV â 0.016 eV for the light holes. Another important
feature of the acceptor levels (still in the case of low or moderately-high values of the
impurity concentration) is that they are localized in space, as schematically illustrated
in Fig. 18.12. For this reason, the Fermi-Dirac statistics describing the equilibrium
distribution of the electrons within the acceptor states is slightly different from that
used for the band electrons, and reads
</p>
<p>PA(E) =
1
</p>
<p>(1/dA) exp [(E &minus; EF )/(kB T )] + 1
, (18.36)
</p>
<p>15 A boron atom that has not released the orbiting hole is electrically neutral; when the orbiting hole
breaks the bond and becomes free to move within the lattice, the atom becomes negatively ionized,
because the release of a hole is actually the capture of a valence-band electron by the boron atom.
The symbol N&minus;A reminds one of that. The release of a second hole does not occur.</p>
<p/>
</div>
<div class="page"><p/>
<p>388 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>Fig. 18.12 Schematic
representation of the acceptor
states
</p>
<p>E
V
</p>
<p>E
C
</p>
<p>E
VL
</p>
<p>E
G
</p>
<p>E
CU
</p>
<p>E
A
</p>
<p>with dA the acceptors&rsquo; degeneracy coefficient. In silicon, germanium, and gallium
arsenide it is dA = 4 [103, Sect. 2.4]. Combining (18.34) with (18.35) and (18.36)
yields
</p>
<p>N&minus;A =
NA
</p>
<p>(1/dA) exp [(ED &minus; EF )/(kB T )] + 1
. (18.37)
</p>
<p>The position of the Fermi level is calculated by the same token as for the n-type
dopant and is based on the balance relation
</p>
<p>n+N&minus;A = p, (18.38)
</p>
<p>whose limit for NA &rarr; 0 yields (18.11) as should be. Now, inserting (18.17, 18.37)
into (18.38) after letting Î¾A = (EV &minus; EA)/(kB T ) &lt; 0, provides
</p>
<p>NC Î¦1/2(Î¾e) +
NA
</p>
<p>(1/dA) exp (Î¾h &minus; Î¾A) + 1
= NV Î¦1/2(Î¾h). (18.39)
</p>
<p>The latter, along with the relation Î¾e + Î¾h = &minus;EG/(kB T ), form a system in the two
unknowns Î¾e, Î¾h, whose solution determines the position of EF with respect to the
band edges EC and EV at a given temperature T &gt; 0 and acceptor concentration
NA. It is easily found that, for a fixed temperature, the argument Î¾h = (EV &minus;
EF )/(kB T ) increases when NA increases. The demonstration is identical to that
leading to (18.25). In the intrinsic case NA = 0 it is EF = EFi and Î¾h &lt; 0; as NA
increases, the Fermi level moves towards EV , this making Î¾h less and less negative.
At extremely high concentrations of the acceptor atoms, the Fermi level may reach
EV and even enter the valence band, this making Î¾h positive. As n, p, and N
</p>
<p>&minus;
A are
</p>
<p>non negative, it is intuitive that an increasing concentration of acceptor atoms makes
p larger than n; for this reason, in a p-doped semiconductor holes are called majority
carriers while electrons are called minority carriers.
</p>
<p>To discuss from a qualitative standpoint the dependence of the Fermi level with
respect to variations in temperature one may observe that, like in an n-doped material,</p>
<p/>
</div>
<div class="page"><p/>
<p>18.4 Uniform Distribution of Impurities 389
</p>
<p>at very high temperatures the concentration of electron&ndash;hole pairs generated by the
semiconductor prevails over the concentration of holes provided by the dopant atoms,
so that the position of the Fermi level must be close to the intrinsic one; in contrast,
when T &rarr; 0 the Fermi level is positioned between EV and EA. In conclusion,
for a p-doped semiconductor one expects that dEF /dT &gt; 0. Also, in a p-type
semiconductor it is EF &lt; EFi ; thus, the Fermi potential (18.26) is positive.
</p>
<p>18.4.2.2 Complete Ionization and Non-Degenerate Condition
</p>
<p>(Acceptor Type)
</p>
<p>When the Fermi level&rsquo;s position and temperature are such that
</p>
<p>Î¾h &minus; Î¾A &lt; &minus;1, EA &lt; EF &minus; kB T , (18.40)
</p>
<p>the exponential term at the right hand side of (18.37) is negligible with respect to
unity, so that N&minus;A â NA. This condition is indicated with complete ionization. Note
that, since Î¾A &lt; 0, the complete-ionization condition in a p-doped semiconductor
also implies Î¾h &lt; &minus;1; as a consequence, the approximation Î¦1/2(Î¾h) â exp (Î¾h)
for the Fermi integral holds (Sect. C.13). Moreover, it is Î¾e &lt; Î¾h &lt; &minus;1 because
the Fermi level belongs to the lower half of the gap; thus, the same approximation
applies to Î¦1/2(Î¾e) as well. In conclusion, the semiconductor is non degenerate and
the balance relation (18.39) reduces to
</p>
<p>NC exp
</p>
<p>(
</p>
<p>&minus;EC &minus; EF
kB T
</p>
<p>)
</p>
<p>+NA â NV exp
(
</p>
<p>&minus;EF &minus; EV
kB T
</p>
<p>)
</p>
<p>. (18.41)
</p>
<p>From the exponential expressions ofn andp it follows, like in the n-type case, that the
product of the equilibrium concentrations fulfills (18.29). The algebraic derivation
of the electron and hole concentrations in the non-degenerate and spatially-uniform
case is also similar:
</p>
<p>p2 &minus;NA p &minus; n2i = 0, p =
NA
</p>
<p>2
+
</p>
<p>&radic;
</p>
<p>N2A
</p>
<p>4
+ n2i , n =
</p>
<p>n2i
</p>
<p>p
, (18.42)
</p>
<p>with the further approximation p â NA, n â n2i /NA holding within the low and
moderately-high range of dopant concentrations, and around room temperature.
</p>
<p>Couplingp = NA with the expression ofp given by the right hand side of (18.41),
and considering the values of NV given in Table 18.2, yields
</p>
<p>EF = EV + kB T log
(
NV
</p>
<p>NA
</p>
<p>)
</p>
<p>&gt; EV , (18.43)
</p>
<p>whence, as anticipated,
</p>
<p>dEF
dNA
</p>
<p>= &minus;kB T
NA
</p>
<p>&lt; 0,
dEF
dT
</p>
<p>= kB log
(
NV
</p>
<p>NA
</p>
<p>)
</p>
<p>= EF &minus; EV
T
</p>
<p>&gt; 0. (18.44)</p>
<p/>
</div>
<div class="page"><p/>
<p>390 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>Fig. 18.13 Schematic
representation of a
semiconductor with both
donor and acceptor states
</p>
<p>E
D
</p>
<p>E
V
</p>
<p>E
C
</p>
<p>E
VL
</p>
<p>E
G
</p>
<p>E
CU
</p>
<p>E
A
</p>
<p>From definition (18.26) of the Fermi potential it follows EF &minus;EV = EFi &minus;EV &minus;
q ÏF ; replacing the latter in p = NV exp [&minus; (EF &minus;EV )/(kB T )] yields an alternative
expression of the equilibrium concentration and of the Fermi potential itself,
</p>
<p>p = ni exp
(
q ÏF
</p>
<p>kB T
</p>
<p>)
</p>
<p>, ÏF = &minus;
kB T
</p>
<p>q
log
</p>
<p>(
NA
</p>
<p>ni
</p>
<p>)
</p>
<p>&gt; 0. (18.45)
</p>
<p>18.4.3 Compensation Effect
</p>
<p>The architecture of semiconductor devices is such that donor and acceptor dopants
are present in the same region (Fig. 18.13). Letting ND , NA be the corresponding
concentrations, still assumed uniform in space, the equilibrium concentrations of
electrons and holes are expressed by (18.17) as in the other cases discussed above,
with NC , NV and Î¾e, Î¾h given by (18.4, 18.8) and (18.18), respectively. In turn, the
concentrations of ionized donors and acceptors are given by (18.22) and (18.37),
respectively. The balance equation reads
</p>
<p>n+N&minus;A = p +N+D , (18.46)
</p>
<p>namely, NC Î¦1/2(Î¾e) + NA PA(EA) = NV Î¦1/2(Î¾h) + ND [1 &minus; PD(ED)]. One ob-
serves that if N+D = N&minus;A , the balance equation (18.46) coincides with that of an
intrinsic semiconductor (compare with (18.11)). As a consequence, the position of
the Fermi level is given by (18.16), and the electrons released by the donor atoms are
trapped by the acceptor ones. In this case the semiconductor is fully compensated. If,
instead, it is N+D ï¿½= N&minus;A , the semiconductor is partially compensated, and one must
distinguish between two cases of the balance relation (18.46), depending on the sign
of the net ionized impurity concentration N = N+D &minus;N&minus;A . In the first case,
</p>
<p>N &gt; 0, n = p +N , (18.47)</p>
<p/>
</div>
<div class="page"><p/>
<p>18.5 Non-Uniform Distribution of Dopants 391
</p>
<p>the balance relation is identical to that of an n-doped semiconductor (compare with
(18.23)), with an effective donor dopant equal to N . In the second case,
</p>
<p>N &lt; 0, n+ |N | = p, (18.48)
</p>
<p>the balance relation is identical to that of a p-doped semiconductor (compare with
(18.38)), with an effective acceptor dopant equal to |N |. In the non-degenerate case,
(18.29) still holds. If complete ionization also occurs, then N = ND &minus; NA; when
the donor-type dopant prevails, electrons are the majority carriers, and the same
calculation as that leading to (18.30) yields
</p>
<p>n = N
2
</p>
<p>+
&radic;
</p>
<p>N2
</p>
<p>4
+ n2i . (18.49)
</p>
<p>If N â« ni , then
</p>
<p>n â N , p â n
2
i
</p>
<p>N
, ÏF = &minus;
</p>
<p>kB T
</p>
<p>q
log
</p>
<p>(
N
</p>
<p>ni
</p>
<p>)
</p>
<p>&lt; 0. (18.50)
</p>
<p>If, on the contrary, the acceptor-type dopant prevails, holes are the majority carriers,
and the same calculation as that leading to (18.42) yields
</p>
<p>p = &minus;N
2
</p>
<p>+
&radic;
</p>
<p>N2
</p>
<p>4
+ n2i . (18.51)
</p>
<p>If &minus;N â« ni , then
</p>
<p>p â &minus;N = |N |, n â n
2
i
</p>
<p>|N | , ÏF =
kB T
</p>
<p>q
log
</p>
<p>( |N |
ni
</p>
<p>)
</p>
<p>&lt; 0. (18.52)
</p>
<p>18.5 Non-Uniform Distribution of Dopants
</p>
<p>This section deals with the more realistic case where the donor concentration ND ,
the acceptor concentration NA, or both, depend on position. A qualitative reasoning
shows that the balance equations (18.23), (18.38), or (18.46) do not hold any more.
To show this, consider the simple case where only the n-type dopant is present,
ND = ND(r), NA = 0, and select two nearby positions, say, r1 and r2, in the
limiting case T &rarr; 0; then, let the temperature increase such that a fraction of the
donor atoms ionizes. If ND(r1) ï¿½= ND(r2), the numbers of electrons transiting to the
conduction band at r1 and r2 is different, so that the concentration in one position,
say, r1 is larger than that in the other; thus, some electrons diffuse16 from the former
position to the latter. On the other hand, as the position of the positive charges
</p>
<p>16 Diffusive transport is introduced in Sect. 23.3.</p>
<p/>
</div>
<div class="page"><p/>
<p>392 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>within the ionized donors is fixed, the spatial rearrangement of the conduction-band
electrons unbalances the negative charges with respect to the positive ones, so that
the local charge density differs from zero. The same reasoning applies when both
donor and acceptor dopants are present, so that in a general non-uniform case it is
</p>
<p>Ìº(r) = q
[
</p>
<p>p(r) &minus; n(r) +N+D (r) &minus;N&minus;A (r)
]
</p>
<p>ï¿½= 0. (18.53)
</p>
<p>A non-vanishing charge density produces in turn an electric field E = E(r) whose
action balances the diffusion. In conclusion, the equilibrium condition is kept by
an exact balance of the two transport mechanisms. Considering that the equilibrium
condition is time-independent, the Maxwell equations in the semiconductor reduce
to Îµsc divE = Ìº, with E = &minus;gradÏ (Sect. 4.4), Ï and Îµsc being the electric potential
and semiconductor permittivity, respectively.17 In other terms, the electric field due
to the non-uniformity of Ìº is found by solving the Poisson equation.
</p>
<p>The effect onto the total energy of the electrons due to the presence of an electric
field also influences the statistical distribution of the electrons in the energy states. It
will be demonstrated in Sect. 19.2.2 that the statistical distribution to be used here is
a modified form of the Fermi-Dirac statistics where E is replaced with E &minus; q Ï(r):
</p>
<p>P (E, r) = 1
exp [(E &minus; q Ï(r) &minus; EF ) / (kB T )] + 1
</p>
<p>; (18.54)
</p>
<p>similarly, (18.21) and (18.36) become
</p>
<p>PD(A)(E, r) =
1
</p>
<p>(1/dD(A)) exp [(E &minus; q Ï(r) &minus; EF )/(kB T )] + 1
. (18.55)
</p>
<p>Note that the calculations leading to the concentrations are carried out in the same
manner as in Sects. 18.4.1, 18.4.2, because they involve integrals over energy only.
As a consequence, (18.17) generalize to
</p>
<p>n(r) = NC Î¦1/2 (Î¾e(r)) , Î¾e(r) = &minus;
Î¶e(r)
</p>
<p>kB T
= &minus;EC &minus; EF &minus; q Ï(r)
</p>
<p>kB T
, (18.56)
</p>
<p>and
</p>
<p>p(r) = NV Î¦1/2 (Î¾h(r)) , Î¾h(r) = &minus;
Î¶h(r)
</p>
<p>kB T
= &minus;EF + q Ï(r) &minus; EV
</p>
<p>kB T
. (18.57)
</p>
<p>Similarly, (18.22, 18.34) become
</p>
<p>N+D (r) = ND(r) [1 &minus; PD(ED , r)] , N&minus;A (r) = NA(r)PA(EA, r). (18.58)
</p>
<p>Note that the summands at the right hand side of (18.53) depend on position through
the electric potential Ï and also through the explicit dependence of ND and NA; as a
</p>
<p>17 Note that the material&rsquo;s permittivity must be used here instead of vacuum&rsquo;s. This is coherent
with the use of charge density and, in a non-equilibrium situation, of current density, which entail
averages over volumes of space.</p>
<p/>
</div>
<div class="page"><p/>
<p>18.6 Band-Gap Narrowing 393
</p>
<p>consequence, inserting the expression of the charge density into the right hand side
of the Poisson equation yields
</p>
<p>&minus;Îµsc &nabla;2Ï = Ìº(Ï, r), (18.59)
</p>
<p>namely, a second-order, partial differential equation in the unknown Ï, with position-
dependent coefficients. The equation must be supplemented with suitable boundary
conditions.18 Equation (18.59) is the generalization of the balance equation (18.46)
to the non-uniform case: in the case of (18.46), the problem is algebraic and yields
EF , whereas in the case of (18.59) it is differential and yields EF +q Ï. After solving
(18.59) one reconstructs n, p, N+D , and N
</p>
<p>&minus;
A at each point through (18.56), (18.57),
</p>
<p>and (18.58). In the non-degenerate case, (18.56) becomes
</p>
<p>n = n(0) exp
(
</p>
<p>q Ï
</p>
<p>kB T
</p>
<p>)
</p>
<p>, n(0) = NC exp
(
EF &minus; EC
kB T
</p>
<p>)
</p>
<p>= ni exp
(&minus;qÏF
</p>
<p>kB T
</p>
<p>)
</p>
<p>,
</p>
<p>(18.60)
</p>
<p>with n(0) the value of the electron concentration in the position(s) where Ï = 0. The
last expression of n(0) is obtained by combining definition (18.26) with first relation
in (18.12). Similarly,
</p>
<p>p = p(0) exp
(&minus;q Ï
kB T
</p>
<p>)
</p>
<p>, p(0) = NV exp
(
EV &minus; EF
kB T
</p>
<p>)
</p>
<p>= ni exp
(
qÏF
</p>
<p>kB T
</p>
<p>)
</p>
<p>.
</p>
<p>(18.61)
</p>
<p>From (18.60, 18.61) one finally obtains
</p>
<p>n = ni exp
[
q (Ï &minus; ÏF )
</p>
<p>kB T
</p>
<p>]
</p>
<p>, p = ni exp
[
q (ÏF &minus; Ï)
</p>
<p>kB T
</p>
<p>]
</p>
<p>. (18.62)
</p>
<p>One observes that (18.29) still holds, namely, np = n(0) p(0) = n2i : in the non-
degenerate case, the equilibrium product does not depend on position. If complete
ionization also occurs, then N+D (r) = ND(r), N&minus;A (r) = NA(r): the ionized-dopant
concentrations do not depend on the electric potential.
</p>
<p>18.6 Band-Gap Narrowing
</p>
<p>When the dopant concentration is large, the density of states associated to the dopant
atoms can no longer be described as in Figs. 18.7, 18.11. Rather, considering by way
of example an n-type dopant, the form of the density of states is similar to that shown
in Fig. 18.14, namely, it overlaps the lower portion of the conduction band forming
</p>
<p>18 Such boundary conditions must be coeherent with the choice of the zero point of the total energy.
An example is given in Sect. 21.2.</p>
<p/>
</div>
<div class="page"><p/>
<p>394 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>Fig. 18.14 Density of states
in an n-doped semiconductor,
where the high concentration
of the dopant produces the
band-gap narrowing. The
gap&rsquo;s extension is arbitrary
and does not refer to any
specific material
</p>
<p>-0.4 -0.2 0 0.2 0.4
(E - E
</p>
<p>F
) / (k
</p>
<p>B
 T)
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>g
(E
</p>
<p>) 
  
  
 (
</p>
<p>ar
b
it
</p>
<p>ra
ry
</p>
<p> u
n
it
</p>
<p>s)
</p>
<p>the so-called impurity band. In addition, the dopant atoms are close to each other, to
the extent that the probability of tunneling of an electron, from a neutral to a nearby,
ionized donor atom, is not negligible (Sect. 18.7.2). In a non-equilibrium condition,
the tunneling electrons give rise to a current density; the phenomenon is referred
to as impurity-band conduction. From the practical standpoint, the union of the
conduction and impurity bands is viewed as a broader conduction band whose lower
edge is shifted with respect to the undoped, or moderately-doped case; the effect is
also called band-gap narrowing. The analysis is similar when a large concentration of
acceptor atoms is present. In conclusion, band-gap narrowing is in general produced
by the lowering of the conduction-band edge, ï¿½EC(r) &gt; 0, combined with the lifting
of the valence-band edge, ï¿½EV (r) &gt; 0. Both quantities are position dependent
because in general the dopant concentrations are such.
</p>
<p>Indicating with ECi , EV i the lower edge of the conduction band and, respectively,
the upper edge of the valence band in the undoped or moderately-doped case, and
observing that the variations due to heavy doping are positive, one has for the actual
positions of the band edges:
</p>
<p>EC(r) = ECi &minus;ï¿½EC(r), EV (r) = EV i +ï¿½EV (r), (18.63)
</p>
<p>whence
</p>
<p>EG(r) = EGi &minus;ï¿½EG(r), EGi = ECi &minus; EV i , ï¿½EG = ï¿½EC +ï¿½EV &gt; 0.
(18.64)
</p>
<p>To calculate the carrier concentrations when band-gap narrowing is present, one
must replace EC with ECi &minus;ï¿½EC(r) in the second relation of (18.56), and EV with
EV i +ï¿½EV (r) in the second relation of (18.57), to find
</p>
<p>Î¾e(r) = &minus;
ECi &minus; EF &minus; q Ï(r)
</p>
<p>kB T
+ ï¿½EC(r)
</p>
<p>kB T
, (18.65)</p>
<p/>
</div>
<div class="page"><p/>
<p>18.6 Band-Gap Narrowing 395
</p>
<p>Fig. 18.15 Band-gap
narrowing as a function of the
total doping concentration, in
normalized form, using the
experimental expression
18.67
</p>
<p>0 20 40 60 80 100
( N
</p>
<p>D
 + N
</p>
<p>A
 ) / N
</p>
<p>r
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>Î
E
</p>
<p>G
 /
</p>
<p> E
r
</p>
<p>Î¾h(r) = &minus;
EF &minus; EV i + q Ï(r)
</p>
<p>kB T
+ ï¿½EV (r)
</p>
<p>kB T
. (18.66)
</p>
<p>Band-gap narrowing makes Î¾e, Î¾h to increase with respect to the moderately-doped
case; as a consequence, the equilibrium carrier concentrations n and p are larger
as well. As mentioned in Sect. 18.3, band gap is measured by either electrical or
optical methods. The results of gap&rsquo;s measurements, that show that EG decreases
when the dopant concentration exceeds some limiting value Nr , are usually rendered
in compact form by means of interpolating expressions, an example of which is [100,
101]
</p>
<p>ï¿½EG = Er
(
</p>
<p>F +
&radic;
</p>
<p>F 2 + 0.5
)
</p>
<p>, F = log
(
ND +NA
</p>
<p>Nr
</p>
<p>)
</p>
<p>, (18.67)
</p>
<p>with Er = 9 meV, Nr = 1017 cm&minus;3. The function described by (18.67) is shown
in normalized form in Fig. 18.15. Expressions like (18.67) describe the cumulative
effect of the total doping concentration, without distinguishing between the donor
or acceptor contribution to band-gap narrowing. For this reason, when band-gap
narrowing is accounted for in numerical calculations, ï¿½EG is equally distributed
between the two bands, namely, ï¿½EC = ï¿½EV = ï¿½EG/2.
</p>
<p>It is interesting to note that the onset of band-gap narrowing corresponds to a
total dopant concentration of about 1017 cm&minus;3, where the non-degeneracy condition
still holds. As a consequence, a range of dopant concentrations exists where the
exponential approximation can be used for the equilibrium carrier concentrations,
whereas the band-gap narrowing effect must be accounted for.19 The non-degeneracy
condition reads in this case
</p>
<p>ECi &minus; EF &minus; q Ï &minus;ï¿½EC &gt; kB T , EF &minus; EV i + q Ï &minus;ï¿½EV &gt; kB T . (18.68)
</p>
<p>19 Such a range may be quite large if one considers the compensation effect (Sect. 18.4.3).</p>
<p/>
</div>
<div class="page"><p/>
<p>396 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>Remembering (18.62), the equilibrium concentrations become
</p>
<p>n = ne exp
[
q (Ï &minus; ÏF )
</p>
<p>kB T
</p>
<p>]
</p>
<p>, ne = ni exp
(
ï¿½EC
</p>
<p>kB T
</p>
<p>)
</p>
<p>&gt; ni , (18.69)
</p>
<p>p = pe exp
[
q (ÏF &minus; Ï)
</p>
<p>kB T
</p>
<p>]
</p>
<p>, pe = ni exp
(
ï¿½EV
</p>
<p>kB T
</p>
<p>)
</p>
<p>&gt; ni , (18.70)
</p>
<p>where pe = ne on account of ï¿½EV = ï¿½EC . The common value ne is called effective
intrinsic concentration. The equilibrium product then reads
</p>
<p>np = n2e , n2e = n2i exp
(
ï¿½EG
</p>
<p>kB T
</p>
<p>)
</p>
<p>. (18.71)
</p>
<p>18.7 Complements
</p>
<p>18.7.1 Si, Ge, GaAs in the Manufacturing of Integrated Circuits
</p>
<p>As noted in Sect. 18.3, silicon, germanium, and gallium arsenide have similar ef-
fective densities of states, but different gap extensions (Table 18.1); in this respect,
silicon is considered as a reference material, so that germanium is indicated as a
narrow-gap material while gallium arsenide is indicated as a wide-gap material.
The differences in the gap extension produce huge differences in the intrinsic con-
centration ni (Table 18.2); the latter, in turn, has a strong influence on the functioning
of the integrated circuits. In fact, the saturation current of a p-n junction is propor-
tional to n2i (Sect. 21.3.1); as a consequence, this parameter determines the current
of the junction when a reverse bias is applied to it. When many junctions are present,
as is typically the case in integrated circuits, the inverse currents may build up and
give rise to a substantial parasitic current. From this standpoint, gallium arsenide is
preferable with respect to silicon, which in turn is preferable with respect to germa-
nium. Gallium arsenide is also preferable because of the smaller effective mass of
the electrons, which makes the electron mobility larger (Sect. 17.6.6). On the other
hand, silicon is much less expensive; in fact it is the second most abundant element
in Earth&rsquo;s crust (the first one is oxygen); gallium, germanium, and arsenic are much
rarer.
</p>
<p>The historical development of the semiconductor-device manufacture has fol-
lowed, instead, a different path. Until the mid sixties of the last century, germanium
was preferred; the reason for this was that a technological process, able to purify the
material to the level required by the electronic industry, was available for germanium
first. As soon as the purification method became available for silicon as well, the lat-
ter replaced germanium in the fabrication of semiconductor devices and, soon after,
of integrated circuits. The silicon technology developed with a steady pace, giving
rise to decades of exponential miniaturization and development in the integrated-
circuit manufacture. The miniaturization of gallium-arsenide-based circuits did not</p>
<p/>
</div>
<div class="page"><p/>
<p>18.7 Complements 397
</p>
<p>proceed with the same pace because the technology of compound materials is more
complicate.
</p>
<p>In 1980, practically 100 % of the worldwide market share of integrated circuit
was silicon based, almost equally distributed between the bipolar and MOSFET
technologies [13]. In the following years the MOSFET technology became dominant,
reaching a market share of 88 % in the year 2000; of the remaining 12 %, the bipolar,
silicon-based technology kept an 8 % share, while the remaining 4 % was taken by
integrated circuits using III-V compounds.
</p>
<p>In 1989, germanium was introduced again in the silicon integrated-circuit tech-
nology to form silicon-germanium alloys (Si1&minus;xGex). The alloy makes a flexible
band-gap tuning possible; it is used for manufacturing heterojunction bipolar tran-
sistors, yielding higher forward gain and lower reverse gain than traditional bipolar
transistors. Another application of the alloy is in the Silicon-Germanium-On-
Insulator (SGOI) technology. The difference in the lattice constants of germanium
and silicon induces a strain in the material under the gate, that makes electron mobility
to increase.
</p>
<p>18.7.2 Qualitative Analysis of the Impurity Levels
</p>
<p>A qualitative analysis of the impurity levels may be carried out basing on a modified
version of the Kronig&ndash;Penney model discussed in Sect. 17.8.4. To this purpose,
consider the case of donor atoms placed at equal distances in a one-dimensional
lattice, like that of Fig. 18.16. The deeper wells are those introduced by the dopants,
while the finer structure above the x axis is due to the semiconductor nuclei. Note that
the relative distances in the figure are not realistic and are used only for illustrative
purposes; assuming in fact that the structure represented a cross section of a three-
dimensional semiconductor, where a uniform donor concentration ND is present,
the distance between two neighboring impurity atoms is found to be (1/ND)1/3.
If the semiconductor&rsquo;s concentration is Nsc, the ratio (Nsc/ND)1/3 indicates how
many semiconductor atoms are present in the interval between two neighboring
impurities. Considering silicon by way of example (Nsc = 5 &times; 1022 cm&minus;3), and
taking ND = 5 &times; 1016 cm&minus;3 yields (Nsc/ND)1/3 = 100.
</p>
<p>With this provision, let c be the width of the barrier separating two dopant-induced
wells, and consider a negative value E&prime; of the electron&rsquo;s energy. If c is large, the
probability that the electron tunnels from a well to an adjacent, empty one is negligibly
small; in this case, the electron is confined within the well where the localization
probability is the largest, and the energy states E&prime; &lt; 0 are similar to those of a single
well (the energy states of the finite rectangular well are worked out in Sect. 11.5).
The lowest state of the well is the ground state ED shown in Fig. 18.16. If, instead, a
positive energy state E is considered, the wave function is extended over the whole
lattice like in the Kronig&ndash;Penney model. In summary, the addition of dopant atoms
with a low or moderately high concentration, such that their mutual distance c is
large, provides a set of energy states that adds up to the band structure of the intrinsic</p>
<p/>
</div>
<div class="page"><p/>
<p>398 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>Fig. 18.16 Potential energy
in the Kronig&ndash;Penney model
modified to account for
impurity atoms
</p>
<p>E
D
</p>
<p>x
</p>
<p>V
</p>
<p>c
</p>
<p>E
</p>
<p>E&rsquo;
</p>
<p>semiconductor. The states introduced by the dopants are localized in space at the
positions of the dopant atoms, and are distributed in energy as discrete levels whose
mutual distances depend on the form of the well.
</p>
<p>In turn, the states with positive energy have a structure similar to that of the
intrinsic semiconductor, because in this respect the dopant atoms have little effect
on the lattice; in Fig. 18.16, the lower edge EC of the conduction band coincide with
E = 0. As said above, electrons belonging to the dopant atoms can not move as long
as they are confined within wells, because tunneling is precluded; on the other hand,
they may be promoted to conduction-band states by absorbing energy in a collision,
and become band electrons, that is, mobile. Conversely, a band electron may loose
energy due to a collision, and be trapped in an empty well.
</p>
<p>When, due to an increasing dopant concentration, the width c of the barrier be-
comes smaller, the transmission coefficient increases and the electrons belonging to
the wells have a non-negligible probability of moving from a well to another. When
the structure of the wells becomes finer, the description of their energy states becomes
more similar to that applicable to the intrinsic semiconductor: for an infinite structure
one obtains a continuum of states, that fill up the well and connect to those of the
conduction band. This explains the band-gap narrowing phenomenon introduced in
Sect. 18.6.
</p>
<p>18.7.3 Position of the Impurity Levels
</p>
<p>To determine the position of the impurity levels for the case of a low or moderately
high impurity concentration of the donor type, one considers the dispersion relation
E(k) of the conduction band of the intrinsic semiconductor, in the parabolic-band
approximation (17.57, 17.58):
</p>
<p>E(k) â EC +
3
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>hÌ2
</p>
<p>2mia
(ki &minus; kia)2,
</p>
<p>1
</p>
<p>mia
= 1
</p>
<p>hÌ2
</p>
<p>(
&part;2E
</p>
<p>&part;k2i
</p>
<p>)
</p>
<p>a
</p>
<p>&gt; 0. (18.72)</p>
<p/>
</div>
<div class="page"><p/>
<p>18.7 Complements 399
</p>
<p>Now, assume that a donor-type impurity is added in the origin, and that the impurity
is ionized. As a consequence, it gives rise to a hydrogenic-like potential energy20
</p>
<p>of the form V = &minus;q2/(4Ï Îµsc r). The effect of V may be considered as a local
perturbation over the band structure, so that when the ionized impurity is present the
total energy of an electron becomes H = E(k)+V (r), with E(k) the same as in the
unperturbed case. Shifting the origin of k to ka , and replacing ki with &minus;i &part;/&part;xi , one
obtains the Hamiltonian operator21
</p>
<p>H â EC &minus;
3
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>hÌ2
</p>
<p>2mia
</p>
<p>&part;2
</p>
<p>&part;x2i
&minus; q
</p>
<p>2
</p>
<p>4Ï Îµsc r
. (18.73)
</p>
<p>To estimate the eigenvalues of H one may replace each mia with the average mea =
(m1a m2a m3a)1/3 (Sect. 17.6.3), to obtain
</p>
<p>&minus; hÌ
2
</p>
<p>2mea
&nabla;2vn &minus;
</p>
<p>q2
</p>
<p>4Ï Îµsc r
vn = (E&prime;n &minus; EC) vn, (18.74)
</p>
<p>with vn the eigenfunction. Apart from the coefficients, (18.74) is identical to the
Schr&ouml;dinger equation for the Coulomb case treated in Sect. 13.5.2, whose eigenvalues
are given by (13.49). It follows
</p>
<p>E&prime;n = EC &minus;
mea
</p>
<p>2 hÌ2
</p>
<p>(
q2
</p>
<p>4Ï Îµsc
</p>
<p>)2 1
</p>
<p>n2
, n = 1, 2, . . . (18.75)
</p>
<p>Thus, the donor impurity provides infinite levels from the minimum E&prime;1 to the max-
imum EC . Considering the case of silicon by way of example, one has m1a = ml =
0.97 m0, m2a = m3a = mt = 0.19 m0 (Table 17.4), with m0 â 9.11 &times; 10&minus;31 kg
the rest mass of the electron, whence mea = 0.33 m0. Letting ED = E&prime;1 and using
Îµsc â 11.7 Îµ0, with Îµ0 = 8.854 &times; 10&minus;14 F cm&minus;1 the vacuum permittivity, one finds
the ionization energy of the donor impurity in silicon:
</p>
<p>EC &minus; ED =
mea
</p>
<p>2 hÌ2
</p>
<p>(
q2
</p>
<p>4Ï Îµsc
</p>
<p>)2
</p>
<p>â 32.8 meV. (18.76)
</p>
<p>The analysis is similar for an ionized, acceptor-type impurity. The hydrogenic-
like potential energy becomes V = q2/(4Ï Îµsc r), and the dispersion relation around
a maximum ka of the valence band reads
</p>
<p>E(k) â EV &minus;
3
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>hÌ2
</p>
<p>2mia
(ki &minus; kia)2,
</p>
<p>1
</p>
<p>mia
= &minus; 1
</p>
<p>hÌ2
</p>
<p>(
&part;2E
</p>
<p>&part;k2i
</p>
<p>)
</p>
<p>a
</p>
<p>&gt; 0. (18.77)
</p>
<p>20 Compare with Sect. 17.6.6. Like in Sect. 18.5, the semiconductor permittivity is used instead of
that of vacuum, because the wave function of an electron subject to the force due to V extends over
several lattice cells.
21 More comments about the procedure of obtaining an operator from a simplified form of the
eigenvalues of a more general operator are made in Sect. 19.2.</p>
<p/>
</div>
<div class="page"><p/>
<p>400 18 Electrons and Holes in Semiconductors at Equilibrium
</p>
<p>When the impurity is present the Hamiltonian operator becomes
</p>
<p>H â EV +
3
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>hÌ2
</p>
<p>2mia
</p>
<p>&part;2
</p>
<p>&part;x2i
+ q
</p>
<p>2
</p>
<p>4Ï Îµsc r
. (18.78)
</p>
<p>Again, to estimate the eigenvalues one replaces each mia with the average mha . One
finds
</p>
<p>&minus; hÌ
2
</p>
<p>2mha
&nabla;2vn &minus;
</p>
<p>q2
</p>
<p>4ÏÎµsc r
vn = (EV &minus; E&prime;&prime;n) vn, (18.79)
</p>
<p>whence
</p>
<p>E&prime;&prime;n = EV +
mha
</p>
<p>2 hÌ2
</p>
<p>(
q2
</p>
<p>4Ï Îµsc
</p>
<p>)2 1
</p>
<p>n2
, (18.80)
</p>
<p>n = 1, 2, . . . . The acceptor impurity provides infinite levels from the minimum EV
to the maximum E&prime;&prime;1 . Letting EA = E&prime;&prime;1 one finds the ionization energy EA &minus; EV of
the donor impurity. Taking again silicon by way of example, and using the values
mhh = 0.5 m0, mhl = 0.16 m0 from Table 17.3, one finds EA&minus;EV = 49.7 meV for
the heavy holes and EA &minus; EV = 15.9 meV for the light holes.
</p>
<p>The ionization energies of phosphorus and boron in vacuo are about 10.5 eV
and 8.3 eV, respectively, that is, much higher than those calculated here. The strong
difference is ascribed to the presence of the silicon crystal: a comparison between
(13.49) and (18.75) or (18.80) shows in fact that the coefficients of 1/n2 in the crystal
case are much smaller than that in vacuo, due to the presence of the effective mass
in the numerator and of the square of the material permittivity in the denominator.
The small distance between the ground state of the impurity atoms and the edge of
the band explains the ease with which the dopants ionize at room temperature.</p>
<p/>
</div>
<div class="page"><p/>
<p>Part VI
</p>
<p>Transport Phenomena in Semiconductors</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 19
</p>
<p>Mathematical Model of Semiconductor Devices
</p>
<p>19.1 Introduction
</p>
<p>The chapter describes the reasoning that leads from the single-particle Schr&ouml;dinger
equation for an electron in a crystal to the mathematical model of semiconductor
devices. The latter is a set of equations describing the evolution in space and time
of a number of average quantities of interest: with reference to the electrons of the
conduction band or holes of the valence band, such quantities are the concentration,
average velocity, current density, average kinetic energy, and so on. The model of
semiconductor devices has different levels of complexity depending on the trade-off
between the information that one needs to acquire about the physical behavior of the
device under investigation and the computational cost of the system of differential
equations to be solved. In fact, the possible models are hierarchically ordered from
the drift-diffusion model, which is the simplest one, to the hydrodynamic model, and
so on. In essence, these models are different approaches to the problem of solving, in
a more or less simplified form, the Boltzmann Transport Equation. Those described
in this chapter are the most widely adopted in the commercial simulation programs
used by semiconductor Companies. Other important methods, that are not addressed
in this book, are the Monte Carlo method and the spherical-harmonics expansion.
</p>
<p>The steps leading to the mathematical model of semiconductor devices start with
a form of the single-particle Schr&ouml;dinger equation based on the equivalent Hamil-
tonian operator, where it is assumed that the external potential energy is a small
perturbation superimposed to the periodic potential energy of the nuclei; this leads
to a description of the collisionless electron&rsquo;s dynamics in terms of canonically-
conjugate variables, that are the expectation values of the wave packet&rsquo;s position and
momentum. The dynamics of the Hamiltonian type makes it possible to introduce
the statistical description of a many-electron system, leading to the semiclassical
Boltzmann Transport Equation. After working out the collision operator, the per-
turbative approximation is considered; the simplified form of the transport equation
thus found is tackled by means of the moments method, whence the hydrodynamic
and drift-diffusion versions of the model are derived. A detailed analysis of the
derivation of the electron and hole mobility in the parabolic-band approximation is
provided. Then, the semiconductor model is coupled with Maxwell&rsquo;s equation, and
</p>
<p>&copy; Springer Science+Business Media New York 2015 403
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_19</p>
<p/>
</div>
<div class="page"><p/>
<p>404 19 Mathematical Model of Semiconductor Devices
</p>
<p>the applicability of the quasi-static approximation is discussed. The typical boundary
conditions used in the analysis of semiconductor devices are shown, and an example
of analytical solution of the one-dimensional Poisson equation is given.
</p>
<p>The complements discuss the analogy between the equivalent Hamiltonian op-
erator and the corresponding Hamiltonian function introduced in an earlier chapter,
provide a detailed description of the closure conditions of the models, and illus-
trate the Matthiessen&rsquo;s rule for the relaxation times. Finally, a short summary of the
approximations leading to the derivation of the semiconductor model is given.
</p>
<p>19.2 Equivalent Hamiltonian Operator
</p>
<p>The separation procedure outlined in Sects. 16.2 through 16.5 has led to the single-
electron Schr&ouml;dinger Equation (17.40), namely, [ &minus; hÌ2/(2m)&nabla;2 + V ] w = E w,
where the nuclei are kept fixed and the force acting onto the electron derives from a
potential energy having the periodicity of the direct lattice: V (r + l) = V (r), with
l given by (17.1); as mentioned in Sects. 16.4, 16.5, the external forces are absent
(Uext = 0).
</p>
<p>Thanks to the periodicity of the Hamiltonian operator of (17.40) it is possible
to recast the time-independent Schr&ouml;dinger equation into a different form as shown
below. The procedure is based on the analogy with the Schr&ouml;dinger equation for a
free particle, &minus;&nabla;2 w = k2 w with k2 = 2mE/hÌ2. One notes in fact that the left hand
side is obtained by replacing k with &minus;i grad in the right hand side; this is just another
form of the transformation of momentum into the momentum operator (Sect. 8.5),
which in the present case yields the whole Hamiltonian operator because for a free
particle the energy is purely kinetic. This type of transformation can be pursued
also for the Schr&ouml;dinger equation with a periodic potential energy by observing that
the eigenvalues Ei(k), for each branch i, are periodic within the reciprocal, scaled
lattice, Ei(k + g) = Ei(k) (Sect. 17.6), hence they can be expanded in terms of the
direct-lattice translational vectors l (Sect. 17.3):
</p>
<p>Ei(k) =
&sum;
</p>
<p>l
</p>
<p>Eil exp (i l &middot; k) Eil = Ei(l) =
1
</p>
<p>Ïg
</p>
<p>&int;
</p>
<p>Ïg
</p>
<p>Ei(k) exp ( &minus; i l &middot; k) d3k.
</p>
<p>(19.1)
</p>
<p>The eigenvalue Ei(k) is now transformed into an operator by letting k &larr; &minus;i grad;
remembering (17.158), this yields
</p>
<p>Ei(k) &larr; Ei( &minus; i grad) =
&sum;
</p>
<p>l
</p>
<p>Eil exp (l &middot; grad) =
&sum;
</p>
<p>l
</p>
<p>Eil Tl. (19.2)
</p>
<p>The form of operator (19.2) is purely kinetic, as the space coordinates do not appear
in it. The shape of the potential energy V whenceEi(k) originates is embedded in the
coefficients Eil of expansion (19.1). To complete the procedure one must show that
operator (19.2) has the same eigenvalues and eigenfunctions as the original operator</p>
<p/>
</div>
<div class="page"><p/>
<p>19.2 Equivalent Hamiltonian Operator 405
</p>
<p>of [ &minus; hÌ2/(2m)&nabla;2 + V ] w = E w. Applying Ei( &minus; i grad) to a Bloch function wik
yields, using the first relation in (19.1) and the periodicity1 of Î¶ik (Sect. 17.6),
</p>
<p>&sum;
</p>
<p>l
</p>
<p>Eil Tl Î¶ik(r) exp (i k &middot; r) = Î¶ik(r)
&sum;
</p>
<p>l
</p>
<p>Eil exp [i k &middot; (r + l)] =
</p>
<p>= Î¶ik(r) exp (i k &middot; r)
&sum;
</p>
<p>l
</p>
<p>Eil exp (i k &middot; l) = wik(r)Ei(k). (19.3)
</p>
<p>The result
</p>
<p>Ei( &minus; i grad) wik = Ei(k) wik (19.4)
</p>
<p>shows that, for each branch i, the purely kinetic operator Ei( &minus; i grad) has the same
eigenvalues and eigenfunctions as the Hamiltonian whence Ei(k) originates. For this
reason, operatorEi(&minus;i grad) is called equivalent Hamiltonian. In summary, when the
potential energy is periodic it is possible to directly reconstruct an equivalent operator
by letting k &larr; &minus;i grad, in the same way as for a free particle. In this respect, the
latter case may be viewed as a limiting condition of the former one, obtained by
extending the period of the potential energy to infinity.2 Another similarity between
the free-particle case and that of a periodic potential energy is that the Hamiltonian
operator is purely kinetic (albeit, in the latter case, at the cost of a more complicate
form of the kinetic term).
</p>
<p>19.2.1 Electron Dynamics
</p>
<p>As illustrated in Sect. 17.6.1, the general solution of the time-dependent Schr&ouml;dinger
equation
</p>
<p>[
</p>
<p>&minus; hÌ
2
</p>
<p>2m
&nabla;2 + V (r)
</p>
<p>]
</p>
<p>Ï = i hÌ &part;Ï
&part;t
</p>
<p>, (19.5)
</p>
<p>for a particle subjected to a periodic potential energy V , is (17.51), or its
approximation using the wave packet of branch i = n,
</p>
<p>Ï(r, t) â Î¶n0 exp (iÎ¦n0)
&sum;
</p>
<p>k
</p>
<p>cnk exp [i (r &minus; un t) &middot; (k &minus; k0)] , (19.6)
</p>
<p>with Î¦n0 = k0 &middot; r &minus; Ïn0 t .
</p>
<p>1 Like in Sect. 17.6.1, the periodic part of the Bloch function is indicated with Î¶ik to avoid confusion
with the group velocity.
2 This method of reconstructing the operator from the eigenvalues was anticipated in Sect. 17.6.8.</p>
<p/>
</div>
<div class="page"><p/>
<p>406 19 Mathematical Model of Semiconductor Devices
</p>
<p>Now, consider the case where an external,3 non periodic potential energy U (r) is
added to the periodic one; the Hamiltonian operator becomes&minus;hÌ2/(2m)&nabla;2+V +U ,
yielding the eigenvalue equation
</p>
<p>[
</p>
<p>&minus; hÌ
2
</p>
<p>2m
&nabla;2 + V (r) + U (r)
</p>
<p>]
</p>
<p>w&prime;q = E&prime;q w&prime;q, (19.7)
</p>
<p>with q the label of the new eigenvalues.As the set w&prime;q is complete, a possible expansion
of Ï is
</p>
<p>Ï =
&sum;
</p>
<p>q
</p>
<p>c&prime;q w
&prime;
q exp ( &minus; iE&prime;q t/hÌ). (19.8)
</p>
<p>However, expansion (19.8) is inconvenient because the Hamiltonian operator in
(19.7) is not periodic; as a consequence, the properties of the eigenvalues and eigen-
functions typical of the periodic case are lost. A more suitable expansion4 is found
by using the eigenfunctions of the Hamiltonian operator corresponding to U = 0,
namely, the Bloch functions; in this case the coefficients of the expansion depend on
time:
</p>
<p>Ï =
&sum;
</p>
<p>ik
</p>
<p>aik(t) wik =
&sum;
</p>
<p>ik
</p>
<p>cik(t) wik exp ( &minus; iÏik t), (19.9)
</p>
<p>where cik = aik exp (iÏik t) &rarr; const as U &rarr; 0. This form is more convenient
because it holds also in the case where the external potential energy depends on time,
U = U (r, t). The approximate expression (19.6) of the wave function becomes
</p>
<p>Ï(r, t) â Î¶n0 exp (iÎ¦n0)A, A =
&sum;
</p>
<p>k
</p>
<p>cnk(t) exp [i (r &minus; un t) &middot; (k &minus; k0)] ,
</p>
<p>(19.10)
</p>
<p>with |Ï |2 = |Î¶n0|2 |A|2 and
&int;
</p>
<p>ï¿½
|Ï |2 d3r = 1. As Î¶n0 is a rapidly-varying function of
</p>
<p>r, the physical information about the dynamics of the wave packet is given by |A|2.
So far, the only approximation in (19.10) is the use of a single branch n of the
</p>
<p>dispersion relation. On the other hand it must be observed that in the sum V +U the
first term has the periodicity of the lattice, namely, it varies rapidly in space, whereas
the external potential energy is typically a slowly-varying function; in fact, it is due
to the application of external generators and/or to the presence of a non-uniform
distribution of charge within the material.5 Also, the field associated to U is weak,
</p>
<p>3 For the sake of simplicity, suffix &ldquo;ext&rdquo; is dropped from the symbol of the external energy.
4 The approach is the same as that used for treating the time-dependent perturbation theory (compare
with 14.4).
5 The field produced by non uniformities in the local charge density, which is present also in an
equilibrium condition if the dopant distribution is not spatially constant (compare with Sect. 18.5),
is classified as &ldquo;external&rdquo; because it can be treated as a perturbation. Instead, rapid variations of
the physical properties of the material, like those that typically occur at interfaces, can not be
treated using the perturbative method and require the solution of the Schr&ouml;dinger equation without
approximations.</p>
<p/>
</div>
<div class="page"><p/>
<p>19.2 Equivalent Hamiltonian Operator 407
</p>
<p>so that it does not influence the form of V . This leads to the idea of treating U as a
perturbation superimposed to the periodic Hamiltonian operator &minus;hÌ2/(2 m)&nabla;2 +V .
Using this approximation, the Hamiltonian operator of the perturbed problem is
rewritten as
</p>
<p>&minus; hÌ
2
</p>
<p>2m
&nabla;2 + V (r) + U (r, t) â En( &minus; i grad) + U (r, t), (19.11)
</p>
<p>where index n reminds one that the eigenfunctions of only the nth branch are used in
the expansion. The approximation inherent in (19.11) consists in using the properties
of the unperturbed problem in the perturbed case; in fact, the functional dependence
of En( &minus; i grad) on &minus;i grad derives from the unperturbed eigenvalues En(k). Re-
membering that En(&minus; i grad) is purely kinetic, (19.11) is similar to the Hamiltonian
operator of a particle subjected only to the external potential U . The approximate
form of the time-dependent Schr&ouml;dinger equation then reads
</p>
<p>[
</p>
<p>En( &minus; i grad) + U
]
</p>
<p>Ï = i hÌ &part;Ï
&part;t
</p>
<p>. (19.12)
</p>
<p>19.2.2 Expectation Values&mdash;Crystal Momentum
</p>
<p>The solution of (19.12) consists in determining the coefficients cnk(t) of (19.10);
this can be tackled by the method illustrated in Sect. 14.2, namely, by reducing
(19.12) to a system of coupled differential equations in the unknowns cnk. More
interesting it is to use (19.12) for calculating the expectation values of position and
momentum; remembering that Ï â exp (iÎ¦n0) Î¶n0 A is normalized to unity, one
readily finds ãrã = ãÏ |r|Ïã = r0, where r0 denotes the center of the wave packet in
the position space. As for momentum, it is ãpã = ãÏ | &minus; i hÌgrad|Ïã, namely, using
Î¦n0 = k0 &middot; r &minus; Ïn0 t ,
</p>
<p>ãpã = &minus;i hÌ
&int;
</p>
<p>ï¿½
</p>
<p>Ï&lowast;
[
</p>
<p>i k0 Ï + exp (iÎ¦n0) grad(Î¶n0 A)
]
</p>
<p>d3r =
</p>
<p>= hÌ k0
&int;
</p>
<p>ï¿½
</p>
<p>|Ï |2 d3r &minus; i hÌ
&int;
</p>
<p>ï¿½
</p>
<p>(Î¶n0A)
&lowast; grad(Î¶n0 A) d
</p>
<p>3r. (19.13)
</p>
<p>The first term at the right hand side of (19.13) yields hÌ k0 due to normaliza-
tion. Letting Î¶n0 A = a + i b, one finds in the second term (Î¶n0 A)&lowast; grad(Î¶n0 A) =
(1/2) grad(a2 + b2)+ i (a gradb&minus; b grada). The contribution of grad(a2 + b2) to the
integral is zero due to normalization; since A is slowly varying and normalizable,
while Î¶n0 oscillates rapidly, it follows
</p>
<p>ãpã = hÌ k0 + hÌ
&int;
</p>
<p>ï¿½
</p>
<p>(a gradb &minus; b grada) d3r â hÌ k0, (19.14)</p>
<p/>
</div>
<div class="page"><p/>
<p>408 19 Mathematical Model of Semiconductor Devices
</p>
<p>with k0 the center of the wave packet in the k space. The product hÌ k0 is called crystal
momentum. As for the time derivatives of ãrã and ãpã one finds, from (17.52),
</p>
<p>rÌ0 = un =
1
</p>
<p>hÌ
</p>
<p>(
</p>
<p>gradkEn
)
</p>
<p>k0
= i
</p>
<p>hÌ
</p>
<p>&sum;
</p>
<p>l
</p>
<p>lEil exp (i l &middot; k0), (19.15)
</p>
<p>where the last expression derives from (19.1). For the time derivative of momentum
one preliminarily observes that En( &minus; i grad) commutes with the gradient operator;
in fact,
</p>
<p>En( &minus; i grad) gradÏ =
&sum;
</p>
<p>l
</p>
<p>EnlTl gradÏ(r, t) =
&sum;
</p>
<p>l
</p>
<p>Enl gradÏ(r + l, t), (19.16)
</p>
<p>grad En( &minus; i grad)Ï = grad
&sum;
</p>
<p>l
</p>
<p>Enl Ï(r + l, t) =
&sum;
</p>
<p>l
</p>
<p>Enl gradÏ(r + l, t).
</p>
<p>(19.17)
</p>
<p>Then, using definition (10.24) of the time derivative of an expectation value,6 and
remembering that the operator associated to p is &minus;i hÌ grad, one finds
</p>
<p>hÌ kÌ0 =
dãpã
dt
</p>
<p>= ãÏ |
[
</p>
<p>En( &minus; i grad) + U
]
</p>
<p>grad &minus; grad
[
</p>
<p>En( &minus; i grad) + U
]
</p>
<p>|Ïã.
(19.18)
</p>
<p>Moreover it is U gradÏ &minus; grad(U Ï) = &minus;Ï gradU , so that (19.18) eventually
reduces to
</p>
<p>hÌkÌ0 =
dãpã
dt
</p>
<p>= &minus;
&int;
</p>
<p>Î©
</p>
<p>|Ï |2 gradU d3r. (19.19)
</p>
<p>As U is slowly-varying in space, Ehrenfest approximation (10.33) applies, whence
</p>
<p>hÌ kÌ0 =
dãpã
dt
</p>
<p>â &minus; (gradU)r0 . (19.20)
</p>
<p>Introducing the function Hn(r0, k0, t) = En(k0) + U (r0, t), one finds that (19.15)
and (19.20) are equivalent, respectively, to
</p>
<p>xÌi 0 =
&part;Hn
</p>
<p>&part;(hÌ ki 0)
, hÌ kÌi 0 = &minus;
</p>
<p>&part;Hn
</p>
<p>&part;xi 0
, i = 1, 2, 3. (19.21)
</p>
<p>Relations (19.21) are of paramount importance in solid-state theory. They show in fact
that within a periodic lattice the dynamics of the expectation values of a wave packet,
subjected to an external potential energy that varies slowly in space, is described by
Hamilton equations (compare with (1.42)), where r0 = ãrã and hÌ k0 = ãpã play the
role of position and momentum, respectively. It follows that Hn is a Hamiltonian
</p>
<p>6 Definition (10.24) could be used also for deriving (19.15).</p>
<p/>
</div>
<div class="page"><p/>
<p>19.2 Equivalent Hamiltonian Operator 409
</p>
<p>function proper. Another important observation is that the time variations of the
wave packet&rsquo;s momentum are due to the external force only; as a consequence, if
U = const one has hÌ kÌ0 = 0, namely, the crystal momentum is a constant of motion.
</p>
<p>A further insight into the structure of Hn is obtained by calculating the work
exerted onto the wave packet by the external force &minus;gradr0U = hÌ kÌ0 during an
elementary time dt :
</p>
<p>dW = hÌ kÌ0 &middot; dr0 = hÌ kÌ0 &middot; un dt = hÌ un &middot; dk0 =
(
</p>
<p>gradkEn
)
</p>
<p>k0
&middot; dk0 = dEn.
</p>
<p>(19.22)
</p>
<p>The work equals the variation of En; it follows that En, apart from an additive
constant, is the kinetic energy of the wave packet. In turn, U is the potential energy
which, as mentioned above, derives from the external force only. If the force acting
on the electron is due to an electric field, then U = &minus;q Ï; this justifies the modified
form (18.54) of the Fermi&ndash;Dirac statistics to be used when an electric field is present.7
</p>
<p>In the more general case where a magnetic field is also acting on the electron, hÌ Î´kÌ
is given by the Lorentz force
</p>
<p>hÌ Î´kÌ = F = &minus;q (E + un &and; B) , (19.23)
and the Hamiltonian operator in (19.12) must be modified accordingly (compare
with (9.19)).
</p>
<p>It is important to remark again that the description of the wave packet&rsquo;s dynamics
given in this section holds when the force is a weak perturbation with respect to the
unperturbed situation. As a consequence, the description does not apply when the
electron undergoes a collision; in fact, the force acting during a collision is strong
and can not be treated as a perturbation.
</p>
<p>19.2.3 Dynamics in the Parabolic-Band Approximation
</p>
<p>When the wave packet is centered onto a wave vector k0 near the ath minimum of
the conduction band, the diagonal expansion of En(k) yields (17.57). Dropping the
branch index n and letting k = k0, Î´ki = ki0 &minus; kia yields
</p>
<p>Ee = E(k0) &minus; EC â
1
</p>
<p>2
</p>
<p>3
&sum;
</p>
<p>i=1
</p>
<p>hÌ2
</p>
<p>mia
(ki0 &minus; kia)2 =
</p>
<p>1
</p>
<p>2
hÌ Î´k &middot;
</p>
<p>(
</p>
<p>mÌa
)&minus;1
</p>
<p>hÌ Î´k &ge; 0,
</p>
<p>(19.24)
</p>
<p>with (mÌa)&minus;1 given by (17.58). Expression (19.24) bears a strong similarity with the
kinetic energy of the classical case. The same comment applies to the expression of
group velocity given by (17.61), namely,
</p>
<p>u =
(
</p>
<p>mÌa
)&minus;1
</p>
<p>hÌ Î´k. (19.25)
</p>
<p>7 More comments about the analogy with the perturbation theory in the classical case are made in
Sect. 19.6.1.</p>
<p/>
</div>
<div class="page"><p/>
<p>410 19 Mathematical Model of Semiconductor Devices
</p>
<p>Replacing (19.25) into (19.24) yieldsEe = (1/2) mÌau&middot;u. When the expectation value
hÌ k0 of momentum coincides with hÌ ka , corresponding to an absolute minimum EC
of the conduction band, it is Ee = 0. Such a value is also the minimum of the
positive-definite quadratic form at the right hand side of (19.24). This shows that Ee
is the kinetic energy of the electron, and allows one to identify EC as the additive
constant mentioned above.
</p>
<p>In general, the relation between force and acceleration within a crystal is
anisotropic. For the sake of simplicity consider the case of the parabolic-band
approximation; the time derivative of (19.25) then yields
</p>
<p>uÌ =
(
</p>
<p>mÌa
)&minus;1
</p>
<p>hÌ Î´kÌ =
(
</p>
<p>mÌa
)&minus;1
</p>
<p>F. (19.26)
</p>
<p>If the entries of the mass tensor are different from each other, the acceleration is
not parallel to the force; the physical reason for this is easily understood if one thinks
that the forces due to the crystal structure are embedded in the mass tensor through
the second derivatives of E(k). The mass tensor becomes a scalar only if the branch
E is isotropic: mÌa = ma I, with I the identity tensor. More comments about this
issue are made in Sect. 19.6.2.
</p>
<p>The analysis for the valence band is similar. Again, the branch index n is dropped
and symbols k = k0, Î´ki = ki0 &minus; kia are used,8 to find (17.64), namely,
</p>
<p>Eh = EV &minus; E(k0) â
1
</p>
<p>2
</p>
<p>3
&sum;
</p>
<p>i=1
</p>
<p>hÌ2
</p>
<p>mia
(ki0 &minus; kia)2 =
</p>
<p>1
</p>
<p>2
hÌ Î´k &middot; (mÌa)&minus;1 hÌ Î´k &ge; 0,
</p>
<p>(19.27)
</p>
<p>with (mÌa)&minus;1 given by (17.63), mia &gt; 0. For the group velocity one finds
</p>
<p>u = 1
hÌ
</p>
<p>(
</p>
<p>gradkE
)
</p>
<p>k0
= &minus;
</p>
<p>(
</p>
<p>mÌa
)&minus;1
</p>
<p>hÌ Î´k. (19.28)
</p>
<p>The work exerted onto the wave packet by the external force &minus;gradr0U = hÌ kÌ0
during an elementary time dt is
</p>
<p>dW = hÌ kÌ0 &middot; u dt = d
[
</p>
<p>&minus;
3
</p>
<p>&sum;
</p>
<p>i=1
</p>
<p>hÌ2
</p>
<p>2mia
Î´k2i
</p>
<p>]
</p>
<p>= dE, (19.29)
</p>
<p>which, again, shows that E is the kinetic energy of the electron apart from an addi-
tive constant. The negative signs in (19.27) and (19.28) make the discussion of the
valence-band case somewhat awkward; however, the difficulty is readily eliminated
if one refers to holes instead of electrons. For example, consider the case of an elec-
tron whose expectation value of momentum, initially equal to hÌ ka , is brought by
the action of an external field to some other value hÌ k&prime;0 in the vicinity of hÌ ka . For
</p>
<p>8 For Si, Ge, and GaAs it is kia = 0 (Sect. 17.6.5).</p>
<p/>
</div>
<div class="page"><p/>
<p>19.3 Dynamics in the Phase Space 411
</p>
<p>this transition to occur it is implied that the initial state ka is occupied9 and the final
state k&prime;0 is empty. As a consequence of (19.27), E changes from EV to E(k
</p>
<p>&prime;
0) &lt; EV ,
</p>
<p>namely, it decreases during the time interval ï¿½t during which the energy variation
occurs; hence, the external field has exerted in ï¿½t a negative work onto the electron,
in fact, energy has been absorbed from the electron by the field. If a hole is considered
instead, the initial and final states of the transition exchange roles; however, from
the standpoint of the energy balance nothing changes, namely, the field still absorbs
energy from the particle. It follows that the hole&rsquo;s energy must decrease due to the
transition: this is possible only if the energy axis associated to the hole is reversed
with respect to that of the electron, so that, apart from an additive constant, the hole&rsquo;s
kinetic energy is&minus;E. From this point on, the reasoning becomes identical to that out-
lined above for the electron of the valence band: using (19.27), when the expectation
value hÌ k0 of momentum coincides with hÌ ka , corresponding to an absolute maxi-
mum EV of the valence band, it is Eh = 0. Such a value is also the minimum of the
positive-definite quadratic form at the right hand side of (19.27). This shows thatEh is
the kinetic energy of the hole, and allows one to identify EV as the additive constant.
</p>
<p>19.3 Dynamics in the Phase Space
</p>
<p>The theory outlined in Sects. 19.2, 19.2.1, and 19.2.2 has led to the conclusion that the
dynamics of the expectation values of a wave packet describing an electron&rsquo;s motion,
subjected to an external potential energy that varies slowly in space, is described by
the Hamilton equations (19.21) where ãrã and ãpã play the role of position and
momentum.
</p>
<p>For a system made of a large number of electrons, the description of the dynamics
of the individual wave packets is impossible from the practical standpoint. In this
case one resorts to the same device as that used in Sect. 6.2 for a system of classical
particles, namely, the distribution function. Being the formal apparatus identical to
that of Sect. 6.2, only the relevant differences will be remarked. The &micro;-type phase
space is defined here by the variables
</p>
<p>s =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â£
</p>
<p>x1
</p>
<p>x2
</p>
<p>x3
</p>
<p>k1
</p>
<p>k2
</p>
<p>k3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¦
</p>
<p>, e =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â¢
â£
</p>
<p>&part;H/&part;k1
</p>
<p>&part;H/&part;k2
</p>
<p>&part;H/&part;k3
</p>
<p>&minus;&part;H/&part;x1
&minus;&part;H/&part;x2
&minus;&part;H/&part;x3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¥
â¦
</p>
<p>, (19.30)
</p>
<p>9 For the sake of simplicity, spin is not considered here.</p>
<p/>
</div>
<div class="page"><p/>
<p>412 19 Mathematical Model of Semiconductor Devices
</p>
<p>(compare with (1.57)) so that the distribution function10 reads f = f (r, k, t). Note
that the units of f are different from those of the classical distribution function. For
the latter, in fact, it is [f&micro;] = (J s)&minus;3, so that the product f&micro; d3r d3 p is dimensionless
(compare with (6.1)); in the present case, instead, both f d3r d3k and d3r d3k are
dimensionless, hence the distribution function itself is dimensionless.
</p>
<p>The system considered for the investigation is that of the electrons belonging to
the conduction band. Remembering the first relation in (6.3), the concentration and
average velocity of such electrons are given by
</p>
<p>n(r, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
f (r, k, t) d3k, v(r, t) = 1
</p>
<p>n
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u(k) f (r, k, t) d3k,
</p>
<p>(19.31)
</p>
<p>with u the electron&rsquo;s group velocity. In the equilibrium condition it is f eq = QP ,
where the Fermi&ndash;Dirac statistics P depends on k only through E(k), namely, it is
even with respect to k. In turn, u = (1/hÌ) gradkE is odd, so that the whole integrand
in the second definition of (19.31) is odd. As the integration domain is symmetric
with respect to k = 0, it is veq = 0 as should be. In a non-equilibrium condition it is
f = QÎ¦, withÎ¦(r, k) the occupation probability of a state. If the band is completely
filled, then Î¦ = 1, and the electron flux n v becomes proportional to the integral of
u; as the latter is odd, the flux vanishes: this explains why a completely filled band
does not contribute to the material&rsquo;s conduction, as anticipated in Sect. 17.6.5.
</p>
<p>The Boltzmann collisionless equation in the r, k space is derived in the same
manner as for (6.28); it reads
</p>
<p>&part;f
</p>
<p>&part;t
+ rÌ &middot; gradrf + kÌ &middot; gradkf = 0. (19.32)
</p>
<p>The effects of collisions may be grouped into two classes: the collisions of the
first class induce transitions that change the number of electrons of the band. Such
transitions are the generations and recombinations introduced in Sect. 17.6.6, where
the initial state of the electron belongs to the conduction band and the final one belongs
to the valence band, or vice versa.11 The transitions of this class are collectively called
inter-band transitions.
</p>
<p>The collisions of the second class are those where the initial and final state belong
to the same band, and are called intra-band transitions; they do not change the
number of electrons of the band. The distinction between the two classes is useful
because the inter-band transitions exhibit characteristic times that are much larger
than those of the intra-band transitions. In turn, the intra-band transitions are further
divided into two subclasses: the intra-valley transitions, where the initial and final
</p>
<p>10 Suffix &micro; is dropped to distinguish this distribution function from that of the classical case.
11 In addition to this one must also consider the trapping-detrapping phenomena involving localized
states. So far, only the localized states due to dopants have been considered (Sect. 18.4); other types
of localized states are introduced in Chap. 20.</p>
<p/>
</div>
<div class="page"><p/>
<p>19.3 Dynamics in the Phase Space 413
</p>
<p>states are in the vicinity of the same extremum of the band, and the inter-valley
transitions, where the initial and final state are in the vicinity of different extrema.12
</p>
<p>Within each class, the transitions are further grouped depending on the entity with
which the collision occurs; typical examples of collisions are those with phonons,
impurities, defects, and photons. Like in the classical case, collisions are not ac-
counted for in the derivation of (19.32), where the effect of only the slowly-varying
external potential energy is present; the further time change of f due to collisions
is more conveniently kept separate from that of the external potential energy. Also,
it is assumed that the system under consideration is dilute, so that each wave packet
spends a relatively large fraction of time without suffering any collision; in other
terms, the time during which an electron is subjected to the external field is much
longer than that involved in a collision. For this reason it is preferable to write the
Boltzmann equation, when the collisions are accounted for, as
</p>
<p>&part;f
</p>
<p>&part;t
+ u &middot; gradrf &minus;
</p>
<p>q
</p>
<p>hÌ
(E + u &and; B) &middot; gradkf = C (19.33)
</p>
<p>(compare with (6.29) and (6.31)). To derive (19.33), the expression (19.23) of the
Lorentz force acting on the electron is used, after dropping index n from the group
velocity. Term C embeds the forces acting during the collisions; such forces are
short ranged and much more intense than those due to the external field; as a
consequence, the Ehrenfest approximation (10.33) does not apply, so that a full
quantum-mechanical approach is necessary to treat the collision term.
</p>
<p>In conclusion, the relations involving the expectation values at the left hand side
of (19.33) are formally identical to those of the classical case, whereas the right hand
side is calculated by quantum methods. The form (19.33) of the Boltzmann Transport
Equation (BTE) is also called semiclassical.
</p>
<p>19.3.1 Collision Term
</p>
<p>The left hand side of (19.33) equals df/dt , whence the right hand side is the rate of
change of f due to collisions. As f (r, k, t) d3r d3k is the number of electrons of the
conduction band that at time t belong to the elementary volume d3r d3k centered on
(r, k), the rate of change can be expressed as
</p>
<p>C = Cin &minus; Cout, (19.34)
</p>
<p>where Cin d3r d3k is the number of electrons entering d3r d3k per unit time, due to
collisions, and Cout d3r d3k is the number of electrons leaving d3r d3k per unit time,
due to collisions. To illustrate the reasoning it is convenient to refer to Fig. 19.1,
</p>
<p>12 Here the extrema are the minima of the conduction band. The region near an extremum of a band
is also called valley.</p>
<p/>
</div>
<div class="page"><p/>
<p>414 19 Mathematical Model of Semiconductor Devices
</p>
<p>Fig. 19.1 Example of the
time evolution of a
phase-space domain in a
one-dimensional case. The
situation with no external
force is considered
</p>
<p>A
</p>
<p>D
1
</p>
<p>1
B
</p>
<p>1
</p>
<p>1
C
</p>
<p>2
C
</p>
<p>2
A B
</p>
<p>2
</p>
<p>2
D
</p>
<p>x
</p>
<p>k
</p>
<p>where a one-dimensional case is illustrated using the x, k coordinates. Instead of an
elementary volume dx dk, a finite, rectangular cell is considered, whose position at
time t1 is fixed by the vertices A1, B1, C1, and D1. For simplicity it is assumed that
no external force is present (U = const), so that the crystal momentum is conserved.
In particular, the vertices&rsquo; momenta at t = t1 are hÌ km = hÌ k(A1) = hÌ k(B1) and
hÌ kM = hÌ k(C1) = hÌ k(D1). The corresponding positions are x(A1) = x(C1) = 0,
x0 = x(B1) = x(D1). Letting m&lowast; indicate the effective mass, the position of the
vertices at a subsequent time t2 = t1 +ï¿½t is
</p>
<p>x(A2) =
hÌkm
</p>
<p>m&lowast;
ï¿½t , x(B2) = x0 + x(A2), x(C2) =
</p>
<p>hÌkM
</p>
<p>m&lowast;
ï¿½t , x(D2) = x0 + x(C2),
</p>
<p>this giving rise to the parallelogram also shown in Fig. 19.1. If no collisions occur,
the electrons inside the parallelogram at t = t2 are the same as those that were
inside the rectangle at t = t1; in contrast, when collisions occur, some electrons
leave the rectangle without reaching the parallelogram (hence, Cout ï¿½= 0), while
the parallelogram is reached by other electrons that originally did not belong to the
rectangle (Cin ï¿½= 0). This is schematically indicated by the arrows in Fig. 19.1. In
general it is Cout ï¿½= Cin, so that df/dt ï¿½= 0. The description is the same also in
the case when the external force is present, the difference being that the trajectories
in the phase space are not rectilinear and the deformation of the domain is more
complicate.
</p>
<p>To give the analysis a more formal aspect it is necessary to determine how the
population of the elementary domain d6s = d3r d3k evolves in the elementary time
interval dt . To begin, one introduces the scattering probability per unit time and unit
phase volume, S, from an initial state to a final state of the phase space.13 The initial
</p>
<p>13 The units of S are [S] = s&minus;1.</p>
<p/>
</div>
<div class="page"><p/>
<p>19.3 Dynamics in the Phase Space 415
</p>
<p>(final) state is indicated by the first (second) pair of arguments of S, namely,
</p>
<p>S
(
</p>
<p>r, k &rarr; r&prime;, k&prime;
)
</p>
<p>d3r &prime; d3k&prime; (19.35)
</p>
<p>is the probability per unit time that an electron scatters from (r, k) to the elementary
volume d3r &prime; d3k&prime; centered at (r&prime;, k&prime;). Then, let dNin = Cin d6s, dNout = Cout d6s,
and s = (r, k), s&prime; = (r&prime;, k&prime;). The number dNin is determined by observing that the
electrons contributing to it are those that initially belong to elementary phase-space
volumes, say, d6s &prime;, different from d6s. The population of d6s &prime; at time t is f (s&prime;, t) d6s &prime;;
if the latter is multiplied by the scattering probability per unit time from s&prime; to d6s,
given by S
</p>
<p>(
</p>
<p>s&prime; &rarr; s
)
</p>
<p>d6s, the unconditional number of transitions from d6s &prime; to d6s is
obtained. The actual number of such transitions is then found by remembering that
electrons are fermions, so that transitions towards d6s are possible only if the final
states are empty; in other terms, the unconditional number of s&prime; &rarr; s transitions must
be multiplied by 1 &minus; Î¦(s, t), where Î¦(s, t) is the probability that the final state is
full. Finally, the contributions of all elementary volumes d6s &prime; must be added up, to
find14
</p>
<p>dNin =
&int;
</p>
<p>s&prime;
</p>
<p>[
</p>
<p>f (s&prime;, t) d6s &prime;
] [
</p>
<p>S
(
</p>
<p>s&prime; &rarr; s
)
</p>
<p>d6s
]
</p>
<p>[1 &minus;Î¦(s, t)] . (19.36)
</p>
<p>The derivation of dNout is similar; one obtains
</p>
<p>dNout =
&int;
</p>
<p>s&prime;
</p>
<p>[
</p>
<p>f (s, t) d6s
] [
</p>
<p>S
(
</p>
<p>s &rarr; s&prime;
)
</p>
<p>d6s &prime;
] [
</p>
<p>1 &minus;Î¦(s&prime;, t)
]
</p>
<p>. (19.37)
</p>
<p>The collision term C = Cin &minus; Cout is now determined by subtracting (19.37) from
(19.36) and dividing the result by d6s. This shows that C is the sum of two terms;
the first one is linear with respect to f and reads
</p>
<p>&int;
</p>
<p>s&prime;
</p>
<p>[
</p>
<p>f (s&prime;, t) S
(
</p>
<p>s&prime; &rarr; s
)
</p>
<p>&minus; f (s, t) S
(
</p>
<p>s &rarr; s&prime;
)]
</p>
<p>d6s &prime;. (19.38)
</p>
<p>As for the second term, one must preliminarily observe that f = QÎ¦, with Q =
1/(4Ï3) the density of states in the phase space, (17.50); then, the second term of C
turns out to be quadratic with respect to Î¦ or f :
</p>
<p>Q
</p>
<p>&int;
</p>
<p>s&prime;
Î¦(s, t)Î¦(s&prime;, t)
</p>
<p>[
</p>
<p>S
(
</p>
<p>s &rarr; s&prime;
)
</p>
<p>&minus; S
(
</p>
<p>s&prime; &rarr; s
)]
</p>
<p>d6s &prime;. (19.39)
</p>
<p>14 For the sake of conciseness, in Sects. 19.3.1, 19.3.2, and 19.3.3 the six-fold integrals over d3r &prime; d3k&prime;
</p>
<p>and the three-fold integrals over d3k&prime; are indicated with
&int;
</p>
<p>s&prime; and
&int;
</p>
<p>k&prime; , respectively.</p>
<p/>
</div>
<div class="page"><p/>
<p>416 19 Mathematical Model of Semiconductor Devices
</p>
<p>Fig. 19.2 Qualitative picture
of a collision between an
electron and a
negatively-ionized impurity.
The latter is schematically
represented by the black
circle, whereas the gray area
indicates the screening region.
The initial and final state of
the electron are indicated with
(r, k) and (r&prime;, k&prime;), respectively
</p>
<p>r, k r&rsquo;, k&rsquo;
</p>
<p>19.3.2 Point-Like Collisions
</p>
<p>The two summands (19.38), (19.39) in the expression of C are substantially simpli-
fied thanks to the property that the collisional forces, albeit very strong, are short
ranged; as a consequence, whereas the momentum of the colliding electron may
undergo a large change due to the collision, the electron&rsquo;s position changes little.
The issue is illustrated with the aid of Fig. 19.2, that schematically describes an
electron collision with a negatively-ionized dopant. The latter is represented by the
black circle, whereas the gray region around it indicates the positive charge attracted
by the negative ion; such a positive charge acts like an electric screen that tends to
neutralize the ion. As a consequence of the screen, the decay of the electrostatic po-
tential acting between the ion and the incoming electron, when the relative distance
increases, is much stronger than in the pure Coulomb case.15 In practice, one can
assume that the electron-ion repulsion is non negligible only when the electron is
inside the screen. This makes the dynamics of the interaction rather different from
that of the pure Coulomb case, treated in Sect. 3.8. As shown in the figure, the final
momentum k&prime; may differ largely from the initial one, k; in contrast, considering the
atomic scale of the phenomenon, the final position r&prime; may be thought of as coinciding
with the initial one, r. To vest this observation with mathematical form, considering
that the scattering probability in (19.38) and (19.39) undergoes an integration over
r&prime;, one lets16
</p>
<p>S
(
</p>
<p>s &rarr; s&prime;
)
</p>
<p>= S0
(
</p>
<p>r, k &rarr; k&prime;
)
</p>
<p>Î´(r&prime; &minus; r). (19.40)
</p>
<p>Another important consequence of the above discussion is that, although the
duration of the interaction is very short, the force acting on the electron due the
interaction is much stronger than the external forces, to the extent that the effects of
</p>
<p>15 The derivation and treatment of the screened Coulomb interaction are carried out in Sects. 20.6.4
and 14.7, respectively.
16 Note that the units of S0 are different from those of S: in fact, [S0] = cm3/s. Examples of
calculations of phonon scattering and ionized-impurity scattering are given in Sects. 20.5.1 and
20.5.2, respectively.</p>
<p/>
</div>
<div class="page"><p/>
<p>19.3 Dynamics in the Phase Space 417
</p>
<p>the latter can be neglected during the interaction itself. It follows that S and S0 do
not depend on the external forces; this greatly simplifies the analysis of S0. Inserting
(19.40) into (19.38) yields, for the first part of C,
</p>
<p>&int;
</p>
<p>k&prime;
</p>
<p>[
</p>
<p>f (r, k&prime;, t) S0
(
</p>
<p>r, k&prime; &rarr; k
)
</p>
<p>&minus; f (r, k, t) S0
(
</p>
<p>r, k &rarr; k&prime;
)]
</p>
<p>d3k&prime; ; (19.41)
</p>
<p>in turn, the second part (19.39) becomes
</p>
<p>Q
</p>
<p>&int;
</p>
<p>k&prime;
Î¦(r, k, t)Î¦(r, k&prime;, t)
</p>
<p>[
</p>
<p>S0
(
</p>
<p>r, k &rarr; k&prime;
)
</p>
<p>&minus; S0
(
</p>
<p>r, k&prime; &rarr; k
)]
</p>
<p>d3k&prime;. (19.42)
</p>
<p>The term S0 is typically calculated using the first-order perturbation theory
(Sect. 14.3), which shows that the transition probability is invariant upon rever-
sal of the initial and final states. It follows that the quantity in brackets in (19.42)
vanishes, so that (19.41) is in fact the only contribution to C. The latter is recast in a
more compact form by defining the relaxation time Ï (r, k) and the collision operator
fÌ (r, k) such that
</p>
<p>1
</p>
<p>Ï
=
</p>
<p>&int;
</p>
<p>k&prime;
S0
</p>
<p>(
</p>
<p>r, k &rarr; k&prime;
)
</p>
<p>d3k&prime;, fÌ =
&int;
</p>
<p>k&prime; f (r, k
&prime;, t) S0
</p>
<p>(
</p>
<p>r, k&prime; &rarr; k
)
</p>
<p>d3k&prime;
&int;
</p>
<p>k&prime; S0 (r, k &rarr; k&prime;) d3k&prime;
,
</p>
<p>(19.43)
</p>
<p>to find C = Cin &minus; Cout = (fÌ &minus; f )/Ï . The BTE (19.33) thus becomes
</p>
<p>&part;f
</p>
<p>&part;t
+ u &middot; gradrf &minus;
</p>
<p>q
</p>
<p>hÌ
(E + u &and; B) &middot; gradkf = &minus;
</p>
<p>f &minus; fÌ
Ï
</p>
<p>. (19.44)
</p>
<p>In the derivation of (19.44) no distinction is made between the inter-band and
intra-band transitions. For a dilute system one can assume that the transitions of
the two types are uncorrelated, so that the corresponding probabilities are additive:
S0 = S0b + S0v, where index b (v) stands for &ldquo;inter-band" (&ldquo;intra-band"). As a
consequence,
</p>
<p>1
</p>
<p>Ï
= 1
</p>
<p>Ïb
+ 1
</p>
<p>Ïv
,
</p>
<p>1
</p>
<p>Ïb
=
</p>
<p>&int;
</p>
<p>k&prime;
S0b d
</p>
<p>3k&prime;,
1
</p>
<p>Ïv
=
</p>
<p>&int;
</p>
<p>k&prime;
S0v d
</p>
<p>3k&prime;. (19.45)
</p>
<p>For the semiconductors of interest, the relaxation times defined in (19.45) differ
by several orders of magnitude (e.g., in electronic-grade silicon17 is Ïb &gt; 10&minus;6 s,
Ïv &lt; 10&minus;12 s). This makes the intra-band transitions dominant (Ï = Ïb Ïv/(Ïb+Ïv) â
Ïv); one exception exists though, where the effects of the intra-band transitions cancel
each other exactly, so that the inter-band transitions only are left. Such an exception
is discussed in Sect. 19.4.
</p>
<p>17 The semiconductor&rsquo;s purification degree necessary for manufacturing integrated circuit is called
electronic grade; it indicates that the ratio between the concentration of impurities (different from
dopants) and that of the semiconductor atoms is smaller than 10&minus;9. Lower-quality materials, with a
ratio smaller than 10&minus;6, are used in the fabrication of solar cells; in this case the purification degree
is called solar grade.</p>
<p/>
</div>
<div class="page"><p/>
<p>418 19 Mathematical Model of Semiconductor Devices
</p>
<p>19.3.3 Perturbative Form of the BTE
</p>
<p>The Boltzmann Transport equation (19.44) is an integral-differential equation in the
phase space and time, in the unknownf . The kernel of the integral part isS0, while the
equation coefficients are E(r, t), B(r, t), Ï (r, k), and u(k) = (1/hÌ) gradkH . In equi-
librium f becomes f eq = QP , with P (r, k) the Fermi&ndash;Dirac statistics; as shown in
Sect. 19.2.2, P depends on position if the semiconductor is not uniform. Moreover
it is df eq/dt = 0; hence, to make the collision term to vanish at equilibrium, it must
be fÌ eq = f eq (detailed-balance principle, Sect. 6.5).
</p>
<p>In general, the solution of the BTE is quite a difficult task. The issue of effective
solution methods for this equation will be introduced later; however, a solution
procedure is outlined here which, although seldom used in practical cases, has the
advantage of providing a simplified form of (19.44), upon which a number of models
for semiconductor-device analysis are based. The procedure consists in setting up
the iterative scheme
</p>
<p>df (m+1)
</p>
<p>dt
= &minus;f
</p>
<p>(m+1) &minus; fÌ (m)
Ï
</p>
<p>, fÌ (m) =
&int;
</p>
<p>k&prime; f
(m) S0 d3k&prime;
</p>
<p>&int;
</p>
<p>k&prime; S0 d
3k&prime;
</p>
<p>. (19.46)
</p>
<p>with m the iteration index. In this way the fÌ (m) term at the right hand side of the
first equation in (19.46) is known from the previous iteration, so that the integral-
differential equation is transformed into a number of differential-only equations.
If convergence occurs, the iterations are brought to an end when a suitable norm
||f (m+1) &minus; f (m)|| is smaller than a prescribed value.
</p>
<p>To start the procedure it is reasonable to choose, for the approximation of order
zero, the equilibrium distribution: f (0) = f eq; from the detailed-balance principle it
follows fÌ (0) = f eq. The first step of the iteration procedure then yields f (1), called
first-perturbation solution. In many cases of practical interest, the material or device
under investigation is sufficiently close to the equilibrium condition to make f (1) an
acceptable solution; one then stops the iterations at the first-perturbation solution
and takes f â f (1). This is equivalent to solving the perturbative form of the BTE
</p>
<p>&part;f
</p>
<p>&part;t
+ u &middot; gradrf &minus;
</p>
<p>q
</p>
<p>hÌ
(E + u &and; B) &middot; gradkf = &minus;
</p>
<p>f &minus; f eq
Ï
</p>
<p>. (19.47)
</p>
<p>It is interesting to comment on the form of (19.47). The first term at the left
hand side differs from zero only if the distribution function depends explicitly on
time; hence, it vanishes in a non-equilibrium condition if the latter is of the steady-
state type. The second term vanishes if the distribution function is independent of
the spatial coordinates, hence it describes a contribution to electron transport that
originates from a spatial non uniformity. For this reason this term is called diffusive
term (compare with Sect. 23.3). The third term vanishes if the external force is
missing, hence it originates from the action of the external forces on the electrons
and, for this reason, is called drift term. At the right hand side of (19.47), the
magnitude of the relaxation time influences the amount by which the distribution</p>
<p/>
</div>
<div class="page"><p/>
<p>19.4 Moments Expansion of the BTE 419
</p>
<p>function departs from equilibrium; to better show this, one recasts (19.47) as
</p>
<p>f = f eq &minus; Ï Lf , L = &part;
&part;t
</p>
<p>+ u &middot; gradr &minus;
q
</p>
<p>hÌ
(E + u &and; B) &middot; gradk, (19.48)
</p>
<p>with L the Liouvillian operator. If Ï &rarr; 0, then f &rarr; f eq; this shows that the
perturbative solution is in fact acceptable if the relaxation time is sufficiently small.18
</p>
<p>A final comment refers to the spatially-uniform case, where f = f (k, t), Ï =
Ï (k); then, (19.47) simplifies to
</p>
<p>&part;f
</p>
<p>&part;t
&minus; q
</p>
<p>hÌ
(E + u &and; B) &middot; gradkf = &minus;
</p>
<p>f &minus; f eq
Ï
</p>
<p>. (19.49)
</p>
<p>If the fields are set to zero at some instant of time, say, t = 0, (19.49) reduces to a
differential equation with respect to time only, with k a parameter; thus, for each k
the solution approaches the equilibrium distribution19 according to the law
</p>
<p>f = f eq + (ft=0 &minus; f eq) exp ( &minus; t/Ï ). (19.50)
In passing, this result explains why Ï is called &ldquo;relaxation time&rdquo;.
</p>
<p>19.4 Moments Expansion of the BTE
</p>
<p>The moments expansion of the BTE is a transformation method that has success-
fully been applied to the analysis of semiconductor devices. It reduces the original
equation to a set of partial-differential equations in the r, t space; the number of
such equations can be adapted to the type of information to be acquired about the
device under investigation. More specifically, applying the moments method to the
BTE and truncating the series of moments at a suitable order, one extracts from the
BTE a hierarchically-ordered set of models, ranging from the simplest to the more
complicate ones ([90&ndash;92], and references therein).
</p>
<p>The BTE is an equation in the r, k, t space. The basic idea of the moments method
is that, for the description of carrier-transport phenomena in semiconductor devices,
it is often sufficient to rely on equations defined over the r, t space alone; in fact, for
practical applications the information about the distribution of the crystal momentum
is less important. The equations in the r, t space are extracted from the BTE by
multiplying the latter by suitable functions Î±(k) and integrating the result over the
k space. The integration saturates the k coordinates and, as shown in Sect. C.6,
provides an equation in the r, t space.20 Remembering that the electron dynamics
</p>
<p>18 On the other hand, in a collisionless case it is S0 &rarr; 0 whence, from (19.43), it follows Ï &rarr; &infin;.
In this situation there is no limit to the departure of f from f eq.
19 Compare with the discussion carried out in Sect. 6.6.3.
20 As indicated in Sect. C.6, term &ldquo;moment&rdquo; is specifically used when Î± is a polynomial in k. As the
dependence of Î± on k is not specified yet, it is implied that the form of Î± is such that the integrals
in (19.51) converge.</p>
<p/>
</div>
<div class="page"><p/>
<p>420 19 Mathematical Model of Semiconductor Devices
</p>
<p>using the equivalent Hamiltonian operator is described by expanding the electron&rsquo;s
wave function in terms of the Bloch functions (Sect. 19.2.1), the integration over the
k space is in fact limited to the first Brillouin zone. On the other hand, the typical
behavior of the distribution function at the boundary Å´ of the first Brilluoin zone is
such that Î±(k) f (r, k, t) &rarr; 0 when k &rarr; kÅ´ . This amount to assuming that there
are no electrons at the boundary.21 From a practical standpoint, the hypothesis has
the same effect as that of replacing the first Brillouin zone with an infinite domain
and assuming that the distribution function in a non-equilibrium condition vanishes
at infinity in the same exponential-like fashion as it does at equilibrium, where it
becomes proportional to the Fermi&ndash;Dirac statistics [86, 89]. With these premises,
using the general form (19.33) of the equation, the moment of the BTE with respect
to Î± reads
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î±
</p>
<p>[
&part;f
</p>
<p>&part;t
+ u &middot; gradrf &minus;
</p>
<p>q
</p>
<p>hÌ
(E + u &and; B) &middot; gradkf
</p>
<p>]
</p>
<p>d3k =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î± C d3k.
</p>
<p>(19.51)
</p>
<p>As the BTE is a continuity equation of the distribution function in the phase space,
(19.51) is expected to be a continuity equation in the r space; in fact, as shown below,
it is the continuity equation of the product nÎ±, where n is the concentration of the
electrons in the conduction band, given by the first relation in (19.31), and
</p>
<p>Î±(r, t) = 1
n
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î±(k) f (r, k, t) d3k (19.52)
</p>
<p>is the average of Î± over the k space. The continuity equation is derived below by
working out separately the different terms appearing in (19.51).
</p>
<p>Time Derivative
</p>
<p>The derivation of this term is readily accomplished by observing that Î± &part;f/&part;t =
&part;(Î± f )/&part;t , whence
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î±
&part;f
</p>
<p>&part;t
d3k = &part;
</p>
<p>&part;t
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î± f d3k = &part;
</p>
<p>&part;t
(n Î±) . (19.53)
</p>
<p>This shows that (19.51) is the continuity equation of nÎ±, as anticipated.
</p>
<p>Diffusion Term
</p>
<p>To calculate this terms one starts with the relation Î± u &middot; gradrf = divr(Î± u f ), that
derives from the second identity in (A.16) and from the fact that Î± u does not depend
on r. Thus,
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î± u &middot; gradrf d3k = divr
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î± u f d3k = divr (n Î± u) . (19.54)
</p>
<p>21 In the case of the conduction band of germanium, the minima are at the boundary (Sect. 17.6.5),
which makes the hypothesis inconsistent as it stands; to perform the integration one must shift
the origin of the k space and exploit the periodicity of the band structure. The hypothesis that
the distribution function vanishes at the boundary of the first Brillouin zone is made also in the
application of the moments method to the holes of the valence band.</p>
<p/>
</div>
<div class="page"><p/>
<p>19.4 Moments Expansion of the BTE 421
</p>
<p>Drift Term
</p>
<p>The term containing the electric field is treated starting from the identity
</p>
<p>Î± E &middot; gradkf = E &middot; gradk(Î± f ) &minus; f E &middot; gradkÎ±. (19.55)
The integral of the first term at the right hand side of (19.55) vanishes due to identity
(A.26) and to the asymptotic behavior of f described earlier. As a consequence,
</p>
<p>&minus;
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î± E &middot; gradkf d3k = E &middot;
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
f gradkÎ± d
</p>
<p>3k = E &middot; n gradkÎ±. (19.56)
</p>
<p>The term containing the magnetic induction is treated more easily by rewriting
the mixed product as gradkf &middot; Î± u &and; B = gradkf &and; Î± u &middot; B (compare with (A.31))
and using the first identity in (A.35), to find
</p>
<p>gradkf &and; Î± u &middot; B = rotk(f Î± u) &middot; B &minus; f rotk(Î± u) &middot; B. (19.57)
The integral of rotk(f Î± u) &middot; B over k vanishes due to identity (A.38) and to the
asymptotic behavior of f ; this yields
</p>
<p>&minus;
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î± u &and; B &middot; gradkf d3k = B &middot;
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
f rotk(Î± u) d
</p>
<p>3k. (19.58)
</p>
<p>In turn, identity (A.35) transforms the integrand at the right hand side of (19.58) as
f rotk(Î± u) = f Î± rotku + f gradkÎ± &and; u where, thanks to the definition (17.52) of
the group velocity, it is rotku = (1/hÌ) rotkgradkH = 0. Thus, (19.58) becomes
</p>
<p>&minus;
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î± u &and; B &middot; gradkf d3k = B &middot;
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
f gradkÎ± &and; u d3k =
</p>
<p>=
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
f gradkÎ± &middot; u &and; B d3k = n gradkÎ± &middot; u &and; B. (19.59)
</p>
<p>In (19.59), the term containing the magnetic induction does not contribute to the
moment if Î± or f depends on k through energy alone, Î± = Î±(H ) or f = f (H ). In
fact, in the first case it is gradkÎ± = (dÎ±/dH ) gradkH , whence
</p>
<p>gradkÎ± &middot; u &and; B =
dÎ±
</p>
<p>dH
hÌ u &middot; u &and; B = 0. (19.60)
</p>
<p>The same calculation holds when f = f (H ), starting from the integrand at the
left hand side of (19.59).
</p>
<p>Collision Term
</p>
<p>Here it is convenient to distinguish between the inter-band and intra-band transitions,
introduced in Sects. 19.3, 19.3.2. Thus, the collision term is written C = Cb + Cv,
where as above suffix b (v) stands for &ldquo;inter-band&rdquo; (&ldquo;intra-band&rdquo;). This yields
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î± C d3k = Wb +Wv, Wb(v)[Î±] =
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î± Cb(v) d
</p>
<p>3k, (19.61)
</p>
<p>where the functional symbol reminds one that Wb(v) is determined by the form of Î±.</p>
<p/>
</div>
<div class="page"><p/>
<p>422 19 Mathematical Model of Semiconductor Devices
</p>
<p>19.4.1 Moment Equations
</p>
<p>Adding up (19.53), (19.54), (19.56), (19.59), and (19.61) after multiplying the drift
terms by q/hÌ provides the explicit form of (19.51), that reads
</p>
<p>&part;
</p>
<p>&part;t
(n Î±)+ divr (n Î± u)+
</p>
<p>q
</p>
<p>hÌ
n gradkÎ± &middot; (E + u &and; B) = Wb[Î±] +Wv[Î±]. (19.62)
</p>
<p>A simple reasoning shows that the equations of the form (19.62) that are obtained
from different choices of Î± are coupled with each other. To show this one takes for
simplicity the one-dimensional case and lets Î± = c km, with m a positive integer and
c a constant. Also, the parabolic-band approximation is assumed to hold, so that u
is a linear function of k. It follows that the time derivative in (19.62) contains the
moment of order m of f , while the diffusion term (due to the product Î± u) contains
the moment of order m+ 1; in turn, the summand proportional to E in the drift term
contains the moment of order m&minus; 1 due to the derivative of Î±, while the summand
proportional to B contains the moment of orderm. These considerations are sufficient
to show that the equation whose unknown is the moment of order m is coupled with
those whose unknowns are the moment of order m&minus; 1 and m+ 1.
</p>
<p>In the typical applications of the moments expansion a finite set of equations is
considered, starting from the lowest-order moment m = 0 up to some order m0.
The system of equations thus obtained is indeterminate because, due to the coupling
mentioned above, the number of equations is m0 whereas the number of unknown
moments appearing in them is m0 + 1. To make the system determinate it is then
necessary to add an extra condition, that is found by prescribing an approximate form
of the (m0 + 1)th moment.22 Such a prescription reduces the number of unknown
moments to m0 and makes the system of differential equations determinate; for this
reason it is called closure condition. The typical choice for the closure condition is
to approximate the (m0 + 1)th moment using the equilibrium distribution.
</p>
<p>19.4.1.1 Moment of Order Zero
</p>
<p>The moment of order zero is obtained by letting Î± = 1 in (19.62), whose left hand
side becomes &part;n/&part;t + divr (n u); the electron concentration n is the moment of
order zero and u = v is the average velocity, as defined in (19.31). If the zero-order
moment of the collision term does not introduce further unknowns, the equation&rsquo;s
unknowns are two: n and v. The form of the left hand side shows that integrating the
zero-order moment of the BTE over an arbitrary volume ï¿½ of the r space provides
the balance equation for the number of electrons of the conduction band (compare
</p>
<p>22 The choice of the highest-order moment as the function to be approximated is reasonable in view
of the analysis of the moments method carried out in Sect. C.6. In fact, as the moments are the
coefficients of a converging Taylor series, they become smaller and smaller as the order increases;
thus, the error due to approximating the highest-order coefficient is expected to be the smallest.</p>
<p/>
</div>
<div class="page"><p/>
<p>19.4 Moments Expansion of the BTE 423
</p>
<p>with Sect. 23.2):
</p>
<p>d
</p>
<p>dt
</p>
<p>&int;
</p>
<p>ï¿½
</p>
<p>n dï¿½+
&int;
</p>
<p>ï¿½
</p>
<p>n v &middot; s dï¿½ =
&int;
</p>
<p>ï¿½
</p>
<p>Wb[1] dï¿½+
&int;
</p>
<p>ï¿½
</p>
<p>Wv[1] dï¿½, (19.63)
</p>
<p>where ï¿½ is the boundary of ï¿½ and s the unit vector normal to ï¿½, oriented in the
outward direction. The second integral at the right hand side of (19.63) does not
contribute to the electrons&rsquo; balance; in fact, it describes transitions that do not in-
fluence the number of electrons of the band because both the initial and final state
belong to it. On the other hand, due to the arbitrariness of ï¿½, the integral vanishes
only if Wv[1] = 0. This result shows that the zero-order moment of the intra-band
transitions vanishes,23 so that the only transitions of importance for the zero-order
moment, despite being dominated by much larger relaxation times, are the inter-band
ones. This is the exception anticipated in Sect. 19.3.2. The zero-order moment for
the electrons of the conduction band then reads
</p>
<p>&part;n
</p>
<p>&part;t
+ divr (n v) = Wb[1]. (19.64)
</p>
<p>The form of the inter-band term Wb[1], which is not relevant for the analysis in hand,
is worked out in Chap. 20.
</p>
<p>19.4.1.2 General Form of the Higher-Order Moments
</p>
<p>As shown above, the contribution of the intra-band transitions vanishes for Î± = 1.
In contrast, it becomes dominant for other choices of Î±; in fact, in such cases the
intra-band transitions do not cancel out any more and their scattering rates turn out
to be much higher than those of the inter-band transitions. This allows one to adopt
an approximation for Wb[Î±], namely,
</p>
<p>Wb[Î±] =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î± Cb d
</p>
<p>3k â Î±
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Cb d
</p>
<p>3k. (19.65)
</p>
<p>In other terms it is assumed that, since the contribution of Wb[Î±] to the collision term
is small when Î± ï¿½= 1, the error introduced by (19.65) is negligible. Expanding the
time derivative in (19.62), and using (19.64), (19.65), yields
</p>
<p>n
&part;Î±
</p>
<p>&part;t
+ divr (n Î± u)&minus; Î± divr (n v)+
</p>
<p>q
</p>
<p>hÌ
n gradkÎ± &middot; (E + u &and; B) = Wv[Î±],
</p>
<p>(19.66)
</p>
<p>where only the intra-band transitions appear. Due to its simpler form, (19.66) will
be used in the following to derive the balance equations with Î± ï¿½= 1.
</p>
<p>23 A similar reasoning is used to explain (20.16).</p>
<p/>
</div>
<div class="page"><p/>
<p>424 19 Mathematical Model of Semiconductor Devices
</p>
<p>19.4.1.3 Moments of Order One, Two, and Three
</p>
<p>The moment of order one of the BTE is found by letting Î± = ui with i = 1, 2, 3
in (19.66); this yields the continuity equation for the ith component of the average
velocity of the electrons, ui = vi :
</p>
<p>n
&part;vi
</p>
<p>&part;t
+ divr (n ui u)&minus; vi divr (n v)+
</p>
<p>q
</p>
<p>hÌ
n gradkui &middot; (E + u &and; B) = Wv[ui].
</p>
<p>(19.67)
</p>
<p>To proceed it is necessary to introduce the definition of average kinetic energy and
average flux of the electrons&rsquo; kinetic energy,24
</p>
<p>w(r, t) = 1
n
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ee(k) f (r, k, t) d
</p>
<p>3k, (19.68)
</p>
<p>b(r, t) = 1
n
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ee(k) u(k) f (r, k, t) d
</p>
<p>3k, (19.69)
</p>
<p>with Ee = E(k) &minus; EC . Then, the moment of order two of the BTE is found by
letting Î± = Ee in (19.66); this yields the continuity equation for the average kinetic
energy of the electrons, (19.68). In the derivation, the term containing the magnetic
induction vanishes due to (19.60); using the definition (17.52) of the group velocity,
the equation reads
</p>
<p>n
&part;w
</p>
<p>&part;t
+ divr (n b)&minus; w divr (n v)+ q n v &middot; E = Wv[Ee]. (19.70)
</p>
<p>The moment of order three of the BTE is found by lettingÎ± = Ee ui with i = 1, 2, 3
in (19.66); this yields the continuity equation for the average flux of the electrons&rsquo;
kinetic energy, (19.69); the equation reads
</p>
<p>n
&part;bi
</p>
<p>&part;t
+ divr
</p>
<p>(
</p>
<p>nEe ui u
)
</p>
<p>&minus; bi divr (n v)+
q
</p>
<p>hÌ
n gradk(Ee ui) &middot; (E + u &and; B) =
</p>
<p>Wv[Ee ui]. (19.71)
</p>
<p>The choices Î± = 1, Î± = ui , Î± = Ee, and Î± = Ee ui are such that each moment
equation provides the balance relation of a dynamic quantity of interest: number
of electrons, average velocity, average kinetic energy, average flux of the kinetic
energy; the even-order moments yield a scalar equation, whereas the odd-order
moments yield a vector equation.
</p>
<p>24 In the equilibrium condition the product Ee f eq is even with respect to k. In turn, u =
(1/hÌ) gradkE is odd, so that b
</p>
<p>eq = 0. Compare with the similar comment made about the average
velocity in (19.31).</p>
<p/>
</div>
<div class="page"><p/>
<p>19.4 Moments Expansion of the BTE 425
</p>
<p>19.4.2 Hierarchical Models
</p>
<p>The order-one moment (19.67) contains the new unknown ui u besides n and v
already present in (19.64); the order-two moment (19.70) contains again n and v,
and the new unknowns w, b. The order-three moment contains n, v, b, and the
new unknown Ee ui u. The drift terms and the collision terms, depending on their
form, may, or may not introduce extra unknowns; even if they don&rsquo;t, the number
of unknowns listed above exceeds that of the equations. It is worth anticipating that
the finite set of balance equations indicated in Sect. 19.4.1 is obtained by taking the
equations in pairs: specifically, the first pair is made of the balance equations of order
zero and one, (19.64) and (19.66), that are collectively termed drift-diffusion model;
in this case, the three unknowns n, v, and ui u are reduced to two by the closure
condition (Sect. 19.4.1), that consists in replacing the highest-order moment ui u
with its equilibrium expression. A more elaborate model is obtained by taking the
first two pairs, namely, the balance equations of order zero through three, (19.64),
(19.66), (19.70), and (19.71), that are collectively termed hydrodynamic model; the
six unknowns n, v, and ui u, w, b, Ee ui u are reduced to five by prescribing the
closure condition, then to four by determining a relation between the second-order
moments ui u and w.
</p>
<p>By this procedure one constructs a set of hierarchically-ordered models of in-
creasing complexity. The type of model adopted in practical applications depends on
the trade-off between the information that one needs to acquire about the physical
behavior of the device under investigation and the computational cost of the system
of differential equations to be solved. To date, the moments method has been investi-
gated up to order 6 [45], and has been extended to order 21 using a scheme based on
Legendre polynomial expansion [59]; the standard implementations in the commer-
cial simulation programs used by semiconductor Companies adopt the hydrodynamic
model.25
</p>
<p>The balance equations derived so far are still rather cumbersome in view of the
application to the analysis of semiconductor devices. A number of simplifications are
illustrated below, which eventually lead to the standard form of the hydrodynamic
model [38, 40, 89, 93]. To begin, one considers the time derivatives at the left hand
side of the balance equations. Such derivatives differ from zero only if the distribution
function depends explicitly on time, which typically happens when time-dependent
boundary conditions are imposed to the device under investigation. In the practical
cases, the maximum frequency of the electric signals applied to a device or an
integrated circuit is lower by many orders of magnitude than the inverse relaxation
times associated to the intra-band transitions; this makes it possible to neglect the
time derivatives of vi , w, and bi . A quasi-static approximation26 is thus assumed
</p>
<p>25 Comprehensive reviews of the solution methods for the BTE are in [55, 56] as far as the Monte
Carlo method is concerned, and in [49] for deterministic methods.
26 A similar reasoning is used to treat the time derivative of the vector potential when the
semiconductor equations are coupled with the Maxwell equations (Sect. 19.5.4).</p>
<p/>
</div>
<div class="page"><p/>
<p>426 19 Mathematical Model of Semiconductor Devices
</p>
<p>in the continuity Eqs. (19.67), (19.70), and (19.71). The argument leading to this
approximation does not apply to the case of (19.64) because only the inter-band
transitions take place there, whose relaxation times are much longer than those of the
intra-band transitions and, in many cases, also than the inverse maximum frequency
of the external signal. As a consequence, the term &part;n/&part;t in (19.64) must be retained
when the boundary conditions depend on time.
</p>
<p>As a second approximation, one adopts the parabolic-band approximation; this
implies that in a non-equilibrium condition the electrons of the conduction band still
occupy energy states in the vicinity of the absolute minima. Such a condition is in
general fulfilled as shown below.27 Letting a indicate one of the absolute minima of
the conduction band, and using (19.24) after dropping suffix &ldquo;0&rdquo;, yields
</p>
<p>ui =
hÌ (ki &minus; kia)
</p>
<p>mia
, gradkui =
</p>
<p>hÌ
</p>
<p>mia
ii , gradk(Ee ui) = hÌ
</p>
<p>(
Ee
</p>
<p>mia
ii + ui u
</p>
<p>)
</p>
<p>,
</p>
<p>(19.72)
</p>
<p>with ii the unit vector of the ith axis. From now on, the equations derived from
the parabolic-band approximation refer to the ath valley. In principle, the electron
concentration, average velocity, and the other averages should be indicated with na ,
va , and so on; this is not done here to avoid complicacies in the notation. The suffix
will be introduced in Sect. 19.5.2, where the contributions of the valleys are added
up. This comment does not apply to the moment of order zero, (19.64), because its
derivation does not entail any simplifying hypothesis.
</p>
<p>With these premises, one manipulates the terms ui u, Ee ui u by introducing the
auxiliary quantity c = u &minus; v, called random velocity. Clearly it is ci = ui &minus; vi = 0,
so that ui u = vi v + ui u; it follows
</p>
<p>divr(n ui u) = divr(n ci c) + vi divr(n v) + n v &middot; gradrvi . (19.73)
The last term at the right hand side of (19.73) is called convective term. In the typical
operating conditions of the semiconductor devices this term can be neglected (refer
to [86] and the comments below). Replacing into (19.67) the simplified form of
(19.73) along with the second relation of (19.72) yields
</p>
<p>divr (nmia ci c)+ q n (E + v &and; B)i = mia Wv[ui]. (19.74)
The latter equation contains the unknowns n and v already present in (19.64), and the
new unknown ci c. The drift term does not introduce extra unknowns. Note that ci c is
actually made of three vectors, so that it may be thought of as a symmetric 3&times;3 tensor
with components ci cj , i, j = 1, 2, 3. To give it a more compact form, after observing
that mia ci c has the units of an energy, one defines the electron-temperature tensor
of components Tij such that
</p>
<p>kB Tij = mia ci cj , n kB Tij =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
mia ci cj f d
</p>
<p>3k, (19.75)
</p>
<p>27 The adoption of the parabolic-band approximation may be avoided at the cost of redefining the
carrier temperature and introducing more relaxation times [108].</p>
<p/>
</div>
<div class="page"><p/>
<p>19.4 Moments Expansion of the BTE 427
</p>
<p>with kB the Boltzmann constant. Letting Ti be the vector of entries Ti1, Ti2, Ti3, so
that kB Ti = mia ci c, one finds for the ith component of the moment of order one
</p>
<p>divr (n kB Ti)+ q n (E + v &and; B)i = mia Wv[ui]. (19.76)
In the equilibrium condition the electron-temperature tensor reduces to the product
of a scalar coefficient times the identity tensor; in the limit of the Boltzmann dis-
tribution, the scalar coefficient identifies with the lattice temperature (Sect. 19.6.4),
this providing an estimate of the modulus |c| of the random velocity. The modulus
|v| of the average velocity in a non-equilibrium condition can be estimated as well,
basing upon the current density and carrier concentration of the devices&rsquo; operating
conditions. It is found that in typical situations it is |v| âª |c|, so that the average
motion of the carriers in a non-equilibrium condition can be thought of as that of a
slowly-drifting fluid. This justifies the neglect of the convective term in (19.73), and
also allows one to neglect vi v with respect to ci c when these terms appear in the
same expression.
</p>
<p>The simplifications used in (19.67) apply in the same manner to the moment of
order three, (19.71); in fact it is Ee ui u = Ee ui c + Ee ui v, whence
</p>
<p>divr(nEe ui u) = divr(nEe ui c) + bi divr(n v) + n v &middot; gradrbi . (19.77)
Using the third relation of (19.72) in the drift term of (19.71) transforms the latter
into (q/mia) n [(w ii +mia vi v+mia ci c) &middot;E+b&and;B &middot; ii +mia ui u &middot; u &and; B], where
the mixed product vanishes due to the repeated factor, and mia vi v is negligible as
shown above. Replacing (19.77) into (19.71) after neglecting the time derivative and
the convective term, yields
</p>
<p>divr
(
</p>
<p>nmia Ee ui c
)
</p>
<p>+ q n [(w ii + kB Ti) &middot; E + b &and; B &middot; ii] = mia Wv[Ee ui].
(19.78)
</p>
<p>The relation between the second-order moments necessary to reduce the number of
unknowns is now determined starting from the expression ofEe in the parabolic-band
approximation. Using the first relation in (19.72) yields Ee = (1/2)
</p>
<p>&sum;3
i=1 mia u
</p>
<p>2
i
</p>
<p>whence, from (19.68),
</p>
<p>w = 1
2
</p>
<p>3
&sum;
</p>
<p>i=1
mia v
</p>
<p>2
i +
</p>
<p>3
</p>
<p>2
kB Te, Te =
</p>
<p>T11 + T22 + T33
3
</p>
<p>, (19.79)
</p>
<p>with Te the electron temperature. The two summands of w in (19.79) are also called
convective part and thermal part of the average kinetic energy, respectively. The
same reasoning that has led to the neglect of mia vi v with respect to mia ci c also
shows that the thermal part is dominant with respect to the convective part, so that
w â (3/2) kB Te. Moreover, it can be assumed that the electron-temperature tensor
retains the same structure of the equilibrium case, so that
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>T11 T12 T13
</p>
<p>T21 T22 T23
</p>
<p>T31 T32 T33
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>â
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>T11 0 0
</p>
<p>0 T22 0
</p>
<p>0 0 T33
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>â Te(r, t) I, (19.80)</p>
<p/>
</div>
<div class="page"><p/>
<p>428 19 Mathematical Model of Semiconductor Devices
</p>
<p>with I the identity tensor. As a consequence, (w ii + kB Ti)&middot;E = (5/2) kB Te ii &middot;E and
divr(n kB Ti) = &part;(n kB Te)/&part;xi . The latter is the ith component of gradr (n kB Te).
In summary, the balance equations for the moments of order one, two, and three read
</p>
<p>&part; (n kB Te)
</p>
<p>&part;xi
+ q n (E + v &and; B)i = mia Wv[ui], (19.81)
</p>
<p>divr (n b)&minus; (3/2) kB Te divr (n v)+ q n v &middot; E = Wv[Ee], (19.82)
divr
</p>
<p>(
</p>
<p>nmia Ee ui c
)
</p>
<p>+ q n [(5/2) kB Te E + b &and; B]i = mia Wv[Ee ui]. (19.83)
</p>
<p>19.4.2.1 Macroscopic Relaxation Times of the Higher-Order Moments
</p>
<p>As remarked in Sect. (19.4.1), the collision terms of the moments of order higher
than zero account for the intra-band transitions only. These terms are worked out
here using the perturbative form of the BTE (Sect. 19.3.3); this approach is coherent
with the other approximations from which the balance Eqs. (19.81&ndash;19.83) derive.
The collision term of (19.82) then becomes
</p>
<p>Wv[Ee] = &minus;
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ee
</p>
<p>f &minus; f eq
Ï
</p>
<p>d3k, (19.84)
</p>
<p>with Ï â Ïv (Sect. 19.3.2). The equilibrium part is worked out by defining the
energy-relaxation time Ïw such that
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ee
</p>
<p>f eq
</p>
<p>Ïv
d3k = 1
</p>
<p>Ïw
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ee f
</p>
<p>eq d3k = n
eq weq
</p>
<p>Ïw
â 3
</p>
<p>2
</p>
<p>neq kBT
eq
e
</p>
<p>Ïw
, (19.85)
</p>
<p>where the definitions (19.68, 19.79) of the electrons&rsquo; average kinetic energy and
temperature are used. The left hand side of (19.85) does not vanish because the
integrand is positive definite. The non-equilibrium part of Wv[Ee] is approximated
as
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ee
</p>
<p>f
</p>
<p>Ïv
d3k â 1
</p>
<p>Ïw
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ee f d
</p>
<p>3k = nw
Ïw
</p>
<p>â 3
2
</p>
<p>n kBTe
</p>
<p>Ïw
, (19.86)
</p>
<p>based on the observation that, due to the smallness of the intra-band relaxation time
Ïv, the distribution function departs little from the equilibrium one (Sect. 19.3.3).
</p>
<p>The derivation of the analogues of Ïw for the collision terms of (19.81) and (19.83)
is somewhat more complicate. In fact, in most semiconductors, among which Si, Ge,
and GaAs, the relaxation time Ïv is even with respect to k [57], which makes the
integrals of ui f eq/Ïv and Ee ui f eq/Ïv to vanish because the integrand is odd. To
overcome the difficulty one expands f &minus; f eq into a Taylor series with respect to a
parameter and truncates the series in such a way as to retain the first summand which</p>
<p/>
</div>
<div class="page"><p/>
<p>19.5 Hydrodynamic and Drift-Diffusion Models 429
</p>
<p>is odd with respect to k. For instance, letting Î» be the parameter28 and assuming that
the first-order term of the expansion is odd, one lets f &minus; f eq â (df/dÎ»)eq Î» whence
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
ui
</p>
<p>(df/dÎ»)eq
</p>
<p>Ïv
d3k = 1
</p>
<p>Ïpi
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
ui (df/dÎ»)
</p>
<p>eq d3k, (19.87)
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ee ui
</p>
<p>(df/dÎ»)eq
</p>
<p>Ïv
d3k = 1
</p>
<p>Ïbi
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ee ui (df/dÎ»)
</p>
<p>eq d3k, (19.88)
</p>
<p>with Ïpi and Ïbi the momentum-relaxation time and relaxation time of the energy flux,
respectively.29 Due to their definitions, Ïpi and Ïbi are diagonal tensors. However,
as their degree of anisotropy is small, they are approximated by scalar quantities,
Ïpi â Ïp and Ïbi â Ïb. Investigations about the relaxation times have been carried
out by different techniques, specifically, the spherical-harmonics expansion method
to determine the dependence on the average energy [90, 93], and the Monte Carlo
method to study the anisotropy properties [11, 12, 43].
</p>
<p>Using (19.87, 19.88) along with the definitions (19.31, 19.69) of the average
velocity and average flux of kinetic energy finally yields
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>ui
</p>
<p>Ïv
</p>
<p>(
df
</p>
<p>dÎ»
Î»
</p>
<p>)eq
</p>
<p>d3k = n vi
Ïp
</p>
<p>,
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>Ee ui
</p>
<p>Ïv
</p>
<p>(
df
</p>
<p>dÎ»
Î»
</p>
<p>)eq
</p>
<p>d3k = n bi
Ïb
</p>
<p>.
</p>
<p>(19.89)
</p>
<p>19.5 Hydrodynamic and Drift-Diffusion Models
</p>
<p>In Sect. 19.4 the moments method has been applied to derive a set of balance equa-
tions; the general form of the latter has successively been modified by introducing a
number of simplifications: among them is the parabolic-band approximation, due to
which, as indicated in Sect. 19.4.2, a set of equations restricted to the ath valley of the
conduction band is obtained. In order to recover the equations for the whole band, it
is necessary to add up the single-valley contributions. The procedure is the same for
the hydrodynamic and drift-diffusion models; it will be worked out explicitly only
for the simpler case of the drift-diffusion model.
</p>
<p>28 Typically the parameter used in this procedure is the electric field [57]. An expansion truncated
to the first order is coherent with the first-order perturbation approach.
29 The term &ldquo;momentum&rdquo; for Ïpi derives from the observation that the continuity equation for the
ith component of the average velocity vi of the electrons, (19.67), may also be thought of as the
continuity equation for the ith component of the average momentum, mia vi . In turn, Ïbi is also
called heat-relaxation time.</p>
<p/>
</div>
<div class="page"><p/>
<p>430 19 Mathematical Model of Semiconductor Devices
</p>
<p>19.5.1 HD Model
</p>
<p>As anticipated in Sect. 19.4.2, the hydrodynamic (HD) model is obtained by taking the
balance equations of order zero through three, (19.64), (19.81), (19.82), and (19.83),
and imposing the closure condition onto the fourth-order moment. For simplicity,
the latter is considered in the non-degenerate case whence, from (19.159), it is
mia
</p>
<p>(
</p>
<p>Ee ui c
)eq â ii (5/2) (kB T )2. Letting W = Wb[1] and using (19.85), (19.86),
</p>
<p>(19.89) yields
</p>
<p>&part;n
</p>
<p>&part;t
+ divr (n v) = W ,
</p>
<p>&part; (n kB Te)
</p>
<p>&part;xi
+ q n (E + v &and; B)i = &minus;
</p>
<p>mia
</p>
<p>Ïp
n vi ,
</p>
<p>(19.90)
</p>
<p>divr (n b)&minus;
3
</p>
<p>2
kB Te divr (n v)+ q n v &middot; E = &minus;
</p>
<p>3
</p>
<p>2
</p>
<p>kB
</p>
<p>Ïw
</p>
<p>[
</p>
<p>n Te &minus; (n Te)eq
]
</p>
<p>, (19.91)
</p>
<p>5
</p>
<p>2
(kB T )
</p>
<p>2 &part;n
</p>
<p>&part;xi
+ q n
</p>
<p>(
5
</p>
<p>2
kB Te E + b &and; B
</p>
<p>)
</p>
<p>i
</p>
<p>= &minus;mia
Ïb
</p>
<p>n bi . (19.92)
</p>
<p>which constitute a system of first-order, partial-differential equations in the unknowns
n, v, Te, and b. In general, the model&rsquo;s equations are to be solved over a volume that
encloses the device under investigation; the boundary conditions that typically apply
are discussed in Sect. 19.5.6. Two of the equations are scalar (namely, (19.91) and
the first one in (19.90)), while the other two are vector equations. The system is non
linear because the unknowns are multiplied by each other.30 Note, however, that the
second equation in (19.90) is linear with respect to the components of v; the latter
can be extracted and replaced into the two scalar equations. The same procedure
is applicable to (19.92), which is linear with respect to the components of b. After
the replacements are completed, the system reduces to two scalar equations of the
second order. An example is given in Sect. 19.5.5, with reference to the simpler case
of the drift-diffusion model. Due to the components mia of the effective-mass tensor,
the vector equations are anisotropic; however, when the contributions of the different
valleys are combined together, the anisotropy cancels out (the explicit calculation is
provided for the drift-diffusion model below).
</p>
<p>The qualitative analysis of the model carried out above implies that the electric
field and magnetic induction are known, so that they are embedded in the model&rsquo;s
coefficients. In fact, this is not true, because the fields are influenced by the distribu-
tion of electric charge and current density that are some of the model&rsquo;s unknowns.
For this reason, as shown below, the hydrodynamic equations, and the drift-diffusion
ones as well, must be coupled with the Maxwell equations.
</p>
<p>30 Also, the generation-recombination term W embeds non-linear dependencies on some of the
unknowns, Chap. 20.</p>
<p/>
</div>
<div class="page"><p/>
<p>19.5 Hydrodynamic and Drift-Diffusion Models 431
</p>
<p>19.5.2 DD Model
</p>
<p>The drift-diffusion (DD) model is obtained by taking the balance equations of order
zero and one, (19.90), and imposing the closure condition onto the second-order
moment. For simplicity, the latter is considered in the non-degenerate case, whence
T
</p>
<p>eq
e = T (Sect. 19.6.4); the model thus reads
&part;n
</p>
<p>&part;t
+ divr (n v) = W , kB T
</p>
<p>&part;na
</p>
<p>&part;xi
+ q na (E + va &and; B)i = &minus;
</p>
<p>mia
</p>
<p>Ïp
na via.
</p>
<p>(19.93)
</p>
<p>As indicated in Sect. 19.4.2, the first equation in (19.93) refers to the whole conduc-
tion band because its derivation did not entail any simplifying hypothesis; in contrast,
the second equation refers to the ath minimum of the band due to the parabolic-band
approximation. This explains the index attached to n and to the average velocity; the
momentum-relaxation time, instead, does not depend on the valley [90]. As noted
above, the dependence on the components via is linear, which makes it possible to
express them in terms of the other functions. In fact, it is more convenient to extract,
instead of va , the electron-current density of the ath minimum; remembering (4.21)
and (4.22), the latter is given by Ja = &minus;q na va . Then, the second equation in (19.93)
is recast as
</p>
<p>Jia = J &prime;ia &minus;
q Ïp
</p>
<p>mia
(Ja &and; B)i , J &prime;ia = kB T
</p>
<p>q Ïp
</p>
<p>mia
</p>
<p>&part;na
</p>
<p>&part;xi
+ q Ïp
</p>
<p>mia
q na (E)i , (19.94)
</p>
<p>with J &prime;ia = Jia(B = 0). Letting Î¼ia = q Ïp/mia , the matrix form of (19.94) reads
â¡
</p>
<p>â¢
â¢
â£
</p>
<p>Ja1
</p>
<p>Ja2
</p>
<p>Ja3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>=
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>J &prime;a1
</p>
<p>J &prime;a2
</p>
<p>J &prime;a3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
&minus;
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>Î¼a1 0 0
</p>
<p>0 Î¼a2 0
</p>
<p>0 0 Î¼a3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>Ja2 B3 &minus; Ja3 B2
Ja3 B1 &minus; Ja1 B3
Ja1 B2 &minus; Ja2 B1
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>, (19.95)
</p>
<p>equivalent to
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>1 Î¼a1 B3 &minus;Î¼a1 B2
&minus;Î¼a2 B3 1 Î¼a2 B1
Î¼a3 B2 &minus;Î¼a3 B1 1
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>Ja1
</p>
<p>Ja2
</p>
<p>Ja3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>=
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>J &prime;a1
</p>
<p>J &prime;a2
</p>
<p>J &prime;a3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
. (19.96)
</p>
<p>The diagonal tensor Î¼Ìa of entries Î¼ia is called mobility tensor of the ath valley. Note
that the product of a mobility by a magnetic induction is dimensionless. Letting
Ma = Î¼a1 Î¼a2 Î¼a3 (Î¼Ìa)&minus;1 B, the components of the current density are found by
solving the algebraic system (19.96), where the determinant of the matrix is
</p>
<p>DM = 1 + Î¼a1 Î¼a2 Î¼a3
(
B21
</p>
<p>Î¼1a
+ B
</p>
<p>2
2
</p>
<p>Î¼2a
+ B
</p>
<p>2
3
</p>
<p>Î¼3a
</p>
<p>)
</p>
<p>= 1 + B &middot; Ma. (19.97)</p>
<p/>
</div>
<div class="page"><p/>
<p>432 19 Mathematical Model of Semiconductor Devices
</p>
<p>The components of Ja are finally found to be
</p>
<p>DM Jai = J &prime;ai + Î¼ai
(
</p>
<p>B &and; J&prime;a
)
</p>
<p>i
+
</p>
<p>(
</p>
<p>Ma &middot; J&prime;a
)
</p>
<p>Bi . (19.98)
</p>
<p>In typical situations the modulus of the magnetic induction is small; hence terms that
are quadratic in the components of B may be neglected. This yields the approximate
form
</p>
<p>Jai â J &prime;ai + Î¼ai
(
</p>
<p>B &and; J&prime;a
)
</p>
<p>i
. (19.99)
</p>
<p>The electron current density of the whole conduction band is thus found as
</p>
<p>J =
MC&sum;
</p>
<p>a=1
Ja =
</p>
<p>MC&sum;
</p>
<p>a=1
</p>
<p>[
</p>
<p>kB T Î¼Ìa gradna + Î¼Ìa q na E + Î¼Ìa
(
</p>
<p>B &and; J&prime;a
)]
</p>
<p>. (19.100)
</p>
<p>In the perturbative approach followed here, it can be assumed that the total electron
concentration n equally distributes31 over the valleys, na = n/MC . The first two
summands at the right hand side of (19.100) then yield
</p>
<p>J&prime; =
MC&sum;
</p>
<p>a=1
J&prime;a = q Î¼Ìn nE + q DÌn gradn, (19.101)
</p>
<p>where the diagonal tensors Î¼Ìn, DÌn are defined as
</p>
<p>Î¼Ìn =
1
</p>
<p>MC
</p>
<p>MC&sum;
</p>
<p>a=1
Î¼Ìa , DÌn =
</p>
<p>kB T
</p>
<p>q
Î¼Ìn. (19.102)
</p>
<p>They are called electron-mobility tensor and electron-diffusivity tensor, respectively.
The second relation in (19.102), that states that diffusivity and mobility are propor-
tional through kB T/q, is called Einstein relation.32 The form of Î¼Ìn is specified on a
case-by-case basis, depending on the semiconductor under consideration. Taking sil-
icon by way of example (MC = 6), the mass tensor is obtained from (17.82&ndash;17.84);
thus, the mobility tensor Î¼Ìa has one of the following forms:
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>Î¼l 0 0
</p>
<p>0 Î¼t 0
</p>
<p>0 0 Î¼t
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>,
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>Î¼t 0 0
</p>
<p>0 Î¼l 0
</p>
<p>0 0 Î¼t
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>,
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>Î¼t 0 0
</p>
<p>0 Î¼t 0
</p>
<p>0 0 Î¼l
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>, (19.103)
</p>
<p>31 From this assumption and from (19.100) it also follows J = &minus;q &sum;MCa=1 na va =
&minus;q (n/6) &sum;MCa=1 va , whence J = &minus;q n v with v = (1/6)
</p>
<p>&sum;MC
a=1 va .
</p>
<p>32 The relation derives from Einstein&rsquo;s investigation on the Brownian motion [35] and has therefore
a broader application. In a semiconductor it holds within the approximations of parabolic bands
and non-degenerate conditions.</p>
<p/>
</div>
<div class="page"><p/>
<p>19.5 Hydrodynamic and Drift-Diffusion Models 433
</p>
<p>with Î¼l = q Ïp/ml , Î¼t = q Ïp/mt . The first form in (19.103) applies to the two
minima belonging to axis k1, and so on; thus, the electron-mobility tensor (19.102)
is found to be
</p>
<p>Î¼Ìn =
1
</p>
<p>6
</p>
<p>â
</p>
<p>â
â
â
</p>
<p>2
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>Î¼l 0 0
</p>
<p>0 Î¼t 0
</p>
<p>0 0 Î¼t
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
+ 2
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>Î¼t 0 0
</p>
<p>0 Î¼l 0
</p>
<p>0 0 Î¼t
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
+ 2
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>Î¼t 0 0
</p>
<p>0 Î¼t 0
</p>
<p>0 0 Î¼l
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>â
</p>
<p>â
â
â 
</p>
<p>= Î¼n I,
</p>
<p>(19.104)
</p>
<p>with I the identity tensor and Î¼n = (Î¼l + 2Î¼t )/3 the electron mobility. The second
definition in (19.102) then yields DÌn = Dn I, with Dn = (kB T/q)Î¼n the elec-
tron diffusivity or electron-diffusion coefficient. From these results and (19.101) one
derives
</p>
<p>J&prime; = q Î¼n nE + q Dn gradn, J&prime;a =
1
</p>
<p>Î¼n MC
Î¼Ìa J
</p>
<p>&prime;. (19.105)
</p>
<p>From this, after a somewhat lengthy calculation, the last term at the right hand side
of (19.100) is found to be
</p>
<p>MC&sum;
</p>
<p>a=1
Î¼Ìa
</p>
<p>(
</p>
<p>B &and; J&prime;a
)
</p>
<p>= an Î¼n B &and; J&prime;, an =
Î¼t (Î¼t + 2Î¼l)
</p>
<p>3Î¼2n
. (19.106)
</p>
<p>As anticipated in the qualitative discussion about the HD model, despite the fact
that each vector equation is anisotropic, when the contributions of the different
valleys are combined together the anisotropy cancels out. From the definition of the
electron mobility Î¼n = (Î¼l + 2Î¼t )/3 one may also extract a scalar effective mass
mn = q Ïp/Î¼n, that fulfills 1/mn = (2/mt + 1/ml)/3. Using the room-temperature
values taken from Table 17.4 yields, for silicon, mn/m0 â 0.26. By the same token
one finds an â 2.61.
</p>
<p>In the next sections, the current density of the electrons in the conduction band
will be used in equations involving also the current density of the holes in the valence
band; for this reason it is necessary to use different symbols. Specifically, Jn for the
former and Jp for the latter; with this provision, the above calculation yields
</p>
<p>Jn = q Î¼n nE + q Dn gradn+ q an Î¼n B &and; (Î¼n nE +Dn gradn) , (19.107)
</p>
<p>which is called drift-diffusion transport equation. Thus the DD model for the elec-
trons of the conduction band is given by (19.107) along with the first equation in
(19.93); the latter is rewritten here as
</p>
<p>&part;n
</p>
<p>&part;t
&minus; 1
</p>
<p>q
div(Jn) = Wn, (19.108)
</p>
<p>where a specific symbol for the generation-recombination term has been introduced
as well.</p>
<p/>
</div>
<div class="page"><p/>
<p>434 19 Mathematical Model of Semiconductor Devices
</p>
<p>19.5.3 DD Model for the Valence Band
</p>
<p>The transport models illustrated so far are applicable to the valence band as well;
here, the DD model will be worked out. Remembering the discussion of Sect. 19.2.3
about the dynamics in the parabolic-band approximation, the model is described
in terms of the concentration and current density of holes. The two quantities are
defined by adapting the corresponding expression for electrons, (19.31), as shown
below. Letting f = QÎ¦, with Q = 1/(4Ï3) the density of states in the phase space
and Î¦ the occupation probability, the hole concentration is
</p>
<p>p(r, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Q (1 &minus;Î¦) d3k. (19.109)
</p>
<p>In turn, the hole current density is defined starting from the definition of the
electron current density of the valence band. The latter is similar to (19.31), the
difference being that the integration in (19.31) is restricted to the branch of E(k)
belonging to the conduction band, whereas the integration in (19.110) below is
restricted to one of the two branches of the valence band:
</p>
<p>Ja = &minus;q
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u(k)QÎ¦(r, k, t) d3k. (19.110)
</p>
<p>Letting Î¦ = 1 &minus; (1 &minus;Î¦) transforms (19.110) into
</p>
<p>Ja = q
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
uQ(1 &minus;Î¦) d3k &minus; q
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
uQ d3k, (19.111)
</p>
<p>where the second integral vanishes because u is odd with respect to k. As a conse-
quence, the current density of the branch under consideration may also be thought
of as given by the motion of the empty states (holes), having the group velocity u(k)
and the positive charge q. Moreover, one defines the average velocity of holes using
Q (1 &minus;Î¦) as weighing function, to find
</p>
<p>Ja = q pa
&int;
</p>
<p>k
uQ (1 &minus;Î¦) d3k
</p>
<p>&int;
</p>
<p>k
Q (1 &minus;Î¦) d3k = q pa va (19.112)
</p>
<p>where the definition (19.109) of the hole concentration has been specified for the
branch under consideration, and the short-hand notation
</p>
<p>&int;
</p>
<p>k
has been used.
</p>
<p>Given the above definitions, the derivation of the drift-diffusion model for holes
follows the same pattern as for the electrons. Remembering the description of the
band structure given in Sect. 17.6.5, for the valence band index a ranges over h
and l; moreover, due to the isotropy of each branch deriving from the parabolic-
band approximation (compare with 17.78), the effective mass is scalar. Then, the
equivalent of (19.94) read, in vector form,
</p>
<p>Ja = J&prime;a +
q Ïpa
</p>
<p>ma
Ja &and; B , J&prime;a = &minus;kB T
</p>
<p>q Ïpa
</p>
<p>ma
gradpa +
</p>
<p>q Ïpa
</p>
<p>ma
q pa E ,
</p>
<p>(19.113)</p>
<p/>
</div>
<div class="page"><p/>
<p>19.5 Hydrodynamic and Drift-Diffusion Models 435
</p>
<p>where index a is attached also to the momentum-relaxation time because the two
branches are different. Still due to such a difference, the holes do not distribute
equally over the branches; the contribution of the drift and diffusion components
then read, respectively,
</p>
<p>q Ïph
</p>
<p>mhh
q ph E +
</p>
<p>q Ïpl
</p>
<p>mhl
q pl E = q (Î¼ph + Î¼pl)p E, (19.114)
</p>
<p>&minus;kB T
q Ïph
</p>
<p>mhh
gradph &minus; kB T
</p>
<p>q Ïpl
</p>
<p>mhl
gradpl = &minus;kB T (Î¼ph + Î¼pl) gradp, (19.115)
</p>
<p>where
</p>
<p>Î¼ph =
q Ïph
</p>
<p>mhh
</p>
<p>ph
</p>
<p>p
, Î¼pl =
</p>
<p>q Ïpl
</p>
<p>mhl
</p>
<p>pl
</p>
<p>p
. (19.116)
</p>
<p>An approximate expression of Î¼ph, Î¼ph is obtained by replacing the concen-
trations with the corresponding equilibrium values ph = NV h Î¦1/2(Î¾h), pl =
NV l Î¦1/2(Î¾h), with
</p>
<p>NV h = 2MV
(
</p>
<p>mhh
</p>
<p>2Ï hÌ2
kB T
</p>
<p>)3/2
</p>
<p>, NV l = 2MV
(
</p>
<p>mhl
</p>
<p>2Ï hÌ2
kB T
</p>
<p>)3/2
</p>
<p>(19.117)
</p>
<p>(compare with (18.8)), whence, using p = ph + pl ,
</p>
<p>Î¼ph â
q Ïph m
</p>
<p>1/2
hh
</p>
<p>m
3/2
hh +m
</p>
<p>3/2
hl
</p>
<p>, Î¼pl â
q Ïpl m
</p>
<p>1/2
hl
</p>
<p>m
3/2
hh +m
</p>
<p>3/2
hl
</p>
<p>. (19.118)
</p>
<p>Then, Ja is extracted from the first relation in (19.113), whose matrix form is
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>1 Î¼a B3 &minus;Î¼a B2
&minus;Î¼a B3 1 Î¼a B1
Î¼a B2 &minus;Î¼a B1 1
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>Ja1
</p>
<p>Ja2
</p>
<p>Ja3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>=
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>J &prime;a1
</p>
<p>J &prime;a2
</p>
<p>J &prime;a3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>, (19.119)
</p>
<p>Î¼a = q Ïpa/ma . The determinant of the matrix in (19.119) is DM = 1+Î¼2a B2. Still
considering the case where B is weak, one finds
</p>
<p>Ja â J&prime;a &minus; Î¼a B &and; J&prime;a. (19.120)
</p>
<p>In turn, the contribution of the last term at the right hand side of the above yields
</p>
<p>&minus;ap B &and;
(
</p>
<p>q Î¼p p E &minus; q Dp gradp
)
</p>
<p>, Î¼p = Î¼ph + Î¼pl , (19.121)
</p>
<p>with Î¼p the hole mobility. In turn, the hole diffusivity (or hole-diffusion coefficient)
and the dimensionless parameter ap are given by
</p>
<p>Dp =
kB T
</p>
<p>q
Î¼p, ap =
</p>
<p>1
</p>
<p>Î¼2p
</p>
<p>(
q Ïph
</p>
<p>mhh
Î¼ph +
</p>
<p>q Ïpl
</p>
<p>mhl
Î¼pl
</p>
<p>)
</p>
<p>. (19.122)</p>
<p/>
</div>
<div class="page"><p/>
<p>436 19 Mathematical Model of Semiconductor Devices
</p>
<p>Putting (19.114), (19.115), and (19.121) together finally provides the drift-diffusion
transport equation for the holes,
</p>
<p>Jp = q Î¼p p E &minus; q Dp gradp &minus; q ap Î¼p B &and;
(
</p>
<p>Î¼p p E &minus;Dp gradp
)
</p>
<p>. (19.123)
</p>
<p>Thus, the DD model for the holes of the valence band is given by (19.123) along
with the balance equation for the holes&rsquo; number, that reads
</p>
<p>&part;p
</p>
<p>&part;t
+ 1
</p>
<p>q
div(Jp) = Wp. (19.124)
</p>
<p>19.5.4 Coupling with Maxwell&rsquo;s Equations
</p>
<p>As anticipated in Sect. 19.5.1, as the electromagnetic field is influenced by the distri-
bution of charge and current density, it is necessary to couple the equations describing
the charge transport (in the form, e.g., of the hydrodynamic or drift-diffusion model)
with the Maxwell equations. For this, one inserts the total charge density Ï and cur-
rent density J into the right hand sides of (4.19); considering that there are different
groups of charges and currents, one uses (4.22), where the charge density is given
by (18.53), namely,33
</p>
<p>Ï = q (p &minus; n+N ), N = N+D &minus;N&minus;A . (19.125)
</p>
<p>In turn, the current density reads
</p>
<p>J = Jp + Jn = Ïp vp + Ïn vn = q p vp &minus; q n vn, (19.126)
</p>
<p>with Jn and Jp given by (19.107) and (19.123), respectively. As noted in Sect. 18.5,
the material&rsquo;s permittivity must be used here instead of vacuum&rsquo;s; as a consequence,
the relation between electric displacement and field reads D = Îµsc E.
</p>
<p>One notes that the E and B fields are the sum of two contributions: the first one
derives from the internal charge and current-density distribution as mentioned above,
while the second one derives from external sources, e.g., voltage or current generators
connected to the device or integrated circuits, or electric and magnetic fields present
in the environment. In general, the internal contribution to B is negligible and is
not considered in semiconductor devices or integrated circuit; it follows that B is
to be accounted for in (19.107) and (19.123) only when it derives from external
sources34 and, due to this, it must be thought of as a prescribed function of r and t .
</p>
<p>33 Equation (18.53) is the definition of charge density in a semiconductor; as a consequence it holds
in general, not only in the equilibrium condition considered in Sect. 18.5. In fact, it can readily
be extended to account for charges trapped in energy states different from those of the dopants
(Sect. 20.2.2).
34 A typical example is found when a semiconductor device or circuit is used as a magnetic-field
sensor or in specific measurement setups, like in the Hall-voltage measurement (Sect. 25.4).</p>
<p/>
</div>
<div class="page"><p/>
<p>19.5 Hydrodynamic and Drift-Diffusion Models 437
</p>
<p>With these premises, the analysis will continue here after letting B = 0. Despite this
simplification, the continuity and transport Eqs. (19.108), (19.107) and (19.123),
(19.124) must be coupled with the whole set of Maxwell equations: in fact, the
expression of the electric field in terms of the potentials is given by the second
relation in (4.26), namely, E = &minus;gradÏ &minus; &part;A/&part;t ; as a consequence, in a dynamic
condition both the scalar and vector potential must be determined. In a steady-state
or equilibrium condition, instead, the expression of the electric field reduces to
E = &minus;gradÏ; in this case it is sufficient to couple the semiconductor model with the
first equation in (4.19) only.
</p>
<p>The presence of the vector potential A makes the model more complicate; thus, it
is useful to ascertain whether, in the typical operating conditions, the time derivative
&part;A/&part;t in the expression of E should be kept or not. As noted above, the derivative
differs from zero only if the boundary conditions (e.g., the applied voltages) vary with
time. To associate a characteristic time to a boundary condition one takes the period
associated to the maximum frequency of the boundary condition&rsquo;s spectrum, Ïmin =
1/Î½max; then, one compares Ïmin with the time ï¿½t necessary for the electromagnetic
perturbation produced by the boundary condition to propagate to a position internal
to the semiconductor. If d is the distance between a point on the boundary and an
internal point, the propagation time can be estimated to be ï¿½t = d/uf , with uf
the radiation&rsquo;s phase velocity corresponding to Î½max. If it happens that ï¿½t âª Ïmin,
the propagation is practically instantaneous, namely, the electromagnetic field at the
internal point is consistent with the boundary condition existing at the same instant
of time; as a consequence, the boundary condition is thought of as stationary, and
the &part;A/&part;t derivative is neglected. This is called quasi-static approximation; the
condition of its applicability is summarized as35
</p>
<p>Ît = d
uf
</p>
<p>âª Ïmin =
1
</p>
<p>Î½max
, Î½max âª
</p>
<p>uf
</p>
<p>d
. (19.127)
</p>
<p>To estimate the condition one must fix the value of d; as a conservative choice
one takes the channel length of the MOSFET transistors of the old generations,
d &asymp; 10&minus;7 m. Using uf &asymp; 108 m s&minus;1 yields Î½max âª 1015 Hz, which is amply fulfilled
in the present state-of-the-art integrated circuits. Note that the condition is even better
verified in the last-generation devices, whose channel length is shorter than 10&minus;7 m.
</p>
<p>The choice of the channel length in the above estimate is dictated by the fact that
the channel is the active region of the device. Choosing, instead, d as the (much
larger) thickness of the silicon wafer would not make sense, because the phenomena
taking place in the wafer&rsquo;s bulk are relatively unimportant. Other distances within an
integrated circuit are larger by orders of magnitude than the value of d considered in
the estimate; for instance, the diameter of the integrated circuit itself is of the order
of 10&minus;2 m, hence the quasi-static approximation is not applicable to the case of two
devices placed, e.g., at opposite corners of a chip and connected by a line. In fact,
</p>
<p>35 A similar reasoning is used to treat the time derivative of vi , w, and bi in the derivation of the
BTE&rsquo;s moments of order larger than zero (Sect. 19.4.2).</p>
<p/>
</div>
<div class="page"><p/>
<p>438 19 Mathematical Model of Semiconductor Devices
</p>
<p>the propagation of signals along the lines connecting different devices on a chip is
modeled using the whole set of Maxwell equations.36
</p>
<p>19.5.5 Semiconductor-Device Model
</p>
<p>Thanks to the quasi-static approximation, the equations describing the semiconduc-
tor, in the drift-diffusion case and with B = 0, read
</p>
<p>divD = q (p &minus; n+N ), D = &minus;Îµsc gradÏ, (19.128)
&part;n
</p>
<p>&part;t
&minus; 1
</p>
<p>q
divJn = Wn, Jn = q Î¼n nE + q Dn gradn, (19.129)
</p>
<p>&part;p
</p>
<p>&part;t
+ 1
</p>
<p>q
divJp = Wp, Jp = q Î¼p p E &minus; q Dp gradp. (19.130)
</p>
<p>As outlined in Chap. 24, insulating layers play an essential role in the fabrication
of integrated circuits; it is then necessary to extend the model to incorporate also
the description of such layers. This is easily accomplished by observing that mobile
charges are absent in an insulator, so that the balance equations for the number of
particles and the transport equations reduce to identities, 0 = 0. The model for the
insulators then reduces to Poisson&rsquo;s equation only. The right hand side of the latter
does not necessarily vanish because, as indicated in Sect. 24.1, contaminants may
enter the insulator during the fabrication steps; some of these contaminants may
ionize and act as fixed charges so that, letting Nox be their density, the model for the
insulator reads37
</p>
<p>divD = q Nox, D = &minus;Îµox gradÏ, n = p = 0, Jn = Jp = 0.
(19.131)
</p>
<p>The set of Eqs. (19.128&ndash;19.131) is commonly called semiconductor-device model.
It is made of partial-differential equations of the first order, in the unknowns Ï, n, p
and D, Jn, Jp. The coefficients are Î¼n, Î¼p, Dn = (kB T/q)Î¼n, Dp = (kB T/q)Î¼p.
In turn, N , Wn, Wp are either known functions, or are expressed in terms of the
unknowns themselves. Some of the equations are non linear because the unknowns
are multiplied by each other. Each equation on the left in (19.128&ndash;19.131) contains
the divergence of a vector; in turn, the expression of the vector is given by the
corresponding equation on the right, in terms of the scalar unknowns (in fact it is
E = &minus;gradÏ). It follows that, by introducing the expressions of D, Jn, and Jp
</p>
<p>36 The progressive device scaling from one generation to the next is in general associated to an
increase in the size of the chips. Due to this, the constraints on the circuit&rsquo;s speed are rather imposed
by the lines connecting the devices than by the devices themselves.
37 The insulator&rsquo;s permittivity is indicated with Îµox because, in the examples shown later, silicon
dioxide (SiO2) is used as the reference insulator.</p>
<p/>
</div>
<div class="page"><p/>
<p>19.5 Hydrodynamic and Drift-Diffusion Models 439
</p>
<p>into the divergence operator, each pair of first-order equation is transformed into a
single, second-order equation. This observation is useful in view of the application
of numerical methods to the solution of the semiconductor-device model.
</p>
<p>Remembering the derivation of the transport model, the termsWn, Wp in (19.129),
(19.130) are due to the generation-recombination phenomena. Specifically, Wn is
the difference between the number of electrons entering the conduction band, and of
those leaving it, per unit volume and time; in turn, Wp is the difference between the
number of holes entering the valence band, and of those leaving it, per unit volume
and time.38 For this reason, they are also called net generation rates.
</p>
<p>As mentioned in Sect. 19.3, the transitions of a given class are further grouped
depending on the entity with which the particle&rsquo;s collision occurs. As far as the net
generation rates are concerned, it is customary to separate the contribution of the
phonon collisions from those of the other types (e.g., electron&ndash;electron collisions,
electron&ndash;photon collisions, and so on); in fact, unless the device is kept at a very
low temperature, the phonon collisions are the most important ones. Thus, the net
generation rates are recast as
</p>
<p>Wn = Gn &minus; Un, Wp = Gp &minus; Up, (19.132)
where Un, Up describe the transitions due to phonon collisions, while Gn, Gp de-
scribe those of the other types. The minus signs in (19.132) come from the fact that
Un is defined as the difference between the number of electrons leaving the conduc-
tion band, and of those entering it, because of phonon collisions, per unit volume and
time; similarly, Up is defined as the difference between the number of holes leaving
the valence band, and of those entering it, because of phonon collisions, per unit
volume and time. The terms used for Un, Up are net thermal recombination rates,
those for Gn, Gp are net non-thermal generation rates.
</p>
<p>Another comment about the semiconductor-device model concerns the drift terms
in (19.129), (19.130). The latter can be recast as Jdrn = Ïn E and Jdrp = Ïp E, where
</p>
<p>Ïn = q Î¼n n, Ïp = q Î¼p p (19.133)
are the electron conductivity and hole conductivity, respectively. From J = Jn + Jp,
in a uniform material one obtains J = Ï E, that is, Ohm&rsquo;s law, with
</p>
<p>Ï = Ïn + Ïp = q
(
</p>
<p>Î¼n n+ Î¼p p
)
</p>
<p>. (19.134)
</p>
<p>19.5.6 Boundary Conditions
</p>
<p>In practical applications, the equations of the semiconductor-device model, (19.128)
through (19.131), are solved over a closed domain whose boundary39 is indicated
</p>
<p>38 The units are [Wn,Wp] = m&minus;3 s&minus;1.
39 A two- or three-dimensional case is considered. In the one-dimensional case the boundary reduces
to the two points enclosing the segments over which the equations are to be solved.</p>
<p/>
</div>
<div class="page"><p/>
<p>440 19 Mathematical Model of Semiconductor Devices
</p>
<p>V
G
</p>
<p>V
S
</p>
<p>V
D
</p>
<p>Fig. 19.3 MOS structure used to discuss the boundary conditions for the mathematical model of
semiconductor devices. Only the conducting boundaries are shown. Note that the vertical scale of
the drawing is not realistic
</p>
<p>here withÅ´. The boundary is partitioned into portions, some of which, indicated with
Å´i1,Å´i2, . . . , are insulating boundaries, namely, they can not be crossed by electrons
or holes; the remaining portions, Å´c1,Å´c2, . . . , can be crossed by the carriers and are
termed conducting boundaries.
</p>
<p>Considering that the domain over which the equations are solved is in general a
part of a much larger domain enclosing an integrated circuit, some flexibility exists
as for the choice of Å´. Thanks to this, it is possible to select Å´i1,Å´i2, . . . such that
the normal component of the vector unknowns vanishes there; in other terms, letting
s be the unit vector normal to an insulating boundary at some point r, it is
</p>
<p>E &middot; s = 0, &part;Ï
&part;s
</p>
<p>= 0, r &isin; Å´i1,Å´i2, . . . . (19.135)
</p>
<p>where &part;/&part;s indicates the derivative normal to the boundary at r. An example of
how this can be accomplished is given in Figs. 19.3 and 19.4, representing the
schematic cross-section of a MOSFET. In Fig. 19.3 only the conducting boundaries
are shown, with VS , VG, and VD indicating the voltage applied to the source, gate,
and drain contact, respectively. The bulk contact is grounded, as shown by the line
below; such a contact is the ground reference for the whole chip and, for this reason,
extends laterally beyond the region occupied by the MOSFET under consideration.
The insulating boundaries must now be selected in order to form a closed line that
completes the boundary Å´; in principle, such a completion may be accomplished
in different ways. Consider, however, the completion shown in the upper part of
Fig. 19.4: as in general it is VS ï¿½= VG, it is likely that one of the field lines in the
region between the source and gate contacts coincides with the segment ab. As a
consequence, choosing ab as the insulating boundary in that region guarantees that
the component of E normal to such a boundary is zero, thus achieving the condition
sought. The same reasoning applies to line cd . By this procedure one succeeds in
prescribing the boundary conditions for the Poisson equation along the insulating
boundaries. If, instead, the insulating boundaries were placed differently, like, e.g.,
in the lower part of Fig. 19.4, the component of E normal to the boundary would be
different from zero; besides that, it would be impossible to determine it a priori, and
Poisson&rsquo;s equation would become ill-posed.
</p>
<p>Once the insulating boundaries are completed, the same condition as (19.135) is
prescribed onto the current densities, namely, Jn &middot; s = Jp &middot; s = 0 whence, using the
second equation in (19.129),</p>
<p/>
</div>
<div class="page"><p/>
<p>19.5 Hydrodynamic and Drift-Diffusion Models 441
</p>
<p>Fig. 19.4 The same structure
as in Fig. 19.3, to which the
insulating boundaries have
been added (dash-dotted
lines). The upper part of the
figure shows the correct
placement of the insulating
boundaries, the lower part
shows a wrong placement
</p>
<p>V
G
</p>
<p>V
S
</p>
<p>V
D
</p>
<p>c
</p>
<p>d
</p>
<p>a
b
</p>
<p>V
G
</p>
<p>V
S
</p>
<p>V
D
</p>
<p>&minus;q Î¼n n
&part;Ï
</p>
<p>&part;s
+ q Dn
</p>
<p>&part;n
</p>
<p>&part;s
= 0, r &isin; Å´i1,Å´i2, . . . . (19.136)
</p>
<p>Combining the above with (19.135) yields &part;n/&part;s = 0; repeating the calculation for
the holes finally shows that at the insulating boundaries the boundary condition is
the same for all scalar unknowns Ï, n, p:
</p>
<p>&part;Ï
</p>
<p>&part;s
= 0, &part;n
</p>
<p>&part;s
= 0, &part;p
</p>
<p>&part;s
= 0, r &isin; Å´i1,Å´i2, . . . , (19.137)
</p>
<p>i.e., a boundary condition of the homogeneous Neumann type.
The conducting boundariesÅ´c1,Å´c2, . . . are typically covered with metal layers or
</p>
<p>heavily-doped polycrystalline layers that provide the electric contacts to the device.
Unless the operating condition of the device departs strongly from equilibrium, a
contact is able to supply the amount of charge necessary to keep the equilibrium and
charge-neutrality conditions in the semiconductor layer adjacent to it. Thus at each
point r of this layer one takes Ï = 0 or, more specifically,
</p>
<p>Ïc = q (pc &minus; nc +Nc) = 0, r &isin; Å´c1,Å´c2, . . . , (19.138)
where index c indicates the conducting boundary. In most cases the metal or poly-
crystalline layer is connected to a voltage generator, so that the electric potential is
prescribed, or to another part of the integrated circuit, so that the electric potential
can be determined from a separate calculation. In these cases, the electric potential of
the contact is known. From it, one derives the electric potential Ïc of the conducting
boundary adjacent to the contact; in fact, when the departure from the equilibrium
condition is not too strong, the difference between the electric potential of the con-
ducting boundary and that of the contact does not depend on the current density that
crosses the boundary, and equals the contact&rsquo;s work function.40 The latter is experi-
mentally known, this yielding Ïc. In conclusion, at a conducting boundary where the
</p>
<p>40 Examples of application of this concept are given in Sects. 21.2.2 and 22.2.</p>
<p/>
</div>
<div class="page"><p/>
<p>442 19 Mathematical Model of Semiconductor Devices
</p>
<p>voltage is prescribed, the boundary condition is the same for all scalar unknowns:
Ï = Ïc, n = nc, p = pc, r &isin; Å´c1,Å´c2, . . . , i.e., a boundary condition of the Dirichlet
type. Note that the quantities in parenthesis in (19.138) depend on Ïc (compare with
(18.56) and (18.57)); as a consequence, they can be calculated only after the electric
potential has been determined.
</p>
<p>In some instances a current generator is connected to a contact; as a consequence,
the voltage is not prescribed at the corresponding conducting boundary. However,
such a voltage can be determined by observing that the flux of the current density
across the boundary equals the generator&rsquo;s current. This provides the extra relation
that keeps the well-posedness of the mathematical problem.41
</p>
<p>19.5.7 Quasi-Fermi Potentials
</p>
<p>The drift-diffusion transport equations, given by the second relation in (19.129),
(19.130), can be recast in a monomial form by defining two auxiliary functions
</p>
<p>Ïn(r, t) = Ï &minus;
kB T
</p>
<p>q
log
</p>
<p>(
n
</p>
<p>ni
</p>
<p>)
</p>
<p>, Ïp(r, t) = Ï +
kB T
</p>
<p>q
log
</p>
<p>(
p
</p>
<p>ni
</p>
<p>)
</p>
<p>, (19.139)
</p>
<p>whose inversion yields
</p>
<p>n = ni exp
[
q (Ï &minus; Ïn)
</p>
<p>kB T
</p>
<p>]
</p>
<p>, p = ni exp
[
q (Ïp &minus; Ï)
</p>
<p>kB T
</p>
<p>]
</p>
<p>. (19.140)
</p>
<p>In the equilibrium limit, (19.140) must coincide with (18.62), namely, Ïn &rarr; ÏF ,
Ïp &rarr; ÏF . It follows that the auxiliary functions (19.139) are a formal gener-
alization of the concept of Fermi potential; they have the advantage of keeping
the exponential form of the expressions of n and p in the non-equilibrium case.
For this reason, Ïn and Ïp are called quasi-Fermi potentials for electrons and
holes, respectively.42 From (19.140) one finds (kB T/q) gradn = n grad(Ï &minus; Ïn)
and (kB T/q) gradp = p grad(Ïp &minus; Ï) which, replaced into the second relation of
(19.129), (19.130), respectively, yield
</p>
<p>Jn = &minus;q Î¼n n gradÏ + q
kBTL
</p>
<p>q
Î¼n gradn = &minus;q Î¼n n gradÏn, (19.141)
</p>
<p>Jp = &minus;q Î¼p p gradÏ &minus; q
kB T
</p>
<p>q
Î¼p gradp = &minus;q Î¼p p gradÏp. (19.142)
</p>
<p>41 This outcome becomes immediately clear by applying a numerical-discretization method to the
problem. In fact, the component of the current density normal to the contact depends on the electric
potential of the contact itself; thus, the extra relation provided by the flux-conservation equation
embeds the extra unknown Ïc.
42 By some authors, Ïn and Ïp are called Imref potentials, where &ldquo;Imref&rdquo; is &ldquo;Fermi&rdquo; read from
right to left [103].</p>
<p/>
</div>
<div class="page"><p/>
<p>19.5 Hydrodynamic and Drift-Diffusion Models 443
</p>
<p>One notes that the monomial forms (19.141), (19.142) thus achieved are similar to
drift-diffusion equations where the drift term only is present. This result allows one
to interpret &minus;gradÏn and &minus;gradÏp as effective fields acting on the electrons (or,
respectively, holes) and incorporating both drift and diffusion effects. The monomial
form is useful for describing unipolar devices, where one of the current densities Jn,
Jp dominates over the other and is essentially solenoidal (Sect. 22.6).
</p>
<p>The definition of the quasi-Fermi potential given above is applicable only to
drift-diffusion equations of the form (19.129), (19.130), that are valid within the
approximations of parabolic bands and non-degenerate conditions. However, the
concept of quasi-Fermi potential can be generalized by disposing, e.g., of the non-
degeneracy hypothesis. For this, one starts from the equilibrium expressions of n and
p, given by (18.56) and (18.57), respectively, and replaces EF in the definitions of
Î¾e, Î¾h with EF = EFi &minus;q ÏF (compare with (18.26)); then, the Fermi potential ÏF is
replaced with Ïn in the definition of Î¾e, and with Ïp in that of Î¾h. The non-equilibrium
concentrations then read
</p>
<p>n = NC Î¦1/2 (Î¾e) , Î¾e = &minus;
EC &minus; EFi
</p>
<p>kB T
+ q (Ï &minus; Ïn)
</p>
<p>kB T
, (19.143)
</p>
<p>and
</p>
<p>p = NV Î¦1/2 (Î¾h) , Î¾h = &minus;
EFi &minus; EV
</p>
<p>kB T
+ q (Ïp &minus; Ï)
</p>
<p>kB T
. (19.144)
</p>
<p>19.5.8 Poisson Equation in a Semiconductor
</p>
<p>In the equilibrium condition the concentrations of electrons (19.143) and holes
(19.144) depend on the electric potential only. In turn, the ionized donor and ac-
ceptor concentrations depend on the electric potential and, possibly, on position
if the dopant distributions are position dependent. In summary, the general form
of the equilibrium charge concentration is Ï = Ï(Ï, r). The semiconductor-device
model reduces to the Poisson equation alone because at equilibrium it is &part;/&part;t = 0,
Jn = Jp = 0; the equation reads &minus;Îµsc &nabla;2Ï = q (p &minus; n + N ) = Ìº(Ï, r), which is
a semi-linear partial differential equation (PDE).43 If the explicit dependence on r
is absent, Ï = Ï(Ï), and the problem is one dimensional, say, in the x direction,
Poisson&rsquo;s equation can be solved analytically over a domain I where dÏ/dx ï¿½= 0. In
</p>
<p>43 A PDE of order s in the unknown Ï is called quasi-linear if it is linear in the order-s derivatives of
Ï and its coefficients depend on the independent variables and the derivatives of Ï of orderm &lt; s. A
quasi-linear PDE where the coefficients of the order-s derivatives are functions of the independent
variables alone, is called semi-linear. A PDE which is linear in the unknown function and all its
derivatives, with coefficients depending on the independent variables alone, is called linear. PDE&rsquo;s
not belonging to the classes above are fully non-linear.</p>
<p/>
</div>
<div class="page"><p/>
<p>444 19 Mathematical Model of Semiconductor Devices
</p>
<p>fact, multiplying by dÏ/dx both sides of &minus;Îµsc d2Ï/dx2 = Ï(Ï), one obtains
</p>
<p>&minus;Îµsc
d2Ï
</p>
<p>dx2
dÏ
</p>
<p>dx
= Ï(Ï) dÏ
</p>
<p>dx
,
</p>
<p>d
</p>
<p>dx
</p>
<p>(
dÏ
</p>
<p>dx
</p>
<p>)2
</p>
<p>= d
dx
</p>
<p>S(Ï), (19.145)
</p>
<p>where dS/dÏ = &minus;2 Ï(Ï)/Îµsc. Integrating (19.145) from x0 to x, where both points
belong to I , and letting Ï0 = Ï(x0), yields
</p>
<p>(
dÏ
</p>
<p>dx
</p>
<p>)2
</p>
<p>= G2(Ï), G(Ï) =
[
(
</p>
<p>dÏ
</p>
<p>dx
</p>
<p>)2
</p>
<p>0
</p>
<p>+ S(Ï) &minus; S(Ï0)
]1/2
</p>
<p>. (19.146)
</p>
<p>Separating the variables in (19.146) then provides
</p>
<p>dx = &plusmn; dÏ
G(Ï)
</p>
<p>, x = x0 &plusmn;
&int; Ï
</p>
<p>Ï0
</p>
<p>dÏ
</p>
<p>G(Ï)
, (19.147)
</p>
<p>namely, the inverse relation x = x(Ï). The choice of the sign is made on case-
by-case basis (an example is given in Sect. 21.2). The approach can be extended
to the non-equilibrium case if it happens that the electric potential depends on one
independent variable, say, x, while the Poisson equation contains terms that depend
also on independent variables different from x. In fact, the other variables can be
considered as parameters during the integration with respect to x. An example of this
case is given in Sect. 22.7.1.
</p>
<p>19.6 Complements
</p>
<p>19.6.1 Comments on the Equivalent Hamiltonian Operator
</p>
<p>It has been observed in Sect. 19.2.2 that, in the description of the wave-packet
dynamics based on the equivalent Hamiltonian operator and crystal momentum, that
the time variations of the latter are due to the external force only; as a consequence, if
U = const one has hÌ kÌ0 = 0, namely, the crystal momentum is a constant of motion.
The periodic part of the potential energy is incorporated with the kinetic part, to form
an equivalent operator. Thus, the expression of the Hamiltonian operator is eventually
made of two terms, the equivalent-kinetic part, where the space coordinates do not
explicitly appear, and the potential part due to the external force only; from this
standpoint it is similar to that of a particle in vacuo.
</p>
<p>The same results were found in the analysis of the motion of a classical particle
subjected to a periodic potential onto which a weak perturbation is superimposed
(Sect. 3.11). The classical investigation makes it clear that the crystal momentum
is in fact different from the actual momentum of the particle; also, the subsequent
elaboration carried out in Sect. 3.12 shows that the concept of effective mass is not
distinctive of Quantum Mechanics.</p>
<p/>
</div>
<div class="page"><p/>
<p>19.6 Complements 445
</p>
<p>19.6.2 Special Cases of Anisotropy
</p>
<p>It is interesting to note that for an anisotropic branch the acceleration uÌ may still be
parallel to F; this happens when the force is parallel to one of the coordinate axes.
Taking by way of example a force parallel to the first coordinate axis, F = F i1, it
follows in fact
</p>
<p>uÌ1 = F/m1a , uÌ2 = 0, uÌ3 = 0. (19.148)
</p>
<p>This seems to imply that a suitable choice of the reference is sufficient to make
the acceleration parallel to the force. However, this is not so: as noted in Sect. 17.6.2,
for (19.24) to hold, the reference in the k space must be chosen in such a way as to
make the Hessian matrix of En(k) diagonal; this, in turn, fixes the reference in the
r space, because the two references are reciprocal to each other. As a consequence,
if one rotates the r reference to align one of its axes with the force, the k reference
rotates as well; as the mass tensor in the new reference is not necessarily diagonal,
the anisotropy present in the old reference is maintained.
</p>
<p>19.6.3 Î±-Moment at Equilibrium
</p>
<p>The derivation of the moment with respect to Î± of the BTE has been shown in
Sect. 19.4.1, leading to (19.62). In the equilibrium condition the distribution function
f eq is independent of t and depends on k through the Hamiltonian function H only;
since the latter is even with respect to k, the distribution function is even as well. In
turn, as the transitions balance each other, the right hand side of (19.62) vanishes.
The term with the magnetic induction vanishes as well (compare with (19.60)); in
conclusion, in the equilibrium condition (19.62) reduces to
</p>
<p>divr (n Î± u)
eq + q
</p>
<p>hÌ
</p>
<p>(
</p>
<p>n gradkÎ± &middot; E
)eq = 0. (19.149)
</p>
<p>It is easily found that (19.149) yields the identity 0 = 0 if Î± is even with respect
to k. This, on the contrary, is not true when Î± is odd; in this case the equilibrium
condition consists in the balance between the diffusion term, due to the spatial non-
uniformity of (nÎ± u)eq, and the second term, proportional to the carrier concentration
and linearly dependent on the electric field.
</p>
<p>19.6.4 Closure Conditions
</p>
<p>The closure conditions for the drift-diffusion and hydrodynamic model are derived
in this section. The former consists in calculating (19.75) using the equilibrium
distribution f eq = QP , with Q = 1/(4Ï3) the density of states in the r, k space</p>
<p/>
</div>
<div class="page"><p/>
<p>446 19 Mathematical Model of Semiconductor Devices
</p>
<p>and P the Fermi&ndash;Dirac statistics. In the equilibrium case it is v = 0, whence c = u,
and
</p>
<p>neq kB T
eq
ij =
</p>
<p>mia
</p>
<p>4Ï3
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>ui uj
</p>
<p>exp [(Ee + Î¶e)/(kB T )] + 1
d3k, (19.150)
</p>
<p>with Ee = E &minus; EC and Î¶e = EC &minus; q Ï &minus; EF (compare with (18.54)). In the
above, Ee is even with respect to all components of k. For j ï¿½= i the integrand is
odd with respect to ki because ui = (1/hÌ) &part;Ee/&part;ki , and with respect to kj because
uj = (1/hÌ) &part;Ee/&part;kj ; as a consequence it is Tij = 0 for j ï¿½= i, while
</p>
<p>neq kB T
eq
ii =
</p>
<p>mia
</p>
<p>4Ï3
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>u2i
</p>
<p>exp [(Ee + Î¶e)/(kB T )] + 1
d3k, (19.151)
</p>
<p>namely, in the equilibrium condition the electron-temperature tensor is diagonal. For
this result to hold, the parabolic-band approximation is not necessary.
</p>
<p>In the parabolic-band approximation, (19.24) and (19.72) hold, and the temper-
ature tensor in equilibrium is evaluated at the ath minimum of the conduction band
by letting
</p>
<p>Î·i =
hÌ Î´ki&radic;
2mia
</p>
<p>, d3k = 2
&radic;
</p>
<p>2
</p>
<p>hÌ3
m3/2ea d
</p>
<p>3Î·, mia u
2
i = 2 Î·2i , (19.152)
</p>
<p>where the first relation is the Herring-Vogt transformation (17.66) and mea is defined
in (17.68). Adding up over the minima and using (17.72) yields
</p>
<p>neq kB T
eq
ii =
</p>
<p>&radic;
2
</p>
<p>Ï3 hÌ3
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>MC m
3/2
e Î·
</p>
<p>2
i
</p>
<p>exp [(Î·2 + Î¶e)/(kB T )] + 1
d3Î·. (19.153)
</p>
<p>As the value of the integral in (19.153) does not depend on index i, it follows that the
diagonal entries T eqii are equal to each other; as a consequence, the common value
of the three integrals can be replaced with T eqe = (T eq11 + T
</p>
<p>eq
22 + T
</p>
<p>eq
33 )/3, namely,
</p>
<p>neq kB T
eq
ii =
</p>
<p>&radic;
2
</p>
<p>3Ï3 hÌ3
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>MC m
3/2
e Î·
</p>
<p>2
</p>
<p>exp [(Î·2 + Î¶e)/(kBTL)] + 1
d3Î·. (19.154)
</p>
<p>Turning to spherical coordinates (B.1) yields d3Î· = Î·2 dÎ· sin Î¸ dÎ¸ dÏ, with Î·2 =
Î·21 + Î·22 + Î·23 = Ee and dÎ· = 1/(2
</p>
<p>&radic;
Ee) dEe, Î·2 dÎ· =
</p>
<p>&radic;
Ee dEe/2. The integral
</p>
<p>over the angles equals 4Ï whence, using (C.104) with Î (1 + 3/2) = (3/2)&radic;Ï/2,
</p>
<p>neq kB T
eq
ii = kB T NC Î¦3/2(Î¾e), (19.155)
</p>
<p>with NC = 2MC [me kB T/(2Ï hÌ2)]3/2 the effective density of states (18.4), and
Î¾e = &minus;Î¶e/(kBT ). On the other hand, from (18.17) it is neq = NC Î¦1/2(Î¾e), whence
</p>
<p>T eqe (r) = T
Î¦3/2(Î¾e)
</p>
<p>Î¦1/2(Î¾e)
. (19.156)</p>
<p/>
</div>
<div class="page"><p/>
<p>19.6 Complements 447
</p>
<p>The dependence on position is due to Î¾e = (q Ï &minus; EC + EF )/(kB T ). However, in
the non-degenerate case the approximation (C.105) holds, Î¦Î±(Î¾e) = exp (Î¾e), and
the electron-temperature tensor at equilibrium reduces to T eqe = T .
</p>
<p>Coming now to the hydrodynamic model, and remembering (19.83), the closure
condition is found by calculating the equilibrium value of nmia Ee ui c, that reads
</p>
<p>neq mia
(
</p>
<p>Ee ui c
)eq = mia
</p>
<p>4Ï3
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Ee ui cP d
</p>
<p>3k, (19.157)
</p>
<p>with P the Fermi&ndash;Dirac statistics. The procedure is similar to that of the drift-
diffusion model. At equilibrium one can replace c with u; then, out of the three
components of u, only that of index i contributes to the integral, because those of
index j ï¿½= i make the integrand odd with respect to both ki and kj . In other terms, the
integrand in (19.157) is replaced with Ee u2i P ii , which differs from the integrand
of (19.151) because of factor Eeii ; this shows that the tensor defined by (19.157) is
diagonal as well.44 When the transformation (19.152) is used, the right hand side of
(19.157) becomes similar to (19.153), the only difference being the additional factor
Î·2 i that derives from Eeii . The next step, replacing the common value of the three
integrals with one third of their sum, yields an expression similar to (19.154), the only
difference being that Î·2 is replaced with Î·4 i. Transforming into spherical coordinates
and inserting (C.104) with Î (1 + 5/2) = (5/2)Î (1 + 3/2) = (15/4)&radic;Ï/2 finally
yields
</p>
<p>neq mia
(
</p>
<p>Ee ui c
)eq = ii
</p>
<p>5
</p>
<p>2
(kB T )
</p>
<p>2 NC Î¦5/2(Î¾e). (19.158)
</p>
<p>It follows
</p>
<p>mia
(
</p>
<p>Ee ui c
)eq = ii
</p>
<p>5
</p>
<p>2
(kB T )
</p>
<p>2 Î¦5/2(Î¾e)
</p>
<p>Î¦1/2(Î¾e)
â ii
</p>
<p>5
</p>
<p>2
(kB T )
</p>
<p>2 , (19.159)
</p>
<p>where the approximation holds in the non-degenerate case.
</p>
<p>19.6.5 Matthiessen&rsquo;s Rule
</p>
<p>The effects of the inter-band and intra-band transitions have been separated in
Sect. 19.3.2 under the assumption that the two types are uncorrelated. The sepa-
ration may further be pursued within each class, depending on the entity with which
the collision occurs. Here the collisions leading to the intra-band transitions only are
considered. With reference to (19.45), and assuming that the intra-band transitions
are uncorrelated, one lets S0v = S(1)0v + S(2)0v + . . . , whence
</p>
<p>1
</p>
<p>Ïv
= 1
</p>
<p>Ïv1
+ 1
</p>
<p>Ïv2
+ . . . , 1
</p>
<p>Ïvj
=
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
S
</p>
<p>(j )
0v (r, k &rarr; k&prime;) d3k&prime;. (19.160)
</p>
<p>44 As above, for this result to hold the parabolic-band approximation is not necessary.</p>
<p/>
</div>
<div class="page"><p/>
<p>448 19 Mathematical Model of Semiconductor Devices
</p>
<p>This way of combining the relaxation times, also called Matthiessen&rsquo;s rule, still holds
in the definitions of the macroscopic relaxation times Ïp, Ïw and Ïb (Sect. 19.4.2),
and in the definitions (19.104), (19.118) of electron and hole mobilities through Ïp.
</p>
<p>19.6.6 Order of Magnitude of Mobility and Conductivity
</p>
<p>As shown in Sect. 19.5.2, the electron and hole mobilities are expressed by relations
of the form Î¼ = q Ïp/m&lowast;, where Ïp is the momentum-relaxation time and m&lowast; an
effective mass. To the purpose of estimating the order of magnitude it is not necessary
to distinguish between electrons and holes. Considering the T = 300 K case and
taking Ïp &asymp; 0.25 &times; 10&minus;12 s, m&lowast; &asymp; 0.4 &times; 10&minus;30 kg yields45
</p>
<p>Î¼ = q Ïp
mâ
</p>
<p>&asymp; 1.60 &times; 10&minus;19 C &times; 0.25 &times; 10
&minus;12 s
</p>
<p>0.4 &times; 10&minus;30 kg = 10
3 cm
</p>
<p>2
</p>
<p>V s
. (19.161)
</p>
<p>The diffusion coefficient at T = 300 K is estimated from the Einstein relation
(19.102), D = (kB T/q)Î¼, where
</p>
<p>kB T
</p>
<p>q
&asymp; 1.38 &times; 10
</p>
<p>&minus;23 (J/K) &times; 300 K
1.60 &times; 10&minus;19 C = 26 &times; 10
</p>
<p>&minus;3 V. (19.162)
</p>
<p>One finds
</p>
<p>D &asymp; 26 &times; 10&minus;3 V &times; 103 cm
2
</p>
<p>V s
= 26 cm
</p>
<p>2
</p>
<p>s
. (19.163)
</p>
<p>To estimate the conductivity one takes by way of example the expression for electrons
from (19.133), Ïn = q Î¼n n, where, due to the estimates above, it is q Î¼n &asymp; 1.60 &times;
10&minus;19 C&times;103 cm2/(V s) = 1.60&times;10&minus;16 cm2/ï¿½. For silicon at T = 300 K it is n =
ni &asymp; 1010 cm&minus;3 (Table 18.2);46 in comparison, when silicon is doped with a uniform
donor concentration equal to, say, N &prime;D = 1016 cm&minus;3, it is n â N &prime;D = 1016 cm&minus;3
(compare with (18.30)). In conclusion,
</p>
<p>Ïn[intrinsic] &asymp; 10&minus;6 (ï¿½ cm)&minus;1, Ïn[N &prime;D] &asymp; 1 (ï¿½ cm)&minus;1. (19.164)
</p>
<p>As a further comparison, the estimates for an insulator and, respectively, a conductor,
are made with n â 104 cm&minus;3 and n â 1022 cm&minus;3, to find
</p>
<p>Ïn[insulator] &asymp; 10&minus;12 (ï¿½ cm)&minus;1, Ïn[conductor] &asymp; 106 (ï¿½ cm)&minus;1. (19.165)
</p>
<p>45 Mobility is traditionally expressed in cm2/(V s) instead of m2/(V s).
46 The equilibrium concentrations are used in the estimates.</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 449
</p>
<p>19.6.7 A Resum&eacute; of the Transport Model&rsquo;s Derivation
</p>
<p>The number of steps that lead to the hydrodynamic or drift-diffusion model for
semiconductors is quite large; thus, a brief summary is of use. The starting point
is the single-particle Schr&ouml;dinger equation for an electron in a crystal. To reach
this stage of the theory a considerable amount of work has already been spent,
necessary to reduce the many-particle problem to a tractable form (Chap. 16). When
the external forces are absent, the single-particle equation is recast in a form based on
the equivalent Hamiltonian operator, that exploits the periodicity of the lattice (this
implies in turn that the nuclei are kept fixed in the equilibrium positions). Finally,
the external forces are added, assuming that the external potential energy is a small
perturbation; thanks to this hypothesis, it is possible to describe the collisionless
motion of a single electron by means of a Hamiltonian function whose canonical
variables are the expectation values of the wave packet&rsquo;s position and momentum
(Sects. 19.2.1 and 19.2.2).
</p>
<p>Basing on the Hamiltonian function thus found, the analysis shifts from the de-
scription of the single-particle to the statistical treatment of a system made of a large
number of electrons, following the same pattern as in the classical case; this leads to
the semiclassical BTE (Sect. 19.3), for which the general form of the collision term
is worked out (Sect. 19.3.1). The latter is simplified, first, by considering point-like
collisions, then by taking the perturbative form of the collision operator (Sects. 19.3.2
and 19.3.3).
</p>
<p>The perturbative form of the BTE is treated with the moments method, that pro-
vides a hierarchical set of models, e.g., the drift-diffusion and the hydrodynamic
model. Important approximations at this stage are, for all moments of order larger
than zero, the neglect of the inter-band transitions, of the time derivatives, and of
the convective terms. The models reach the final form thanks to the hypothesis of
parabolic bands and the approximation of the relaxation-time tensors with scalar
quantities.
</p>
<p>Problems
</p>
<p>19.1 In the expressions (19.115), (19.118) defining the hole mobility Î¼p, assume
that Ïph â Ïpl . Letting Ïp be the common value, determine the value of the
normalized effective mass mh/m0 to be used in Î¼p = q Ïp/mh for silicon at
room temperature. Also, determine the value of parameter ap in (19.122) in the
same conditions.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 20
</p>
<p>Generation-Recombination and Mobility
</p>
<p>20.1 Introduction
</p>
<p>The chapter illustrates the main contributions to the transitions of the inter-band type,
that give rise to the generation-recombination terms in the continuity equations for
electrons and holes, and to those of the intra-band type, that give rise to the electron
and hole mobilities in the current-density equations. The inter-band transitions that
are considered are the net thermal recombinations (of the direct and trap-assisted
type), Auger recombinations, impact-ionization generations, and net-optical recom-
binations. The model for each type of event is first given as a closed-form function
of the semiconductor-device model&rsquo;s unknowns, like carrier concentrations, electric
field, or current densities. Such functions contain a number of coefficients, whose
derivation is successively worked out in the complements by means of a microscopic
analysis. Some discussion is devoted to the optical-generation and recombination
events, to show how the concepts of semiconductor laser, solar cell, and optical
sensor may be derived as particular cases of non-equilibrium interactions between
the material and an electromagnetic field. The intra-band transitions are treated in
a similar manner: two examples, the collisions with acoustic phonons and ionized
impurities, are worked out in some detail; the illustration then follows of how the
contributions from different scattering mechanisms are combined together in the
macroscopic mobility models. The material is supplemented with a brief discussion
about advanced modeling methods.
</p>
<p>20.2 Net Thermal Recombinations
</p>
<p>As anticipated in Sect. 19.5.5, it is customary to separate the net generation rates Wn,
Wp into two contributions, namely, those deriving from the phonon collisions and
those of the other types (e.g., electron-electron collisions, electron-photon collisions,
and so on). The separate contributions are defined in (19.132); this section deals with
the net thermal recombination rates Un, Up.
</p>
<p>&copy; Springer Science+Business Media New York 2015 451
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_20</p>
<p/>
</div>
<div class="page"><p/>
<p>452 20 Generation-Recombination and Mobility
</p>
<p>Fig. 20.1 A graphic example
of direct thermal
recombination (a) and
generation (b). The edges of
the conduction and valence
bands are indicated with the
same symbols used in
Sect. 18.2. The same drawing
applies also to the description
of the direct optical
recombinations and
generations (Sect. 20.4)
</p>
<p>E
CU
</p>
<p>E
C
</p>
<p>E
V
</p>
<p>E
VL
</p>
<p>a b
</p>
<p>In the calculations carried out below, the non-equilibrium carrier concentrations
are derived by integrating over the bands&rsquo; energy. This is consistent with the general
definitions (19.31) and (19.109). In fact, considering the non-equilibrium electron
concentration n as defined in (19.31), one introduces the variable transformation
illustrated in Sect. B.5 and replaces the quantities appearing in it as follows:
</p>
<p>(u, v, w) &larr; (k1, k2, k3), Ï &larr; (r, t), Î· &larr; E, (20.1)
</p>
<p>S &larr; n, s &larr; f = QÎ¦, b &larr; g, sÌ &larr; P , (20.2)
</p>
<p>where Q, g(E) are the densities of states in the phase space r, k and, respectively, in
energy, while Î¦(r, k, t), P (r,E, t) are the non-equilibrium occupation probabilities
in the phase space and, respectively, in energy; the integration in energy is carried out
over the range corresponding to the conduction band&rsquo;s branch. The hole concentration
is treated in the same manner. In conclusion,
</p>
<p>n(r, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
QÎ¦ d3k =
</p>
<p>&int; ECU
</p>
<p>EC
</p>
<p>g P dE, (20.3)
</p>
<p>p(r, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Q (1 &minus;Î¦) d3k =
</p>
<p>&int; EV
</p>
<p>EVL
</p>
<p>g (1 &minus; P ) dE. (20.4)
</p>
<p>20.2.1 Direct Thermal Recombinations
</p>
<p>To begin, a graphic example of thermal transitions is shown in Fig. 20.1, where
the edges of the conduction and valence bands are indicated with the same symbols</p>
<p/>
</div>
<div class="page"><p/>
<p>20.2 Net Thermal Recombinations 453
</p>
<p>used in Sect. 18.2; the transition marked with a is a recombination event, in which
an electron belonging to an energy state of the conduction band transfers to an
empty state of the valence band. The energy difference between the initial and final
state is released to the lattice in the form of a phonon. The opposite transition,
where the electron&rsquo;s energy increases due to phonon absorption, is an electron-hole
generation and is marked with b in the figure. The transitions of type a and b are
called direct thermal recombination and direct thermal generation, respectively. Let
ra be the number of direct thermal recombinations per unit volume and time, and rb
the analogue for the generations; considering the conduction band as a reference, the
difference ra &minus; rb provides the contribution to the net thermal recombination rate Un
due to the direct thermal transitions. When the valence band is considered instead,
the rates of electron transitions reverse; however, for the valence band the transitions
of holes must be considered: as consequence, the contribution to Up is again ra &minus; rp.
In conclusion,
</p>
<p>UDT = UDT n = UDTp = ra &minus; rb, (20.5)
</p>
<p>where D stands for &ldquo;direct&rdquo; and T for &ldquo;thermal&rdquo;. The expressions of ra , rb are
determined by a reasoning similar to that used in Sect. 19.3.1 to express the collision
term of the BTE; here, however, the analysis is carried out directly in the energy
space instead of the k space.1 Let P (r,E, t) be the occupation probability of a state
at energy E; then, let C be the probability per unit time and volume (in r) of an
electron transition from a state of energy E to a state of energy E&prime; belonging to
a different band, induced by the interaction with a phonon.2 Such a probability
depends on the phonon energy hÌ Ï (Sect. 12.5), and also on the position in r if the
semiconductor is non uniform. Typically, the equilibrium distribution is assumed for
the phonons, which makes C independent of time; as the collisions are point-like
(Sect. 19.3.2), the spatial positions of the initial and final states coincide, whence
C = C(r, hÌ Ï,E &rarr; E&prime;).
</p>
<p>Indicating with g(E) the density of states of the band where the initial state
belongs, the productg dE P is the number of electrons within the elementary interval
dE around the initial state; such a product is multiplied by C to find the number of
unconditional E &rarr; E&prime; transitions. On the other hand, the transitions take place only
if the final states around E&prime; are empty; as the fraction of empty states in that interval
is g&prime; dE&prime; (1 &minus; P &prime;), the number of actual transitions from dE to dE&prime; turns out to be
g dE P C g&prime; dE&prime; (1 &minus; P &prime;). Now, to calculate the ra or rb rate it is necessary to add
up all transitions: for ra one lets E range over the conduction band and E&prime; over the
valence band; the converse is done to calculate rb. As the calculation of the latter is
</p>
<p>1 A more detailed example of calculations is given below, with reference to collisions with ionized
impurities.
2 The units of C are [C] = m&minus;3 s&minus;1. Remembering that the phonon energy equals the change in
energy of the electron due to the transition (Sect. 14.8.2), it is C = 0 for hÌ Ï &lt; EC &minus; EV = EG
(refer also to Fig. 20.1).</p>
<p/>
</div>
<div class="page"><p/>
<p>454 20 Generation-Recombination and Mobility
</p>
<p>somewhat easier, it is shown first:
</p>
<p>rb =
&int; EV
</p>
<p>EVL
</p>
<p>g dE P
&int; ECU
</p>
<p>EC
</p>
<p>C g&prime; dE&prime;
(
</p>
<p>1 &minus; P &prime;
)
</p>
<p>. (20.6)
</p>
<p>As in normal operating conditions the majority of the valence-band states are filled,
while the majority of the conduction-band states are empty, one lets P â 1 and
1 &minus; P &prime; â 1, whence, using symbol GDT for rb,
</p>
<p>GDT (r, hÌ Ï) =
&int; EV
</p>
<p>EVL
</p>
<p>g dE
&int; ECU
</p>
<p>EC
</p>
<p>C g&prime; dE&prime;. (20.7)
</p>
<p>Thus, the generation rate is independent of the carrier concentrations. To proceed,
one uses the relation g = ï¿½Î³ , with Î³ the combined density of states in energy and
volume, given by (15.65), and the definition (20.4) of the hole concentration. Thus,
the recombination rate is found to be
</p>
<p>ra =
&int; ECU
</p>
<p>EC
</p>
<p>g dE P
&int; EV
</p>
<p>EVL
</p>
<p>C g&prime; dE&prime; (1 &minus; P &prime;) = p
&int; ECU
</p>
<p>EC
</p>
<p>K g P dE, (20.8)
</p>
<p>where K(r, hÌ Ï,E), whose units are [K] = s&minus;1, is the average of ï¿½C over the
valence band, weighed by g&prime; (1 &minus; P &prime;):
</p>
<p>K =
&int; EV
EVL
</p>
<p>ï¿½C g&prime; (1 &minus; P &prime;) dE&prime;
&int; EV
EVL
</p>
<p>g&prime; (1 &minus; P &prime;) dE&prime;
. (20.9)
</p>
<p>Strictly speaking, K is a functional of P &prime;; however, the presence of P &prime; in both
numerator and denominator of (20.9) makes such a dependence smoother, so that
one can approximate K using the equilibrium distribution instead of P &prime;. By the same
token one uses the definition of the electron concentration (20.3) to find
</p>
<p>ra = Î±DT np, Î±DT (r, hÌÏ) =
&int; ECU
EC
</p>
<p>ï¿½K g P dE
&int; ECU
EC
</p>
<p>g P dE
, (20.10)
</p>
<p>where the integrals are approximated using the equilibrium probability. In conclu-
sion,
</p>
<p>UDT = Î±DT np &minus;GDT , (20.11)
</p>
<p>where Î±DT is the transition coefficient of the direct thermal transitions, with units
[Î±DT ] = m3 s&minus;1, and GDT their generation rate ([GDT ] = m&minus;3 s&minus;1). As in the
equilibrium case it is ra = rb, namely, GDT = Î±DT neq peq, it follows UDT =
Î±DT (np &minus; neqpeq).</p>
<p/>
</div>
<div class="page"><p/>
<p>20.2 Net Thermal Recombinations 455
</p>
<p>Fig. 20.2 Different types of
trap-assisted transitions
</p>
<p>E
Fi
</p>
<p>t
E
</p>
<p>E
</p>
<p>E
</p>
<p>E
CU
</p>
<p>E
C
</p>
<p>E
V
</p>
<p>E
VL
</p>
<p>a b
</p>
<p>c d
</p>
<p>20.2.2 Trap-Assisted Thermal Recombinations
</p>
<p>An important contribution to the thermal generation and recombination phenomena
is due to the so-called trap-assisted transitions. As mentioned in Sect. 19.3, among
the possible collisions undergone by electrons or holes are those with lattice defects.
The latter may originate from lattice irregularities (e.g., dislocations of the mate-
rial&rsquo;s atoms occurring during the fabrication process, Sect. 24.1), or from impurities
that were not eliminated during the semiconductor&rsquo;s purification process, or were
inadvertently added during a fabrication step. Some defects may introduce energy
states localized in the gap; such states, called traps, may capture an electron from
the conduction band and release it towards the valence band, or vice versa. The
phenomena are illustrated in Fig. 20.2, where four traps located in the energy gap
are shown in order to distinguish among the different transition events, that are: a)
capture of a conduction-band electron by a trap, b) release of a trapped electron to-
wards the conduction band, c) release of a trapped electron towards the valence band
(more suitably described as the capture of a valence-band hole by the trap), and d)
capture of a valence-band electron from the valence band (more suitably described
as the release of a hole towards the valence band). Each transition is accompanied
by the absorption or emission of a phonon. Thus, transitions of type a and b con-
tribute to the net thermal recombination Un of the conduction band, while those of
type c and d contribute to the net thermal recombination Up of the valence band.
Also, a sequence of two transitions, one of type a involving a given trap, followed
by one of type c involving the same trap, produces an electron-hole recombination
and is therefore called trap-assisted thermal recombination; similarly, a sequence
of two transitions, one of type d involving a given trap, followed by one of type b
involving the same trap, produces an electron-hole generation and is therefore called
trap-assisted thermal generation.
</p>
<p>To calculate the contribution of the trap-assisted transitions to Un and Up it is
necessary to distinguish between two kinds of traps: those of donor type, that are
electrically neutral when the electron is present in the trap and become positively
charged when the electron is released, and those of acceptor type, that are electrically
neutral when the electron is absent from the trap and become negatively charged when</p>
<p/>
</div>
<div class="page"><p/>
<p>456 20 Generation-Recombination and Mobility
</p>
<p>the electron is captured. In this respect, the traps are similar to the dopants&rsquo; atoms.
Instead, a strong difference is made by the position of the traps&rsquo;energy within the gap.
Consider, for instance, traps localized near the gap&rsquo;s midpoint (the latter is indicated
by the intrinsic Fermi level EFi in Fig. 20.2); the phonon energy necessary for the
transition is aboutEG/2 in all cases, to be compared with the valueEG necessary for a
direct transition. On the other hand, the equilibrium-phonon distribution (Sect. 16.6)
is the Bose&ndash;Einstein statistics (15.55); it follows that the number dNph of phonons
in the interval dÏ is
</p>
<p>dNph =
gph(Ï) dÏ
</p>
<p>exp [hÌ Ï/(kB T )] &minus; 1
, (20.12)
</p>
<p>with hÌ Ï the energy and gph the density of states of the phonons. Due to (20.12),
dNph/dÏ rapidly decreases as the phonon energy increases, this making the probabil-
ity of an electron-phonon interaction much larger at lower energies. For this reason,
even in an electronic-grade semiconductor, where the concentration of defects is
very small (Sect. 19.3.2), the traps are able to act as a sort of &ldquo;preferred path&rdquo; in
energy for the inter-band transitions, to the extent that the contribution to Un, Up
of the trap-assisted transitions is largely dominant over that of the direct transitions.
Therefore, in the continuity Eqs. (20.13) below, and in the subsequent derivation of
the trap-assisted, thermal-transition rates, symbols Un, Up refer only to the latter
transitions, not any more to the sum of the trap-assisted and direct ones.
</p>
<p>The net thermal-recombination terms Un, Up appear in (19.129) and (19.130)
after replacing Wn, Wp with (19.132); this yields
</p>
<p>&part;n
</p>
<p>&part;t
+ Un &minus;
</p>
<p>1
</p>
<p>q
divJn = Gn,
</p>
<p>&part;p
</p>
<p>&part;t
+ Up +
</p>
<p>1
</p>
<p>q
divJp = Gp. (20.13)
</p>
<p>To introduce the trap-assisted transitions one formally duplicates (20.13) as if the
acceptor and donor traps formed two additional bands; as the acceptor traps are either
neutral or negatively charged, the charge and current densities of the band associated
to them are thought of as due to electrons; instead, the charge and current densities
of the band associated to the donor traps are thought of as due to holes. In summary,
the two additional equations read
</p>
<p>&part;na
</p>
<p>&part;t
+ Una &minus;
</p>
<p>1
</p>
<p>q
divJna = Gna ,
</p>
<p>&part;pd
</p>
<p>&part;t
+ Upd +
</p>
<p>1
</p>
<p>q
divJpd = Gpd (20.14)
</p>
<p>with a and d standing for &ldquo;acceptor&rdquo; and &ldquo;donor&rdquo;, respectively. To ease the cal-
culation it is assumed that the non-thermal phenomena are absent, whence Gn =
Gp = Gna = Gpd = 0. Combining (20.13) with (20.14), and observing that
J = Jp + Jpd + Jn + Jna is the total current density of the semiconductor, yields
</p>
<p>&part;[q (p + pd &minus; n&minus; na)]
&part;t
</p>
<p>+ divJ = q (Un + Una) &minus; q (Up + Upd ). (20.15)
</p>
<p>As the net dopant concentration N is independent of time, it is &part;[q (p + pd &minus; n &minus;
na)]/&part;t = &part;[q (p + pd &minus; n &minus; na + N )]/&part;t = &part;Ï/&part;t ; thus, the left hand side of</p>
<p/>
</div>
<div class="page"><p/>
<p>20.2 Net Thermal Recombinations 457
</p>
<p>(20.15) vanishes due to (4.23), and3
</p>
<p>Un + Una = Up + Upd . (20.16)
</p>
<p>The two continuity Eqs. (20.14) are now simplified by observing that in crystalline
semiconductors the current densities Jpd , Jna of the traps are negligible. In fact, the
trap concentration is so low that inter-trap tunneling is precluded by the large distance
from a trap to another; the reasoning is the same as that used in Sect. 18.7.2 with
respect to the impurity levels.4 Letting Jpd = Jna = 0 makes the two Eqs. (20.14)
local:
</p>
<p>&part;na
</p>
<p>&part;t
= &minus;Una ,
</p>
<p>&part;pd
</p>
<p>&part;t
= &minus;Upd . (20.17)
</p>
<p>In steady-state conditions the traps&rsquo; populations are constant, this yielding Una =
Upd = 0 and, from (20.16), Un = Up. In equilibrium all continuity equations reduce
to the identity 0 = 0, whence the net-recombination terms vanish independently,
U
</p>
<p>eq
n = U eqna = U eqp = U eqpd = 0.
</p>
<p>20.2.3 Shockley-Read-Hall Theory
</p>
<p>The Shockley-Read-Hall theory describes the trap-assisted, net thermal-recombina-
tion term in a crystalline semiconductor based upon the steady-state relation Un =
Up. In fact, the outcome of the theory is used also in dynamic conditions; this
approximation is acceptable because, due to the smallness of the traps&rsquo;concentration,
the contribution of the charge density stored within the traps is negligible with respect
to that of the band and dopant states; the contribution of the time variation of the
traps&rsquo; charge density is similarly negligible. The theory also assumes that only one
trap level is present, of energy Et ; with reference to Fig. 20.2, the trap levels must
be thought of aligned with each other. If more than one trap level is present, the
contributions of the individual levels are added up at a later stage. In the theory it
is not important to distinguish between acceptor-type or donor-type traps; however,
one must account for the fact that a trap can accommodate one electron at most.
</p>
<p>Still with reference to Fig. 20.2, let ra be the number of type-a transitions per
unit volume and time, and similarly for rb, rc, rd . The derivation of these rates is
</p>
<p>3 The result expressed by (20.16) is intuitive if one thinks that adding up all continuity equations
amounts to counting all transitions twice, the first time in the forward direction (e.g., using the
electrons), the second time in the backward direction (using the holes). The reasoning is similar to
that leading to the vanishing of the intra-band contribution in (19.63).
4 In a polycrystalline semiconductor the traps&rsquo;current densities are not negligible; in fact, the whole
system of equations (20.13) and (20.14) must be used to correcly model the material [16, 17, 18].
The conduction phenomenon associated to these current densities is called gap conduction.</p>
<p/>
</div>
<div class="page"><p/>
<p>458 20 Generation-Recombination and Mobility
</p>
<p>similar to that of the direct transitions and is shown in the complements; here the
expressions of the net thermal-recombination terms are given, that read
</p>
<p>Un = ra &minus; rb = Î±n nNt (1 &minus; Pt ) &minus; en Nt Pt , (20.18)
</p>
<p>Up = rc &minus; rd = Î±p pNt Pt &minus; ep Nt (1 &minus; Pt ), (20.19)
</p>
<p>where Nt is the concentration of traps of energy Et , Pt the trap-occupation proba-
bility, Î±n, Î±p the electron- and hole-transition coefficients, respectively, and en, ep
the electron- and hole-emission coefficients, respectively.5 The ratios en/Î±n, ep/Î±p
are assumed to vary little from the equilibrium to the non-equilibrium case. From
U
</p>
<p>eq
n = U eqp = 0 one derives
</p>
<p>en
</p>
<p>Î±n
= neq
</p>
<p>(
1
</p>
<p>P
eq
t
</p>
<p>&minus; 1
)
</p>
<p>,
ep
</p>
<p>Î±p
= peq
</p>
<p>(
1
</p>
<p>P
eq
t
</p>
<p>&minus; 1
)&minus;1
</p>
<p>. (20.20)
</p>
<p>The occupation probability at equilibrium is the modified Fermi-Dirac statistics
(compare with (18.21) or (18.36))
</p>
<p>P
eq
t =
</p>
<p>[
1
</p>
<p>dt
exp
</p>
<p>(
Et &minus; EF
kB T
</p>
<p>)
</p>
<p>+ 1
]&minus;1
</p>
<p>,
1
</p>
<p>P
eq
t
</p>
<p>&minus; 1 = 1
dt
</p>
<p>exp
</p>
<p>(
Et &minus; EF
kB T
</p>
<p>)
</p>
<p>,
</p>
<p>(20.21)
</p>
<p>with dt the degeneracy coefficient of the trap. It follows, after introducing the short-
hand notation nB = en/Î±n, pB = ep/Î±p,
</p>
<p>nB =
neq
</p>
<p>dt
exp
</p>
<p>(
Et &minus; EF
kB T
</p>
<p>)
</p>
<p>, pB = peq dt exp
(
EF &minus; Et
kB T
</p>
<p>)
</p>
<p>. (20.22)
</p>
<p>Note that nB pB = neq peq. Replacing (20.22) into (20.18), (20.19), and letting
Un = Up yields
</p>
<p>Î±n n (1 &minus; Pt ) &minus; Î±n nB Pt = Î±p p Pt &minus; Î±p pB (1 &minus; Pt ), (20.23)
</p>
<p>whence
</p>
<p>Pt =
Î±n n+ Î±p pB
</p>
<p>Î±n (n+ nB) + Î±p (p + pB)
, 1 &minus; Pt =
</p>
<p>Î±n nB + Î±p p
Î±n (n+ nB) + Î±p (p + pB)
</p>
<p>.
</p>
<p>(20.24)
</p>
<p>In this way one expresses the trap-occupation probability as a function of two of
the unknowns of the semiconductor-device model, namely, n and p, and of a few
parameters. Among the latter, nB andpB are known (given the trap&rsquo;s energy) because
</p>
<p>5 It is [Î±n,p] = m3 s&minus;1, [en,p] = s&minus;1.</p>
<p/>
</div>
<div class="page"><p/>
<p>20.2 Net Thermal Recombinations 459
</p>
<p>they are calculated in the equilibrium condition. In conclusion, replacing (20.24) into
(20.18) or (20.19) yields, for the common value USRH = Un = Up,
</p>
<p>USRH =
np &minus; neq peq
</p>
<p>(n+ nB)/(Nt Î±p) + (p + pB)/(Nt Î±n)
, (20.25)
</p>
<p>where the indices stand for &ldquo;Shockley-Read-Hall&rdquo;. Eventually, the only unknown
parameters turn out to be the productsNt Î±p andNt Î±n which, as shown in Sect. 25.2,
can be obtained from measurements.
</p>
<p>The expression obtained so far, (20.25), has been derived considering a single
trap level Et . Before adding up over the levels it is convenient to consider how
sensitive USRH is to variations of Et ; in fact, one notes that the numerator of (20.25)
is independent of Et , whereas the denominator D has the form
</p>
<p>D = c + 2 Î» cosh Î·, Î· = Et &minus; EF
kB T
</p>
<p>+ 1
2
</p>
<p>logÎ¼, (20.26)
</p>
<p>where
</p>
<p>c = 1
Nt
</p>
<p>(
n
</p>
<p>Î±p
+ p
</p>
<p>Î±n
</p>
<p>)
</p>
<p>, Î» = 1
Nt
</p>
<p>&radic;
</p>
<p>neq
</p>
<p>Î±p
</p>
<p>peq
</p>
<p>Î±n
, Î¼ = 1
</p>
<p>d2t
</p>
<p>neq/Î±p
</p>
<p>peq/Î±n
. (20.27)
</p>
<p>The denominator has a minimum where Î· = 0; thus, USRH has a maximum there.
Moreover, the maximum is rather sharp due to the form of the hyperbolic cosine. It
follows that the trap level EtM that most efficiently induces the trap-assisted transi-
tions is found by letting Î· = 0. The other traps levels have a much smaller efficiency
and can be neglected; in conclusion, it is not necessary to add up over the trap levels.6
</p>
<p>In conclusion, one finds
</p>
<p>EtM = EF +
kB T
</p>
<p>2
log
</p>
<p>(
</p>
<p>d2t
peq/Î±n
</p>
<p>neq/Î±p
</p>
<p>)
</p>
<p>. (20.28)
</p>
<p>An estimate of EtM is easily obtained by considering the non-degenerate condition,
whence neq = NC exp [(EF &minus;EC)/(kB T )] and peq = NV exp [(EV &minus;EF )/(kB T )]
(compare with (18.28)). It follows
</p>
<p>EtM â
EC + EV
</p>
<p>2
+ kB T
</p>
<p>2
log
</p>
<p>(
</p>
<p>d2t
NV Î±p
</p>
<p>NC Î±n
</p>
<p>)
</p>
<p>. (20.29)
</p>
<p>Observing that the second term at the right hand side of (20.29) is small, this result
shows that the most efficient trap level is near the gap&rsquo;s midpoint which, in turn, is
near the intrinsic Fermi level EFi . In fact, combining (20.29) with (18.16) yields
</p>
<p>EtM â EFi +
kB T
</p>
<p>2
log
</p>
<p>(
</p>
<p>d2t
Î±p
</p>
<p>Î±n
</p>
<p>)
</p>
<p>â EFi . (20.30)
</p>
<p>6 This simplification is not applicable in a polycrystalline semiconductor.</p>
<p/>
</div>
<div class="page"><p/>
<p>460 20 Generation-Recombination and Mobility
</p>
<p>Defining the lifetimes
</p>
<p>Ïp0 =
1
</p>
<p>Nt Î±p
, Ïn0 =
</p>
<p>1
</p>
<p>Nt Î±n
, (20.31)
</p>
<p>gives (20.25) the standard form
</p>
<p>USRH =
np &minus; neq peq
</p>
<p>Ïp0 (n+ nB) + Ïn0 (p + pB)
, (20.32)
</p>
<p>which is also called Shockley-Read-Hall recombination function. In equilibrium it is
U
</p>
<p>eq
SRH = 0; in a non-equilibrium condition, a positive value ofUSRH, corresponding to
</p>
<p>an excess of the np product with respect to the equilibrium product neq peq, indicates
that recombinations prevail over generations, and vice versa. In a non-equilibrium
condition it may happen that USRH = 0; this occurs at the boundary between a region
where recombinations prevail and another region where generations prevail.
</p>
<p>In a non-degenerate semiconductor (20.22) become, letting Et = EtM = EFi
and using (18.12),
</p>
<p>nB =
ni
</p>
<p>dt
, pB = dt ni , (20.33)
</p>
<p>whence nB pB = n2i . This result is useful also in a degenerate semiconductor for
discussing possible simplifications in the form of USRH.
</p>
<p>20.2.3.1 Limiting Cases of the Shockley-Read-Hall Theory
</p>
<p>The operating conditions of semiconductor devices are often such that the SRH
recombination function (20.32) can be reduced to simpler forms. The first case is the
so-called full-depletion condition, where both electron and hole concentrations are
negligibly small with respect to nB and pB . Remembering that neq peq = nB pB one
finds
</p>
<p>USRH â &minus;
nB pB
</p>
<p>Ïp0 nB + Ïn0 pB
= &minus;
</p>
<p>&radic;
nB pB
</p>
<p>Ïg
, Ïg =
</p>
<p>&radic;
nB
</p>
<p>pB
Ïp0 +
</p>
<p>&radic;
nB
</p>
<p>pB
Ïn0.
</p>
<p>(20.34)
</p>
<p>In a non-degenerate condition nB , pB take the simplified form (20.33), whence&radic;
nBpB = ni and Ïg = Ïp0/dt + Ïn0 dt . In a full-depletion condition USRH is always
</p>
<p>negative, namely, generations prevail over recombinations; for this reason, Ïg is
called generation lifetime.
</p>
<p>The second limiting case of interest is the so-called weak-injection condition. This
condition occurs when both inequalities below are fulfilled:
</p>
<p>|n&minus; neq| âª ceq, |p &minus; peq| âª ceq, (20.35)</p>
<p/>
</div>
<div class="page"><p/>
<p>20.2 Net Thermal Recombinations 461
</p>
<p>where ceq is the equilibrium concentration of the majority carriers in the spatial
position under consideration. From the above definition it follows that the concept
of weak injection is applicable only after specifying which carriers are the majority
ones. Expanding the product np to first order in n and p around the equilibrium
value yields np â neq peq + neq (p &minus; peq) + peq (n &minus; neq). As a consequence, the
numerator of (20.32) becomes
</p>
<p>np &minus; neq peq â neq (p &minus; peq) + peq (n&minus; neq). (20.36)
To proceed, it is necessary to distinguish between the n-type and p-type regions.
</p>
<p>Weak-Injection Condition, n-Type Semiconductor
</p>
<p>The weak-injection condition (20.35) reads |n&minus; neq| âª neq, |p &minus; peq| âª neq. As a
consequence, one lets n â neq in the denominator of (20.32) and neglects nB with
respect to neq; in fact, in a non-degenerate condition it is nB â ni âª neq, and the
same inequality is also applicable in a degenerate condition. As the lifetimes are
similar to each other, the term Ïn0 (p + pB) in the denominator is negligible with
respect to Ïp0 neq, because p is a concentration of minority carriers and pB is similar
to nB . In conclusion, the denominator of (20.32) simplifies to Ïp0 neq, whence
</p>
<p>USRH â
p &minus; peq
Ïp0
</p>
<p>+ n&minus; n
eq
</p>
<p>(neq/peq) Ïp0
. (20.37)
</p>
<p>The second term at the right hand side of (20.37) is negligible7 because neq/peq â« 1;
letting Ïp = Ïp0 finally yields
</p>
<p>USRH â
p &minus; peq
</p>
<p>Ïp
, (20.38)
</p>
<p>with Ïp the minority-carrier lifetime in an n-doped region.
</p>
<p>Weak-Injection Condition, p-Type Semiconductor
</p>
<p>The weak-injection condition (20.35) reads |n&minus; neq| âª peq, |p&minus; peq| âª peq. As a
consequence, one lets p â peq in the denominator of (20.32) and neglects pB with
respect to peq; the other term in the denominator of (20.35) is neglected as above,
this simplifying the denominator to Ïn0 peq. In conclusion,
</p>
<p>USRH â
p &minus; peq
</p>
<p>(peq/neq) Ïn0
+ n&minus; n
</p>
<p>eq
</p>
<p>Ïn0
. (20.39)
</p>
<p>The first term at the right hand side of (20.39) is negligible because peq/neq â« 1;
letting Ïn = Ïn0 finally yields
</p>
<p>USRH â
n&minus; neq
</p>
<p>Ïn
, (20.40)
</p>
<p>with Ïn the minority-carrier lifetime in a p-doped region.
</p>
<p>7 Considering for instance the example given in Sect. 18.4.1, one has neq â 1015 cm&minus;3, peq â 105
cm&minus;3, whence neq/peq â 1010.</p>
<p/>
</div>
<div class="page"><p/>
<p>462 20 Generation-Recombination and Mobility
</p>
<p>The simplified expressions of USRH found here are particularly useful; in fact,
in contrast to (20.32), the weak-injection limits (20.38) and (20.40) are linear with
respect top orn. Moreover, as (20.38) and (20.40) depend on one unknown only, they
decouple the continuity equation of the minority carriers (the first one in (19.129)
or in (19.130)) from the other equations of the semiconductor&rsquo;s model; thanks to
this it is possible to separate the system of equations. The simplification introduced
by the full-depletion condition is even stronger, because (20.34) is independent of
the model&rsquo;s unknowns. On the other hand, all simplifications illustrated here are
applicable only in the regions where the approximations hold; once the simplified
model&rsquo;s equations have been solved locally, it is necessary to match the solutions at
the boundaries between adjacent regions.
</p>
<p>20.3 Auger Recombination and Impact Ionization
</p>
<p>An important, non-thermal recombination mechanism is Auger recombination. The
phenomenon is due to the electron-electron or hole-hole collision, and is illustrated
in Fig. 20.3. With reference to case a, two electrons whose initial state is in the
conduction band collide and exchange energy. The outcome of the collision is that
one of the electrons suffers an energy loss equal or larger than the energy gap and
makes a transition to an empty state of the valence band; the other electron absorbs
the same amount of energy and makes a transition to a higher-energy state of the
conduction band. The phenomenon is also indicated as an Auger recombination
initiated by electrons. The analogue for holes is shown in case c of Fig. 20.3: two holes
whose initial state is in the valence band collide and exchange energy. Remembering
that hole energy increases in the opposite direction with respect to that of electrons
(Sect. 19.2.3), the hole that suffers an energy loss equal or larger than the energy gap
makes a transition to a filled state of the conduction band; the other hole absorbs the
same amount of energy and makes a transition to a higher-energy state of the valence
band. The phenomenon is indicated as an Auger recombination initiated by holes.
</p>
<p>The phenomenon dual to Auger recombination is illustrated in Fig. 20.4 and is
called impact ionization. With reference to case b, an electron whose initial state is in
the conduction band at high energy collides and exchanges energy with an electron
whose initial state is in the valence band. The initial energy E of the electron in the
conduction band is such that E&minus;EC is equal or larger than the energy gap, whereas
the initial energy of the electron in the valence band is near EV . The outcome of
the collision is that, although the high-energy electron suffers an energy loss equal
or larger than the energy gap, its final state is still in the conduction band; the other
electron absorbs the same amount of energy and makes a transition to the conduction
band. The phenomenon is in fact an electron-hole pair generation and is also indicated
as an impact-ionization event initiated by electrons. The analogue for holes is shown
in case d of Fig. 20.4: a hole whose initial state is in the valence band at high energy
collides and exchanges energy with a hole whose initial state is in the conduction
band. The initial energy E of the hole in the valence band is such that |E &minus; EV |</p>
<p/>
</div>
<div class="page"><p/>
<p>20.3 Auger Recombination and Impact Ionization 463
</p>
<p>Fig. 20.3 Auger
recombinations initiated by
electrons (a) and holes (c)
</p>
<p>E
Fi
</p>
<p>E
CU
</p>
<p>E
C
</p>
<p>E
V
</p>
<p>E
VL
</p>
<p>a c
</p>
<p>Fig. 20.4 Impact-ionization
transitions initiated by
electrons (b) and holes (d) E CU
</p>
<p>E
C
</p>
<p>E
V
</p>
<p>E
VL
</p>
<p>E
Fi
</p>
<p>b d
</p>
<p>is equal or larger than the energy gap, whereas the initial energy of the hole in the
conduction band is near EC . The outcome of the collision is that, although the high-
energy hole suffers an energy loss equal or larger than the energy gap, its final state
is still in the valence band; the other hole absorbs the same amount of energy and
makes a transition to the valence band. The phenomenon is in fact an electron-hole
pair generation and is also indicated as an impact-ionization event initiated by holes.
</p>
<p>The derivation of the Auger and impact-ionization rates is shown in the com-
plements; here the expressions of the net recombinations due to the Auger and
impact-ionization events are given, that read
</p>
<p>UAIn = ra &minus; rb = cn n2 p &minus; In n, UAIp = rc &minus; rd = cp p2 n&minus; Ip p, (20.41)</p>
<p/>
</div>
<div class="page"><p/>
<p>464 20 Generation-Recombination and Mobility
</p>
<p>where UAIn refers to the electron-initiated transitions and U
AI
p to the hole-initiated
</p>
<p>ones. As usual, ra indicates the number of transitions of type a per unit time and
volume; the same holds for rb, rc, and rd . In (20.41), cn, In are the transition
coefficients for theAuger recombination and impact ionization initiated by electrons,
and cp, Ip the analogue for holes; cn, cp are also called Auger coefficients.8 In
equilibrium it is UAIn = UAIp = 0, whence In = cn neq peq, Ip = cp neq peq. The
above hold also in a non-equilibrium case as long as the operating conditions are not
too far from equilibrium; with these premises it follows
</p>
<p>UAIn = cn n (np &minus; neq peq) , UAIp = cp p (np &minus; neq peq) , (20.42)
</p>
<p>When the operating condition departs strongly from equilibrium, the simplification
leading to (20.42) is no longer applicable and the general expressions (20.41) must
be used. Referring to all recombinations as due to transitions of electrons, their rate is
easily found to be ra+rc; similarly, the total generation rate is rb+rd . In conclusion,
the net recombination rate due to the Auger and impact-ionization phenomena is
given by
</p>
<p>UAI = UAIn + UAIp . (20.43)
</p>
<p>ForAuger recombination to occur it is necessary that an electron collides with another
electron, or a hole collides with another hole. The probability of such an event is
relatively small because in normal operating conditions and at room temperature
there is a high probability that a carrier collides with a phonon; as a consequence, for
the collisionless motion of an electron to be interrupted by a collision with another
electron it is necessary that the electron concentration be very high. This situation
occurs only in a heavily-doped, n-type region; similarly, an Auger recombination
initiated by holes can be significant only in a heavily-doped, p-type region.9
</p>
<p>Considering now the case of impact-ionization, for this phenomenon to occur it is
necessary that an electron, or a hole, acquires a kinetic energy larger than the energy
gap. This is a rare event as well,10 because in general the carrier undergoes a phonon
collision when its kinetic energy is still significantly lower than the energy gap. The
impact-ionization event occurs only if the carrier acquires a substantial energy over
a distance much shorter than the average collisionless path, which happens only in
presence of a strong electric field.11
</p>
<p>The qualitative reasoning outlined above explains why the conditions for a
strongAuger recombination are incompatible with those that make impact-ionization
</p>
<p>8 The units are [cn,p] = cm6 s&minus;1 and [In,p] = s&minus;1.
9 In fact, Auger recombination becomes significant in the source and drain regions of MOSFETs
and in the emitter regions of BJTs, where the dopant concentration is the highest.
10 In principle, high-energy electrons or hole exist also in the equilibrium condition; however, their
number is negligible because of the exponentially-vanishing tail of the Fermi-Dirac statistics.
11 The high-field conditions able to produce a significant impact ionization typically occur in the
reverse-biased p-n juctions like, e.g., the drain junction in MOSFETs and the collector junction in
BJTs.</p>
<p/>
</div>
<div class="page"><p/>
<p>20.4 Optical Transitions 465
</p>
<p>dominant; in fact, a large charge density, like that imposed by a heavy dopant con-
centration, prevents the electric field from becoming strong. Vice versa, a strong
electric field prevents a large carrier concentration from building up. It is therefore
sensible to investigate situations where only one term dominates within UAI .
</p>
<p>20.3.1 Strong Impact Ionization
</p>
<p>As indicated in Sect. 20.3, far from equilibrium the approximations In = cn neq peq,
Ip = cp neq peq are not valid, and the general expressions (20.41) must be used.
Here the situation where impact ionization dominates over the other generation-
recombination mechanisms is considered, using the steady-state case. If impact
ionization is dominant, it is Un &minus; Gn = Up &minus; Gp â UAI â &minus;In n &minus; Ip p. The
continuity equations (the first ones in (19.129) and (19.130)) then become
</p>
<p>divJn = &minus;q In n&minus; q Ip p, divJp = q In n+ q Ip p. (20.44)
</p>
<p>As outlined in Sect. 20.3, impact-ionization dominates if the electric field is high.
For this reason, the transport equations in (19.129) and (19.130) are simplified by
keeping the ohmic term only, to yield Jn â q Î¼n nE and Jp â q Î¼p p E. As a
consequence, the electron and hole current densities are parallel to the electric field.
Let e(r) be the unit vector of the electric field, oriented in the direction of increasing
field, E = |E| e; it follows Jn = Jn e and Jp = Jp e, with Jn and Jp strictly positive.
Extracting n, p from the above and replacing them into (20.44) yields
</p>
<p>&minus;divJn = kn Jn + kp Jp, divJp = kn Jn + kp Jp, (20.45)
</p>
<p>where the ratios
</p>
<p>kn =
In
</p>
<p>Î¼n |E|
, kp =
</p>
<p>Ip
</p>
<p>Î¼p |E|
, (20.46)
</p>
<p>whose units are [kn,p] = m&minus;1, are the impact-ionization coefficients for electrons
and holes, respectively. Equations (20.45) form a system of differential equations of
the first order, whose solution in the one-dimensional case is relatively simple if the
dependence of the coefficients on position is given (Sect. 21.5).
</p>
<p>20.4 Optical Transitions
</p>
<p>The description of the optical transitions is similar to that of the direct thermal
transitions given in Sect. 20.2.1; still with reference to Fig. 20.1, the transition marked
with a can be thought of as an optical-recombination event if the energy difference
between the initial and final state is released to the environment in the form of a
photon. The opposite transition (b), where the electron&rsquo;s energy increases due to</p>
<p/>
</div>
<div class="page"><p/>
<p>466 20 Generation-Recombination and Mobility
</p>
<p>photon absorption from the environment, is an optical electron-hole generation. The
expression of the net optical-recombination rate is similar to (20.11) and reads
</p>
<p>UO = Î±O np &minus;GO , (20.47)
</p>
<p>whose coefficients are derived in the same manner as those of UDT (Sect. 20.2.1).
In normal operating conditions the similarity between the direct-thermal and op-
</p>
<p>tical generation-recombination events extends also to the external agent that induces
the transitions. In fact, the distribution of the phonon energies is typically the equilib-
rium one, given by the Bose&ndash;Einstein statistics (15.55) at the lattice temperature; as
for the photons, the environment radiation in which the semiconductor is immersed
can also be assimilated to the equilibrium one, again given by the Bose-Einstein statis-
tics at the same temperature. The conditions of the optical generation-recombination
events drastically change if the device is kept far from equilibrium. Consider for
instance the case where the electron concentration of the conduction band is artifi-
cially increased with respect to the equilibrium value at the expense of the electron
population of the valence band, so that both n and p in (20.47) increase. This brings
about an excess of recombinations; if the probability of radiative-type generation-
recombination events is high,12 the emission of a large number of photons follows.
The angular frequencies of the emitted photons are close to (EC&minus;EV )/hÌ, because the
majority of the electrons in the conduction band concentrate near EC , and the final
states of the radiative transitions concentrate near EV . In this way, the energy spent
to keep the artificially-high concentration of electron-hole pairs is transformed into
that of a nearly-monochromatic optical emission. In essence, this is the description of
the operating principle of a laser.13 Another method for keeping the device far from
equilibrium is that of artificially decreasing both the concentration of electrons of the
conduction band and the concentration of holes of the valence band. The outcome is
opposite with respect to that described earlier: the decrease of both n andp in (20.47)
brings about an excess of generations, which in turn corresponds to the absorption
of photons from the environment. The absorption may be exploited to accumulate
energy (this leading to the concept of solar cell), or to provide an electrical signal
whose amplitude depends on the number of absorbed photons (this leading to the
concept of optical sensor).
</p>
<p>In a non-equilibrium condition the amount of energy exchanged between the
semiconductor and the electromagnetic field is not necessarily uniform in space.
Consider, by way of example, the case of an optical sensor on which an external
radiation impinges; as the non-equilibrium conditions are such that the absorption
events prevail, the radiation intensity within the material progressively decreases at
increasing distances from the sensor&rsquo;s surface. Therefore, it is important to determine
the radiation intensity as a function of position.
</p>
<p>12 As indicated in Sect. 17.6.6, among semiconductors this is typical of the direct-gap ones.
13 In fact, LASER is the acronym of Light Amplification by Stimulated Emission of Radiation.</p>
<p/>
</div>
<div class="page"><p/>
<p>20.4 Optical Transitions 467
</p>
<p>Fig. 20.5 Sketch of photon
absorption in a material layer Î¾d Î¦ (Î¾+dÎ¾)(Î¾)Î¦
</p>
<p>dA
</p>
<p>It is acceptable to assume that the absorption events are uncorrelated from each
other. Thus, one can limit the analysis to a monochromatic radiation; the effect of
the whole spectrum is recovered at a later stage by adding up over the frequencies.
When absorption prevails, (20.47) simplifies to UO â &minus;GO , where GO is a function
of the radiation&rsquo;s frequency Î½ and possibly of position. If the radiation&rsquo;s intensity
varies with time, GO depends on time as well.14 When the radiation interacts with
the external surface of the material, part of the energy is reflected; moreover, the
radiation is refracted at the boundary, so that the propagation direction outside the
material differs in general from that inside. Letting Î¾ be the propagation direction
inside the material, consider an elementary volume with a side dÎ¾ aligned with Î¾
and a cross-section dA normal to it (Fig. 20.5). The monochromatic radiation can be
described as a flux of photons of equal energy h Î½, with h the Planck constant, and a
momentum&rsquo;s direction parallel to Î¾ . Let Î¦(Î¾ ) be the flux density of photons entering
the volume from the face corresponding to Î¾ , and Î¦(Î¾ +dÎ¾ ) the flux density leaving
it at Î¾ + dÎ¾ ; the following holds, Î¦ = K uf , where K(Î¾ ) is the concentration of the
photons and uf their constant phase velocity. Then,
</p>
<p>&part;Î¦
</p>
<p>&part;Î¾
= &part;K
</p>
<p>&part;(Î¾/uf )
= &part;K
</p>
<p>&part;t
. (20.48)
</p>
<p>The derivatives in (20.48) are negative because the photon concentration decreases
in time due to absorption; as the loss of each photon corresponds to the loss of an
energy quantum h Î½, the loss of electromagnetic energy per unit volume and time is
&minus;h Î½ (&part;Î¦/&part;Î¾ ). By a similar token one finds15 that the energy absorbed by the optical-
generation events per unit time and volume is h Î½ GO . The latter is not necessarily
equal to &minus;h Î½ (&part;Î¦/&part;Î¾ ); in fact, some photons crossing the elementary volume may
be lost due to collisions with nuclei (this, however, is a rare event), or with electrons
that are already in the conduction band, so that no electron-hole pair generation
</p>
<p>14 In principle, a time-dependence of the intensity is incompatible with the hypothesis that the
radiation is monochromatic. However, the frequency with which the intensity may vary is extremely
small with respect to the optical frequencies.
15 It is implied that h Î½ &ge; EC &minus; EV , and that the two-particle collisions only are to be considered.</p>
<p/>
</div>
<div class="page"><p/>
<p>468 20 Generation-Recombination and Mobility
</p>
<p>occurs. To account for these events one lets
</p>
<p>GO = &minus;Î·
&part;Î¦
</p>
<p>&part;Î¾
&gt; 0, (20.49)
</p>
<p>with 0 &lt; Î· &lt; 1 the quantum efficiency. In moderately-doped semiconductors Î· is
close to unity because the concentration of the conduction-band electrons is small;
instead, the efficiency degrades in degenerate semiconductors. The spatial depen-
dence of the generation term can be derived from (20.49) if that of the photon flux
is known. To proceed, one defines the absorption coefficient as
</p>
<p>k = &minus; 1
Î¦
</p>
<p>&part;Î¦
</p>
<p>&part;Î¾
&gt; 0, (20.50)
</p>
<p>with [k] = m&minus;1. In general it is k = k(Î¦, Î¾ , Î½); however, as the absorption effects are
uncorrelated, the flux density lost per unit path dÎ¾ is proportional to the flux density
available at Î¾ . Then, k is independent of Î¦; neglecting momentarily the dependence
on Î¾ as well, one finds
</p>
<p>Î¦(Î¾ ) = Î¦B exp [ &minus; k(Î½) Î¾ ], (20.51)
</p>
<p>with Î¦B = Î¦(Î¾ = 0+) on account of the fact that, due to the reflection at the
interface, the flux density on the inside edge of the boundary is different from that
on the outside edge. When k is independent of position, its inverse 1/k is called
average penetration length of the radiation. When k depends on position, (20.50) is
still separable and yields
</p>
<p>Î¦(Î¾ ) = Î¦B exp ( &minus; km Î¾ ), km =
1
</p>
<p>Î¾
</p>
<p>&int; Î¾
</p>
<p>0
k(Î¾ &prime;; Î½) dÎ¾ &prime;. (20.52)
</p>
<p>Combining (20.52) with (20.49), the optical-generation term is found to be
</p>
<p>GO = Î·Î¦B k(Î¾ , Î½) exp
[
</p>
<p>&minus;
&int; Î¾
</p>
<p>0
k(Î¾ &prime;, Î½) dÎ¾ &prime;
</p>
<p>]
</p>
<p>. (20.53)
</p>
<p>20.5 Macroscopic Mobility Models
</p>
<p>It has been shown in Sect. 19.5.2 that the carrier mobilities are defined in terms of the
momentum-relaxation times. Specifically, in the parabolic-band approximation it is,
for the electrons of the conduction band, Î¼n = (Î¼l + 2Î¼t )/3, with Î¼l = q Ïp/ml ,
Î¼t = q Ïp/mt , where Ïp is the electron momentum-relaxation time (19.87); similarly,
for the holes of the valence band the carrier mobility is given by inserting (19.118)
into the second relation of (19.121), namely, a linear combination of the heavy-hole
and light-hole momentum-relaxation times. As, in turn, the inverse momentum-
relaxation time is a suitable average of the inverse intra-band relaxation time, the</p>
<p/>
</div>
<div class="page"><p/>
<p>20.5 Macroscopic Mobility Models 469
</p>
<p>Matthiessen rule follows (Sect. 19.6.5); in conclusion, the electron and hole mobili-
ties are calculated by combining the effects of the different types of collisions (e.g.,
phonons, impurities, and so on) suffered by the carrier.16 In the case of electrons, the
application of the Matthiessen rule is straightforward, leading to
</p>
<p>1
</p>
<p>Î¼n
= mn
</p>
<p>q
</p>
<p>(
</p>
<p>1
</p>
<p>Ï
ph
p
</p>
<p>+ 1
Ï
</p>
<p>imp
p
</p>
<p>+ . . .
)
</p>
<p>, (20.54)
</p>
<p>where the index refers to the type of collision, and 1/mn = (1/ml + 2/mt )/3. For
holes a little more algebra is necessary, which can be avoided if the approximation
Ïph â Ïpl is applicable.
</p>
<p>In the typical operating conditions of semiconductor devices the most impor-
tant types of collisions are those with phonons and ionized impurities. For devices
like surface-channel MOSFETs, where the flow lines of the current density are
near the interface between semiconductor and gate insulator, a third type is also
very important, namely, the collisions with the interface. The macroscopic mo-
bility models are closed-form expressions in which mobility is related to a set of
macroscopic parameters (e.g., temperature) and to some of the unknowns of the
semiconductor-device model; the concept is similar to that leading to the expressions
of the generation-recombination terms shown in earlier sections.
</p>
<p>20.5.1 Example of Phonon Collision
</p>
<p>By way of example, a simplified analysis of the contribution to mobility of the
electron-phonon collision is outlined below, starting from the definition of the ith
component of the momentum-relaxation tensor Ïpi given by (19.87); the simplifica-
tions are such that the first-order expansion f &minus; f eq â (df/dÎ»)eq Î» is not used here.
Starting from the perturbative form (19.47) one considers the steady-state, uniform
case and lets B = 0, Ï = Ïv, to find
</p>
<p>q
</p>
<p>hÌ
E &middot; gradkf =
</p>
<p>f &minus; f eq
Ïv
</p>
<p>. (20.55)
</p>
<p>Replacing f with f eq at the left hand side of (20.55), and using the definition (17.52)
of the group velocity, yields gradkf
</p>
<p>eq = (df eq/dH ) hÌ u, with H the Hamiltonian
function defined in Sect. 19.2.2. Inserting into (19.87) yields
</p>
<p>Ïpi
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
ui E &middot; u (df eq/dH ) d3k =
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
ui E &middot; u (df eq/dH ) Ïv d3k. (20.56)
</p>
<p>As the derivative df eq/dH is even with respect to k, the integrals involving velocity
components different from ui vanish because the corresponding integrand is odd;
</p>
<p>16 As mentioned in Sect. 19.6.5, it is assumed that the different types of collisions are incorrelated.</p>
<p/>
</div>
<div class="page"><p/>
<p>470 20 Generation-Recombination and Mobility
</p>
<p>as a consequence, only the ith component of the electric field remains, and cancels
out. A further simplification is obtained by replacing the Fermi-Dirac statistics with
the Maxwell-Boltzmann distribution law, f eq â Q exp [( &minus; Ee + q Ï &minus; EC +
EF )/(kB T )], to find
</p>
<p>Ïpi
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u2i exp [&minus; Ee/(kB T )] d3k =
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u2i exp [&minus; Ee/(kB T )] Ïv d3k.
</p>
<p>(20.57)
</p>
<p>To proceed it is necessary to make an assumption about Ïv. Remembering the def-
inition of the relaxation time given by the first relation in (19.43), it is reasonable
to assume that the scattering probability S0 increases with the kinetic energy Ee of
the electron, so that the relaxation time decreases; a somewhat stronger hypothesis
is that the relaxation time depends on Ee only, namely, the collision is isotropic.17
</p>
<p>In this case, (20.57) is readily manipulated by a Herring-Vogt transformation.
Following the same procedure as in Sect. 19.6.4, one finds that all numerical factors
cancel out; as a consequence, one may replace the auxiliary coordinate Î·2i with
Î·2/3 = Ee/3, this showing that Ïpi = Ïp is isotropic as well. One eventually finds
</p>
<p>Ïp =
&int; +&infin;
</p>
<p>0 Ïv(Ee) E
3/2
e exp [&minus; Ee/(kB T )] dEe
</p>
<p>&int; +&infin;
0 E
</p>
<p>3/2
e exp [&minus; Ee/(kB T )] dEe
</p>
<p>. (20.58)
</p>
<p>A simple approximation for the relaxation time is Ïv = Ïv0 (Ee/E0)&minus;Î± , where Ïv0,
E0, and Î± are positive parameters independent of Ee. From (C.88) it follows
</p>
<p>Ïp = Ïv0
Î (5/2 &minus; Î±)
Î (5/2)
</p>
<p>(
E0
</p>
<p>kB T
</p>
<p>)Î±
</p>
<p>. (20.59)
</p>
<p>When the electron-phonon interaction is considered, Ïv0 = Ï phv0 is found to be in-
versely proportional to kB T and to the concentration Nsc of semiconductor&rsquo;s atoms;
moreover, for acoustic phonons18 it is Î± = 1/2 [62, Sects. 61, 62], whence
</p>
<p>Ï app = Ïv0(Nsc, T )
4
</p>
<p>3
&radic;
Ï
</p>
<p>(
E0
</p>
<p>kB T
</p>
<p>)1/2
</p>
<p>, Î¼apn &prop; N&minus;1sc (kB T )&minus;3/2, (20.60)
</p>
<p>where &ldquo;ap&rdquo; stands for &ldquo;acoustic phonon&rdquo;. More elaborate derivations, including also
the contribution of optical phonons, still show that carrier-phonon collisions make
mobility to decrease when temperature increases.
</p>
<p>17 The first-principle derivation of the scattering probabilities is carried out by applying Fermi&rsquo;s
Golden Rule (Sect. 14.8.3) to each type of perturbation, using the Bloch functions for the unperturbed
states [57]. An example is given later in the case of ionized-impurity scattering.
18 Acoustic phonons are those whose momentum and energy belong to the acoustic branch
of the lattice-dispersion relation (Sect. 17.8.5); a similar definition applies to optical phonons
(Sect. 17.8.6).</p>
<p/>
</div>
<div class="page"><p/>
<p>20.5 Macroscopic Mobility Models 471
</p>
<p>20.5.2 Example of Ionized-Impurity Collision
</p>
<p>As a second example one considers the collisions with ionized impurities. The inter-
action with a single ionized impurity is a perturbation of the Coulomb type; due to the
presence of the crystal, the more suitable approach is the screened Coulomb perturba-
tion, an example of which is shown in Sect. 14.7, leading to the perturbation-matrix
element (14.34):
</p>
<p>h
(0)
kg =
</p>
<p>A/(2Ï )3
</p>
<p>q2c + q2
, A = Îº Z e
</p>
<p>2
</p>
<p>Îµ0
. (20.61)
</p>
<p>In (20.61), e &gt; 0 is the elementary electric charge, Z a positive integer, Îµ0 the
vacuum permittivity, qc &gt; 0 the inverse screening length,19 q = |q| = |k &minus; g| and,
finally, Îº = 1 ( &minus; 1) in the repulsive (attractive) case. The wave vectors k and g
correspond to the initial and final state of the transition, respectively. In principle,
(20.61) should not be used as is because it holds in vacuo; in fact, the eigenfunctions
of the unperturbed Hamiltonian operator used to derive (20.61) are plane waves.
Inside a crystal, instead, one should define the perturbation matrix hkg(t) using the
Bloch functions wk = uk exp (i k &middot; r) in an integral of the form (14.24). However, it
can be shown that the contribution of the periodic part uk can suitably be averaged
and extracted from the integral, in the form of a dimensionless coefficient, whose
square modulusG is called overlap factor. For this reason, the collisions with ionized
impurities is treated starting from the definition (20.61) to calculate the perturbation
matrix, with the provision that the result is to be multiplied by G and the permittivity
Îµsc of the semiconductor replaces Îµ0 in the second relation of (20.61).
</p>
<p>Like in Sect. 14.6, a Gaussian wave packet (14.27) centered on some wave vector
b ï¿½= g is used as initial condition. In this case the perturbation is independent of
time, hbg = h(0)bg = const ï¿½= 0; as a consequence, the infinitesimal probability dPb
that such a perturbation induces a transition, from the initial condition (14.27), to a
final state whose energy belongs to the range dEg, is given by (14.32). In turn, the
integral (14.32) providing H (0)b (Eg) is calculated in Problem 14.1. Assuming that the
duration tP of the interaction is large enough to make Fermi&rsquo;s Golden Rule (14.44)
applicable, and inserting the overlap factor, one finally obtains
</p>
<p>dPb &asymp; G
(
</p>
<p>2Ï m
</p>
<p>hÌ2
</p>
<p>)3/2 8Ï tP Î´(Eb &minus; Eg)A2
Î»3 hÌ (2Ï )5 q2c (q2c + 8mEg/hÌ2)
</p>
<p>&radic;
</p>
<p>Eg dEg, (20.62)
</p>
<p>where the relation Eg = hÌ2 g2/(2m) has been used. Integrating over Eg and dividing
by tP provides the probability per unit time of a transition from the initial energy Eb
to any final energy; letting Ec = hÌ2 q2c /(2m), one finds
</p>
<p>PÌ (Eb) =
1
</p>
<p>Ïvc
</p>
<p>&radic;
4Eb/Ec
</p>
<p>1 + 4Eb/Ec
.
</p>
<p>1
</p>
<p>Ïvc
= GA
</p>
<p>2/
&radic;
</p>
<p>2Ï m
</p>
<p>8Ï2 (Î»2 Ec)3/2
. (20.63)
</p>
<p>19 An example of derivation of the screening length is given in Sect. 20.6.4.</p>
<p/>
</div>
<div class="page"><p/>
<p>472 20 Generation-Recombination and Mobility
</p>
<p>The above expression provides the contribution to the intra-band relaxation time of
the scattering due to a single impurity. One notes that, since A is squared, the effect
onto (20.63) of a positive impurity is the same as that of a negative one. If the effect
of each impurity is uncorrelated with that of the others,20 the probabilities add up;
letting NI = N+D +N&minus;A be the total concentration of ionized impurities, the product
NI d3r is the total number ionized impurities in the elementary volume d3r; it follows
that the probability per unit time and volume is given by PÌ (Eb)NI d3r . Considering
that NI depends on position only, mobility inherits the inverse proportionality with
NI ; letting &ldquo;ii&rdquo; indicate &ldquo;ionized impurity&rdquo;, one finds Î¼iin &prop; 1/NI .
</p>
<p>The derivation of the dependence on NI shown above is in fact oversimplified,
and the resulting model does not reproduce the experimental results with sufficient
precision. One of the reasons for this discrepancy is that the inverse screening length
qc depends on the dopant concentration as well. In order to improve the model, while
still keeping an analytical form, the model is modified by letting 1/Î¼iin &prop; NÎ±I , with
Î± a dimensionless parameter to be extracted from the comparison with experiments.
One then lets
</p>
<p>1
</p>
<p>Î¼iin(NI )
= 1
</p>
<p>Î¼iin(NR)
</p>
<p>(
NI
</p>
<p>NR
</p>
<p>)Î±
</p>
<p>, (20.64)
</p>
<p>with NR a reference concentration.
</p>
<p>20.5.3 Bulk and Surface Mobilities
</p>
<p>Combining the phonon and ionized-impurity contributions using the Matthiessen
rule yields 1/Î¼Bn (T ,NI ) = 1/Î¼
</p>
<p>ph
n (T ) + 1/Î¼iin(NI ), namely,
</p>
<p>Î¼Bn (T ,NI ) =
Î¼
</p>
<p>ph
n (T )
</p>
<p>1 + c(T ) (NI/NR)Î±
, (20.65)
</p>
<p>with c(T ) = Î¼phn (T )/Î¼iin(NR). In practical cases the doping concentration ranges
over many orders of magnitude; for this reason, (20.65) is usually represented in a
semilogarithmic scale: letting r = log10 (NI/NR), b = Î± loge 10, and b0 = loge c,
(20.65) becomes
</p>
<p>Î¼Bn (T ,NI ) =
Î¼
</p>
<p>ap
n (T )
</p>
<p>1 + exp (br + b0)
. (20.66)
</p>
<p>The curves corresponding to b = 1, 1.5, 3 and b0 = 0 are drawn in Fig. 20.6, using
r as independent variable at a fixed T . Index &ldquo;B&rdquo; in the mobility defined in (20.65)
</p>
<p>20 In silicon, this assumption is fulfilled for values of the concentration up to about 1019 cm&minus;3 [64,
84].</p>
<p/>
</div>
<div class="page"><p/>
<p>20.5 Macroscopic Mobility Models 473
</p>
<p>Fig. 20.6 Graph of the
theoretical mobility curve
(20.66), normalized to its
maximum, for different
values of b, with b0 = 0.
Each curve has a flex at
r = rflex = &minus;b0/b and takes
the value 0.5 there. The slope
at the flex is &minus;b/4
</p>
<p>-6 -4 -2 0 2 4 6
r = log
</p>
<p>10
 (N
</p>
<p>I
 / N
</p>
<p>R
 )
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>Î¼
n
</p>
<p>B
 (
</p>
<p> T
,
</p>
<p>N
I 
) 
</p>
<p> /
Î¼
</p>
<p>n
</p>
<p>p
h
 (
</p>
<p> T
 )
</p>
<p>b = 1.00
b = 1.50
b = 3.00
</p>
<p>or (20.66) stands for &ldquo;bulk&rdquo;. More generally, the term bulk mobility is ascribed to
the combination of all contributions to mobility different from surface collisions.
</p>
<p>As mentioned at the beginning of this section, in surface-channel devices the
degradation of mobility produced by the interaction of the carriers with the interface
between channel and gate insulator is also very important. The macroscopic models
of this effect are built up by considering that the carrier-surface interaction is more
likely to occur if the flow lines of the current density are closer to the interface itself;
such a closeness is in turn controlled by the intensity of the electric field&rsquo;s component
normal to the interface, E&perp;. In conclusion, the model describes the contribution to
mobility due to surface scattering as a decreasing function of E&perp;, e.g., for electrons,
</p>
<p>1
</p>
<p>Î¼sn(E&perp;)
= 1
</p>
<p>Î¼sn(ER)
</p>
<p>(
E&perp;
ER
</p>
<p>)Î²
</p>
<p>, (20.67)
</p>
<p>with ER a reference field and Î² a dimensionless parameter to be extracted from
experiments. Combining the bulk and surface contributions using the Matthiessen
rule yields 1/Î¼n(T ,NI ,E&perp;) = 1/Î¼Bn (T ,NI ) + 1/Î¼sn(E&perp;), namely,
</p>
<p>Î¼n(T ,NI ,E&perp;) =
Î¼Bn (T ,NI )
</p>
<p>1 + d(T ,NI ) (E&perp;/ER)Î²
, (20.68)
</p>
<p>with d(T ,NI ) = Î¼Bn (T ,NI )/Î¼sn(ER).
</p>
<p>20.5.4 Beyond Analytical Modeling of Mobility
</p>
<p>In general the analytical approaches outlined above do not attain the precision nec-
essary for applications to realistic devices. For this reason, one must often resort
to numerical-simulation methods; in this way, the main scattering mechanisms are</p>
<p/>
</div>
<div class="page"><p/>
<p>474 20 Generation-Recombination and Mobility
</p>
<p>Fig. 20.7 Electron mobility
in silicon calculated with the
spherical-harmonics
expansion method (HARM)
as a function of the total
ionized-dopant concentration
NI , using the lattice
temperature T as parameter.
The calculations are
compared with measurements
by Lombardi [73], Klaassen
[64], and Arora [1] (courtesy
of S. Reggiani)
</p>
<p>10
12
</p>
<p>10
16
</p>
<p>10
20
</p>
<p>10
24
</p>
<p>10
28
</p>
<p>N
I
   (cm
</p>
<p>-3
)
</p>
<p>0
</p>
<p>500
</p>
<p>1000
</p>
<p>1500
</p>
<p>2000
</p>
<p>2500
</p>
<p>3000
</p>
<p>Î¼
n
</p>
<p>(c
m
</p>
<p>2
/ 
</p>
<p>V
 s
</p>
<p>ec
)
</p>
<p>HARM
</p>
<p>Lombardi
</p>
<p>Klaassen
</p>
<p>Arora
</p>
<p>T  = 250 K
</p>
<p>T  = 300 K
</p>
<p>T  = 400 K
</p>
<p>T  = 500 K
</p>
<p>incorporated into the analysis (e.g., for silicon: acoustic phonons, optical phonons,
ionized impurities, and impact ionization), along with the full-band structure of the
semiconductor, which is included in the simulation through the density of states and
group velocity defined in the energy space. The latter, in turn, are obtained directly
from the corresponding functions in the momentum space by integrating the full-
band system over the angles. The energy range considered to date allows for the
description of carrier dynamics up to 5 eV.
</p>
<p>As mentioned above, the ionized-impurity collisions can be treated as interaction
between the carrier and a single impurity as long as the impurity concentration is
below some limit. When the limit is exceeded, impurity clustering becomes relevant
and must be accounted for [64]. In fact, at high doping densities the carrier scatters
with a cluster ofK ions, whereK is a function of the impurity concentration. Finally,
different outcomes are found for majority- or minority-mobility calculations: e.g.,
minority-hole mobility is found to be about a factor 2 higher than the majority-hole
mobility for identical doping levels.
</p>
<p>Figures 20.7 and 20.8 show the outcome of electron- and hole-mobility calcu-
lations for bulk silicon, obtained from the spherical-harmonics method illustrated
in [112]. The method incorporates the models for the scattering mechanisms listed
above. The electron and hole mobility have been calculated as a function of the total
ionized-dopant concentration NI , using the lattice temperature T as a parameter; in
the figures, they are compared with measurements taken from the literature.
</p>
<p>To include the surface effects in the analysis it is necessary to account for the
fact that in modern devices the thickness of the charge layer at the interface with
the gate insulator is so small that quantum confinement and formation of subbands
must be considered. The typical collisions mechanisms to be accounted for at the
semiconductor-insulator interface are surface roughness, scattering with ionized im-
purities trapped at the interface, and surface phonons. Figures 20.9 and 20.10 show
the outcome of electron and hole surface-mobility calculations in silicon, also ob-
tained from the spherical-harmonics method [84]. The electron and hole mobility</p>
<p/>
</div>
<div class="page"><p/>
<p>20.6 Complements 475
</p>
<p>Fig. 20.8 Hole mobility in
silicon calculated with the
spherical-harmonics
expansion method (HARM)
as a function of the total
ionized-dopant concentration
NI , using the lattice
temperature T as parameter.
The calculations are
compared with measurements
by Lombardi [73], Klaassen
[64], and Arora [1] (courtesy
of S. Reggiani)
</p>
<p>10
12
</p>
<p>10
16
</p>
<p>10
20
</p>
<p>10
24
</p>
<p>10
28
</p>
<p>N
I
   (cm
</p>
<p>-3
)
</p>
<p>0
</p>
<p>500
</p>
<p>1000
</p>
<p>1500
</p>
<p>Î¼
p
  
(c
</p>
<p>m
2
 /
</p>
<p> V
 s
</p>
<p>ec
)
</p>
<p>HARM
</p>
<p>Lombardi 
</p>
<p>Klaassen
</p>
<p>Arora
</p>
<p>T  = 200 K
</p>
<p>T  = 250 K
</p>
<p>T  = 300 K
</p>
<p>T  = 400 K
</p>
<p>Fig. 20.9 Electron surface
mobility in silicon calculated
with the spherical-harmonics
expansion method (HARM)
method at room temperature,
using the acceptor
concentration NA as
parameter. The calculations
are compared with
measurements by Takagi
[106] (courtesy of S.
Reggiani)
</p>
<p>10
-2
</p>
<p>10
-1
</p>
<p>10
0
</p>
<p>Effective electric field (MV cm
-1
</p>
<p>)
</p>
<p>10
</p>
<p>100
</p>
<p>1000
</p>
<p>E
ff
</p>
<p>ec
ti
</p>
<p>v
e 
</p>
<p>el
ec
</p>
<p>tr
o
n
 m
</p>
<p>o
b
il
</p>
<p>it
y
 (
</p>
<p>cm
2  
</p>
<p>V
-1
</p>
<p>se
c
</p>
<p>-1
)
</p>
<p>N
A
</p>
<p> = 3.9 10
15
</p>
<p> cm
-3
</p>
<p>N
A
</p>
<p> = 2.0 10
16
</p>
<p> cm
-3
</p>
<p>N
A
</p>
<p> = 7.2 10
16
</p>
<p>cm
-3
</p>
<p>N
A
</p>
<p> = 3.0 10
17
</p>
<p>cm
-3
</p>
<p>N
A
</p>
<p> = 7.7 10
17
</p>
<p> cm
-3
</p>
<p>N
A
</p>
<p> = 2.4 10
18
</p>
<p>cm
-3
</p>
<p>HARM
</p>
<p>have been calculated as functions of the dopant concentration (NA and ND , respec-
tively), at room temperature; in the figures, they are compared with measurements
taken from the literature.
</p>
<p>20.6 Complements
</p>
<p>20.6.1 Transition Rates in the SRH Recombination Function
</p>
<p>The expressions of the transition rates ra , rb, rc, rd to be used in the calculation of
the Shockley-Read-Hall recombination function (20.32) are determined by the same
reasoning as that used in Sect. 20.2.1 for the direct thermal transitions. Let P (r,E, t)</p>
<p/>
</div>
<div class="page"><p/>
<p>476 20 Generation-Recombination and Mobility
</p>
<p>Fig. 20.10 Hole surface
mobility in silicon calculated
with the spherical-harmonics
expansion method (HARM)
at room temperature, using
the donor concentration ND
as parameter. The calculations
are compared with
measurements by Takagi
[106] (courtesy of S.
Reggiani)
</p>
<p>0.10 1.00
</p>
<p>Effective Electric Field (MV cm
-1
</p>
<p>)
</p>
<p>100
</p>
<p>1000
</p>
<p>E
ff
</p>
<p>ec
ti
</p>
<p>v
e 
</p>
<p>h
o
</p>
<p>le
 m
</p>
<p>o
b
</p>
<p>il
it
</p>
<p>y
 (
</p>
<p>cm
2
 V
</p>
<p>-1
 s
</p>
<p>ec
-1
</p>
<p>)
</p>
<p>N
D
</p>
<p>= 7.8 10
15
</p>
<p> cm
-3
</p>
<p>N
D
</p>
<p> = 1.6 10
16
</p>
<p> cm
-3
</p>
<p>N
D
</p>
<p> = 5.1 10
16
</p>
<p> cm
-3
</p>
<p>N
D
</p>
<p> = 2.7 10
17
</p>
<p> cm
-3
</p>
<p>N
D
</p>
<p> = 6.6 10
17
</p>
<p> cm
-3
</p>
<p>HARM
</p>
<p>be the occupation probability of a state at energy E, and C(E &rarr; E&prime;) the probability
per unit time and volume (in r) of a transition from a filled state of energy E to an
empty state of energyE&prime;. Such a probability is independent of time; it depends on the
energy of the phonon involved in the transition, and possibly on position. Then, define
P &prime; = P (r,E = E&prime;, t), Pt = P (r,E = Et , t), where Et is the energy of the trap.
Finally, let Î³ (E) be the combined density of states in energy and volume of the bands,
and Î³t (r,E) the same quantity for the traps (the latter depends on position if the traps&rsquo;
distribution is non uniform). The number of transitions per unit volume and time, from
states in the interval dE belonging to a band, to states in the interval dE&prime; belonging
to the trap distribution, is obtained as the product of the number ï¿½Î³ (E) dE P of
filled states in the interval dE, times the transition probability per unit volume and
time C, times the number ï¿½Î³t (r,E&prime;) dE&prime; (1 &minus; P &prime;) of empty states in the interval
dE&prime;. Thus, letting ï¿½Et be an energy interval belonging to the gap and containing the
traps, the transition rate from the conduction band to the traps is given by
</p>
<p>ra =
&int; ECU
</p>
<p>EC
</p>
<p>&int;
</p>
<p>ï¿½Et
</p>
<p>ï¿½Î³ (E) dE P C(E &rarr; E&prime;)ï¿½Î³t (r,E&prime;) dE&prime; (1 &minus; P &prime;). (20.69)
</p>
<p>By the same token, the transition rate from the valence band to the traps is
</p>
<p>rd =
&int; EV
</p>
<p>EVL
</p>
<p>&int;
</p>
<p>ï¿½Et
</p>
<p>ï¿½Î³ (E) dE P C(E &rarr; E&prime;)ï¿½Î³t (r,E&prime;) dE&prime; (1 &minus; P &prime;). (20.70)
</p>
<p>In turn, the number of transitions per unit volume and time, from states in the interval
dE&prime; belonging the trap distribution, to states in the interval dE belonging to a band,
is obtained as the product of the number ï¿½Î³t (r,E&prime;) dE&prime; P &prime; of filled states in the
interval dE&prime;, times C(r,E&prime; &rarr; E), times the number ï¿½Î³ (E) dE (1 &minus; P ) of empty
states in the interval dE. Thus, the transition rates from the traps to conduction or
valence band are respectively given by
</p>
<p>rb =
&int; ECU
</p>
<p>EC
</p>
<p>&int;
</p>
<p>ï¿½Et
</p>
<p>ï¿½Î³t (r,E
&prime;) dE&prime; P &prime; C(r,E&prime; &rarr; E)ï¿½Î³ (E) dE (1 &minus; P ), (20.71)</p>
<p/>
</div>
<div class="page"><p/>
<p>20.6 Complements 477
</p>
<p>rc =
&int; EV
</p>
<p>EVL
</p>
<p>&int;
</p>
<p>ï¿½Et
</p>
<p>ï¿½Î³t (r,E
&prime;) dE&prime; P &prime; C(r,E&prime; &rarr; E)ï¿½Î³ (E) dE (1 &minus; P ). (20.72)
</p>
<p>The combined density of states of the traps is treated in the same manner as that of
the dopant atoms (compare with (18.20) and (18.35)) by letting
</p>
<p>Î³t (r,E
&prime;) = Nt (r) Î´(E&prime; &minus; Et ), (20.73)
</p>
<p>where Nt (r) is the trap concentration. Thanks to this, the integrals over ï¿½Et are
easily evaluated, to yield
</p>
<p>ra = Nt (1 &minus; Pt )ï¿½2
&int; ECU
</p>
<p>EC
</p>
<p>Î³ P C(r,E &rarr; Et ) dE = Nt (1 &minus; Pt )Î±n n, (20.74)
</p>
<p>rc = Nt Pt ï¿½2
&int; EV
</p>
<p>EVL
</p>
<p>Î³ (1 &minus; P )C(r,Et &rarr; E) dE = Nt Pt Î±p p, (20.75)
</p>
<p>where the definitions (20.3), (20.4) of the electron and hole concentrations are used,
and the transition coefficients for electrons and holes are defined as the weighed
averages
</p>
<p>Î±n = ï¿½2
&int; ECU
EC
</p>
<p>Î³ P C dE
&int; ECU
EC
</p>
<p>Î³ P dE
, Î±p = ï¿½2
</p>
<p>&int; EV
EVL
</p>
<p>Î³ (1 &minus; P )C dE
&int; EV
EVL
</p>
<p>Î³ (1 &minus; P ) dE
. (20.76)
</p>
<p>Like in the case of (20.10), the integrals in (20.76) are approximated using the
equilibrium probability. The remaining transition rates rb, rd are determined in a
similar manner, using also the approximation 1 &minus; P â 1 in (20.71) and P â 1
in (20.70). Like in Sect. 20.2.1, the approximation is justified by the fact that in
normal operating conditions the majority of the valence-band states are filled, while
the majority of the conduction-band states are empty. In conclusion,
</p>
<p>rb = Nt Pt ï¿½2
&int; ECU
</p>
<p>EC
</p>
<p>Î³ (1 &minus; P )C(r,Et &rarr; E) dE â Nt Pt en, (20.77)
</p>
<p>rd = Nt (1 &minus; Pt )ï¿½2
&int; EV
</p>
<p>EVL
</p>
<p>Î³ P C(r,E &rarr; Et ) dE â Nt (1 &minus; Pt ) ep, (20.78)
</p>
<p>with the emission coefficients defined by
</p>
<p>en = ï¿½2
&int; ECU
</p>
<p>EC
</p>
<p>Î³ C dE, ep = ï¿½2
&int; EV
</p>
<p>EVL
</p>
<p>Î³ C dE. (20.79)</p>
<p/>
</div>
<div class="page"><p/>
<p>478 20 Generation-Recombination and Mobility
</p>
<p>20.6.2 Coefficients of the Auger and Impact-Ionization Events
</p>
<p>The expression of the coefficients cn, cp and In, Ip, to be used in the calculation of the
net recombination rates (20.41) due to the Auger and impact-ionization phenomena,
are found in the same way as the transition rates of the SRH recombination function
(Sect. 20.6.1) or the direct thermal recombinations (Sect. 20.2.1). Let P (r,E, t) be
the occupation probability of a state of energy E, and Cn(E1,E2 &rarr; E&prime;1,E&prime;2) the
combined probability per unit time and volume (in r) of an electron transition from
a filled state of energy E1 in the conduction band to an empty state of energy E&prime;1 in
the conduction band, and of another electron from a filled state of energy E2 to an
empty state of energy E&prime;2, where E2 and E
</p>
<p>&prime;
2 belong to different bands.
</p>
<p>Auger Coefficients
</p>
<p>In an Auger recombination it is E&prime;1 &gt; E1; also, E2 belongs to the conduction band
while E&prime;2 belongs to the valence band. Due to energy conservation it is
</p>
<p>21
</p>
<p>Cn = Cn0 Î´
[
</p>
<p>(E1 &minus; E&prime;1) + (E2 &minus; E&prime;2)
]
</p>
<p>, (20.80)
</p>
<p>where E2 &minus;E&prime;2 â EG; it follows E&prime;1 â E1+EG. Then, define Pi = P (r,E = Ei , t),
P &prime;i = P (r,E = E&prime;i , t), with i = 1, 2, and let Î³ (E) be the combined density of states
in energy and volume for the bands; in particular, letgi = ï¿½Î³ (Ei) and g&prime;i = ï¿½Î³ (E&prime;i).
From the above definitions one finds, for the rate ra of the Auger recombinations
initiated by electrons,
</p>
<p>ra =
&int;
</p>
<p>g1 dE1 P1 g2 dE2 P2 Cn g
&prime;
1 dE
</p>
<p>&prime;
1 (1 &minus; P &prime;1) g&prime;2 dE&prime;2 (1 &minus; P &prime;2), (20.81)
</p>
<p>where
&int;
</p>
<p>indicates a fourfold integral that extends thrice over the conduction band
and once over the valence band. Observing that P &prime;1 âª 1 and integrating over E&prime;1 with
Cn = Cn0 Î´(E1 + EG &minus; E&prime;1) yields
</p>
<p>ra =
&int; ECU
</p>
<p>EC
</p>
<p>g1 dE1 P1 Cn0 gG
</p>
<p>&int; ECU
</p>
<p>EC
</p>
<p>g2 dE2 P2
</p>
<p>&int; EV
</p>
<p>EVL
</p>
<p>g&prime;2 dE
&prime;
2 (1 &minus; P &prime;2), (20.82)
</p>
<p>where gG = g(E1 +EG) and [Cn0 gG] = s&minus;1 m&minus;3. Thanks to (20.3) and (20.4), the
second integral in (20.82) equals ï¿½n and the third one equals ï¿½p. Letting
</p>
<p>cn = ï¿½3
&int; ECU
EC
</p>
<p>Cn0 gG g1 P1 dE1
&int; ECU
EC
</p>
<p>g1 P1 dE1
, (20.83)
</p>
<p>finally yields ra = cn n2 p. The derivation of rc = cp p2 n is similar.
</p>
<p>21 The units of Cn0 are [Cn0 = J s&minus;1 m&minus;3].</p>
<p/>
</div>
<div class="page"><p/>
<p>20.6 Complements 479
</p>
<p>Impact Ionization&rsquo;s Transition Coefficients
</p>
<p>Using the same symbols introduced at the beginning of Sect. 20.6.2, for an impact-
ionization event initiated by an electron it is E1 &gt; E&prime;1; in turn, E2 belongs to the
valence band and E&prime;2 belongs to the conduction band. It follows
</p>
<p>rb =
&int;
</p>
<p>g1 dE1 P1 g2 dE2 P2 Cn g
&prime;
1 dE
</p>
<p>&prime;
1 (1 &minus; P &prime;1) g&prime;2 dE&prime;2 (1 &minus; P &prime;2), (20.84)
</p>
<p>where the fourfold integral extends thrice over the conduction band and once over
the valence band. From the energy-conservation relation E1 + E2 = E&prime;1 + E&prime;2 and
from E&prime;2 &minus; E2 â EG it follows E&prime;1 â E1 &minus; EG. Observing that P2 â 1, P &prime;1 âª 1,
P &prime;2 âª 1, and integrating over E&prime;1 with Cn = Cn0 Î´(E1 &minus; EG &minus; E&prime;1) yields
</p>
<p>rb =
&int; ECU
</p>
<p>EC
</p>
<p>Cn0 gG g1 P1 dE1
</p>
<p>&int; EV
</p>
<p>EVL
</p>
<p>g2 dE2
</p>
<p>&int; ECU
</p>
<p>EC
</p>
<p>g&prime;2 dE
&prime;
2, (20.85)
</p>
<p>where gG = g(E1 &minus; EG), and the product of the second and third integral is a di-
mensionless quantity that depends only on the semiconductor&rsquo;s structure. Indicating
such a quantity with Î½n, and letting
</p>
<p>In = Î½n
&int; ECU
EC
</p>
<p>Cn0 gG g1 P1 dE1
&int; ECU
EC
</p>
<p>g1 P1 dE1
, (20.86)
</p>
<p>finally yields rb = In n. The derivation of rd = Ip p is similar.
</p>
<p>20.6.3 Total Recombination-Generation Rate
</p>
<p>The expressions for the most important generation-recombination terms have been
worked out in this chapter. Only one of them, the SRH recombination function
USRH, involves energy states different from those of the conduction and valence
bands; in principle, such states would require additional continuity equations to be
added to the semiconductor-device model. However, as discussed in Sect. 20.2.3,
this is not necessary in crystalline semiconductors. The other mechanisms (direct
thermal recombination-generation UDT , Auger recombination and impact ionization
UAI , and optical recombination-generation UO) do not involve intermediate states.
As a consequence, with reference to (20.13) the generation-recombination terms
of the electron-continuity equation are equal to those of the hole continuity equa-
tion. Finally, assuming that the different generation-recombination phenomena are
uncorrelated, and neglecting UDT with respect to USRH (Sect. 20.2.2), yields
</p>
<p>Un &minus;Gn = Up &minus;Gp â USRH + UAI + UDO . (20.87)</p>
<p/>
</div>
<div class="page"><p/>
<p>480 20 Generation-Recombination and Mobility
</p>
<p>20.6.4 Screened Coulomb Potential
</p>
<p>In the context of physics, the general meaning of screening is the attenuation in the
electric field intensity due to the presence of mobile charges; the effect is treated
here using the Debye-H&uuml;ckel theory [29], which is applicable to a non-degenerate
semiconductor where the dopants are completely ionized. For a medium of permit-
tivity Îµ, with charge density Ï, the electric potential in the equilibrium condition is
found by solving Poisson&rsquo;s equation
</p>
<p>&minus;Îµ&nabla;2Ï = Ï. (20.88)
</p>
<p>One starts by considering a locally-neutral material, to which a perturbation is added
due, for instance, to the introduction of a fixed charge Zc ec placed in the origin; this,
in turn, induces a variation in Ï. The corresponding perturbation of Ï is calculated
to first order by replacing Ï with Ï + Î´Ï and Ï with Ï + (&part;Ï/&part;Ï) Î´Ï, where the
derivative is calculated at Î´Ï = 0; the perturbed form of Poisson&rsquo;s equation reads:
</p>
<p>&minus;Îµ&nabla;2Ï &minus; Îµ&nabla;2Î´Ï = Ï + &part;Ï
&part;Ï
</p>
<p>Î´Ï. (20.89)
</p>
<p>As the unperturbed terms cancel out due to (20.88), a Poisson equation in the
perturbation is obtained,
</p>
<p>&nabla;2Î´Ï = q2c Î´Ï, q2c = &minus;
&part;Ï/&part;Ï
</p>
<p>Îµ
, (20.90)
</p>
<p>where 1/qc is the screening length or Debye length. The definition implies that
&part;Ï/&part;Ï &lt; 0; this is in fact true, as shown below with reference to a non-degenerate
semiconductor with completely-ionized dopants. Letting N+D = ND , N&minus;A = NA
in (19.125), and using the non-degenerate expressions (18.60), (18.61) of the
equilibrium concentrations, one finds thatN = ND&minus;NA is left unaffected by the per-
turbation, while the electron concentration22 n transforms into n exp [e Î´Ï/(kB T )]
and the hole concentration p transforms into p exp [ &minus; e Î´Ï/(kB T )]. From Ï =
e (p &minus; n+N ) one obtains, to first order,
</p>
<p>&part;Ï
</p>
<p>&part;Ï
= &minus; e
</p>
<p>2
</p>
<p>kB T
(n+ p), q2c =
</p>
<p>e2 (n+ p)
Îµ kB T
</p>
<p>&gt; 0. (20.91)
</p>
<p>The left hand side of the Poisson equation in (20.90) is conveniently recast using a set
of spherical coordinates r , Î¸ ,Ï whose origin coincides with the center of symmetry
of the perturbation; using (B.25) one finds
</p>
<p>&nabla;2Î´Ï = 1
r
</p>
<p>&part;2
</p>
<p>&part;r2
(r Î´Ï) + r
</p>
<p>&minus;2
</p>
<p>sin Î¸
</p>
<p>&part;
</p>
<p>&part;Î¸
</p>
<p>(
</p>
<p>sin Î¸
&part;Î´Ï
</p>
<p>&part;Î¸
</p>
<p>)
</p>
<p>+ r
&minus;2
</p>
<p>sin2 Î¸
</p>
<p>&part;2Î´Ï
</p>
<p>&part;Ï2
. (20.92)
</p>
<p>22 The electron charge is indicated here with e to avoid confusion with qc.</p>
<p/>
</div>
<div class="page"><p/>
<p>20.6 Complements 481
</p>
<p>Considering a perturbation with a spherical symmetry, only the first term at the right
hand side of (20.92) is left, whence (20.90) becomes an equation in the unknown
r Î´Ï:
</p>
<p>d2
</p>
<p>dr2
(r Î´Ï) = q2c (r Î´Ï). (20.93)
</p>
<p>The general solution of (20.93) is r Î´Ï = A1 exp ( &minus; qc r) + A2 exp (qc r), where
it must be set A2 = 0 to prevent the solution from diverging as r becomes large. In
conclusion,
</p>
<p>Î´Ï = A1
r
</p>
<p>exp ( &minus; qc r). (20.94)
</p>
<p>The remaining constant is found by observing that for very small r the pure Coulomb
case Î´Ï â A1/r is recovered, whence A1 = Zcece/(4Ï Îµ). This makes (20.94) to
coincide with (14.33).</p>
<p/>
</div>
<div class="page"><p/>
<p>Part VII
</p>
<p>Basic Semiconductor Devices</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 21
</p>
<p>Bipolar Devices
</p>
<p>21.1 Introduction
</p>
<p>The mathematical model of semiconductor devices, derived in Chap. 19, is applied
here to the description of the fundamental bipolar device, the p&ndash;n junction. The term
bipolar indicates that both electrons and holes contribute to the current. The analy-
sis is carried out using the simple example of a one-dimensional abrupt junction in
steady state, with the hypotheses of non-degeneracy and complete ionization, that
lend themselves to an analytical treatment. The equilibrium condition is considered
first, and the solution of Poisson&rsquo;s equation is tackled, showing that the structure
can be partitioned into space-charge and quasi-neutral regions. Then, the Shockley
theory is illustrated, leading to the derivation of the ideal I (V ) characteristic. The
semiconductor model is then applied to illustrating two features of the reverse-bias
condition, namely, the depletion capacitance and the avalanche due to impact ion-
ization. The complements justify the simplification of considering only the diffusive
transport for the minority carriers in a quasi-neutral region, and provide the deriva-
tion of the Shockley boundary conditions. Finally, the expression of the depletion
capacitance is worked out for the case of an arbitrary charge-density profile.
</p>
<p>21.2 P&ndash;N Junction in Equilibrium
</p>
<p>A very simple, yet fundamental, semiconductor device is the p&ndash;n junction, whose
one-dimensional version is sketched in Fig. 21.1. The device is fabricated by ther-
mally diffusing (Chap. 23), or ion implanting p-type dopant atoms into an n-type
substrate, or vice versa. As a consequence, the diffused or implanted profile is not
spatially uniform. The substrate profile may in turn result from a similar process, so
that in general it is not uniform either. The locus of points where the ionized dopant
concentrations are equal to each other, N+D = N&minus;A , is a surface called metallurgical
</p>
<p>&copy; Springer Science+Business Media New York 2015 485
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_21</p>
<p/>
</div>
<div class="page"><p/>
<p>486 21 Bipolar Devices
</p>
<p>Fig. 21.1 Schematic example
of a one-dimensional p&ndash;n
junction
</p>
<p>p
</p>
<p>n
</p>
<p>metallurgical  junction
</p>
<p>x0
</p>
<p>&minus;type semiconductor
</p>
<p>&minus;type semiconductor
</p>
<p>junction.1 The theory of the p&ndash;n junction is carried out with reference to a simplified
structure, where the device is one dimensional and aligned with the x axis; in this
case the metallurgical junction is a plane normal to x and, as shown in Fig. 21.1, its
position is made to coincide with the reference&rsquo;s origin. Also, the non-uniform dopant
concentrations NA(x) and ND(x) are approximated by piecewise-constant functions,
NA = const for x &lt; 0 and ND = const for x &gt; 0. The device obtained from this ap-
proximation is called abrupt p&ndash;n junction. Considering the actual form of the dopant
distribution, the approximation is not realistic; however, the much simpler model
based on it is still able to capture the essential features of the device characteristics.
Moreover, the model assumes that the conditions of non-degeneracy and complete
ionization hold; this assumption makes the analytical approach possible.
</p>
<p>Within an integrated circuit the p&ndash;n junction is supplemented with contacts that
connect it to the rest of the circuit. Such contacts are typically made of metals, metal
silicides, or heavily-doped polycrystalline semiconductors; as a consequence, two
more junctions are present: the first one is between the contact and the p-doped
semiconductor, the other one between the contact and the n-doped semiconductor.
It is implied that the contacts are made of the same material; if it is not so, more
junctions must be considered as shown below.
</p>
<p>21.2.1 Built-In Potential
</p>
<p>A qualitative description of the device in the equilibrium condition starts from the
assumption that the extension of the p-doped and n-doped regions along the x axis
is large, so that, far away from the junction, the semiconductor can be considered as
uniformly doped of the p or n type, respectively. This fixes the boundary conditions
for the electron and hole concentrations:2 in fact, remembering that in the non-
degeneracy and complete-ionization conditions the equilibrium concentrations in a
uniform semiconductor are given by (18.42) for the p type and by (18.30) for the n
type, one finds
</p>
<p>1 The metallurgical junction is often indicated with the same term used for the whole device, namely,
p&ndash;n junction or simply junction.
2 The use of asymptotic conditions is not applicable to shallow junctions like, e.g., those used for
the fabrication of solar cells. In this case, the theory is slightly more involved.</p>
<p/>
</div>
<div class="page"><p/>
<p>21.2 P&ndash;N Junction in Equilibrium 487
</p>
<p>pp0 = p( &minus;&infin;) â NA, np0 = n( &minus;&infin;) â
n2i
</p>
<p>NA
, (21.1)
</p>
<p>nn0 = n( +&infin;) â ND , pn0 = p( +&infin;) â
n2i
</p>
<p>ND
. (21.2)
</p>
<p>The above concentrations are also called asymptotic concentrations; the last ap-
proximations are derived from the assumption NA,ND â« ni which, as outlined in
Sect. 18.4.1, has a vast range of validity. The distance between the conduction-band
edge and the Fermi level is found from n = NC exp [&minus;(EC&minus;EF )/(kB T )] (compare
with (18.28)); combining with (21.1) and (21.2) yields
</p>
<p>n2i
</p>
<p>NA
â NC exp
</p>
<p>[
</p>
<p>&minus;EC( &minus;&infin;) &minus; EF
kB T
</p>
<p>]
</p>
<p>, ND â NC exp
[
</p>
<p>&minus;EC( +&infin;) &minus; EF
kB T
</p>
<p>]
</p>
<p>,
</p>
<p>(21.3)
</p>
<p>whence
</p>
<p>EC( &minus;&infin;) &minus; EC( +&infin;) = kB T log
(
NA ND
</p>
<p>kB T
</p>
<p>)
</p>
<p>. (21.4)
</p>
<p>An identical expression is found for EV ( &minus;&infin;) &minus; EV ( +&infin;). These findings show
that EC , EV are functions of position; their explicit form is determined below.
Alternatively, one may use (18.60) and (18.61), to find
</p>
<p>Ï0 = kB T log
(
NA ND
</p>
<p>kB T
</p>
<p>)
</p>
<p>, Ï0 = Ï( +&infin;) &minus; Ï( &minus;&infin;), (21.5)
</p>
<p>whereÏ0 is called built-in potential.3 One notes that so far the values of the constants
n(0), p(0) in (18.60) and (18.61) have been left unspecified; remembering that n(0) is
the value of n in the position(s) where Ï = 0, and the same for p(0), the numerical
values sought are determined by specifying the zero point of Ï. Here such a point is
fixed by letting Ï( +&infin;) = 0 whence, using (21.3) and (21.4), one finds
</p>
<p>p(0) = p( +&infin;) = pn0, n(0) = n( +&infin;) = nn0. (21.6)
</p>
<p>The expressions of the carrier concentrations in terms of the band energies EC ,
EV must be coherent with those expressed in terms of Ï. In fact, the relation be-
tween EC(x) and Ï(x) is found by combining n = n(0) exp [q Ï/(kB T )] with n =
NC exp [(EF &minus; EC)/(kB T )] and using n(0) = NC exp{[EF &minus; EC( +&infin;)]/(kB T )};
a similar procedure is applied to EV , to eventually find
</p>
<p>EC(x) = EC( +&infin;) &minus; q Ï(x), EV (x) = EV ( +&infin;) &minus; q Ï(x). (21.7)
</p>
<p>3 The same quantity is also called barrier potential and is sometimes indicated with ÏB .</p>
<p/>
</div>
<div class="page"><p/>
<p>488 21 Bipolar Devices
</p>
<p>Letting N (x) = &minus;NA for x &lt; 0 and N (x) = +ND for x &gt; 0, the electric potential
is found by solving the Poisson equation
</p>
<p>d2Ï
</p>
<p>dx2
= q
</p>
<p>Îµsc
</p>
<p>[
</p>
<p>nn0 exp
</p>
<p>(
qÏ
</p>
<p>kB T
</p>
<p>)
</p>
<p>&minus; pn0 exp
(&minus;qÏ
kB T
</p>
<p>)
</p>
<p>&minus;N (x)
]
</p>
<p>(21.8)
</p>
<p>with boundary conditions Ï(&minus;&infin;) = &minus;Ï0 and Ï(+&infin;) = 0. One notes that within
each half domain the charge density in (21.8) has the formÏ = Ï(Ï), which makes the
theory of Sect. 19.5.8 applicable. Therefore, it is convenient to separately solve (21.8)
in each half space, and apply suitable matching conditions at x = 0 afterwards. When
the regional-solution method is used, the boundary conditions must be modified with
respect to Ï(&minus;&infin;) = &minus;Ï0 and Ï(+&infin;) = 0; the new conditions are shown below. In
the n-doped region the charge density reads Ï = q(p&minus;n+ND); when x &rarr; +&infin; the
latter becomes 0 = pn0 &minus; nn0 &minus;ND: in fact, as at large distances from the origin the
material behaves like a uniformly-doped semiconductor, local charge neutrality is
fulfilled at infinity. Using the dimensionless potential u = q Ï/(kB T ), and indicating
the derivatives with primes, gives the equation the form
</p>
<p>u&prime;&prime; = 1
L2D
</p>
<p>AD(u), AD = exp (u) &minus; 1 +
pn0
</p>
<p>nn0
[1 &minus; exp ( &minus; u)], L2D =
</p>
<p>Îµsc kB T
</p>
<p>q2 nn0
,
</p>
<p>(21.9)
</p>
<p>with LD the Debye length for the electrons. The normalized charge density AD
vanishes for u = 0, and is positive (negative) when u is positive (negative). Note that,
by letting x &rarr; +&infin; in n = ni exp [(Ï&minus;ÏF )/(kB T )], p = ni exp [(ÏF&minus;Ï)/(kB T )],
and using the normalized Fermi potential uF = q ÏF /(kB T ), one finds pn0/nn0 =
(ni/ND)2 = exp (2 uF ), where uF &lt; 0 on account of the fact that here an n-doped
region is considered. Following the method illustrated in Sect. 19.5.8 transforms the
left hand side of (21.8) into u&prime;&prime; u&prime; = (1/2) [(u&prime;)2]&prime;. This term is then integrated from
x = 0 to x = +&infin;; the result is simplified by observing that the region far from the
junction is substantially uniform, whence the electric potential is constant there. As
u&prime; is proportional to the electric field, it follows that u&prime;(+&infin;) = 0: this is the second
boundary condition to be added to u( + &infin;) = 0. In conclusion, the integration of
(21.9) from x &ge; 0 to +&infin; yields
</p>
<p>(
</p>
<p>u&prime;
)2 = 2
</p>
<p>L2D
BD(u), BD = exp (u) &minus; 1 &minus; u +
</p>
<p>n2i
</p>
<p>N2D
[u + exp ( &minus; u) &minus; 1]. (21.10)
</p>
<p>It is easily found that BD is non negative; in fact, from (21.10) one derives BD = 0
for u = 0, and at the same time dBD/du = AD(u) is positive for u &gt; 0, negative
for u &lt; 0; as a consequence, BD grows from zero in either direction when u departs
from the origin. Letting F 2D = BD one finds |u&prime;| =
</p>
<p>&radic;
2FD/LD; as the condition
</p>
<p>u = 0 holds only asymptotically, the modulus of u&prime; always grows as u departs
from the origin, showing that u is monotonic. Considering that u must fulfill the
other boundary condition u( &minus;&infin;) = &minus;q Ï0/(kB T ) &lt; 0, one concludes that u is a</p>
<p/>
</div>
<div class="page"><p/>
<p>21.2 P&ndash;N Junction in Equilibrium 489
</p>
<p>Fig. 21.2 Solution of the
one-dimensional Poisson
equation 21.8 in an abrupt
p&ndash;n junction at equilibrium,
with NA = 1016 cm&minus;3,
ND = 1015 cm&minus;3. The
continuous vertical line
</p>
<p>marks the position of the
metallurgical junction, the
dashed vertical lines mark the
edges of the space-charge
region
</p>
<p>-1 -0.5 0 0.5 1 1.5 2
x      (Î¼m)
</p>
<p>-0.6
</p>
<p>-0.4
</p>
<p>-0.2
</p>
<p>0
</p>
<p>Ï
  
  
  
(V
</p>
<p>)
</p>
<p>monotonically-growing function, whence, choosing the positive sign and separating
the variables, one finds
</p>
<p>du
</p>
<p>FD(u)
=
</p>
<p>&radic;
2
</p>
<p>LD
dx (21.11)
</p>
<p>for x &ge; 0. The above must be tackled numerically because it has no analytical
solution.4 Once the normalized potential is found from (21.11), its value in the origin,
u(x = 0), along with that of the derivative u&prime;(x = 0) =
</p>
<p>&radic;
2FD[u(x = 0)]/LD ,
</p>
<p>provide the boundary conditions for the solution in the p-doped region.
The solution for x &lt; 0 follows the same pattern, where the asymptotic neutrality
</p>
<p>condition reads nn0 exp ( &minus; Ï0) &minus; pn0 exp (Ï0) + NA = 0, with Ï0 = q Ï0/(kB T ).
Letting v = u + Ï0, np0/pp0 = (ni/NA)2 = exp ( &minus; 2 uF ) âª 1, and using (21.5)
provides
</p>
<p>v&prime;&prime; = 1
L2A
</p>
<p>AA(v), AA =
n2i
</p>
<p>N2A
[ exp (v) &minus; 1] + 1 &minus; exp ( &minus; v), L2A =
</p>
<p>Îµsc kB T
</p>
<p>q2 pp0
,
</p>
<p>(21.12)
</p>
<p>where LA is the Debye length for the holes. The rest of the procedure is similar to
that used in the n-doped region.
</p>
<p>21.2.2 Space-Charge and Quasi-Neutral Regions
</p>
<p>The form of the electric potential Ï is shown in Fig. 21.2 for a p&ndash;n junction at
equilibrium with NA = 1016 cm&minus;3, ND = 1015 cm&minus;3. The form of the bands is
</p>
<p>4 The numerical procedure is outlined in the note of Sect. 22.2.1.</p>
<p/>
</div>
<div class="page"><p/>
<p>490 21 Bipolar Devices
</p>
<p>Fig. 21.3 Form of the bands
for the same device as in
Fig. 21.2
</p>
<p>-1 -0.5 0 0.5 1 1.5 2
x      (Î¼m)
</p>
<p>-1
</p>
<p>-0.5
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>1.5
</p>
<p>2
</p>
<p>E
  
  
  
(e
</p>
<p>V
)
</p>
<p>E
F
</p>
<p>( E
C
 + E
</p>
<p>V
 ) / 2
</p>
<p>E
C
 (x)
</p>
<p>E
V
 (x)
</p>
<p>shown in Fig. 21.3 for the same device. It is interesting to note that the device can be
thought of as made of three regions: in the intermediate region, whose boundaries are
marked by dashed vertical lines in Fig. 21.2, the electric potential has a non-negligible
curvature, this showing that the charge density is large. The region is called space-
charge region, and contains the metallurgical junction, marked by the continuous
vertical line. In the two regions on the sides of the space-charge region, the electric
potential is nearly constant,5 whence the electric field &minus;dÏ/dx is negligibly small.
As a consequence, the charge density Ï = &minus;Îµsc d2Ï/dx2 is negligible as well; for
this reason, the two regions under consideration are called quasi-neutral regions.6
</p>
<p>The transition from the space-charge region and one or the other quasi-neutral
region is sharp. Thanks to this, it is possible to identify the width l of the space-
charge region and correlate it with other parameters of the device; such a correlation
is worked out in Sect. 21.4 in a specific operating regime. For convenience, the width
of the space-charge region is expressed as l = lp+ ln, where lp is the extension of the
space-charge region on the p side of the metallurgical junction, and ln the analogue
on the n side. As shown in Fig. 21.2, it is ln &gt; lp; as explained in Sect. 21.4, this is
due to the global charge neutrality and to the fact that ND &lt; NA.
</p>
<p>If the equilibrium carrier concentrations corresponding to the electric potential of
Fig. 21.2 are drawn in a logarithmic scale, the curves look similar to that of Fig. 21.2,
apart from scaling factors and from the inversion due to the negative sign in p =
pn0 exp [&minus; q Ï/(kB T )]. This is shown in Fig. 21.4. A more realistic representation,
shown in Fig. 21.5, uses a linear scale. The hole concentration p ranges from pp0 â
NA = 1016 cm&minus;3 in the p-type quasi-neutral region to pn0 â n2i /ND = 105 cm&minus;3 in
</p>
<p>5 The electric potential can not be exactly constant, because the solution of (21.8) is an analytical
function; as a consequence, if Ï were constant in a finite interval, it would be constant everywhere.
6 The inverse reasoning would not be correct: in fact, Ï = 0 may yield dÏ/dx = const ï¿½= 0, which
makes Ï a linear function of x; deducing Ï = const from Ï = 0 is correct only if the additional
condition of spatial uniformity holds.</p>
<p/>
</div>
<div class="page"><p/>
<p>21.2 P&ndash;N Junction in Equilibrium 491
</p>
<p>Fig. 21.4 Electron and hole
concentrations in a
one-dimensional, abrupt p&ndash;n
junction at equilibrium, with
NA = 1016 cm&minus;3,
ND = 1015 cm&minus;3. The figure
is drawn in a logarithmic
scale. The continuous vertical
line marks the position of the
metallurgical junction, the
dashed vertical lines mark the
edges of the space-charge
region
</p>
<p>-1 -0.5 0 0.5 1 1.5 2
x      (Î¼m)
</p>
<p>1&times;10
3
</p>
<p>1&times;10
7
</p>
<p>1&times;10
11
</p>
<p>1&times;10
15
</p>
<p>n
 (
</p>
<p>x
) 
</p>
<p>,
p
</p>
<p> (
x
) 
</p>
<p>  
  
</p>
<p> (
cm
</p>
<p>-3
)
</p>
<p>n
p
</p>
<p>Fig. 21.5 The same
concentrations as in Fig. 21.4,
drawn in a linear scale
</p>
<p>-1 -0.5 0 0.5 1 1.5 2
x      (Î¼m)
</p>
<p>0
</p>
<p>5&times;10
15
</p>
<p>1&times;10
16
</p>
<p>n
 (
</p>
<p>x
) 
</p>
<p>,
p
</p>
<p> (
x
) 
</p>
<p>  
  
</p>
<p> (
cm
</p>
<p>-3
)
</p>
<p>n
p
</p>
<p>the n-type quasi-neutral region; similarly, the electron concentration n ranges from
np0 â n2i /NA = 104 cm&minus;3 in the p-type quasi-neutral region to nn0 â ND = 1015
cm&minus;3 in the n-type quasi-neutral region. This shows that the two concentrations
vary by several orders of magnitude over the space-charge region, whose length
is about 1 Î¼m; for this reason, if these gradients existed alone, they would make
holes (electrons) to diffuse in the positive (negative) direction of the x axis. Such
diffusions in fact do not occur, because in the equilibrium condition they are balanced
by the electric field. The latter is negative: in fact, the electric potential increases
with x, so that the force associated to the electric field E is negative (positive) for
holes (electrons); the equations for the current densities of the semiconductor device
model in (19.129) and (19.130) yield in this case
</p>
<p>&minus;qÎ¼p pE = &minus;qDp
dp
</p>
<p>dx
&gt; 0, &minus;qÎ¼n nE = +qDn
</p>
<p>dn
</p>
<p>dx
&gt; 0, (21.13)
</p>
<p>whence Jp = Jn = 0. The description of the p&ndash;n junction in the equilibrium con-
dition is completed by adding the contacts; as indicated above, this amounts to
introducing two more junctions. The contacts are made of materials different from</p>
<p/>
</div>
<div class="page"><p/>
<p>492 21 Bipolar Devices
</p>
<p>the semiconductor of which the p&ndash;n junction is made, hence the atomic structure of
the contact&rsquo;s material must adapt to that of the semiconductor when the contact is
deposited on it; for this reason, the structure of the contact-semiconductor junction
must be described on a case-by-case basis. From the qualitative standpoint, one can
use the analogy with the p&ndash;n junction to deduce the existence of a built-in poten-
tial Î¦mp between the contact and the p-type semiconductor, and of another built-in
potential Î¦mn between the contact and the n-type semiconductor. The built-in po-
tentials are influenced by the dopant concentration of the semiconductor, namely,
Î¦mp = Î¦mp(NA) and Î¦mn = Î¦mn(ND). Assume that the contacts are made of
the same material; if they are short-circuited, a closed loop is formed where, from
Kirchhoff&rsquo;s voltage law, the built-in potentials fulfill the relation
</p>
<p>Ï0 +Î¦mn &minus;Î¦mp = 0. (21.14)
</p>
<p>This situation is schematically illustrated in Fig. 21.6, where it is assumed that the
material of the contacts is the same.7 In the figure, the built-in potentials at the
contacts are represented by discontinuities; in the practical cases, in fact, to prevent
the contact-semiconductor junction from behaving like a rectifying device, a heavy
dose of dopant is preliminarily introduced into the semiconductor region onto which
the contact is to be deposited. For this reason, the spatial extension where Î¦mp or
Î¦mn occurs is negligibly small with respect to the typical scale length of the device.
Regardless of this, another important outcome of the fabrication process mentioned
above is that the concentration of carriers available in the materials forming a contact
is very large; for this reason, as mentioned in Sect. 19.5.6, a contact is able to
supply the amount of charge necessary to keep the equilibrium and charge-neutrality
conditions in the semiconductor layer adjacent to it. This also implies that, within
some limits to be specified later, in a non-equilibrium condition the built-in potential
is practically the same as in equilibrium. In circuit theory, a contact whose built-in
potential is independent of the current that crosses it is called ideal Ohmic contact;
this condition is equivalent to that of a vanishing differential resistivity of the contact.
</p>
<p>21.3 Shockley Theory of the P&ndash;N Junction
</p>
<p>The analytical derivation of the current-voltage characteristic of the p&ndash;n junction is
based on the hypothesis that the device is not too far from equilibrium, so that the
weak-injection condition (20.35) is fulfilled in the quasi-neutral regions. Within this
limit, the approximation that the contacts are ideal is acceptable. A non-equilibrium
condition is obtained by applying, e.g., a bias voltage V between the contacts; if V
is such that the electric potential at the contact of the p region is higher than that of
the n region, the condition is called forward bias; when it is lower, the condition is
called reverse bias. Fig. 21.7 shows the symbol of the p&ndash;n junction used in circuit
</p>
<p>7 If it is not so, one must add to the left hand side of (21.14) the barrier between the two materials.</p>
<p/>
</div>
<div class="page"><p/>
<p>21.3 Shockley Theory of the P&ndash;N Junction 493
</p>
<p>Fig. 21.6 Electric potential
for the same device as in
Fig. 21.2, including the
built-in potentials of the
contacts
</p>
<p>-3 -2.5 -2 -1.5 -1 -0.5 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
x      (Î¼m)
</p>
<p>-0.6
</p>
<p>-0.4
</p>
<p>-0.2
</p>
<p>0
</p>
<p>Ï
  
  
  
(V
</p>
<p>)
</p>
<p>mp
Î¦
</p>
<p>Î¦
mn
</p>
<p>ln
</p>
<p>lp
</p>
<p>0
Ï
</p>
<p>Fig. 21.7 Symbol and
typical I , V reference for the
p&ndash;n junction
</p>
<p>&minus;type semiconductorn&minus;type semiconductorp
</p>
<p>V
</p>
<p>I
</p>
<p>theory, along with the standard references for the applied voltage V and current I .
In a one-dimensional case the current is given by I = Ae J , with Ae the device
cross-sectional area and J the total current density.
</p>
<p>Numerical solutions of the semiconductor-device model show that in the weak-
injection condition the partitioning of the device into space-charge and quasi-neutral
regions still holds; this implies that, when a bias voltage is applied between the
contacts, such a voltage adds algebraically to the built-in potential. In fact, the dis-
continuities at the contacts are the same as in the equilibrium condition due to the
contacts&rsquo; ideality, and the electric potential in the quasi-neutral regions is nearly
constant; the extension of the space-charge region, instead, changes due to the ap-
plication of the external voltage, lp = lp(V ), ln = ln(V ). When a forward bias is
applied, lp and ln slightly decrease, as qualitatively shown in Fig. 21.8 (the drawing
is not in the same scale as Fig. 21.6, and is meant only to show the change in l; the
solution in the space-charge region is omitted). The same applies to Fig. 21.9, that
refers to the reverse bias and shows that in this case lp and ln increase. Using (21.14),
the application of Kirchhoff&rsquo;s voltage law to either case yields, for the voltage drop
Ï across the space-charge region, the expression
</p>
<p>Ï +Î¦mn + V &minus;Î¦mp = 0, Ï + V &minus; Ï0 = 0. (21.15)
</p>
<p>In reverse bias (V &lt; 0) it is always Ï &gt; Ï0 &gt; 0; in forward bias (V &gt; 0) a
sufficiently large value of V in (21.15) could make Ï to become negative. However,
when V becomes large the weak-injection condition does not hold any more, and</p>
<p/>
</div>
<div class="page"><p/>
<p>494 21 Bipolar Devices
</p>
<p>Fig. 21.8 Schematic
description of the change in
the extension l of the
space-charge region in a
forward-biased p&ndash;n junction
(V &gt; 0). The thin lines refer
to the equilibrium case. The
drawing is not in the same
scale as Fig. 21.6
</p>
<p>0
Ï
</p>
<p>0
</p>
<p>Ï
</p>
<p>x
</p>
<p>l
</p>
<p>V
</p>
<p>mp
Î¦
</p>
<p> 0V  &gt;
l p l n
</p>
<p>mn
Î¦
</p>
<p>Ï
</p>
<p>Fig. 21.9 Schematic
description of the change in
the extension l of the
space-charge region in a
reverse-biased p&ndash;n junction
(V &lt; 0). The thin lines refer
to the equilibrium case. The
drawing is not in the same
scale as Fig. 21.6
</p>
<p>0
</p>
<p>Ï
</p>
<p>x
</p>
<p>Ï
V
</p>
<p>l
</p>
<p>mn
Î¦
</p>
<p>Ï
0
</p>
<p>l nl pmp
Î¦
</p>
<p>(21.15) does not apply; in conclusion, the range of forward biases to be considered
here is such that the condition Ï0 &gt; Ï &gt; 0 is always fulfilled.
</p>
<p>When a forward bias is applied, due to Ï &lt; Ï0 the electric field within the space-
charge region decreases with respect to the equilibrium case;8 thus, the drift term in
the drift-diffusion equations of (19.129) and (19.130) becomes weaker. The diffusion
term, in contrast, becomes slightly stronger, because the values of the electron con-
centrations in the quasi-neutral regions are fixed by the asymptotic conditions, and the
width of the space-charge region slightly decreases with respect to the equilibrium
case. In conclusion, the diffusion term prevails and the current-density equations
yield
</p>
<p>&minus;qDp
dp
</p>
<p>dx
&gt; &minus;qÎ¼p pE &gt; 0, qDn
</p>
<p>dn
</p>
<p>dx
&gt; &minus;qÎ¼n nE &gt; 0, (21.16)
</p>
<p>so that Jp &middot; i = qp vp &gt; 0 and Jn &middot; i = &minus;qn vn &gt; 0. The total current density
(Jp + Jn) &middot; i is positive as well.
</p>
<p>When a reverse bias is applied, due to Ï &gt; Ï0 the voltage drop across the
space-charge region increases with respect to the equilibrium case. The region&rsquo;s
width increases as well; however, the increase in l is relatively weak, whence the
</p>
<p>8 The width of the space-charge region decreases as well (Fig. 21.8); such a decrease, however, is
small, and does not compensate for the decrease in the potential drop.</p>
<p/>
</div>
<div class="page"><p/>
<p>21.3 Shockley Theory of the P&ndash;N Junction 495
</p>
<p>electric field within the space-charge region increases and the drift term in the drift-
diffusion equations of (19.129) and (19.130) becomes stronger. The diffusion term,
in contrast, becomes weaker, because the values of the electron concentrations in the
quasi-neutral regions are fixed by the asymptotic conditions. In conclusion, the drift
term prevails and the current-density equations yield
</p>
<p>&minus;qÎ¼p pE &gt; &minus;qDp
dp
</p>
<p>dx
&gt; 0, &minus;qÎ¼n nE &gt; qDn
</p>
<p>dn
</p>
<p>dx
&gt; 0, (21.17)
</p>
<p>so that Jp &middot; i = qp vp &lt; 0, Jn &middot; i = &minus;qn vn &lt; 0. The total current density is negative
as well.
</p>
<p>The I (V ) relation of the p&ndash;n junction is worked out here in the one-dimensional
and steady-state case, this leading to the Shockley equations [97, 98]. The steady-
state form divJ = 0 of the continuity equation (4.23) reduces in one dimension to
dJ/dx = 0, whence
</p>
<p>J = Jp(x) + Jn(x) = const. (21.18)
</p>
<p>The hole and electron current densities depend on position and fulfill the steady-
state continuity equations of (19.129) and (19.130); in the latter, only the net thermal
recombination term is considered, to find
</p>
<p>dJp
dx
</p>
<p>= &minus;qUSRH,
dJn
dx
</p>
<p>= qUSRH. (21.19)
</p>
<p>Once Jp, Jn are determined from (21.19), they are specified at a suitable position and
added up. As shown below, such positions are the boundaries &minus;lp and ln between
the space-charge and quasi-neutral regions, for instance, J = Jp( &minus; lp) + Jn( &minus; lp).
Observing that&minus;lp is the boundary of the p-type region, Jp(&minus;lp) is a majority-carrier
current density, whereas Jn(&minus; lp) is a minority-carrier current density. The opposite
happens if the other boundary is chosen, to yield J = Jp(ln) + Jn(ln). To proceed,
it is convenient to seek for an expression of J where both current densities refer
to minority carriers; this is achieved by integrating (21.19) over the space-charge
region, to define the recombination current density
</p>
<p>JU =
&int; ln
</p>
<p>&minus;lp
qUSRH dx = Jp( &minus; lp) &minus; Jp(ln) = Jn(ln) &minus; Jn( &minus; lp). (21.20)
</p>
<p>Combining (21.20) with the expression of the total current density at, e.g., ln provides
</p>
<p>J = Jp(ln) + Jn(ln) = Jp(ln) + Jn( &minus; lp) + JU , (21.21)
</p>
<p>which has the desired form.</p>
<p/>
</div>
<div class="page"><p/>
<p>496 21 Bipolar Devices
</p>
<p>21.3.1 Derivation of the I (V ) Characteristic
</p>
<p>Remembering the simplified form (20.38) or (20.40) of the net thermal-recombina-
tion term in the weak-injection condition, and using peq = pn0 in the n-type region
and neq = np0 in the p-type region, transforms (21.19) into, respectively,
</p>
<p>dJp
dx
</p>
<p>= q p &minus; pn0
Ïp
</p>
<p>, x &gt; ln, (21.22)
</p>
<p>dJn
dx
</p>
<p>= q n&minus; np0
Ïn
</p>
<p>, x &lt; &minus;lp. (21.23)
</p>
<p>In this way, the hole- and electron-continuity equations are decoupled from each
other; also, they are to be solved over disjoint intervals. To the current-continuity
equations one associates the corresponding drift-diffusion equation taken from
(19.129) or (19.130); it follows that in each quasi-neutral region the drift-diffusion
equation is that of the minority carriers. It can be shown that in a quasi-neutral region,
when the weak-injection condition holds, the diffusion term of the minority carries
dominates over the drift term (the details are worked out in Sect. 21.6.1). Thus, for
x &lt; &minus;lp (p-type region), Jn = q Î¼n nE + q Dn dp/dx â q Dn dp/dx. Inserting
the latter into (21.23) yields Dn d2n/dx2 = (n&minus; np0)/Ïn. In this derivation the dif-
fusion coefficient Dn = kB T Î¼n/q is not subjected to the derivative; in fact, the two
parameters that influence bulk mobility, T and NA (Sect. 20.5), are independent of
position. The equation then reads,
</p>
<p>d2(n&minus; np0)
dx2
</p>
<p>= n&minus; np0
Ln
</p>
<p>, Ln =
&radic;
</p>
<p>Ïn Dn, (21.24)
</p>
<p>with Ln the diffusion length of the minority carriers in the p-type region. It is a
second-order, linear equation in the unknown n; it is decoupled from the rest of the
semiconductor-device model: in fact, the simplified form of the net-recombination
term contains only the electron concentration, and the neglect of the drift term elimi-
nates the coupling with the Poisson equation. The boundary conditions must be fixed
at x &rarr; &minus;&infin; and x = &minus;lp; the former is n( &minus;&infin;) = np0, whereas the latter needs a
more elaborate derivation, given in Sect. 21.6.2, whose outcome (also called Shock-
ley&rsquo;s boundary condition) is n( &minus; lp) = np0 exp [q V/(kB T )]. The general solution
of (21.24) is
</p>
<p>n = np0 + An exp (x/Ln) + Bn exp ( &minus; x/Ln), (21.25)
</p>
<p>whence the asymptotic boundary condition yields Bn = 0. The other boundary
condition provides n( &minus; lp) = np0 + A&minus;n , with A&minus;n = An exp ( &minus; lp/Ln). The
electron current density is then found from
</p>
<p>Jn = qDn
dn
</p>
<p>dx
= qDn
</p>
<p>Ln
An exp (x/Ln) = Jn( &minus; lp) exp [(x + lp)/Ln], (21.26)</p>
<p/>
</div>
<div class="page"><p/>
<p>21.3 Shockley Theory of the P&ndash;N Junction 497
</p>
<p>where, using n( &minus; lp) = np0 + A&minus;n and the boundary condition at x = &minus;lp,
</p>
<p>Jn( &minus; lp) =
qDn A
</p>
<p>&minus;
n
</p>
<p>Ln
= qDn np0
</p>
<p>Ln
F , F (V ) = exp [qV /(kB T )] &minus; 1. (21.27)
</p>
<p>In the same manner one finds
</p>
<p>Jp(ln) =
q Dp pn0
</p>
<p>Lp
F , Lp =
</p>
<p>&radic;
</p>
<p>Ïp Dp, (21.28)
</p>
<p>where F is the same as in (21.27), and Lp is the diffusion length of the minority
carriers in the n-type region. Inserting (21.27) and (21.28) into (21.21) yields the
total current density,
</p>
<p>J = Jp(ln) + Jn( &minus; lp) + JU = q
(
Dppn0
</p>
<p>Lp
+ Dnnp0
</p>
<p>Ln
</p>
<p>)
</p>
<p>F + JU . (21.29)
</p>
<p>Multiplying (21.29) by the cross-sectional areaAe and defining the saturation current
density
</p>
<p>Js = q
(
Dppn0
</p>
<p>Lp
+ Dnnp0
</p>
<p>Ln
</p>
<p>)
</p>
<p>= qn2i
</p>
<p>(&radic;
</p>
<p>Dp/Ïp
</p>
<p>ND
+
</p>
<p>&radic;
Dn/Ïn
</p>
<p>NA
</p>
<p>)
</p>
<p>, (21.30)
</p>
<p>yields the expression of the I (V ) characteristic of the p&ndash;n junction:
</p>
<p>I = Is
[
</p>
<p>exp
</p>
<p>(
qV
</p>
<p>kB T
</p>
<p>)
</p>
<p>&minus; 1
]
</p>
<p>+ IU , Is = Ae Js , IU = Ae JU . (21.31)
</p>
<p>The characteristic fulfills the equilibrium condition I (0) = 0; in fact, at equi-
librium it is USRH = 0. When qV /kB T â« 1, the exponential term in (21.31)
prevails over the other terms and the characteristic becomes I â Is exp [qV /(kB T )],
namely, the well-known exponential form of the forward-bias case. Finally, when
qV /kB T âª &minus;1, the current becomes I â &minus;Is + IU . As the order of magnitude of
Is may be similar to that of IU , it is necessary to calculate the latter explicitly. The
analysis is made easier by the observation that the electric field (which in the reverse-
bias condition prevails over diffusion) drains the holes from the space-charge region
to the p-type quasi-neutral region; similarly, the electrons of the space-charge region
are drained towards the n-type quasi-neutral region. As a consequence, the carrier
concentrations in the space-charge region are negligible, and the full-depletion con-
dition (20.34) applies there; using the non-degenerate expression one finds, for the
reverse-bias current,
</p>
<p>I â &minus;Is + IU â &minus;Is + Ae
&int; ln
</p>
<p>&minus;lp
q
&minus;ni
Ïg
</p>
<p>dx = &minus;Is &minus; qAe
ni
</p>
<p>Ïg
l(V ) &lt; 0, (21.32)
</p>
<p>where the expression (21.20) of the recombination current density has been used,
and l = l(V ) is the width of the space-charge region. As shown in Sect. 21.4, in</p>
<p/>
</div>
<div class="page"><p/>
<p>498 21 Bipolar Devices
</p>
<p>Fig. 21.10 Charge density in
a reverse-biased p&ndash;n junction
using the ASCE
approximation, in arbitrary
units. The ratio NA/ND is the
same as in Fig. 21.6
</p>
<p>D
q N
</p>
<p>&minus; q N
A
</p>
<p>ln0 x
</p>
<p>Ï
</p>
<p>&minus; lp
</p>
<p>the reverse-bias condition and for an abrupt junction it is l &prop; &radic;Ï0 + |V |; as a
consequence, IU increases with |V |.
</p>
<p>The approximations that have been introduced to derive the I (V ) characteristic are
many; in fact, (21.31) is referred to as the ideal characteristic. However, it captures
quite well the general behavior of the device as long as the applied voltage is within
the limit of the weak-injection approximation. When the forward bias exceeds such
a limit, the drift term is not negligible anymore and the effect of the electric field in
the quasi-neutral regions must be accounted for. Considering in turn the reverse-bias
condition, at large values of |V | the electric field in the space-charge region becomes
sufficiently strong to induce impact ionization (Sect. 20.3) and, possibly, the junction
breakdown due to avalanche (Sect. 21.5).
</p>
<p>The dependence of the I (V ) characteristic on temperature is due, besides that of
q V/(kB T ), to the coefficients of Js and JU . To this purpose, the second form of
(21.30) is more useful because it shows explicitly the term n2i , whose temperature
dependence is exponential (18.14); in fact, the temperature dependence of Dp/Ïp,
Dn/Ïn is much weaker. The same considerations apply to JU , whose main depen-
dence on temperature is due to factor ni . The dependence on ni of the reverse current
(at constant temperature) has been used in the considerations about the parasitic
currents in integrated circuits made in Sect. 18.7.
</p>
<p>21.4 Depletion Capacitance of the Abrupt P&ndash;N Junction
</p>
<p>It has been anticipated in Sect. 21.3.1 that, when a reverse bias is applied to the
junction, the full-depletion condition holds in the space-charge region; as a conse-
quence, the charge density Ï in the latter is essentially due to the dopant atoms. In the
abrupt junction considered here, the dopants&rsquo; concentration is piecewise constant; a
simplified description of the charge density in the situation in hand is obtained from
the abrupt space-charge edge (ASCE) approximation, which describes Ï with the
form sketched in Fig. 21.10. In other terms, the approximation consists in replacing</p>
<p/>
</div>
<div class="page"><p/>
<p>21.4 Depletion Capacitance of the Abrupt P&ndash;N Junction 499
</p>
<p>with a discontinuity the smooth change of Ï at x = &minus;lp, x = 0, and x = ln; thus,
the space charge is given by
</p>
<p>Ï = &minus;qNA, &minus;lp &lt; x &lt; 0, (21.33)
</p>
<p>Ï = qND , 0 &lt; x &lt; ln, (21.34)
</p>
<p>and Ï = 0 elsewhere. The electric field and the electric potential are continuous
because there are no charge layers or double layers; letting E0 = E(0), from
dE/dx = Ï/Îµsc and (21.33), (21.34) one draws
</p>
<p>E0 &minus; E( &minus; lp)
lp
</p>
<p>= &minus;qNA
Îµsc
</p>
<p>,
E(ln) &minus; E0
</p>
<p>ln
= qND
</p>
<p>Îµsc
, (21.35)
</p>
<p>the first of which holds for &minus;lp &le; x &le; 0, the second one for 0 &le; x &le; ln. In the
quasi-neutral regions the field is negligible; in the order of approximation used here
one lets E = 0 in such regions, whence E( &minus; lp) = E(ln) = 0 and, from (21.35),
</p>
<p>E0 = &minus;
qND
</p>
<p>Îµsc
ln = &minus;
</p>
<p>qNA
</p>
<p>Îµsc
lp &lt; 0, ND ln = NA lp. (21.36)
</p>
<p>In conclusion, the electric field is a piecewise-linear function whose form is shown
in Fig. 21.11. Due to dÏ/dx = &minus;E, the integral of &minus;E over the space-charge region
equals the potential drop Ï :
</p>
<p>Ï = Ï(ln) &minus; Ï( &minus; lp) = &minus;
&int; +ln
</p>
<p>&minus;lp
E dx = &minus;1
</p>
<p>2
E0 (ln + lp). (21.37)
</p>
<p>Inserting into (21.37) one or the other form of E0 from (21.36), one obtains two
equivalent expressions for lp + ln:
</p>
<p>ln + lp = ln +
ND
</p>
<p>NA
ln = ND ln
</p>
<p>(
1
</p>
<p>ND
+ 1
</p>
<p>NA
</p>
<p>)
</p>
<p>= NA lp
(
</p>
<p>1
</p>
<p>ND
+ 1
</p>
<p>NA
</p>
<p>)
</p>
<p>. (21.38)
</p>
<p>Then, combining (21.38) with (21.37) one finds
</p>
<p>Ï = q
2 Îµsc
</p>
<p>(
1
</p>
<p>ND
+ 1
</p>
<p>NA
</p>
<p>)
</p>
<p>(NDln)
2 = q
</p>
<p>2 Îµsc
</p>
<p>(
1
</p>
<p>ND
+ 1
</p>
<p>NA
</p>
<p>)
(
</p>
<p>NAlp
)2
</p>
<p>, (21.39)
</p>
<p>whence
</p>
<p>ln =
1
</p>
<p>ND
</p>
<p>(
2 Îµsc Ï/q
</p>
<p>1/ND + 1/NA
</p>
<p>)1/2
</p>
<p>, lp =
1
</p>
<p>NA
</p>
<p>(
2 Îµsc Ï/q
</p>
<p>1/ND + 1/NA
</p>
<p>)1/2
</p>
<p>, (21.40)
</p>
<p>and
</p>
<p>l = ln + lp =
[
</p>
<p>2 Îµsc
q
</p>
<p>(
1
</p>
<p>ND
+ 1
</p>
<p>NA
</p>
<p>)
</p>
<p>Ï
</p>
<p>]1/2
</p>
<p>, Ï = Ï0 &minus; V. (21.41)</p>
<p/>
</div>
<div class="page"><p/>
<p>500 21 Bipolar Devices
</p>
<p>Fig. 21.11 Electric field
consistent with the charge
density of Fig. 21.10, in
arbitrary units
</p>
<p>ln
</p>
<p>E
0
</p>
<p>x
</p>
<p>Ï
</p>
<p>0
</p>
<p>&minus; lp
</p>
<p>Multiplying byqAe both sides of the second relation in (21.36) yieldsqND Ae ln =
qNA Ae lp, that represents the global charge conservation in the device. Such a con-
servation is implied by the assumption that E = 0 in the quasi-neutral regions,
as is found by integrating divD = Ï over the space-charge region. In the charge-
conservation relation the widths lp, ln depend on V through (21.40); it follows that
in the reverse-bias condition the device can be assimilated to a non-linear capacitor
where the charge per unit area of the two oppositely-charged sides is, respectively,
Qp = &minus;qNA lp and Qn = qND ln. The differential capacitance per unit area
is defined as C = dQp/dV = &minus;dQn/dV ; from the definition,9 two equivalent
expressions follow,
</p>
<p>C = &minus;qNA
dlp
dV
</p>
<p>= q d(NA lp)
dÏ
</p>
<p>, C = &minus;qND
dln
dV
</p>
<p>= q d(ND ln)
dÏ
</p>
<p>. (21.42)
</p>
<p>Using (21.40), the differential capacitance per unit area of the abrupt p&ndash;n junction is
found to be
</p>
<p>C =
[
</p>
<p>qÎµsc/(2Ï)
</p>
<p>1/ND + 1/NA
</p>
<p>]1/2
</p>
<p>= [(qÎµsc/2)/(1/ND + 1/NA)]
1/2
</p>
<p>[Ï0 (1 &minus; V/Ï0)]1/2
, (21.43)
</p>
<p>which is given the more compact form10
</p>
<p>C = C0
(
</p>
<p>1 &minus; V
Ï0
</p>
<p>)&minus;1/2
, C0 = C(V = 0) =
</p>
<p>[
qÎµsc/(2Ï0)
</p>
<p>1/ND + 1/NA
</p>
<p>]1/2
</p>
<p>. (21.44)
</p>
<p>9 Definition C = dQp/dV is coherent with the choice of the reference in Fig. 21.7. The units of C
are [C] = F cm&minus;2. Compare with the calculation of the MOS capacitance in Sect. 22.3.
10 It is worth reminding that the result holds only in the reverse-bias condition. In the forward-
bias condition the injection of carriers from the quasi-neutral regions into the space-charge region
prevents one from neglecting the contribution of the carrier concentrations to the charge density
and makes the use of (21.44) erroneous.</p>
<p/>
</div>
<div class="page"><p/>
<p>21.5 Avalanche Due to Impact Ionization 501
</p>
<p>Combining (21.44) with (21.41) one derives the interesting relation
</p>
<p>1
</p>
<p>C2
= 2
</p>
<p>qÎµsc
</p>
<p>(
1
</p>
<p>ND
+ 1
</p>
<p>NA
</p>
<p>)
</p>
<p>Ï = l
2
</p>
<p>Îµ2sc
, C = Îµsc
</p>
<p>l
, (21.45)
</p>
<p>namely, the standard expression for the capacitance per unit area of the parallel-plate
capacitor. Such an expression is not limited to the case where the dopant concentration
is piecewise constant; as shown in Sect. 21.6.3, it applies in fact to all cases.
</p>
<p>From the standpoint of circuit design, the capacitance associated to a p&ndash;n junction
is a parasitic effect that hampers the circuit&rsquo;s speed. However, the effect is also
exploited to manufacture voltage-controlled capacitors, called variable capacitors
or varactors. In these devices, that are operated in reverse bias, the geometry is
designed to maximize the capacitance; they are used, e.g., in voltage-controlled
oscillators, parametric amplifiers, and frequency modulation.11 The bias range of
these devices is such that the reverse current is negligibly small; if the modulus of
the reverse bias is made to increase, and is eventually brought outside this range,
carrier multiplication due to impact ionization (Sect. 20.3) takes place; this, as shown
in Sect. 21.5, leads to a strong increase of the reverse current.
</p>
<p>21.5 Avalanche Due to Impact Ionization
</p>
<p>The situation where impact ionization dominates over the other generation-
recombination mechanisms has been illustrated in Sect. 20.3.1, showing that in the
steady-state case the continuity equations for electrons and holes reduce to (20.45).
Such equations are applicable, for instance, to the space-charge region of a reverse-
biased p&ndash;n junction; when the value of |V | becomes large, the increase in the number
of carriers due to impact ionization may give rise to an avalanche phenomenon that
eventually leads to the junction&rsquo;s avalanche breakdown, namely, a strong increase
in the current due to carrier multiplication.12 The absolute value VB of the voltage at
which the phenomenon occurs is called breakdown voltage. To illustrate avalanche,
the one-dimensional case is considered, so that (20.45) become
</p>
<p>dJn
dx
</p>
<p>= kn Jn + kp Jp,
dJp
dx
</p>
<p>= &minus;kn Jn &minus; kp Jp, (21.46)
</p>
<p>11 Varactors are also manufactured using technologies other than the bipolar one; e.g., with MOS
capacitors or metal-semiconductor junctions.
12 If the breakdown is accompanied by current crowding, the junction may be destroyed due to
excessive heating. Special p&ndash;n junctions, called avalanche diodes, are designed to have breakdown
uniformly spread over the surface of the metallurgical junction, to avoid current crowding. Such
devices are able to indefinitely sustain the breakdown condition; they are used as voltage reference
and for protecting electronic circuits against excessively-high voltages.</p>
<p/>
</div>
<div class="page"><p/>
<p>502 21 Bipolar Devices
</p>
<p>where the impact-ionization coefficients kn, kp depend on x through the electric
field E and are determined experimentally.13 To ease the notation the boundaries
of the space-charge region are indicated with a, b; also, considering the reference&rsquo;s
orientation (Fig. 21.7), it is E, Jn, Jp &lt; 0, where the electric field is significant
only for a &le; x &le; b. As in the one-dimensional and steady-state case it is J =
Jn(x) + Jp(x) = const, eliminating Jp from the first equation in (21.46) yields
</p>
<p>dJn
dx
</p>
<p>= kn Jn + kp (J &minus; Jn) = (kn &minus; kp) Jn + kp J , (21.47)
</p>
<p>namely, a first-order equation in Jn containing the yet undetermined parameter J .
The equation is recast as
</p>
<p>dJn
dx
</p>
<p>&minus; dm
dx
</p>
<p>Jn = kp J = kn J &minus;
dm
</p>
<p>dx
J , m =
</p>
<p>&int; x
</p>
<p>a
</p>
<p>(kn &minus; kp) dx &prime; (21.48)
</p>
<p>where m(a) = 0, dm/dx = kn&minus;kp. Multiplying by the integrating factor exp (&minus;m)
and dividing by J transforms (21.48) into
</p>
<p>1
</p>
<p>J
</p>
<p>d
</p>
<p>dx
</p>
<p>[
</p>
<p>Jn exp ( &minus;m)
]
</p>
<p>= kn exp ( &minus;m) &minus;
dm
</p>
<p>dx
exp ( &minus;m), (21.49)
</p>
<p>where &minus;(dm/dx) exp (&minus;m) = d exp (&minus;m)/dx. Integrating (21.49) from a to b and
using m(a) = 0 yields
</p>
<p>Jn(b)
</p>
<p>J
exp [ &minus;m(b)] &minus; Jn(a)
</p>
<p>J
= Yn + exp [ &minus;m(b)] &minus; 1, (21.50)
</p>
<p>where the electron-ionization integral is defined as
</p>
<p>Yn =
&int; b
</p>
<p>a
</p>
<p>kn exp ( &minus;m) dx. (21.51)
</p>
<p>The above result is somewhat simplified by observing that, due to impact ionization,
the concentration of electrons in the conduction band increases from a to b, whereas
that of holes increases from b to a; the concept is rendered in Fig. 21.12: consider a
portion x1 &lt; x &lt; x2 of the space-charge region, where it is assumed for simplicity
that the electric potential is linear. As the electric field is oriented to the left, electrons
(indicated by the black dots) are accelerated to the right, holes (the white dots) are
accelerated to the left. The vertical lines indicate the exchange of energies involved in
impact-ionization events initiated by electrons or holes. An electron transited from
the valence to the conduction band is accelerated by the field and may acquire a
kinetic energy sufficient for initiating an impact-ionization event itself; the same
applies to holes. As a consequence, the number of conduction-band electrons is
</p>
<p>13 An example of model for kn, kp is that proposed by Chynoweth [14]: kn = kns exp (&minus;|Ecn/E|Î²n ),
kp = kps exp ( &minus; |Ecp/E|Î²p ), where the parameters depend on temperature [83, 111].</p>
<p/>
</div>
<div class="page"><p/>
<p>21.5 Avalanche Due to Impact Ionization 503
</p>
<p>Fig. 21.12 Schematic
description of the avalanche
phenomenon. The details are
given in the text
</p>
<p>1
</p>
<p>2
</p>
<p>E
V
</p>
<p>E
C
</p>
<p>x
</p>
<p>xx
</p>
<p>multiplied from left to right, namely, the number of those exiting at x2 is larger than
the number entering at x1; similarly, the number of valence-band holes is multiplied
from right to left. Due to the multiplication mechanism, taking x = b by way of
example, the major contribution to J = Jn(b)+Jp(b) is given by Jn(b). Then, letting
J â Jn(b) in (21.50) and canceling out some terms provides
</p>
<p>1 &minus; 1
Mn
</p>
<p>= Yn, Mn =
Jn(b)
</p>
<p>Jn(a)
&ge; 1, (21.52)
</p>
<p>where Mn is the electron-multiplication factor. The latter is a measure of the impact
ionization&rsquo;s level. As long as Yn &lt; 1, corresponding to a finite value of Mn, the
avalanche condition does not occur; when Yn &rarr; 1, then Mn &rarr; &infin;: in this case, the
injection of a negligibly-small number of electrons at a produces a large electron
current density at b. The operating conditions where Mn is large must be avoided
because an excessive current may damage the device. Note that in the design stage
of the device one first calculates Yn from (21.51), then obtains Mn from (21.52).
Thus, it may well happen that Yn &gt; 1, corresponding to Mn &lt; 0; this outcome is not
physically sound, and simply indicates that the parameters used in the calculation of
the ionization integral (21.51) are not consistent.14
</p>
<p>The analysis of the impact-ionization condition can also be carried out start-
ing with the elimination of Jn from the second equation in (21.46). The equation
corresponding to (21.48) reads
</p>
<p>dJp
dx
</p>
<p>= &minus;kp Jp &minus; kn (J &minus; Jp) =
dm
</p>
<p>dx
Jp &minus; kn J ; (21.53)
</p>
<p>in turn, the equation corresponding to (21.50) is
</p>
<p>Jp(b)
</p>
<p>J
exp [ &minus;m(b)] &minus; Jp(a)
</p>
<p>J
= &minus; Yp
</p>
<p>exp [m(b)]
+ exp [ &minus;m(b)] &minus; 1, (21.54)
</p>
<p>14 This happens, for instance, if a value of |V | larger than the breakdown voltage is used in (21.51).</p>
<p/>
</div>
<div class="page"><p/>
<p>504 21 Bipolar Devices
</p>
<p>with the hole-ionization integral given by
</p>
<p>Yp =
&int; b
</p>
<p>a
</p>
<p>kp exp [m(b) &minus;m] dx. (21.55)
</p>
<p>Letting J â Jp(a) in (21.54) yields
</p>
<p>1 &minus; 1
Mp
</p>
<p>= Yp, Mp =
Jp(a)
</p>
<p>Jp(b)
&ge; 1, (21.56)
</p>
<p>where Mp is the hole-multiplication factor. Using the definition (21.48) of m, the
relation between the ionization integrals is found to be
</p>
<p>Yn = exp [ &minus;m(b)]Yp + 1 &minus; exp [ &minus;m(b)]. (21.57)
</p>
<p>The above shows thatYp = 1 corresponds toYn = 1, namely, the avalanche condition
Yp = 1 for the holes coincides with that of the electrons, as should be.
</p>
<p>21.6 Complements
</p>
<p>21.6.1 Weak-Injection Limit of the Drift-Diffusion Equations
</p>
<p>In the calculation of the I (V ) characteristic of the p&ndash;n junction carried out in
Sect. 21.3.1 it has been stated that in a quasi-neutral region, when the weak-injection
condition holds, the diffusion term of the minority carries dominates over the drift
term. To better discuss this issue, the case of a p-doped region is considered, so
that the majority-carrier concentration is ceq = peq = pp0 and (20.35) become
|p &minus; pp0| âª pp0, |n&minus; np0| âª pp0. The latter may be recast as
</p>
<p>|p &minus; pp0| &le; Î± pp0, |n&minus; np0| &le; Î± pp0, (21.58)
</p>
<p>with Î± âª 1. Indicating with pm, pM the minimum and maximum values of p
imposed by (21.58), one finds pM &minus; pp0 = Î± pp0, pp0 &minus; pm = Î± pp0, whence
</p>
<p>pM = (1 + Î±) pp0, pm = (1 &minus; Î±) pp0. (21.59)
</p>
<p>Similarly, for the minority-carrier concentration one finds nM &minus; np0 = Î± pp0, np0 &minus;
nm = Î± pp0, whence
</p>
<p>nM = np0 + Î± pp0, nm = np0 &minus; Î± pp0. (21.60)
</p>
<p>The maximum absolute variation of p turns out to be:
</p>
<p>pM &minus; pm = 2 Î± pp0. (21.61)</p>
<p/>
</div>
<div class="page"><p/>
<p>21.6 Complements 505
</p>
<p>Instead, the maximum variation of n must be treated with some care. In fact, using
the non-degenerate case one finds
</p>
<p>nM =
n2i
</p>
<p>pp0
+ Î± pp0 = pp0
</p>
<p>(
</p>
<p>n2i
</p>
<p>p2p0
+ Î±
</p>
<p>)
</p>
<p>, (21.62)
</p>
<p>nm =
n2i
</p>
<p>pp0
&minus; Î± pp0 = pp0
</p>
<p>(
</p>
<p>n2i
</p>
<p>p2p0
&minus; Î±
</p>
<p>)
</p>
<p>. (21.63)
</p>
<p>Even for a relatively low dopant concentration, say, NA â pp0 = 1016 cm&minus;3, at room
temperature one has n2i /p
</p>
<p>2
p0 â 10&minus;12, which is much smaller than the reasonable
</p>
<p>values of Î±. It follows nM â Î± pp0, nm â 0, where the limit of nm must be chosen as
such because n is positive definite. In conclusion, the maximum relative variations
of p and n with respect to the equilibrium values are given by
</p>
<p>pM &minus; pm
pp0
</p>
<p>= 2 Î±, nM &minus; nm
np0
</p>
<p>â Î± pp0
np0
</p>
<p>= Î±
p2p0
</p>
<p>n2i
â« 2 Î±. (21.64)
</p>
<p>By way of example, one may let Î± = 10&minus;3, still with NA = 1016 cm&minus;3. While
the maximum relative variation of p is 2 &times; 10&minus;3, that of n is 109; it follows that
the constraint imposed onto the derivative is strong in the case of p, much weaker
for n. Within the same example, the maximum absolute variation is 2 &times; 1013 cm&minus;3
for p and 1013 cm&minus;3 for n, in both cases much smaller than the majority-carrier
concentration (1016 cm&minus;3). The conclusion is that in a quasi-neutral region, under the
weak-injection conditions, the diffusive transport prevails for the minority carriers,
whereas the transport of the majority carriers is dominated by drift. With reference
to the p-doped region considered here, one has Jp â qÎ¼p pE and Jn â qDn gradn,
respectively.
</p>
<p>21.6.2 Shockley&rsquo;s Boundary Conditions
</p>
<p>The derivation of the analytical model of the p&ndash;n junction&rsquo;s I (V ) characteristic,
worked out in Sect. 21.3.1, requires the boundary conditions for the minority-carrier
concentrations at the boundaries of the space-charge region; specifically, one needs
to determine n( &minus; lp) and p(ln). The derivation is based on calculating approximate
expressions for the ratios n(&minus; lp)/n(ln), p(ln)/p(&minus; lp), where the denominators are
majority-carrier concentrations that are in turn approximated with n(ln) â nn0 â ND
and p( &minus; lp) â pp0 â NA.
</p>
<p>To proceed, one considers the electron drift-diffusion equation Jn = qÎ¼n nE +
qDn dn/dx, and observes that in the space-charge region the drift and diffusion
terms have opposite signs; also, their moduli are much larger than that of the
current density. In fact, the latter is small due to the weak-injection condition,</p>
<p/>
</div>
<div class="page"><p/>
<p>506 21 Bipolar Devices
</p>
<p>whereas the terms at the right hand side of the equation are large because the
electric potential and the electron concentration have non-negligible variations over
the space-charge region. It follows that the moduli of the drift and diffusion terms
are comparable to each other: &minus;qÎ¼n nE â qDn dn/dx â« |Jn| and, similarly,
&minus;qÎ¼p pE â &minus;qDp dp/dx â« |Jp| for holes. Now, the approximation is intro-
duced, that consists in neglecting Jn and Jp; this yields equilibrium-like expressions
for the concentrations, n â n(0) exp [qÏ/(kB T )], p â n(0) exp [ &minus; qÏ/(kB T )],
which are used to calculate the ratios sought:
</p>
<p>n( &minus; lp)
n(ln)
</p>
<p>â exp
[
q(V &minus; Ï0)
</p>
<p>kB T
</p>
<p>]
</p>
<p>= n
2
i
</p>
<p>NA ND
exp
</p>
<p>(
qV
</p>
<p>kB T
</p>
<p>)
</p>
<p>, (21.65)
</p>
<p>p(ln)
</p>
<p>p( &minus; lp)
â exp
</p>
<p>[
q(V &minus; Ï0)
</p>
<p>kB T
</p>
<p>]
</p>
<p>= n
2
i
</p>
<p>NA ND
exp
</p>
<p>(
qV
</p>
<p>kB T
</p>
<p>)
</p>
<p>. (21.66)
</p>
<p>The last form of (21.65), (21.66) is obtained from the definition (21.5) of the built-
in potential. Using n(ln) â nn0 â ND and p( &minus; lp) â pp0 â NA along with
np0 = n2i /NA and pn0 = n2i /ND (compare with (21.1,21.2)), finally yields the
Shockley boundary conditions
</p>
<p>n( &minus; lp) â np0 exp
(
</p>
<p>qV
</p>
<p>kB T
</p>
<p>)
</p>
<p>, p(ln) â pn0 exp
(
</p>
<p>qV
</p>
<p>kB T
</p>
<p>)
</p>
<p>. (21.67)
</p>
<p>21.6.3 Depletion Capacitance&mdash;Arbitrary Doping Profile
</p>
<p>The expression of the depletion capacitance worked out in Sect. 21.4 for an abrupt p&ndash;
n junction is extended here to an arbitrary doping profile, still in one dimension. Let
a &lt; x &lt; b be the region where the charge density Ï differs from zero, and assume
for the electric potential that Ï = Ï(a) = const for x &lt; a and Ï = Ï(b) = const
for x &gt; b. Also, it is assumed that there are no single layers or double layers of
charge, whence the electric field E and Ï are continuous. The constancy of Ï in
the outside regions implies the global charge neutrality, as is found by integrating
Îµsc dE/dx = Ï from a to b and using the continuity of E:
</p>
<p>&int; b
</p>
<p>a
</p>
<p>Ï dx = 0. (21.68)
</p>
<p>Thanks to (21.68) one finds, for any x,
</p>
<p>&int; x
</p>
<p>a
</p>
<p>Ï dx +
&int; b
</p>
<p>x
</p>
<p>Ï dx = 0 Q = &minus;
&int; x
</p>
<p>a
</p>
<p>Ï dx =
&int; b
</p>
<p>x
</p>
<p>Ï dx, (21.69)
</p>
<p>which provides the definition of the charge per unit area Q. The definition holds
also if x is outside the interval [a, b]; in this case, however, one finds Q = 0. In the</p>
<p/>
</div>
<div class="page"><p/>
<p>21.6 Complements 507
</p>
<p>following it is assumed that x is internal to the space-charge region. The solution
of the Poisson equation is taken from Prob. 4.2; using E(a) = 0 and the global
charge-neutrality condition after letting Ï = Ï(b) &minus; Ï(a), yields
</p>
<p>Îµsc Ï =
&int; b
</p>
<p>a
</p>
<p>xÏ dx. (21.70)
</p>
<p>If the voltage drop changes by a small amount, Ï &larr; Ï + dÏ , the space-charge
boundaries are modified, a &larr; a + da, b &larr; b + db, whence Q changes as well:15
</p>
<p>dQ =
&int; b+db
</p>
<p>b
</p>
<p>Ï dx = Ï(b) db =
&int; a+da
</p>
<p>a
</p>
<p>Ï dx = Ï(a) da. (21.71)
</p>
<p>On the other hand, from (21.70) it follows
</p>
<p>Îµsc dÏ =
&int; b+db
</p>
<p>a+da
x Ï dx &minus;
</p>
<p>&int; b
</p>
<p>a
</p>
<p>xÏ dx = b Ï(b) db &minus; a Ï(a) da = (b &minus; a) dQ.
(21.72)
</p>
<p>Thus, the capacitance per unit area of the space-charge region is
</p>
<p>C = dQ
dÏ
</p>
<p>= Îµsc
b &minus; a , (21.73)
</p>
<p>which is the expected generalization of (21.45). Note that the absence of charge layers
makes the variation dQ to depend on the variations in a and b only. As a consequence
it is a = a(Ï), b = b(Ï), whence C = C(Ï). If Ï and Ï(x) are prescribed, the
values of a, b are determined by the system of Eqs. (21.68) and (21.70).
</p>
<p>It is interesting to note that if the charge density has a power form, Ï &sim; xn,
then Ï depends on the (n + 2)th power of b &minus; a. Consider by way of example a
diffused junction, namely, a junction obtained, e.g., by diffusing a dopant of the p type
into a uniform n-type substrate. Expanding Ï to first order around the metallurgical
junction, and using the full-depletion and ASCE approximations, yields Ï â k x for
&minus;l/2 &lt; x &lt; l/2 and Ï = 0 elsewhere. Using (21.70) and (21.72) then yields
</p>
<p>Îµsc Ï =
1
</p>
<p>12
k l3, C = C0
</p>
<p>(
</p>
<p>1 &minus; V
Ï0
</p>
<p>)&minus;1/3
, C0 =
</p>
<p>(
k Îµ2sc
</p>
<p>12Ï0
</p>
<p>)1/3
</p>
<p>. (21.74)
</p>
<p>The general expression (21.72) of the capacitance per unit area of the space-charge
region finds a useful application in a measuring technique for the doping profile
(Sect. 25.5).
</p>
<p>15 After the change in the boundaries&rsquo; positions, x in (21.69) is still internal to the space-charge
region.</p>
<p/>
</div>
<div class="page"><p/>
<p>508 21 Bipolar Devices
</p>
<p>21.6.4 Order of Magnitude of Junction&rsquo;s Parameters
</p>
<p>Still considering an abrupt, p&ndash;n silicon junction with NA = 1016 cm&minus;3, ND = 1015
cm&minus;3, the built-in potential at room temperature is
</p>
<p>Ï0 =
kB T
</p>
<p>q
log
</p>
<p>(
NA ND
</p>
<p>n2i
</p>
<p>)
</p>
<p>â 0.65 V (21.75)
</p>
<p>(compare with (21.5)). The carrier mobilities have been estimated in Sect. 19.6.6; in
fact, hole mobility is smaller than electron mobility and, as outlined in Sect. 20.5.3,
the mobility degradation due to impurity scattering is expected to vary from one
side of the junction to the other because the doping concentrations are different. The
experimental minority-carrier mobilities for the doping concentrations and temper-
ature considered here are Î¼n â 1000 cm2 V&minus;1 s&minus;1 in the p region and Î¼p â 500
cm2 V&minus;1 s&minus;1 in the n region [103, Sect. 1.5], whence
</p>
<p>Dn =
kB T
</p>
<p>q
Î¼n â 26 cm2 s&minus;1, Dp =
</p>
<p>kB T
</p>
<p>q
Î¼p â 13 cm2 s&minus;1. (21.76)
</p>
<p>The experimental values of the minority-carrier lifetimes are Ïn â 5 &times; 10&minus;5 s and
Ïp â 2 &times; 10&minus;5 s. The corresponding diffusion lengths (21.24), (21.28) are
</p>
<p>Ln =
&radic;
</p>
<p>Ïn Dn â 360 Î¼m, Lp =
&radic;
</p>
<p>Ïp Dp â 160 Î¼m. (21.77)
The above values provide for the saturation current density (21.30)
</p>
<p>Js = q
(
Dp pn0
</p>
<p>Lp
+ Dn np0
</p>
<p>Ln
</p>
<p>)
</p>
<p>â 14 pA cm&minus;2. (21.78)
</p>
<p>From (21.41), the width of the depletion region at zero bias is found to be
</p>
<p>l(V = 0) = ln + lp =
[
</p>
<p>2 Îµsc
q
</p>
<p>(
1
</p>
<p>ND
+ 1
</p>
<p>NA
</p>
<p>)
</p>
<p>Ï0
</p>
<p>]1/2
</p>
<p>â 1 Î¼m, (21.79)
</p>
<p>with ln/lp = NA/ND = 10. The permittivity of silicon Îµsc = 11.7 &times; Îµ0 has been
used, with Îµ0 â 8.854 &times; 10&minus;14 F cm&minus;1 the vacuum permittivity. Finally, the value
of the differential capacitance per unit area at zero bias (21.44) is
</p>
<p>C0 =
[
</p>
<p>qÎµsc/(2Ï0)
</p>
<p>1/ND + 1/NA
</p>
<p>]1/2
</p>
<p>= Îµsc
l(V = 0) â 11 nF cm
</p>
<p>&minus;2. (21.80)
</p>
<p>Problems
</p>
<p>21.1 Evaluate the built-in potential at room temperature in an abrupt p&ndash;n junction
with NA = 1016 cm&minus;3 and ND = 1015 cm&minus;3.
</p>
<p>21.2 Show that avalanche due to impact ionization is possible only if both
coefficients kn and kp are different from zero.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 22
</p>
<p>MOS Devices
</p>
<p>22.1 Introduction
</p>
<p>The mathematical model of semiconductor devices, derived in Chap. 19, is applied
here to the description of two fundamental devices of the insulated-gate type: the
MIS capacitor, whose most important implementation is the MOS capacitor, and
the IGFET, whose most important implementation is the MOSFET. Both devices
can be realized starting from either a p-doped or an n-doped substrate; only the first
realization is illustrated here: the extension of the theory to the other one is immediate.
The analysis of the MOS capacitor is carried out using the simple example of a
one-dimensional device in steady state, with the hypotheses of non-degeneracy and
complete ionization, that lend themselves to an analytical treatment. Observing that
in a steady-state condition the device is in equilibrium, the theory needs the solution
of Poisson&rsquo;s equation only. From the solution of the latter, the device&rsquo;s capacitance
is calculated, followed by a number of other important relations, that are useful
in the subsequent treatment of the MOSFET. The theory of the MOSFET is then
tackled in two dimensions and in steady-state conditions, first deriving a general
expression for the channel current that holds in the case of a well-formed channel.
The calculation is then completed by introducing the gradual-channel approximation:
the differential conductances are derived first, followed by the expression of the
drain current as a function of the applied voltages. A further simplification leads
to the linear&ndash;parabolic model, which is widely used in the semiqualitative analyses
of circuits. The complements address the solution of the Poisson equation in the
channel when a non-equilibrium condition holds, to provide a formal proof of the
relation between the surface and quasi-Fermi potentials used in the gradual-channel
approximation; finally, a few phenomena that are not accounted for by the gradual-
channel approximation are discussed, and the neglect of the dependence on position
of the average carrier mobility is justified.
</p>
<p>&copy; Springer Science+Business Media New York 2015 509
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_22</p>
<p/>
</div>
<div class="page"><p/>
<p>510 22 MOS Devices
</p>
<p>t
i
</p>
<p>gate contact bulk contactinsulator
</p>
<p>contact&minus;insulator interface
</p>
<p>semiconductor&minus;insulator interface
</p>
<p>x0
</p>
<p>semiconductor
</p>
<p>Fig. 22.1 Cross section of a metal&ndash;insulator&ndash;semiconductor capacitor. The thickness of the insulator
layer is not realistic: in real devices the layer is much thinner than the contacts
</p>
<p>22.2 Metal&ndash;Insulator&ndash;Semiconductor Capacitor
</p>
<p>The Metal&ndash;Insulator&ndash;Semiconductor (MIS) capacitor is a fundamental device, that
constitutes the basis for the field-effect transistors used in the fabrication of inte-
grated circuits. The device has also extensively been used for studying the properties
of semiconductor surfaces [103]. A one-dimensional version of it is sketched in
Fig. 22.1: the structure is fabricated by depositing or thermally growing (Chap. 24)
an insulator layer over a semiconductor substrate. The fabrication process must ob-
tain an electrically clean interface; in fact, the number of localized electronic states
at the interface must be kept to a minimum to avoid carrier trapping&ndash;detrapping pro-
cesses. The contact deposited onto the insulator is called gate contact, the other one
is called bulk contact.
</p>
<p>In the standard silicon technology, the insulator is obtained by thermally growing
silicon dioxide (Sect. 24.2). For this reason, the thickness of the insulator is indicated
in the following with tox instead of the generic symbol ti used in Fig. 22.1; by the
same token, the insulator&rsquo;s permittivity is indicated with Îµox, and the device is called
MOS capacitor. In the last years, the progressive scaling down in the size of semi-
conductor devices has brought the insulator thickness to the range of nanometers. A
smaller thickness has the advantage of providing a larger capacitance; however, it
may eventually lead to dielectric breakdown and leakage by quantum tunneling. Sil-
icon dioxide, which has been used as a gate insulator for decades, is being replaced
in advanced devices with insulating layers made of materials having a larger permit-
tivity (high-k dielectrics). Such layers are obtained by deposition (Sect. 24.5). Still
with reference to the silicon technology, the conductive layers are made of metals,
heavily-doped polycrystalline silicon, or metal silicides; here they will be indicated
with the generic term &ldquo;metal&rdquo;.
</p>
<p>Like in the case of p&ndash;n junctions, the theory of the MOS capacitor is carried
out with reference to a simplified structure, where the device is one dimensional</p>
<p/>
</div>
<div class="page"><p/>
<p>22.2 Metal&ndash;Insulator&ndash;Semiconductor Capacitor 511
</p>
<p>Fig. 22.2 The three materials
forming the MOS capacitor
shown separately. The
symbols&rsquo; meaning is
illustrated in the text
</p>
<p>0
E
</p>
<p>C
E m
</p>
<p>A
ox
</p>
<p>E
C
</p>
<p>ox
</p>
<p>0
E
</p>
<p>0
E
</p>
<p>E
F
</p>
<p>E
F
</p>
<p>m E
F
</p>
<p>ox C
E
</p>
<p>E
Fi
</p>
<p>V
E
</p>
<p>W
</p>
<p>E
V
ox
</p>
<p>metal oxide semiconductor
</p>
<p>A
</p>
<p>and aligned with the x axis; in this case the semiconductor&ndash;insulator interface is a
plane normal to x and, as shown in Fig. 22.1, its position is made to coincide with
the reference&rsquo;s origin. A constant dopant concentration is present in the semicon-
ductor region; to further simplify the analytical approach one also assumes that the
conditions of non-degeneracy and complete ionization hold.
</p>
<p>To describe the functioning of the device it is necessary to consider the fact that,
in a region where the important electric phenomena occur, different materials are
brought into an intimate contact. With reference to Fig. 22.2, the three materials (gate
metal, oxide, and semiconductor) are initially considered separate from each other,
and in the equilibrium condition. The left part of the figure shows the conduction
band of the metal, with EmC the band&rsquo;s lower edge and E
</p>
<p>m
F the metal&rsquo;s Fermi level.
</p>
<p>Due to the form of the Fermi-Dirac statistics, the probability that an electron&rsquo;s energy
exceeds EmF is small; remembering the discussion of Sect. 7.2, the minimum energy
necessary for an electron to transit from the metal into vacuum is the metal work
function W = E0 &minus; EmF , with E0 the vacuum level (left part of Fig. 22.2). For an
insulator or a semiconductor, the electrons with maximum energy belong to states
in the vicinity of the lower edge of the conduction band, EoxC (center) or EC (right);
in this case the minimum energy necessary for transiting into vacuum is the electron
affinityAox = E0&minus;EoxC orA = E0&minus;EC , respectively. The semiconductor considered
in the figure is uniformly doped of the p type, as shown by the fact that the Fermi
level is below the intrinsic Fermi level EFi (Sect. 18.4.2). However, the analysis
carried out here applies also to a semiconductor of the n type.
</p>
<p>When the materials are brought into contact, they form a single, non-uniform
system; as a consequence, in the equilibrium condition the Fermi levels must align
with each other. On the other hand the vacuum levels must align as well, and the bands
must adapt to compensate for a possible charge redistribution that occurs when the
materials contact each other. The situation is similar to that represented in Fig. 21.3
for the p&ndash;n junction. The values of the parameters W ,A, . . . selected for drawing
Fig. 22.2 fulfill the relation
</p>
<p>W &minus; A = EC &minus; EF . (22.1)</p>
<p/>
</div>
<div class="page"><p/>
<p>512 22 MOS Devices
</p>
<p>Fig. 22.3 The three materials
forming the MOS capacitor
after being brought into
contact. The symbols&rsquo;
meaning is illustrated in the
text
</p>
<p>0
E
</p>
<p>A
ox
</p>
<p>E
F
</p>
<p>E
V
ox
</p>
<p>E
C
</p>
<p>ox
</p>
<p>C
E m
</p>
<p>C
E
</p>
<p>E
Fi
</p>
<p>V
E
</p>
<p>metal
</p>
<p>W
</p>
<p>oxide semiconductor
</p>
<p>A
</p>
<p>As a consequence, there is no need for the bands to modify their shape; as shown
in Fig. 22.3, which represents the situation after the materials have been brought into
contact, the bands do not deform. The condition where the semiconductor&rsquo;s bands
are everywhere parallel to the Fermi level is indicated with flat-band condition.1 It is
important to remark that condition (22.1) seldom occurs in realistic cases; however,
as shown below, the case W &minus;A ï¿½= EC &minus;EF is easily incorporated into the analysis.
</p>
<p>When the bulk contact is considered, Figs. 22.2 and 22.3 must be completed
by adding the band structure of the contact&rsquo;s material to the right of that of the
semiconductor. Assuming that the gate and bulk contacts are made of the same
material, the structure to be added is identical to that already present on the left part
of the figures. In the interior of each material, due to spatial uniformity, the electric
potential is piecewise constant, thus the electric field is zero.
</p>
<p>Consider now the case where a voltage VG is applied between the gate and bulk
contacts; the voltage reference is such that VG &gt; 0 when the electric potential of
the gate contact is larger than that of the bulk contact, and vice versa. In steady-
state conditions, the insulator prevents a current from flowing through the device;
therefore, during the transient consequent to the application ofVG, the electric charge
adjusts itself to the new boundary conditions. At the end of the transient the device
is again in an equilibrium condition, while the form of the bands is different from
that of Fig. 22.3. Similarly, the electric potential in the oxide and semiconductor is
not constant any longer; its form is found by solving the Poisson equation in each
region.
</p>
<p>22.2.1 Surface Potential
</p>
<p>The solution of the Poisson equation in the semiconductor region follows the same
pattern as for the p&ndash;n junction (Sect. 21.2.1). Here a uniformly p-doped region
</p>
<p>1 The form of (22.1) is general enough to hold for both p- and n-type semiconductors.</p>
<p/>
</div>
<div class="page"><p/>
<p>22.2 Metal&ndash;Insulator&ndash;Semiconductor Capacitor 513
</p>
<p>is considered; its extension along the x axis is large, so that, far away from the
semiconductor&ndash;insulator interface, the semiconductor behaves as if it were isolated.
This fixes the carrier-equilibrium concentrations in the bulk; the asymptotic value
of the electric potential is set to zero, Ï( +&infin;) = 0 whence, remembering that the
non-degeneracy and complete-ionization conditions hold, it is
</p>
<p>p(0) = p( +&infin;) = pp0 â NA, n(0) = n( +&infin;) = np0 â
n2i
</p>
<p>NA
. (22.2)
</p>
<p>The Poisson equation in the semiconductor then reads
</p>
<p>u&prime;&prime; = 1
L2A
</p>
<p>A(u), A(u) = n
2
i
</p>
<p>N2A
</p>
<p>[
</p>
<p>exp (u) &minus; 1
]
</p>
<p>+ 1 &minus; exp ( &minus; u), (22.3)
</p>
<p>with LA the Debye length for the holes defined in (21.12). The normalized charge
density A(u) has the same sign as u (compare with Sect. 21.2.1). Multiplying by
u&prime; both sides of the first equation in (22.3), transforming its left hand side into
u&prime;&prime; u&prime; = (1/2)
</p>
<p>[
</p>
<p>(u&prime;)2
]&prime;
</p>
<p>, and integrating from x &ge; 0 to +&infin;, yields
</p>
<p>(
</p>
<p>u&prime;
)2 = 2
</p>
<p>L2A
B(u), B(u) = n
</p>
<p>2
i
</p>
<p>N2A
</p>
<p>[
</p>
<p>exp (u) &minus; 1 &minus; u
]
</p>
<p>+ u + exp ( &minus; u) &minus; 1.
(22.4)
</p>
<p>Following the same reasoning as for (21.10), one finds that B is non negative
and u monotonic. However, in contrast with the case of the p&ndash;n junction, where the
sign of u&prime; is positive due to the boundary condition at x &rarr; &minus;&infin;, here u may either
increase or decrease monotonically; in fact, the sign of u&prime; is fixed by the boundary
condition VG, which in turn may be either positive or negative. In conclusion, one
finds
</p>
<p>u&prime; = &plusmn;
&radic;
</p>
<p>2
</p>
<p>LA
F (u), F (u) =
</p>
<p>&radic;
</p>
<p>n2i
</p>
<p>N2A
</p>
<p>[
</p>
<p>exp (u) &minus; 1 &minus; u
]
</p>
<p>+ u + exp ( &minus; u) &minus; 1,
</p>
<p>(22.5)
</p>
<p>where the sign must be found on a case-by-case basis. Separating (22.5), finally
yields
</p>
<p>du
</p>
<p>F (u)
= &plusmn;
</p>
<p>&radic;
2
</p>
<p>LA
dx, (22.6)
</p>
<p>which must be solved numerically because it has no analytical solution.2 Much in-
formation, however, is gained directly from (22.5), without the need of integrating
</p>
<p>2 The numerical evaluation from (22.6) of the inverse relation x = x(u) is straightforward, though.
Letting Î¾ =
</p>
<p>&radic;
2 x/LA, Î¾0 = 0, u0 = us , F0 = F (u0), it is uk+1 = uk â Î´u, Fk+1 = F (uk+1), and
</p>
<p>Î¾k+1 = Î¾k + (1/Fk + 1/Fk+1) Î´u/2, with k = 0, 1, . . . .</p>
<p/>
</div>
<div class="page"><p/>
<p>514 22 MOS Devices
</p>
<p>Fig. 22.4 The cylinder used
to calculate the relation
between electric displacement
and charge per unit area
across an interface
</p>
<p>n  = &minus;i
L
</p>
<p>n  = i
R
</p>
<p>c
</p>
<p>interface
</p>
<p>(22.6). To this purpose, one notes that the electric potential is continuous at the
semiconductor&ndash;oxide interface; in fact, the normalized charge density in the semi-
conductor (22.3) has no charge layers in it, hence it can not contribute to a double
charge layer at the interface. As a consequence, one can adopt the same symbol Ïs for
the electric potential at x = 0, without distinguishing between the two sides of the
interface; Ïs is called surface potential, whilst us = qÏs/(kB T ) is the normalized
surface potential. In contrast, the electric field is discontinuous at the same interface;
for this reason, one defines
</p>
<p>u&prime;s = lim
x&rarr;0+
</p>
<p>du
</p>
<p>dx
, Es = &minus;
</p>
<p>kB T
</p>
<p>q
u&prime;s , Eox = &minus; lim
</p>
<p>x&rarr;0&minus;
dÏ
</p>
<p>dx
. (22.7)
</p>
<p>The relation between Es and Eox is found by considering a cylinder of thickness c
placed across the semiconductor&ndash;oxide interface, such that the unit vector nR normal
to the right face is parallel to the unit vector i of the x axis, whereas the unit vector nL
normal to the left face is antiparallel to i (Fig. 22.4). Letting Ae be the common area
of the two faces, the total charge within the cylinder is Ae Q, with Q the charge per
unit area. Integrating divD = Ï over the cylinder&rsquo;s volume and using (A.23) yields
</p>
<p>Ae Q =
&int;
</p>
<p>Ae
</p>
<p>D &middot; n dAe = Ae [DL i &middot; ( &minus; i) +DR i &middot; i] = Ae (DR &minus;DL) , (22.8)
</p>
<p>with DR
(
</p>
<p>DL
)
</p>
<p>the electric displacement on the right (left) face. From D = Îµ E one
then finds Q = Îµsc ER &minus; Îµox EL. It has been shown above that there are no charge
layers on the semiconductor&rsquo;s side; as for the oxide layer, in principle it should
be free of charges, although some contaminants may be present (Sect. 24.1). Here
it is assumed that the oxide is free of charge; in conclusion, letting the cylinder&rsquo;s
thickness c go to zero, one obtains Q &rarr; 0, whence, using the limits (22.7),
</p>
<p>Îµsc Es = Îµox Eox. (22.9)</p>
<p/>
</div>
<div class="page"><p/>
<p>22.2 Metal&ndash;Insulator&ndash;Semiconductor Capacitor 515
</p>
<p>To find Eox one observes that in a one-dimensional medium free of charge the
electric potential is linear, whence Eox is given by the negative potential drop across
the oxide divided by the oxide thickness tox. To complete the analysis it is then
necessary to consider the interface between oxide and gate metal.
</p>
<p>In the interior of the metal the electric potential is uniform; its value with respect to
the metal of the bulk contact is VG. However, in the solution of the Poisson equation
within the semiconductor, the asymptotic condition Ï( +&infin;) = 0 has been chosen,
which holds inside the semiconductor region; the surface potential Ïs is referred to
such a zero as well. It follows that VG and Ïs are referred to two different zeros.
Remembering the discussion carried out in Sect. 21.2.2, the difference between the
external zero (namely, that within the bulk contact) and the internal zero (given
by the asymptotic condition) is the built-in potential Î¦mp between the bulk contact
and the p-type semiconductor; thus, the gate voltage referred to the internal zero
is V &prime;G = VG &minus; Î¦mp. Also, the electric potential is continuous across the interface
between the oxide and the gate metal, because no double layer is present there. In
contrast, as E = 0 within the metal while Eox ï¿½= 0, the electric field is generally
discontinuous; in fact, a charge layer of density
</p>
<p>Ïm = Qm Î´(x + t&minus;ox), (22.10)
</p>
<p>with Qm the charge per unit area of the metal, builds up at the gate&ndash;metal&rsquo;s surface.
In conclusion, the electric field within the oxide reads
</p>
<p>Eox =
V &prime;G &minus; Ïs
</p>
<p>tox
. (22.11)
</p>
<p>22.2.2 Relation Between Surface Potential and Gate Voltage
</p>
<p>Combining (22.5), (22.7), (22.9), and (22.11) one finds
</p>
<p>Cox
(
</p>
<p>V &prime;G &minus; Ïs
)
</p>
<p>= âÎµsc
kB T
</p>
<p>q
</p>
<p>&radic;
2
</p>
<p>LA
F
(
</p>
<p>Ïs
)
</p>
<p>, Cox =
Îµox
</p>
<p>tox
, (22.12)
</p>
<p>where Cox is the oxide capacitance per unit area, and F (Ïs) is obtained by replacing
u with qÏs/(kB T ) in the second relation of (22.5). The left hand side of (22.12) is
the charge per unit area Qm in the gate metal. This is easily found by considering the
same cylinder as above, this time placed across the metal&ndash;oxide interface. Integrating
divD = Ï over the cylinder&rsquo;s volume, using (22.10), and observing that DL = 0
because the metal&rsquo;s interior is equipotential, yields
</p>
<p>Ae Qm =
&int;
</p>
<p>Ae
</p>
<p>D &middot; n dAe = Ae DR = Ae Cox
(
</p>
<p>V &prime;G &minus; Ïs
)
</p>
<p>. (22.13)</p>
<p/>
</div>
<div class="page"><p/>
<p>516 22 MOS Devices
</p>
<p>Fig. 22.5 Normalized surface
potential us in an MOS
capacitor with a p-type
substrate (NA = 1016 cm&minus;3),
as a function of the
normalized gate voltage u&prime;G
</p>
<p>-200 0 200 400 600
Normalized gate voltage
</p>
<p>-10
</p>
<p>0
</p>
<p>10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>N
o
rm
</p>
<p>al
iz
</p>
<p>ed
 s
</p>
<p>u
rf
</p>
<p>ac
e 
</p>
<p>p
o
te
</p>
<p>n
ti
</p>
<p>al
</p>
<p>2 u
F
 = 27.6
</p>
<p>Due to the global charge neutrality, the following relation holds between the
charge per unit area in the gate metal, Qm, and that within the semiconductor, Qsc:
</p>
<p>Qm +Qsc = 0, Qsc =
&int; &infin;
</p>
<p>0
q
(
</p>
<p>p &minus; n&minus;NA
)
</p>
<p>dx = &minus;Cox
(
</p>
<p>V &prime;G &minus; Ïs
)
</p>
<p>.
</p>
<p>(22.14)
</p>
<p>In conclusion, (22.12) provides the relation between surface potential and gate
voltage. When Ïs = 0, the electric potential vanishes everywhere in the semicon-
ductor, namely, V &prime;G = 0 corresponds to the flat-band condition. When V &prime;G &gt; 0, the
charge in the gate metal is positive; as a consequence, the left hand side of (22.12) is
positive as well, whence V &prime;G &gt; Ïs and the positive sign must be chosen at the right
hand side. The opposite happens when V &prime;G &lt; 0. An example of the Ïs = Ïs(V &prime;G)
relation is given in Fig. 22.5, showing the normalized surface potential us in an
MOS capacitor as a function of the normalized gate voltage u&prime;G = qV&prime;G/(kB T ). The
semiconductor&rsquo;s doping is of the p type with NA = 1016 cm&minus;3, corresponding to
2 uF = 2 qÏF /
</p>
<p>(
</p>
<p>kB T
)
</p>
<p>= log (pp0/np0) â 27.6.
The Ïs = Ïs
</p>
<p>(
</p>
<p>V &prime;G
)
</p>
<p>relation lends itself to identifying different functioning regimes
of the MOS capacitor. This identification can be carried out more accurately basing
upon the values of the electron and hole concentrations at the semiconductor surface,
ns = n(x = 0) and ps = p(x = 0). In the non-degenerate conditions considered
here, the expressions of the surface concentrations read
</p>
<p>ns = np0 exp
(
</p>
<p>us
)
</p>
<p>= ni exp
(
</p>
<p>us &minus; uF
)
</p>
<p>, ps = pp0 exp
(
</p>
<p>&minus; us
)
</p>
<p>= ni exp
(
</p>
<p>uF &minus; us
)
</p>
<p>.
</p>
<p>(22.15)
</p>
<p>Depending on the value of us , several functioning regimes are identified, which
are listed in Table 22.1. The regimes&rsquo; designations are given by comparing the
carrier concentrations at the surface with the intrinsic and asymptotic ones. When
us &lt; 0 the majority-carrier surface concentration (holes, in the example used here)
exceeds the asymptotic one; the regime is called accumulation. When us = 0, both</p>
<p/>
</div>
<div class="page"><p/>
<p>22.2 Metal&ndash;Insulator&ndash;Semiconductor Capacitor 517
</p>
<p>Table 22.1 MOS capacitor, p substrate&mdash;functioning regimes
</p>
<p>Norm. surface potential Surface concentrations Designation
</p>
<p>us &lt; 0 ns &lt; np0 &lt; ni &lt; pp0 &lt; ps Accumulation
</p>
<p>us = 0 ns = np0 &lt; ni &lt; pp0 = ps Flat band
0 &lt; us &lt; uF np0 &lt; ns &lt; ni &lt; ps &lt; pp0 Depletion
</p>
<p>us = uF np0 &lt; ns = ni = ps &lt; pp0 Mid gap
uF &lt; us &lt; 2 uF np0 &lt; ps &lt; ni &lt; ns &lt; pp0 Weak inversion
</p>
<p>us = 2 uF np0 = ps &lt; ni &lt; ns = pp0 Threshold
2 uF &lt; us ps &lt; np0 &lt; ni &lt; pp0 &lt; ns Strong inversion
</p>
<p>majority- and minority-carrier concentrations equal the corresponding asymptotic
concentrations everywhere, and the already-mentioned flat-band condition holds.
For 0 &lt; us &lt; uF , the majority-carrier concentration is smaller than the asymptotic
one, while the minority-carrier concentration is smaller than the intrinsic one. By
continuity, the majority-carrier concentrations is smaller than the asymptotic one not
only at the semiconductor&rsquo;s surface, but also in a finite region of width xd , which is
therefore depleted from carriers; for this reason, the condition 0 &lt; us &lt; uF is called
depletion regime, and xd is called depletion width.3 When us = uF , both majority-
and minority-carrier concentrations at the surface equal the intrinsic concentration;
remembering that in an intrinsic semiconductor the Fermi level practically coin-
cides with the gap&rsquo;s midpoint (Sect. 18.3), this regime is called mid gap. When
uF &lt; us &lt; 2 uF , the minority-carrier concentration at the surface exceeds that of the
majority carriers; however, it is still lower than the asymptotic concentration of the
majority carriers: the regime is called weak inversion. When us = 2 uF , the surface
concentration of the minority carriers equals the asymptotic concentration of the ma-
jority carriers, and vice versa; the regime is called threshold of the strong inversion, or
simply threshold. Finally, when us &gt; 2 uF , the minority-carrier concentration at the
surface exceeds the asymptotic concentration of the majority carriers, and the regime
is called strong inversion. In Fig. 22.5 the normalized surface potential at threshold,
2 uF , is marked by the horizontal bar; one notes that in the strong-inversion regime
the surface potential rapidly saturates as the gate voltage increases.
</p>
<p>The form of the electric potential and charge density is shown in Fig. 22.6 for
the accumulation regime. The upper part of the figure shows the charge density,
which is schematically represented by a negative charge layer at the metal&ndash;oxide
interface and by the thicker, positive layer at the semiconductor oxide interface. The
lower part of the figure shows the electric potential along with the band structure
of the semiconductor; note that two different vertical axes are used, in such a way
that energy increases upwards and the electric potential increases downwards. The
</p>
<p>3 The depletion width xd is conceptually the same thing as the extension lp of the space-charge
region on the p side of a metallurgical junction (Sect. 21.2.2). A different symbol is used to avoid
confusion in the analysis of the MOSFET (Sect. 22.6).</p>
<p/>
</div>
<div class="page"><p/>
<p>518 22 MOS Devices
</p>
<p>Fig. 22.6 Schematic
representation of the charge
density and electric potential
in a p-substrate MOS
capacitor in the accumulation
regime
</p>
<p>p
</p>
<p>tox
</p>
<p>x
</p>
<p>Ï
</p>
<p>&minus;type semiconductor
</p>
<p>E
</p>
<p>E
</p>
<p>E
</p>
<p>C
</p>
<p>V
</p>
<p>F
</p>
<p>x
</p>
<p>Ï
</p>
<p>metal
</p>
<p>oxide
</p>
<p>E
Fi
</p>
<p>Ï
F
</p>
<p>V&rsquo;
G
</p>
<p>Ï
s
</p>
<p>E
</p>
<p>Fig. 22.7 Schematic
representation of the charge
density and electric potential
in a p-substrate MOS
capacitor in the mid-gap
condition
</p>
<p>&minus;type semiconductorp
</p>
<p>metal
</p>
<p>E
</p>
<p>E
</p>
<p>E
</p>
<p>C
</p>
<p>V
</p>
<p>F
</p>
<p>x
</p>
<p>E
</p>
<p>Ï
</p>
<p>V&rsquo;
G
</p>
<p>Ï
s
</p>
<p>oxide
</p>
<p>Ï
F
</p>
<p>E
Fi
</p>
<p>tox
</p>
<p>x
</p>
<p>Ï
</p>
<p>&minus;q N
A
</p>
<p>x d
</p>
<p>zero of the electric potential coincides with the horizontal part of the dashed line
(
</p>
<p>in fact, here it is V &prime;G &lt; Ïs &lt; 0
)
</p>
<p>. The mid-gap condition, V &prime;G &gt; 0, Ïs = ÏF , is
illustrated in Fig. 22.7, whose general description is similar to that of Fig. 22.6; here
the charge layer on the gate metal is positive, and balances the negative charge of
the semiconductor. Due to the depletion that occurs in the region adjacent to the
semiconductor&ndash;oxide interface, the charge density is dominated by the contribution
from the negative acceptor ions, Ï â &minus;qNA. In the figure, the charge density of
the semiconductor is schematically indicated by the shaded area, that corresponds
to a charge per unit area equal to &minus;qNA xd . Finally, Fig. 22.8 shows the form of the</p>
<p/>
</div>
<div class="page"><p/>
<p>22.2 Metal&ndash;Insulator&ndash;Semiconductor Capacitor 519
</p>
<p>Fig. 22.8 Schematic
representation of the charge
density and electric potential
in a p-substrate MOS
capacitor at threshold
</p>
<p>tox
</p>
<p>x
</p>
<p>Ï
</p>
<p>&minus;q N
A
</p>
<p>dx
</p>
<p>metal
</p>
<p>E
</p>
<p>E
</p>
<p>E
</p>
<p>C
</p>
<p>V
</p>
<p>F
</p>
<p>E
</p>
<p>Ï
</p>
<p>x
</p>
<p>E
Fi
</p>
<p>Ï
F
</p>
<p>Ï
s
</p>
<p>V&rsquo;
G
</p>
<p>oxide
</p>
<p>&minus;type semiconductorp
</p>
<p>electric potential and charge density for the threshold condition, V &prime;G &gt; 0, Ïs = 2 ÏF .
Again, the general description is similar to that of Figs. 22.6 and 22.7; here, there
are two contributions to the negative charge of the semiconductor: the first one
comes from the contribution of the negative acceptor ions, whose charge density is
schematically indicated by the shaded area of width xd (note that, due to the larger
value of VG, the depletion width is larger than that of the mid-gap condition). The
second contribution to the semiconductor&rsquo;s charge is due to the electrons, whose
concentrations at the interface or near it is sufficiently large to be significant; they
form a negative layer, called inversion layer, whose width, albeit larger than that of
the positive layer located at the metal&ndash;oxide interface,4 is much smaller than xd .
</p>
<p>Numerical solutions of the semiconductor-device model show that, with the ex-
ception of the accumulation regime, the semiconductor region of a uniformly-doped
MOS capacitor can be partitioned into a space-charge and a quasi-neutral region; the
quasi-neutral region behaves as an isolated, uniform semiconductor, whereas in the
volume of the space-charge5 region the charge density is essentially dominated by
the ionized dopants. In the threshold and strong-inversion regimes, the layer of mo-
bile charges near the semiconductor&ndash;oxide interface gives a significant contribution,
which must be accounted for; it can approximated as a charge layer at the interface.
Considering the range Ïs &gt; 0 only, namely, excluding the accumulation regime for
</p>
<p>4 The width of the region where the charged layer at the metal&ndash;oxide interface is significant is of
the order of 1 nm. That of an inversion layer is of the order of 5 nm; an example is given below,
with reference to Fig. 22.13.
5 With reference to MOS devices, the space-charge region is also called depleted region.</p>
<p/>
</div>
<div class="page"><p/>
<p>520 22 MOS Devices
</p>
<p>the p-substrate MOS capacitor, the charge per unit area in the semiconductor is found
to be
</p>
<p>Qsc =
&int; &infin;
</p>
<p>0
Ï dx â
</p>
<p>&int; xd
</p>
<p>0
Ï dx â &minus;q
</p>
<p>&int; xd
</p>
<p>0
</p>
<p>(
</p>
<p>n+NA
)
</p>
<p>dx = Qi +Qb, (22.16)
</p>
<p>where the first approximation is due to neglecting the charge of the quasi-neutral
region, the second one to neglecting the holes in the space-charge region. Quantities
Qi ,Qb &lt; 0 are, respectively, the integral of&minus;qn and&minus;qNA; they are called inversion
charge per unit area and bulk charge per unit area.
</p>
<p>22.3 Capacitance of the MOS Structure
</p>
<p>The capacitance per unit area of the MOS structure is given by6
</p>
<p>C = dQm
dVG
</p>
<p>= dQm
dV &prime;G
</p>
<p>. (22.17)
</p>
<p>Combining (22.17) with (22.12) and (22.14) yields
</p>
<p>1
</p>
<p>C
= dV
</p>
<p>&prime;
G
</p>
<p>dQm
= d
</p>
<p>(
</p>
<p>V &prime;G &minus; Ïs
)
</p>
<p>+ dÏs
dQm
</p>
<p>= 1
Cox
</p>
<p>+ dÏs
d
(
</p>
<p>&minus;Qsc
) . (22.18)
</p>
<p>The above is recast in a more compact form by defining the semiconductor
capacitance per unit area
</p>
<p>Csc = &minus;
dQsc
dÏs
</p>
<p>= &minus; q
kB T
</p>
<p>dQsc
dus
</p>
<p>= &plusmn;
&radic;
</p>
<p>2 Îµsc
LA
</p>
<p>dF
</p>
<p>dus
&gt; 0, (22.19)
</p>
<p>where the positive (negative) sign holds for us &gt; 0
(
</p>
<p>us &lt; 0
)
</p>
<p>. In conclusion, the
capacitance is the series of the oxide and semiconductor capacitances:
</p>
<p>1
</p>
<p>C
= 1
</p>
<p>Cox
+ 1
</p>
<p>Csc
. (22.20)
</p>
<p>In (22.20) it is Cox = const while Csc has a rather complicate dependence on us .
However, basing on the second equation in (22.5), one may investigate the limiting
cases of (22.20). For this, using exp (&minus;2 uF ) = n2i /N2A, one finds for the asymptotic
behavior of F in a p-substrate device,
</p>
<p>F â exp
(
</p>
<p>us/2 &minus; uF
)
</p>
<p>, us â« 1 ; F â exp
(
</p>
<p>&minus; us/2
)
</p>
<p>, us âª &minus;1. (22.21)
</p>
<p>6 Like in the case of the depletion capacitance of the p&ndash;n junction (Sect. 21.4), definition C =
dQm/dVG is coherent with the choice of the voltage reference described in Sect. 22.2. The units of
C are [C] = F m&minus;2.</p>
<p/>
</div>
<div class="page"><p/>
<p>22.3 Capacitance of the MOS Structure 521
</p>
<p>Fig. 22.9 Normalized
capacitance C/Cox as a
function of the normalized
gate voltage u&prime;G, in a
p-substrate MOS capacitor
with NA = 1016 cm&minus;3, for
different values of
r = Îµsc tox/
</p>
<p>(
</p>
<p>Îµox
&radic;
</p>
<p>2LA
)
</p>
<p>. The
details of the calculations are
in Problem 22.7.2
</p>
<p>-200 -100 0 100 200
Normalized gate voltage
</p>
<p>0.0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1.0
</p>
<p>N
o
</p>
<p>rm
al
</p>
<p>iz
ed
</p>
<p> c
ap
</p>
<p>ac
it
</p>
<p>an
ce
</p>
<p>C
 /
</p>
<p> C
o
x
</p>
<p>r = 5
r = 0.5
</p>
<p>When, instead, it is |us | âª 1, expanding the exponentials yields exp
(
</p>
<p>&plusmn; us
)
</p>
<p>â
1 &plusmn; us + u2s/2, whence, observing that exp
</p>
<p>(
</p>
<p>&minus; 2 uF
)
</p>
<p>âª 1,
</p>
<p>F 2 â 1
2
</p>
<p>[
</p>
<p>1 + exp ( &minus; 2 uF )
]
</p>
<p>u2s â
1
</p>
<p>2
u2s , F â &plusmn;
</p>
<p>us&radic;
2
. (22.22)
</p>
<p>Then, from (22.19) the asymptotic values of Csc are found to be
</p>
<p>Csc â
1&radic;
2
</p>
<p>Îµsc
</p>
<p>LA
exp
</p>
<p>(
</p>
<p>us/2 &minus; uF
)
</p>
<p>, us â« 1, (22.23)
</p>
<p>Csc â
1&radic;
2
</p>
<p>Îµsc
</p>
<p>LA
exp
</p>
<p>(
</p>
<p>&minus; us/2
)
</p>
<p>, us âª &minus;1. (22.24)
</p>
<p>Both limits correspond to the same asymptotic value of the capacitance per unit area,
</p>
<p>C = Cox Csc
Cox + Csc
</p>
<p>â Cox, |us | â« 1. (22.25)
</p>
<p>Near the origin, instead, one finds
</p>
<p>Csc â
Îµsc
</p>
<p>LA
, |us | âª 1. (22.26)
</p>
<p>The limit of C for us &rarr; 0 is called flat-band capacitance per unit area; from (22.26)
one finds
</p>
<p>C â CFB =
Cox
</p>
<p>1 + Cox LA/Îµsc
&lt; Cox, |us | âª 1. (22.27)
</p>
<p>Examples of capacitance&rsquo;s calculations are shown in Fig. 22.9.</p>
<p/>
</div>
<div class="page"><p/>
<p>522 22 MOS Devices
</p>
<p>Fig. 22.10 Normalized
charge per unit area as a
function of the normalized
surface potential, in a
p-substrate MOS capacitor
with NA = 1016 cm&minus;3
</p>
<p>-10 0 10 20 30 40
Normalized surface potential u
</p>
<p>s
</p>
<p>10
-4
</p>
<p>10
-2
</p>
<p>10
0
</p>
<p>10
2
</p>
<p>10
4
</p>
<p>N
o
</p>
<p>rm
al
</p>
<p>iz
ed
</p>
<p> c
h
</p>
<p>ar
g
</p>
<p>e 
  
</p>
<p> | 
Q
</p>
<p>sc
 | 
</p>
<p> /
Q
</p>
<p>sc
</p>
<p>(1
)
</p>
<p>  u
F
</p>
<p>= 13.8
</p>
<p>2u
F
</p>
<p>= 27.6
</p>
<p>Fig. 22.11 Individual
contributions of electrons,
holes, and bulk charge to
F 2 = [Qsc/Q(1)sc ]2, as a
function of the normalized
surface potential us , in a
p-substrate MOS capacitor
with NA = 1016 cm&minus;3
</p>
<p>-10 0 10 20 30 40
Normalized surface potential u
</p>
<p>s
</p>
<p>10
-20
</p>
<p>10
-15
</p>
<p>10
-10
</p>
<p>10
-5
</p>
<p>10
0
</p>
<p>10
5
</p>
<p>10
10
</p>
<p>C
o
n
tr
</p>
<p>ib
u
ti
</p>
<p>o
n
s 
</p>
<p>to
 [
</p>
<p> Q
sc
</p>
<p> /
 Q
</p>
<p>sc
</p>
<p>(1
)  
]2
</p>
<p>Electrons
Bulk charge
Holes
</p>
<p>22.4 Simplified Expression of the Inversion Charge
</p>
<p>To the purpose of applying some results of the MOS capacitor&rsquo;s theory to the analysis
of MOSFETs, it is convenient to determine a simplified form of the inversion layer&rsquo;s
charge, that holds in all the functioning regimes with the exception of accumulation.
For this, one starts from the expression of the semiconductor charge per unit area
which, combining (22.12) and (22.13), reads
</p>
<p>Qsc = &plusmn;Q(1)sc F
(
</p>
<p>us
)
</p>
<p>, Q(1)sc = Îµsc
kB T
</p>
<p>q
</p>
<p>&radic;
2
</p>
<p>LA
, (22.28)
</p>
<p>where the negative (positive) sign must be chosen when us &gt; 0 (us &lt; 0), and Q(1)sc
is the value of Qsc corresponding to F = 1. The relation Qsc = Qsc
</p>
<p>(
</p>
<p>us
)
</p>
<p>is shown in
normalized units in Fig. 22.10. In turn, Fig. 22.11 shows, still in normalized form, the
individual contributions of electrons, holes, and bulk charge to F 2 =
</p>
<p>[
</p>
<p>Qsc/Q
(1)
sc
</p>
<p>]2
;</p>
<p/>
</div>
<div class="page"><p/>
<p>22.4 Simplified Expression of the Inversion Charge 523
</p>
<p>such contributions are, respectively, exp
(
</p>
<p>&minus; 2 uF
) [
</p>
<p>exp
(
</p>
<p>us
)
</p>
<p>&minus; 1
]
</p>
<p>, exp
(
</p>
<p>&minus; us
)
</p>
<p>&minus; 1,
and [1&minus;exp
</p>
<p>(
</p>
<p>&minus;2 uF )
]
</p>
<p>us . The contribution of holes dominates for us &lt; 0, that of the
bulk charge dominates for 0 &lt; us &lt; 2uF and, finally, that of the electrons dominates
for us &gt; 2uF .
</p>
<p>When accumulation is excluded, in a p-substrate capacitor one must take Ïs &gt; 0.
The approximate dependence of F on the normalized potential is easily worked out
from (22.5), whose limiting case in the depletion and weak-inversion regimes is
</p>
<p>F â &radic;us , 0 &lt; us &lt; 2uF . (22.29)
</p>
<p>Introducing (22.29) into (22.28) yields, for 0 &lt; us &lt; 2 uF ,
</p>
<p>Qsc â &minus;
2 Îµsc kB T
</p>
<p>qLA
</p>
<p>&radic;
qÏs
</p>
<p>kB T
= &minus;Cox Î³
</p>
<p>&radic;
Ïs , Î³ =
</p>
<p>&radic;
</p>
<p>2 Îµsc qpp0
Cox
</p>
<p>, (22.30)
</p>
<p>where the expression (21.12) of the Debye length LA has been used.7 It is interesting
to note that a relation identical to (22.30) is obtained using the full-depletion and
ASCE approximations (Sect. 21.4); in fact, letting Ï = &minus;qNA for 0 &lt; x &lt; xd and
Ï = 0 for x &gt; xd (compare, e.g., with Figs. 22.7 and 22.8) yields a simplified form
of the Poisson equation,
</p>
<p>Ï&prime;&prime; â qNA
Îµsc
</p>
<p>, 0 &lt; x &lt; xd . (22.31)
</p>
<p>The boundary conditions of (22.31) are obtained in the same manner as in the p&ndash;
n junction, and read Ï
</p>
<p>(
</p>
<p>xd
)
</p>
<p>= 0, Ï&prime;
(
</p>
<p>xd
)
</p>
<p>= 0; the solution of (22.31) fulfilling
the boundary conditions is Ï(x) = qNA
</p>
<p>(
</p>
<p>x &minus; xd
)2
/
(
</p>
<p>2 Îµsc
)
</p>
<p>. Letting x = 0 in the
above, yields a relation between the surface potential and the depletion width; in
turn, in the full-depletion and ASCE approximations the bulk charge per unit area is
Qb = &minus;qNA xd . In summary,
</p>
<p>Ïs =
qNA
</p>
<p>2 Îµsc
x2d , Qb = &minus;qNA xd = &minus;
</p>
<p>&radic;
</p>
<p>2 Îµsc qNA Ïs . (22.32)
</p>
<p>Observing that for 0 &lt; us &lt; 2 uF it is Qsc â Qb, and that NA â pp0, one finds
that the second relation in (22.32) coincides with the first one in (22.30). Combining
Qsc â Qb with (22.30) and with the general expression (22.14) yields V &prime;G &minus; Ïs =
Î³
&radic;
Ïs ; from it, one finds a simplified Ïs = Ïs
</p>
<p>(
</p>
<p>V &prime;G
)
</p>
<p>relation, that holds in the
depletion and weak-inversion conditions:8
</p>
<p>&radic;
Ïs =
</p>
<p>&radic;
</p>
<p>V &prime;G +
(
</p>
<p>Î³ /2
)2 &minus; Î³ /2. (22.33)
</p>
<p>The contribution of electrons to the semiconductor charge per unit area, Qi =
&minus;q
</p>
<p>&int; xd
0 n dx, becomes relevant from the threshold condition on. Remembering the
</p>
<p>7 The units of Î³ are [Î³ ] = V1/2.
8 The negative sign in front of the square root in (22.33) must be discarded.</p>
<p/>
</div>
<div class="page"><p/>
<p>524 22 MOS Devices
</p>
<p>discussion of Sect. 22.2.2, the electron charge is approximated as a charge layer at the
interface, &minus;qn â Qi Î´
</p>
<p>(
</p>
<p>x+
)
</p>
<p>; as a consequence, the space charge can be considered
as entirely due to the ionized dopant atoms also when Ïs &gt; 2 ÏF , so that (22.31) and
(22.32) still hold. From (22.16) one then finds the result sought, that is, a simplified
form of the inversion layer&rsquo;s charge, that holds in the depletion, weak-inversion, and
strong-inversion regimes:
</p>
<p>Qi = Qsc &minus;Qb = &minus;Cox
[(
</p>
<p>V &prime;G &minus; Ïs
)
</p>
<p>&minus; Î³ &radic;Ïs
]
</p>
<p>&lt; 0. (22.34)
</p>
<p>The theory worked out so far is based on the assumption that relation (22.1) holds
between the gate metal&rsquo;s work function, the semiconductor&rsquo;s affinity, and the position
of the semiconductor&rsquo;s Fermi level with respect to the band edges. Moreover, the
gate oxide has been assumed free of charge. In fact, as the above conditions seldom
occur, one must account for the effects of the difference ï¿½W = W &minus;A&minus;
</p>
<p>(
</p>
<p>EC&minus;EF
)
</p>
<p>and for the oxide charge. It can be shown that, if the oxide charge is fixed, the two
additional effects produce a shift in V &prime;G with respect to the value V
</p>
<p>&prime;
G = VG &minus; Î¦mp
</p>
<p>that holds for the ideal MOS capacitor with a p-type substrate [103, Sect. 9.4]. In
fact, the combination of Î¦mp, ï¿½W , and of the oxide charge per unit area Qox,
provides an expression of the form V &prime;G = VG &minus; VFB , where the constant VFB =
VFB(Î¦mp,Qox,ï¿½W ) is called flat-band voltage.9
</p>
<p>22.4.1 Quantitative Relations in the MOS Capacitor
</p>
<p>In the p-type silicon substrate considered so far it is pp0 â NA = 1016 cm&minus;3 and,
at room temperature, ni â 1010 cm&minus;3. In turn, the asymptotic minority-carrier
concentration is np0 = n2i /NA â 104 cm&minus;3; it follows exp
</p>
<p>(
</p>
<p>&minus; 2 uF
)
</p>
<p>= np0/pp0 â
10&minus;12 and, as shown, e.g., in Fig. 22.5, 2 uF â 27.6. Using kB T/q â 26 mV then
yields 2 ÏF â 0.72 V. As Îµsc â 11.7&times; 8.854&times; 10&minus;14 = 1.036&times; 10&minus;12 F cm&minus;1, one
finds
</p>
<p>LA =
&radic;
</p>
<p>2 Îµsc kB T
</p>
<p>q2 pp0
â 5.8 &times; 10&minus;2 Î¼m, (22.35)
</p>
<p>Q(1)sc =
2 Îµsc kB T
</p>
<p>qLA
=
</p>
<p>&radic;
</p>
<p>2 Îµsc kB T pp0 â 9.3 &times; 10&minus;9 C cm&minus;2. (22.36)
</p>
<p>The relation Qsc
(
</p>
<p>V &prime;G
)
</p>
<p>is found from Qsc = &minus;Cox
[
</p>
<p>V &prime;G &minus; Ï
(
</p>
<p>V &prime;G
)]
</p>
<p>, where Ï(V &prime;G) is
obtained from (22.12). The result is shown in normalized form in Fig. 22.12.
</p>
<p>9 The designation is due to the fact that VG = VFB establishes the flat-band condition in the
semiconductor.</p>
<p/>
</div>
<div class="page"><p/>
<p>22.4 Simplified Expression of the Inversion Charge 525
</p>
<p>Fig. 22.12 Normalized
semiconductor charge
Qsc/Q
</p>
<p>(1)
sc as a function of the
</p>
<p>normalized gate voltage u&prime;G,
for a p-substrate MOS
capacitor with
NA = 1016 cm&minus;3
</p>
<p>-20 -10 0 10 20 30 40 50
Normalized gate voltage
</p>
<p>-20
</p>
<p>-10
</p>
<p>0
</p>
<p>10
</p>
<p>20
</p>
<p>N
o
</p>
<p>rm
al
</p>
<p>iz
ed
</p>
<p> c
h
</p>
<p>ar
g
</p>
<p>e
Q
</p>
<p>sc
  
</p>
<p>/
Q
</p>
<p>sc
</p>
<p>(1
)
</p>
<p>2 u
F
 = 27.6
</p>
<p>Fig. 22.13 Normalized
concentrations n/pp0 and(
NA &minus; p
</p>
<p>)
</p>
<p>/pp0 as a function
of position x/LA, for a
p-substrate MOS capacitor
with NA = 1016 cm&minus;3 in
strong inversion
(
</p>
<p>us = 2.5 uF
)
</p>
<p>10
-5
</p>
<p>10
-4
</p>
<p>10
-3
</p>
<p>10
-2
</p>
<p>10
-1
</p>
<p>10
0
</p>
<p>10
1
</p>
<p>Normalized abscissa x / L
A
</p>
<p>10
-3
</p>
<p>10
-2
</p>
<p>10
-1
</p>
<p>10
0
</p>
<p>10
1
</p>
<p>10
2
</p>
<p>10
3
</p>
<p>10
4
</p>
<p>N
o
rm
</p>
<p>al
iz
</p>
<p>ed
 c
</p>
<p>o
n
ce
</p>
<p>n
tr
</p>
<p>at
io
</p>
<p>n
s
</p>
<p>n/p
p0
</p>
<p>(N
A
</p>
<p>-p)/p
p0
</p>
<p>Note that the results illustrated so far have been obtained without the need of inte-
grating (22.6). The result of a numerical integration of (22.6) is shown in Fig. 22.13,
where the dependence on position of n and NA &minus; p is drawn for a p-substrate MOS
capacitor with NA = 1016 cm&minus;3 in the strong-inversion regime
</p>
<p>(
</p>
<p>us = 2.5 uF
)
</p>
<p>. The
term
</p>
<p>(
</p>
<p>NA &minus; p
)
</p>
<p>/pp0 is significant in a surface region of the semiconductor, whose
thickness is several units of x/LA. The term n/pp0 is much larger, but only in a
much thinner region near the surface. If the width of the inversion layer is conven-
tionally taken at the intersection between the two curves of Fig. 22.13, that occurs at
x/LA â 0.1, one finds from (22.35) a width of about 5 nm.</p>
<p/>
</div>
<div class="page"><p/>
<p>526 22 MOS Devices
</p>
<p>Fig. 22.14 Cross-section of
an n-channel MOSFET. The
black areas are the metal
contacts
</p>
<p>x
d
</p>
<p>n+ n+
</p>
<p>SiO2
</p>
<p>I
D
</p>
<p>d y
p &minus;Si
</p>
<p>S1 S2
</p>
<p>S D
</p>
<p>x
</p>
<p>y
</p>
<p>Lg
</p>
<p>L
</p>
<p>l p
</p>
<p>l n
</p>
<p>G
</p>
<p>B
</p>
<p>O
</p>
<p>22.5 Insulated-Gate Field-Effect Transistor&mdash;MOSFET
</p>
<p>The principle of the insulated-gate, field-effect transistor (IGFET) was demonstrated
in the early 1930s [103, Chap. 10]. The first structures using a thermally-oxidized
silicon layer were fabricated in 1960. The IGFET architecture using silicon dioxide as
gate dielectric is more commonly called MOSFET. This device architecture, jointly
with the continuous improvements in the silicon technology, made it possible the
tremendous progress in the fabrication of integrated circuits during the last decades,
and is the most common component in digital and analog circuits.
</p>
<p>The electric current in a MOSFET is transported by one type of carriers only,
electrons or holes; for this reason the device is called unipolar. In a p-substrate
device, the carriers are the electrons that form the charge layer at the semiconductor&ndash;
insulator interface; therefore, this type of transistor is called n-channel MOSFET.
Conversely, in an n-substrate device the carriers are holes, and the transistor is called
p-channel MOSFET.The schematic cross-section of an n-channel MOSFET is shown
in Fig. 22.14. The starting point is a p-type silicon substrate, with an NA = const
dopant concentration, onto which a layer of silicon dioxide is thermally grown and
patterned; then, the gate contact (G) is deposited. The extension Lg of the gate metal
in the horizontal direction is called geometrical length of the gate. The next step is
the introduction of a heavy dose of an n-type dopant on the two sides of the gate. As
shown in the figure, lateral diffusion (Sect. 23.7.3) makes the gate oxide to partially
overlap the n-doped regions.10
</p>
<p>10 The n-type regions are typically obtained by ion implantation, whose lateral penetration is limited.
However, ion implantation is followed by a thermal process (annealing), during which thermal
diffusion takes place.</p>
<p/>
</div>
<div class="page"><p/>
<p>22.6 N-Channel MOSFET&mdash;Current-Voltage Characteristics 527
</p>
<p>The metallizations of the n+ regions provide two more contacts, called source (S)
and drain (D); the bottom metal layer contacting the p-type substrate is indicated with
bulk (B), and the term channel denotes the interfacial semiconductor region between
the two junctions. To distinguish the applied voltages from one another, two letters
are used; considering the bulk metallization as the reference contact, in an n-channel
MOSFET a typical choice of the three independent voltages is VGB = VG &minus; VB ,
VSB = VS &minus; VB , and VDB = VD &minus; VB . As the standard MOSFET architecture
is structurally symmetric, it is not possible to distinguish the source contact from
the drain contact basing on geometry or dopant distribution: the distinction is to be
based on the applied voltages; in fact, in the typical operating regime of the device
the source&ndash;bulk and drain&ndash;bulk junctions are never forward biased, whence in an
n-channel MOSFET it is VSB &ge; 0 and VDB &ge; 0. The drain contact is identified11 by
the condition VDB &minus; VSB = VDS &gt; 0.
</p>
<p>22.6 N-Channel MOSFET&mdash;Current-Voltage Characteristics
</p>
<p>To work out the theory of the MOSFET, one introduces a reference whose x axis is
normal to the semiconductor&ndash;insulator interface, while the y axis is parallel to it. The
origin (O) is placed at the intersection of the source p&ndash;n junction and the interface
(Fig. 22.14). The y coordinate corresponding to the intersection of the drain p&ndash;n
junction and the interface is indicated with L; the latter is called electric length of
the gate, or channel length. The device is considered uniform in the z direction; its
width along such a direction is indicated with W .
</p>
<p>Purpose of the analysis is to derive the steady-state characteristics, namely, the
relations between the currents at the contacts and the applied voltages. To proceed,
one assumes that the gate voltage VGB is such that at all positions y along the channel
the strong-inversion condition holds. Thus, a layer of electrons is present, indicated
in Fig. 22.14 with the shaded area underneath the gate oxide; the term well-formed
channel is used to denote this situation. The minimum gate voltage necessary for
obtaining a well-formed channel will be identified later. In a steady-state condition
there is no current through the gate contact because the gate insulator is in series to
it; also, the current flowing through the bulk contact is negligibly small because the
two junctions are reverse biased. Since the channel layer connects two heavily-doped
regions of the n type, the application of a drain-source voltage VDS &gt; 0 gives rise to
a current ID that flows from the drain to the source contact (its reference is shown
in Fig. 22.14); for a given VDS, the drain current ID is controlled by the amount
of charge available in the channel, which is in turn controlled by the gate voltage
VGB. In other terms, the device is an electronic valve in which the gate&ndash;bulk port
controls the current flowing into the drain&ndash;source port; moreover, in the steady-state
</p>
<p>11 In fact, in some types of logic circuits the source and drain contact may exchange their roles
depending on the applied voltages.</p>
<p/>
</div>
<div class="page"><p/>
<p>528 22 MOS Devices
</p>
<p>condition the control port does not expend energy, because the gate current is zero.
This, among other things, explains the success of the MOSFET concept.
</p>
<p>Due to the uniformity in the z direction, the electron and hole current densities
have the form
</p>
<p>Jn = Jnx i + Jny j, Jp = Jpx i + Jpy j, (22.37)
with i, j the unit vectors of the x and y axes, respectively. On the other hand it
is Jnx = Jpx = 0 because no current can flow through the insulator, so only the
y components Jny , Jpy are left in (22.37). In turn, the condition of a well-formed
channel implies that the concentration of holes is negligibly small with respect to that
of the electrons,12 whence |Jny | â« |Jpy |. It follows J = Jn + Jp â Jn = Jny(x, y) j.
The equality J = Jn is the mathematical form of the MOSFET&rsquo;s property of being
unipolar. It also entails divJ = divJn; therefore, remembering that in a steady-state
condition it is divJ = 0, it follows that divJn = 0 as well.
</p>
<p>Consider now two planes parallel to the x, z plane, placed at different positions y1
and y2 in the channel; their intersections with the x, y plane are respectively marked
with S1 and S2 in Fig. 22.14. From the divergence theorem (A.23) and the property
divJn = 0 it follows13
</p>
<p>&int;&int;
</p>
<p>2
Jn &middot; j dx dz &minus;
</p>
<p>&int;&int;
</p>
<p>1
Jn &middot; j dx dz = 0 ; (22.38)
</p>
<p>as a consequence, the channel current
</p>
<p>I =
&int; W
</p>
<p>z=0
</p>
<p>&int; xd
</p>
<p>x=0
Jn &middot; j dx dz = W
</p>
<p>&int; xd
</p>
<p>0
Jny dx (22.39)
</p>
<p>is independent of y. The last form of (22.39) derives from the uniformity in z. To
express Jny in (22.39) it is convenient to adopt the monomial form (19.141) of the
electron current density, Jn = &minus;qÎ¼n n gradÏn, with Ïn the electron quasi-Fermi
potential. The components of Jn in monomial form read
</p>
<p>Jnx = &minus;qÎ¼n n
&part;Ïn
</p>
<p>&part;x
, Jny = &minus;qÎ¼n n
</p>
<p>&part;Ïn
</p>
<p>&part;y
, (22.40)
</p>
<p>where Jnx = 0 as found above. In the channel it is n ï¿½= 0, whence for Jnx to vanish
it must be &part;Ïn/&part;x = 0; as a consequence, Ïn in the channel14 depends on y only. In
conclusion,
</p>
<p>I = W dÏn
dy
</p>
<p>Qi(y), Qi =
&int; xd
</p>
<p>0
&minus;qÎ¼n n dx &lt; 0, (22.41)
</p>
<p>12 Compare with Fig. 22.13; the latter describes an equilibrium case, however the situation is similar
to the one depicted here.
13 In the integrals of (22.38) the upper limit of x is given by the depletion width xd (y) shown in
Fig. 22.14. Compare also with Sect. 22.7.1.
14 Far from the channel the semiconductor is practically in the equilibrium condition, whence
Ïn &rarr; ÏF as x increases. However, in the bulk region where the dependence of Ïn on x is significant,
the electron concentration is negligible; as a consequence, the integral in (22.39) is not affected.</p>
<p/>
</div>
<div class="page"><p/>
<p>22.6 N-Channel MOSFET&mdash;Current-Voltage Characteristics 529
</p>
<p>where Qi is the inversion-layer charge per unit area at position y in the channel. In
the integral of (22.41) it is n = n(x, y) and Î¼n = Î¼n(x, y); defining the effective
electron mobility as the average
</p>
<p>Î¼e(y) =
&int; xd
</p>
<p>0 &minus;qÎ¼n n dx
&int; xd
</p>
<p>0 &minus;qn dx
&gt; 0, (22.42)
</p>
<p>yields
</p>
<p>I = W dÏn
dy
</p>
<p>Î¼e(y)Qi(y). (22.43)
</p>
<p>In (22.43), Î¼e and Qi are positive- and negative-definite, respectively, and I , W are
constant; it follows that dÏn/dy has always the same sign and, as a consequence,
Ïn(y) is invertible. Using the inverse function y = y
</p>
<p>(
</p>
<p>Ïn
)
</p>
<p>within Î¼e and Qi makes
(22.43) separable; integrating the latter over the channel yields
</p>
<p>&int; L
</p>
<p>0
I dy = L I = W
</p>
<p>&int; Ïn(L)
</p>
<p>Ïn(0)
Î¼e
</p>
<p>(
</p>
<p>Ïn
)
</p>
<p>Qi
(
</p>
<p>Ïn
)
</p>
<p>dÏn. (22.44)
</p>
<p>In turn, the dependence of Î¼e on y is weak,15 whence
</p>
<p>I = W
L
</p>
<p>Î¼e
</p>
<p>&int; Ïn(L)
</p>
<p>Ïn(0)
Qi
</p>
<p>(
</p>
<p>Ïn
)
</p>
<p>dÏn. (22.45)
</p>
<p>22.6.1 Gradual-Channel Approximation
</p>
<p>In the derivation of (22.45) the condition of a well-formed channel has not been
exploited yet; this condition makes a number of approximations possible, which
are collectively indicated with the term gradual-channel approximation;16 they lead
to an expression of (22.45) in closed form. First, one uses the definition of surface
potential which, in the two-dimensional analysis considered here, is given byÏs(y) =
Ï(x = 0, y); it is shown in Sect. 22.7.1 that the condition of a well-formed channel
entails the relation
</p>
<p>Ïs = Ïn + ÏF . (22.46)
</p>
<p>15 This issue is discussed in Sect. 22.7.1.
16 The gradual-channel approximation is not limited to the analysis of the MOSFET shown here.
Indeed, it is a widely-used method to treat the Poisson equation in devices in which the geometrical
configuration and applied voltages are such that the variation of the electric field in one direction is
much weaker than those in the other two directions. Typically, the former direction is the longitudinal
one (that is, along the channel), the other two the transversal ones. From the mathematical standpoint,
the approximation amounts to eliminating a part of the Laplacian operator, so that the dependence
on all variables but one becomes purely algebraic.</p>
<p/>
</div>
<div class="page"><p/>
<p>530 22 MOS Devices
</p>
<p>It follows that dÏn/dy in (22.43) can be replaced with dÏs/dy, this showing that
the transport in a well-formed channel is dominated by the drift term, Jny =
&minus;qÎ¼n n dÏs/dy = qÎ¼n nEsy , with Esy the y-component of the electric field at
x = 0; using (22.46) one changes the variable from Ïn to Ïs in the integral of
(22.45). The integration limits in terms of Ïs are found by the same reasoning leading
to (22.46), and read (Sect. 22.7.1)
</p>
<p>Ïs(0) = VSB + 2 ÏF , Ïs(L) = VDB + 2 ÏF . (22.47)
</p>
<p>In conclusion, (22.45) becomes
</p>
<p>I = W
L
</p>
<p>Î¼e
</p>
<p>&int; VDB+2 ÏF
</p>
<p>VSB+2 ÏF
Qi
</p>
<p>(
</p>
<p>Ïs
)
</p>
<p>dÏs . (22.48)
</p>
<p>The next step of the gradual-channel approximation consists in determining the
relation Qi(Ïs), for which the solution of the Poisson equation in two dimensions is
necessary. As shown in Sect. 22.7.1, one can exploit the strong difference between
the strengths of the electric-field components in the x and y directions, to give the
equation a one-dimensional form in which the y coordinate acts as a parameter. This
is equivalent to assimilating each elementary portion of the channel, like that marked
with dy in Fig. 22.14, to a one-dimensional MOS capacitor whose surface potential
has the local value Ïs(y). The final step of the gradual-channel approximation is the
adoption of the full-depletion and ASCE approximations (Sect. 21.4), so that the
inversion-layer charge per unit area at position y in the channel is given by (22.34),
namely, Qi = &minus;Cox
</p>
<p>[(
</p>
<p>V &prime;GB &minus; Ïs
)
</p>
<p>&minus; Î³&radic;Ïs
]
</p>
<p>&lt; 0. Observing that VDB + 2 ÏF &gt;
VSB + 2 ÏF while the integrand in (22.48) is negative, it follows that I &lt; 0, whence
ID = &minus;I due to the reference chosen for the drain current (Fig. 22.14). In conclusion,
(22.48) transforms into17
</p>
<p>ID = Î²
&int; VDB+2 ÏF
</p>
<p>VSB+2 ÏF
</p>
<p>[(
</p>
<p>V &prime;GB &minus; Ïs
)
</p>
<p>&minus; Î³&radic;Ïs
]
</p>
<p>dÏs , Î² =
W
</p>
<p>L
Î¼e Cox. (22.49)
</p>
<p>22.6.2 Differential Conductances and Drain Current
</p>
<p>The drain current&rsquo;s expression (22.49) of the n-channel MOSFET provides a relation
of the form ID = ID
</p>
<p>(
</p>
<p>VGB,VDB,VSB
)
</p>
<p>, where VGB = V &prime;GB + VFB . In the integrated-
circuit operation an important role is played by the differential conductances of
the device, each of them defined as the partial derivative of ID with respect to one
of the applied voltages. In some cases the differential conductances can be found
without the need of actually calculating the integral in (22.49); for this reason, here
such conductances are calculated first. Prior to that, it is worth noting that in circuit
</p>
<p>17 The units of Î² are [Î²] = A V&minus;2.</p>
<p/>
</div>
<div class="page"><p/>
<p>22.6 N-Channel MOSFET&mdash;Current-Voltage Characteristics 531
</p>
<p>applications it is often preferred to use the source contact, instead of the bulk contact,
as a voltage reference. The transformation from one reference to the other is easily
obtained from
</p>
<p>VDS = VDB &minus; VSB &gt; 0, VGS = VGB &minus; VSB, VBS = &minus;VSB &le; 0. (22.50)
</p>
<p>Then, the drain conductance18 is defined as the derivative of ID with respect to VDB,
at constant VSB and VGB; or, equivalently, as the derivative with respect to VDS, at
constant VBS and VGS:
</p>
<p>gD =
(
</p>
<p>&part;ID
</p>
<p>&part;VDB
</p>
<p>)
</p>
<p>VSB,VGB
</p>
<p>=
(
</p>
<p>&part;ID
</p>
<p>&part;VDS
</p>
<p>)
</p>
<p>VBS,VGS
</p>
<p>. (22.51)
</p>
<p>Remembering that the derivative of an integral with respect to the upper limit is the
integrand calculated at such limit, from (22.49) one finds
</p>
<p>gD = Î²
[
(
</p>
<p>V &prime;GB &minus; VDB &minus; 2 ÏF
)
</p>
<p>&minus; Î³
&radic;
</p>
<p>VDB + 2 ÏF
]
</p>
<p>. (22.52)
</p>
<p>Using (22.47) and (22.34) yields
</p>
<p>gD = Î²
[
(
</p>
<p>V &prime;GB &minus; Ïs(L)
)
</p>
<p>&minus; Î³
&radic;
</p>
<p>Ïs(L)
]
</p>
<p>= W
L
</p>
<p>Î¼e [&minus;Qi(L)] , (22.53)
</p>
<p>namely, the output conductance is proportional to the inversion charge per unit area
at the drain end of the channel. The quantity in brackets in (22.53) is non-negative
by construction; its zero corresponds to the value of Ïs(L) obtained from (22.33).
Such a zero is indicated with Ïsats and is termed saturation surface potential. From
(22.50), the saturation voltage in the bulk and source references is found to be
</p>
<p>V satDB = Ïsats &minus; 2 ÏF , V satDS = V satDB &minus; VSB, (22.54)
</p>
<p>respectively. Similarly, the current I satD = ID
(
</p>
<p>V satDS
)
</p>
<p>(which depends on VGS) is called
saturation current. If a value ofVDS larger thanV satDS is used, gD becomes negative; this
result is not physically sound and indicates that the gradual-channel approximation
is not applicable in that voltage range.19
</p>
<p>Still considering the drain conductance, it is also important to determine its limit
for VDB &rarr; VSB, or VDS &rarr; 0. Again, there is no need to calculate the integral in
(22.49) which, in this limiting case, is the product of the integration interval VDS
times the integrand calculated in the lower integration limit; in turn, the derivative
eliminates VDS, whence
</p>
<p>gD(VDS &rarr; 0) = Î²
[
(
</p>
<p>V &prime;GB &minus; VSB &minus; 2 ÏF
)
</p>
<p>&minus; Î³
&radic;
</p>
<p>VSB + 2 ÏF
]
</p>
<p>. (22.55)
</p>
<p>18 The drain conductance is also called output conductance; in this case it is indicated with go.
19 In fact, beyond the saturation voltage the Poisson equation near the drain end of the channel can
not be reduced any more to a one-dimensional equation where y is treated as a parameter (compare
with Sect. 22.7.1).</p>
<p/>
</div>
<div class="page"><p/>
<p>532 22 MOS Devices
</p>
<p>Replacing V &prime;GB with VGB &minus; VFB and using (22.50) yields
</p>
<p>gD(VDS &rarr; 0) = Î² (VGS &minus; VT ) , VT = VFB + 2 ÏF + Î³
&radic;
</p>
<p>2 ÏF &minus; VBS
(22.56)
</p>
<p>where, remembering that the junctions are never forward biased, it is VBS &le; 0.
The VT = VT
</p>
<p>(
</p>
<p>VBS
)
</p>
<p>voltage defined in (22.56) is called threshold voltage, and its
dependence on VBS is called body effect. Near VDS = 0 the relation between ID
and VDS is ID = Î² (VGS &minus; VT ) VDS: there, the current-voltage characteristics are
approximated by straight lines whose slope, for a given VBS, is prescribed by VGS.
At larger values of VDS the limiting case (22.56) does not hold any longer: the slope
of the ID = ID(VDS) curves decreases, to eventually vanish when VDS reaches V satDS .
Considering that ID is non-negative, the theory depicted above is applicable as long
as Î² (VGS &minus; VT ) &ge; 0; this observation allows one to better specify the condition of a
well-formed channel, used at the beginning: from the formal standpoint the condition
of a well-formed channel is VGS &gt; VT .
</p>
<p>The integration of (22.49) is straightforward and yields ID = I &prime;D &minus; I &prime;&prime;D , where I &prime;D
is obtained by integrating Î²
</p>
<p>(
</p>
<p>V &prime;GB &minus; Ïs
)
</p>
<p>. In this calculation many terms cancel out,
to yield the relatively simple expression
</p>
<p>I &prime;D = Î²
[
</p>
<p>(VGS &minus; VFB &minus; 2 ÏF ) VDS &minus;
1
</p>
<p>2
V 2DS
</p>
<p>]
</p>
<p>. (22.57)
</p>
<p>In turn, I &prime;&prime;D is obtained by integrating &minus;Î² Î³
&radic;
Ïs , and reads
</p>
<p>I &prime;&prime;D = Î²
2
</p>
<p>3
Î³
[
</p>
<p>(VDS + 2 ÏF &minus; VBS)3/2 &minus; (2 ÏF &minus; VBS)3/2
]
</p>
<p>. (22.58)
</p>
<p>Comparisons with experiments show that the model ID = I &prime;D&minus;I &prime;&prime;D , where the two
contributions are given by (22.57) and (22.58), provides a fair description of the drain
current up to the saturation voltage. Beyond saturation, the model is not correct any
longer: in fact, the terms with a negative sign within the expression of ID give rise to
a negative slope gD; instead, the experiments show that for VDS &gt; V satDS the current
tends to saturate. For this reason, the analytical model is given a regional form:
for a prescribed pair VGS, VBS, the regional model first separates the on condition
VGS &gt; VT from the off condition VGS &le; VT . The on condition is further separated
into the linear region20 0 &lt; VDS &le; V satDS , where the drain current is described by
the ID = I &prime;D &minus; I &prime;&prime;D model worked out above, and the saturation region VDS &gt; V satDS ,
where the regional model lets ID = I satD . Finally, in the off condition the model lets
ID = 0.
</p>
<p>For a given bulk-source voltage VBS, the ID = ID
(
</p>
<p>VDS
)
</p>
<p>curves corresponding to
different values ofVGS are called output characteristics. Other types of characteristics
</p>
<p>20 The term linear originates from the behavior of the curves near the origin, shown by (22.56).
The term is ascribed to the region up to V satDS despite the fact that far away from the origin the curves
are blatantly non linear.</p>
<p/>
</div>
<div class="page"><p/>
<p>22.6 N-Channel MOSFET&mdash;Current-Voltage Characteristics 533
</p>
<p>Fig. 22.15 Low frequency,
small-signal circuit of an
n-channel MOSFET
</p>
<p>iG iB
iD
</p>
<p>iS
</p>
<p>GSv BSv g vBS gmvGS g DSvDB
</p>
<p>are also used to enrich the picture of the MOSFET&rsquo;s behavior: for instance, the
transfer characteristics are the ID = ID
</p>
<p>(
</p>
<p>VGS
)
</p>
<p>curves drawn using VBS as a parameter
and letting VDS = const, with a value of VDS small enough to let the limiting case
(22.56) hold.
</p>
<p>Besides the drain conductance (22.51), two more differential conductances are
defined in a MOSFET: the first one is the transconductancegm, given by the derivative
of ID with respect to VGB, at constant VDB and VSB; or, equivalently, as the derivative
with respect to VGS, at constant VDS and VBS. Observing that VGS appears only in I &prime;D
one finds
</p>
<p>gm =
(
</p>
<p>&part;ID
</p>
<p>&part;VGB
</p>
<p>)
</p>
<p>VSB,VDB
</p>
<p>=
(
</p>
<p>&part;ID
</p>
<p>&part;VGS
</p>
<p>)
</p>
<p>VDS,VBS
</p>
<p>= Î² VDS. (22.59)
</p>
<p>The second one is the bulk transconductance gB , defined as the derivative of ID with
respect to VBS at constant VDS and VGS:
</p>
<p>gB =
(
&part;ID
</p>
<p>&part;VBS
</p>
<p>)
</p>
<p>VDS,VGS
</p>
<p>= &minus;
(
&part;I &prime;&prime;D
&part;VBS
</p>
<p>)
</p>
<p>VDS
</p>
<p>. (22.60)
</p>
<p>The small-signal circuit of an n-channel MOSFET is shown in Fig. 22.15. Since the
circuit is derived from the steady-state transport model, it holds at low frequencies
only. The small-signal voltages are indicated with vDS, vGS, and vBS. The gate and bulk
contacts are left open because the corresponding currents are zero; as a consequence,
iD = iS is the only non-zero small-signal current of the circuit. Observing that
</p>
<p>iD = gD vDS + gm vGS + gB vBS, (22.61)
</p>
<p>the drain-source branch of the circuit is made of three parallel branches. One of them
is represented as a resistor 1/gD because the current flowing in it is controlled by the
voltage vDS applied to the same port; the other two branches are voltage-controlled
generators because the current of each branch is controlled by the voltage applied to
a different port.
</p>
<p>It is worth adding that the body effect mentioned above is actually an incon-
venience, because it introduces a complicate dependence on VBS which must be
accounted for during the circuit&rsquo;s design. The body effect is suppressed by letting</p>
<p/>
</div>
<div class="page"><p/>
<p>534 22 MOS Devices
</p>
<p>VBS = 0: in a circuit&rsquo;s design, this is obtained by shorting the bulk and source con-
tacts, which amounts to reducing the original four-contact device to a three-contact
device.21 This solution is adopted whenever the circuit&rsquo;s architecture allows for it.
</p>
<p>22.6.2.1 Linear&ndash;Parabolic Model
</p>
<p>In semiqualitative circuit analyses the whole term I &prime;&prime;D is neglected, this leading to
a simplified model ID â I &prime;D , called linear&ndash;parabolic model. As the neglect of I &prime;&prime;D
is equivalent to letting Î³ &rarr; 0, it follows gB â 0 and, from the second relation in
(22.56), the simplified threshold voltage reads
</p>
<p>VT â VFB + 2 ÏF . (22.62)
</p>
<p>In turn, from ID â I &prime;D = Î²
[(
</p>
<p>VGS &minus; VT
)
</p>
<p>VDS &minus; V 2DS/2
]
</p>
<p>one finds for the drain
conductance
</p>
<p>gD â Î² (VGS &minus; VFB &minus; 2 ÏF &minus; VDS) = Î² (VGS &minus; VT &minus; VDS) , (22.63)
whence
</p>
<p>V satDS = VGS &minus; VT . (22.64)
The transconductance gm is the same as in the general case. Note that the linear&ndash;
parabolic expression of the drain current may be recast as ID â Î²
</p>
<p>(
</p>
<p>V satDS VDS&minus;V 2DS/2
)
</p>
<p>,
with V satDS given by (22.64). As a consequence,
</p>
<p>I satD â Î²
[
(
</p>
<p>V satDS
)2 &minus; 1
</p>
<p>2
</p>
<p>(
</p>
<p>V satDS
)2
]
</p>
<p>= 1
2
Î² (VGS &minus; VT )2 . (22.65)
</p>
<p>The linear&ndash;parabolic model then yields for the saturation region
</p>
<p>ID = I satD , gD â 0, gm â Î² (VGS &minus; VT ) , gB â 0. (22.66)
An example of the output characteristics of an n-type MOSFET obtained from the
linear&ndash;parabolic model is given in Fig. 22.16, using VT = 1 V, Î² = 0.3 A V&minus;2. The
dashed curve represents (22.65).
</p>
<p>22.7 Complements
</p>
<p>22.7.1 Poisson&rsquo;s Equation in the MOSFET Channel
</p>
<p>The derivation of the MOSFET&rsquo;s current carried out in Sect. 22.6 is based upon
two integrals; the first one, (22.39), is calculated over a section of the channel at
</p>
<p>21 Note that letting VBS = 0 also makes gB to vanish.</p>
<p/>
</div>
<div class="page"><p/>
<p>22.7 Complements 535
</p>
<p>Fig. 22.16 Output
characteristics of an n-type
MOSFET obtained from the
linear&ndash;parabolic model, with
VT = 1 V, Î² = 0.3 A V&minus;2.
The dashed curve represents
(22.65)
</p>
<p>0 2 4 6 8 10
V
</p>
<p>DS
    (V)
</p>
<p>  0.0
</p>
<p>  0.5
</p>
<p>  1.0
</p>
<p>  1.5
</p>
<p>  2.0
</p>
<p>  2.5
</p>
<p>  3.0
</p>
<p>I D
  
  
(m
</p>
<p>A
)
</p>
<p>V
GS
</p>
<p> = 3 V
</p>
<p>V
GS
</p>
<p> = 4 V
</p>
<p>V
GS
</p>
<p> = 5 V
</p>
<p>V
GS
</p>
<p> = 2 V
</p>
<p>V
DS
</p>
<p>sat
</p>
<p>some position y, the second one, (22.44), is calculated along the channel from
y = 0 to y = L. Apparently this procedure eliminates the need of solving the
Poisson equation. In fact, the solution of the latter is deeply rooted in the relation
(22.46), which is a fundamental point of the procedure itself, and in the choice of
the integration limits (22.47), which are also related to (22.46).
</p>
<p>The Poisson equation in a non-equilibrium condition is conveniently tackled by
expressing the carrier concentrations in terms of the quasi-Fermi potentials Ïn and
Ïp; the device considered here is the same n-channel MOSFET of Sect. 22.6. Using
the normalized form un = qÏn/
</p>
<p>(
</p>
<p>kB T
)
</p>
<p>and up = qÏp/
(
</p>
<p>kB T
)
</p>
<p>, the concentrations
read n = ni exp
</p>
<p>(
</p>
<p>u &minus; un
)
</p>
<p>and p = ni exp
(
</p>
<p>up &minus; u
)
</p>
<p>, respectively. Remembering that
in the equilibrium limit it is un, up &rarr; uF , with uF the normalized Fermi potential,
it is useful to introduce the differences
</p>
<p>Ïn = un &minus; uF , Ïp = up &minus; uF , (22.67)
</p>
<p>by which the concentrations take the form
</p>
<p>n = np0 exp
(
</p>
<p>u &minus; Ïn
)
</p>
<p>, p = pp0 exp
(
</p>
<p>Ïp &minus; u
)
</p>
<p>. (22.68)
</p>
<p>In the equilibrium limit it is Ïn,Ïp &rarr; 0. Moreover, when a non-equilibrium con-
dition holds, at any position y in the channel it is limx&rarr;&infin; Ïn,Ïp = 0; in fact,
as observed in Sect. 22.6, far from the channel the semiconductor is practically
in the equilibrium condition, whence Ïn &rarr; ÏF as x increases. The same ap-
plies to Ïp. With these provisions, the charge density in the semiconductor reads
Ï = q
</p>
<p>[
</p>
<p>pp0 exp
(
</p>
<p>Ïp &minus; u
)
</p>
<p>&minus; np0 exp
(
</p>
<p>u &minus; Ïn
)
</p>
<p>&minus;NA
]
</p>
<p>, namely,
</p>
<p>Ï = &minus;qpp0 A, A =
n2i
</p>
<p>N2A
</p>
<p>[
</p>
<p>exp
(
</p>
<p>u &minus; Ïn
)
</p>
<p>&minus; 1
]
</p>
<p>+ 1 &minus; exp
(
</p>
<p>Ïp &minus; u
)
</p>
<p>, (22.69)
</p>
<p>and the Poisson equation takes the form
</p>
<p>&part;2u
</p>
<p>&part;x2
+ &part;
</p>
<p>2u
</p>
<p>&part;y2
= 1
</p>
<p>L2A
A, (22.70)</p>
<p/>
</div>
<div class="page"><p/>
<p>536 22 MOS Devices
</p>
<p>with LA the holes&rsquo; Debye length defined in (21.12). One notes that (22.69), (22.70)
are generalizations of (22.3). In the description of the MOSFET the accumulation
condition is not considered, hence the holes&rsquo; contribution exp
</p>
<p>(
</p>
<p>Ïp &minus; u
)
</p>
<p>to A is
negligible in the channel region; thus,
</p>
<p>A â n
2
i
</p>
<p>N2A
</p>
<p>[
</p>
<p>exp (u &minus; Ïn) &minus; 1
]
</p>
<p>+ 1 â n
2
i
</p>
<p>N2A
exp (u &minus; Ïn) + 1 &gt; 0, (22.71)
</p>
<p>where the term n2i /N
2
A = exp ( &minus; 2 uF ) is negligible with respect to unity. Remem-
</p>
<p>bering that the quasi-Fermi potential in the channel does not depend on x, in (22.71)
it is u = u(x, y), Ïn = Ïn(y), with u(&infin;, y) = 0, u&prime;(&infin;, y) = 0 due to the charge
neutrality of the bulk region; in fact, as shown by numerical solutions, both u and u&prime;
</p>
<p>practically vanish when x reaches the value of the depletion width xd (y).
The Poisson equation is to be solved in two dimensions. If the condition of a
</p>
<p>well-formed channel holds, the components of the electric field along the x and y
directions are quite different from each other. The x component at the semiconductor&ndash;
oxide interface, Esx , which is due to the voltage applied to the gate contact, is large
because it maintains the strong-inversion condition of the surface. Moreover, the
derivative &part;Ex/&part;x = &minus;&part;2u/&part;x2 is also large, because Ex changes from Esx to
zero in the short distance xd (y). In contrast, the y component of the electric field at
the interface, Esy , which is due to the voltage VDS applied between the drain and
source contacts, is small; in fact, VDS is small in itself because the linear region
only is considered, and the channel length L is larger than the insulator thickness.
Moreover, numerical solutions show that for 0 &lt; VDS &lt; V satDS the dependence of
both Esx and Esy on y is weak, which in particular makes &part;Ey/&part;y = &minus;&part;2u/&part;y2
also small at the semiconductor&ndash;insulator interface. In conclusion, one approximates
(22.70) as
</p>
<p>&part;2u
</p>
<p>&part;x2
+ &part;
</p>
<p>2u
</p>
<p>&part;y2
â d
</p>
<p>2u
</p>
<p>dx2
= 1
</p>
<p>L2A
A. (22.72)
</p>
<p>The dependence of A on y remains, and y is treated as a parameter in the solution
procedure. Due to the form of (22.72), the solution method is identical to that used
in Sect. 22.2.1 to treat the equilibrium case; it yields
</p>
<p>(
qEsx
</p>
<p>kB T
</p>
<p>)2
</p>
<p>= 2
L2A
</p>
<p>F 2, F 2 = exp
(
</p>
<p>&minus; Ïn &minus; 2 uF
) [
</p>
<p>exp (us) &minus; 1
]
</p>
<p>+ us . (22.73)
</p>
<p>Remembering that the accumulation condition is excluded, here it is us(y) &ge; 0; the
flat-band condition us = 0 corresponds to F = 0. In the strong-inversion condition
the contribution of the electron charge (proportional to exp
</p>
<p>(
</p>
<p>us
)
</p>
<p>&minus; 1 in (22.73)) is
dominant; for this to happen it is necessary that the exponent us&minus;Ïn&minus;2 uF in (22.73)
be positive; it follows that the threshold condition is identified by us = Ïn + 2 uF .
Remembering the definition (22.67) of Ïn one then finds
</p>
<p>us = un + uF , 0 &le; y &le; L, (22.74)</p>
<p/>
</div>
<div class="page"><p/>
<p>22.7 Complements 537
</p>
<p>that is, the normalized form of (22.46). Note that us = Ïn+2 uF is coherent with the
definition of the threshold condition at equilibrium (Table 22.1), which is obtained
by letting Ïn = 0. Also, specifying us = Ïn + 2 uF at the source and drain ends of
the channel provides the integration limits (22.47) [103, Sect. 10.2].
</p>
<p>The neglect of the variation in the y component of the electric field along the
channel makes the general relation
</p>
<p>Qsc = &minus;Cox (V &prime;GB &minus; Ïs) = &minus;Cox
kB T
</p>
<p>q
(u&prime;GB &minus; us) (22.75)
</p>
<p>still valid at each position y along the channel, withQsc &lt; 0 because us &gt; 0 (Qsc = 0
in the flat-band condition us = 0). Also, when the inversion charge is approximated
by a charge layer at x = 0+, the volume charge is entirely due to the ionized dopants,
whose contribution in the second relation of (22.73) is proportional to us like in the
equilibrium case. Using the same relation Qi = Qsc&minus;Qb as in Sect. 22.4 one finally
finds that the theory worked out in this section makes (22.34) applicable also in a
non-equilibrium condition in which the channel is well formed.
</p>
<p>22.7.2 Inversion-Layer Charge and Mobility Degradation
</p>
<p>In the model (22.49) for the drain current worked out in the previous sections, the
modulus of the inversion-layer chargeQi decreases from source to drain due to the in-
crease inÏs along the channel (compare with (22.34)). Considering that the MOSFET
current is carried by the inversion-layer charge, the vanishing of the latter occurring
at the drain end of the channel when VDS &rarr; V satDS may seem an oddity. However, it
is important to remember that a number of approximations are necessary to reach
the result expressed by (22.57) and (22.58); such approximations make the theory
applicable only in the linear region and in the condition of a well-formed channel.
</p>
<p>WhenVDS &rarr; V satDS , the vertical component of the electric field at the interface,Esx ,
is made weaker by the interplay between the voltages applied to the gate electrode and
to the nearby drain electrode; for this reason, at the drain end of the channel the flow
lines of Jn do not keep close to the interface any longer, but spread into the substrate,
this decreasing the carrier density. The phenomenon is better understood with the aid
of Fig. 22.17, where the linear-parabolic model is used with, e.g., VT = 0.5, VS = 0,
VGS = 1.5, VDS = 2 V.AsV satDS = 1V, the saturation conditionVDS &gt; V satDS = 1 holds.
Along the dash-dotted line enclosed in the right oval, the direction of the electric field
is that shown in the vector diagram in the upper-right part of the figure; in particular,
the vertical component of the field at the position marked by the vertical dashed line
points upwards. As a consequence, the channel electrons are repelled downwards
and the flow lines of the current density detach from the interface. At the source
end of the channel, instead, the vertical component of the field points downwards.
By continuity, a position within the channel exists where, in saturation, the vertical
component of the field vanishes; such a position (not shown in the figure) is called
inversion point. Also, the large component of the electric field along the y direction,</p>
<p/>
</div>
<div class="page"><p/>
<p>538 22 MOS Devices
</p>
<p>Fig. 22.17 Illustration of the
electric field&rsquo;s components at
the channel ends in the
saturation condition
</p>
<p>E
</p>
<p>E
</p>
<p>Ey
</p>
<p>x
</p>
<p>V
G
</p>
<p>V
S
</p>
<p>V
D
</p>
<p>Ey
</p>
<p>Ex
</p>
<p>E
</p>
<p>which exists within the space-charge region of the reverse-biased drain junction,
makes the carriers&rsquo; average velocity to increase at the drain end of the channel; as the
total current is constant, a further decrease in the carrier concentration occurs. The
two effects briefly illustrated above are not accounted for by the simplified model,
and require a more elaborate approach in which the two-dimensional structure of the
electric field is accounted for.
</p>
<p>Another comment is useful, this time related to the off condition. When VGS &rarr;
VT , the current of a real device does not actually vanish; in fact, a current (called
subthreshold current), due to the carriers present in the channel in the weak-inversion
condition, flows for VGS &lt; VT . Also in this case a more elaborate theory is necessary,
showing that the subthreshold current vanishes exponentially as VGS decreases [3].
</p>
<p>It is worth concluding this section by commenting the simplification used in
(22.45), where the effective electron mobility Î¼e is assumed to be independent of
the position y along the channel. The factors that affect mobility in a MOSFET are
collisions with phonons, ionized impurities, and semiconductor&ndash;oxide interface; re-
membering the features of the macroscopic mobility models (Sect. 20.5), the electron
mobility Î¼n(x, y) is made to depend on the lattice temperature T , concentration of
ionized impurities NA, and x component of the electric field Ex(x, y). The first two
parameters, T and NA, do not introduce a dependence on position because they are
themselves constant. The x dependence of Ex is absorbed by the integral (22.42)
that defines Î¼e; it follows that the average mobility depends on y because Ex does.
Such a dependence, in turn, is relatively weak in the strong-inversion condition as
remarked in Sect. 22.7.1. Therefore, the dependence of Î¼e on position is considered
negligible.
</p>
<p>Problems
</p>
<p>22.1 Work out a method for drawing the curves of Fig. 22.9 without approximations.</p>
<p/>
</div>
<div class="page"><p/>
<p>Part VIII
</p>
<p>Miscellany</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 23
</p>
<p>Thermal Diffusion
</p>
<p>23.1 Introduction
</p>
<p>The fabrication of integrated circuits requires the introduction into the semiconductor
material of atoms belonging to specifically-selected chemical species. Such atoms
are called impurities or dopants. As shown in Chap. 18, the inclusion of dopants into
the semiconductor lattice attains the important goals of fixing the concentration of
mobile charges in the material and making it practically independent of temperature.
</p>
<p>Dopants are divided into two classes, termed n-type and p-type. With reference to
silicon (Si), the typical n-type dopants are phosphorus (P), arsenic (As), and antimony
(Sb), while the typical p-type dopants are boron (B), aluminum (Al), gallium (Ga),
and Indium (In). When a dopant atom is introduced into the semiconductor lattice,
in order to properly act as a dopant it must replace an atom of the semiconductor,
namely, it must occupy a lattice position. When this happens, the dopant atom is
also called substitutional impurity. An impurity atom that does not occupy a lattice
position is called interstitial. Interstitials can not properly act as dopants, however,
they degrade the conductivity and other electrical properties of the semiconductor.
</p>
<p>The concentration of the dopant atoms that are introduced into a semiconductor
is smaller by orders of magnitude than the concentration of the semiconductor atoms
themselves. As a consequence, the average distance between dopant atoms within
the lattice is much larger than that between the semiconductor atoms. Thus, the
material resulting from a doping process is not a chemical compound: it is still
the semiconductor in which some of the electrical properties are modified by the
presence of the dopant atoms. In fact, while the presence and type of dopants are
easily revealed by suitable electrical measurements, they may remain undetectable
by chemical analyses.
</p>
<p>As a high-temperature condition is necessary to let the dopant atoms occupy the
lattice position, during the fabrication of the integrated circuit the semiconductor
wafer undergoes several high-temperature processes. This, in turn, activates the
dopant diffusion.
</p>
<p>&copy; Springer Science+Business Media New York 2015 541
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_23</p>
<p/>
</div>
<div class="page"><p/>
<p>542 23 Thermal Diffusion
</p>
<p>The chapter illustrates the diffusive transport with reference to the processes that
are used for introducing impurities into a semiconductor in a controlled way. First,
the expressions of the continuity equation and of the diffusive flux density are de-
rived. These expressions are combined to yield the diffusion equation, whose form
is reduced to a one-dimensional model problem. The model problem allows for an
analytical solution, based on the Fourier-transform method, that expresses the dif-
fused profile at each instant of time as the convolution of the initial condition and an
auxiliary function.
</p>
<p>Then, the solution of the model problem is used to calculate the impurity profiles
resulting from two important processes of semiconductor technology, namely, the
predeposition and the drive-in diffusion. In the last part of the chapter the solution
of the model problem is extended to more general situations. Specific data about the
parameters governing the diffusion processes in semiconductors are in [46, Chap. 3],
[104, Chap. 10], [105, Chap. 7], [71, Chap. 12]. Many carefully-drawn illustrations
of the diffusion process are found in [75, Sect. 1.5]. The properties of the Fourier
transform are illustrated in [72, 118].
</p>
<p>23.2 Continuity Equation
</p>
<p>The continuity equation described in this section is a balance relation for the number
of particles. Here it is not necessary to specify the type of particles that are being
considered: they may be material particles, like molecules or electrons, particles
associated to the electromagnetic field (photons), those associated to the vibrational
modes of atoms (phonons), and so on. Although the type of particles is not specified,
it is assumed that all particles considered in the calculations are of the same type.
</p>
<p>The balance relation is obtained by considering the space where the particles
belong and selecting an arbitrary volume V in it, whose boundary surface is denoted
with S. The position of the volume is fixed. Let N (t) be the number of particles that
are inside S at time t . Due to the motion of the particles, in a given time interval
some of them move across S in the outward direction, namely, from the interior to
the exterior of S. In the same interval of time, other particles move across S in the
inward direction. Let Fout(t) and Fin(t) be the number of particles per unit time that
cross S in the outward or inward direction, respectively, and let F = Fout &minus;Fin. The
quantity F , whose units are s&minus;1, is the flux of the particles across the surface S. If
the only reason that makes N to change is the crossing of S by some particles, the
balance relation takes the form of the first equation in (23.1). The minus sign at the
right hand side is due to the definition of F ; in fact, N decreases with time when
F &gt; 0, and vice versa.
</p>
<p>Besides the crossing of the boundary S by some particles, there is another mech-
anism able to contribute to the time variation of N , namely, the generation or
destruction of particles inside the volume V . This possibility seems to violate some
commonly-accepted conservation principle. However it is not so, as some examples</p>
<p/>
</div>
<div class="page"><p/>
<p>23.2 Continuity Equation 543
</p>
<p>given in Sect. 23.7.1 will show. As a consequence, the description of the particle gen-
eration or destruction must be included. This is accomplished by letting Wge(t) and
Wde(t) be the number of particles per unit time that are generated or, respectively,
destroyed within the volume V . Defining W = Wge &minus; Wde, the balance relation
that holds when generation or destruction are present takes the form of the second
equation in (23.1):
</p>
<p>dN
</p>
<p>dt
= &minus;F , dN
</p>
<p>dt
= &minus;F + W. (23.1)
</p>
<p>The quantity W , whose units are s&minus;1, is the net generation rate within volume V .
It is convenient to recast (23.1) in local form. This is done basing on the second
</p>
<p>equation of (23.1), which is more general, and is accomplished by describing the
motion of the particles as that of a continuous fluid. Such a description is legitimate if
V can be partitioned into equal cells of volume ï¿½V1,ï¿½V2, . . . having the following
properties: (i) the cells can be treated as infinitesimal quantities in the length scale of
the problem that is being considered and, (ii) the number of particles within each cell
is large enough to make their average properties significant. If the above conditions
are fulfilled one lets ï¿½Vk &rarr; dV and introduces the concentration N (r, t), such that
N dV is the number of particles that at time t belong to the volume dV centered
at position r. Similarly, one defines the net generation rate per unit volume W (r, t)
such that W dV is the net generation rate at time t within dV . The units of N and W
are m&minus;3 and m&minus;3 s&minus;1, respectively. From the definitions of N , W it follows that the
number N (t) of particles that are inside S at time t is found by integrating N (r, t)
over V , and that the net generation rate W(t) is found by integrating W over V .
</p>
<p>To recast in local form the part of (23.1) related to the flux F , one associates a
velocity v(r, t) to the concentration N (r, t). In general, such a velocity is different
from the velocity of each individual particle that contributes to the concentration N .
In fact, v is a suitable average of the particles&rsquo; velocities, whose definition (6.6) is
given in Sect. 6.2. In the elementary time dt the concentration originally in r moves
over a distance v dt in the direction of v. As consequence, if r belongs to the boundary
surface S, a crossing of S by the particles may occur, this contributing to the flux.
To calculate the contribution to the flux at a point r belonging to S, one takes the
plane tangent to S at r and considers an elementary area dS of this plane centered at
r (Fig. 23.1). The construction implies that the surface S is smooth enough to allow
for the definition of the tangent plane at each point of it.
</p>
<p>Let s be the unit vector normal to dS, oriented in the outward direction with
respect to S. If v is normal to s, no crossing of S occurs and the contribution to the
flux at point r is zero. If the scalar product v &middot; s is positive, the crossing occurs in
the outward direction and contributes to Fout. Its contribution is found by observing
that the elementary cylinder, whose base area and side are dS and, respectively, v dt ,
has a volume equal to v &middot; s dS dt . Due to the sign of v &middot; s, the cylinder is outside the
surface S. The number of particles in the cylinder is found by multiplying its volume
by the concentration N (r, t). Letting F = Nv, such a number reads F &middot; s dS dt . As
the particles that are in the cylinder at time t + dt were inside the surface S at time
t , dividing the above expression by dt yields the elementary contribution of point r</p>
<p/>
</div>
<div class="page"><p/>
<p>544 23 Thermal Diffusion
</p>
<p>Fig. 23.1 Illustration of the
symbols used in the
calculation of the flux
</p>
<p>dS
</p>
<p>d tv
</p>
<p>V
</p>
<p>S
r
</p>
<p>s
</p>
<p>to the flux, dF = F &middot; s dS &gt; 0. The contribution from a point r where v &middot; s &lt; 0 is
calculated in a similar way. The flux F is then found by integrating F &middot; s over the
surface S. The quantity F &middot; s = dF/dS, whose units are m&minus;2s&minus;1, is the flux density.
</p>
<p>Introducing the relations found so far into the second form of (23.1), and
interchanging the derivative with respect to t with the integral over V , yields
</p>
<p>&int;
</p>
<p>V
</p>
<p>(
&part;N
</p>
<p>&part;t
&minus;W
</p>
<p>)
</p>
<p>dV = &minus;
&int;
</p>
<p>S
</p>
<p>F &middot; s dS = &minus;
&int;
</p>
<p>V
</p>
<p>divF dV. (23.2)
</p>
<p>The last equality in (23.2) is due to the divergence theorem (A.23), whereas the use
of the partial-derivative symbol is due to the fact the N , in contrast with N , depends
also on r. The procedure leading to (23.2) does not prescribe any constraint on the
choice of the volume V . As a consequence, the two integrals over V that appear in
(23.2) are equal to each other for any V . It follows that the corresponding integrands
must be equal to each other, this yielding the continuity equation
</p>
<p>&part;N
</p>
<p>&part;t
+ divF = W , F = Nv. (23.3)
</p>
<p>As mentioned above, (23.3) is the local form of the second equation of (23.1), which
in turn is a balance relation for the number of particles. In the steady-state condition
the quantities appearing in (23.3) do not depend explicitly on time, hence (23.3)
reduces to divF = W . In the equilibrium condition it is v = 0 and (23.3) reduces to
the identity 0 = 0. It is worth noting that in the equilibrium condition the velocity
of each particle may differ from zero; however, the distribution of the individual
velocities is such that the average velocity v vanishes. Similarly, in the equilibrium
condition the generation or destruction of particles still occurs; however, they balance
each other within any dV .
</p>
<p>To proceed it is assumed that the net generation rate per unit volume W , besides
depending explicitly on r and t , may also depend on N and F, but not on other
functions different from them.</p>
<p/>
</div>
<div class="page"><p/>
<p>23.3 Diffusive Transport 545
</p>
<p>23.3 Diffusive Transport
</p>
<p>The continuity Eq. (23.3) provides a relation between the two quantities N and F
(or, equivalently, N and v). If both N and F are unknown it is impossible, even in
the simple case W = 0, to calculate them from (23.3) alone. However, depending on
the specific problem that is being considered, one can introduce additional relations
that eventually provide a closed system of differential equations. The important case
of the diffusive transport is considered in this section.
</p>
<p>It is convenient to specify, first, that the term transport indicates the condition
where an average motion of the particles exists, namely F ï¿½= 0 for some r and t .
The type of transport in which the condition F ï¿½= 0 is caused only by the spatial
nonuniformity of the particles&rsquo; concentration N is called diffusive. Simple examples
of diffusive transport are those of a liquid within another liquid, or of a gas within
another gas. They show that in the diffusive motion of the particles, the flux density
is oriented from the regions where the concentration is larger towards the regions
where the concentration is smaller.
</p>
<p>The analytical description of the diffusion process dates back to 1855 [36]. Here
the relation between F and N in the diffusive case is determined heuristically, basing
on the observation that gradN is a sensible indicator of the spatial nonuniformity of
N . Specifically it is assumed, first, that F depends onN and gradN , but not on higher-
order derivatives ofN . The dependence on gradN is taken linear, F = F0&minus;D gradN ,
with F0 = 0 because F must vanish when the concentration is uniform. Finally, one
remembers that the particles&rsquo; flux density is oriented in the direction of a decreasing
concentration, namely, opposite to gradN . It follows that D &gt; 0, so that the relation
takes the form
</p>
<p>F = &minus;D gradN , D &gt; 0. (23.4)
</p>
<p>The above is called transport equation of the diffusion type, or Fick&rsquo;s first law of
diffusion. Parameter D is the diffusion coefficient, whose units are m2 s&minus;1. From the
derivation leading to (23.4) it follows that, if a dependence of F on N exists, it must
be embedded in D. In the case D = D(N ) the relation (23.4) is linear with respect
to gradN , but not with respect to N . The diffusion coefficient may also depend
explicitly on r and t . For instance, it depends on position when the medium where
the diffusion occurs is nonuniform; it depends on time when an external condition
that influences D, e.g., temperature, changes with time.
</p>
<p>For the typical dopants used in the silicon technology, and in the temperature
range of the thermal-diffusion processes, the experimentally-determined dependence
on temperature of the diffusion coefficient can be approximated by the expression
</p>
<p>D = D0 exp [ &minus; Ea/(kBT )], (23.5)
</p>
<p>where kB (J K&minus;1) is the Boltzmann constant and T (K) the process temperature. In
turn, the activation energy Ea and D0 are parameters whose values depend on the
material involved in the diffusion process. The form of (23.5) makes it more conve-
nient to draw it as an Arrhenius plot, that displays the logarithm of the function using</p>
<p/>
</div>
<div class="page"><p/>
<p>546 23 Thermal Diffusion
</p>
<p>the inverse temperature as a variable: logD = log (D0)&minus; (Ea/kB) (1/T ). At the dif-
fusion temperatures, Ea and D0 can often be considered independent of temperature.
In this case the Arrhenius plot is a straight line (examples of Arrhenius plots are given
in Chap. 24). At room temperature the diffusion coefficient of dopants in silicon is
too small to make diffusion significant. In order to activate the diffusion mechanism
a high-temperature process is necessary, typically between 900 and 1100â¦C.
</p>
<p>23.4 Diffusion Equation&mdash;Model Problem
</p>
<p>Inserting (23.4) into (23.3) yields the diffusion equation
</p>
<p>&part;N
</p>
<p>&part;t
= div(D gradN ) +W , (23.6)
</p>
<p>where W depends on r, t , N , and gradN at most, while D depends on r, t , and
N at most. The above is a differential equation in the only unknown N . It must be
supplemented with the initial condition N0(r) = N (r, t = 0) and suitable boundary
conditions for t &gt; 0. If the diffusion coefficient is constant, or depends on t at most,
(23.6) becomes
</p>
<p>&part;N
</p>
<p>&part;t
= D&nabla;2N +W , D = D(t). (23.7)
</p>
<p>It is convenient to consider a simplified form of (23.7) to be used as a model problem.
For this, one takes the one-dimensional case in the x direction and lets W = 0, this
yielding
</p>
<p>&part;N
</p>
<p>&part;t
= D &part;
</p>
<p>2N
</p>
<p>&part;x2
. (23.8)
</p>
<p>Equation (23.8) is also called Fick&rsquo;s second law of diffusion. Thanks to the linearity
of (23.8), the solution can be tackled by means of the Fourier-transform method,
specifically, by transforming both sides of (23.8) with respect to x. Indicating1 with
G(k, t) = FxN the transform ofN with respect to x, and using some of the properties
of the Fourier transform illustrated in Appendix C.2, one finds
</p>
<p>Fx
&part;N
</p>
<p>&part;t
= dG
</p>
<p>dt
, FxD
</p>
<p>&part;2N
</p>
<p>&part;x2
= DFx
</p>
<p>&part;2N
</p>
<p>&part;x2
= &minus;k2DG. (23.9)
</p>
<p>The symbol of total derivative is used at the right hand side of the first of (23.9)
because k is considered as a parameter. The Fourier transform of the initial condition
of N provides the initial condition for G, namely, G0 = G(k, t = 0) = FxN0.
</p>
<p>1 Symbol Fx indicating the Fourier transform should not be confused with the symbol F used for
the particles&rsquo; flux in Sect. 23.2.</p>
<p/>
</div>
<div class="page"><p/>
<p>23.5 Predeposition and Drive-in Diffusion 547
</p>
<p>Equating the right hand sides of (23.9) and rearranging yields dG/G = &minus;k2D(t) dt .
Integrating the latter from 0 to t ,
</p>
<p>log (G/G0) = &minus;k2a(t), a(t) =
&int; t
</p>
<p>0
D(t &prime;) dt &prime;, (23.10)
</p>
<p>with a an area. The concentrationN is now found by antitransforming the expression
of G extracted from the first of (23.10):
</p>
<p>N (x, t) = F&minus;1k G =
1&radic;
2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
G0 exp (ikx &minus; ak2) dk. (23.11)
</p>
<p>In turn, G0 within the integral of (23.11) is expressed as the transform of N0. After
rearranging the integrals one finds
</p>
<p>N (x, t) =
&int; +&infin;
</p>
<p>&minus;&infin;
N0(Î¾ )
</p>
<p>{&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>1
</p>
<p>2Ï
exp [ik (x &minus; Î¾ ) &minus; ak2] dk
</p>
<p>}
</p>
<p>dÎ¾. (23.12)
</p>
<p>As shown in Appendix C.7, the expression in braces in (23.12) is the integral form
of the function Î(x &minus; Î¾ , t) defined by (C.75). As a consequence, the solution of the
simplified form (23.8) of the diffusion equation is the convolution between Î and
the initial condition N0, namely,
</p>
<p>N (x, t) =
&int; +&infin;
</p>
<p>&minus;&infin;
N0(Î¾ )Î(x &minus; Î¾ , t) dÎ¾. (23.13)
</p>
<p>A straightforward calculation shows that Î fulfills (23.8) for all Î¾ . As a consequence,
(23.13) is a solution as well. In addition, due to (C.79), (23.13) also fulfills the initial
condition N0.
</p>
<p>23.5 Predeposition and Drive-in Diffusion
</p>
<p>Basing on the model problem worked out in Sect. 23.4 it is possible to describe the
thermal diffusion of dopants in silicon. The modification induced in the electrical
properties of the silicon lattice by the inclusion of atoms belonging to different
chemical species (e.g., phosphorus or boron) are described elsewhere (Sects. 18.4.1
and 18.4.2). Here the analysis deals with the diffusion process in itself.
</p>
<p>The formation of a diffused profile in silicon is typically obtained in a two-step
process [46, 75, 105]. In the first step, called predeposition, a shallow layer of dopants
is introduced into the semiconductor. The most common predeposition methods are
the diffusion from a chemical source in a vapor form or the diffusion from a solid
source (e.g., polycrystalline silicon) having a high concentration of dopants in it.
In both methods the silicon wafers are placed in contact with the source of dopant
within a furnace kept at a high temperature.</p>
<p/>
</div>
<div class="page"><p/>
<p>548 23 Thermal Diffusion
</p>
<p>-10 -5 0 5 10
x coordinate (a.u.)
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>1.5
</p>
<p>2
</p>
<p>C
om
</p>
<p>pl
em
</p>
<p>en
ta
</p>
<p>ry
 e
</p>
<p>rr
or
</p>
<p> f
u
nc
</p>
<p>tio
n
</p>
<p>0.0025
0.04
0.25
1
4
</p>
<p>Fig. 23.2 Normalized profiles N/C produced at different instants by a predeposition, using the
first of (23.15) as initial condition with arbitrary units for the x coordinate. The outcome is a set of
complementary error functions whose expression is the first of (23.16). The legends show the value
of 4 a for each curve, also in arbitrary units, with a = a(t) given by the second of (23.10)
</p>
<p>During a predeposition step, new dopant atoms are continuously supplied by the
source to the silicon region. As a consequence, the number of dopant atoms in the
silicon region increases with time. When the desired amount of atoms is reached,
the supply of dopants is blocked, whereas the diffusion process is continued. During
this new step, called drive-in diffusion, the number of dopant atoms in the silicon
region remains constant. The drive-in diffusion is continued until a suitable profile
is reached.
</p>
<p>Typically, the blocking of the flow of dopant atoms from the source to the silicon
region is achieved by introducing oxidizing molecules into the furnace atmosphere,
this resulting in the growth of a silicon-dioxide layer at the silicon surface (the details
of the oxidation process are given in Chap. 24).
</p>
<p>It is worth anticipating that in some processes the predeposition step is skipped,
and the dopant atoms are introduced into the silicon wafers at low temperature by
means of an ion-implantation process. The implanted wafers are then placed into the
high-temperature furnace to activate the drive-in diffusion.
</p>
<p>23.5.1 Predeposition
</p>
<p>Figure 23.2 provides a schematic picture of the source&ndash;wafer structure during a
predeposition step. The interface between wafer and source is assumed to coincide
with the y, z plane, with the x axis oriented towards the wafer&rsquo;s bulk, and the initial
condition N0 is assumed constant in the source region. The diffusion coefficients in
the source and wafer regions are provisionally taken equal to each other. Thanks to
these assumptions the problem has no dependencies on the y, z variables, and the
one-dimensional form (23.8) of the diffusion equation holds. In the practical cases
the extent of the source region in the x direction is large and the concentration of the</p>
<p/>
</div>
<div class="page"><p/>
<p>23.5 Predeposition and Drive-in Diffusion 549
</p>
<p>dopant atoms in it is high. As a consequence, the source is not depleted when the
atoms diffuse into the wafer. The spatial form of the concentration N at a given time
t = t &prime; is called diffused profile. Its integral over the semiconductor region,
</p>
<p>Q(t &prime;) =
&int; +&infin;
</p>
<p>0
N (x, t = t &prime;) dx (m&minus;2), (23.14)
</p>
<p>is called dose.
For convenience the constant value of the initial condition in the source region is
indicated with 2C (m&minus;3). It follows that the initial condition of the predeposition
step is given by the first of (23.15). In turn, the general expression (23.13) of the
dopant concentration reduces to the second of (23.15):
</p>
<p>N0(Î¾ ) =
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>2C Î¾ &lt; 0
</p>
<p>0 Î¾ &gt; 0
; N (x, t) = 2C
</p>
<p>&int; 0
</p>
<p>&minus;&infin;
Î(x &minus; Î¾ , t) dÎ¾. (23.15)
</p>
<p>Using (C.78) and (C.71) one finds the following expressions for the diffused profile
and dose of the predeposition step,
</p>
<p>N (x, t) = C erfc
(
</p>
<p>x&radic;
4a
</p>
<p>)
</p>
<p>, Q(t) = C
&radic;
</p>
<p>4a
</p>
<p>Ï
, (23.16)
</p>
<p>where the dependence on t derives from the second of (23.10). As parameter a
increases with time, the dose increases with time as well, consistently with the
qualitative description of predeposition given earlier in this section. In most cases
the diffusion coefficient is independent of time, a = D t , this yielding Q &prop; &radic;t .
</p>
<p>Still from the second of (23.10) one finds a(0) = 0. Combining the latter with the
properties (C.69) of the complementary error function shows that limt&rarr;0+ N (x, t)
coincides with the initial condition given by the first of (23.15). Also, the solution
(23.16) fulfills the boundary conditions N ( &minus;&infin;, t) = 2C, N ( +&infin;, t) = 0 at any
t &gt; 0. Finally it is N (0, t) = C at any t &gt; 0. This explains the term constant-source
diffusion that is also used to indicate this type of process. In fact, the concentra-
tion at the wafer&rsquo;s surface is constant in time. Figure 23.2 shows the normalized
concentration N/C calculated from the first of (23.16) at different values of a.
</p>
<p>The analysis of the diffusion process carried out so far was based on the as-
sumption of a position-independent diffusion coefficient D. In the actual cases this
assumption is not fulfilled because the dopant source and the wafer are made of
different materials. As a consequence, the solution of (23.8) must be reworked. In
the case of predeposition this is accomplished with little extra work, which is based
on the first of (23.16) as shown below.
</p>
<p>One assumes, first, that the diffusion coefficient in either region is independent of
time, as is the standard condition of the typical processes. In each region the diffusion
coefficient takes a spatially-constant value, say, DS in the source and DW ï¿½= DS in
the wafer. Now, observe that (23.8) is homogeneous and contains the derivatives
of N , but not N itself. It follows that, if C erfc[x/(4a)1/2] is the solution of (23.8)</p>
<p/>
</div>
<div class="page"><p/>
<p>550 23 Thermal Diffusion
</p>
<p>fulfilling some initial and boundary conditions, then A erfc[x/(4a)1/2] + B is also
a solution of (23.8), fulfilling some other conditions that depend on the constants A
and B. One then lets, with t &gt; 0,
</p>
<p>NS = AS erfc
(
</p>
<p>x&radic;
4DS t
</p>
<p>)
</p>
<p>+ BS , x &lt; 0, (23.17)
</p>
<p>NW = AW erfc
(
</p>
<p>x&radic;
4DW t
</p>
<p>)
</p>
<p>+ BW , x &gt; 0, (23.18)
</p>
<p>and fixes two relations among the constants in order to fulfill the initial conditions
(23.15):
</p>
<p>lim
t=0+
</p>
<p>NS = 2AS + BS = 2C, lim
t=0+
</p>
<p>NW = BW = 0. (23.19)
</p>
<p>In order to fix the remaining constants one must consider the matching conditions of
the two regional solutions (23.17, 23.18) at the source&ndash;wafer interface. The concen-
trations across an interface between two different media are related by the segregation
coefficient k [105, Sect. 1.3.2]. Also, given that no generation or destruction of dopant
atoms occurs at the interface, the flux density &minus;D &part;N/&part;x must be continuous there.
In summary, the matching conditions at the source&ndash;wafer interface are
</p>
<p>NW (0
+, t) = k NS(0&minus;, t), DW
</p>
<p>(
&part;NW
</p>
<p>&part;x
</p>
<p>)
</p>
<p>0+
= DS
</p>
<p>(
&part;NS
</p>
<p>&part;x
</p>
<p>)
</p>
<p>0&minus;
. (23.20)
</p>
<p>Using (23.17, 23.18, 23.19) transforms (23.20) into AW = k (2C&minus;AS) and, respec-
tively,
</p>
<p>&radic;
DW AW =
</p>
<p>&radic;
DS AS whence, remembering the first of (23.19) and letting
</p>
<p>Î· = DW/DS ,
</p>
<p>AS =
k
&radic;
Î·
</p>
<p>1 + k&radic;Î· 2C, BS =
1 &minus; k&radic;Î·
1 + k&radic;Î· 2C, AW =
</p>
<p>k
</p>
<p>1 + k&radic;Î· 2C. (23.21)
</p>
<p>Thanks to (23.21), the concentration of the dopant atoms in the source region at the
source&ndash;wafer interface at t &gt; 0 turns out to beNS(0&minus;, t) = AS+BS = 2C/(1+k&radic;Î·).
If, in particular, the source of dopant is in the gaseous phase, it is Î· âª 1. As k
is of order unity, one finds for the gaseous source NS(0&minus;, t) â 2C, namely, the
interface concentration of the source region is practically equal to the asymptotic
one. Figure 23.3 shows the diffused profile N calculated from (23.17, 23.18) at two
different instants t1 and t2 = 16 t1, with DS = 400DW . The coefficients are, in
arbitrary units, AS = 2, BS = 78, AW = 40, BW = 0. From the first of (23.19)
it follows C = 41. Letting (4DW t1)1/2 = 1 (a.u.) one has (4DS t1)1/2 = 20,
(4DW t2)1/2 = 4, and (4DW t2)1/2 = 80. These values are used to calculate the four
curves shown in the figure.</p>
<p/>
</div>
<div class="page"><p/>
<p>23.5 Predeposition and Drive-in Diffusion 551
</p>
<p>Fig. 23.3 Diffused profiles
calculated at t1 and t2 = 16 t1
when two different materials
are involved. The calculation
is based on (23.17), (23.18) as
described at the end of
Sect. 23.5.1. The legends
show the (4Dt)1/2 value for
each curve
</p>
<p>-4 -2 0 2 4
x coordinate (a. u.)
</p>
<p>0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>D
if
</p>
<p>fu
se
</p>
<p>d
 p
</p>
<p>ro
fi
</p>
<p>le
 N
</p>
<p>    1
    4
  20
  80
</p>
<p>23.5.2 Drive-in Diffusion
</p>
<p>As indicated at the beginning of this section, the drive-in diffusion is started when the
desired amount of atoms has been introduced into the silicon lattice, and is continued
until a suitable profile is reached.
</p>
<p>In principle, the profile to be used as initial condition of a drive-in diffusion is
not exactly equal to the final profile of the predeposition step. In fact, the boundary
condition (&part;NW/&part;x)0+ is different from zero during the predeposition step. Instead,
during the growth of the silicon-dioxide layer that blocks the supply of dopant atoms
from the source region, the boundary condition becomes equal to zero to adapt to
the situation of a vanishing flux density of dopants across the interface.
</p>
<p>The calculation of the drive-in diffusion is tackled more easily by assuming that the
blocking of the supply of dopants atoms is instantaneous, so that the final profile of the
predeposition step is &ldquo;frozen&rdquo;. Then, one considers the full domain &minus;&infin; &lt; x &lt; +&infin;
instead of the wafer domain 0 &le; x &lt; +&infin;, with the same diffusion coefficient
D = DW everywhere. In this way one can still use the model problem (23.8). As for
the initial condition N0, one mirrors the final profile of the predeposition step over
the negative axis, this making the initial condition even with respect to x. Letting
x &larr; &minus;x in (23.13) one easily proves that N (&minus; x, t) = N (x, t) if N0(&minus; Î¾ ) = N0(Î¾ );
namely, if the initial condition is even, then the solution is even at all times. With
the provisions above one finds (&part;NW/&part;x)0+ = &minus;(&part;NW/&part;x)0&minus; , which automatically
fulfills the condition of a vanishing flux density of dopants across the origin. Then,
the application of (23.13) provides the profile of the drive-in diffusion in the wafer
region 0 &le; x &lt; +&infin;.
</p>
<p>The final profile (23.16) of the predeposition step, used as initial condition, does
not lend itself to an analytical calculation of the drive-in diffusion. Some examples
of calculation are given below, in which profiles of a simpler form than (23.16) are
used as approximations. Let Q be the dose present within the wafer region. As a first
example one lets
</p>
<p>N0(Î¾ ) = 2QÎ´(Î¾ ), N (x, t) = 2Q
&int; +&infin;
</p>
<p>&minus;&infin;
Î´(Î¾ )Î(x &minus; Î¾ , t) dÎ¾. (23.22)</p>
<p/>
</div>
<div class="page"><p/>
<p>552 23 Thermal Diffusion
</p>
<p>From the properties of the Dirac Î´ (Sect. C.4) it follows
</p>
<p>N (x, t) = 2QÎ(x, t) = 2Q exp [ &minus; x
2/(4 a)]&radic;
</p>
<p>4Ï a
, (23.23)
</p>
<p>showing that, when the initial condition is a Dirac Î´, the profile resulting from a
diffusion process is Gaussian. Only the portion of (23.23) belonging to the wafer
region, that is, x &ge; 0, must in fact be considered. Integrating (23.23) from 0 to
+&infin; and using (C.77) yields the expected value Q of the dose at all times. Although
rather crude, the approximation of using a Dirac Î´ as initial condition is acceptable,
because the profile obtained from a predeposition or an ion-implantation process is
typically very thin.
</p>
<p>As a second example one takes a Gaussian profile as the initial condition, specif-
ically, the second of (23.23) where, to better distinguish the symbols, a is replaced
with a1. It is assumed that the drive-in diffusion to be calculated is characterized by
another value of the parameter, say, a2. The difference between a2 and a1 may be due
to the duration of the diffusion process under investigation, to a temperature-induced
difference in the diffusion coefficients, or both. As usual the instant t = 0 is set as
the initial time of the diffusion process. Applying (23.13) yields
</p>
<p>N (x, t) = 2Q
&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>exp [ &minus; Î¾ 2/(4 a1)]&radic;
4Ï a1
</p>
<p>exp [ &minus; (x &minus; Î¾ )2/(4 a2)]&radic;
4Ï a2
</p>
<p>dÎ¾. (23.24)
</p>
<p>Using the auxiliary variable Î· = Î¾&minus;a1 x/(a1+a2), whence x&minus;Î¾ = &minus;Î·+a2 x/(a1+
a2), transforms the exponent of (23.24) as
</p>
<p>&minus; Î¾
2
</p>
<p>4 a1
&minus; (x &minus; Î¾ )
</p>
<p>2
</p>
<p>4 a2
= &minus; x
</p>
<p>2
</p>
<p>4 (a1 + a2)
&minus; a1 + a2
</p>
<p>4 a1a2
Î·2. (23.25)
</p>
<p>Then, integrating with respect to
&radic;
</p>
<p>(a1 + a2)/(4a1a2) Î· and using again (C.77) yields
</p>
<p>N (x, t) = 2Q exp [ &minus; x
2/(4 a1 + 4 a2)]&radic;
</p>
<p>4Ï (a1 + a2)
. (23.26)
</p>
<p>As before, the integral of the profile from 0 to +&infin; yields the dose Q at all
times. The result expressed by (23.26) is important because it shows that a diffusion
process whose initial condition is a Gaussian profile yields another Gaussian profile.
The parameter of the latter is found by simply adding the parameter a2 =
</p>
<p>&int; t
</p>
<p>0 D(t
&prime;) dt &prime;
</p>
<p>of the diffusion process in hand, whose duration is t , to the parameter a1 of the initial
condition. Clearly, the result is also applicable to a sequence of successive diffusion
processes. In fact, it is used to calculate the final profiles after the wafers have
undergone the several thermal processes that are necessary for the integrated-circuit
fabrication.</p>
<p/>
</div>
<div class="page"><p/>
<p>23.7 Complements 553
</p>
<p>23.6 Generalization of the Model Problem
</p>
<p>The generalization of the model problem (23.8) to three dimensions, that is, Eq. (23.7)
withW = 0 and initial conditionN0(r) = N (r, t = 0), is still tackled by means of the
Fourier transform. For this, it is necessary to define the vectors r = (r1, r2, r3), s =
(s1, s2, s3), k = (k1, k2, k3), and the elements d3k = dk1 dk2 dk3, d3s = ds1 ds2 ds3.
Using (C.20) and following the procedure of Sect. 23.4, one finds again the relations
(23.10). This time, however, it is k2 = k21 + k22 + k23 . The solution N (r, t) is readily
found as a generalization of (23.12), namely
</p>
<p>N (r, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
N0(s)
</p>
<p>{&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>1
</p>
<p>(2Ï )3
exp [ik &middot; (r &minus; s) &minus; ak2] d3k
</p>
<p>}
</p>
<p>d3s.
</p>
<p>(23.27)
</p>
<p>The expression in braces in (23.27) is the product of three functions of the same form
as (C.75). It follows
</p>
<p>N (r, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
N0(s)
</p>
<p>exp [ &minus; |r &minus; s|2/(4a)]
(4Ï a)3/2
</p>
<p>d3s. (23.28)
</p>
<p>When the net generation rate per unit volume, W , is different from zero, it is in
general impossible to find an analytical solution of (23.7). An important exception
is the case where W is linear with respect to N and has no explicit dependence on r
or t . In this case (23.7) reads
</p>
<p>&part;N
</p>
<p>&part;t
= D&nabla;2N &minus; N &minus;Na
</p>
<p>Ï
, D = D(t), (23.29)
</p>
<p>where the two constants Na (m&minus;3) and Ï (s) are positive. This form of W is such that
the particles are generated if N (r, t) &lt; Na , while they are destroyed if N (r, t) &gt;
Na . Equation (23.29) is easily solved by introducing an auxiliary function N &prime; such
that N = Na + N &prime; exp ( &minus; t/Ï ). In fact, N &prime; turns out to be the solution of the
three-dimensional model problem, so that, using (23.28), the solution of (23.29)
reads
</p>
<p>N (r, t) = Na + exp ( &minus; t/Ï )
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
N0(s)
</p>
<p>exp [ &minus; |r &minus; s|2/(4a)]
(4Ï a)3/2
</p>
<p>d3s. (23.30)
</p>
<p>23.7 Complements
</p>
<p>23.7.1 Generation and Destruction of Particles
</p>
<p>The discussion carried out in Sect. 23.2 about the continuity equation implies the
possibility that particles may be generated or destroyed. To tackle this issue consider
the problem &ldquo;counting the time variation of students in a classroom&rdquo;. Assuming</p>
<p/>
</div>
<div class="page"><p/>
<p>554 23 Thermal Diffusion
</p>
<p>that the classroom has only one exit, to accomplish the task it suffices to count the
students that cross the exit, say, every second. The students that enter (leave) the
room are counted as a positive (negative) contribution.
</p>
<p>Consider now a slightly modified problem: &ldquo;counting the time variation of non-
sleeping students in a classroom&rdquo;. To accomplish the task it does not suffice any more
to count the students that cross the exit. In fact, a student that is initially awake inside
the classroom may fall asleep where she sits (one assumes that sleeping students do
not walk); this provides a negative contribution to the time variation sought, without
the need of crossing the exit. Similarly, an initially-sleeping student may wake up,
this providing a positive contribution. Falling asleep (waking up) is equivalent to
destruction (creation) of a non-sleeping student.
</p>
<p>In the two examples above the objects to be counted are the same, however, in the
second example they have an extra property that is not considered in the first one.
This shows that creation/destruction of a given type of objects may occur or not,
depending on the properties that are considered. When particles instead of students
are investigated, it is often of interest to set up a continuity equation for describing the
time variation, in a given volume, of the particles whose energy belongs to a specified
range. Due to their motion, the particles undergo collisions that change their energy.
As a consequence a particle may enter, or leave, the specified energy range without
leaving the spatial volume to which the calculation applies. In this example the origin
of the net generation rate per unit volume W introduced in Sect. 23.2 is the extra
property about the particles&rsquo; energy.
</p>
<p>23.7.2 Balance Relations
</p>
<p>As indicated in Sect. 23.2, and with the provisions illustrated in Sect. 23.7.1, the
continuity equation is a balance relation for the number of particles. Due to its intrin-
sic simplicity and generality, the concept of balance relation is readily extended to
physical properties different from the number of particles; for instance, momentum,
energy, energy flux, and so on. A detailed illustration of this issue is given in Chap. 19.
It is also worth noting, in contrast, that the transport equation of the diffusion type
(23.4), being based on a specific assumption about the transport mechanism, is less
general than the continuity equation.
</p>
<p>23.7.3 Lateral Diffusion
</p>
<p>The treatment of predeposition and drive-in diffusion carried out in Sect. 23.5 is
based on a one-dimensional model. This implies that the concentration of the dopant
at the interface between the source and wafer regions is constant along the y and
z directions. In the practical cases this is impossible to achieve, because the area
over which the source is brought into contact with the wafer is finite. In fact, prior</p>
<p/>
</div>
<div class="page"><p/>
<p>23.7 Complements 555
</p>
<p>to the predeposition step the surface of the wafer is covered with a protective layer,
called mask. As indicated in Sect. 24.1, in the current silicon technology the mask
is typically made of thermally-grown silicon dioxide. Next, a portion of the mask is
removed to expose the silicon surface over a specific area, called window, through
which the predeposition step takes place.
</p>
<p>From the description above it follows that the initial condition N0 of the predepo-
sition step is constant only within the window, while it is equal to zero in the other
parts of the y, z plane. This makes the hypothesis of a one-dimensional phenomenon
inappropriate, and calls for the use of the three-dimensional solution (23.28). The
subsequent drive-in diffusions must be treated in three dimensions as well, due to
the form of their initial conditions. An important effect is the diffusion of the dopant
underneath the edges of the mask. This phenomenon, called lateral diffusion, makes
the area where the doping profile is present larger than the original mask, and must
be accounted for in the design of the integrated circuit.
</p>
<p>23.7.4 Alternative Expression of the Dose
</p>
<p>The definition of the dose Q deriving from the one-dimensional model problem
is (23.14). Letting W = 0 in (23.3), using its one-dimensional form &part;N/&part;t =
&minus;&part;F/&part;x, and observing that it is F ( +&infin;, t) = 0 due to the initial condition, gives
the following expression for the time derivative of the dose:
</p>
<p>dQ
</p>
<p>dt
= &minus;
</p>
<p>&int; +&infin;
</p>
<p>0
</p>
<p>&part;F (x, t)
</p>
<p>&part;x
dx = F (0, t). (23.31)
</p>
<p>Integrating (23.31) and remembering that the dose at t = 0 is equal to zero yields
</p>
<p>Q(t &prime;) =
&int; t &prime;
</p>
<p>0
F (0, t) dt. (23.32)
</p>
<p>The procedure leading from the original definition (23.14) of the dose to its alternative
expression (23.32) is based solely on (23.3), hence it does not depend on a specific
transport model.
</p>
<p>23.7.5 The Initial Condition of the Predeposition Step
</p>
<p>The initial condition N0 of the predeposition step is given by the first of (23.15).
To carry out the solution of the diffusion equation it is necessary to recast N0 in
an integral representation of the Fourier type. However, (23.15) does not fulfill the
condition (C.19) that is sufficient for the existence of such a representation.
</p>
<p>Nevertheless the solution procedure leading to (23.13) is still applicable. In fact,
remembering the definition (C.8) of the unit step function H , the initial condition</p>
<p/>
</div>
<div class="page"><p/>
<p>556 23 Thermal Diffusion
</p>
<p>can be recast as N0(Î¾ ) = 2C [1 &minus;H (Î¾ )]. In turn, as shown in appendix C.4, H can
be represented in the required form.
</p>
<p>Problems
</p>
<p>23.1 A Gaussian doping profileN = 2Q exp (&minus;x2/c1)/
&radic;
Ïc1 undergoes a thermal-
</p>
<p>diffusion process at a temperature such that D = 10&minus;11 cm2/s. Assuming
c1 = 1.6 &times; 10&minus;7 cm2, calculate the time that is necessary to reduce the peak
value of the profile to 2/3 of the initial value.
</p>
<p>23.2 A Gaussian doping profile N = 2Q exp (&minus;x2/c1)/
&radic;
Ïc1, c1 = 9&times;10&minus;8 cm2,
</p>
<p>undergoes a thermal-diffusion process with c2 = 16 &times; 10&minus;8 cm2 yielding
another Gaussian profile. Find the value xÌ (in microns) where the two profiles
cross each other.
</p>
<p>23.3 A Gaussian doping profile N = 2Q exp ( &minus; x2/c1)/
&radic;
Ï c1, c1 = 2.5 &times;
</p>
<p>10&minus;6 cm2, undergoes a 240 min-long thermal-diffusion process at a tempera-
ture such that the diffusion coefficient is D = 2.5&times;10&minus;10 cm2 s&minus;1. Determine
the ratio between the peak value of the final profile and that of the initial one.
</p>
<p>23.4 A Gaussian doping profile N = 2Q exp ( &minus; x2/c1)/
&radic;
Ï c1, c1 = 10&minus;6 cm2,
</p>
<p>undergoes a thermal-diffusion process in which c2 = 3 &times; 10&minus;8 cm2. Find the
position xÌ (in microns) where the value of the initial doping profile equals the
value that the final profile has in x = 0.
</p>
<p>23.5 A Gaussian doping profile N = 2Q exp ( &minus; x2/c1)/
&radic;
Ï c1) undergoes a
</p>
<p>thermal-diffusion process in which c2 = 10&minus;8 cm2. The value of the final
profile in the origin is equal to that of the initial profile at x0 = 1.1 &times;
</p>
<p>&radic;
c1.
</p>
<p>Find the value of c1 in cm2.
23.6 A Gaussian doping profile N = 2Q exp ( &minus; x2/c1)/
</p>
<p>&radic;
Ï c1), c1 = 1.8 &times; 10&minus;8
</p>
<p>cm2, undergoes a thermal-diffusion process whose duration is t = 10 min,
with D = 10&minus;11 cm2 s&minus;1. At the end of the process the concentration at some
point x0 is N1 = 3 &times; 1016 cm&minus;3. If the process duration were 20 min, the
concentration at the same point would be N2 = 3 &times; 1017. Find the value of x0
in microns.
</p>
<p>23.7 The doping profile resulting from a predeposition process with D =
10&minus;11 cm2 s&minus;1 is N (x) = NS erfc(x/
</p>
<p>&radic;
c). The ratio between the dose and
</p>
<p>surface concentration is Q/NS = Î»/
&radic;
Ï , Î» = 1095 nm. Find the duration t of
</p>
<p>the predeposition process, in minutes.
23.8 The initial condition of a drive-in diffusion is given by N0 = 2Q (h &minus; x)/h2
</p>
<p>for 0 &le; x &le; h, and by N0 = 0 elsewhere, where Q &gt; 0 is the dose. Find the
expression of the profile at t &gt; 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 24
</p>
<p>Thermal Oxidation&mdash;Layer Deposition
</p>
<p>24.1 Introduction
</p>
<p>High-quality oxide is essential in silicon technology. The most important applica-
tions of the oxide are the passivation of the wafer&rsquo;s surface, the isolation between
metallizations, the formation of masks for, e.g., diffusion or implantation of dopants,
the isolation between devices, and the formation of the gate insulator in MOS devices.
</p>
<p>While the oxides used for passivation or isolation between metallization are typ-
ically obtained by chemical vapor deposition (Sect. 24.5), the oxide suitable for the
other applications listed above is obtained by thermal oxidation. In fact, the extraor-
dinary evolution of the VLSI technology in the last decades is due to a large extent
to the excellent electrical properties of the thermally-grown layers of silicon dioxide
and to the reliability and control of the growth process.
</p>
<p>In crystalline silicon dioxide (quartz), one silicon atom forms chemical bonds
with four oxygen atoms, creating a tetrahedral structure. In turn, one oxygen atom
forms chemical bonds with two silicon atoms. The tetrahedra are thus connected
to form a structure with a stoichiometric ratio 1 : 2 and density Ï = 2.65 g cm&minus;3
(Fig. 24.1). In thermally-grown SiO2 not all tetrahedra are connected, because at the
silicon&ndash;oxide interface chemical bonds must be created with the pre-existing silicon
crystal, whose interatomic distance is different from that of SiO2. As a consequence,
the oxide has a shorter-range order giving rise to a more open (amorphous) structure
with density Ï = 2.20 g cm&minus;3. Because of this the diffusion of contaminants, in
most cases Na and H2O, is easier than in crystalline silicon dioxide.
</p>
<p>Also, the need of adapting to the silicon crystal produces a mechanical stress in the
oxide layer closer to the silicon surface, which in turn influences the concentration
of substrate defects and the value of some electrical properties in MOS devices
(typically, the threshold voltage, Sect. 22.6.2). The properties of the mechanically-
stressed layer are influenced by the process temperature T . At relatively low process
temperatures, T &lt; 950 â¦C, the stressed layer is thinner and the mechanical stress
in it is stronger; when T &gt; 950â¦C, the stress distributes over a thicker layer and
becomes locally weaker.
</p>
<p>The growth of a thermal oxide&rsquo;s layer is obtained by inducing a chemical reaction
between the silicon atoms belonging to the wafer and an oxidant species that is
</p>
<p>&copy; Springer Science+Business Media New York 2015 557
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_24</p>
<p/>
</div>
<div class="page"><p/>
<p>558 24 Thermal Oxidation&mdash;Layer Deposition
</p>
<p>Fig. 24.1 Structure of
quartz. Silicon atoms are
represented in gray, oxygen
atoms in white. Within the
tetrahedron, the distance
between two oxygen atoms is
about 0.227 nm, that between
the silicon atom and an
oxygen atom is about
0.160 nm. The schematic
representation in two
dimensions is shown in the
lower-right part of the figure
</p>
<p>brought into contact with it. As mentioned above, another technique for obtaining
an oxide layer is deposition. The latter process has actually a broader scope, in fact
it is used for depositing several types of conducting or insulating materials that are
necessary in the fabrication of the integrated circuits. Deposition differs from the
thermal growth because the chemical reaction may be absent or, if present, it does
not involve the species that are in the solid phase. One special type of deposition is
epitaxy, that is used to grow a crystalline layer over another crystalline layer.
</p>
<p>The chapter illustrates the oxidation of silicon, starting from the description of
the chemical reactions involved in it, and deriving the relation between the thickness
of the oxide layer and that of the silicon layer consumed in its growth. The kinetics
of the oxide growth is analyzed, the linear&ndash;parabolic model is worked out, and its
features are commented. Then, a brief description of the deposition processes is
given, followed by the description of the chemical reaction involved in the epitaxial
process and by the analysis of the epitaxial kinetics.
</p>
<p>In the last part of the chapter a number of complementary issues are discussed.
Specific data about the parameters governing the thermal oxidation, deposition,
and epitaxial processes in semiconductors are in [46, Chap. 2], [104, Chap. 9],
[105, Chap. 3], [71, Chap. 3]. Many carefully-drawn illustrations are found in [75,
Sect. 1.2].
</p>
<p>24.2 Silicon Oxidation
</p>
<p>Silicon exposed to air at room temperature oxidizes spontaneously and forms a
shallow layer of SiO2 of about 1 nm called native oxide. As soon as the native oxide
is formed, the oxygen molecules of the air can not reach the silicon surface any
more and the chemical reaction dies out. In fact, oxidation of silicon is caused by
the inward motion of the oxidant. To activate the reaction and grow a layer of the
desired thickness it is necessary to place the wafers at atmospheric pressure in a
furnace (Fig. 24.2) kept at a temperature in the range 800â¦C &le; T &le; 1200 â¦C. This</p>
<p/>
</div>
<div class="page"><p/>
<p>24.2 Silicon Oxidation 559
</p>
<p>Tube
</p>
<p>Boat
</p>
<p>Silicon wafers
</p>
<p>Resistance heater
</p>
<p>Filtered air
</p>
<p>End cap
</p>
<p>Carrier gas Exhaust
</p>
<p>Fig. 24.2 Furnace for silicon oxidation. The intake of the carrier gas (O2 or H2O) is on the left end
of the furnace, the exhaust on the right end. The tube, end cap, and boat, are made of fused quartz
to avoid contamination
</p>
<p>increases the diffusion coefficient of the oxidant. The latter penetrates the already-
formed oxide layer and reaches the silicon surface, where new SiO2 molecules are
formed. The furnace is made of a quartz or polycrystalline-silicon tube heated by a
resistance or by induction through a radiofrequency coil. To grow the oxide layer in a
reproducible way it is necessary to control the temperature inside the furnace within
&plusmn;1 â¦C. The oxidant is introduced from one end of the furnace after being mixed with
a carrier gas (typically, N2 or Ar).
</p>
<p>The chemical reactions involved in the growth of thermal oxide are different
depending on the type of oxidant. The latter is either molecular oxygen (O2) or steam
(H2O). The corresponding thermal growth is called, respectively, dry oxidation or
wet (steam) oxidation. The reactions read
</p>
<p>Si + O2 â SiO2, Si + 2H2O â SiO2 + 2H2, (24.1)
</p>
<p>where the hydrogen molecules produced by the second reaction are eliminated by the
carrier gas. The formation of SiO2 molecules is accompanied by a change in volume.
In fact, each newly-formed SiO2 molecule uses up a silicon atom initially belonging
to the silicon crystal. On the other hand, the concentration of the silicon atoms in a
silicon crystal is about N1 = 5.0 &times; 1022 cm&minus;3, while that of the silicon atoms in a
thermally-grown SiO2 layer is about N2 = 2.2&times; 1022 cm&minus;3. Thus the ratio between
the volume V of SiO2 and that of the silicon consumed for its formation is
</p>
<p>V (SiO2)
</p>
<p>V (Si)
= N1
</p>
<p>N2
â 2.28. (24.2)
</p>
<p>As the oxide layer is free to expand only in the direction normal to the wafer,
(24.2) is actually the ratio between the thickness s of the newly-formed SiO2 layer</p>
<p/>
</div>
<div class="page"><p/>
<p>560 24 Thermal Oxidation&mdash;Layer Deposition
</p>
<p>0.44 s
</p>
<p>s
</p>
<p>Oxide surface
</p>
<p>Silicon&minus;oxide interface
</p>
<p>Original silicon surface
</p>
<p>Fig. 24.3 The left part of the figure shows the position of the original silicon surface (prior to
oxidation). The right part shows the position of the oxide&rsquo;s surface and of the silicon&ndash;oxide interface
after an oxide layer of thickness s has been grown
</p>
<p>and that of the silicon layer consumed in the process. It follows
</p>
<p>s(Si)
</p>
<p>s(SiO2)
= V (Si)/A
</p>
<p>V (SiO2)/A
= N2
</p>
<p>N1
â 0.44, (24.3)
</p>
<p>with A the area of the oxidized region. In other terms, when an oxide layer of
thickness s is grown, the silicon&ndash;oxide interface shifts by 0.44 s with respect to the
original position (Fig. 24.3). If the oxidation takes place uniformly over the whole
area of the wafer, the shift of the interface is uniform as well. However, in many cases
the oxidation involves only portions of the wafer&rsquo;s area. This makes the silicon&ndash;oxide
interface non planar, because the shift is different from one portion to another.
</p>
<p>24.3 Oxide-Growth Kinetics
</p>
<p>Growth kinetics is modeled after Deal and Grove [28]. The model describes the
succession of steps by which the oxidant, initially in the gaseous phase, comes into
contact with silicon and reacts with it. The steps are: the oxidant (i) diffuses from the
source region into the already-formed oxide, (ii) crosses the oxide still by diffusion
and reaches the silicon&ndash;oxide interface, (iii) produces a chemical reaction that forms
a new SiO2 molecule.
</p>
<p>The motion of the gas parallel to the wafer surface is not considered. As a conse-
quence, the only non-vanishing component of the oxidant average velocity has the
direction x normal to the wafer surface. The corresponding flux density is F = F &middot; i,
with i the unit vector parallel to x. The oxidant concentration N is assumed uniform
over the wafer&rsquo;s surface, this making N and F to depend on x and t only.
</p>
<p>The concentration of the oxidant in the bulk of the gaseous phase, NG, is a known
boundary condition because it is regulated by the microprocessors controlling the
furnace. In the gaseous region, at the gas&ndash;oxide interface, and in the oxide region,
no generation or destruction of oxidant molecules occurs. The flux density is given</p>
<p/>
</div>
<div class="page"><p/>
<p>24.3 Oxide-Growth Kinetics 561
</p>
<p>by
</p>
<p>F = &minus;DS
&part;N
</p>
<p>&part;x
, F = &minus;DO
</p>
<p>&part;N
</p>
<p>&part;x
, (24.4)
</p>
<p>respectively in the source and oxide region. In (24.4), the symbol DS (DO) indicates
the diffusion coefficient of the oxidant in the source (oxide) region. Each diffusion
coefficient is taken independent of time and spatially constant in its own region. The
matching conditions at the source&ndash;oxide interface are the same as in (23.20), namely,
</p>
<p>NO = kNS , DO
(
&part;N
</p>
<p>&part;x
</p>
<p>)
</p>
<p>O
</p>
<p>= DS
(
&part;N
</p>
<p>&part;x
</p>
<p>)
</p>
<p>S
</p>
<p>, (24.5)
</p>
<p>where k is the gas&ndash;oxide segregation coefficient, while the index S (O) attached
to the concentration or its derivative indicates that the function is calculated at the
source&ndash;oxide interface on the side of the source (oxide). As one of the two phases is
gaseous, it is DS â« DO whence |(&part;N/&part;x)S | âª |(&part;N/&part;x)O |. The situation here is
similar to that illustrated in Fig. 23.3. It follows that the interface concentration of
the source region, NS , is practically equal to the boundary condition NG. The first
of (24.5) then yields NO = kNG.
</p>
<p>To proceed one observes that, due to the thinness of the oxide layer, the oxidant
concentration in it can be described by a linear approximation. Due to this, the flux
density in the oxide layer (the second equation in (24.4)) becomes
</p>
<p>F = &minus;DO
NI &minus;NO
</p>
<p>s
= DO
</p>
<p>kNG &minus;NI
s
</p>
<p>, (24.6)
</p>
<p>whereNI is the oxidant concentration on the oxide side of the silicon&ndash;oxide interface,
and s the oxide thickness. Note that the flux density in (24.6) is constant with respect
to x, whereas it is time dependent because s increases with time.
</p>
<p>When the oxidant reaches the silicon&ndash;oxide interface it reacts with silicon, so that
there is no flux density of the oxidant on the semiconductor&rsquo;s side of this interface.
In fact, the oxidant&rsquo;s molecules are destroyed at the interface to form molecules of
SiO2. The flux density FI entering the silicon&ndash;oxide interface gives the number of
oxidant molecules destroyed per unit area and time which, to a first approximation,
is taken proportional to the concentration NI . It follows
</p>
<p>FI = vr NI , (24.7)
</p>
<p>where the constant vr (m s&minus;1) is called reaction velocity. AsFI is just another symbol
to denote the spatially-constant flux density within the oxide, one combines (24.7)
with (24.6) to obtain
</p>
<p>NI =
DO kNG
</p>
<p>vrs +DO
. (24.8)
</p>
<p>At a given instant Eq. (24.8) expresses NI in terms of the boundary condition NG,
the process parameters k, DO , vr , and the oxide thickness s.</p>
<p/>
</div>
<div class="page"><p/>
<p>562 24 Thermal Oxidation&mdash;Layer Deposition
</p>
<p>24.4 Linear&ndash;Parabolic Model of the Oxide Growth
</p>
<p>The relation between the oxidant&rsquo;s flux density F and the growth velocity ds/dt of
the oxide layer is found as follows. Letting A be the area of the oxidized region, the
product AF provides the number of oxidant molecules reaching the silicon&ndash;oxide
interface per unit time. Each molecule, in turn, makes the volume V of the oxide
layer to increase by a finite amount w. As a consequence, the volume increase per unit
time of the oxide layer is dV/dt = wAF . As shown in Sect. 24.2, the oxide layer is
free to expand only in the direction normal to the wafer, so that dV/dt = A ds/dt .
Combining the above relations and using (24.7, 24.8) yields a differential equation
in the unknown s:
</p>
<p>ds
</p>
<p>dt
= wFI = wvrNI = vrDO
</p>
<p>w kNG
</p>
<p>vr s +DO
. (24.9)
</p>
<p>The above is readily separated as (s/DO + 1/vr ) ds = wkNG dt and integrated from
t = 0, to yield
</p>
<p>1
</p>
<p>cp
</p>
<p>(
</p>
<p>s2 &minus; s2i
)
</p>
<p>+ 1
cl
</p>
<p>(s &minus; si) = t ,
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>cp = 2w kNGDO
cl = w kNG vr
</p>
<p>, (24.10)
</p>
<p>with si = s(t = 0). The relation between s and t given by (24.10) is called linear&ndash;
parabolic model of the oxide growth. The quantities cp (m2 s&minus;1) and cl (m s&minus;1) are
the parabolic coefficient and linear coefficient, respectively. The model is recast as
</p>
<p>1
</p>
<p>cp
s2 + 1
</p>
<p>cl
s = t + Ï , Ï = 1
</p>
<p>cp
s2i +
</p>
<p>1
</p>
<p>cl
si . (24.11)
</p>
<p>Using (24.11) and the definitions (24.10) of cp and cl one finds two limiting cases
of the s(t) relation. Specifically, it is s â cl (t + Ï ) when the oxide thickness is
such that vrs âª 2D, while it is s â [cp (t + Ï )]1/2 when the oxide thickness
is such that vrs â« 2D. Due to the form of cp and cl , in the first limiting case the
oxide growth does not depend on the diffusion coefficient DO , whereas in the second
limiting case it does not depend on the reaction velocity vr . This is easily understood
if one considers that the concentration NO = kNG is prescribed. As a consequence,
as long as the oxide thickness is small the derivative of the concentration (hence
the flux density) is limited essentially by the flux density entering the silicon&ndash;oxide
interface, (24.7); on the contrary, when the oxide thickness becomes large the flux
density is limited essentially by the diffusion across the oxide because the value of
the concentration NI at the silicon&ndash;oxide interface becomes less important.
</p>
<p>The differential form of (24.11),
</p>
<p>dt
</p>
<p>ds
= 2
</p>
<p>cp
s + 1
</p>
<p>cl
, (24.12)
</p>
<p>is a linear relation between dt/ds and s. Such quantities can be measured indepen-
dently from each other, this providing a method for measuring cp and cl . Repeating</p>
<p/>
</div>
<div class="page"><p/>
<p>24.5 Layer Deposition and Selective Oxide Growth 563
</p>
<p>the measurement at different temperatures shows that the temperature dependence
of the parabolic and linear coefficients is given by
</p>
<p>cp = cp0 exp [&minus; Eap/(kBT )], cl = cl0 exp [&minus; Eal/(kBT )]. (24.13)
</p>
<p>The form of (24.13) is due to the temperature dependence of D &prop; exp [&minus;
Eap/(kBT )] and, respectively, vr &prop; exp [&minus; Eal/(kBT )]. In fact, the parameters
w, NG that appear in the definitions (24.10) are independent of temperature, whereas
the temperature dependence of the segregation coefficient k, that can be measured
independently, is shown to be relatively weak.
</p>
<p>The measurement of cp and cl allows one to determine also other properties of the
oxidation process; for instance, the effect of carrying out a steam or dry oxidation,
and the influence of the substrate orientation. As for the first issue one finds
</p>
<p>k(Steam) &gt; k(Dry), DO(Steam) &gt; DO(Dry). (24.14)
</p>
<p>The Arrhenius plots of cp and cl are shown in Figs. 24.4 and 24.5, respectively.
In each plot the upper (lower) continuous curve refers to the steam (dry) oxidation.
As for the effect of the crystal orientation of the silicon wafer, one observes that
the number of chemical reactions per unit time involved in the formation of SiO2
molecules must depend on the surface density of silicon atoms at the silicon&ndash;oxide
interface. Due to this, the reaction velocity is expected to depend on the orientation
of the interface. The crystal planes that are typically used in the silicon technology
are the (111) one, whose surface density is 11.8 &times; 1014 cm&minus;2, and those equivalent
to the (100) one,1 whose surface density is 6.8&times; 1014 cm&minus;2. In fact the experiments
show that
</p>
<p>vr [(111)]
</p>
<p>vr [(100)]
= 1.68 â 11.8 &times; 10
</p>
<p>14 cm&minus;2
</p>
<p>6.8 &times; 1014 cm&minus;2 . (24.15)
</p>
<p>The effect on cl of the crystal orientation is shown by the dotted curves in the
Fig. 24.5.
</p>
<p>24.5 Layer Deposition and Selective Oxide Growth
</p>
<p>The deposition of films of different materials is necessary at several steps of the
integrated-circuit fabrication. Conducting materials provide the electrical connec-
tions among the individual devices of the integrated circuit, while insulating materials
provide the electrical insulation between the metal layers, and the protection from
the environment. The majority of the deposition processes take place in the vapor
phase under reduced-pressure or vacuum conditions. One exception is the deposition
of resist, which is carried out in the liquid phase.
</p>
<p>1 The definitions of the crystal planes are given in Sect. 17.8.1.</p>
<p/>
</div>
<div class="page"><p/>
<p>564 24 Thermal Oxidation&mdash;Layer Deposition
</p>
<p>Fig. 24.4 Parabolic
coefficient cp as a function of
1,000/T . The units are
Î¼m2 h&minus;1. The activation
energy of the steam case is
0.71 eV, that of the dry case is
1.24 eV
</p>
<p>(C)T
</p>
<p>1000 /       ( K     )&minus;1T
</p>
<p>1200 800 550
</p>
<p>7.0 8.0 9.0 0.1 1.1 2.1
10
</p>
<p>&minus;4
</p>
<p>10
&minus;3
</p>
<p>10
&minus;2
</p>
<p>10
&minus;1
</p>
<p>0
10
</p>
<p>Steam
</p>
<p>Dry
</p>
<p>Fig. 24.5 Linear coefficient
cl as a function of 1,000/T .
The units are Î¼m h&minus;1. The
activation energy of the steam
case is 2.05 eV, that of the dry
case is 2.0 eV
</p>
<p>1000 /       ( K     )&minus;1T
</p>
<p>(C)T
</p>
<p>1200 900 700
</p>
<p>(111)  Si
</p>
<p>(111)  Si(100)  Si
</p>
<p>(100)  Si
</p>
<p>Dry
</p>
<p>Steam
</p>
<p>10
&minus;4
</p>
<p>0.7 0.8 0.9 1.0 1.10.6
</p>
<p>10
&minus;3
</p>
<p>10
&minus;2
</p>
<p>10
&minus;1
</p>
<p>0
10
</p>
<p>1
10
</p>
<p>When the material to be deposited does not react chemically with other substances,
the process is called physical vapor deposition (PVD). An example of PVD is the
deposition of a metal by evaporation in vacuo. When the material to be deposited is
the product of a chemical reaction that takes place over the wafer surface or in its
vicinity, the process is called chemical vapor deposition (CVD).</p>
<p/>
</div>
<div class="page"><p/>
<p>24.5 Layer Deposition and Selective Oxide Growth 565
</p>
<p>Table 24.1 Examples of CVD reactions
</p>
<p>Product Reactiona Deposition temperature (â¦C)
</p>
<p>Polysilicon SiH4 &rarr; Si + 2H2 575&ndash;650
Silicon dioxide SiH4 + O2 &rarr; SiO2 + 2H2 400&ndash;450
Silicon nitride 3SiH4 + 4NH3 &rarr; Si3N4 + 12H2 700&ndash;900
</p>
<p>aSiH4 and NH3 are called silane and ammonia, respectively
</p>
<p>The materials that are most widely used in CVD processes are polycrystalline
silicon (also termed polysilicon), silicon dioxide (SiO2), and silicon nitride (Si3N4).
Examples of CVD reactions are given in Table 24.1. More examples are found in
[105, Sect. 6.2].
</p>
<p>The structure of the deposited layer depends on the substrate&rsquo;s properties and
deposition conditions. In the manufacturing of integrated circuits the substrate is
crystalline, that is, it has long-range order extending throughout the entire volume
(Chap. 17). If the material to be deposited on a crystalline substrate is the same as that
of the substrate, by means of a carefully-controlled process it is possible to obtain
a deposited layer that replicates the substrate&rsquo;s structure. Such a process is called
epitaxy and, with reference to silicon, is described in Sect. 24.6.
</p>
<p>The structure of silicon deposited on a different material is polycrystalline, that
is, it has a long-range order only within small volumes. Such volumes, called grains,
have an average diameter of about 1 &micro;m and are oriented randomly with respect
to each other. Polycrystalline silicon is used for fabricating the gate electrodes in
MOS devices, for obtaining ohmic contacts to shallow junctions, and for producing
resistors. To increase the gate&rsquo;s conductivity, a layer of metal or metal silicide (like
tungsten or tantalum silicide) may be deposited over the polycrystalline silicon.
</p>
<p>The structure of deposited SiO2 or Si3N4 is amorphous, that is, it has a short-range
order only. The applications of SiO2 have been illustrated in Sect. 24.1. Silicon nitride
Si3N4 provides a strong barrier to the diffusion of water, that corrodes the metalliza-
tions, and of other contaminants, like sodium, that make the devices unstable by
changing their threshold voltage. In addition, Si3N4 is resistant to high temperatures
and oxidizes slowly. For these reasons it is used for passivating the wafer and for pro-
ducing the masks that are necessary for the selective oxidation of silicon. The latter
process, also called local oxidation (LOCOS), consists in depositing and patterning
a Si3N4 layer over the areas where the substrate&rsquo;s oxidation must be prevented. As
oxidation is isotropic, a lateral penetration of the oxidized region occurs under the
edge of Si3N4. This produces a characteristic profile of the oxide layer called bird&rsquo;s
beak. To compensate for the effect of the lateral penetration, the Si3N4 mask must
be larger than the area whose oxidation is to be prevented.
</p>
<p>A layer replicates the topography of the surface onto which it is deposited. For
this reason it is important to avoid, or reduce, the formation of steps on the substrate.
In fact, over a step the layer&rsquo;s thickness is smaller than on a flat surface which, in
turn, may cause reliability problems in the final circuit. For instance, the non-uniform
thickness of a metal line causes a non-uniform distribution of the current density. This
may induce metal migration and the eventual breakdown of the metal connection.</p>
<p/>
</div>
<div class="page"><p/>
<p>566 24 Thermal Oxidation&mdash;Layer Deposition
</p>
<p>24.6 Epitaxy
</p>
<p>Epitaxy (from the Greek verb epit&agrave;sso, &ldquo;to deploy side by side&rdquo;) is used to grow a
monocrystalline layer over another monocrystalline layer. Most epitaxial processes
use the CVD method. When the epitaxial layer is made of the same material as the
substrate, e.g., silicon over silicon, the term homoepitaxy is also used, while the term
heteroepitaxy is reserved to the case where the materials are different. Heteroepitaxy
is possible when the difference between the lattice constants2 of the two materials
is small. An example of heteroepitaxy is the silicon-on-sapphire (SOS) process,
that belongs to the silicon-on-insulator (SOI) technological family and consists in
growing a thin layer of silicon (about 0.5 &micro;m) on a wafer made of a sapphire crystal
(Al2O3).Another application of heteroepitaxy is the fabrication of the heterojunctions
that are necessary in optoelectronic devices.
</p>
<p>In the silicon technology, epitaxy originated from the need of producing high-
resistance layers in bipolar technology. This type of layers is necessary, e.g., for
realizing the collector region of the bipolar junction transistor, whose dopant con-
centration must be substantially lower than that of the base region. Due to the high
temperature of the CVD process (about 1200 â¦C), during an epitaxy a diffusion oc-
curs of the substrate dopant into the epitaxial layer and of the epitaxial-layer&rsquo;s dopant
into the substrate. This effect must be accounted for, and compensated, at the design
stage of the process.
</p>
<p>The fundamental reaction of epitaxy combines silicon tetrachloride SiCl4 with
molecular hydrogen in the vapor phase to obtain silicon in solid phase, while the
hydrochloric acid HCl remains in the vapor phase and is eliminated:
</p>
<p>SiCl4 + 2H2 â Si + 4HCl. (24.16)
</p>
<p>Reaction (24.16) is reversible: an excess of HCl removes silicon atoms from the
wafer&rsquo;s surface and releases SiCl4 and 2H2 in the vapor phases. This reaction is
used in the first stages of the process to the purpose of cleaning the wafer&rsquo;s surface.
Besides (24.16), a secondary reaction takes place as well, namely,
</p>
<p>SiCl4 + Si &rarr; 2SiCl2. (24.17)
</p>
<p>Reaction (24.17) removes silicon from the wafer&rsquo;s surface and releases silicon dichlo-
ride SiCl2 in the vapor phase. For this reason, reactions (24.16) and (24.17) compete
with each other. When the vapor concentration of SiCl4 is sufficiently low the first
reaction prevails and the thickness of the epitaxial layer increases with time. In
contrast, at higher SiCl4 concentrations the second reaction prevails and silicon is
etched.
</p>
<p>The epitaxial layer is doped by introducing hydrides of the dopants into the vapor
phase. The hydride, e.g., arsine (AsH3), phosphine (PH3), or diborane (B2H6), is
</p>
<p>2 The definition of lattice constant is given in Sect. 17.6.4.</p>
<p/>
</div>
<div class="page"><p/>
<p>24.7 Kinetics of Epitaxy 567
</p>
<p>absorbed on the surface, decomposes, and is incorporated in the growing layer, e.g.,
</p>
<p>2AsH3 &rarr; 2As + 3H2. (24.18)
</p>
<p>24.7 Kinetics of Epitaxy
</p>
<p>As in the case of the oxide-growth kinetics (Sect. 24.3), the motion of the vapor
parallel to the wafer surface is not considered. As a consequence, the only non-
vanishing component of the average velocity of the SiCl4 molecules has the direction
x normal to the wafer surface. The corresponding flux density is F = F &middot; i, with i
the unit vector parallel to x. The SiCl4 concentration N is assumed uniform over the
wafer&rsquo;s surface, this making N and F to depend on x and t only.
</p>
<p>The SiCl4 concentration in the bulk of the vapor phase, NG, is a known boundary
condition because it is regulated by the microprocessors controlling the furnace. The
flux density is given by
</p>
<p>F = &minus;D &part;N
&part;x
</p>
<p>â vG (NG &minus;NI ), (24.19)
</p>
<p>where D is the diffusion coefficient of SiCl4 in the vapor phase and NI the SiCl4
concentration at the wafer&rsquo;s surface. The diffusion coefficient is taken independent
of time and spatially constant. The form of the right hand side of (24.4), where the
parameter vG (m s&minus;1) is called gas-phase mass-transfer coefficient, is due to the
observation that D is very large because the diffusion takes place in the vapor phase.
As a consequence, the derivative &part;N/&part;x is so small that a linear approximation for
N is acceptable (the situation here is similar to that illustrated for the region on the
left of the origin in Fig. 23.3). Note that the flux density in the vapor phase (24.19)
is constant with respect to x. In principle it depends on time because the extension
of the vapor phase decreases due to the growth of the epitaxial layer. However, this
time dependence can be disregarded because the relative variation in the vapor-phase
extension is negligible.
</p>
<p>The flux density FI entering the silicon surface gives the number of SiCl4
molecules destroyed per unit area and time which, to a first approximation, is taken
proportional to the concentration NI . It follows
</p>
<p>FI = vr NI , (24.20)
</p>
<p>where the constant vr (m s&minus;1), as in the case of the oxide-growth kinetics, is called
reaction velocity. As FI is just another symbol to denote the spatially-constant flux
density, one combines (24.20) with (24.19) to obtain
</p>
<p>NI =
vG
</p>
<p>vr + vG
NG. (24.21)
</p>
<p>At a given instant Eq. (24.21) expresses NI in terms of the boundary condition NG
and process parameters vG, vr .</p>
<p/>
</div>
<div class="page"><p/>
<p>568 24 Thermal Oxidation&mdash;Layer Deposition
</p>
<p>Fig. 24.6 Normalized growth
velocity as a function of the
normalized inverse
temperature, as given by
(24.23) and (24.24), at
different values of the
rv = vG/vr0 ratio
</p>
<p>0 5 10 15 20
</p>
<p>Normalized inverse temperature
</p>
<p>10
-4
</p>
<p>10
-2
</p>
<p>10
0
</p>
<p>10
2
</p>
<p>N
o
rm
</p>
<p>al
iz
</p>
<p>ed
 g
</p>
<p>ro
w
</p>
<p>th
 v
</p>
<p>el
o
ci
</p>
<p>ty r
v
 = 10
</p>
<p>-1
</p>
<p>r
v
 = 10
</p>
<p>-3
</p>
<p>r
v
 = 10
</p>
<p>-5
</p>
<p>The relation between the flux density F of SiCl4 and the growth velocity ds/dt
of the epitaxial layer is found by the same reasoning as that used in Sect. 24.4 for
the growth velocity of SiO2. From (24.20, 24.21) it follows
</p>
<p>ds
</p>
<p>dt
= wFI = wvrNI = w
</p>
<p>vrvG
</p>
<p>vr + vG
NG (24.22)
</p>
<p>whence, observing that s(t = 0) = 0,
</p>
<p>s = cl t , cl = w
vrvG
</p>
<p>vr + vG
NG. (24.23)
</p>
<p>The s(t) relation (24.23) is linear with respect to time. The growth velocity cl of the
epitaxial layer depends on the concentration NG of SiCl4 at the boundary and on
the process parameters w, vr , and vG. The temperature dependence of the gas-phase
mass-transfer coefficient vG is weak. As w and NG are independent of temperature,
the temperature dependence of cl is to be ascribed to vr . It is found
</p>
<p>vr = vr0 exp [&minus; Eal/(kBT )]. (24.24)
When the temperature is such that vr âª vG, which typically happens for T &lt;
1,150 â¦C, the second of (24.23) yields the limiting case cl â wNG vr , whence
cl &prop; exp [&minus; Eal/(kBT )]; when, instead, it is vr â« vG, which typically happens
for T &gt; 1,200â¦C, the limiting case is cl â wNG vG = const. An Arrhenius plot of
the normalized growth velocity cl/(wNG vG) as a function of the normalized inverse
temperature Eal/(kBT ) is shown in Fig. 24.6 for different values of the rv = vG/vr0
ratio.
</p>
<p>24.8 Complements
</p>
<p>24.8.1 An Apparent Contradiction
</p>
<p>In commenting (24.6) it was noted that the flux density F in the oxidation process is
constant with respect to x, whereas it depends on time due to the time dependence of</p>
<p/>
</div>
<div class="page"><p/>
<p>24.8 Complements 569
</p>
<p>Fig. 24.7 Oxidant
concentration within the
oxide at two different
instants, t1 and t2 &gt; t1
</p>
<p>N
I
</p>
<p>k N
G
</p>
<p>k N
G
</p>
<p>N
I
</p>
<p>t
2
</p>
<p>t
1
</p>
<p>x
</p>
<p>x
</p>
<p>the oxide thickness s. This seems to bring about a contradiction. In fact, as the one-
dimensional form of the continuity Eq. (23.3) with W = 0 yields &part;N/&part;t+&part;F/&part;x =
0, the constancy of F makes N independent of time. However, N does depend on
time. This is demonstrated by Fig. 24.7, that shows the linear approximation of the
oxidant concentration within the oxide at two different instants, t1 and t2 &gt; t1. The
value k NG at the source&ndash;oxide interface is kept constant by the boundary condition
as explained in Sect. 24.3, while the value NI at the silicon&ndash;oxide interface changes
with time due to (24.8), and the oxide&rsquo;s thickness changes as well.
</p>
<p>The contradiction is eliminated by observing that the continuity Eq. (23.3) has
been derived for the case where the boundary is fixed, whereas the growth of thermal
oxide is a moving-boundary process. The motion of the boundary is not a rigid one
(otherwise the problem could be fixed by moving the reference accordingly), because
the oxide volume is actually expanding. In conclusion, Eq. (23.3) must not be used.
In fact, the derivation of the linear&ndash;parabolic model of the oxide growth (24.10) is
based solely on the definition of the flux density.
</p>
<p>24.8.2 Elementary Contributions to the Layer&rsquo;s Volume
</p>
<p>The relation ds/dt = wFI was used to connect, in Sect. 24.4, the growth velocity
of the oxide layer to the flux density of the oxidant and, in Sect. 24.7, the growth
velocity of the epitaxial layer to the flux density of SiCl4. The coefficient w is the
amount by which one oxidant or SiCl4 molecule makes the volume of the layer to
increase. To specify w for the oxidation process one must distinguish between the
dry and steam cases. In the first one, each molecule of the oxidant produces one SiO2
molecule. As a consequence, w is the volume of the SiO2 molecule. In the steam
case, two H2O molecules are necessary for producing one SiO2 molecule, hence w
is half the volume of the latter. By the same token, in the epitaxial process w is the
volume of a Si atom.</p>
<p/>
</div>
<div class="page"><p/>
<p>570 24 Thermal Oxidation&mdash;Layer Deposition
</p>
<p>24.8.3 Features of the Oxide Growth and Epitaxial Growth
</p>
<p>The quadratic term in the left hand side of (24.10) becomes dominant at larger oxide
thicknesses. This in turn slows down the growth rate, as shown by (24.9). A qualitative
explanation of the phenomenon is easily obtained by considering that, in order to
reach the silicon&ndash;oxide interface, the oxidant must diffuse across the already-formed
oxide. The slope of the oxidant concentration, hence its flux density, decreases with
time because the thickness of the oxide region increases, while the value k NG at the
source&ndash;oxide interface is kept constant by the boundary condition. The decrease in
the oxidant concentration NI at the silicon&ndash;oxide interface, shown by (24.8), is not
sufficient to contrast the decrease in the concentration&rsquo;s slope. The reasoning above
does not apply to the epitaxial growth; in fact, in this case the chemical reaction
occurs at the vapor&ndash;silicon interface and there is no intermediate layer to be crossed.
As a consequence, the corresponding model (24.23) has no quadratic term.
</p>
<p>In the analysis of the oxide-growth kinetics carried out in Sect. 24.3 it
is assumed that the interface concentration in the source region, NS , is
practically equal to the boundary condition NG. The simplification is used in the
expression (24.6) of the flux density in the oxide layer. The calculation then pro-
ceeds by considering only the oxidant diffusion across the already-formed layer and
the chemical reaction at the silicon&ndash;oxide interface. In this respect, the assumption
NS = NG has the mere effect of introducing a negligible change in (24.6). A similar
approximation would not be possible in the analysis of the epitaxial growth. In fact,
letting NI = NG in (24.19) would set the flux density to zero. The difference be-
tween the two cases is that in the epitaxial growth the flux density exists only in the
vapor phase, while in the oxide growth it exists both in the gaseous and solid phases.
However, as DS â« DO , only the diffusion in the solid phase plays a significant role
in determining the kinetics of the oxidation process.
</p>
<p>24.8.4 Reaction Velocity
</p>
<p>The reaction velocity vr is among the parameters used in the analysis of the oxide-
growth kinetics and epitaxial kinetics. This parameter controls the flux density
through (24.7) or (24.20), and is found to depend also on the concentration Ndop
of dopant atoms in the silicon lattice. The dependence is negligible as long as
Ndop &le; ni(T ), where ni (called intrinsic concentration, Sect. 18.3) is calculated
at the process temperature. When Ndop &gt; ni(T ), the reaction velocity increases with
Ndop. It should be noted that ni â 1018 cm&minus;3 at T = 1000 â¦C. As a consequence,
the dependence of vr on Ndop becomes important only at relatively high dopant
concentrations.</p>
<p/>
</div>
<div class="page"><p/>
<p>24.8 Complements 571
</p>
<p>Fig. 24.8 Typical growth
velocity cl of an epitaxial
process, expressed in microns
per minute, as a function of
the mole fraction of
tetrachloride. The shaded
area shows the typical
operating range c
</p>
<p>l
</p>
<p>[SiCl   ]
</p>
<p>5
</p>
<p>4
</p>
<p>3
</p>
<p>2
</p>
<p>1
</p>
<p>0
</p>
<p>&minus;1
</p>
<p>&minus;2
</p>
<p>6
</p>
<p>0 0.1 0.2 0.3 0.4
</p>
<p>Polycrystal
</p>
<p>Crystal
</p>
<p>Growth
</p>
<p>Etching
</p>
<p>Typical range
</p>
<p>4
</p>
<p>24.8.5 Molecular Beam Epitaxy
</p>
<p>Epitaxy can also be obtained by a process different from CVD, that is called molecular
beam epitaxy (MBE) and is based on evaporation. The main advantages of MBE
are the low-temperature processing and the fine control of the dopant distribution
throughout the epitaxial layer. On the other side, MBE has a low throughput and a
higher cost. As a consequence, CVD is used is in the majority of cases for growing
epitaxial layers in the silicon technology [105, Sect. 6.3].
</p>
<p>24.8.6 Secondary Reaction in the Epitaxial Growth
</p>
<p>The analysis of the epitaxial kinetics carried out in Sect. 24.7 is based on the hypoth-
esis that only the fundamental reaction (24.16) is present. However, as mentioned
in Sect. 24.7, the secondary reaction (24.17) also takes place, which removes sili-
con atoms from the wafer&rsquo;s surface and, therefore, competes with (24.16). At low
concentrations of SiCl4 the effect of the secondary reaction is negligible and the
theory of Sect. 24.7 holds; in particular, as shown by (24.23), the growth velocity cl
is proportional to the concentration NG of SiCl4 in the bulk of the vapor phase. At
larger tetrachloride concentrations the dependence of cl on NG becomes sublinear
as shown in Fig. 24.8. Further increases in NG make cl to continuously decrease,
and to eventually vanish when the secondary reaction balances the fundamental one.
Further on, the secondary reaction prevails and cl becomes negative, that is, silicon
is etched.
</p>
<p>The growth velocity also influences the structure of the epitaxial layer. When
cl is low the deposited silicon atoms match the preexisting crystalline structure, so
that the newly-formed layer is crystalline as well. Higher values of cl make the
matching more and more difficult. Beyond a critical value of cl the epitaxial layer is</p>
<p/>
</div>
<div class="page"><p/>
<p>572 24 Thermal Oxidation&mdash;Layer Deposition
</p>
<p>polycrystalline, as sketched in Fig. 24.8. To avoid the growth of a polycrystal it is
necessary to keep the SiCl4 concentration in the range shown in the figure.
</p>
<p>Problems
</p>
<p>24.1 A silicon wafer covered with an si = 0.21 &micro;m-thick thermal oxide un-
dergoes a second thermal oxidation whose duration is 136 min. Using the
values cp = 4.43 &times; 10&minus;2 &micro;m2 h&minus;1 for the parabolic coefficient and cl =
8.86&times;10&minus;1 &micro;m h&minus;1 for the linear coefficient, calculate the silicon thickness
consumed during the second thermal oxidation.
</p>
<p>24.2 Consider a thermal-oxidation process of silicon where the parabolic and linear
coefficients are, respectively, 4.43&times; 10&minus;2 &micro;m2 h&minus;1 and 8.86&times; 10&minus;1 &micro;m h&minus;1.
At some instant the oxidant concentration NI at the silicon&ndash;oxide interface is
1&times;1012 cm&minus;3. Find the gradient of the oxidant concentration within the oxide
layer at the same instant, expressed in 1017 cm&minus;4 units.
</p>
<p>24.3 A silicon wafer covered with an si = 105 nm-thick layer of thermal oxide
undergoes a second thermal-oxidation process that consumes a 100 nm-thick
layer of silicon. Letting the parabolic and linear coefficients be cp = 4.43 &times;
10&minus;2 &micro;m2 h&minus;1 and cl = 8.86 &times; 10&minus;1 &micro;m h&minus;1, respectively, determine the
duration in minutes of the second oxidation process.
</p>
<p>24.4 Consider a thermal-oxidation process of silicon where the parabolic and linear
coefficients are, respectively, 0.12 &micro;m2 h&minus;1 and 3 &micro;m h&minus;1. At some instant
the oxide thickness is 20 nm, and the oxidant concentration in the oxide at the
source&ndash;oxide interface isNO = 3&times;1012 cm&minus;3. Find the oxidant concentration
at the silicon&ndash;oxide interface, expressed in 1011 cm&minus;3 units.
</p>
<p>24.5 A silicon wafer covered with an si = 5 nm-thick layer of thermal oxide
undergoes a thermal-oxidation process that grows a Îs1 = 7 nm-thick oxide
layer and a successive thermal-oxidation process that grows a Îs2 = 20 nm-
thick oxide layer. In both processes the parabolic and linear coefficients are,
respectively, 4.1&times;10&minus;2 &micro;m2 h&minus;1 and 8.5&times;10&minus;1 &micro;m h&minus;1. Determine the total
duration in seconds of the two processes.
</p>
<p>24.6 A silicon wafer covered with an si = 80 nm-thick layer of thermal oxide
undergoes a thermal-oxidation process whose linear coefficient is 1 &micro;m h&minus;1.
The ratio between the diffusion coefficient of the oxidant within the oxide and
the reaction velocity at the silicon&ndash;oxide interface is r = DO/vr = 50 nm.
Find how many minutes are necessary to reach a final oxide thickness equal
to 150 nm.
</p>
<p>24.7 A silicon wafer covered with an si = 40 nm-thick layer of thermal oxide
undergoes a thermal-oxidation process where the oxidant&rsquo;s diffusion coef-
ficient in the oxide is DO = 4.5 &times; 10&minus;6 cm2 s&minus;1, the reaction velocity is
vr = 4 cm s&minus;1, and the product of the parabolic coefficient and the process
duration is cptP = 5 &times; 10&minus;11 cm2. Calculate the final thickness of the oxide
in nm.</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 573
</p>
<p>24.8 A silicon wafer undergoes an epitaxial growth that produces a 12 &micro;m-thick
silicon layer. At the end of the process the wafer&rsquo;s weight has increased by
907 mg. UsingpSi = 2.33 g cm&minus;3 for the specific weight of silicon, determine
the wafer&rsquo;s diameter in inches (1 in. = 2.54 cm).
</p>
<p>24.9 A 1.2 &micro;m-thick epitaxial layer of silicon is grown by a 1 min-long process
in which the reaction velocity is vr = 10 cm s&minus;1. Find the concentration of
SiCl4 at the silicon surface expressed in 1016 cm&minus;3 units.
</p>
<p>24.10 The flux density of SiCl4 in an epitaxial process in silicon is 8.33 &times;
1016 cm&minus;2s&minus;1. Remembering that the concentration of the silicon atoms in the
crystal lattice is 5 &times; 1022 cm&minus;3, determine how many minutes are necessary
to grow a 2 &micro;m-thick epitaxial layer.
</p>
<p>24.11 Determine the reaction velocity vr (in cm min&minus;1) of an epitaxial process
in silicon that in 5 min grows an s = 2 &micro;m-thick layer. For the surface
concentration of the silicon tetrachloride and the atomic volume of silicon
use, respectively, the values 1016 cm&minus;3 and (5 &times; 1022)&minus;1 cm3.
</p>
<p>24.12 In an epitaxial process the ratio between the SiCl4 concentration in the bulk of
the vapor phase and at the wafer&rsquo;s surface is a = NG/NI = 2, while the ratio
between the reaction velocity and growth velocity is b = vr/cl = 4.87&times;105.
Remembering that the concentration of the silicon atoms in the crystal lattice
is 5 &times; 1022 cm&minus;3, determine the value of NG in cm&minus;3.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 25
</p>
<p>Measuring the Semiconductor Parameters
</p>
<p>25.1 Introduction
</p>
<p>A number of methods used for measuring the semiconductor parameters are illus-
trated here. Apart from the intrinsic usefulness, the methods are interesting because
they show the connection with the theories worked out in other chapters. For example,
the measurement of lifetimes exploits the features of the net thermal recombination
and of optical generation, that are combined in a simplified form of the continuity
equation for the minority carriers. Similarly, the measurement of mobility carried
out with the Haynes-Shockley experiment is based on a clever use of the diffusion of
optically generated carriers. The Hall effect, in turn, provides a powerful method to
extract the information about the concentration and mobility of the majority carriers;
the method exploits the effect of a magnetic field applied in the direction normal
to that of the current density, and is widely used for determining, e.g., the depen-
dence of carrier concentration and mobility on the concentration of dopants and on
temperature. The chapter is completed by the illustration of a method for measuring
the doping profile in an asymmetric, reverse-biased, one-dimensional junction; the
procedure is based on the observation that, despite the fact that the relation between
the applied voltage and the extension of the space-charge region is non linear, the
differential capacitance of the junction has the same form as that of a parallel-plate,
linear capacitor.
</p>
<p>25.2 Lifetime Measurement
</p>
<p>The lifetimes have been introduced in Sect. 20.2.3 with reference to the trap-assisted,
thermal generation and recombination phenomena. A measurement method for the
lifetimes is illustrated here with the aid of Fig. 25.1, that shows a uniformly-doped,
thin layer of semiconductor of length L and cross-section A. The method is able
to measure the minority-carrier lifetime; in the example shown in the figure, which
refers to an n-doped material, the outcome is Ïp. The x axis is taken normal to
the external surface of the semiconductor, with the origin placed on such a surface.
</p>
<p>&copy; Springer Science+Business Media New York 2015 575
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6_25</p>
<p/>
</div>
<div class="page"><p/>
<p>576 25 Measuring the Semiconductor Parameters
</p>
<p>Fig. 25.1 Measurement
scheme for the
minority-carrier lifetime
</p>
<p>y
</p>
<p>x
</p>
<p>z
</p>
<p>AI
</p>
<p>An
</p>
<p>L
</p>
<p>V
</p>
<p>The latter, parallel to the y, z plane, is illuminated with a monochromatic radiation
of frequency Î½, whose intensity is uniform over the surface and constant in time.
Remembering the expression (20.53) of the optical-generation term, and observing
that due to uniformity the absorption coefficient does not depend on position, one
finds
</p>
<p>GO = Î·Î¦B k exp (&minus;kx) , k = k(Î½). (25.1)
</p>
<p>At the same time, a constant voltage V is applied to the semiconductor, producing
an electric field in the z direction. The device is thin in the x and y directions, and
elongated in the z direction, to the extent that the flow lines of the current density are
substantially parallel to the z axis; also, the small extension in the x direction makes
it possible to neglect the x-dependence of GO and let GO â Gc = Î·Î¦Bk. With
these premises,1 the material is spatially uniform also in the non-equilibrium case; it
follows that the condition of local charge neutrality holds. For simplicity one assumes
that the n-dopant concentration ND is sufficiently low to insure that non-degeneracy
and complete ionization hold, N+D = ND; thus, local neutrality reads
</p>
<p>n = p +ND. (25.2)
</p>
<p>The non-equilibrium condition prescribed by the combination of illumination and
bias is adjusted in such a way that a weak-injection condition holds (Sect. 20.2.3.1);
in this case the hole-continuity Eq. (19.124) reads
</p>
<p>&part;p
</p>
<p>&part;t
+ 1
</p>
<p>q
divJp = G&minus; U â Gc &minus;
</p>
<p>p &minus; pn0
Ïp
</p>
<p>. (25.3)
</p>
<p>In the steady-state, uniform condition considered here, (25.3) reduces to
</p>
<p>ï¿½p = p &minus; pn0 = Ïp Gc, (25.4)
</p>
<p>showing that optical generation is exactly balanced by thermal recombination. If, at
time t = 0, the source of light is removed, Gc vanishes and recombination prevails;
it follows that the semiconductor undergoes a transient to adapt to the new situation.
</p>
<p>1 The required thinness of the device can be achieved by growing an n-type epitaxial layer over a
p-type substrate, and keeping the layer-substrate junction reverse biased.</p>
<p/>
</div>
<div class="page"><p/>
<p>25.2 Lifetime Measurement 577
</p>
<p>Fig. 25.2 Measurement
scheme for the
minority-carrier lifetime
</p>
<p>I
0
</p>
<p>Ïp
</p>
<p>+ IpI0
</p>
<p>I
</p>
<p>t
</p>
<p>On the other hand, spatial uniformity still holds: during the transient the spatial
derivatives in (25.3) are still zero, and the equation reads
</p>
<p>dp
</p>
<p>dt
= d(p &minus; pn0)
</p>
<p>dt
= &minus;p &minus; pn0
</p>
<p>Ïp
, t &gt; 0. (25.5)
</p>
<p>From (25.4), the initial condition of (25.5) is ï¿½p(t = 0) = ÏpGc; thus, the solution
of (25.5) is found to be
</p>
<p>Îp = ÏpGc exp ( &minus; t/Ïp). (25.6)
</p>
<p>To determine the conductivity of the device it is necessary to find the electron concen-
tration n or, equivalently, the difference ï¿½n = n&minus; nn0. This is easily accomplished
by observing that spatial uniformity holds also during the transient; as a consequence,
the condition of local charge neutrality (25.2) applies. At the end of the transient, the
latter becomes nn0 = pn0 + ND which, subtracted from (25.2), yields ï¿½n = ï¿½p at
all times. The semiconductor conductivity (19.134) can then be written
</p>
<p>Ï = Ï0 + Ïp exp ( &minus; t/Ïp), (25.7)
</p>
<p>with Ï0 = q (Î¼n nn0 +Î¼p pn0) and Ïp = q (Î¼n+Î¼p) Ïp Gc. In the one-dimensional,
uniform case considered here, the current is the product of the current density times
the cross sectionAof the device, and the electric field is the ratio of the applied voltage
to the lengthL (Fig. 25.1). In conclusion, for t &gt; 0 the current I = V/R = V Ï A/L
is given by
</p>
<p>I = I0 + Ip exp (&minus; t/Ïp), (25.8)
</p>
<p>with I0 = Ï0 (A/L)V , Ip = Ïp (A/L)V , namely, the current&rsquo;s decay time is
the minority-carrier lifetime. The quantity to be measured is the current through
the device which, for t &lt; 0, is equal to the constant I0 + Ip, while it decreases
exponentially towards I0 for t &gt; 0 (Fig. 25.2). The measurement of Ïp is easily
accomplished by observing that the tangent to the exponential branch drawn at the
origin intercepts the asymptotic value I0 at t = Ïp. Note that the hypothesis of a
monochromatic illumination is not essential; in fact, the analysis still holds if Gc in
(25.3) is replaced with the integral of Gc over the frequencies.</p>
<p/>
</div>
<div class="page"><p/>
<p>578 25 Measuring the Semiconductor Parameters
</p>
<p>25.2.0.1 Thermal Velocity and Capture Cross-Section
</p>
<p>In an n-doped material the hole lifetime is related to the hole-transition coefficient Î±p
and to the trap concentration Nt by Ïp = Ïp0 = 1/(Î±pNt ) (Sect. 20.2.3). It follows
that measuring Ïp after deliberately introducing a known concentration Nt of traps
into the semiconductor provides the value of the transition coefficient Î±p. The latter
is often recast in a different form by defining the carrier thermal velocity uth with the
relation
</p>
<p>1
</p>
<p>2
m&lowast; u2th =
</p>
<p>3
</p>
<p>2
kB T , (25.9)
</p>
<p>where m&lowast; = me for electrons and m&lowast; = mh for holes, with me, mh the average
effective masses. Using the data of Table 18.1 one finds, for silicon, me â 2.98 &times;
10&minus;31 kg and mh â 3.20 &times; 10&minus;31 kg. In turn, the capture cross-sections of the traps,
for electrons and holes respectively, are defined by
</p>
<p>Ïe =
Î±n
</p>
<p>uth,e
, Ïh =
</p>
<p>Î±p
</p>
<p>uth,h
. (25.10)
</p>
<p>From the above definitions it follows that in an n-doped material
</p>
<p>Ïp = Ïp0 =
1
</p>
<p>Î±p Nt
= 1
</p>
<p>Ïh uth,h Nt
. (25.11)
</p>
<p>In particular, in silicon at TL = 300 K it is from (25.9) uth,e â uth,h &sim; 2&times;107 cm s&minus;1.
The measure of Î±p thus provides for the cross-section the value Ïh â 5 &times; 10&minus;15 cm2.
A qualitative picture of the cross-section as a circle centered at the trap yields the
definition of a radius rh such that Ïh = Ï r2h . It turns out rh â 4 &times; 10&minus;8 cm, namely,
rh is of the order of the atomic radius. The measure of Ïn, Î±n, and Ïe is carried out
in a similar way, starting from a p-doped material.
</p>
<p>25.3 Mobility Measurement&mdash;Haynes-Shockley Experiment
</p>
<p>A measurement method for mobility is illustrated with the aid of Fig. 25.3, showing
a uniformly-doped layer of semiconductor to which a constant positive voltage V is
applied; this produces an electric field in the x direction, E = E i1. The method is
able to measure the minority-carrier mobility; in the example shown in the figure,
which refers to an n-doped material, the outcome is Î¼p.
</p>
<p>Holes are generated at some position x by, e.g., illuminating the material with a
laser pulse. The electric field makes the holes to drift to the right, where they are
eventually collected after crossing a distance ï¿½x1 in the direction parallel to E. The
lower part of Fig. 25.3 shows three profiles of the hole distribution at successive
instants of time, from left to right.2 The leftmost, thin profile corresponds to the
</p>
<p>2 The generated electrons drift to the left and are absorbed by the left contact.</p>
<p/>
</div>
<div class="page"><p/>
<p>25.3 Mobility Measurement&mdash;Haynes-Shockley Experiment 579
</p>
<p>Fig. 25.3 Measurement
scheme for mobility
(Haynes-Shockley
experiment)
</p>
<p>n0
</p>
<p>V n
</p>
<p>Îx
</p>
<p>x1
</p>
<p>p &minus; p
</p>
<p>Vs
</p>
<p>1
</p>
<p>Measuring electrode
</p>
<p>instant of the laser pulse; the other two profiles are shifted to the right because of the
action of the field. The hole distribution becomes progressively wider and shorter
because of diffusion; also, its area decreases with time due to recombination. When
the profile crosses the section corresponding to the measuring electrode, the largest
value of the measured voltage VS corresponds to the profile&rsquo;s peak. This allows one
to measure the time ï¿½t necessary for the profile&rsquo;s peak to cover the distance from
the section where the laser pulse is applied to that of the measuring electrode. Then,
the average velocity of the peak is found from ï¿½x1/ï¿½t .
</p>
<p>The analysis of the experiment is carried out assuming that the perturbation is
sufficiently small, so that a weak-injection condition holds. The continuity equation
for the minority carriers reads
</p>
<p>&part;p
</p>
<p>&part;t
+ p &minus; pn0
</p>
<p>Ïp
+ div
</p>
<p>(
</p>
<p>Î¼p p E &minus;Dp grad p
)
</p>
<p>= 0, (25.12)
</p>
<p>with Î¼p, Dp = const due to spatial uniformity. Remembering that div D = Ï, in
(25.12) it is
</p>
<p>div (pE) = E &middot; grad p + p Ï
Îµsc
</p>
<p>â E &middot; grad p, (25.13)
</p>
<p>on account of the fact that, due to the weak-injection condition, the perturbation with
respect to the local charge neutrality is small, whereas grad p is large. Using the
auxiliary function f = (p &minus; pn0) exp (t/Ïp) transforms (25.12) into
</p>
<p>&part;f
</p>
<p>&part;t
&minus;Dp &nabla;2f + Î¼p E &middot; grad f = 0. (25.14)
</p>
<p>The above equation is further simplified by applying a suitable change of the
variables,
</p>
<p>râ = râ(r, t) = r &minus; v t , tâ = tâ(r, t) = t , (25.15)</p>
<p/>
</div>
<div class="page"><p/>
<p>580 25 Measuring the Semiconductor Parameters
</p>
<p>where v is a constant velocity, yet undefined. The relations between the spatial
derivatives with respect to the old and new variables read
</p>
<p>&part;f
</p>
<p>&part;xi
=
</p>
<p>3
&sum;
</p>
<p>j=1
</p>
<p>&part;f
</p>
<p>&part;xâj
</p>
<p>&part;xâj
</p>
<p>&part;xi
= &part;f
</p>
<p>&part;xâi
, (25.16)
</p>
<p>so that, using the star to indicate the operators acting on the new spatial variables,
</p>
<p>gradâf = grad f , &nabla;2âf = &nabla;2f. (25.17)
The time derivatives are treated in the same manner, to find
</p>
<p>&part;f
</p>
<p>&part;t
= &part;f
</p>
<p>&part;tâ
</p>
<p>&part;tâ
</p>
<p>&part;t
+
</p>
<p>3
&sum;
</p>
<p>j=1
</p>
<p>&part;f
</p>
<p>&part;xâj
</p>
<p>&part;xâj
</p>
<p>&part;t
= &part;f
</p>
<p>&part;tâ
&minus; v &middot; gradâf. (25.18)
</p>
<p>Replacing (25.17), (25.18) into (25.14) yields
</p>
<p>&part;f
</p>
<p>&part;tâ
= Dp &nabla;2âf +
</p>
<p>(
</p>
<p>v &minus; Î¼p E
)
</p>
<p>&middot; gradâf. (25.19)
</p>
<p>Exploiting the arbitrariness of v one lets v = Î¼p E, so that (25.19) simplifies to a
diffusion equation, &part;f /&part;tâ = Dp &nabla;2âf . The solution of the latter is given by (23.28),
namely,
</p>
<p>f (râ, tâ) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
f (s, 0)Î(râ &minus; s, tâ) d3s, (25.20)
</p>
<p>with
</p>
<p>Î(râ &minus; s, tâ) = 1(
4Ï Dp tâ
</p>
<p>)3/2 exp
</p>
<p>(
</p>
<p>&minus;|r
â &minus; s|2
</p>
<p>4Dp tâ
</p>
<p>)
</p>
<p>, (25.21)
</p>
<p>and f (s, 0) = p(s, 0) &minus; pn0. Using again the old variables yields
</p>
<p>p = pn0 + exp ( &minus; t/Ïp)
(
</p>
<p>4Ï Dp t
)3/2
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
f (s, 0)Î(r &minus; v t &minus; s, t) d3s.
</p>
<p>(25.22)
</p>
<p>The input pulse can be selected in such a way that f (s, 0) &asymp; c Î´(s), where c is a
dimensionless constant. In conclusion,
</p>
<p>p = pn0 +
c exp ( &minus; t/Ïp)
(
</p>
<p>4Ï Dp t
)3/2 exp
</p>
<p>[
</p>
<p>&minus; (x1 &minus; Î¼p E t)
2 + x22 + x23
</p>
<p>4Dp t
</p>
<p>]
</p>
<p>, (25.23)
</p>
<p>which, apart from the additive constantpn0, is a Gaussian whose amplitude decreases
in time and whose peak moves along the x1 direction with the constant velocity
v = Î¼pE. Measuring the time Ît1 needed for the peak to cross the distance Îx1
finally yields the mobility
</p>
<p>Î¼p =
1
</p>
<p>E
</p>
<p>Îx1
</p>
<p>Ît1
. (25.24)</p>
<p/>
</div>
<div class="page"><p/>
<p>25.4 Hall-Voltage Measurement 581
</p>
<p>&gt; 0V
</p>
<p>&gt; 0V
</p>
<p>   &gt; 0V
H
</p>
<p>   &lt; 0V
H
</p>
<p>&minus;&minus; &minus;
</p>
<p>+ + +
</p>
<p>z
B
</p>
<p>B
</p>
<p>I
</p>
<p>Ï
H
</p>
<p>B
</p>
<p>F
</p>
<p>v&minus;&minus;Ï
</p>
<p>++ +
</p>
<p>&minus; &minus; &minus;
</p>
<p>z
B
</p>
<p>B
</p>
<p>I
</p>
<p>Ï
H
</p>
<p>B
</p>
<p>Fv+
</p>
<p>+Ï
</p>
<p>Fig. 25.4 Scheme of a Hall-voltage measurement
</p>
<p>25.4 Hall-Voltage Measurement
</p>
<p>The measurements based on the Hall effect are a powerful investigation tool that
exploits the combined action of the electric and magnetic field. The Hall effect is
the production of a voltage drop, transverse to the direction of the electric current,
due to the application of a magnetic field. The qualitative features of the method are
explained with the aid of Fig. 25.4. Consider a uniformly doped, prismatic block
of semiconductor. The block is slender, and a constant voltage V is applied to it to
produce an electric field E aligned with the longitudinal direction. As a consequence,
one can assume that the flow lines of the current density be parallel to E; due to spatial
uniformity, such a current density is essentially due to the drift of majority carriers.
At the same time, a constant magnetic-induction field B is applied, normal to one of
the lateral faces. The upper part of the figure refers to an n-doped semiconductor;
there, the majority carriers are electrons, whose average velocity is oriented opposite
to the field; it follows that the Lorentz force F = Ï&minus; v&minus; &and; B (Sect. 4.11) is oriented
as shown in the figure. The negative indices in the expression of the Lorentz force
remind one that the charge density and average velocity are those of negative charges.
The mobile electrons are pushed by the Lorentz force towards the lower face of the
device, where they form a negative charge layer. The flow lines of the current density
are still parallel to the longitudinal direction; however, their density is not uniform any
more. Due to the global charge neutrality, the negative charge layer is compensated
by a positive charge layer that forms at the upper face. The two opposite layers,
schematically indicated in the diagram in the upper-right part of Fig. 25.4, produce
an electric field normal to the upper and lower faces; as a result, a measurable voltage</p>
<p/>
</div>
<div class="page"><p/>
<p>582 25 Measuring the Semiconductor Parameters
</p>
<p>drop (Hall voltage) between the two faces comes into existence: for the example in
hand, the voltage of the upper face is larger than that of the lower face.
</p>
<p>In a p-doped semiconductor (lower part of the figure), the majority carriers are
holes, whose average velocity is oriented in the direction of the field; the Lorentz
force F = Ï+ v+&and;B is oriented as in the previous case, because both charge density
and average velocity change sign with respect to the n-doped semiconductor. The
consequence is that the mobile holes are pushed towards the lower face of the device,
where they form a positive charge layer. In conclusion, the sign of the Hall voltage
is opposite with respect to the case of the n-doped semiconductor.
</p>
<p>The analysis of the experiment is based on the drift-diffusion equations incor-
porating the magnetic terms, (19.107), (19.123); the diffusion terms are neglected,
whence
</p>
<p>Jn = qÎ¼nnE &minus; qanÎ¼2nnE &and; B, Jp = qÎ¼ppE + qapÎ¼2ppE &and; B. (25.25)
</p>
<p>The total current density J = Jn + Jp then reads
</p>
<p>J = ÏE + rÏ 2E &and; B, (25.26)
</p>
<p>where Ï = q Î¼p p + q Î¼n n is the electric conductivity and
</p>
<p>r = q
Ï 2
</p>
<p>(
</p>
<p>ap Î¼
2
p p &minus; an Î¼2n n
</p>
<p>)
</p>
<p>=
ap Î¼
</p>
<p>2
p p &minus; an Î¼2n n
</p>
<p>q
(
</p>
<p>Î¼p p + Î¼n n
)2 (25.27)
</p>
<p>is the Hall coefficient. The two quantities Ï and r can be measured independently as
shown below; while Ï is positive definite, r has a sign. In particular, the following
limiting cases hold: for the p-type dopant it is p â« n, whence Ï â qÎ¼pp and
r â ap/(qp) &gt; 0; thus,
</p>
<p>p = ap
q r
</p>
<p>, Î¼p =
r
</p>
<p>ap
Ï (p â« n). (25.28)
</p>
<p>Similarly, for the n-type dopant it is n â« p, whence Ï â q Î¼n n and r â
&minus;an/(q n) &lt; 0; thus,
</p>
<p>n = &minus; an
q r
</p>
<p>, Î¼n = &minus;
r
</p>
<p>an
Ï (n â« p). (25.29)
</p>
<p>From (25.28) and (25.29) it follows that the concentration and mobility of the majority
carriers can be determined independently, provided Ï and r are known. In turn, the
measurement of Ï and r is easily carried out by applying (25.26) to the prismatic
sample of Fig. 25.4. Let iL be the unit vector of the longitudinal direction, and iW
the unit vector parallel to B, so that B = B iW . Observing that EW = 0, JW = 0,
and E &and; B = ELBiH &minus; EHBiL, it follows
</p>
<p>JL = ÏEL &minus; rÏ 2EHB, JH = ÏEH + rÏ 2ELB, (25.30)</p>
<p/>
</div>
<div class="page"><p/>
<p>25.5 Measurement of Doping Profiles 583
</p>
<p>with JH = 0. In turn, B is small enough to make the following approximations
possible:
</p>
<p>J = JL â ÏEL, EH = &minus;rÏELB â &minus;rJB. (25.31)
</p>
<p>On the other hand it isEL â VL/L, EH â VH /H , and J = I/(W H ), whenceVH =
&minus;rBI/W and I/(WH ) = ÏVL/L. In conclusion,
</p>
<p>Ï = LI
WHVL
</p>
<p>, r = &minus;WVH
BI
</p>
<p>, (25.32)
</p>
<p>namely, the two parameters are obtained by combining the Hall voltage with
other known physical and geometrical parameters. Typical applications of the mea-
surement scheme shown in this section are the measurements of majority-carrier
concentrations and mobilities as functions of temperature and dopant concentration.
</p>
<p>25.5 Measurement of Doping Profiles
</p>
<p>The calculation of the depletion capacitance for an arbitrary doping profile, in the
one-dimensional case, has been carried out in Sect. 21.6.3; the analysis has yielded,
among others, the two relations (21.72) and (21.73), that are reported below:
</p>
<p>dQ = Ï(b) db, C = dQ
dÏ
</p>
<p>= Îµsc
b &minus; a , (25.33)
</p>
<p>where C is the differential capacitance per unit area of the space&ndash;charge region,
whose boundaries are a and b, and Ï = Ï(b) &minus; Ï(a). For a strongly-asymmetric
junction it is, e.g., b &minus; a â b, and (25.33) become
</p>
<p>C â Îµsc
b
</p>
<p>, Îµsc dÏ â b Ï(b) db =
1
</p>
<p>2
Ï(b) db2 = 1
</p>
<p>2
Ï(b) d
</p>
<p>(
Îµ2sc
</p>
<p>C2
</p>
<p>)
</p>
<p>. (25.34)
</p>
<p>As a consequence,
</p>
<p>Ï(b) = 2
Îµsc
</p>
<p>[
</p>
<p>d
(
</p>
<p>1/C2
)
</p>
<p>dÏ
</p>
<p>]&minus;1
</p>
<p>. (25.35)
</p>
<p>Basing upon (25.35), a measurement scheme can be devised, which proceeds as
follows:
</p>
<p>1. C is measured at a given bias V , and b is determined from b = Îµsc/C.
2. C is measured again after slightly varying the bias from V to V +dV = V +dÏ .
3. A numerical calculation of the derivative yields Ï(b).</p>
<p/>
</div>
<div class="page"><p/>
<p>584 25 Measuring the Semiconductor Parameters
</p>
<p>An example of application of the above scheme is given with reference to an asym-
metric p-n junction with, e.g., a = &minus;lp, b = ln, and ln â« lp. In the reverse-bias
condition, and using the full-depletion approximation (20.34), it is Ï â q N , whence
</p>
<p>N (ln) â
2
</p>
<p>qÎµsc
</p>
<p>[
</p>
<p>d
(
</p>
<p>1/C2
)
</p>
<p>dÏ
</p>
<p>]&minus;1
</p>
<p>. (25.36)
</p>
<p>This provides a method for measuring the dopant distribution.</p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix A
Vector and Matrix Analysis
</p>
<p>A.1 Scalar Product
</p>
<p>Consider two complex, n-dimensional column vectors
</p>
<p>a =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â£
</p>
<p>a1
...
</p>
<p>an
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¦
</p>
<p>, b =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â£
</p>
<p>b1
...
</p>
<p>bn
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¦
</p>
<p>, (A.1)
</p>
<p>whose entries are the components in an n-dimensional Cartesian reference and may
depend on position, time, and other parameters. The scalar product of the two vectors
is indicated with a &middot; b and is defined as
</p>
<p>a &middot; b =
n
</p>
<p>&sum;
</p>
<p>i=1
a&lowast;i bi . (A.2)
</p>
<p>with a&lowast;i the complex conjugate of ai . Two non-vanishing vectors a and b are or-
thogonal if a &middot; b = 0. As b &middot; a = (a &middot; b)&lowast;, the order of the factors in the scalar
product matters; in fact it becomes irrelevant only when the factors are real. The
scalar product is distributive and bilinear; if, say, a = h1 p1 + h2 p2, then
</p>
<p>a &middot; (k1 b1 + k2 b2) = h&lowast;1 k1 p1 &middot; b1 + h&lowast;2 k1 p2 &middot; b1 + h&lowast;1 k2 p1 &middot; b2 + h&lowast;2 k2 p2 &middot; b2,
(A.3)
</p>
<p>where h1,h2, k1, k2 are complex constants (in (A.3), the product k1 b1 is the vector
of components k1 b1i , and so on). The modulus of a is defined as
</p>
<p>a = |a| = &radic;a &middot; a =
(
</p>
<p>n
&sum;
</p>
<p>i=1
|ai |2
</p>
<p>)1/2
</p>
<p>&ge; 0. (A.4)
</p>
<p>&copy; Springer Science+Business Media New York 2015 585
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6</p>
<p/>
</div>
<div class="page"><p/>
<p>586 Appendix A Vector and Matrix Analysis
</p>
<p>A.2 Schwarz Inequality and Generalizations
</p>
<p>Using (A.2, A.3, A.4) one proves the Schwarz inequality
</p>
<p>|a &middot; b| &le; a b. (A.5)
</p>
<p>The above is obvious if a = 0 or b = 0; let b ï¿½= 0 and define c = a &minus; (a &middot; b) b/b2,
whence c &middot; b = 0. It follows
</p>
<p>a2 =
(
</p>
<p>c + a &middot; b
b2
</p>
<p>b
</p>
<p>)
</p>
<p>&middot;
(
</p>
<p>c + a &middot; b
b2
</p>
<p>b
</p>
<p>)
</p>
<p>= c2 + |a &middot; b|
2
</p>
<p>b2
&ge; |a &middot; b|
</p>
<p>2
</p>
<p>b2
, (A.6)
</p>
<p>which is equivalent to (A.5). The strict equality in (A.5) holds if and only if b = k a,
with k any complex constant. Observing that |a &middot; b|2 = &real;2(a &middot; b) + &image;2(a &middot; b), from
(A.5) one also derives the inequalities &minus;ab &le; &real;(a &middot; b) &le; +ab. Thanks to this, one
defines the cosine of the angle Ï between two non-vanishing vectors a and b as
</p>
<p>cosÏ = &real;(a &middot; b)
ab
</p>
<p>. (A.7)
</p>
<p>Other types of products may be defined besides the scalar product, also involving
higher-rank factors: for instance, n&times; n matrices of the second rank like
</p>
<p>A =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â¢
â¢
â£
</p>
<p>A11 A12 . . . A1n
</p>
<p>A21 A22 . . . A2n
...
</p>
<p>...
. . .
</p>
<p>...
</p>
<p>An1 An2 . . . Ann
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¥
â¥
â¦
</p>
<p>, B =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â¢
â¢
â£
</p>
<p>B11 B12 . . . B1n
</p>
<p>B21 B22 . . . B2n
...
</p>
<p>...
. . .
</p>
<p>...
</p>
<p>Bn1 Bn2 . . . Bnn
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¥
â¥
â¦
</p>
<p>, (A.8)
</p>
<p>and so on. Given a second-rank matrix A of entries Aij , its transpose Q = AT is the
matrix of entries Qij = Aji . Transposition applies also to vectors: the transpose of
the column vector a defined in (A.1) is the row vector aT = [a1, . . . , an]. With these
premises, given the column vectors a, b and the matrices A, B, the products A B,
A b, and a bT yield, respectively, an n&times; n matrix, an n-dimensional column vector,
and an n&times; n matrix whose entries are
</p>
<p>(A B)ij =
n
</p>
<p>&sum;
</p>
<p>k=1
Aik Bkj , (A b)i =
</p>
<p>n
&sum;
</p>
<p>j=1
Aij bj ,
</p>
<p>(
</p>
<p>a bT
)
</p>
<p>ij
= ai bj . (A.9)
</p>
<p>Applying definitions (A.9) one finds
</p>
<p>(A B)T = BT AT , (A b)T = bT AT ,
(
</p>
<p>a bT
)T = b aT . (A.10)</p>
<p/>
</div>
<div class="page"><p/>
<p>A.3 Nabla Operator 587
</p>
<p>A.3 Nabla Operator
</p>
<p>A further extension of the concepts introduced in this chapter consists in replacing
one or more factors with an operator. An important example is that of the real, vector
operator nabla,1
</p>
<p>&nabla; =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â£
</p>
<p>&part;/&part;x1
...
</p>
<p>&part;/&part;xn
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¦
</p>
<p>, (A.11)
</p>
<p>where x1, . . . , xn are the coordinates of an n-dimensional Cartesian reference. The
product of &nabla; and a complex, scalar function f (x1, . . . , xn) is defined in the same
manner as the product of a vector and a scalar quantity introduced above: &nabla;f is a
vector of components (&nabla;)if , namely,
</p>
<p>&nabla;f =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â£
</p>
<p>&part;f/&part;x1
...
</p>
<p>&part;f/&part;xn
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¦
. (A.12)
</p>
<p>In turn, the scalar product of &nabla; and a complex vector a of the same dimension as &nabla;
yields
</p>
<p>&nabla; &middot; a = &part;a1
&part;x1
</p>
<p>+ . . .+ &part;an
&part;xn
</p>
<p>. (A.13)
</p>
<p>The product defined by (A.12) is also called gradient of f , whereas the scalar product
(A.13) is also called divergence of a. The corresponding symbols are &nabla;f = grad f
and &nabla; &middot; a = div a, respectively. The scalar product of &nabla; by itself is called Laplacian
operator
</p>
<p>&nabla;2 = &nabla; &middot; &nabla; = &part;
2
</p>
<p>&part;x21
+ . . .+ &part;
</p>
<p>2
</p>
<p>&part;x2n
, (A.14)
</p>
<p>then,
</p>
<p>&nabla;2f = &part;
2f
</p>
<p>&part;x21
+ . . .+ &part;
</p>
<p>2f
</p>
<p>&part;x2n
, &nabla;2a =
</p>
<p>â¡
</p>
<p>â¢
â¢
â¢
â£
</p>
<p>&nabla;2a1
...
</p>
<p>&nabla;2an
</p>
<p>â¤
</p>
<p>â¥
â¥
â¥
â¦
. (A.15)
</p>
<p>Combining the above definitions yields the identities
</p>
<p>&nabla;2f = &nabla; &middot; (&nabla;f ) = div grad f , &nabla; &middot; (f &lowast;a) = div (f &lowast;a) = f &lowast; div a + grad f &middot; a.
(A.16)
</p>
<p>1 Symbol &nabla; is not a Greek letter. However, the term nabla is a Greek word, meaning &ldquo;harp&rdquo;.</p>
<p/>
</div>
<div class="page"><p/>
<p>588 Appendix A Vector and Matrix Analysis
</p>
<p>If, in turn, it is a = grad g, the second relation of (A.16) with the aid of the first one
yields the identity
</p>
<p>div (f &lowast; grad g) = f &lowast; &nabla;2g + grad f &middot; grad g. (A.17)
</p>
<p>A.4 Dyadic Products
</p>
<p>Sometimes it is convenient to adopt a notation that uses the basis set of real, mutually-
orthogonal unit vectors i1, . . . , in associated with the axes of a Cartesian reference.
By construction it is ir &middot; is = Î´rs , where the Kronecker symbol Î´rs is the entry of
indices rs of a second-rank matrix defined as
</p>
<p>Î´rs =
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>1 s = r
0 s ï¿½= r
</p>
<p>(A.18)
</p>
<p>The expression of vector a in terms of the basis vectors is a = a1 i1 + . . . + an in.
The notation applies also to the higher-rank objects; for instance, in this notation the
matrix A of (A.8) reads
</p>
<p>A = A11 i1 iT1 + A12 i1 iT2 + . . .+ An,n&minus;1 in iTn&minus;1 + Ann in iTn , (A.19)
A group like ir iTs is also called dyadic product. Observing that ir is an n-dimensional
column vector whose rth entry is equal to 1 while all the other entries are equal to 0,
the application of the third equation in (A.9) shows that ir iTs is an n&times;n matrix whose
entry of indices rs is equal to 1, while all the other entries are equal to zero. As a
consequence, the form (A.19) expresses A as a sum of matrices, each associated to an
individual entry. Using this notation, a product like A b reads
</p>
<p>&sum;
</p>
<p>rs Ars ir i
T
s
</p>
<p>&sum;
</p>
<p>k bk ik .
On the other hand, due to the second equation in (A.9), the same product is equal to
&sum;
</p>
<p>rs Ars bs ir . This shows that ir i
T
s ik = ir Î´sk , that is, the juxtaposition of the right
</p>
<p>unit vector of the dyadic product with the next unit vector must be treated as a scalar
product.
</p>
<p>The relation defined by the second equation in (A.9) applies also when b is replaced
with a vector operator, with the provision that the operator is meant to act towards
the left. For instance, replacing b with &nabla; yields (A&nabla;)i =
</p>
<p>&sum;n
j=1 &part;Aij/&part;xj . It follows
</p>
<p>that the divergence of a second-rank matrix is a column vector of the form
</p>
<p>div A =
n
</p>
<p>&sum;
</p>
<p>j=1
</p>
<p>&part;A1j
</p>
<p>&part;xj
i1 + . . .+
</p>
<p>n
&sum;
</p>
<p>j=1
</p>
<p>&part;Anj
</p>
<p>&part;xj
in. (A.20)
</p>
<p>In turn, considering the product defined by the third equation in (A.9) and replacing
b with &nabla;, still with the provision that the operator acts towards the left, yields
(a&nabla;T )ij = &part;ai/&part;xj . It follows that the gradient of a column vector is a second-rank
matrix of the form
</p>
<p>grad a = &part;a1
&part;x1
</p>
<p>i1 i
T
1 +
</p>
<p>&part;a1
</p>
<p>&part;x2
i1 i
</p>
<p>T
2 + . . .+
</p>
<p>&part;an
</p>
<p>&part;xn&minus;1
i1 i
</p>
<p>T
n&minus;1 +
</p>
<p>&part;an
</p>
<p>&part;xn
in i
</p>
<p>T
n (A.21)</p>
<p/>
</div>
<div class="page"><p/>
<p>A.6 Vector Product 589
</p>
<p>whence, from (A.20),
</p>
<p>div (f A) = f div A + A grad f , div (a bT ) = a div b + ( grad a) b. (A.22)
</p>
<p>A.5 Divergence Theorem
</p>
<p>The divergence theorem (or Gauss theorem) states that
&int;
</p>
<p>V
</p>
<p>div v dV =
&int;
</p>
<p>S
</p>
<p>n &middot; v dS, (A.23)
</p>
<p>where V is an n-dimensional volume, dV = dx1 . . . dxn, S the (n&minus; 1)-dimensional
surface enclosing V , and n the unit vector normal to the surface element dS, oriented
in the outward direction with respect to S. Letting v = f &lowast; grad g and using (A.17)
yields the first Green theorem
</p>
<p>&int;
</p>
<p>S
</p>
<p>f &lowast;
&part;g
</p>
<p>&part;n
dS =
</p>
<p>&int;
</p>
<p>V
</p>
<p>(
</p>
<p>f &lowast; &nabla;2g + grad f &middot; grad g
)
</p>
<p>dV , (A.24)
</p>
<p>where &part;g/&part;n = n &middot; grad g is the derivative of g in the direction of n. It is easily
found that (A.24) is the generalization to n dimensions of the integration by parts.
Rewriting (A.24) after letting v = g grad f &lowast;, and subtracting from (A.24), yields
the second Green theorem
</p>
<p>&int;
</p>
<p>S
</p>
<p>(
</p>
<p>f &lowast;
&part;g
</p>
<p>&part;n
&minus; g &part;f
</p>
<p>&lowast;
</p>
<p>&part;n
</p>
<p>)
</p>
<p>dS =
&int;
</p>
<p>V
</p>
<p>(
</p>
<p>f &lowast; &nabla;2g &minus; g&nabla;2f &lowast;
)
</p>
<p>dV. (A.25)
</p>
<p>A special case of the first Green theorem occurs when vector b = grad g is constant;
the relation (A.24) then reduces to
</p>
<p>&int;
</p>
<p>S
</p>
<p>f &lowast; n dS &middot; b =
&int;
</p>
<p>V
</p>
<p>grad f dV &middot; b, b = const. (A.26)
</p>
<p>As identity (A.26) holds for any choice of b, the two integrals in it are equal to each
other.
</p>
<p>A.6 Vector Product
</p>
<p>Another possible product between two vectors is the vector product a &and; b, which
yields a column vector. In contrast with the other products introduced in this section,
the definition of the vector product will be limited to the three-dimensional case; it
is given as the expansion of a determinant, namely,
</p>
<p>a &and; b =
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>i1 i2 i3
</p>
<p>a1 a2 a3
</p>
<p>b1 b2 b3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>&rArr; a &and; b =
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>a2b3 &minus; a3b2
a3b1 &minus; a1b3
a1b2 &minus; a2b1
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
. (A.27)</p>
<p/>
</div>
<div class="page"><p/>
<p>590 Appendix A Vector and Matrix Analysis
</p>
<p>From (A.27) it follows b &and; a = &minus;a &and; b and a &and; a = 0. The latter also shows
that, if two non-vanishing vectors are parallel to each other, say, b = k a ï¿½= 0, then
a &and; b = 0. When the vector product involves the unit vectors associated to the axes
of a right-handed Cartesian reference, the following relations are found:
</p>
<p>i1 &and; i2 = i3, i2 &and; i3 = i1, i3 &and; i1 = i2. (A.28)
</p>
<p>An intrinsic relation that provides the modulus of a &and; b is found by specifying (A.7)
for the case of three-dimensional, real vectors, this yielding
</p>
<p>cos2 Ï = 1 &minus; sin2 Ï =
</p>
<p>(
&sum;3
</p>
<p>i=1 ai bi
)2
</p>
<p>a2 b2
. (A.29)
</p>
<p>As cosÏ = 1 when the two vectors are parallel, b = k a, k &gt; 0, while cosÏ = &minus;1
when they are antiparallel, b = k a, k &lt; 0, the range of Ï is [0,Ï ]. Letting rij =
ai bj&minus;aj bi and observing that (
</p>
<p>&sum;3
i=1 a
</p>
<p>2
i ) (
</p>
<p>&sum;3
i=1 b
</p>
<p>2
i ) = (
</p>
<p>&sum;3
i=1 ai bi)
</p>
<p>2+r223+r231+r212
provides
</p>
<p>sin2 Ï = r
2
23 + r231 + r212
</p>
<p>a2 b2
= |a &and; b|
</p>
<p>2
</p>
<p>a2 b2
, |a &and; b| = a b sin Ï , (A.30)
</p>
<p>where sin Ï &ge; 0 due to the range of Ï .
</p>
<p>A.7 Mixed Product
</p>
<p>The vector product a &and; b can in turn be scalarly multiplied by another vector c,
to yield a scalar quantity called mixed product. For the sake of simplicity, in the
definition of the mixed product the three vectors will be considered real. From (A.2)
one finds
</p>
<p>a &and; b &middot; c =
3
</p>
<p>&sum;
</p>
<p>i=1
(a &and; b)i ci =
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>c1 c2 c3
</p>
<p>a1 a2 a3
</p>
<p>b1 b2 b3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>=
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>a1 a2 a3
</p>
<p>b1 b2 b3
</p>
<p>c1 c2 c3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
. (A.31)
</p>
<p>The two determinants in (A.31) are equal because they transform into each other by
interchanging rows an even number of times. On the other hand, from their equality
it follows a&and;b&middot;c = a &middot;b&and;c, namely, the mixed product is invariant upon interchange
of the &ldquo;wedge&rdquo; and &ldquo;dot&rdquo; symbols.
</p>
<p>Considering three non-vanishing vectors a, b, c, where a and b are not parallel
to each other, and remembering the properties of determinants, one finds that the
mixed product vanishes if c is parallel to a or parallel to b. In fact,
</p>
<p>a &and; b &middot; a = a &and; b &middot; b = 0. (A.32)</p>
<p/>
</div>
<div class="page"><p/>
<p>A.8 Rotational of a Vector 591
</p>
<p>It follows that the vector product a &and; b is normal to both a and b, namely, is normal
to the plane defined by the two non-parallel vectors a and b. If one associates the
plane of a and b with that of the unit vectors i1 and i2 then, using (A.28), the vector
product simplifies to a &and; b = (a1 b2 &minus; a2 a1) i3, that provides the information about
the direction of a &and; b. Finally, using (A.27) twice provides the expression for the
double vector product
</p>
<p>a &and; (b &and; c) = a &middot; c b &minus; a &middot; b c, (a &and; b) &and; c = a &middot; c b &minus; b &middot; c a. (A.33)
</p>
<p>A.8 Rotational of a Vector
</p>
<p>The expressions involving the vector product can be extended to the case where one
or two vectors are replaced with the nabla operator (A.11). The vector product
</p>
<p>&nabla; &and; a =
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>i1 i2 i3
</p>
<p>&part;/&part;x1 &part;/&part;x2 &part;/&part;x3
</p>
<p>a1 a2 a3
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>=
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>&part;a3/&part;x2 &minus; &part;a2/&part;x3
&part;a1/&part;x3 &minus; &part;a3/&part;x1
&part;a2/&part;x1 &minus; &part;a1/&part;x2
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>(A.34)
</p>
<p>is also called rotational of a, the corresponding symbol being &nabla; &and; a = rot a. Com-
bining (A.34) with the three-dimensional case of (A.12) and (A.13) shows that the
following identities hold:
</p>
<p>rot (f a) = f rot a + grad f &and; a, rot grad f = 0, div rot a = 0, (A.35)
rot rot a = grad div a &minus; &nabla;2a, div (a &and; b) = b &middot; rot a &minus; a &middot; rot b. (A.36)
</p>
<p>Integrating the second equation in (A.36) over a three-dimensional volume V and
using (A.23) yields the identity
</p>
<p>&int;
</p>
<p>S
</p>
<p>n &middot; a &and; b dS =
&int;
</p>
<p>V
</p>
<p>(b &middot; rot a &minus; a &middot; rot b) dV. (A.37)
</p>
<p>A special case of (A.37) occurs when vector a is constant. In fact, noting that n&middot;a&and;b =
&minus;n &middot; b &and; a = &minus;n &and; b &middot; a, (A.37) reduces to
</p>
<p>a &middot;
&int;
</p>
<p>S
</p>
<p>n &and; b dS = a &middot;
&int;
</p>
<p>V
</p>
<p>rot b dV , a = const. (A.38)
</p>
<p>As identity (A.38) holds for any choice of a, the two integrals in it are equal to each
other.</p>
<p/>
</div>
<div class="page"><p/>
<p>592 Appendix A Vector and Matrix Analysis
</p>
<p>Fig. A.1 Rotational theorem
(Sect. A.9): orientation of the
unit vectors
</p>
<p>n
</p>
<p>&minus;n
</p>
<p>b
</p>
<p>t
</p>
<p>A.9 Rotational Theorem
</p>
<p>The rotational theorem (or Stokes theorem) states that
&int;
</p>
<p>S
</p>
<p>n &middot; rot v dS =
&int;
</p>
<p>C
</p>
<p>t &middot; v dC, (A.39)
</p>
<p>where C is the boundary curve of the open surface S, t the unit vector tangent to
C, and n the unit vector normal to the surface element dS. The direction of the unit
vectors is such that the orientation of b = t &and; n is external with respect to the curve
(Fig. A.1).
</p>
<p>A.10 Helmholtz Theorem
</p>
<p>A vector u such that rot u = 0 is called irrotational. From the second identity in
(A.35) one finds that, if u = grad f , then u is irrotational. The inverse is not true in
general; however, if the domain of u is simply connected, the condition rot u = 0
implies that u can be expressed as a gradient: u = grad f .
</p>
<p>A vector v such that div v = 0 is called solenoidal. From the third identity in
(A.35) one finds that, if v = rot a, then v is solenoidal. The inverse is not true in
general; however, if the domain of v is simply connected, the condition div v = 0
implies that v can be expressed as a rotational: v = rot a.
</p>
<p>The Helmholtz theorem states that a vector w defined in a simply-connected
domain can be expressed in a unique manner as the sum of an irrotational and a
solenoidal vector:
</p>
<p>w = grad f + rot a. (A.40)
Scalar f is found by taking the divergence of both sides of (A.40) and using the
identities div grad f = &nabla;2f , div rot a = 0. In turn, vector a is found by taking the
rotational of both sides of (A.40) and using the first identity in (A.36) along with the
auxiliary condition div a = 0. By this procedure it is found that f and a fulfill the
relations
</p>
<p>&nabla;2f = div w, &nabla;2a = &minus; rot w. (A.41)</p>
<p/>
</div>
<div class="page"><p/>
<p>A.12 Wronskian Determinant 593
</p>
<p>The right hand sides of (A.41) are known because w is prescribed. As a consequence,
the problem of finding f and a is equivalent to solving a set of Poisson equations. The
solution of (A.41) is unique provided that w vanishes at infinity faster than r&minus;1 [65,
Sect. XI.3]. Unless some additional prescriptions are imposed on f and a, (A.40)
still holds if one adds to f an arbitrary constant and, to a, the gradient of an arbitrary
scalar function.
</p>
<p>A.11 Doubly-Stochastic Matrices
</p>
<p>Consider a set of M square matrices of order M , S1, . . . , SM , and a set of M real,
non-negative numbers Î¸k such that Î¸1 + . . .+ Î¸M = 1. The matrix
</p>
<p>S =
M
&sum;
</p>
<p>k=1
Î¸kSk (A.42)
</p>
<p>is called convex combination of the Sk matrices.
The following theorem is easily proved: if the matrices Sk are doubly stochastic,2
</p>
<p>then S is doubly stochastic as well. In fact from the definition of S it is (S)ij =
&sum;M
</p>
<p>k=1 Î¸k(Sk)ij whence, adding the terms row-wise,
</p>
<p>M
&sum;
</p>
<p>j=1
(S)ij =
</p>
<p>M
&sum;
</p>
<p>k=1
Î¸k
</p>
<p>M
&sum;
</p>
<p>j=1
(Sk)ij =
</p>
<p>M
&sum;
</p>
<p>k=1
Î¸k = 1. (A.43)
</p>
<p>The same result is obtained when summing column-wise. As permutation matri-
ces are doubly stochastic, from the above theorem the special case follows: a convex
combination of permutation matrices is a doubly-stochastic matrix. The inverse prop-
erty also holds: a doubly-stochastic matrix is a convex combination of permutation
matrices [5].
</p>
<p>A.12 Wronskian Determinant
</p>
<p>The Wronskian determinant provides the condition of linear independence of func-
tions [51, Sect. 5.2]. Although its properties hold for any number of functions, they
will be discussed here for the case of two functions only, say, u and v defined on
some interval of the independent variable x. It is convenient to seek for the condition
of linear dependence first. If u, v are linearly dependent, then two non-vanishing
constants c1, c2 exist such that
</p>
<p>c1 u + c2 v = 0 (A.44)
</p>
<p>2 The definition of doubly-stochastic matrix is given in Sect. 7.6.1.</p>
<p/>
</div>
<div class="page"><p/>
<p>594 Appendix A Vector and Matrix Analysis
</p>
<p>for all x in the interval. If (A.44) holds, it is easily found that both c1 and c2 must differ
from zero. Also, as the function at the left hand side of (A.44) vanishes identically,
its derivative vanishes as well. Such a derivative exists because u and v are supposed
to be solutions of a second-order differential equation. Then,
</p>
<p>c1 u
&prime; + c2 v&prime; = 0 (A.45)
</p>
<p>for all x in the interval. As (A.44, A.45) hold together, for all x the two constants c1,
c2 are the non-trivial solution of a homogeneous algebraic system. Now, if the non-
trivial solution of the algebraic system exists for all x, the determinantW = u v&prime;&minus;u&prime; v
must vanish identically. That is, the condition W = 0 (identically) is necessary for
the linear dependence of u, v. As a consequence, the condition W ï¿½= 0 (identically)
is sufficient for the linear independence of u, v.</p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix B
Coordinates
</p>
<p>B.1 Spherical Coordinates
</p>
<p>When the problem in hand has a spherical symmetry it is convenient to describe the
position of a particle by means of the spherical coordinates.
</p>
<p>With reference to Fig. B.1, the transformation relations between the Cartesian
(x, y, z) and spherical (r ,Ï ,Ï) coordinates are
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>x = r sin Ï cosÏ
y = r sin Ï sin Ï
z = r cosÏ
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>r2 = x2 + y2 + z2
</p>
<p>cosÏ = z/r
tan Ï = y/x
</p>
<p>(B.1)
</p>
<p>that are a special case of (1.26). The limits of the spherical coordinates are 0 &le; r &lt;
&infin;, 0 &le; Ï &le; Ï , 0 &le; Ï &lt; 2Ï . The 3 &times; 3 matrix of the partial derivatives of the
Cartesian coordinates with respect to the spherical ones, expressed in terms of the
latter (Jacobian matrix), is
</p>
<p>&part;(x, y, z)
</p>
<p>&part;(r ,Ï ,Ï)
=
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>sin Ï cosÏ r cosÏ cosÏ &minus;r sin Ï sin Ï
sin Ï sin Ï r cosÏ sin Ï r sin Ï cosÏ
</p>
<p>cosÏ &minus;r sin Ï 0
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>, (B.2)
</p>
<p>where the left hand side is a short-hand notation for a matrix whose elements are
J11 = &part;x/&part;r , J12 = &part;x/&part;Ï , and so on. The Jacobian determinant is
</p>
<p>J = det &part;(x, y, z)
&part;(r ,Ï ,Ï)
</p>
<p>= r2 sin Ï. (B.3)
</p>
<p>The matrix of the partial derivatives of the spherical coordinates with respect to the
Cartesian ones, expressed in terms of the former, is
</p>
<p>&part;(r ,Ï ,Ï)
</p>
<p>&part;(x, y, z)
=
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>sin Ï cosÏ sin Ï sin Ï cosÏ
</p>
<p>(1/r) cosÏ cosÏ (1/r) cosÏ sin Ï &minus;(1/r) sin Ï
&minus;(1/r) sin Ï/ sin Ï (1/r) cosÏ/ sin Ï 0
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>,
</p>
<p>(B.4)
&copy; Springer Science+Business Media New York 2015 595
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6</p>
<p/>
</div>
<div class="page"><p/>
<p>596 Appendix B Coordinates
</p>
<p>Fig. B.1 Cartesian (x, y, z)
and spherical (r ,Ï ,Ï)
coordinates
</p>
<p>Î¸
</p>
<p>Ï
</p>
<p>x
</p>
<p>z
</p>
<p>y
</p>
<p>r
</p>
<p>whence
</p>
<p>det
&part;(r ,Ï ,Ï)
</p>
<p>&part;(x, y, z)
= 1
</p>
<p>r2 sin Ï
= 1
</p>
<p>J
. (B.5)
</p>
<p>To calculate (B.4) consider, e.g., the last term of the second row, (&part;Ï/&part;z)xy =
&minus;(1/r) sin Ï . The second line of the second group of (B.1) yields (&part; cosÏ/&part;z)xy =
1/r &minus; z2/r3, where (&part;r/&part;z)xy = z/r has been used, that in turn derives from
the first line of the second group of (B.1). The relation z = r cosÏ then yields
(&part; cosÏ/&part;z)xy = (1/r) sin2 Ï . On the other hand the same quantity can also be writ-
ten as (&part; cosÏ/&part;z)xy = &minus; sin Ï (&part;Ï/&part;z)xy . Comparing the two expressions above
yields the result sought.
</p>
<p>Differentiating with respect to time the first of (B.1) yields the relations
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>xÌ = rÌ sin Ï cosÏ + r ÏÌ cosÏ cosÏ &minus; r ÏÌ sin Ï sin Ï
yÌ = rÌ sin Ï sin Ï + r ÏÌ cosÏ sin Ï + r ÏÌ sin Ï cosÏ
zÌ = rÌ cosÏ &minus; r ÏÌ sin Ï
</p>
<p>(B.6)
</p>
<p>that express the components of the velocity in the Cartesian reference as functions of
the generalized coordinates r ,Ï ,Ï and generalized velocities rÌ , ÏÌ , ÏÌ of the spherical
reference. From (B.6) the expression of the kinetic energy in spherical coordinates
follows:
</p>
<p>T = 1
2
m (xÌ2 + yÌ2 + zÌ2) = 1
</p>
<p>2
m
</p>
<p>(
</p>
<p>rÌ2 + r2ÏÌ2 + r2ÏÌ2 sin2 Ï
)
</p>
<p>. (B.7)
</p>
<p>B.2 Polar Coordinates
</p>
<p>To describe the motion of particles confined over a plane one may adopt, instead of
the Cartesian coordinates x, y, the polar coordinates r ,Ï. The relations between the
two groups of coordinates are</p>
<p/>
</div>
<div class="page"><p/>
<p>B.3 Coordinate Rotation 597
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>x = r cosÏ
y = r sin Ï
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>r2 = x2 + y2
</p>
<p>tan Ï = y/x
(B.8)
</p>
<p>The limits of the polar coordinates are 0 &le; r &lt; &infin;, 0 &le; Ï &lt; 2Ï . The Jacobian
matrix and the Jacobian determinant are, respectively,
</p>
<p>&part;(x, y)
</p>
<p>&part;(r ,Ï)
=
</p>
<p>â¡
</p>
<p>â£
cosÏ &minus;r sin Ï
sin Ï r cosÏ
</p>
<p>â¤
</p>
<p>â¦ , J = det &part;(x, y)
&part;(r ,Ï)
</p>
<p>= r. (B.9)
</p>
<p>Differentiating with respect to time the first of (B.8) yields the relations
â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>xÌ = rÌ cosÏ &minus; r ÏÌ sin Ï
yÌ = rÌ sin Ï + r ÏÌ cosÏ
</p>
<p>(B.10)
</p>
<p>that express the components of the velocity in the Cartesian reference as functions of
the generalized coordinates r ,Ï and generalized velocities rÌ , ÏÌ of the polar reference.
From (B.10) the expression of the kinetic energy in polar coordinates follows:
</p>
<p>T = 1
2
m (xÌ2 + yÌ2) = 1
</p>
<p>2
m
</p>
<p>(
</p>
<p>rÌ2 + r2ÏÌ2
)
</p>
<p>. (B.11)
</p>
<p>B.3 Coordinate Rotation
</p>
<p>Consider a coordinate transformation that consists in a rotation around the origin,
bringing a right-handed system of coordinates x = (x1, x2, x3) into another right-
handed system s = (s1, s2, s3). The transformation is described by the linear relations
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>s1 = a11 x1 + a12 x2 + a13 x3
s2 = a21 x1 + a22 x2 + a23 x3
s3 = a31 x1 + a32 x2 + a33 x3
</p>
<p>(B.12)
</p>
<p>which can be recast in the matrix form s = Ax. It is known that a matrix describing
this type of transformation is orthogonal [42, Sect. 4.2], namely,
</p>
<p>3
&sum;
</p>
<p>i=1
aij aik = Î´jk , detA = 1, A&minus;1 = AT , j , k = 1, 2, 3, (B.13)
</p>
<p>where apex T indicates the transpose. From (B.13) it follows
(
</p>
<p>A&minus;1
)T = A. As a
</p>
<p>consequence, the effect of the rotation onto the modulus of a particle&rsquo;s velocity is
found from
</p>
<p>(
</p>
<p>xÌT , xÌ
)
</p>
<p>=
[
(
</p>
<p>A&minus;1 sÌ
)T
</p>
<p>, A&minus;1 sÌ
]
</p>
<p>=
(
</p>
<p>sÌT A, A&minus;1 sÌ
)
</p>
<p>=
(
</p>
<p>sÌT , A A&minus;1 sÌ
)
</p>
<p>=
(
</p>
<p>sÌT , sÌ
)
</p>
<p>.
</p>
<p>(B.14)</p>
<p/>
</div>
<div class="page"><p/>
<p>598 Appendix B Coordinates
</p>
<p>In (B.14) the symbol (aT , b) denotes the scalar product between the vectors a and
b, namely, it is equivalent to a &middot; b. The above calculation shows that u2 = (xÌT , xÌ) is
invariant under rotation of the coordinate system. The same reasoning applies to the
modulus of position r2 = (xT , x) = (sT , s).
</p>
<p>B.4 Differential Operators Under Coordinate Transformations
</p>
<p>Consider the coordinate transformation between the two sets xi , Î¾i , i = 1, 2, . . . , n:
</p>
<p>Î¾i = Î¾i(x1, . . . , xn), xi = xi(Î¾1, . . . , Î¾n). (B.15)
</p>
<p>If a function f is transformed using the above, the following hold:
</p>
<p>&part;f
</p>
<p>&part;xi
=
</p>
<p>n
&sum;
</p>
<p>j=1
</p>
<p>&part;f
</p>
<p>&part;Î¾j
</p>
<p>&part;Î¾j
</p>
<p>&part;xi
,
</p>
<p>&part;2f
</p>
<p>&part;x2i
=
</p>
<p>n
&sum;
</p>
<p>j=1
</p>
<p>(
</p>
<p>&part;f
</p>
<p>&part;Î¾j
</p>
<p>&part;2Î¾j
</p>
<p>&part;x2i
+
</p>
<p>n
&sum;
</p>
<p>k=1
</p>
<p>&part;2f
</p>
<p>&part;Î¾j&part;Î¾k
</p>
<p>&part;Î¾j
</p>
<p>&part;xi
</p>
<p>&part;Î¾k
</p>
<p>&part;xi
</p>
<p>)
</p>
<p>. (B.16)
</p>
<p>Adding up over i in the second of (B.16) yields
</p>
<p>&nabla;2f =
n
</p>
<p>&sum;
</p>
<p>j=1
</p>
<p>(
</p>
<p>&part;f
</p>
<p>&part;Î¾j
&nabla;2Î¾j +
</p>
<p>n
&sum;
</p>
<p>k=1
</p>
<p>&part;2f
</p>
<p>&part;Î¾j&part;Î¾k
&nabla;Î¾j &middot; &nabla;Î¾k
</p>
<p>)
</p>
<p>, (B.17)
</p>
<p>where symbols&nabla; and&nabla;2 indicate, respectively, the gradient and the Laplacian opera-
tor with respect to the coordinates xi . By way of example consider the transformation
(B.1) from Cartesian to spherical coordinates. Remembering (B.4) one finds
</p>
<p>&nabla;r &middot; &nabla;r = 1, &nabla;Ï &middot; &nabla;Ï = 1
r2
</p>
<p>, &nabla;Ï &middot; &nabla;Ï = 1
r2 sin2 Ï
</p>
<p>, (B.18)
</p>
<p>&nabla;r &middot; &nabla;Ï = 0, &nabla;Ï &middot; &nabla;Ï = 0, &nabla;Ï &middot; &nabla;r = 0, (B.19)
</p>
<p>whence
</p>
<p>&nabla;2f = &part;f
&part;r
</p>
<p>&nabla;2r + &part;
2f
</p>
<p>&part;r2
+ &part;f
</p>
<p>&part;Ï
&nabla;2Ï + &part;
</p>
<p>2f
</p>
<p>&part;Ï2
</p>
<p>1
</p>
<p>r2
+ &part;f
</p>
<p>&part;Ï
&nabla;2Ï + &part;
</p>
<p>2f
</p>
<p>&part;Ï2
</p>
<p>1
</p>
<p>r2 sin2 Ï
.
</p>
<p>(B.20)
</p>
<p>In turn, letting Î³
.= sin Ï cosÏ/r , Î¶ .= sin Ï cosÏ/r , Ï .= sin2 Ï , the terms &nabla;2r ,
</p>
<p>&nabla;2Ï , &nabla;2Ï are found from
â¡
</p>
<p>â¢
â¢
â£
</p>
<p>&part;2r/&part;x2 &part;2r/&part;y2 &part;2r/&part;z2
</p>
<p>&part;2Ï/&part;x2 &part;2Ï/&part;y2 &part;2Ï/&part;z2
</p>
<p>&part;2Ï/&part;x2 &part;2Ï/&part;y2 &part;2Ï/&part;z2
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>= 1
r
&times; (B.21)</p>
<p/>
</div>
<div class="page"><p/>
<p>B.5 Density of States 599
</p>
<p>&times;
</p>
<p>â¡
</p>
<p>â¢
â¢
â£
</p>
<p>1 &minus; Ï cos2 Ï 1 &minus; Ï sin2 Ï Ï
Î³ ( sin2 Ï/Ï &minus; 2 cos2 Ï) Î³ ( cos2 Ï/Ï &minus; 2 sin2 Ï) 2Î³
</p>
<p>2Î¶/Ï &minus;2Î¶/Ï 0
</p>
<p>â¤
</p>
<p>â¥
â¥
â¦
</p>
<p>, (B.22)
</p>
<p>whence
</p>
<p>&nabla;2r = 2
r
</p>
<p>, &nabla;2Ï = 1
r2
</p>
<p>cos Î¸
</p>
<p>sin Î¸
, &nabla;2Ï = 0, (B.23)
</p>
<p>&nabla;2f = &part;f
&part;r
</p>
<p>2
</p>
<p>r
+ &part;
</p>
<p>2f
</p>
<p>&part;r2
+ &part;f
</p>
<p>&part;Ï
</p>
<p>1
</p>
<p>r2
</p>
<p>cos Î¸
</p>
<p>sin Î¸
+ &part;
</p>
<p>2f
</p>
<p>&part;Ï2
</p>
<p>1
</p>
<p>r2
+ &part;
</p>
<p>2f
</p>
<p>&part;Ï2
</p>
<p>1
</p>
<p>r2 sin2 Ï
= (B.24)
</p>
<p>= 1
r
</p>
<p>&part;2
</p>
<p>&part;r2
(rf ) + 1
</p>
<p>r2 sin Ï
</p>
<p>&part;
</p>
<p>&part;Ï
</p>
<p>(
</p>
<p>sin Ï
&part;f
</p>
<p>&part;Ï
</p>
<p>)
</p>
<p>+ 1
r2 sin2 Ï
</p>
<p>&part;2f
</p>
<p>&part;Ï2
. (B.25)
</p>
<p>B.5 Density of States
</p>
<p>Consider a function s that depends on the coordinates u, v, w, and on one or more
additional parameters that will collectively be indicated with Ï . Let
</p>
<p>S(Ï ) =
&int;&int;&int;
</p>
<p>s(u, v, w, Ï ) du dv dw, (B.26)
</p>
<p>where the integration is carried out over the whole domain of u, v, w. Next, consider
the transformation from the original variables to the new variables Î±, Î², Î·,
</p>
<p>Î± = Î±(u, v, w), Î² = Î²(u, v, w), Î· = Î·(u, v, w), J = &part;(u, v, w)
&part;(Î±,Î², Î·)
</p>
<p>, (B.27)
</p>
<p>which is assumed to be invertible, so that the Jacobian determinant J does not vanish.
After the transformation is carried out, (B.26) takes the form
</p>
<p>S(Ï ) =
&int;&int;&int;
</p>
<p>s(Î±,Î², Î·, Ï ) |J | dÎ± dÎ² dÎ·. (B.28)
</p>
<p>It may happen that one is interested in the dependence of s on one of the new
variables, say, Î·, rather than in the details about its dependence on the whole set of
new variables. In this case one first carries out the integrals with respect to Î± and Î²
in (B.28), to find
</p>
<p>h(Î·, Ï ) =
&int;&int;
</p>
<p>s(Î±,Î², Î·, Ï ) |J | dÎ± dÎ². (B.29)
</p>
<p>Then one defines
</p>
<p>b(Î·) =
&int;&int;
</p>
<p>|J | dÎ± dÎ². (B.30)</p>
<p/>
</div>
<div class="page"><p/>
<p>600 Appendix B Coordinates
</p>
<p>A function like b(Î·) plays an important role in many physical problems (e.g.,
Sects. 14.6, 15.8.1, 15.8.2). For this reason, although its derivation in this section
is of a purely formal nature, b(Î·) will be called density of states in Î·. Note that the
density of states depends only on the structure of the variable transformation (B.27)
and (at most) on Î·. The form of (B.29) and (B.30) shows that the ratio sÌ = h/b is
a weighed average of s(Î±,Î², Î·, Ï ) over the two variables Î± and Î², that uses |J | as
weight. Introducing the definition of sÌ into (B.28) gives the latter the form
</p>
<p>S(Ï ) =
&int;
</p>
<p>b(Î·) sÌ(Î·, Ï ) dÎ·. (B.31)
</p>
<p>If s happens to be independent of Î± and Î², definition (B.29) yields h = s b, whence
sÌ(Î·, Ï ) = s(Î·, Ï ). The derivation of b is not limited to a three-dimensional case; in
fact it applies to any number of dimensions. In the following, a few examples in one,
two, and three dimensions are given, in which one of the transformation relations
(B.27), namely, Î· = Î·(u, v, w), has a quadratic form; these examples are in fact
particularly significant for the physical applications, where Î· stands for the energy
and u, v, w stand for the generalized coordinates.
</p>
<p>Considering a one-dimensional case with Î· = u2, one finds3
</p>
<p>u = &plusmn;Î·1/2, |J | =
â£
â£
â£
â£
</p>
<p>&part;u
</p>
<p>&part;Î·
</p>
<p>â£
â£
â£
â£
= 1
</p>
<p>2
Î·&minus;1/2, b(Î·) = 2 1
</p>
<p>2
Î·&minus;1/2 = Î·&minus;1/2. (B.32)
</p>
<p>This case is straightforward because there are no other variables involved in the
transformation. Instead, in the two-dimensional case with Î· = u2 + v2, a convenient
transformation involving the second variable is of the polar type (B.8), specifically,
u = Î·1/2 cosÏ, v = Î·1/2 sin Ï. One finds
</p>
<p>|J | = 1
2
</p>
<p>, b(Î·) =
&int; 2Ï
</p>
<p>0
</p>
<p>1
</p>
<p>2
dÏ = Ï. (B.33)
</p>
<p>In the three-dimensional case with Î· = u2 + v2 + w2, a convenient transformation
involving the other two variables is of the spherical type (B.1), specifically, u =
Î·1/2 sin Ï cosÏ, v = Î·1/2 sin Ï sin Ï, w = Î·1/2 cosÏ . One finds
</p>
<p>|J | = 1
2
Î·1/2 sin Ï , b(Î·) =
</p>
<p>&int; 2Ï
</p>
<p>0
</p>
<p>&int; Ï
</p>
<p>0
</p>
<p>1
</p>
<p>2
Î·1/2 sin Ï dÏ dÏ = 2Ï Î·1/2. (B.34)
</p>
<p>The above examples show that, despite the fact that the Î· = Î·(u, v, w) relation is
quadratic in all cases, the form of b(Î·) changes depending on the number of spatial
dimensions.
</p>
<p>Still considering the case where one of the transformation relations (B.27) has
a quadratic form, the analysis can be extended to arbitrary values of the number
</p>
<p>3 Factor 2 in the last expression of (B.32) accounts for the fact that both positive and negative parts
of the segment [&minus; Î·1/2,+Î·1/2] must be considered.</p>
<p/>
</div>
<div class="page"><p/>
<p>B.5 Density of States 601
</p>
<p>of spatial dimensions. As a starting point, and considering provisionally the three-
dimensional case, one notes from (B.30) that the following equality holds:4
</p>
<p>B =
&int;
</p>
<p>b(Î·) dÎ· =
&int;&int;&int;
</p>
<p>|J | dÎ± dÎ² dÎ· =
&int;&int;&int;
</p>
<p>du dv dw. (B.35)
</p>
<p>Remembering the definition of b, it follows that B is the number of states in the
domain of u, v, w. Due to the last integral in (B.34), B is also equal to the volume of
such a domain; in turn, due to the first integral, B can be thought of as the sum of the
volumes of elementary shells of thickness dÎ·, with b(Î·) the area of each shell (that is,
the area of the two-dimensional surface Î· = const). These observations provide the
key to extending the analysis to the case where Î· is a quadratic form in an arbitrary
number of dimensions,
</p>
<p>u21 + u22 + . . .+ u2n = Î·, Î· = g2. (B.36)
</p>
<p>Letting Î· = const, (B.36) is the equation of an (n&minus; 1)-dimensional sphere of radius
g &ge; 0 immersed into the n-dimensional space. The problem is thus reduced to
expressing the area of the sphere in terms of Î·; although it can be solved by using a
generalization of the spherical coordinates to n dimensions, a more elegant approach
consists in finding a recursive expression involving also the sphere&rsquo;s volume.
</p>
<p>To this purpose, let Vn indicate the volume of a sphere of an n-dimensional space,
and let Sn&minus;1 indicate the surface area of the same sphere. When n = 1, the sphere
is a segment whose volume is the length V1 = 2g; for n = 2, the sphere is a circle
whose volume is the area V2 = Ï g2; for n = 3 it is V3 = (4/3)Ï g3; for n = 4
it is V4 = Ï2 g4/2, and so on; in turn, for n = 2 the surface is a circumference
whose area is the length S1 = 2Ï g; for n = 3 it is S2 = 4Ï g2; for n = 4 it is
S3 = 2Ï2 g3, and so on. Consistently with the expression of B as the integral of b
given by (B.35), one finds from the above values the general relation
</p>
<p>Vn =
g
</p>
<p>n
Sn&minus;1. (B.37)
</p>
<p>Combining (B.37) with V1 = 2g also yields S0 = 2, that is, the &ldquo;surface&rdquo; of
the segment considered above; such a surface is made of the segment&rsquo;s endpoints
{&minus;1,+1}. From (B.37) it also follows that Vn &prop; gn and Sn&minus;1 &prop; gn&minus;1, whence
Sn &prop; g Vn&minus;1 and V0 = const. From the values found above one finds S2/(g V1) =
S3/(g V2) = 2Ï ; it follows that Sn = 2Ï g Vn&minus;1 and V0 = 1. The latter is the
&ldquo;volume&rdquo; of a sphere in a zero-dimensional space. The recursive relation involving
the volumes then reads
</p>
<p>Vn =
g
</p>
<p>n
Sn&minus;1 =
</p>
<p>g
</p>
<p>n
2Ï g Vn&minus;2 =
</p>
<p>2Ï g2
</p>
<p>n
Vn&minus;2, V0 = 1, V1 = 2g. (B.38)
</p>
<p>4 In the practical applications of the concepts illustrated here, the integrands in (B.35) embed a
constant factor Q0, called density of states in the u, v, w space which, besides describing some
properties of the physical problem under investigation, makes B dimensionless. Here, all variables
involved are dimensionless, and Q0 is set equal to unity.</p>
<p/>
</div>
<div class="page"><p/>
<p>602 Appendix B Coordinates
</p>
<p>The above can further by improved by observing that the sequenceV0, V1, . . . embeds
Euler&rsquo;s Gamma function of half-integer order; in fact, combining (B.37) and (B.38)
with the definitions of Sect. C.10, yields
</p>
<p>Vn =
Ïn/2
</p>
<p>Î (n/2 + 1) g
n, Sn&minus;1 =
</p>
<p>nÏn/2
</p>
<p>Î (n/2 + 1) g
n&minus;1. (B.39)
</p>
<p>The last step consists in expressing the result in terms of Î·. This is accomplished
by noting that b(Î·) dÎ· = Sn&minus;1(g) dg, where g = &radic;Î· and dg = d&radic;Î· = dÎ·/(2&radic;Î·);
then, one finds
</p>
<p>b(Î·) dÎ· = nÏ
n/2Î·(n&minus;1)/2
</p>
<p>Î (n/2 + 1)
dÎ·
</p>
<p>2Î·1/2
, b(Î·) = nÏ
</p>
<p>n/2
</p>
<p>2Î (n/2 + 1) Î·
n/2&minus;1. (B.40)
</p>
<p>Letting n = 1, 2, 3 in the second expression of (B.40) renders (B.32), (B.33), (B.34),
respectively.</p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix C
Special Integrals
</p>
<p>C.1 Sine Integral
</p>
<p>Define the two functions
</p>
<p>si(t) = &minus;Ï
2
+
</p>
<p>&int; t
</p>
<p>0
</p>
<p>sin x
</p>
<p>x
dx, N (a) =
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>sin (ax)
</p>
<p>x
dx. (C.1)
</p>
<p>The first of them is called sine integral and fulfills the limit limt&rarr;&infin; si = 0, whence
N (1) = Ï/2. To demonstrate the above one starts from the functions
</p>
<p>F (y) =
&int; &infin;
</p>
<p>0
exp (&minus;x) sin (xy)
</p>
<p>x
dx, G(y) =
</p>
<p>&int; &infin;
</p>
<p>0
exp (&minus;xy) sin x
</p>
<p>x
dx, y &ge; 0.
</p>
<p>(C.2)
</p>
<p>The following hold true: F (0) = 0, G(0) = N (1), F (1) = G(1), and
</p>
<p>dF
</p>
<p>dy
=
</p>
<p>&int; &infin;
</p>
<p>0
exp (&minus;x) cos (xy) dx, dG
</p>
<p>dy
=
</p>
<p>&int; &infin;
</p>
<p>0
exp (&minus;xy) sin x dx. (C.3)
</p>
<p>Integrating (C.3) by parts twice yields dF/dy = 1/(1+ y2), dG/dy = &minus;1/(1+ y2)
whence
</p>
<p>F (y) = arctan y + F (0), G(y) = &minus; arctan y +G(0), 0 &le; y &lt; Ï
2
. (C.4)
</p>
<p>It followsF (1) = F (0)+Ï/4 = Ï/4 andF (1) = G(1) = G(0)&minus;Ï/4 = N (1)&minus;Ï/4.
Combining the above yields the result sought. This implicitly proves the convergence
of the integrals in (C.1). The calculation of the second of (C.1) is now straightforward
and yields
</p>
<p>N (a) =
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>&minus;Ï/2, a &lt; 0,
0, a = 0,
</p>
<p>+Ï/2, a &gt; 0.
(C.5)
</p>
<p>&copy; Springer Science+Business Media New York 2015 603
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6</p>
<p/>
</div>
<div class="page"><p/>
<p>604 Appendix C Special Integrals
</p>
<p>The integrand in the second of (C.1) is even with respect to x. It follows that an
integration carried out from &minus;&infin; to +&infin; yields 2N (a). Basing on this one also finds
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>exp (i ax)
</p>
<p>i x
dx = 2N (a) +
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>cos (ax)
</p>
<p>i x
dx = 2N (a). (C.6)
</p>
<p>When calculating the second integral in (C.6) one must let z = &plusmn;ax, Ç«,Z &gt; 0 and
use the principal part. In fact, observing that the integrand is odd one obtains
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>cos (ax)
</p>
<p>i x
dx = &plusmn;i lim
</p>
<p>Ç«&rarr;0
Z&rarr;&infin;
</p>
<p>(&int; &minus;Ç«
</p>
<p>&minus;Z
</p>
<p>cos z
</p>
<p>z
dz +
</p>
<p>&int; +Z
</p>
<p>+Ç«
</p>
<p>cos z
</p>
<p>z
dz
</p>
<p>)
</p>
<p>= 0. (C.7)
</p>
<p>Combining (C.7) with (C.6) provides an integral representation of the Fourier type
for the step function
</p>
<p>H (a) =
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>0 a &lt; 0
</p>
<p>1/2 a = 0
1 a &gt; 0
</p>
<p>â«
</p>
<p>âª
âª
â¬
</p>
<p>âª
âª
â­
</p>
<p>= 1
2
+ 1
</p>
<p>2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>exp (iax)
</p>
<p>ix
dx. (C.8)
</p>
<p>Still from (C.6), using the identity 2 i sin x = exp (i x) &minus; exp (&minus;i x), one finds
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>sin x
</p>
<p>x
exp ( &minus; i a x) dx = N (&minus;a + 1) &minus;N (&minus;a &minus; 1) =
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>0 |a| &gt; 1
Ï/2 a = &plusmn;1
Ï |a| &lt; 1
</p>
<p>(C.9)
</p>
<p>From (C.9) one derives integrals of a similar form, where sin x/x is replaced with
sinn x/xn, n = 2, 3, . . . . The example with n = 2 is given below: one starts from
</p>
<p>d
</p>
<p>da
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>sin2 x
</p>
<p>x2
exp ( &minus; i a x) dx =
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>sin2 x
</p>
<p>i x
exp ( &minus; i a x) dx, (C.10)
</p>
<p>and uses the identity 2 sin2 x = 1 &minus; cos (2 x) to find
&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>1 &minus; cos (2 x)
2 i x
</p>
<p>exp ( &minus; i a x) dx = N (&minus;a) +
&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>cos (2 x)
</p>
<p>2 x
sin (a x) dx,
</p>
<p>(C.11)
</p>
<p>whereN (&minus;a) derives from (C.6) and the integral on the right hand side is obtained by
eliminating the odd part of the integrand. From the identity sin [(a+2) x]+ sin [(a&minus;
2) x] = 2 sin (a x) cos (2 x) such an integral transforms into
&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>sin [(a + 2) x] + sin [(a &minus; 2) x]
4 x
</p>
<p>dx = 1
2
N (a + 2) + 1
</p>
<p>2
N (a &minus; 2), (C.12)</p>
<p/>
</div>
<div class="page"><p/>
<p>C.2 Fourier Transform 605
</p>
<p>where the second definition in (C.1) has been used. Combining (C.10), (C.11), and
(C.12) yields
</p>
<p>d
</p>
<p>da
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>sin2 x
</p>
<p>x2
exp ( &minus; i a x) dx =
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>Ï/2 &minus;2 &lt; a &lt; 0
&minus;Ï/2 0 &lt; a &lt; 2
</p>
<p>0 |a| &gt; 2
(C.13)
</p>
<p>This result shows that the derivative with respect to a of the integral sought is
piecewise constant in the interval &minus;2 &lt; a &lt; +2, and vanishes elsewhere.
The integral is also continuous with respect to a and does not diverge, because
| sin2 x/x2| &le; | sin x/x| and (C.9) converges. This reasoning allows one to fix the
integration constants, to finally obtain
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>sin2 x
</p>
<p>x2
exp ( &minus; i a x) dx =
</p>
<p>â§
</p>
<p>âª
âª
â¨
</p>
<p>âª
âª
â©
</p>
<p>(Ï/2) (a + 2) &minus;2 &lt; a &lt; 0
&minus;(Ï/2) (a &minus; 2) 0 &lt; a &lt; 2
</p>
<p>0 |a| &gt; 2
(C.14)
</p>
<p>By a procedure similar to that used to prove (C.14) one finds
</p>
<p>d
</p>
<p>da
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>sin2 (ax)
</p>
<p>x2
dx = 2N (a),
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>sin2 (ax)
</p>
<p>x2
dx =
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>Ï a, a &gt; 0
</p>
<p>&minus;Ï a, a &lt; 0
(C.15)
</p>
<p>C.2 Fourier Transform
</p>
<p>Let f (x) be a function defined over the entire x axis. Its Fourier transform is defined
as the integral
</p>
<p>G(k) = Fxf =
1&radic;
2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
f (x) exp ( &minus; i k x) dx. (C.16)
</p>
<p>In turn, the Fourier antitransform is defined as
</p>
<p>f (x) = F&minus;1x G =
1&radic;
2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
G(k) exp (i k x) dk. (C.17)
</p>
<p>Combining (C.16) and (C.17) provides a representation of f in the form
</p>
<p>f (x) = 1
2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
exp (i k x)
</p>
<p>[&int; +&infin;
</p>
<p>&minus;&infin;
f (Î¾ ) exp ( &minus; i k Î¾ ) dÎ¾
</p>
<p>]
</p>
<p>dk. (C.18)
</p>
<p>A sufficient condition for the representation (C.18) is
&int; +&infin;
</p>
<p>&minus;&infin;
|f (x)| dx &lt; &infin;. (C.19)</p>
<p/>
</div>
<div class="page"><p/>
<p>606 Appendix C Special Integrals
</p>
<p>If f is discontinuous of the first kind at some point x0, the left hand side of (C.18)
must be replaced with [f (x+0 ) + f (x&minus;0 )]/2. As the condition (C.19) is sufficient, but
not necessary, there are functions that admit an integral representation like (C.18)
without fulfilling (C.19). An important example is the unit step function shown in
Sect. C.1.
</p>
<p>If f depends also on one or more parameters, f = f (x, u, v, . . . ), then it is G =
G(k, u, v, . . . ). In an n-dimensional space, defining the vectors x = (x1, . . . , xn) and
k = (k1, . . . , kn), the Fourier transform reads
</p>
<p>G(k) = Fxf =
1
</p>
<p>(2Ï )n/2
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
. . .
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
f (x) exp ( &minus; i k &middot; x) dx1 . . . dxn. (C.20)
</p>
<p>A useful relation is found by differentiating both sides of (C.17). To this purpose,
one must assume that the conditions for exchanging the derivative with the integral
are fulfilled. It is found
</p>
<p>df
</p>
<p>dx
= 1&radic;
</p>
<p>2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
i k G(k) exp (ikx) dk. (C.21)
</p>
<p>Iterating the procedure yields
</p>
<p>dnf
</p>
<p>dxn
= 1&radic;
</p>
<p>2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
(i k)n G(k) exp (ikx) dk, (C.22)
</p>
<p>showing that, if G(k) is the Fourier transform of f (x), then the Fourier transform of
dnf/dxx is (i k)n G(k). Relations like (C.21) and (C.22) are useful, for instance, in
the solution of linear differential equations with constant coefficients, because they
turn differential relations into polynomial relations (compare with the solution of the
diffusion equation carried out in Sect. 23.4).
</p>
<p>C.3 Gauss Integral
</p>
<p>The relation
</p>
<p>IG =
&int; +&infin;
</p>
<p>0
exp (&minus;x2) dx =
</p>
<p>&int; 0
</p>
<p>&minus;&infin;
exp (&minus;x2) dx. (C.23)
</p>
<p>is called Gauss integral or Poisson integral. To calculate its value one may start from
the double integral
</p>
<p>F (R) =
&int; &int;
</p>
<p>Î£(R)
exp [&minus;(x2 + y2)] dxdy, (C.24)
</p>
<p>whereÎ£(R) is a circle of radiusR centered on the origin. Using the polar coordinates
(B.8) yields
</p>
<p>F (R) =
&int; 2Ï
</p>
<p>0
dÏ
</p>
<p>&int; R
</p>
<p>0
exp ( &minus; Ï2) Ï dÏ = Ï [1 &minus; exp ( &minus; R2)], (C.25)</p>
<p/>
</div>
<div class="page"><p/>
<p>C.3 Gauss Integral 607
</p>
<p>whence limR&rarr;&infin; F (R) = Ï . On the other hand, due to (C.24) it is also
</p>
<p>lim
R&rarr;&infin;
</p>
<p>F (R) =
&int;&int; +&infin;
</p>
<p>&minus;&infin;
exp [&minus;(x2 + y2)] dxdy = lim
</p>
<p>a&rarr;&infin;
</p>
<p>(&int; +a
</p>
<p>&minus;a
exp ( &minus; x2) dx
</p>
<p>)2
</p>
<p>.
</p>
<p>(C.26)
</p>
<p>Combining (C.25, C.26) with (C.23) provides
&int; +&infin;
</p>
<p>&minus;&infin;
exp ( &minus; x2) dx = &radic;Ï , IG =
</p>
<p>&radic;
Ï
</p>
<p>2
. (C.27)
</p>
<p>From (C.27) it follows that for any Î» &gt; 0 it is
</p>
<p>I0(Î») =
&int; &infin;
</p>
<p>0
exp ( &minus; Î»x2) dx = 1
</p>
<p>2
</p>
<p>&radic;
</p>
<p>Ï
</p>
<p>Î»
. (C.28)
</p>
<p>Another integral generated by exp ( &minus; Î»x2) is
</p>
<p>I1(Î») =
&int; &infin;
</p>
<p>0
x exp ( &minus; Î»x2) dx = 1
</p>
<p>2Î»
. (C.29)
</p>
<p>Thanks to (C.28) and (C.29) it is possible to calculate all integrals of the form
</p>
<p>In(Î») =
&int; &infin;
</p>
<p>0
xn exp ( &minus; Î»x2) dx, n &ge; 0. (C.30)
</p>
<p>In fact, using the recursive relation
</p>
<p>d
</p>
<p>dÎ»
In =
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>&part;
</p>
<p>&part;Î»
xn exp ( &minus; Î»x2) dx = &minus;
</p>
<p>&int; &infin;
</p>
<p>0
xn+2 exp ( &minus; Î»x2) dx = &minus;In+2,
</p>
<p>(C.31)
</p>
<p>in combination with (C.29) yields all the integrals whose index is odd,
</p>
<p>I2m+1 =
m!
2
</p>
<p>Î»&minus;(m+1), m = 0, 1, 2, . . . . (C.32)
</p>
<p>Similarly, combining (C.31) with (C.28) yields all the integrals whose index is even,
</p>
<p>I2m(Î») =
(2m&minus; 1)!!
</p>
<p>2m+1
Î»&minus;(m+1/2)
</p>
<p>&radic;
Ï , m = 0, 1, 2, . . . , (C.33)
</p>
<p>where
</p>
<p>(2m&minus; 1)!! = (2m&minus; 1)(2m&minus; 3) . . . 3 &middot; 1, (&minus;1)!! = 1, (C.34)
Finally, observing that the integrand of (C.30) is even (odd) if n is even (odd), one
finds
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
x2m exp ( &minus; Î»x2) dx = 2 I2m(Î»),
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
x2m+1 exp ( &minus; Î»x2) dx = 0.
</p>
<p>(C.35)
</p>
<p>The results of this section still hold for a complex Î» with &real;Î» &gt; 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>608 Appendix C Special Integrals
</p>
<p>Fig. C.1 Generation of a
Dirac Î´ using a barrier-like
function. The width of the
peak is equal to a
</p>
<p>-4.0 -2.0 0.0 2.0 4.0
</p>
<p>x
</p>
<p>0.0
</p>
<p>1.0
</p>
<p>2.0
</p>
<p>Î
B
 (
</p>
<p> x
, 
a
 )
</p>
<p>-4.0 -2.0 0.0 2.0 4.0
0.0
</p>
<p>2.0
</p>
<p>C.4 Dirac&rsquo;s Î´
</p>
<p>Consider a function ÎB(x, a) defined as follows:
</p>
<p>ÎB =
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>1/a &minus;a/2 &le; x &le; +a/2
0 x &lt; &minus;a/2, x &gt; a/2
</p>
<p>(C.36)
</p>
<p>with a &gt; 0.
The above definition yields
</p>
<p>lim
a&rarr;0
</p>
<p>ÎB =
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>0 x ï¿½= 0
+&infin; x = 0
</p>
<p>,
&int; +&infin;
</p>
<p>&minus;&infin;
ÎB(x, a) dx =
</p>
<p>1
</p>
<p>a
</p>
<p>&int; +a/2
</p>
<p>&minus;a/2
dx = 1.
</p>
<p>(C.37)
</p>
<p>As the value of the integral in (C.37) is independent of a, the integral is equal to unity
also in the limit a &rarr; 0. Figure C.1 shows how the form of ÎB changes with a: the
width of the peak decreases as a decreases, while its height increases so that the area
subtending the function remains constant. Note that the procedure depicted above
gives a different result if one carries out the integration after calculating the limit.
In other terms, the integration and the limit are to be carried out in a specific order
(integration first). For a continuous function f (x) the mean-value theorem provides
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
ÎB(x, a) f (x) dx =
</p>
<p>1
</p>
<p>a
</p>
<p>&int; +a/2
</p>
<p>&minus;a/2
f (x) dx = f (xÌ), (C.38)
</p>
<p>with &minus;a/2 &lt; xÌ &lt; +a/2. As a consequence,
</p>
<p>lim
a&rarr;0
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
ÎB(x, a) f (x) dx = f (0). (C.39)</p>
<p/>
</div>
<div class="page"><p/>
<p>C.4 Dirac&rsquo;s Î´ 609
</p>
<p>This result is expressed in a more compact form by defining a linear functional Î´(x)
(called Dirac&rsquo;s symbol) such that
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
Î´(x) f (x) dx = f (0). (C.40)
</p>
<p>The functional associates the number f (0) to the function f (x). If the reasoning
leading to (C.40) is repeated after shifting ÎB from the origin to another point x0,
one finds the generalization of (C.40)
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
Î´(x &minus; x0) f (x) dx = f (x0). (C.41)
</p>
<p>From (C.41) and (C.16) one obtains
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
Î´(x &minus; x0) dx = 1, FxÎ´(x &minus; x0) =
</p>
<p>1&radic;
2Ï
</p>
<p>exp ( &minus; i k x0). (C.42)
</p>
<p>The antitransform (C.17) then reads
</p>
<p>Î´(x &minus; x0) =
1
</p>
<p>2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
exp [i k (x &minus; x0)] dk, (C.43)
</p>
<p>that provides an integral representation of the Dirac Î´. However, it is important to
note that (C.43) has no meaning unless it is used within an integral like, e.g., (C.41).
With this provision, one can consider the Dirac Î´ as the &ldquo;derivative&rdquo; of the step
function; in fact, after a suitable change in the symbols, one finds that the integral at
the right hand side of (C.43) is the derivative with respect to x of the integral at the
right hand side of (C.8). More details about the integral representation of the Dirac
Î´ are given in Sect. C.5.
</p>
<p>The function ÎB(x, a) defined above is an example of generating function of the
Dirac Î´. Several other examples may be given, as shown below. In all cases, if the
generating function Î(x, x0, a) is centered at some point x0, it is even with respect to
x0 and has the properties lima&rarr;0 Î = 0 if x ï¿½= x0 and lima&rarr;0 Î = +&infin; if x = x0.
Consider for instance the Lorentzian function (centered at x0 = 0)
</p>
<p>ÎL =
a/Ï
</p>
<p>a2 + x2 ,
&int; +&infin;
</p>
<p>&minus;&infin;
ÎL dx =
</p>
<p>1
</p>
<p>Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>d
</p>
<p>dx
arctan
</p>
<p>(x
</p>
<p>a
</p>
<p>)
</p>
<p>dx = 1, (C.44)
</p>
<p>with a &gt; 0. Apart from the limiting case a &rarr; 0 the function has only one maximum
that occurs at x = 0 and equals 1/(aÏ ). For x = &plusmn;a the function&rsquo;s value halves
with respect to the maximum, so 2a is conventionally taken as the width of ÎL. The
product 2/Ï of the maximum value by the conventional width is independent of a
and is of order unity. Finally, for a continuous function f (x) it is
</p>
<p>lim
a&rarr;0
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
ÎL(x, a)f (x) dx = f (0). (C.45)</p>
<p/>
</div>
<div class="page"><p/>
<p>610 Appendix C Special Integrals
</p>
<p>Another example of a Î´-generating function is the parameterized Gaussian function
(centered at x0 = 0)
</p>
<p>ÎG =
exp (&minus;x2/a2)
</p>
<p>a
&radic;
Ï
</p>
<p>, a &gt; 0,
&int; +&infin;
</p>
<p>&minus;&infin;
ÎG(x, a) dx = 1 (C.46)
</p>
<p>(more details about this function and integrals related to it are given in Sects. C.3 and
C.8). The function has only one maximum that occurs at x = 0 and equals 1/(a&radic;Ï ).
For x = &plusmn;a&radic;log 2 â &plusmn;0.833 a the function&rsquo;s value halves with respect to the
maximum, this yielding a conventional width of 2a
</p>
<p>&radic;
log 2. The product 2
</p>
<p>&radic;
log 2/
</p>
<p>&radic;
Ï
</p>
<p>of the maximum value by the conventional width is independent of a and of order
unity. For a continuous function f (x) it is
</p>
<p>lim
a&rarr;0
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
ÎG(x, a)f (x) dx = f (0). (C.47)
</p>
<p>A final example of a Î´-generating function is the negative derivative of the Fermi-
Dirac statistics (centered at x0 = 0)
</p>
<p>ÎF = &minus;
d
</p>
<p>dx
</p>
<p>1
</p>
<p>exp (x/a) + 1 =
exp (x/a)
</p>
<p>a
[
</p>
<p>exp (x/a) + 1
]2 , a &gt; 0, (C.48)
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
ÎF (x, a) dx =
</p>
<p>&int; &minus;&infin;
</p>
<p>+&infin;
</p>
<p>d
</p>
<p>dx
</p>
<p>1
</p>
<p>exp (x/a) + 1 dx = 1. (C.49)
</p>
<p>(more details about this function and integrals related to it are given in Sect. C.13).
The function has only one maximum that occurs at x = 0 and equals 1/(4a). For x =
&plusmn;a log (3+
</p>
<p>&radic;
8) â &plusmn;1.76 a the function&rsquo;s value halves with respect to the maximum,
</p>
<p>this yielding a conventional width of 2a log (3+
&radic;
</p>
<p>8). The product (1/2) log (3+
&radic;
</p>
<p>8)
of the maximum value by the conventional width is independent of a and of order
unity. For a continuous function f (x) it is
</p>
<p>lim
a&rarr;0
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
ÎF (x, a)f (x) dx = f (0). (C.50)
</p>
<p>The Î´-generating functions Î vanish for x &rarr; &plusmn;&infin;, otherwise they would not be
integrable from &minus;&infin; to +&infin;. Assuming that Î is differentiable with respect to x
yields, after integrating by parts,
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
f (x)
</p>
<p>dÎ(x, a)
</p>
<p>dx
dx = [Î(x, a) f (x)]+&infin;&minus;&infin; &minus;
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
Î(x, a)
</p>
<p>df
</p>
<p>dx
dx, (C.51)
</p>
<p>with f a differentiable function. In (C.51) the integrated part is zero because Î
vanishes at infinity. Taking the limit a &rarr; 0 at both sides of (C.51) and using (C.40)
yields
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
f (x)
</p>
<p>dÎ´(x)
</p>
<p>dx
dx = &minus;
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
Î´(x)
</p>
<p>df
</p>
<p>dx
dx = &minus;f &prime;(0), (C.52)</p>
<p/>
</div>
<div class="page"><p/>
<p>C.5 Some Properties of Dirac&rsquo;s Î´ 611
</p>
<p>Fig. C.2 Generation of a
Dirac Î´ using a Lorentzian
function. The width of the
peak is proportional to a
</p>
<p>-4 -2 0 2 4
</p>
<p>x
</p>
<p>0.0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>Î
L
</p>
<p>(
x
</p>
<p>,
a
</p>
<p>)
</p>
<p>which is used as the definition of the derivative of Î´. Such a definition generalizes to
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
f (x)
</p>
<p>dnÎ´(x)
</p>
<p>dxn
dx = (&minus;1)n f (n)(0). (C.53)
</p>
<p>C.5 Some Properties of Dirac&rsquo;s Î´
</p>
<p>An integral representation of Î´ is derived from (C.18) after rearranging it as
</p>
<p>f (x) =
&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>[&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>exp [i k (x &minus; Î¾ )]
2Ï
</p>
<p>dk
</p>
<p>]
</p>
<p>f (Î¾ ) dÎ¾ (C.54)
</p>
<p>and comparing with (C.41):
</p>
<p>Î´(Î¾ &minus; x) =
&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>exp [i k (x &minus; Î¾ )]
2Ï
</p>
<p>dk. (C.55)
</p>
<p>Replacing k with &minus;k in (C.55) shows that Î´ is even with respect to its argument,
Î´(x &minus; Î¾ ) = Î´(Î¾ &minus; x). Also, comparing (C.55) with (C.16) shows that Î´(Î¾ &minus; x) is
the Fourier transform of exp (i k x)/
</p>
<p>&radic;
2Ï . The generalization of (C.55) to more than
</p>
<p>one dimension is immediate; e.g., the three-dimensional case reads
</p>
<p>Î´(g &minus; x) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>exp [i k &middot; (x &minus; g)]
(2Ï )3
</p>
<p>d3k. (C.56)
</p>
<p>The discrete-case analogue of (C.56) is given by (C.117, C.121), where the gen-
eralization of the Kronecker symbol is given. Note that the latter is dimensionless,
whereas the units of Dirac&rsquo;s Î´ depend on its argument: by way of example, the inte-
gral
</p>
<p>&int; +&infin;
&minus;&infin; Î´(Î¾ &minus; x) dÎ¾ = 1 shows that the units of Î´(Î¾ &minus; x) are the inverse of those of</p>
<p/>
</div>
<div class="page"><p/>
<p>612 Appendix C Special Integrals
</p>
<p>Fig. C.3 Generation of a
Dirac Î´ using a parameterized
Gaussian function. The width
of the peak is proportional to
a
</p>
<p>-4 -2 0 2 4
x
</p>
<p>0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>1.5
</p>
<p>Î
G
</p>
<p>(
x
</p>
<p>,
a
</p>
<p>)
</p>
<p>dÎ¾ ; similarly, the integral
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin; Î´(g &minus; x) d3g = 1 shows that the units of Î´(g &minus; x)
are the inverse of those of d3g, and so on.
</p>
<p>A generalization of Dirac&rsquo;s Î´ is found by replacing Î´(x) with Î´[q(x)], with q(x) a
function having one or more zeros. Let x1 be a simple zero of q, namely, q &prime;(x1) ï¿½= 0,
and consider the contribution of it to the integral
</p>
<p>&int; +&infin;
&minus;&infin; Î´[q(x)] dx. Observing that in
</p>
<p>a finite neighborhood I1 of x1 there are no other zeros, one can determine such a
contribution by replacingq(x) withq &prime;(x1) (x&minus;x1); in this way, to bring the calculation
back to the standard form one may provisionally scale the differential dx by 1/q &prime;(x1).
However, if the scaling factor were negative, the evenness of Î´ would be violated;
thus, the correct scaling factor is |q &prime;(x1)|, and
</p>
<p>&int;
</p>
<p>I1
</p>
<p>Î´[q(x)] f (x) dx = 1|q &prime;(x1)|
f (x1). (C.57)
</p>
<p>If q has n simple zeros, from (C.57) it follows
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
Î´[q(x)] f (x) dx = 1|q &prime;(x1)|
</p>
<p>f (x1) + . . .+
1
</p>
<p>|q &prime;(xn)|
f (xn). (C.58)
</p>
<p>C.6 Moments Expansion
</p>
<p>For a given function f (k) consider the integral
</p>
<p>Mn =
&int; +&infin;
</p>
<p>&minus;&infin;
knf (k) dk, n = 0, 1, . . . (C.59)
</p>
<p>It is assumed that the integral converges for any n. This implies that f vanishes at
infinity with a strength larger than any power. As the present considerations apply to
a distribution function, the vanishing of f is typically of the exponential type. The</p>
<p/>
</div>
<div class="page"><p/>
<p>C.6 Moments Expansion 613
</p>
<p>quantity Mn is called moment of order n of function f . Thanks to its properties, f
can be Fourier transformed; let
</p>
<p>g(y) = Ff = 1&radic;
2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
f (k) exp (&minus;i y k) dk. (C.60)
</p>
<p>Using the Taylor expansion exp (&minus;i y k) = &sum;&infin;n=0 (&minus;i y k)n/n! yields
</p>
<p>g(y) =
&infin;
&sum;
</p>
<p>n=0
</p>
<p>1
</p>
<p>n!
(&minus;i)n Mn&radic;
</p>
<p>2Ï
yn. (C.61)
</p>
<p>The latter is the Taylor expansion of g around the origin; it follows
</p>
<p>(&minus;i)n Mn&radic;
2Ï
</p>
<p>=
(
</p>
<p>dng
</p>
<p>dyn
</p>
<p>)
</p>
<p>0
</p>
<p>. (C.62)
</p>
<p>The above analysis shows that, if the moments Mn of f (k) are known, from them
one constructs the Fourier transform g(y) = Ff by means of a Taylor series. Then,
one recovers the original function from the inverse transform f (k) = F&minus;1g. In
conclusion, the knowledge of the set of moments of f is equivalent to the knowledge
of f . The result holds true also in the multi-dimensional case f = f (k), where
</p>
<p>Ml+m+n =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
kl1 k
</p>
<p>m
2 k
</p>
<p>n
3 f (k) d
</p>
<p>3k, l,m, n = 0, 1, . . . (C.63)
</p>
<p>is the moment of order l +m+ n of f .
If only the lower-order moments are used, then the Taylor series for the Fourier
</p>
<p>transform is truncated and provides an approximation gÌ for g. As a consequence of
this approximation, the inverse transform fÌ = F&minus;1gÌ provides an approximate form
of the original function f .
</p>
<p>An extension of the above concepts is obtained by replacing the monomial ex-
pression kl1 k
</p>
<p>m
2 k
</p>
<p>n
3 with a function Î±(k), that can be expressed by a polynomial
</p>
<p>interpolation. In this case, in fact, the integral of Î±(k) f (k) is a combination of
moments of f . A further generalization consists in considering f , Î±, or both, as
functions of other variables besides k:
</p>
<p>MÎ±(r, t) =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î±(r, k, t) f (r, k, t) d3k. (C.64)
</p>
<p>If f (r, k, t) is the solution of a differential equation generated by an operator A,
say, Af = 0, one can derive a set of moments from such an equation by selecting
different forms of Î±:
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
Î±Af d3k = 0. (C.65)
</p>
<p>Each moment depends on the other variables r, t . If operator A contains the deriva-
tives with respect to r, t , or both, then the moment of Af = 0 is a differential
equation in r, t , or both.</p>
<p/>
</div>
<div class="page"><p/>
<p>614 Appendix C Special Integrals
</p>
<p>Fig. C.4 Generation of a
Dirac Î´ using a Fermi-Dirac
statistics. The width of the
peak is proportional to a
</p>
<p>-4 -2 0 2 4
x
</p>
<p>0.00
</p>
<p>0.10
</p>
<p>0.20
</p>
<p>0.30
</p>
<p>0.40
</p>
<p>0.50
</p>
<p>Î
F
</p>
<p>(
x
</p>
<p>,
a
</p>
<p>)
</p>
<p>C.7 Error Function
</p>
<p>The error function and the complementary error function are defined, respectively,
as
</p>
<p>erf (x) = 2&radic;
Ï
</p>
<p>&int; x
</p>
<p>0
exp ( &minus; Î¾ 2) dÎ¾ , erfc (x) = 1 &minus; erf (x). (C.66)
</p>
<p>From the definitions (C.66) and from the Gauss integral (C.23) the following
properties are derived:
</p>
<p>d
</p>
<p>dx
erf (x) = 2&radic;
</p>
<p>Ï
exp ( &minus; x2), erf (&minus;x) = &minus; erf (x), (C.67)
</p>
<p>erf (&minus;&infin;) = &minus;1, erf (0) = 0, erf ( +&infin;) = 1, (C.68)
</p>
<p>erfc (&minus;&infin;) = 2, erfc (0) = 1, erfc ( +&infin;) = 0. (C.69)
</p>
<p>Integrating by parts yields
&int; x
</p>
<p>0
erfc (Î¾ ) dÎ¾ = x erfc (x) + 1&radic;
</p>
<p>Ï
</p>
<p>[
</p>
<p>1 &minus; exp (&minus;x2)
]
</p>
<p>. (C.70)
</p>
<p>Applying the de l&rsquo;H&ocirc;pital rule shows that the first term at the right hand side of (C.70)
vanishes for x &rarr; +&infin;. It follows
</p>
<p>&int; +&infin;
</p>
<p>0
erfc (x) dx = 1&radic;
</p>
<p>Ï
. (C.71)
</p>
<p>Still applying the de l&rsquo;H&ocirc;pital rule shows that
</p>
<p>lim
x&rarr;0
</p>
<p>erf (x)
</p>
<p>x
= 2&radic;
</p>
<p>Ï
, lim
</p>
<p>x&rarr;+&infin;
erfc (x)
</p>
<p>exp (&minus;x2) = limx&rarr;+&infin;
1/
&radic;
Ï
</p>
<p>x
, (C.72)</p>
<p/>
</div>
<div class="page"><p/>
<p>C.8 Parametrized Gaussian Function 615
</p>
<p>whence
</p>
<p>erf (x) â 2&radic;
Ï
x for |x| âª 1, erfc (x) â 1&radic;
</p>
<p>Ï
</p>
<p>exp (&minus;x2)
x
</p>
<p>for x â« 1.
(C.73)
</p>
<p>Other applications of the integration by parts yield
</p>
<p>Y =
&int; x
</p>
<p>0
Î¾ erfc (Î¾ ) dÎ¾ = x2 erfc (x) &minus; Y &minus; 1&radic;
</p>
<p>Ï
</p>
<p>&int; x
</p>
<p>0
Î¾
</p>
<p>[
d
</p>
<p>dÎ¾
exp (&minus;Î¾ 2)
</p>
<p>]
</p>
<p>dÎ¾ =
</p>
<p>= 1
2
x2 erfc (x) + 1
</p>
<p>4
erf (x) &minus; 1
</p>
<p>2
&radic;
Ï
x exp (&minus;x2). (C.74)
</p>
<p>C.8 Parametrized Gaussian Function
</p>
<p>The relations introduced in Sects. C.3 and C.7 are useful for investigating the
properties of function
</p>
<p>Î(x &minus; Î¾ , a) = exp [&minus;(x &minus; Î¾ )
2/(4 a)]&radic;
</p>
<p>4Ï a
, a &gt; 0. (C.75)
</p>
<p>The behavior of Î in the limit a &rarr; 0 depends on the argument x &minus; Î¾ , namely
</p>
<p>lim
a&rarr;0
</p>
<p>Î(x &minus; Î¾ , a) =
</p>
<p>â§
</p>
<p>â¨
</p>
<p>â©
</p>
<p>0 Î¾ ï¿½= x
+&infin; Î¾ = x
</p>
<p>(C.76)
</p>
<p>In contrast, its integral over Î¾ is independent of x and a. In fact, using (C.23) after
letting Î¼ = (x &minus; Î¾ )/
</p>
<p>&radic;
4a yields
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
Î(x &minus; Î¾ , a) dÎ¾ = 1&radic;
</p>
<p>Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
exp ( &minus; Î¼2) dÎ¼ = 1. (C.77)
</p>
<p>Adopting the same variable change leading to (C.77) and using (C.23, C.66) yields
</p>
<p>&int; 0
</p>
<p>&minus;&infin;
Î(x &minus; Î¾ , a) dÎ¾ = 1
</p>
<p>2
erfc
</p>
<p>(
x&radic;
4a
</p>
<p>)
</p>
<p>. (C.78)
</p>
<p>The relations (C.77, C.78) hold also in the limit for a &rarr; 0, provided the limit is
calculated after the integration. This property is typical of the functions that generate
the Dirac Î´ (Sect. C.4). In fact it can be shown that for a continuous function g(x)
the following holds:
</p>
<p>lim
a&rarr;0
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
g(Î¾ )Î(x &minus; Î¾ , a) dÎ¾ = g(x). (C.79)</p>
<p/>
</div>
<div class="page"><p/>
<p>616 Appendix C Special Integrals
</p>
<p>Other examples of Î´-generating functions are given in Sect. C.4. This section is
concluded by showing that Î(x&minus; Î¾ , a) admits an integral representation of the form
</p>
<p>Î(x &minus; Î¾ , a) = 1
2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
exp [ik(x &minus; Î¾ ) &minus; ak2] dk. (C.80)
</p>
<p>To prove (C.80) one recasts the argument of the exponential by means of the identity
</p>
<p>ik(x &minus; Î¾ ) &minus; ak2 = &minus; (x &minus; Î¾ )
2
</p>
<p>4a
&minus; a
</p>
<p>[
</p>
<p>k &minus; i(x &minus; Î¾ )
2a
</p>
<p>]2
</p>
<p>, (C.81)
</p>
<p>and uses (C.23) with
&radic;
a [k&minus;i(x&minus;Î¾ )/(2a)] as the integration variable. It is interesting
</p>
<p>to note in passing that letting Î¾ = 0, a = Ï 2/2 in (C.80) yields
</p>
<p>exp [&minus;x2/(2 Ï 2)] = Ï&radic;
2Ï
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
exp ( &minus; Ï 2 k2/2) exp (i k x) dk, (C.82)
</p>
<p>namely, the Gaussian function is the Fourier transform of itself.
</p>
<p>C.9 Euler&rsquo;s Beta Function
</p>
<p>The function defined by the integral
</p>
<p>B(Î», Î¼) =
&int; 1
</p>
<p>0
xÎ»&minus;1 (1 &minus; x)Î¼&minus;1 dx, (C.83)
</p>
<p>with Î», Î¼ complex numbers such that &real;(Î») &gt; 0, &real;(Î¼) &gt; 0, is called Euler&rsquo;s Beta
function or Euler&rsquo;s integral of the first kind [65]. Letting x = y/(y+1) and replacing
y with x gives (C.83) the equivalent form
</p>
<p>B(Î», Î¼) =
&int; +&infin;
</p>
<p>0
xÎ»&minus;1 (1 + x)&minus;(Î»+Î¼) dx. (C.84)
</p>
<p>Limiting the variables&rsquo; range to 0 &lt; &real;(Î»),&real;(Î¼) &lt; 1 and letting
Î¼ = 1 &minus; Î», T0(Î») = B(Î», 1 &minus; Î») (C.85)
</p>
<p>yields
</p>
<p>T0(Î») =
&int; +&infin;
</p>
<p>0
</p>
<p>xÎ»&minus;1
</p>
<p>1 + x dx =
Ï
</p>
<p>sin (Î»Ï )
. (C.86)
</p>
<p>The last equality is demonstrated by applying Cauchy&rsquo;s residue theorem [114,
Sect. 64] to the function f (z) = zÎ»&minus;1/(1 + z), with z complex, that over the real
axis reduces to the integrand of (C.86). The relation (C.86) can be exploited for
calculating other integrals. For instance, for Î» real one lets Î» = 1/(2Î¼), x = y2Î¼ to
find
</p>
<p>&int; +&infin;
</p>
<p>0
</p>
<p>1
</p>
<p>1 + y2Î¼ dy =
Ï/(2Î¼)
</p>
<p>sin [Ï/(2Î¼)]
, Î¼ &gt;
</p>
<p>1
</p>
<p>2
. (C.87)</p>
<p/>
</div>
<div class="page"><p/>
<p>C.10 Euler&rsquo;s Gamma Function 617
</p>
<p>C.10 Euler&rsquo;s Gamma Function
</p>
<p>The function defined by the integral
</p>
<p>Î (Î») =
&int; +&infin;
</p>
<p>0
xÎ»&minus;1 exp (&minus;x) dx, (C.88)
</p>
<p>with Î» a complex number such that &real;(Î») &gt; 0, is called Euler&rsquo;s Gamma function
or Euler&rsquo;s integral of the second kind [33, Sect. 1.3].5 The negative of its derivative
Î &prime; = dÎ/dÎ» calculated for Î» = 1 is called Euler&rsquo;s constant, Î³ = &minus;Î &prime;(1) =
&int; +&infin;
</p>
<p>0 exp (&minus;x) log (x) dx â 0.5772. From (C.88) one finds Î (1) = 1 and, after
integrating by parts,
</p>
<p>Î (Î»+ 1) = Î»Î (Î»). (C.89)
</p>
<p>If Î» = n = 1, 2, . . . (C.89) yields
</p>
<p>Î (n+ 1) = nÎ (n) = n(n&minus; 1)Î (n&minus; 1) = . . . = n!. (C.90)
</p>
<p>The definition of Î is extended by analytic continuation to the complex plane with
the exception of the points Î» = 0,&minus;1,&minus;2, . . . ,&minus;n, . . . . At each negative integer
&minus;n, the function Î has a simple pole with a residue equal to (&minus;1)n/n! [65], namely,
</p>
<p>lim
Î»&rarr;&minus;n
</p>
<p>(Î»+ n)Î (Î») = (&minus;1)
n
</p>
<p>n! , n = 0, 1, 2 . . . (C.91)
</p>
<p>A straightforward calculation shows that the beta and gamma functions are connected
by the relation [65]
</p>
<p>Î (Î»)Î (Î¼) = Î (Î»+ Î¼)B(Î», Î¼). (C.92)
</p>
<p>Thanks to (C.92) one extends the definition of B to the complex plane with the
exception of the points Î», Î¼, Î» + Î¼ = 0,&minus;1,&minus;2, . . . ,&minus;n, . . . . Moreover, limiting
the variables&rsquo; range to 0 &lt; &real;(Î»),&real;(Î¼) &lt; 1 and letting Î¼ = 1&minus;Î» so that Î (Î»+Î¼) =
Î (1) = 1, from (C.86) one finds
</p>
<p>Î (Î»)Î (1 &minus; Î») =
&int; +&infin;
</p>
<p>0
</p>
<p>xÎ»&minus;1
</p>
<p>1 + x dx = T0(Î»), 0 &lt; &real;(Î») &lt; 1. (C.93)
</p>
<p>For Î» = 1/2 (C.93) yields
</p>
<p>Î
</p>
<p>(
1
</p>
<p>2
</p>
<p>)
</p>
<p>= &radic;Ï (C.94)
</p>
<p>5 As remarked in [33], Legendre&rsquo;s notation Î (Î») is unfortunate because the argument that appears
at the right hand side of the definition is Î»&minus; 1. Gauss used the notation Î  (Î»&minus; 1) for the left hand
side of C.88.</p>
<p/>
</div>
<div class="page"><p/>
<p>618 Appendix C Special Integrals
</p>
<p>whence, thanks to (C.89),
</p>
<p>Î
</p>
<p>(
3
</p>
<p>2
</p>
<p>)
</p>
<p>= 1
2
Î
</p>
<p>(
1
</p>
<p>2
</p>
<p>)
</p>
<p>= 1
2
</p>
<p>&radic;
Ï , Î
</p>
<p>(
5
</p>
<p>2
</p>
<p>)
</p>
<p>= 3
2
Î
</p>
<p>(
3
</p>
<p>2
</p>
<p>)
</p>
<p>= 3
4
</p>
<p>&radic;
Ï , . . . (C.95)
</p>
<p>Iterating (C.95) and comparing with (C.33) shows that Î (m + 1/2) = 2 I2m(1),
m = 0, 1, 2, . . .
</p>
<p>C.11 Gamma Function&rsquo;s Asymptotic Behavior
</p>
<p>Euler&rsquo;s Gamma function introduced in Sect. C.10, considered for real values of Î»,
lends itself to a significant application of the asymptotic analysis. Specifically, one
seeks another function f (Î»), expressible through elementary functions, such that
limÎ»&rarr;&infin; [Î (Î» + 1)/f (Î»)] = 1. The asymptotic analysis applied to the Î function
shows that [26]
</p>
<p>lim
Î»&rarr;&infin;
</p>
<p>Î (Î»+ 1)
Î»Î»+1/2 exp (&minus;Î») =
</p>
<p>&radic;
2Ï , (C.96)
</p>
<p>namely, the function sought is f (Î») =
&radic;
</p>
<p>2Ï Î»Î»+1/2 exp (&minus;Î»). Equation (C.96) is
called Stirling&rsquo;s formula. Remembering (C.90) one has Î (Î»+ 1) = Î (n+ 1) = n!
when Î» is a natural number. From (C.96) it follows
</p>
<p>n! â
&radic;
</p>
<p>2Ï nn+1/2 exp (&minus;n) =
&radic;
</p>
<p>2Ï n (n/e)n , (C.97)
</p>
<p>that provides an approximation to the factorial for n â« 1. Letting by way of example
n = 10, the rounded value of the right hand side of (C.97) turns out to be 3 598 696,
that differs from 10! = 3 628 800 by less than 1%.
</p>
<p>The asymptotic value of the derivative of logÎ is also of interest, for instance
when determining the equilibrium distribution of particles in statistical mechanics
(Sects. 6.4, 15.8.1,15.8.2). Using (C.96) one finds
</p>
<p>d
</p>
<p>dÎ»
logÎ (Î»+ 1) â 1
</p>
<p>2 Î»
+ log Î» â log Î», Î» â« 1. (C.98)
</p>
<p>C.12 Integrals Related to the Harmonic Oscillator
</p>
<p>Consider the integral
</p>
<p>I (s) =
&int; 1
</p>
<p>0
</p>
<p>dÎ¾&radic;
1 &minus; Î¾ s , (C.99)
</p>
<p>where s is a real parameter, s &gt; 0. Letting u = Î¾ s one finds 1/&radic;1 &minus; Î¾ s = (1 &minus;
u)1/2&minus;1, dÎ¾ = u1/s&minus;1 du/s whence, using (C.83, C.92, C.94),
</p>
<p>I (s) = 1
s
B(1/s, 1/2) =
</p>
<p>&radic;
Ï
</p>
<p>s
</p>
<p>Î (1/s)
</p>
<p>Î (1/s + 1/2) . (C.100)</p>
<p/>
</div>
<div class="page"><p/>
<p>C.13 Fermi Integrals 619
</p>
<p>By way of example I (2) = Ï/2, which can also be derived directly from (C.99).
When s &rarr; &infin; one can use (C.91) with n = 0. It follows
</p>
<p>lim
s&rarr;&infin;
</p>
<p>I (s) = 1. (C.101)
</p>
<p>Now consider the integral
</p>
<p>J (s) =
&int; 1
</p>
<p>0
</p>
<p>dÎ¾&radic;
1/Î¾ s &minus; 1 , (C.102)
</p>
<p>still with s &gt; 0. The same procedure used for calculating I (s) yields
</p>
<p>J (s) = 1
s
B(1/s + 1/2, 1/2) =
</p>
<p>&radic;
Ï
</p>
<p>s
</p>
<p>Î (1/s + 1/2)
Î (1/s + 1) =
</p>
<p>Ï
</p>
<p>s
</p>
<p>1
</p>
<p>I (s)
, (C.103)
</p>
<p>and lims&rarr;&infin; J (s) = 0. By way of example J (1) = Ï/2, which can also be derived
directly from (C.102). The integrals (C.100, C.103) appear in the theory of the
harmonic oscillator (Sect. 3.3 and Problems 3.1, 3.2).
</p>
<p>C.13 Fermi Integrals
</p>
<p>The Fermi integral of order Î± is defined as
</p>
<p>Î¦Î±(Î¾ ) =
1
</p>
<p>Î (Î± + 1)
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>xÎ±
</p>
<p>1 + exp (x &minus; Î¾ ) dx, Î± &gt; &minus;1, (C.104)
</p>
<p>where Î is defined by (C.88) and Î± is a real parameter. The constraint Î± &gt; &minus;1
guarantees the convergence of the integral. If &minus;Î¾ â« 1 one has exp (x &minus; Î¾ ) &ge;
exp (&minus;Î¾ ) â« 1 and, from (C.88),
</p>
<p>Î¦Î±(Î¾ ) â
exp (Î¾ )
</p>
<p>Î (Î± + 1)
</p>
<p>&int; &infin;
</p>
<p>0
xÎ± exp (&minus;x) dx = exp (Î¾ ), Î¾ â« &minus;1. (C.105)
</p>
<p>A relation between Fermi integral of different order is found by considering, for
some Î± &gt; 0, the integral of order Î± &minus; 1:
</p>
<p>1
</p>
<p>Î (Î±)
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>xÎ±&minus;1
</p>
<p>1 + exp (x &minus; Î¾ ) dx =
1
</p>
<p>Î± Î (Î±)
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>xÎ± exp (x &minus; Î¾ )
[
</p>
<p>1 + exp (x &minus; Î¾ )
]2 dx, (C.106)
</p>
<p>where the right hand side is derived through an integration by parts. Observing that
Î± Î (Î±) = Î (Î±+1) and using again (C.104) shows that the right hand side of (C.106)
is equal to dÎ¦Î±/dÎ¾ . Then,
</p>
<p>dÎ¦Î±
dÎ¾
</p>
<p>= Î¦Î±&minus;1,
d logÎ¦Î±
</p>
<p>dÎ¾
= Î¦Î±&minus;1
</p>
<p>Î¦Î±
. (C.107)</p>
<p/>
</div>
<div class="page"><p/>
<p>620 Appendix C Special Integrals
</p>
<p>The Fermi integrals are positive by construction; from the first relation in (C.107)
it then follows that the Fermi integrals are monotonically-increasing functions of
the argument Î¾ . The Fermi integral of order 0 is expressed in terms of elementary
functions,
</p>
<p>Î¦0 = log
[
</p>
<p>exp (Î¾ ) + 1
]
</p>
<p>. (C.108)
</p>
<p>Approximations for the Fermi integrals are found, e.g., in [6, Appendix C]. In the
applications to the semiconductor theory the Fermi integrals of small half-integer
order (1/2, 3/2) are the most important ones (Sects. 18.2, 19.6.4). Remembering
(C.94, C.95), they read
</p>
<p>Î¦1/2(Î¾ ) =
&int; &infin;
</p>
<p>0
</p>
<p>2 x1/2/
&radic;
Ï
</p>
<p>1 + exp (x &minus; Î¾ ) dx, Î¦3/2(Î¾ ) =
&int; &infin;
</p>
<p>0
</p>
<p>(4/3) x3/2/
&radic;
Ï
</p>
<p>1 + exp (x &minus; Î¾ ) dx.
(C.109)
</p>
<p>C.14 H&ouml;lder&rsquo;s Inequality
</p>
<p>H&ouml;lder&rsquo;s inequality states that for any pair of real constants b, c &gt; 1 such that
1/b + 1/c = 1 it is
</p>
<p>&int;
</p>
<p>Î·
</p>
<p>|F G| dx &le;
(&int;
</p>
<p>Î·
</p>
<p>|F |b dx
)1/b (&int;
</p>
<p>Î·
</p>
<p>|G|c dx
)1/c
</p>
<p>, (C.110)
</p>
<p>where F , G are any complex functions defined over the real interval Î· and such that
the integrals in (C.110) converge. The inequality is proven starting from the function
Ï(r) = rb &minus; b r + b &minus; 1, r &gt; 0, b &gt; 1, whose first derivative is Ï&prime;(r) = b rb&minus;1 &minus; b
and the second one Ï&prime;&prime; = b (b &minus; 1) rb&minus;2. As a consequence, for r &gt; 0 the function
has only one minimum, located at r = 1. The inequality rb+b &ge; b r+1 then holds,
whence
</p>
<p>rb&minus;1
</p>
<p>b
+ 1
</p>
<p>c r
&ge; 1, c = b
</p>
<p>b &minus; 1 &gt; 1. (C.111)
</p>
<p>Let F1(x) and G1(x) be any two complex functions defined over Î· and fulfilling the
normalization condition
</p>
<p>&int;
</p>
<p>Î·
</p>
<p>|F1|b dx =
&int;
</p>
<p>Î·
</p>
<p>|G1|c dx = 1. (C.112)
</p>
<p>Letting rb&minus;1 = |F1|b&minus;1/|G1| and replacing in (C.111) yields
</p>
<p>|F1|b
b
</p>
<p>+ |G1|
c
</p>
<p>c
&minus; |F1 G1| &ge; 0,
</p>
<p>1
</p>
<p>b
+ 1
</p>
<p>c
= 1. (C.113)</p>
<p/>
</div>
<div class="page"><p/>
<p>C.15 Integrals Related to the Electromagnetic Modes 621
</p>
<p>Since the function at the left hand side of (C.113) is non negative, its integral is non
negative as well. Integrating (C.113) over Î· and using the normalization condition
(C.112) yields
</p>
<p>&int;
</p>
<p>Î·
</p>
<p>|F1 G1| dx &le;
1
</p>
<p>b
+ 1
</p>
<p>c
= 1. (C.114)
</p>
<p>On the other hand the normalization condition also yields
</p>
<p>(&int;
</p>
<p>Î·
</p>
<p>|F1|b dx
)1/b
</p>
<p>=
(&int;
</p>
<p>Î·
</p>
<p>|G1|c dx
)1/c
</p>
<p>= 1, (C.115)
</p>
<p>whence
&int;
</p>
<p>Î·
</p>
<p>|F1G1| dx &le;
(&int;
</p>
<p>Î·
</p>
<p>|F1|b dx
)1/b (&int;
</p>
<p>Î·
</p>
<p>|G1|c dx
)1/c
</p>
<p>. (C.116)
</p>
<p>As (C.116) is homogeneous, it still holds after replacing F1, G1 with F = Î»F1 and
G = Î¼G1, where Î», Î¼ are arbitrary positive real numbers. This proves H&ouml;lder&rsquo;s
inequality (C.110).
</p>
<p>C.15 Integrals Related to the Electromagnetic Modes
</p>
<p>In several applications (e.g., calculations related to the modes of the electromagnetic
field, Sect. 5.5) one must evaluate integrals of the form
</p>
<p>Y =
&int;
</p>
<p>V
</p>
<p>exp [i (k &plusmn; k&prime;) &middot; r] d3r , (C.117)
</p>
<p>where k = k(n1, n2, n3) is given by
</p>
<p>k = n1
2Ï
</p>
<p>d1
i1 + n2
</p>
<p>2Ï
</p>
<p>d2
i2 + n3
</p>
<p>2Ï
</p>
<p>d3
i3, ni = 0,&plusmn;1,&plusmn;2, . . . , (C.118)
</p>
<p>i1, i2, i3 being the unit vectors parallel to the coordinate axes. The integration domain
in (C.117) is a box whose sides d1, d2, d3 are aligned with the axes and start from
the origin (Fig. 5.1). The volume of the box is V = d1 d2 d3. As (k &plusmn; k&prime;) &middot; r =
(k1&plusmn;k&prime;1) x1+ (k2 &plusmn;k&prime;2) x2 + (k3&plusmn;k&prime;3) x3, where the upper (lower) signs hold together,
the integral becomes Y = Y1 Y2 Y3, with
</p>
<p>Yi =
&int; di
</p>
<p>0
exp [i (ki &plusmn; k&prime;i) xi] dxi =
</p>
<p>exp [i (ki &plusmn; k&prime;i) di] &minus; 1
i (ki &plusmn; k&prime;i)
</p>
<p>. (C.119)
</p>
<p>Letting Î¸i = (ki &plusmn; k&prime;i) di/2 = Ï (ni &plusmn; n&prime;i), (C.119) becomes
</p>
<p>Yi = di exp (i Î¸i)
exp (i Î¸i) &minus; exp ( &minus; i Î¸i)
</p>
<p>2 i Î¸i
= di exp (i Î¸i)
</p>
<p>sin Î¸i
Î¸i
</p>
<p>. (C.120)</p>
<p/>
</div>
<div class="page"><p/>
<p>622 Appendix C Special Integrals
</p>
<p>It follows that Yi = 0 if ni &plusmn; n&prime;i ï¿½= 0, while Yi = di if ni &plusmn; n&prime;i = 0. Combining the
three integrals shows that it is Y = 0 if k &plusmn; k&prime; ï¿½= 0, while it is Y = V if k &plusmn; k&prime; = 0.
The result is recast in a compact form by means of the three-dimensional extension
of the Kronecker symbol (A.18):
</p>
<p>Y = V Î´[k &plusmn; k&prime;, 0] = V Î´[k &plusmn; k&prime;], (C.121)
</p>
<p>where the last form is obtained by dropping the zero for the sake of conciseness.
Compare (C.117, C.121) with (C.56) and the comments therein.
</p>
<p>C.16 Riemann&rsquo;s Zeta Function
</p>
<p>The function defined by
</p>
<p>Î¶ (Î», a) =
&infin;
&sum;
</p>
<p>k=1
</p>
<p>1
</p>
<p>(k + a)Î» , (C.122)
</p>
<p>where Î» is a complex number with &real;(Î») &gt; 1 and a &ge; 0 is real, is called Riemann&rsquo;s
Zeta function. It can be represented in integral form by combining it with the Gamma
function (C.88): letting x = (k + a) y in the latter, then replacing y back with x,
yields
</p>
<p>Î (Î») = (k + a)Î»
&int; +&infin;
</p>
<p>0
xÎ»&minus;1 exp [&minus;(k + a) x] dx. (C.123)
</p>
<p>Dividing (C.123) by (k + a)Î», letting k = 1, 2, . . . , and adding over k provides
</p>
<p>Î (Î»)
&infin;
&sum;
</p>
<p>k=1
</p>
<p>1
</p>
<p>(k + a)Î» =
&int; +&infin;
</p>
<p>0
xÎ»&minus;1 exp (&minus;ax)
</p>
<p>[ &infin;
&sum;
</p>
<p>k=1
exp ( &minus; kx)
</p>
<p>]
</p>
<p>dx, (C.124)
</p>
<p>where
&sum;&infin;
</p>
<p>k=1 exp ( &minus; k x) = exp (&minus;x) [1 + exp (&minus;x) + exp (&minus;2 x) + . . . ] =
1/[ exp (x) &minus; 1], so that from (C.122),
</p>
<p>Î¶ (Î», a) = 1
Î (Î»)
</p>
<p>&int; +&infin;
</p>
<p>0
</p>
<p>xÎ»&minus;1
</p>
<p>exp (x) &minus; 1 exp (&minus;a x) dx, &real;(Î») &gt; 1. (C.125)
</p>
<p>Remembering (C.89) one finds that (C.125) fulfills the recursive relation
</p>
<p>&part;
</p>
<p>&part;a
Î¶ (Î», a) = &minus;Î» Î¶ (Î»+ 1, a). (C.126)
</p>
<p>Also, letting a = 0 and Î» = 2m, with m = 1, 2, . . . transforms (C.125) into
&int; +&infin;
</p>
<p>0
</p>
<p>x2m&minus;1
</p>
<p>exp (x) &minus; 1 dx = Î (2m) Î¶ (2m, 0) =
(2Ï )2m
</p>
<p>4m
|B2m|, (C.127)</p>
<p/>
</div>
<div class="page"><p/>
<p>C.16 Riemann&rsquo;s Zeta Function 623
</p>
<p>with B2m = (&minus;1)m+1 |B2m|, m &ge; 1 the Bernoulli number6 of order 2m [44]. Thanks
to (C.127) one calculates integrals used in different applications. For instance, letting
m = 2 and using B4 = &minus;1/30
</p>
<p>&int; +&infin;
</p>
<p>0
</p>
<p>x3
</p>
<p>exp (x) &minus; 1 dx =
1
</p>
<p>15
Ï4, (C.128)
</p>
<p>that is used in (15.78) to calculate the Lagrangian multiplier in the equilibrium
statistics for photons. From (C.125) one derives another important class of integrals;
in fact, replacing x with 2 x in the denominator of (C.125) yields
</p>
<p>&int; +&infin;
</p>
<p>0
</p>
<p>xÎ»&minus;1
</p>
<p>exp (2 x) &minus; 1 exp (&minus;a x) dx = 2
&minus;Î» Î (Î») Î¶ (Î», a/2), &real;(Î») &gt; 1 (C.129)
</p>
<p>whence, using the identity 2/[ exp (2 x) &minus; 1] = 1/[ exp (x) &minus; 1] &minus; 1/[ exp (x) + 1]
within (C.125), (C.129) provides
</p>
<p>&int; +&infin;
</p>
<p>0
</p>
<p>xÎ»&minus;1
</p>
<p>exp (x) + 1 exp (&minus;a x) dx = Î (Î»)
[
</p>
<p>Î¶ (Î», a) &minus; 21&minus;Î» Î¶ (Î», a/2)
]
</p>
<p>. (C.130)
</p>
<p>Letting a = 0 and Î» = 2m, m = 1, 2, . . . in the latter, and using (C.127), transforms
(C.130) into
</p>
<p>&int; +&infin;
</p>
<p>0
</p>
<p>x2m&minus;1
</p>
<p>exp (x) + 1 dx =
Ï2m
</p>
<p>2m
</p>
<p>(
</p>
<p>22m&minus;1 &minus; 1
)
</p>
<p>|B2m|. (C.131)
</p>
<p>For instance, for m = 1 and m = 2, (C.131) provides
&int; +&infin;
</p>
<p>0
</p>
<p>x
</p>
<p>exp (x) + 1 dx =
1
</p>
<p>12
Ï2,
</p>
<p>&int; +&infin;
</p>
<p>0
</p>
<p>x3
</p>
<p>exp (x) + 1 dx =
7
</p>
<p>120
Ï4. (C.132)
</p>
<p>6 The Bernoulli numbers are defined by the series expansion x/[ exp (x) &minus; 1] = &sum;&infin;0 Bn xn/n!,
with |x| &lt; 2Ï . It is B0 = 1, B1 = &minus;1/2, B2 = 1/6, B4 = &minus;1/30. Apart from B1, all Bernoulli
numbers of odd index vanish.</p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix D
Tables
</p>
<p>Table D.1 Fundamental
constants
</p>
<p>Quantity Symbol Valuea Units
</p>
<p>Vacuum permittivity Îµ0 8.85419 &times; 10&minus;12 F m&minus;1
</p>
<p>Speed of light c 2.99792 &times; 108 m s&minus;1
</p>
<p>Electron charge q 1.60219 &times; 10&minus;19 C
Electron rest mass m0 9.10953 &times; 10&minus;31 kg
Proton rest mass M0 1.67265 &times; 10&minus;27 kg
Boltzmann constant kB 1.38066 &times; 10&minus;23 J K&minus;1
</p>
<p>Planck constant h 6.62616 &times; 10&minus;34 J s
Reduced Planck c. hÌ 1.05459 &times; 10&minus;34 J s
Atomic radius ra &sim; 10&minus;10 m
Electron radius re 2.81794 &times; 10&minus;15 m
</p>
<p>aThe ratio between the proton and electron rest masses isM0/m0 â
1836. The vacuum permeability is found from Î¼0 = 1/(c2Îµ0)
</p>
<p>Table D.2 Greek alphabet Small Capitala Name Small Capital Name
</p>
<p>Î± A Alpha Î½ N Nu, ni
</p>
<p>Î² B Beta Î¾ Î Xi
</p>
<p>Î³ Î Gamma o O Omicron
</p>
<p>Î´ Î Delta Ï Î  Pi
</p>
<p>Îµ E Epsilon Ìº P Rho
</p>
<p>Î¶ Z Zeta Ï Î£ Sigma
</p>
<p>Î· H Eta Ï T Tau
</p>
<p>Î¸ , Ï Î Theta Ï Î¥ Upsilon
</p>
<p>Î¹ I Iota Ï, Ï Î¦ Phi
</p>
<p>Îº K Kappa Ï X Chi
</p>
<p>Î» Î Lambda Ï Î¨ Psi
</p>
<p>Î¼ M Mu, mi Ï Î© Omega
aSymbol &nabla; is not a Greek letter. However, its name nabla is a
Greek word, meaning &ldquo;harp&rdquo;
</p>
<p>&copy; Springer Science+Business Media New York 2015 625
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions
</p>
<p>Problems of Chap. 1
</p>
<p>1.1 The distance between A and B is a functional of y:
</p>
<p>G[y] =
&int;
</p>
<p>AB
</p>
<p>&radic;
</p>
<p>dx2 + dy2 =
&int; b
</p>
<p>a
</p>
<p>&radic;
</p>
<p>1 + yÌ2 dx.
</p>
<p>As g(y, yÌ, x) =
&radic;
</p>
<p>1 + yÌ2 it is &part;g/&part;y = 0, whence the Euler&ndash;Lagrange equation
reads
</p>
<p>0 = d
dx
</p>
<p>&part;g
</p>
<p>&part;yÌ
= d
</p>
<p>dx
</p>
<p>2yÌ
</p>
<p>2 g
= yÌg &minus; yÌ(2yÌyÌ/2 g)
</p>
<p>g2
= yÌ
</p>
<p>g3
(g2 &minus; yÌ2) = yÌ
</p>
<p>g3
,
</p>
<p>that is, yÌ = 0, y = c1x + c2. The two constants are found from c1a + c2 = ya ,
c1b + c2 = yb.
1.2 Letting H = E one finds
</p>
<p>x2
</p>
<p>a2
+ p
</p>
<p>2
</p>
<p>b2
= 1, a =
</p>
<p>&radic;
</p>
<p>2E/c, b =
&radic;
</p>
<p>2mE.
</p>
<p>The curves are ellipses whose axes are proportional to
&radic;
E. The area of each ellipse is
</p>
<p>Ï a b = 2ÏE/Ï, withÏ = &radic;c/m. As shown in Sect. 3.3, Ï is the angular frequency
of the oscillator, so that the area becomes E T , with T = 2Ï/Ï the period. As time
evolves, the phase point follows the curve in the clockwise direction; in fact, as the
phase point reaches the maximum elongation xM &gt; 0 from the left, the momentum
at xM changes from positive to negative.
</p>
<p>1.3 Letting H = E one finds for the maximum elongation xM = (s E/c)1/s . Note
that the units of c depend on the value of s. The form of the constant-energy curves
becomes more and more rectangular as s increases. As in the previous exercise, the
phase point follows the curve in the clockwise direction.
</p>
<p>&copy; Springer Science+Business Media New York 2015 627
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6</p>
<p/>
</div>
<div class="page"><p/>
<p>628 Solutions
</p>
<p>Problems of Chap. 2
</p>
<p>2.1 From (2.49) one finds
</p>
<p>J (E) = &radic;mc
â®
</p>
<p>&radic;
</p>
<p>2E/c &minus; x2 dx,
</p>
<p>where the integration path is the ellipse described in Problem 1.2. Letting x =&radic;
2E/c sin Ï transforms the above into
</p>
<p>J (E) = 2
&radic;
</p>
<p>m
</p>
<p>c
E
</p>
<p>&int; 2Ï
</p>
<p>0
cos2 Ï dÏ = 2Ï
</p>
<p>Ï
E, Ï =
</p>
<p>&radic;
</p>
<p>c
</p>
<p>m
.
</p>
<p>The first of (2.51) then yields Î½ = wÌ = &part;H/&part;J = &part;E/&part;J = Ï/(2Ï ).
</p>
<p>Problems of Chap. 3
</p>
<p>3.1 Like in problem 1.3, letting H = E &gt; 0 one finds for the maximum elongation
xM = (s E/c)1/s , where the units of c depend on the value of s. The motion is limited
to the interval [&minus;xM ,+xM ] and the potential energy is symmetric with respect to the
origin. Using (2.47) and exploiting the symmetry yields
</p>
<p>T = 4
&radic;
</p>
<p>m
</p>
<p>2
</p>
<p>&int; xM
</p>
<p>0
</p>
<p>dx&radic;
E &minus; V (x) =
</p>
<p>&radic;
</p>
<p>8m
</p>
<p>E
</p>
<p>&int; xM
</p>
<p>0
</p>
<p>[
</p>
<p>1 &minus; (x/xM )s
]&minus;1/2
</p>
<p>dx.
</p>
<p>Letting Î¾ = x/xM and using (C.99, C.100) yields
</p>
<p>T =
&radic;
</p>
<p>8m
</p>
<p>E
xM
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>dÎ¾&radic;
1 &minus; Î¾ s =
</p>
<p>&radic;
8Ï m
</p>
<p>(1/s)Î (1/s)
</p>
<p>Î (1/s + 1/2)
( s
</p>
<p>c
</p>
<p>)1/s
E1/s&minus;1/2.
</p>
<p>The result shows that the case s = 2, namely, that of the linear harmonic oscillator,
is special. In fact, the period does not depend on the total energy, whereas for s ï¿½= 2
it does. Still in the case s = 2 one finds T = 2Ï/Ï, Ï = &radic;c/m, as should be
(compare with the results of Sect. 3.3). In turn, the case s &rarr; &infin; yields s1/s &rarr; 1,
c1/s &rarr; 1 whence, using (C.101), lims&rarr;&infin; T =
</p>
<p>&radic;
8m/E. The above is the period
</p>
<p>in a square well of length 2 (compare with the description of Sect. 3.2). In fact, as
s &rarr; &infin;, the potential energy c|x|s/s transforms into a square well with xM = 1.
The potential energy is shown in Fig. D.1 for some values of s. Thanks to the result
of this problem one may tune the form of the potential energy to make the period
proportional to a chosen power h = 1/s &minus; 1/2 &ge; &minus;1/2 of the energy. For instance,
letting s = 2/3 makes T proportional to E, namely, T =
</p>
<p>&radic;
</p>
<p>m/(3c3) 2ÏE.
</p>
<p>3.2 The solution is similar to that of Problem 3.1. Letting H = E &lt; 0 one finds for
the maximum elongation xM = [k/(s |E|)]1/s , where the units of k depend on the
value of s. The motion is limited to the interval [&minus;xM ,+xM ] and the potential energy
is symmetric with respect to the origin. Using (2.47) and exploiting the symmetry
yields</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions 629
</p>
<p>Fig. D.1 Form of the
potential energy c|x|s/s for
c = 1 and different values of
s (Problem 3.1)
</p>
<p>-2 -1 0 1 2
Position (a. u.)
</p>
<p>0
</p>
<p>5
</p>
<p>10
</p>
<p>P
o
te
</p>
<p>n
ti
</p>
<p>al
 e
</p>
<p>n
er
</p>
<p>g
y
 (
</p>
<p>a.
 u
</p>
<p>.)
</p>
<p>x
6
 / 6
</p>
<p>x
2
 / 2
</p>
<p>abs(x)
</p>
<p>(3/2) [abs(x)]
2/3
</p>
<p>6 [abs(x)]
1/6
</p>
<p>T = 4
&radic;
</p>
<p>m
</p>
<p>2
</p>
<p>&int; xM
</p>
<p>0
</p>
<p>dx&radic;
E &minus; V (x) =
</p>
<p>&radic;
</p>
<p>8m
</p>
<p>|E|
</p>
<p>&int; xM
</p>
<p>0
</p>
<p>[
</p>
<p>(xM/x)
s &minus; 1
</p>
<p>]&minus;1/2
dx.
</p>
<p>Letting Î¾ = x/xM and using (C.102, C.103) yields
</p>
<p>T =
&radic;
</p>
<p>8m
</p>
<p>|E| xM
&int; 1
</p>
<p>0
</p>
<p>dÎ¾&radic;
1/Î¾ s &minus; 1 =
</p>
<p>&radic;
8Ï m
</p>
<p>Î (1/s + 1/2)
s Î (1/s + 1)
</p>
<p>(
k
</p>
<p>s
</p>
<p>)1/s
</p>
<p>|E|&minus;1/s&minus;1/2.
</p>
<p>The Coulomb case s = 1 yields T =
&radic;
</p>
<p>2mÏ k |E|&minus;3/2 (in fact, in the Coulomb
case and for a closed trajectory the period is always proportional to |E|&minus;3/2, compare
with (3.81)). Note that in the case considered here the particle crosses the origin
because the initial conditions are such that its trajectory is aligned with the x axis.
The limit s &rarr; &infin; yields s1/s &rarr; 1, c1/s &rarr; 1 whence, using (C.101, C.103),
lims&rarr;&infin; T = 0. The potential energy is shown in Fig. D.2 for some values of s.
3.3 The O reference is chosen as in Sect. 3.13.5, whence T1a = E = (m1/m)EB .
From (3.36) one extracts Î¼/s0 = tan [(Ï &minus; Ï )/4], to find
</p>
<p>2Î¼/s0
1 &minus; (Î¼/s0)2
</p>
<p>= 2Î¼ s0
s20 &minus; Î¼2
</p>
<p>= tan
(
Ï &minus; Ï
</p>
<p>2
</p>
<p>)
</p>
<p>= 1
tan (Ï/2)
</p>
<p>,
</p>
<p>where s0 is given by the second of (3.33). It follows that s20 &minus; Î¼2 = 2 Î» s0 and
tan (Ï/2) = Î»/Î¼. Then, noting that (3.23) contains sin2 (Ï/2) = tan2 (Ï/2)/[1 +
tan2 (Ï/2)], and using (3.73), one finds sin2 (Ï/2) = 1/(1+ c2/Î»2). The expression
of Î» is taken from the first of (3.32), with Î± given by (3.75). Inserting the result into
(3.23) yields
</p>
<p>T1b =
Î±2 (1 &minus;m1/m2)2 + c2 T 21a
Î±2 (1 +m1/m2)2 + c2 T 21a
</p>
<p>T1a , T1a &minus; T1b =
4 (m1/m2) T1a
</p>
<p>(1 +m1/m2)2 + (c/Î±)2 T 21a
.</p>
<p/>
</div>
<div class="page"><p/>
<p>630 Solutions
</p>
<p>Fig. D.2 Form of the
potential energy &minus;k|x|&minus;s/s
for k = 1 and different values
of s (Problem 3.2)
</p>
<p>-2 -1 0 1 2
Position (a. u.)
</p>
<p>0
</p>
<p>P
o
te
</p>
<p>n
ti
</p>
<p>al
 e
</p>
<p>n
er
</p>
<p>g
y
 (
</p>
<p>a.
 u
</p>
<p>.)
</p>
<p>- | x |
-6
</p>
<p> / 6
</p>
<p>- | x |
-2
</p>
<p> / 2
</p>
<p>- | x |
-1
</p>
<p>- 2 | x |
-1/2
</p>
<p>- 6 | x |
-1/6
</p>
<p>Fig. D.3 Normalized loss of
energy c (T1a &minus; T1b)/Î± as a
function of the normalized
initial energy c T1a/Î±
(Problem 3.3), for different
values of the ratio m1/m2
</p>
<p>0 5 10 15 20
c T
</p>
<p>1a
 / Î±
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>c 
( 
</p>
<p>T
1
</p>
<p>a
 -
</p>
<p> T
1
</p>
<p>b
 )
</p>
<p> /
 Î±
</p>
<p>m
2
 = m
</p>
<p>1
</p>
<p>m
2
 = 2 m
</p>
<p>1
</p>
<p>m
2
 = 5 m
</p>
<p>1
</p>
<p>Obviously it is T1b &lt; T1a . It follows that T1a &minus; T1b is the loss of energy due to the
collision. It is also interesting to note that using the normalized energies c T1a/Î± and
c T1b/Î± makes the expressions above to depend on the m1/m2 ratio only. The loss
of energy is drawn in normalized form in Fig. D.3 for different values of m1/m2.
</p>
<p>Problems of Chap. 4
</p>
<p>4.1 Using primes to indicate derivatives, a first integration yields
</p>
<p>Ï&prime; = Ï&prime;(c) &minus;H , H (x) =
&int; x
</p>
<p>c
</p>
<p>Ìº(Î¾ )
</p>
<p>Îµ0
dÎ¾ ,
</p>
<p>where H is integrated by parts:
&int; x
</p>
<p>a
</p>
<p>H (Î¾ ) dÎ¾ = x H (x) &minus; a H (a) &minus;
&int; x
</p>
<p>a
</p>
<p>Î¾
Ìº(Î¾ )
</p>
<p>Îµ0
dÎ¾.</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions 631
</p>
<p>Integrating Ï&prime; and using the expression of
&int; x
</p>
<p>a
H (Î¾ ) dÎ¾ yields the solution
</p>
<p>Ï = Ï(a) + Ï&prime;(c) (x &minus; a) &minus; x
&int; x
</p>
<p>c
</p>
<p>Ìº(Î¾ )
</p>
<p>Îµ0
dÎ¾ + a
</p>
<p>&int; a
</p>
<p>c
</p>
<p>Ìº(Î¾ )
</p>
<p>Îµ0
dÎ¾ +
</p>
<p>&int; x
</p>
<p>a
</p>
<p>Î¾
Ìº(Î¾ )
</p>
<p>Îµ0
dÎ¾.
</p>
<p>4.2 Letting c = a in the solution to Problem 4.1 yields at any point x within [a, b]
the expression
</p>
<p>Ï(x) = Ï(a) + Ï&prime;(a) (x &minus; a) &minus; x
&int; x
</p>
<p>a
</p>
<p>Ìº(Î¾ )
</p>
<p>Îµ0
dÎ¾ +
</p>
<p>&int; x
</p>
<p>a
</p>
<p>Î¾
Ìº(Î¾ )
</p>
<p>Îµ0
dÎ¾.
</p>
<p>For x &gt; b it is Ìº = 0 so that the solution of Ï&prime;&prime; = 0 is linear and has the form
Ï(x) = Ï(b)+ Ï&prime;(b) (x &minus; b). The term Ï(b) in the latter is obtained by letting x = b
in the above expression of Ï(x). One finds Ï(b) = Ï(a)+Ï&prime;(a) (b&minus;a)&minus;bM0 +M1,
with
</p>
<p>M0 =
&int; b
</p>
<p>a
</p>
<p>Ìº(Î¾ )
</p>
<p>Îµ0
dÎ¾ , M1 =
</p>
<p>&int; b
</p>
<p>a
</p>
<p>Î¾
Ìº(Î¾ )
</p>
<p>Îµ0
dÎ¾
</p>
<p>the first two moments of Ìº/Îµ0 (compare with Sect. C.6). The derivative Ï&prime; is found
from Problem 4.1 with c = a, and reads
</p>
<p>Ï&prime;(x) = Ï&prime;(a) &minus;
&int; x
</p>
<p>a
</p>
<p>Ìº(Î¾ )
</p>
<p>Îµ0
dÎ¾ ,
</p>
<p>whence Ï&prime;(b) = Ï&prime;(a) &minus;M0. Using the expressions of Ï(b), Ï&prime;(b) thus found yields
</p>
<p>Ï(x) = Ï(a) + Ï&prime;(a) (x &minus; a) &minus;M0 x +M1, x &gt; b.
</p>
<p>4.3 From the findings of Problem 4.2 one observes that the solution Ï is invariant for
any charge density ËÌº that leaves M0 and M1 unchanged. Due to this, if both M0, M1
differ from zero, the new charge density must contain two adjustable parameters in
order to fit the values of M0, M1 through the expressions introduced in Problem 4.2.
If only one moment differs from zero, one parameter suffices, while no parameter is
necessary if both moments are equal to zero. Figure D.4 gives an example of charge
density such that M0 = 0 and M1 = 0.
4.4 The starting point is the solution for x &gt; b found in Problem 4.2. When the
charge density is removed, the new solution reads
</p>
<p>Ï(x) = ÏÌ(a) + ÏÌ&prime;(a) (x &minus; a).
</p>
<p>For x &gt; b the two solutions become equal to each other by letting ÏÌ(a) = Ï(a) &minus;
M0 a +M1 and ÏÌ&prime;(a) = Ï&prime;(a) &minus;M0.</p>
<p/>
</div>
<div class="page"><p/>
<p>632 Solutions
</p>
<p>Fig. D.4 Example of charge
density such that M0 = 0 and
M1 = 0
</p>
<p>Ï
0
</p>
<p>&minus; Ï
0
</p>
<p>&minus; Î¾
0
</p>
<p>Î¾
0
</p>
<p>Î¾
</p>
<p>Ï
</p>
<p>4.5 Considering that the value of h is unknown, the integrals that define the moments
(Problem 4.2) must be extended from &minus;&infin; to +&infin;. One finds Î¼ = M0, h = M1/M0.
If h &ge; a, the solution is given by Ï = Ï(a) + Ï&prime;(a) (x &minus; a) &minus; M0 x + M1 for
x &ge; h, while it is given by Ï = Ï(a) + Ï&prime;(a) (x &minus; a) for x &lt; h. If h &lt; a, the
solution is given by Ï = Ï(a) + Ï&prime;(a) (x &minus; a) for x &ge; h, while it is given by
Ï = Ï(a) + Ï&prime;(a) (x &minus; a) &minus; M0 x + M1 for x &lt; h. At h the electric potential is
continuous, Ï(h+) = Ï(h&minus;) = Ï(a) + Ï&prime;(a) (h &minus; a), whereas the electric field is
discontinuous, Ï&prime;(h&minus;) &minus; Ï&prime;(h+) = M0. The case M0 ï¿½= 0, M1 = 0 yields Î¼ = M0,
h = 0, while the case M0 = 0, M1 ï¿½= 0 can not be fulfilled by Î¼Î´(x &minus; h).
</p>
<p>Problems of Chap. 5
</p>
<p>5.1 From n = n(x1) one finds that gradn = i1 dn/dx1 is parallel to x1 whereas
dn/dx2 = dn/dx3 = 0. From the eikonal Eq. (5.57) it follows
</p>
<p>d
</p>
<p>ds
</p>
<p>(
</p>
<p>n
dx2
ds
</p>
<p>)
</p>
<p>= 0, d
ds
</p>
<p>(
</p>
<p>n
dx3
ds
</p>
<p>)
</p>
<p>= 0,
</p>
<p>whence n dx2/ds = const, n dx3/ds = const. The ratio of the latter relations yields
dx2/dx3 = const, namely, x2 = ax3 + b, where a, b are constants. This expression
is one of the two parametric equations u(x1, x2, x3) = 0, v(x1, x2, x3) = 0 describing
the ray, and shows that the ray belongs to a plane parallel to x1. By a suitable rotation
around x1, such that x2 &rarr; x &prime;2, x3 &rarr; x &prime;3, the plane of the ray is made parallel
to the plane x1 x &prime;2, so that the third coordinate x
</p>
<p>&prime;
3 is fixed. In the new reference,
</p>
<p>let Ï be the angle between the direction of the ray and x1 at some point P ; it is
dx1 = cosÏ ds, dx &prime;2 = sin Ï ds. The eikonal equation in the new reference then
provides
</p>
<p>n
dx &prime;2
ds
</p>
<p>= const, n sin Ï = const.</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions 633
</p>
<p>5.2 Like in Problem 5.1 one considers the case where the refraction index depends
only on the x1 coordinate. Let the medium be made of three regions separated by
two planes parallel to each other.
</p>
<p>The two external regions A and B have a constant refraction index, nA and,
respectively, nB ï¿½= nA. The internal region I, whose thickness is s, has a refraction
index that varies continuously from nA to nB as x1 varies from the A-I interface
to the I-B interface. Applying the solution of Problem 5.1 to this case shows that
nA sin ÏA = const everywhere in region A, hence the ray is a straight line there;
similarly it is nB sin ÏB = const everywhere in region B, with the same constant. It
follows
</p>
<p>nB sin ÏB = nA sin ÏA.
</p>
<p>Unless ÏA = 0, the position of the ray along the x &prime;2 axis at the I-B interface is
different from that at the A-I interface; if, however, s is made to vanish, the position
becomes the same, this yielding the Descartes law of refraction: the ray crossing an
interface between two media is continuous, whereas its slopes on the two sides of the
interface fulfill (D). The result still holds in the cases where the interface between the
two media is not planar, provided its curvature is small enough to make geometrical
optics applicable.
</p>
<p>Problems of Chap. 6
</p>
<p>6.1 Letting Ï = Î² h Î½, with Î² = 1/(kB T ), the Boltzmann distribution takes the
form Nn = N0 exp (&minus;nÏ), whence
</p>
<p>&infin;
&sum;
</p>
<p>n=0
Nn = N0
</p>
<p>[
</p>
<p>1 + exp (&minus;Ï) + exp (&minus;2Ï) + . . .
]
</p>
<p>= N0
1 &minus; exp (&minus;Ï) ,
</p>
<p>and
</p>
<p>&infin;
&sum;
</p>
<p>n=0
n h Î½ Nn = h Î½ N0
</p>
<p>[
</p>
<p>exp (&minus;Ï) + 2 exp (&minus;2Ï) + 3 exp (&minus;3Ï) + . . .
]
</p>
<p>.
</p>
<p>Observing that n exp (&minus;nÏ) = &minus;d exp (&minus;nÏ)/dÏ , one finds
&infin;
&sum;
</p>
<p>n=0
n h Î½ Nn = &minus;h Î½
</p>
<p>d
</p>
<p>dÏ
</p>
<p>( &infin;
&sum;
</p>
<p>n=0
Nn &minus;N0
</p>
<p>)
</p>
<p>= h Î½ N0 exp (&minus;Ï)[
1 &minus; exp (&minus;Ï)
</p>
<p>]2 ,
</p>
<p>whence
</p>
<p>En =
&sum;&infin;
</p>
<p>n=0 n h Î½ Nn
&sum;&infin;
</p>
<p>n=0 Nn
= h Î½
</p>
<p>exp (Ï) &minus; 1 =
h Î½
</p>
<p>exp (Î² h Î½) &minus; 1 .</p>
<p/>
</div>
<div class="page"><p/>
<p>634 Solutions
</p>
<p>Problems of Chap. 8
</p>
<p>8.1 Consider the homogeneous equation associated to (8.76), g&prime;&prime; + a g&prime; + b g = 0,
and let f = g h and u = h&prime;; this splits (8.76) into the system
</p>
<p>g&prime;&prime; + a g&prime; + b g = 0, g u&prime; + (2 g&prime; + a g) u = c.
</p>
<p>If g is known, then u is found by integrating a first-order equation, whence f =
g
&int;
</p>
<p>u dÎ¾ . To find g one lets A(x) =
&int;
</p>
<p>a dÎ¾ , g = exp (&minus;A/2) w, this transforming
the homogeneous equation for g into
</p>
<p>w&prime;&prime; + q w = 0, q = b &minus; a2/4 &minus; a&prime;/2,
</p>
<p>which is a time-independent Schr&ouml;dinger equation.
</p>
<p>Problems of Chap. 9
</p>
<p>9.1 Inserting the expression of ck into the one-dimensional form of (9.26) yields
</p>
<p>A (x &minus; u t ; k0) =
&radic;
Ï/2
</p>
<p>Ï3/4
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
exp
</p>
<p>[
</p>
<p>i (x &minus; u t) (k &minus; k0)&minus; Ï 2 k2/2
]
</p>
<p>dk.
</p>
<p>Following the same procedure as in Sect. C.8 one finds
</p>
<p>i (x &minus; u t) (k &minus; k0)&minus;
1
</p>
<p>2
Ï 2 k2 = &minus; (x &minus; u t)
</p>
<p>2
</p>
<p>2 Ï 2
&minus; Ï
</p>
<p>2
</p>
<p>2
</p>
<p>(
</p>
<p>k &minus; j x &minus; u t
Ï 2
</p>
<p>)2
</p>
<p>,
</p>
<p>whence
</p>
<p>A (x &minus; u t ; k0) =
1
</p>
<p>Ï1/4
&radic;
Ï
</p>
<p>exp
</p>
<p>[
</p>
<p>&minus;i k0 (x &minus; u t)&minus;
(x &minus; u t)2
</p>
<p>2 Ï 2
</p>
<p>]
</p>
<p>.
</p>
<p>The particle&rsquo;s localization is determined by
</p>
<p>|A(x &minus; u t)|2 = 1&radic;
Ï Ï
</p>
<p>exp
</p>
<p>[
</p>
<p>&minus; (x &minus; u t)
2
</p>
<p>Ï 2
</p>
<p>]
</p>
<p>.
</p>
<p>Using again the results of Sect. C.8 yields ||A|| = 1.
9.2 Remembering that |Ï |2 = |A|2, the one-dimensional form of (9.23) reads
</p>
<p>x0(t) =
&int; +&infin;
</p>
<p>&minus;&infin;
x |A|2 dx =
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
(x &minus; u t) |A|2 dx + u t
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
|A|2 dx.
</p>
<p>Letting s = x &minus; u t one finds that the integral of s |A(s)|2 vanishes because the
integrand is odd and the integration domain is symmetric with respect to the origin.
Using the result ||A|| = 1 of Problem 9.1 then yields x0(t) = u t .</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions 635
</p>
<p>Problems of Chap. 10
</p>
<p>10.1 To determine the time evolution of the expectation value of the wavepacket for
a free particle one starts from the general expression (9.5), with wk(r) andEk = hÌ Ïk
given by (9.22), and ck given by the second relation in (9.6). The wave function is
assumed normalized,
</p>
<p>&int; +&infin;
&minus;&infin; |Ï(r, t)|2 d3r =
</p>
<p>&int; +&infin;
&minus;&infin; |c(k)|2 d3k = 1. Using the first
</p>
<p>spatial coordinate x1 and defining mk = ck exp (&minus;iÏk t), the following are of use:
x1 wk = &minus;i &part;wk/&part;k1, x21 wk = &minus;&part;2wk/&part;k21 , and
</p>
<p>&minus;
&int; +&infin;
</p>
<p>&minus;&infin;
mk
</p>
<p>&part;wk
</p>
<p>&part;k1
dk1 =
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
wk
</p>
<p>&part;mk
</p>
<p>&part;k1
dk1,
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
mk
</p>
<p>&part;2wk
</p>
<p>&part;k21
dk1 =
</p>
<p>&int; +&infin;
</p>
<p>&minus;&infin;
wk
</p>
<p>&part;2mk
</p>
<p>&part;k21
dk1,
</p>
<p>where the last two equalities are obtained by integrating by parts and observing that,
due to the normalization condition, ck and &part;ck/&part;k1 vanish at infinity. In turn,
</p>
<p>i
&part;mk
</p>
<p>&part;k1
=
</p>
<p>(
</p>
<p>u1 t ck + i
&part;ck
</p>
<p>&part;k1
</p>
<p>)
</p>
<p>exp (&minus;iÏk t), u1 =
&part;Ïk
</p>
<p>&part;k1
= hÌ k1
</p>
<p>m
,
</p>
<p>&minus;&part;
2mk
</p>
<p>&part;k21
=
</p>
<p>[(
</p>
<p>u21 t
2 + i hÌ
</p>
<p>m
t
</p>
<p>)
</p>
<p>ck + 2 i u1 t
&part;ck
</p>
<p>&part;k1
&minus; &part;
</p>
<p>2ck
</p>
<p>&part;k21
</p>
<p>]
</p>
<p>exp (&minus;iÏk t).
</p>
<p>The expectation value ãx1ã = ãÏ |x1|Ïã involves an integration over r to calculate
the scalar product, an integration over k to calculate the integral expression of Ï ,
and an integration over k&prime; to calculate the integral expression of Ï&lowast;. Performing the
integration over r first, letting c&prime;k = c(k&prime;), Ï&prime;k = Ï(k&prime;), and using (C.56) yields
</p>
<p>ãx1ã =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>(
</p>
<p>u1 t |ck|2 + i c&lowast;k
&part;ck
</p>
<p>&part;k1
</p>
<p>)
</p>
<p>d3k.
</p>
<p>Letting ck = ak + i bk, with ak and bk real, and using the asymptotic vanishing of
ck, one finds
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
i c&lowast;k
</p>
<p>&part;ck
</p>
<p>&part;k1
d3k = x01, x01 =
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>(
&part;ak
</p>
<p>&part;k1
bk &minus;
</p>
<p>&part;bk
</p>
<p>&part;k1
ak
</p>
<p>)
</p>
<p>d3k,
</p>
<p>where x01 is a real constant. Repeating the calculation for x2 and x3, and letting
u = gradkÏ, r0 = (x01, x02, x03), finally yields
</p>
<p>ãrã = r0 +
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u t |ck|2 d3k,
</p>
<p>d
</p>
<p>dt
ãrã =
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u |ck|2 d3k = const.
</p>
<p>If |ck|2 is even with respect to all components of k, the expectation value of r does
not change with respect to the initial value r0. Otherwise, it moves at constant speed.</p>
<p/>
</div>
<div class="page"><p/>
<p>636 Solutions
</p>
<p>10.2 The time evolution of the standard deviation of position is found following the
same line and using the same symbols and relations as in Problem 10.1, starting with
</p>
<p>ãx21 ã =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>[(
</p>
<p>u21 t
2 + i hÌ
</p>
<p>m
t
</p>
<p>)
</p>
<p>|ck|2 + 2i u1 t c&lowast;k
&part;ck
</p>
<p>&part;k1
&minus; c&lowast;k
</p>
<p>&part;2ck
</p>
<p>&part;k21
</p>
<p>]
</p>
<p>d3k.
</p>
<p>An integration by parts combined with the normalization condition for ck shows that
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
2i u1 t c
</p>
<p>&lowast;
k
</p>
<p>&part;ck
</p>
<p>&part;k1
d3k = &minus;i hÌ
</p>
<p>m
t + 2 t
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u1
</p>
<p>(
&part;ak
</p>
<p>&part;k1
bk &minus;
</p>
<p>&part;bk
</p>
<p>&part;k1
ak
</p>
<p>)
</p>
<p>d3k,
</p>
<p>where the second term at the right hand side is real, whereas the first one cancels out
in the expression of ãx21 ã. Finally, another integration by parts yields
</p>
<p>&minus;
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
c&lowast;k
</p>
<p>&part;2ck
</p>
<p>&part;k21
d3k =
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>â£
â£
â£
â£
</p>
<p>&part;ck
</p>
<p>&part;k1
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>d3k.
</p>
<p>In conclusion,
</p>
<p>ãx21 ã =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>â£
â£
â£
â£
u1 t ck + i
</p>
<p>&part;ck
</p>
<p>&part;k1
</p>
<p>â£
â£
â£
â£
</p>
<p>2
</p>
<p>d3k.
</p>
<p>Repeating the calculation for x2 and x3 yields
</p>
<p>ãr &middot; rã =
&int; +&infin;
</p>
<p>&minus;&infin;
</p>
<p>â£
â£u t ck + i gradkck
</p>
<p>â£
â£
2
</p>
<p>d3k,
</p>
<p>where the definition of the squared length of a complex vector is found in (A.2) and
(A.4). The standard deviation of the wave packet in the r space is the positive square
root of ãr &middot; rã &minus; ãrã &middot; ãrã = &sum;3i=1 (ï¿½xi)2, where the expression of ãrã was derived in
Prob. 10.1. It is easily shown that the standard deviation diverges with t . In fact, the
leading term of ãx21 ã and, respectively, ãx1ã2 is
</p>
<p>ãx21 ã &sim; t2
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u21 |ck|2 d3k, ãx1ã2 &sim; t2
</p>
<p>(&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u1 |ck|2 d3k
</p>
<p>)2
</p>
<p>,
</p>
<p>the first of which is positive, whereas the second one is non negative. Letting f = ck,
g = u1ck in the Schwartz inequality (8.15) and using the normalization condition of
ck yields
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u21|ck|2 d3k &gt;
</p>
<p>(&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
u1|ck|2 d3k
</p>
<p>)2
</p>
<p>,
</p>
<p>where the strict inequality holds because f and g are not proportional to each other.
For the leading term it follows that (ï¿½x1)2 = ãx21 ã &minus; ãx1ã2 &sim; const &times; t2, where the
constant is strictly positive. The same reasoning applies to x2, x3. In conclusion, the
standard deviation ï¿½xi associated with the ith coordinate diverges in time with the
first power of t .</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions 637
</p>
<p>10.3 Still with reference to the wave packet of a free particle used in Problems 10.1
and 10.2, the time evolution of the expectation value in the p space is found
starting with the first component p1 of momentum. The corresponding operator
is pÌ1 = &minus;i hÌ &part;/&part;x1, and the following relations are of use: pÌ1wk = hÌ k1 wk,
pÌ21wk = hÌ2 k21 wk. The expectation value ãp1ã = ãÏ |p1|Ïã involves an integration
over r to calculate the scalar product, an integration over k to calculate the integral
expression of Ï , and an integration over k&prime; to calculate the integral expression of
Ï&lowast;. Performing the integration over r first, letting c&prime;k = c(k&prime;), Ï&prime;k = Ï(k&prime;), and using
(C.56) yields
</p>
<p>ãp1ã =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
hÌ k1 |ck|2 d3k = p01.
</p>
<p>The real constant p01 defined above is independent of time. In conclusion, repeating
the calculation for p2 and p3, and letting p0 = (p01,p02,p03), the following holds:
ãpã = p0. If |ck|2 is even with respect to all components of k, the expectation value
of p is zero.
</p>
<p>10.4 The calculation of ãÏ |pÌ21|Ïã is carried out following the same line as in
Problem 10.3, leading to
</p>
<p>ãp21ã =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
hÌ2 k21 |ck|2 d3k.
</p>
<p>Repeating the calculation for x2 and x3 yields
</p>
<p>ãp &middot; pã =
&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
hÌ k &middot; hÌ k |ck|2 d3k.
</p>
<p>In turn, the standard deviation of the wave packet in the p space is the positive square
root of ãp &middot;pã&minus;ãpã &middot; ãpã = &sum;3i=1 (ï¿½pi)2. Letting f = ck, g = hÌk1ck in the Schwartz
inequality (8.15) and using the normalization condition of ck yields
</p>
<p>&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
hÌ2 k21 |ck|2 d3k &gt;
</p>
<p>(&int;&int;&int; +&infin;
</p>
<p>&minus;&infin;
hÌ k1 |ck|2 d3k
</p>
<p>)2
</p>
<p>,
</p>
<p>where the strict inequality holds because f and g are not proportional to each other. It
follows that (ï¿½p1)2 = ãp21ã&minus;ãp1ã2 is strictly positive and constant in time. The same
reasoning applies top2, p3. In conclusion, the standard deviationï¿½pi associated with
the ith component of momentum is constant in time.
</p>
<p>10.5 One finds ãxã = x0, dhÌ Î²/dx = hÌ k0, ãpeã = hÌ k0,
&lang; p2e
</p>
<p>2m
</p>
<p>&rang;
</p>
<p>= hÌ
2 k20
</p>
<p>2m
, ãQã = hÌ
</p>
<p>2
</p>
<p>8mÏ 2
, ãT ã = hÌ
</p>
<p>2
</p>
<p>2m
</p>
<p>(
</p>
<p>k20 +
1
</p>
<p>4 Ï 2
</p>
<p>)
</p>
<p>.
</p>
<p>One notes that for a fixed ãT ã all non-negative values of the &ldquo;convective&rdquo; and &ldquo;ther-
mal&rdquo; parts that add up to ãT ã are allowed. In the particular case of a free particle,
where ãT ã = ãEã, the above shows that different values of the average momentum
and &ldquo;dispersion&rdquo; may combine to yield the same total energy.</p>
<p/>
</div>
<div class="page"><p/>
<p>638 Solutions
</p>
<p>Problems of Chap. 11
</p>
<p>11.1 Letting b&minus; = Ï a
&radic;
</p>
<p>2m (
&radic;
E &minus; &radic;E &minus; V0)/hÌ, b+ = Ï a
</p>
<p>&radic;
2m (
</p>
<p>&radic;
E +&radic;
</p>
<p>E &minus; V0)/hÌ and remembering that sinh b â b when |b| âª 1 yields, with m fixed,
</p>
<p>R(a &rarr; 0) =
(
b&minus;
</p>
<p>b+
</p>
<p>)2
</p>
<p>= (
&radic;
E &minus;&radic;E &minus; V0)2
</p>
<p>(
&radic;
E +&radic;E &minus; V0)2
</p>
<p>,
</p>
<p>that coincides with the first relation in (11.11). Conversely, when a &gt; 0 is fixed and
m is let grow one finds
</p>
<p>R â exp [2 (b&minus; &minus; b+)] = exp
(
</p>
<p>&minus;4Ï a
&radic;
</p>
<p>2m
&radic;
</p>
<p>E &minus; V0/hÌ
)
</p>
<p>,
</p>
<p>namely, limm&rarr;&infin; R = 0, this recovering the classical limit.
11.2 The maximum of the cotangent&rsquo;s argument s
</p>
<p>&radic;
</p>
<p>2m (E &minus; V0)/hÌ2 is found by
letting E = 0. Thus,
</p>
<p>Î³ = s
hÌ
</p>
<p>&radic;
</p>
<p>&minus;2mV0 â 13.4,
13.4
</p>
<p>Ï
â 4.3.
</p>
<p>As a consequence, the cotangent has four complete branches and one incomplete
branch in the interval V0 &lt; E &lt; 0, corresponding to five eigenvalues E1, . . . ,E5.
Using the normalized parameter 0 &lt; Î· = &radic;1 &minus; E/V0 &lt; 1, the equation to be
solved reads
</p>
<p>Î·2 &minus; 1/2
Î·
&radic;
</p>
<p>1 &minus; Î·2
= cot (Î³ Î·) .
</p>
<p>Over the Î· axis, the 5 branches belong to the intervals (0,Ï/Î³ ), (Ï/Î³ , 2Ï/Î³ ),
(2Ï/Î³ , 3Ï/Î³ ), (3Ï/Î³ , 4Ï/Î³ ), (4Ï/Î³ , 1).
</p>
<p>Problems of Chap. 13
</p>
<p>13.1 Letting Z = 1 one finds that the lowest total energy of the electron in the
hydrogen atom has the value
</p>
<p>E1(Z = 1) = &minus;
m0
</p>
<p>2 hÌ2
</p>
<p>(
q2
</p>
<p>4Ï Îµ0
</p>
<p>)2
</p>
<p>.
</p>
<p>As noted in Sect. 13.5.2, the electron is bound as long as E &lt; 0. As a consequence,
the minimum energy for which it becomes free is limn&rarr;&infin; En = 0. The hydrogen
atom&rsquo;s ionization energy is thus found to be
</p>
<p>Eion = 0 &minus; E1(Z = 1) = |E1(Z = 1)| =
m0
</p>
<p>2 hÌ2
</p>
<p>(
q2
</p>
<p>4Ï Îµ0
</p>
<p>)2
</p>
<p>.
</p>
<p>Replacing the constants&rsquo;values of Table D.1 yieldsEion â 2.18&times;10&minus;18 J â 13.6 eV.</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions 639
</p>
<p>13.2 The time-dependent wave function is in this case Ï =
w(Emin) exp (&minus;iEmin t/hÌ), whence |Ï |2 = exp (&minus;2 r/a)/(Ï a3). Taking the
Jacobian determinant J = r2 sin Ï from (B.3) and using the definitions of Sect. 10.5
one finds
</p>
<p>ãrã =
&int; &infin;
</p>
<p>0
</p>
<p>&int; Ï
</p>
<p>0
</p>
<p>&int; 2Ï
</p>
<p>0
r
</p>
<p>exp (&minus;2 r/a)
Ï a3
</p>
<p>r2 sin Ï dr dÏ dÏ = 3
2
a.
</p>
<p>From (13.89) one finds a1 = a(Z = 1) = 4Ï hÌ2 Îµ0/(m0 q2) â 5.3&times;10&minus;11 m â 0.53
&Aring;, where the constants&rsquo; values are taken from Table D.1. Note that a1 = r1/2, with
r1 is the radius of the ground state derived from the Bohr hypothesis (Sect. 7.4.4).
The expectation value of r turns out to be ãrã â 0.8 &Aring;.
</p>
<p>Problems of Chap. 14
</p>
<p>14.1 From h(0)bg = [A/(2Ï )3]/(q2c + q2) and q = |b &minus; g| one finds
</p>
<p>H
(0)
b (Eg) =
</p>
<p>A2
</p>
<p>(2Ï )6
</p>
<p>&int; Ï
</p>
<p>0
</p>
<p>&int; 2Ï
</p>
<p>0
</p>
<p>1
</p>
<p>(q2c + q2)2
sin Ï dÏ dÏ,
</p>
<p>A = Îº Z e2/Îµ0. Observing that b is a fixed vector one can use it as the reference
for angle Ï , so that q2 = (b &minus; g) &middot; (b &minus; g) = b2 + g2 &minus; 2 b g cosÏ . From g = b
it follows q2 = 4 g2 sin2 (Ï/2). On the other hand it is sin Ï dÏ = d sin2 (Ï/2)
whence, integrating over Ï and letting Î¼ = sin2 (Ï/2),
</p>
<p>H
(0)
b (Eg) =
</p>
<p>A2
</p>
<p>(2Ï )5
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>dÎ¼
</p>
<p>(q2c + 4 g2 Î¼)2
= A
</p>
<p>2/(2Ï )5
</p>
<p>q2c (q2c + 4 g2)
.
</p>
<p>The dependence on Eg is found through the relation Eg = hÌ2 g2/(2m).
</p>
<p>Problems of Chap. 15
</p>
<p>15.1 After selecting a number 0 &lt; Î· &lt; 1/2, define E+ and E&minus; such that P (E+) =
Î·, P (E&minus;) = 1 &minus; Î·. It follows
</p>
<p>E+ &minus; E&minus; = 2 kB T log
1 &minus; Î·
Î·
</p>
<p>.
</p>
<p>Letting, e.g., Î· = 0.1 one finds E(P = 0.9) &minus; E(P = 0.1) = 2 kB T log 9 â
4.39 kB T . Similarly, letting Î· = 0.01 one finds E(P = 0.99) &minus; E(P = 0.01) =
2 kB T log 99 â 9.19 kB T . At T = 300 K it is kB T â 25.8 meV. From the above
results one finds E(P = 0.9)&minus;E(P = 0.1) â 113 meV and E(P = 0.99)&minus;E(P =
0.01) â 237 meV, respectively.</p>
<p/>
</div>
<div class="page"><p/>
<p>640 Solutions
</p>
<p>Problems of Chap. 19
</p>
<p>19.1 Using (19.115) and adding up the two expressions in (19.118) one finds
</p>
<p>Î¼p = q
(
</p>
<p>m
1/2
hh
</p>
<p>m
3/2
hh +m
</p>
<p>3/2
hl
</p>
<p>+ m
1/2
hl
</p>
<p>m
3/2
hh +m
</p>
<p>3/2
hl
</p>
<p>)
</p>
<p>Ïp =
q Ïp
</p>
<p>mh
.
</p>
<p>Using the values taken from Table 17.3 yields
</p>
<p>m0
</p>
<p>mh
= 0.5
</p>
<p>1/2
</p>
<p>0.53/2 + 0.163/2 +
0.161/2
</p>
<p>0.53/2 + 0.163/2 ,
</p>
<p>whence mh â 0.377m0. As for ap, using the common value of the relaxation time
in (19.122) yields
</p>
<p>ap =
q Ïp
</p>
<p>Î¼2p
</p>
<p>(
Î¼ph
</p>
<p>mhh
+ Î¼pl
</p>
<p>mhl
</p>
<p>)
</p>
<p>.
</p>
<p>Replacing the expressions (19.118) of Î¼ph, Î¼pl ,
</p>
<p>ap =
m
</p>
<p>3/2
hh +m
</p>
<p>3/2
hl
</p>
<p>m
1/2
hh m
</p>
<p>1/2
hl
</p>
<p>(
</p>
<p>m
1/2
hh +m
</p>
<p>1/2
hl
</p>
<p>) = 0.5
3/2 + 0.163/2
</p>
<p>0.51/2 0.161/2
(
</p>
<p>0.51/2 + 0.161/2
) â 1.33.
</p>
<p>Problems of Chap. 21
</p>
<p>21.1 Using kB T/q â 26 mV (compare with (19.162)) and ni â 1010 cm&minus;3
(Table 18.2), one finds
</p>
<p>Ï0 =
kB T
</p>
<p>q
log
</p>
<p>(
NA ND
</p>
<p>n2i
</p>
<p>)
</p>
<p>â 0.65 V. (D.1)
</p>
<p>21.2 The relations to be used are (21.51), (21.55), and (21.57). If kp = 0, kn &gt; 0,
one finds Yp = 0, Yn = 1 &minus; exp [&minus;m(b)]. On the other hand it is in this case
m(b) =
</p>
<p>&int; b
</p>
<p>a
kn dx &gt; 0, whence Yn &lt; 1. If, instead, kn = 0, kp &gt; 0, one finds
</p>
<p>Yn = 0, Yp = 1 &minus; exp [m(b)] with m(b) = &minus;
&int; b
</p>
<p>a
kp dx &lt; 0, whence Yp &lt; 1. In
</p>
<p>conclusion, the condition for avalanche never occurs.
</p>
<p>Problems of Chap. 22
</p>
<p>22.1 The differential capacitance of the MOS structure, extracted from (22.19) and
(22.20), reads
</p>
<p>C
</p>
<p>Cox
= 1
</p>
<p>1 + Cox/Csc
, Csc = &plusmn;
</p>
<p>&radic;
2 Îµsc
LA
</p>
<p>dF
</p>
<p>dus
&gt; 0,</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions 641
</p>
<p>where the plus (minus) sign holds for us &gt; 0 (us &lt; 0). From (22.3) and (22.5) one
finds dF 2/dus = A(us); on the other hand it is dF 2/dus = 2F dF/dus , whence
</p>
<p>Csc = &plusmn;
Îµsc&radic;
2LA
</p>
<p>A
</p>
<p>F
,
</p>
<p>Cox
</p>
<p>Csc
= &plusmn; F
</p>
<p>r A
, r = Îµsc tox
</p>
<p>Îµox
&radic;
</p>
<p>2LA
.
</p>
<p>Then, the C(VG) relation is found by eliminating us from
</p>
<p>u&prime;G = us &plusmn; 2 r F ,
C
</p>
<p>Cox
= 1
</p>
<p>1 &plusmn; F/(r A) .
</p>
<p>In particular, from (22.26) one finds C(V &prime;G = 0) = Cox/[1 + 1/(
&radic;
</p>
<p>2 r)].
</p>
<p>Problems of Chap. 23
</p>
<p>23.1 The maximum initial profile is N (x = 0, t = 0) = 2Q/&radic;Ïc1. Remembering
(23.26), at the end of the diffusion process the profile has become N (x, t = tP ) =
2Q [Ï (c1+c2)]&minus;1/2&times; exp
</p>
<p>[
</p>
<p>&minus;x2/(c1 + c2)
]
</p>
<p>, whenceN (x = 0, t = tP ) = 2Q [Ï (c1+
c2)]&minus;1/2, with tP the process duration and c2 = 4D tP . From N (x = 0, t = tP ) =
(2/3)N (x = 0, t = 0) it follows 1/&radic;c1 + c2 = 2/(3
</p>
<p>&radic;
c1), c2 = (5/4) c1 and,
</p>
<p>finally, tP = (5/16) (c1/D) = 5,000 s.
23.2 The initial and final profiles areNi(x) = 2Q exp (&minus;x2/c1)/(Ïc1)1/2 and, from
(23.26), Nf (x) = 2Q exp [&minus;x2/(c1 + c2)]/[Ï (c1 + c2)]1/2. Letting Nf = Ni and
defining r = [(c1 + c2)/c1]1/2 and a2 = (c1 + c2) c1/c2 yields r = exp (x2/a2),
whence xÌ = 104 &times; a ( log r)1/2 â 2.68 &micro;m
23.3 Converting to seconds one finds tP = 14,400 s, whence c2 = 4D tP =
14.4 &times; 10&minus;6 cm2. Considering that N (x, t = 0) = 2Q exp (&minus;x2/c1)/(Ïc1)1/2 and,
from (23.26), N (x, t = tP ) = 2Q exp [&minus;x2/(c1 + c2)]/[Ï (c1 + c2)]1/2, the ratio
sought is N (x = 0, t = tP )/N (x = 0, t = 0) = [c1/(c1 + c2)]1/2 = 0.385.
23.4 Due to (23.26), the final profile is Nf = 2Q exp [&minus;x2/(c1 + c2)]/[Ï (c1 +
c2)]1/2. From N (xÌ) = Nf (0) one has exp (&minus;xÌ 2/c1) = [c1/(c1 + c2)]1/2. As a
consequence, the position sought is xÌ = [(c1/2) log (1 + c2/c1)]1/2 = 0.83 &micro;m.
23.5 Due to (23.26) the final profile is Nf = 2Q exp [&minus;x2/(c1 + c2)]/[Ï (c1 +
c2)]1/2. Let Î± = 1.1. From the condition Nf (0) = N (x = Î±
</p>
<p>&radic;
c1) one derives
</p>
<p>1/[Ï (c1+c2)]1/2 = exp (&minus;Î±2)/(Ïc1)1/2, whence c1 = c2/[ exp (2Î±2)&minus;1] = 0.976&times;
10&minus;9 cm2.
</p>
<p>23.6 Letting c2 = 4D t = 2.4 &times; 10&minus;8 cm2 and r = c2/(c1 + c2) = 4/7, one
eliminates Q at x = x0 to find N1/N2 =
</p>
<p>&radic;
1 + r exp [&minus;r x20/(c1 + 2 c2)], whence
</p>
<p>x0 = 104 &times; [(1/r) (c1 + 2 c2) log (
&radic;
</p>
<p>1 + r N2/N1)]1/2 = 4.06 &micro;m.
23.7 Remembering (C.71) one has Q =
</p>
<p>&int;&infin;
0 NS erfc(x/
</p>
<p>&radic;
c) dx = NS
</p>
<p>&radic;
c/Ï ,
</p>
<p>whence c = 4D t = Î»2, t = Î»2/(4D) = 2.99 &times; 1016 nm2 s&minus;1 â 5 min.</p>
<p/>
</div>
<div class="page"><p/>
<p>642 Solutions
</p>
<p>-10 -5 0 5 10
Normalized coordinate
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>1.5
</p>
<p>N
o
</p>
<p>rm
al
</p>
<p>iz
ed
</p>
<p> d
if
</p>
<p>fu
se
</p>
<p>d
 p
</p>
<p>ro
fi
</p>
<p>le 0.01
0.25
1
4
9
</p>
<p>Fig. D.5 Normalized profiles hN/Q resulting from the drive-in diffusion of Problem 23.8. The
coordinate is Î¼ = x/h. Each profile corresponds to the value of b(t) shown in the legend. The
parameter is defined by b = 4 a/h2, while a = a(t) is defined by the second of (23.10). As explained
in Sect. 23.5.2, only the profile&rsquo;s portion on the right of the origin must be considered
</p>
<p>23.8 As indicated in Sect. 23.5.2, the initial profile must preliminarily be mirrored
onto the negative axis with N0 = 2Q (h + x)/h2 for &minus;h &le; x &le; 0 and with
N0 = 0 for x &lt; &minus;h. Then, the profile is obtained from (23.13) as the portion of
N (x) = (2Q/h2) (I&minus; + I+) calculated for x &ge; 0, where
</p>
<p>I&minus; =
&int; 0
</p>
<p>&minus;h
(h+ Î¾ )Î(x &minus; Î¾ , t) dÎ¾ , I+ =
</p>
<p>&int; +h
</p>
<p>0
(h&minus; Î¾ )Î(x &minus; Î¾ , t) dÎ¾
</p>
<p>and Î(x &minus; Î¾ , t) is given by (C.75). Letting Î· = (Î¾ &minus; x)/(4 a)1/2, Î¼ = x/h, b =
4 a/h2, and using (C.66) yields
</p>
<p>N = (Q/h)
[
</p>
<p>(Î¼+ 1)Y&minus; + (Î¼&minus; 1)Y+ &minus; (b/Ï )1/2 (Z&minus; + Z+)
]
</p>
<p>,
</p>
<p>with Yâ = erfc(Î¼/
&radic;
b)&minus; erfc[(Î¼&plusmn; 1)/
</p>
<p>&radic;
b ] and Zâ = exp (&minus;Î¼2/b)&minus; exp [&minus;(Î¼&plusmn;
</p>
<p>1)2/b]. When t &rarr; 0+ it is b &rarr; 0. This makes the Zâ terms to vanish, while the
terms containing Yâ render the initial condition N0. When t &gt; 0 the dose is found
by integrating hN over Î¼ from 0 to +&infin;. A somewhat lengthy calculation based
on the expressions of Appendix C.7 shows that the integral of (b/Ï )1/2 (Z&minus; + Z+)
vanishes whereas that of (Î¼+1)Y&minus;+(Î¼&minus;1)Y+ yields unity. As expected, the result
of the dose calculation is Q. The normalized profile hN/Q is shown in Fig. D.5
as a function of the normalized coordinate Î¼ at different values of the parameter
b = b(t).
</p>
<p>Problems of Chap. 24
</p>
<p>24.1 The relation between time t and oxide thickness s is given by (24.11), s2/cp +
s/cl = t &prime; with t &prime; = t + s2i /cp + si/cl . Solving for s and discarding the negative
solution yields s = [(c2p/c2l +4cpt &prime;)1/2 &minus;cp/cl]/2, with cp/cl = 0.05 &micro;m. It follows
t &prime; = t+ s2i /cp + si/cl â 136/60+0.995+0.237 = 3.50 h and 4cpt &prime; = 0.620 &micro;m2.</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions 643
</p>
<p>The total oxide thickness and the thickness of silicon that is consumed in the second
process are, respectively, s = [(0.052 + 4cpt &prime;)1/2 &minus; 0.05]/2 â 0.369 &micro;m and
h = 0.44 (s &minus; si) â 70 nm.
24.2 The gradient sought is found by remembering that, from (24.10), it is cp =
2 w k0 NG DO and cl = w k0 NG vr , whence cl/cp = vr/(2DO) = 20 &micro;m&minus;1,
vr/DO = 4 &times; 105 cm&minus;1. On the other hand, from (24.7,24.6), &minus;DO gradN =
&minus;DO dN/dx = vrNI whence dN/dx = &minus;NO vr/DO = &minus;4 &times; 1017 cm&minus;4.
24.3 Converting the units one finds cp = 738 nm2 min&minus;1, cl = 14.8 nm min&minus;1.
Letting h be the thickness of silicon consumed one has h = 0.44 (s &minus; si), s =
si + h/0.44 whence, from (24.11), t = (s2 &minus; s2i )/cp + (s &minus; si)/cl = 150 min.
24.4 Converting the units yields cp = 2000 nm2 min&minus;1, cl = 50 nm min&minus;1. From
(24.10) it follows vr/DO = 2cl/cp = 0.05, 1 + s vr/DO = 2 whence, using (24.8),
NI = NO/(1 + s vr/DO) = 15 &times; 1011 cm&minus;3.
24.5 Converting the units yields cp = 11.4 nm2 s&minus;1, cl = 0.237 nm s&minus;1. From
(24.10) the duration of the first process is found as t1 = (s2f &minus; s2i )/cp + (sf &minus; si)/cl .
Similarly, that of the second process is t2 = (s2 &minus; s2f )/cp + (s &minus; sf )/cl . As the
coefficients cp, cl are the same one adds the expressions of t1 and t2 to each other
and lets s = si +Îs1 +Îs2. This yields t1 + t2 = (s2 &minus; s2i )/cp + (s &minus; si)/cl = 202
s.
</p>
<p>24.6 Converting the units yields cl = 16.67 nm min&minus;1. Using the definitions (24.10)
of cp and cl one finds r = DO/vr = cp/(2 cl), whence tP = [(s2 &minus; s2i )/(2r) + s &minus;
si]/cl = 13.9 min.
24.7 Letting t = tP and multiplying the first of (24.10) by cp yields s2 +bs+ c = 0
with b = cp/cl , c = &minus;s2i &minus; (cp/cl) si &minus; cpt . Here si and cptP are given while
cp/cl = 2DO/vr = 2.25 &times; 10&minus;6 cm. Solving for s and discarding the negative root
provides the final thickness s = [(b2 &minus; 4c)1/2 &minus; b]/2 = 76.1 nm.
24.8 From the relation ÎP = s Ïr2 pSi, where ÎP , s are the weight and thickness
of the epitaxial layer, and r the wafer&rsquo;s radius, one finds 2 r = 2&radic;ÎP/(ÏspSi) â
20.4 cm â 8 in.
24.9 The surface concentration NS of SiCl4 is found from the relations s/t = cl =
wF2 = w vr NS , whence NS = s/(w vr t) = 1 &times; 1016 cm&minus;3.
24.10 Using 1/w = 5&times; 1022 cm&minus;3 in the relations (24.22,24.23) yields t = s/cl =
s/(wFI ) = 2 min.
24.11 Letting tP be the duration of the process one has, from (24.22,24.23),
cl = s/tP = w vr NI , whence, using 1 &micro;m = 10&minus;4 cm, vr = s/(wNI tP ) = 200
cm min&minus;1.
</p>
<p>24.12 From (24.21) and the second of (24.23) one finds b = (vr +vG)/(vG wNG) =
(NG/NS) (wNG)&minus;1 = a/(wNG), whence NG = a/(w b) = 2 &times; (5 &times; 1022/4.87 &times;
105) = 2.05 &times; 1017 cm&minus;3.</p>
<p/>
</div>
<div class="page"><p/>
<p>Bibliography
</p>
<p>References
</p>
<p>1. N. D. Arora, J. R. Hauser, and D. J. Roulston. Electron and hole mobilities in silicon as
a function of concentration and temperature. IEEE Transactions on Electron Devices, ED-
29(2):292&ndash;295, Feb. 1982.
</p>
<p>2. N. W. Ashcroft and N. D. Mermin. Solid State Physics. Saunders, 1976.
3. G. Baccarani, M. Rudan, and G. Spadini. Analytical IGFET model including drift and
</p>
<p>diffusion currents. Solid-State and Electron Devices, 2:62&ndash;68, 1978.
4. R. Becker. Electromagnetic Fields and Interactions. Dover, New York, 1982.
5. G. Birkhoff. Tres observaciones sobre el algebra lineal. Univ. Nac. Tucuman Rev. Ser. A,
</p>
<p>5:147&ndash;150, 1946 (in Spanish).
6. J. S. Blakemore. Semiconductor Statistics. Dover, New York, 1987.
7. D. Bohm. Quantum Theory. Dover, New York, 1989.
8. D. Bohm and J. P. Vigier. Model of the causal interpretation of quantum theory in terms of a
</p>
<p>fluid with irregular fluctuations. Phys. Rev., 96(1):208&ndash;216, 1954.
9. M. Born and E. Wolf. Principles of Optics. Pergamon Press, 6th edition, 1980.
</p>
<p>10. A. Bravais. M&eacute;moire sur les syst&egrave;mes form&eacute;s par les points distribu&eacute;s r&eacute;guli&egrave;rement sur
un plan ou dans l&rsquo;espace. J. Ecole Polytech., 19(1):128, 1850 (in French. English version:
Memoir 1, Crystallographic Society of America, 1949).
</p>
<p>11. R. Brunetti, P. Golinelli, L. Reggiani, and M. Rudan. Hot-Carrier Thermal Conductivity for
HydrodynamicAnalyses. In G. Baccarani and M. Rudan, editors, Proc. of the 1996 ESSDERC
Conference, pages 829&ndash;832. Edition Frontiers, 1996.
</p>
<p>12. R. Brunetti, M. C.Vecchi, and M. Rudan. Monte CarloAnalysis ofAnisotropy in the Transport
Relaxation Times for the Hydrodynamic Model. In C. Gardner, editor, Fourth Int. Workshop
on Computational Electronics (IWCE), Phoenix, 1995.
</p>
<p>13. C. Y. Chang and S. M. Sze. ULSI Technology. McGraw-Hill, 1996.
14. A. G. Chynoweth. Ionization Rates for Electrons and Holes in Silicon. Phys. Rev., 109(5):1537,
</p>
<p>March 1958.
15. C. Cohen-Tannoudji, B. Diu, and F. Lalo&euml;. Quantum Mechanics. John Wiley &amp; Sons, New
</p>
<p>York, 1977.
16. L. Colalongo, M. Valdinoci, A. Pellegrini, and M. Rudan. Dynamic Modeling of Amorphous-
</p>
<p>and Polycrystalline-Silicon Devices. IEEE Trans. El. Dev., ED-45:826&ndash;833, 1998.
17. L. Colalongo, M. Valdinoci, and M. Rudan. A Physically-Based Analytical Model for a-Si
</p>
<p>Devices Including Drift and Diffusion Currents. In K. Taniguchi and N. Nakayama, editors,
Simulation of Semiconductor Processes and Devices 1999 (SISPAD), pages 179&ndash;182, Kyoto,
September 1999. IEEE.
</p>
<p>18. L. Colalongo, M. Valdinoci, M. Rudan, and G. Baccarani. Charge-Sheet Analytical Model
for Amorphous Silicon TFTs. In H. E. Maes, R. P. Mertens, G. Declerck, and H. Gr&uuml;nbacher,
</p>
<p>&copy; Springer Science+Business Media New York 2015 645
M. Rudan, Physics of Semiconductor Devices,
DOI 10.1007/978-1-4939-1151-6</p>
<p/>
</div>
<div class="page"><p/>
<p>646 Bibliography
</p>
<p>editors, Proc. of the 29th Solid State Device Research Conference (ESSDERC), pages 244&ndash;
245, Leuven, September 1999. Edition Frontiers.
</p>
<p>19. A. H. Compton. A Quantum Theory of the Scattering of X-Rays by Light Elements. Phys.
Rev., 21(5):483&ndash;502, May 1923.
</p>
<p>20. L. N. Cooper. Bound Electron Pairs in a Degenerate Fermi Gas. Phys. Rev., 104:1189&ndash;1190,
November 1956.
</p>
<p>21. C. R. Crowell. The Richardson constant for thermionic emission in Schottky barrier diodes.
Solid-State Electron., 8(4):395&ndash;399, 1965.
</p>
<p>22. C. G. Darwin and R. H. Fowler. Fluctuations in an Assembly in Statistical Equilibrium. Proc.
Cambridge Phil. Soc., 21 (391):730, 1923.
</p>
<p>23. S. Datta. Quantum Transport: Atom to Transistor. Cambridge University Press, Cambridge,
2006.
</p>
<p>24. L. de Broglie. La m&eacute;canique ondulatoire et la structure atomique de la mati&egrave;re et du
rayonnement. J. Phys. Radium, 8(5):225&ndash;241, 1927 (in French).
</p>
<p>25. L. de Broglie. Interpretation of quantum mechanics by the double solution theory. In Annales
de la Fondation Louis de Broglie, volume 12(4), pages 1&ndash;23. Fondation Louis de Broglie,
1987 (translated from the original 1972 version, in French).
</p>
<p>26. N. G. de Bruijn. Asymptotic Methods in Analysis. Dover, New York, 1981.
27. E. De Castro. Fondamenti di Elettronica&mdash;Fisica elettronica ed elementi di teoria dei
</p>
<p>dispositivi. UTET, Torino, 1975 (in Italian).
28. B. E. Deal and A. S. Grove. General relationship for the thermal oxidation of silicon. J. Appl.
</p>
<p>Phys., 36:3770, 1965.
29. P. Debye and E. H&uuml;ckel. The theory of electrolytes. I. Lowering of freezing point and related
</p>
<p>phenomena. Physikalische Zeitschrift, 24:185&ndash;206, 1923.
30. P. A. M. Dirac. The Quantum Theory of the Emission and Absorption of Radiation. Proc. R.
</p>
<p>Soc. Lond. A, 114:243&ndash;265, 1927.
31. P. A. M. Dirac. The Quantum Theory of the Electron. Proc. R. Soc. Lond. A, 117:610&ndash;624,
</p>
<p>Feb. 1928.
32. P. A. M. Dirac. The Principles of Quantum Mechanics. Oxford University Press, Oxford, 4th
</p>
<p>edition, 1992.
33. H. M. Edwards. Riemann&rsquo;s Zeta Function. Dover, New York, 2001.
34. A. Einstein. &Uuml;ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuris-
</p>
<p>tischen Gesichtspunkt. Annalen der Physik, 17(6):132&ndash;148, 1905 (in German). English
translation: D. ter Haar, The Old Quantum Theory, Pergamon Press, 91&ndash;107, 1967.
</p>
<p>35. A. Einstein. On the Movement of Small Particles Suspended in a Stationary Liquid Demanded
by the Molecular-Kinetic Theory of Heat. In Investigations on the theory of the Brownian
movement, chapter 1. Dover, New York, 1956.
</p>
<p>36. A. Fick. &Uuml;ber Diffusion. Ann. der Physik, 94:59&ndash;86, 1855 (in German). Phil. Mag. 10, 30,
1855 (in English).
</p>
<p>37. G. Floquet. Sur les &eacute;quations diff&eacute;rentielles lin&eacute;aires &agrave; coefficients p&eacute;riodiques. Annales
Scientifiques de l&rsquo;Ec. Norm. Sup., 12(2):47&ndash;88, 1883 (in French).
</p>
<p>38. A. Forghieri, R. Guerrieri, P. Ciampolini, A. Gnudi, M. Rudan, and G. Baccarani. A new
discretization strategy of the semiconductor equations comprising momentum and energy
balance. IEEE Trans. on CAD ICAS, 7(2):231&ndash;242, 1988.
</p>
<p>39. D. H. Frisch and L. Wilets. Development of the Maxwell-Lorentz Equations from Special
Relativity and Gauss&rsquo;s Law. Am. J. Phys., 24:574&ndash;579, 1956.
</p>
<p>40. A. Gnudi, F. Odeh, and M. Rudan. Investigation of non-local transport phenomena in small
semiconductor devices. European Trans. on Telecommunications and Related Technologies,
1(3):307&ndash;312 (77&ndash;82), 1990.
</p>
<p>41. I. I. Gol&rsquo;dman and V. D. Krivchenkov. Problems in Quantum Mechanics. Pergamon Press,
London, 1961.
</p>
<p>42. H. Goldstein, C. Poole, and J. Safko. Classical Mechanics. Addison Wesley, third edition,
2002.</p>
<p/>
</div>
<div class="page"><p/>
<p>Bibliography 647
</p>
<p>43. P. Golinelli, R. Brunetti, L. Varani, L. Reggiani, and M. Rudan. Monte Carlo Calculation
of Hot-Carrier Thermal Conductivity in Semiconductors. In K. Hess, J. P. Leburton, and U.
Ravaioli, editors, Proc. of the Ninth Intl. Conf. on Hot Carriers in Semiconductors (HCIS-IX),
pages 405&ndash;408, Chicago, 1995. Plenum Press, New York.
</p>
<p>44. I. S. Gradshteyn and I. M. Ryzhik. Table of Integrals, Series, and Products. Academic Press,
New York, 1980.
</p>
<p>45. T. Grasser, R. Korsik, C. Jungemann, H. Kosina, and S. Selberherr. &ldquo;A non-parabolic six
moments model for the simulation of sub-100nm semiconductor devices&rdquo;. J. of Comp.
Electronics, 3:183&ndash;187, 2004.
</p>
<p>46. A. S. Grove. Physics and Technology of Semiconductor Devices. J. Wiley &amp; Sons, 1967.
47. G. Hardy, J. E. Littlewood, and G. P&oacute;lya. Inequalities. Cambridge University Press,
</p>
<p>Cambridge, second edition, 1952.
48. W. Heisenberg. &Uuml;ber den anschaulichen Inhalt der quantentheoretischen Kinematik und
</p>
<p>Mechanik. Zeitschrift f&uuml;r Physik, 43:172&ndash;198, 1927 (in German). English translation: J.
A. Wheeler and H. Zurek, Quantum Theory and Measurement, Princeton Univ. Press, 62&ndash;84,
1983.
</p>
<p>49. S.-M. Hong, A.-T. Pham, and C. Jungemann. Deterministic Solvers for the Boltzmann
Transport Equation. Computational Microelectronics, S. Selberherr, Ed. Springer Verlag,
Wien-New York, 2011.
</p>
<p>50. K. Huang. Statistical Mechanics. Wiley, New York, second edition, 1987.
51. E. L. Ince. Ordinary Differential Equations. Dover, New York, 1956.
52. L. Infeld. On a New Treatment of Some Eingenvalue Problems. Phys. Rev., 59:737&ndash;747,
</p>
<p>1941.
53. J. D. Jackson. Classical Electrodynamics. John Wiley &amp; Sons, New York, second edition,
</p>
<p>1975.
54. C. Jacoboni. Theory of Electron Transport in Semiconductors. Springer, New York, first
</p>
<p>edition, 2010.
55. C. Jacoboni, R. Brunetti, and P. Bordone. Theory of Transport Properties of Semiconductor
</p>
<p>Nanostructures, volume 4 of Electronics materials, E. Sch&ouml;ll, Ed., chapter 3 &ldquo;Monte Carlo
simulation of semiconductor transport&rdquo;, pages 59&ndash;101. Chapman and Hall, first edition, 1998.
</p>
<p>56. C. Jacoboni and P. Lugli. The Monte Carlo Method for Semiconductor Device Simulation.
Computational Microelectronics, S. Selberherr, Ed. Springer Verlag, Wien-New York, 1989.
</p>
<p>57. C. Jacoboni and L. Reggiani. The Monte Carlo method for the solution of charge transport in
semiconductors with applications to covalent materials. Rev. Mod. Phys., 55:645&ndash;705, 1983.
</p>
<p>58. W. Jones and N. H. March. Theoretical Solid State Physics. Dover, 1973.
59. C. Jungemann, M. Bollh&ouml;fer, and B. Meinerzhagen. Convergence of the Legendre Polynomial
</p>
<p>Expansion of the Boltzmann Equation for Nanoscale Devices. In G. Ghibaudo, T. Skotnicki,
S. Cristoloveanu, and M. Brillou&euml;t, editors, Proc. of the 35th Solid State Device Research
Conference (ESSDERC), pages 341&ndash;344, Grenoble, September 2005.
</p>
<p>60. M. Kac. Some remarks on the use of probability in classical statistical mechanics. Acad. Roy.
Belg. Bull. Cl. Sci. (5), 42:356&ndash;361, 1956.
</p>
<p>61. E. H. Kennard. Zur quantenmechanik einfacher bewegungstypen. Zeitschrift f&uuml;r Physik,
44:326, 1927 (in German).
</p>
<p>62. P. Kir&eacute;ev. La Physique des Semiconducteurs. MIR, Moscou, 1975 (in French).
63. C. Kittel. Introduction to Solid State Physics. J. Wiley &amp; Sons, New York, seventh edition,
</p>
<p>1953.
64. D. B. M. Klaassen. A unified mobility model for device simulation&mdash;I. Model equations and
</p>
<p>concentration dependence. Solid-State Electr., 35(7):953&ndash;959, 1992.
65. C. Lanczos. The Variational Principles in Mechanics. Dover, NewYork, fourth edition, 1970.
66. L. Landau and E. Lifchitz. Physique statistique. MIR, Moscou, 1967 (in French).
67. L. Landau and E. Lifchitz. M&eacute;canique. MIR, Moscou, 1969 (in French).
68. L. Landau and E. Lifchitz. Th&eacute;orie des Champs. MIR, Moscou, 1970 (in French).
69. A. Land&eacute;. New Foundations of Quantum Mechanics. Cambridge University Press, 1965.</p>
<p/>
</div>
<div class="page"><p/>
<p>648 Bibliography
</p>
<p>70. A. Land&eacute;. Solution of the Gibbs Entropy Paradox. Philosophy of Science, 32(2):192&ndash;193,
April 1965.
</p>
<p>71. ed. Levy, R. A. Microelectronics Materials and Processes, volume E-164 of NATO ASI.
Kluwer, 1986.
</p>
<p>72. M. J. Lighthill. Fourier Analysis and Generalized Functions. Cambridge University Press,
Cambridge, 1962.
</p>
<p>73. C. Lombardi, S. Manzini, A. Saporito, and M. Vanzi. A physically based mobility model for
numerical simulation of nonplanar devices. IEEE Transaction on CAD, 7(11):1164&ndash;1171,
novembre 1988.
</p>
<p>74. A. M. Lyapounov. Probl&egrave;me G&eacute;n&eacute;ral de la Stabilit&eacute; du Mouvement. Ann. Fac. Sc. Univ.
Toulouse, 9(2):203&ndash;475, 1907 (in French).
</p>
<p>75. W. Maly. Atlas of IC Technologies: an Introduction to VLSI Processes. The Ben-
jamin/Cummings Publishing Co., 1987.
</p>
<p>76. M. Marcus and H. Minc. A Survey of Matrix Theory and Matrix Inequalities. Dover, 1992.
77. E. Merzbacher. Quantum Mechanics. J. Wiley &amp; Sons, New York, 1970.
78. A. Messiah. M&eacute;canique Quantique. Dunod, Paris, 1969 (in French. English edition: Quantum
</p>
<p>Mechanics, Dover, New York, 1999).
79. M. Muskat and E. Hutchisson. Symmetry of the Transmission Coefficients for the Passage
</p>
<p>of Particles through Potential Barriers. Proc. of the Nat. Academy of Sciences of the USA,
23:197&ndash;201, April 15 1937.
</p>
<p>80. D. A. Neamen. Semiconductor Physics and Devices. Irwin, 1992.
81. W. Pauli. The Connection Between Spin and Statistics. Phys. Rev., 58:716&ndash;722, October
</p>
<p>1940.
82. M. Planck. On an Improvement of Wien&rsquo;s Equation for the Spectrum. In The Old Quantum
</p>
<p>Theory, page 79. Pergamon Press, 1967.
83. S. Reggiani, M. Rudan, E. Gnani, and G. Baccarani. Investigation about the high-temperature
</p>
<p>impact-ionization coefficient in silicon. In R. P. Mertens and Cor L. Claeys, editors, Proc.
of the 34th Solid State Device Research Conference (ESSDERC), pages 245&ndash;248, Leuven,
September 21&ndash;23 2004. IEEE.
</p>
<p>84. S. Reggiani, M. C. Vecchi, A. Greiner, and M. Rudan. Modeling hole surface- and bulk-
mobility in the frame of a spherical-harmonics solution of the BTE. In K. De Meyer and
S. Biesemans, editors, Simulation of Semiconductor Processes and Devices 1998 (SISPAD),
pages 316&ndash;319. Springer-Verlag, Wien, Austria, 1998.
</p>
<p>85. F. Reif. Fundamentals of Statistical and Thermal Physics. McGraw-Hill, New York, 1985.
86. M. Rudan and G. Baccarani. On the structure and closure condition of the hydrodynamic
</p>
<p>model. VLSI Design (Special Issue, J. Jerome, Ed.), 3(2):115&ndash;129, 1995.
87. M. Rudan, E. Gnani, S. Reggiani, and G. Baccarani. The density-gradient correction as a
</p>
<p>disguised pilot wave of de Broglie. In G. Wachutka and G. Schrag, editors, Simulation of
Semiconductor Processes and Devices 2004 (SISPAD), pages 13&ndash;16, Munich, September
2&ndash;4 2004. Springer.
</p>
<p>88. M. Rudan, A. Gnudi, E. Gnani, S. Reggiani, and G. Baccarani. Improving the Accuracy
of the Schr&ouml;dinger-Poisson Solution in CNWs and CNTs. In G. Baccarani and M. Rudan,
editors, Simulation of Semiconductor Processes and Devices 2010 (SISPAD), pages 307&ndash;310,
Bologna, September 6&ndash;8 2010. IEEE.
</p>
<p>89. M. Rudan, A. Gnudi, and W. Quade. Process and Device Modeling for Microelectronics, chap-
ter 2 &ldquo;A Generalized Approach to the Hydrodynamic Model of Semiconductor Equations&rdquo;,
pages 109&ndash;154. G. Baccarani, Ed. Elsevier, 1993.
</p>
<p>90. M. Rudan, M. Lorenzini, and R. Brunetti. Theory of Transport Properties of Semiconductor
Nanostructures, volume 4 of Electronics materials, E. Sch&ouml;ll, Ed., chapter 2 &ldquo;Hydrodynamic
simulation of semiconductor devices&rdquo;, pages 27&ndash;57. Chapman and Hall, first edition, 1998.
</p>
<p>91. M. Rudan and F. Odeh. Multi-dimensional discretization scheme for the hydrodynamic model
of semiconductor devices. COMPEL, 5(3):149&ndash;183, 1986.
</p>
<p>92. M. Rudan, F. Odeh, and J. White. Numerical solution of the hydrodynamic model for a
one-dimensional semiconductor device. COMPEL, 6(3):151&ndash;170, 1987.</p>
<p/>
</div>
<div class="page"><p/>
<p>Bibliography 649
</p>
<p>93. M. Rudan, M. C. Vecchi, and D. Ventura. Mathematical problems in semiconductor physics,
chapter &ldquo;The Hydrodynamic Model in Semiconductors &mdash; Coefficient Calculation for the
Conduction Band of Silicon&rdquo;, pages 186&ndash;214. Number 340 in Pitman Research Notes in
Mathematical Series P. Marcati, P. A. Markowich, R. Natalini, Eds. Longman, 1995.
</p>
<p>94. E. Schr&ouml;dinger. Quantisierung als eigenwertproblem (erste mitteilung). Annalen der Physik,
384(4):361&ndash;376, 1926 (in German).
</p>
<p>95. E. Schr&ouml;dinger. Statistical Thermodynamics. Dover, New York, 1989.
96. M. Schwartz. Principles of Electrodynamics. Dover, New York, 1987.
97. W. Shockley. The Theory of p-n Junctions in Semiconductors and p-n Junction Transistors.
</p>
<p>Bell Syst. Tech. J., 28:435, 1949.
98. W. Shockley. Electrons and Holes in Semiconductors. Van Nostrand Book Co., 1950.
99. J. C. Slater. Quantum Theory of Matter. McGraw-Hill, New York, 1968.
</p>
<p>100. J. W. Slotboom and H. C. DeGraaff. Measurement of bandgap narrowing in silicon bipolar
transistors. Solid-State Electron., 19(2):857&ndash;862, 1976.
</p>
<p>101. J. W. Slotboom and H. C. DeGraaff. Bandgap narrowing in silicon bipolar transistors. IEEE
Trans. El. Dev., 28(8):1123&ndash;1125, August 1977.
</p>
<p>102. J. C. F. Sturm. M&eacute;moire sur les &eacute;quations diff&eacute;rentielles lin&eacute;aires du deuxi&egrave;me ordre. Journal
de Math&eacute;matiques Pures et Appliqu&eacute;es, 1:106&ndash;186, 1836 (in French).
</p>
<p>103. S. M. Sze. Physics of Semiconductor Devices. John Wiley &amp; Sons, NewYork, 1981.
104. S. M. Sze. Semiconductor Devices&mdash;Physics and Technology. J. Wiley &amp; Sons, 1985.
105. S. M. Sze. VLSI Technology. McGraw-Hill, 1988.
106. S. Takagi, A. Toriumi, M. Iwase, and H. Tango. On the Universality of Inversion Layer
</p>
<p>Mobility in Si MOSFET&rsquo;s: Part I&mdash;Effects of Substrate Impurity Concentration. IEEE Trans.
El. Dev., 41(12):2357&ndash;2362, December 1994.
</p>
<p>107. D. ter Haar. On a Heuristic Point of View about the Creation and Conversion of Light. In The
Old Quantum Theory, pages 91&ndash;107. Pergamon Press, 1967.
</p>
<p>108. R. Thoma, A. Emunds, B. Meinerzhagen, H.-J. Peifer, and W. L. Engl. Hydrodynamic
Equations for Semiconductors with Nonparabolic Band Structure. IEEE Trans. El. Dev.,
38(6):1343&ndash;1353, 1991.
</p>
<p>109. R. C. Tolman. Note on the Derivation from the Principle of Relativity of the Fifth Fundamental
Equation of the Maxwell-Lorentz Theory. Phil. Mag. S. 6, 21(123):296&ndash;301, 1911.
</p>
<p>110. R. C. Tolman. Statistical Mechanics. Dover, NewYork, 1979.
111. M. Valdinoci, D. Ventura, M. C. Vecchi, M. Rudan, G. Baccarani, F. Illien, A. Stricker, and
</p>
<p>L. Zullino. Impact-ionization in silicon at large operating temperature. In K. Taniguchi and
N. Nakayama, editors, Simulation of Semiconductor Processes and Devices 1999 (SISPAD),
pages 27&ndash;30, Kyoto, September 1999. IEEE.
</p>
<p>112. M. C. Vecchi and M. Rudan. Modeling Electron and Hole Transport with Full-Band Structure
Effects by Means of the Spherical-Harmonics Expansion ot the BTE. IEEE Trans. El. Dev.,
45(1):230&ndash;238, 1998.
</p>
<p>113. G. H. Wannier. Statistical Physics. Dover, NewYork, 1996.
114. J. Ward Brown and R. V. Churchill. Complex Variables and Applications. McGraw-Hill,
</p>
<p>NewYork, 1996.
115. R. Weinstock. Calculus of Variations. Dover, NewYork, 1974.
116. H. Weyl. Quantenmechanik und gruppentheorie. Zeitschrift f&uuml;r Physik, 46(1&ndash;2):1&ndash;46, 1927
</p>
<p>(in German).
117. J. A. Wheeler and W. H. Zurek. Quantum Theory and Measurement, pages 62&ndash;84. Princeton
</p>
<p>Univ. Press, 1983.
118. N. Wiener. The Fourier Integral and Certain of Its Applications. Dover, NewYork, 1958.</p>
<p/>
</div>
<ul>	<li>Preface</li>
	<li>Contents</li>
	<li>Acronyms</li>
	<li>List of Tables</li>
	<li>Part I A Review of Analytical Mechanics and Electromagnetism</li>
<ul>	<li>Chapter 1 Analytical Mechanics</li>
<ul>	<li>1.1 Introduction</li>
	<li>1.2 Variational Calculus</li>
	<li>1.3 Lagrangian Function</li>
<ul>	<li>1.3.1 Force Deriving from a Potential Energy</li>
	<li>1.3.2 Electromagnetic Force</li>
	<li>1.3.3 Work</li>
	<li>1.3.4 Hamilton Principle---Synchronous Trajectories</li>
</ul>
	<li>1.4 Generalized Coordinates</li>
	<li>1.5 Hamiltonian Function</li>
	<li>1.6 Hamilton Equations</li>
	<li>1.7 Time--Energy Conjugacy---Hamilton--Jacobi Equation</li>
	<li>1.8 Poisson Brackets</li>
	<li>1.9 Phase Space and State Space</li>
	<li>1.10 Complements</li>
<ul>	<li>1.10.1 Higher-Order Variational Calculus</li>
	<li>1.10.2 Lagrangian Invariance and Gauge Invariance</li>
	<li>1.10.3 Variational Calculus with Constraints</li>
	<li>1.10.4 An Interesting Example of Extremum Equation</li>
	<li>1.10.5 Constant-Energy Surfaces</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 2 Coordinate Transformations and Invariance Properties</li>
<ul>	<li>2.1 Introduction</li>
	<li>2.2 Canonical Transformations</li>
	<li>2.3 An Application of the Canonical Transformation</li>
	<li>2.4 Separation---Hamilton's Characteristic Function</li>
	<li>2.5 Phase Velocity</li>
	<li>2.6 Invariance Properties</li>
<ul>	<li>2.6.1 Time Reversal</li>
	<li>2.6.2 Translation of Time</li>
	<li>2.6.3 Translation of the Coordinates</li>
	<li>2.6.4 Rotation of the Coordinates</li>
</ul>
	<li>2.7 Maupertuis Principle</li>
	<li>2.8 Spherical Coordinates---Angular Momentum</li>
	<li>2.9 Linear Motion</li>
	<li>2.10 Action-Angle Variables</li>
	<li>2.11 Complements</li>
<ul>	<li>2.11.1 Infinitesimal Canonical Transformations</li>
	<li>2.11.2 Constants of Motion</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 3 Applications of the Concepts of Analytical Mechanics</li>
<ul>	<li>3.1 Introduction</li>
	<li>3.2 Particle in a Square Well</li>
	<li>3.3 Linear Harmonic Oscillator</li>
	<li>3.4 Central Motion</li>
	<li>3.5 Two-Particle Collision</li>
	<li>3.6 Energy Exchange in the Two-Particle Collision</li>
	<li>3.7 Central Motion in the Two-Particle Interaction</li>
	<li>3.8 Coulomb Field</li>
	<li>3.9 System of Particles near an Equilibrium Point</li>
	<li>3.10 Diagonalization of the Hamiltonian Function</li>
	<li>3.11 Periodic Potential Energy</li>
	<li>3.12 Energy-Momentum Relation in a Periodic Potential Energy</li>
	<li>3.13 Complements</li>
<ul>	<li>3.13.1 Comments on the Linear Harmonic Oscillator</li>
	<li>3.13.2 Degrees of Freedom and Coordinate Separation</li>
	<li>3.13.3 Comments on the Normal Coordinates</li>
	<li>3.13.4 Areal Velocity in the Central-Motion Problem</li>
	<li>3.13.5 Initial Conditions in the Central-Motion Problem</li>
	<li>3.13.6 The Coulomb Field in the Attractive Case</li>
	<li>3.13.7 Dynamic Relations of Special Relativity</li>
	<li>3.13.8 Collision of Relativistic Particles</li>
	<li>3.13.9 Energy Conservation in Charged-Particles' Interaction</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 4 Electromagnetism</li>
<ul>	<li>4.1 Introduction</li>
	<li>4.2 Extension of the Lagrangian Formalism</li>
	<li>4.3 Lagrangian Function for the Wave Equation</li>
	<li>4.4 Maxwell Equations</li>
	<li>4.5 Potentials and Gauge Transformations</li>
	<li>4.6 Lagrangian Density for the Maxwell Equations</li>
	<li>4.7 Helmholtz Equation</li>
	<li>4.8 Helmholtz Equation in a Finite Domain</li>
	<li>4.9 Solution of the Helmholtz Equation in an Infinite Domain</li>
	<li>4.10 Solution of the Wave Equation in an Infinite Domain</li>
	<li>4.11 Lorentz Force</li>
	<li>4.12 Complements</li>
<ul>	<li>4.12.1 Invariance of the Euler Equations</li>
	<li>4.12.2 Wave Equations for the E and B Fields</li>
	<li>4.12.3 Comments on the Boundary-Value Problem</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 5 Applications of the Concepts of Electromagnetism</li>
<ul>	<li>5.1 Introduction</li>
	<li>5.2 Potentials Generated by a Point-Like Charge</li>
	<li>5.3 Energy Continuity---Poynting Vector</li>
	<li>5.4 Momentum Continuity</li>
	<li>5.5 Modes of the Electromagnetic Field</li>
	<li>5.6 Energy of the Electromagnetic Field in Terms of Modes</li>
	<li>5.7 Momentum of the Electromagnetic Field in Terms of Modes</li>
	<li>5.8 Modes of the Electromagnetic Field in an Infinite Domain</li>
	<li>5.9 Eikonal Equation</li>
	<li>5.10 Fermat Principle</li>
	<li>5.11 Complements</li>
<ul>	<li>5.11.1 Fields Generated by a Point-Like Charge</li>
	<li>5.11.2 Power Radiated by a Point-Like Charge</li>
	<li>5.11.3 Decay of Atoms According to the Classical Model</li>
	<li>5.11.4 Comments about the Field's Expansion into Modes</li>
	<li>5.11.5 Finiteness of the Total Energy</li>
	<li>5.11.6 Analogies between Mechanics and Geometrical Optics</li>
</ul>
	<li>Problems</li>
</ul>
</ul>
	<li>Part II Introductory Concepts to Statistical and Quantum Mechanics</li>
<ul>	<li>Chapter 6 Classical Distribution Function and Transport Equation</li>
<ul>	<li>6.1 Introduction</li>
	<li>6.2 Distribution Function</li>
	<li>6.3 Statistical Equilibrium</li>
	<li>6.4 Maxwell-Boltzmann Distribution</li>
	<li>6.5 Boltzmann Transport Equation</li>
	<li>6.6 Complements</li>
<ul>	<li>6.6.1 Momentum and Angular Momentum at Equilibrium</li>
	<li>6.6.2 Averages Based on the Maxwell-Boltzmann Distribution</li>
	<li>6.6.3 Boltzmann's H-Theorem</li>
	<li>6.6.4 Paradoxes --- Kac-Ring Model</li>
	<li>6.6.5 Equilibrium Limit of the Boltzmann Transport Equation</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 7 From Classical Mechanics to Quantum Mechanics</li>
<ul>	<li>7.1 Introduction</li>
	<li>7.2 Planetary Model of the Atom</li>
	<li>7.3 Experiments Contradicting the Classical Laws</li>
	<li>7.4 Quantum Hypotheses</li>
<ul>	<li>7.4.1 Planck's Solution of the Black-Body Problem</li>
	<li>7.4.2 Einstein's Solution of the Photoelectric Effect</li>
	<li>7.4.3 Explanation of the Compton Effect</li>
	<li>7.4.4 Bohr's Hypothesis</li>
	<li>7.4.5 De Broglie's Hypothesis</li>
</ul>
	<li>7.5 Heuristic Derivation of the Schr&ouml;dinger Equation</li>
	<li>7.6 Measurement</li>
<ul>	<li>7.6.1 Probabilities</li>
	<li>7.6.2 Massive Bodies</li>
	<li>7.6.3 Need of a Description of Probabilities</li>
</ul>
	<li>7.7 Born's Interpretation of the Wave Function</li>
	<li>7.8 Complements</li>
<ul>	<li>7.8.1 Core Electrons</li>
</ul>
</ul>
	<li>Chapter 8 Time-Independent Schr&ouml;dinger Equation</li>
<ul>	<li>8.1 Introduction</li>
	<li>8.2 Properties of the Time-Independent Schr&ouml;dinger Equation</li>
<ul>	<li>8.2.1 Schr&ouml;dinger Equation for a Free Particle</li>
	<li>8.2.2 Schr&ouml;dinger Equation for a Particle in a Box</li>
	<li>8.2.3 Lower Energy Bound in the Schr&ouml;dinger Equation</li>
</ul>
	<li>8.3 Norm of a Function---Scalar Product</li>
<ul>	<li>8.3.1 Adjoint Operators and Hermitean Operators</li>
</ul>
	<li>8.4 Eigenvalues and Eigenfunctions of an Operator</li>
<ul>	<li>8.4.1 Eigenvalues of Hermitean Operators</li>
	<li>8.4.2 Gram--Schmidt Orthogonalization</li>
	<li>8.4.3 Completeness</li>
	<li>8.4.4 Parseval Theorem</li>
</ul>
	<li>8.5 Hamiltonian Operator and Momentum Operator</li>
	<li>8.6 Complements</li>
<ul>	<li>8.6.1 Examples of Hermitean Operators</li>
	<li>8.6.2 A Collection of Operators' Definitions and Properties</li>
	<li>8.6.3 Examples of Commuting Operators</li>
	<li>8.6.4 Momentum and Energy of a Free Particle</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 9 Time-Dependent Schr&ouml;dinger Equation</li>
<ul>	<li>9.1 Introduction</li>
	<li>9.2 Superposition Principle</li>
	<li>9.3 Time-Dependent Schr&ouml;dinger Equation</li>
	<li>9.4 Continuity Equation and Norm Conservation</li>
	<li>9.5 Hamiltonian Operator of a Charged Particle</li>
	<li>9.6 Approximate Form of the Wave Packet for a Free Particle</li>
	<li>9.7 Complements</li>
<ul>	<li>9.7.1 About the Units of the Wave Function</li>
	<li>9.7.2 An Application of the Semiclassical Approximation</li>
	<li>9.7.3 Polar Form of the Schr&ouml;dinger Equation</li>
	<li>9.7.4 Effect of a Gauge Transformation on the Wave Function</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 10 General Methods of Quantum Mechanics</li>
<ul>	<li>10.1 Introduction</li>
	<li>10.2 General Methods</li>
	<li>10.3 Separable Operators</li>
	<li>10.4 Eigenfunctions of Commuting Operators</li>
	<li>10.5 Expectation Value and Uncertainty</li>
	<li>10.6 Heisenberg Uncertainty Relation</li>
	<li>10.7 Time Derivative of the Expectation Value</li>
	<li>10.8 Ehrenfest Theorem</li>
	<li>10.9 Complements</li>
<ul>	<li>10.9.1 Minimum-Uncertainty Wave Function</li>
</ul>
	<li>Problems</li>
</ul>
</ul>
	<li>Part III Applications of the Schr&ouml;dinger Equation</li>
<ul>	<li>Chapter 11 Elementary Cases</li>
<ul>	<li>11.1 Introduction</li>
	<li>11.2 Step-Like Potential Energy</li>
<ul>	<li>11.2.1 Case A: 0 &lt; E &lt; V0</li>
	<li>11.2.2 Case B: E &gt; V0</li>
</ul>
	<li>11.3 Energy Barrier</li>
<ul>	<li>11.3.1 Case A: 0 &lt; E &lt; V0</li>
	<li>11.3.2 Case B: 0 &lt; V0 &lt; E</li>
</ul>
	<li>11.4 Energy Barrier of a General Form</li>
	<li>11.5 Energy Well</li>
	<li>Problems</li>
</ul>
	<li>Chapter 12 Cases Related to the Linear Harmonic Oscillator</li>
<ul>	<li>12.1 Introduction</li>
	<li>12.2 Linear Harmonic Oscillator</li>
	<li>12.3 Quantization of the Electromagnetic Field's Energy</li>
	<li>12.4 Quantization of the Electromagnetic Field's Momentum</li>
	<li>12.5 Quantization of a Diagonalized Hamiltonian Function</li>
	<li>12.6 Complements</li>
<ul>	<li>12.6.1 Comments About the Linear Harmonic Oscillator</li>
</ul>
</ul>
	<li>Chapter 13 Other Examples of the Schr&ouml;dinger Equation</li>
<ul>	<li>13.1 Introduction</li>
	<li>13.2 Properties of the One-Dimensional Schr&ouml;dinger Equation</li>
	<li>13.3 Localized States---Operator's Factorization</li>
<ul>	<li>13.3.1 Factorization Method</li>
	<li>13.3.2 First-Order Operators</li>
	<li>13.3.3 The Eigenfunctions Corresponding to l&lt;n</li>
	<li>13.3.4 Normalization</li>
</ul>
	<li>13.4 Schr&ouml;dinger Equation with a Periodic Coefficient</li>
	<li>13.5 Schr&ouml;dinger Equation for a Central Force</li>
<ul>	<li>13.5.1 Angular Part of the Equation</li>
	<li>13.5.2 Radial Part of the Equation in the Coulomb Case</li>
</ul>
	<li>13.6 Complements</li>
<ul>	<li>13.6.1 Operators Associated to Angular Momentum</li>
	<li>13.6.2 Eigenvalues of the Angular Equation</li>
	<li>13.6.3 Eigenfunctions of the Angular Equation</li>
	<li>13.6.4 Eigenvalues of the Radial Equation---Coulomb Case</li>
	<li>13.6.5 Eigenfunctions of the Radial Equation---Coulomb Case</li>
	<li>13.6.6 Transmission Matrix</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 14 Time-Dependent Perturbation Theory</li>
<ul>	<li>14.1 Introduction</li>
	<li>14.2 Discrete Eigenvalues</li>
	<li>14.3 First-Order Perturbation</li>
	<li>14.4 Comments</li>
	<li>14.5 Degenerate Energy Levels</li>
	<li>14.6 Continuous Energy Levels</li>
	<li>14.7 Screened Coulomb Perturbation</li>
	<li>14.8 Complements</li>
<ul>	<li>14.8.1 Perturbation Constant in Time</li>
	<li>14.8.2 Harmonic Perturbation</li>
	<li>14.8.3 Fermi's Golden Rule</li>
	<li>14.8.4 Transitions from Discrete to Continuous Levels</li>
</ul>
	<li>Problems</li>
</ul>
</ul>
	<li>Part IV Systems of Interacting Particles---Quantum Statistics</li>
<ul>	<li>Chapter 15 Many-Particle Systems</li>
<ul>	<li>15.1 Introduction</li>
	<li>15.2 Wave Function of a Many-Particle System</li>
	<li>15.3 Symmetry of Functions and Operators</li>
	<li>15.4 Conservation of Symmetry in Time</li>
	<li>15.5 Identical Particles</li>
<ul>	<li>15.5.1 Spin</li>
</ul>
	<li>15.6 Pauli Exclusion Principle</li>
	<li>15.7 Conservative Systems of Particles</li>
	<li>15.8 Equilibrium Statistics in the Quantum Case</li>
<ul>	<li>15.8.1 Fermi--Dirac Statistics</li>
	<li>15.8.2 Bose--Einstein Statistics</li>
</ul>
	<li>15.9 Complements</li>
<ul>	<li>15.9.1 Connection with Thermodynamic Functions</li>
	<li>15.9.2 Density of States for a Particle in a Three-Dimensional Box</li>
	<li>15.9.3 Density of States for a Two- or One-Dimensional Box</li>
	<li>15.9.4 Density of States for Photons</li>
	<li>15.9.5 Derivation of Planck's Law</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 16 Separation of Many-Particle Systems</li>
<ul>	<li>16.1 Introduction</li>
	<li>16.2 System of Interacting Electrons and Nuclei</li>
	<li>16.3 Adiabatic Approximation</li>
	<li>16.4 Hartree Equations</li>
	<li>16.5 Hartree--Fock Equations</li>
	<li>16.6 Schr&ouml;dinger Equation for the Nuclei</li>
	<li>16.7 Complements</li>
<ul>	<li>16.7.1 Ritz Method</li>
</ul>
</ul>
</ul>
	<li>Part V Applications to Semiconducting Crystals</li>
<ul>	<li>Chapter 17 Periodic Structures</li>
<ul>	<li>17.1 Introduction</li>
	<li>17.2 Bravais Lattice</li>
	<li>17.3 Reciprocal Lattice</li>
	<li>17.4 Wigner--Seitz Cell---Brillouin Zone</li>
	<li>17.5 Translation Operators</li>
<ul>	<li>17.5.1 Bloch Theorem</li>
	<li>17.5.2 Periodic Operators</li>
	<li>17.5.3 Periodic Boundary Conditions</li>
</ul>
	<li>17.6 Schr&ouml;dinger Equation in a Periodic Lattice</li>
<ul>	<li>17.6.1 Wave Packet in a Periodic Potential</li>
	<li>17.6.2 Parabolic-Band Approximation</li>
	<li>17.6.3 Density of States in the Parabolic-Band Approximation</li>
	<li>17.6.4 Crystals of Si, Ge, and GaAs</li>
	<li>17.6.5 Band Structure of Si, Ge, and GaAs</li>
<ul>	<li>17.6.5.1 Valence Band</li>
	<li>17.6.5.2 Conduction Band</li>
</ul>
	<li>17.6.6 Further Comments About the Band Structure</li>
	<li>17.6.7 Subbands</li>
<ul>	<li>17.6.7.1 Two-Dimensional Layer</li>
	<li>17.6.7.2 Wire</li>
</ul>
	<li>17.6.8 Subbands in a Periodic Lattice</li>
</ul>
	<li>17.7 Calculation of Vibrational Spectra</li>
<ul>	<li>17.7.1 Labeling the Degrees of Freedom--- Dynamic Matrix</li>
	<li>17.7.2 Application of the Bloch Theorem</li>
	<li>17.7.3 Properties of the Eigenvalues and Eigenvectors</li>
</ul>
	<li>17.8 Complements</li>
<ul>	<li>17.8.1 Crystal Planes and Directions in Cubic Crystals</li>
	<li>17.8.2 Examples of Translation Operators</li>
	<li>17.8.3 Symmetries of the Hamiltonian Operator</li>
	<li>17.8.4 Kronig--Penney Model</li>
	<li>17.8.5 Linear, Monatomic Chain</li>
	<li>17.8.6 Linear, Diatomic Chain</li>
	<li>17.8.7 Analogies</li>
</ul>
</ul>
	<li>Chapter 18 Electrons and Holes in Semiconductors at Equilibrium</li>
<ul>	<li>18.1 Introduction</li>
	<li>18.2 Equilibrium Concentration of Electrons and Holes</li>
	<li>18.3 Intrinsic Concentration</li>
	<li>18.4 Uniform Distribution of Impurities</li>
<ul>	<li>18.4.1 Donor-Type Impurities</li>
<ul>	<li>18.4.1.1 Concentration of Ionized Impurities (Donor Type)</li>
	<li>18.4.1.2 Complete Ionization and Non-Degenerate Condition (Donor Type)</li>
</ul>
	<li>18.4.2 Acceptor-Type Impurities</li>
<ul>	<li>18.4.2.1 Concentration of Ionized Impurities (Acceptor Type)</li>
	<li>18.4.2.2 Complete Ionization and Non-Degenerate Condition(Acceptor Type)</li>
</ul>
	<li>18.4.3 Compensation Effect</li>
</ul>
	<li>18.5 Non-Uniform Distribution of Dopants</li>
	<li>18.6 Band-Gap Narrowing</li>
	<li>18.7 Complements</li>
<ul>	<li>18.7.1 Si, Ge, GaAs in the Manufacturing of Integrated Circuits</li>
	<li>18.7.2 Qualitative Analysis of the Impurity Levels</li>
	<li>18.7.3 Position of the Impurity Levels</li>
</ul>
</ul>
</ul>
	<li>Part VI Transport Phenomena in Semiconductors</li>
<ul>	<li>Chapter 19 Mathematical Model of Semiconductor Devices</li>
<ul>	<li>19.1 Introduction</li>
	<li>19.2 Equivalent Hamiltonian Operator</li>
<ul>	<li>19.2.1 Electron Dynamics</li>
	<li>19.2.2 Expectation Values---Crystal Momentum</li>
	<li>19.2.3 Dynamics in the Parabolic-Band Approximation</li>
</ul>
	<li>19.3 Dynamics in the Phase Space</li>
<ul>	<li>19.3.1 Collision Term</li>
	<li>19.3.2 Point-Like Collisions</li>
	<li>19.3.3 Perturbative Form of the BTE</li>
</ul>
	<li>19.4 Moments Expansion of the BTE</li>
<ul>	<li>19.4.1 Moment Equations</li>
<ul>	<li>19.4.1.1 Moment of Order Zero</li>
	<li>19.4.1.2 General Form of the Higher-Order Moments</li>
	<li>19.4.1.3 Moments of Order One, Two, and Three</li>
</ul>
	<li>19.4.2 Hierarchical Models</li>
<ul>	<li>19.4.2.1 Macroscopic Relaxation Times of the Higher-Order Moments</li>
</ul>
</ul>
	<li>19.5 Hydrodynamic and Drift-Diffusion Models</li>
<ul>	<li>19.5.1 HD Model</li>
	<li>19.5.2 DD Model</li>
	<li>19.5.3 DD Model for the Valence Band</li>
	<li>19.5.4 Coupling with Maxwell's Equations</li>
	<li>19.5.5 Semiconductor-Device Model</li>
	<li>19.5.6 Boundary Conditions</li>
	<li>19.5.7 Quasi-Fermi Potentials</li>
	<li>19.5.8 Poisson Equation in a Semiconductor</li>
</ul>
	<li>19.6 Complements</li>
<ul>	<li>19.6.1 Comments on the Equivalent Hamiltonian Operator</li>
	<li>19.6.2 Special Cases of Anisotropy</li>
	<li>19.6.3 Î±-Moment at Equilibrium</li>
	<li>19.6.4 Closure Conditions</li>
	<li>19.6.5 Matthiessen's Rule</li>
	<li>19.6.6 Order of Magnitude of Mobility and Conductivity</li>
	<li>19.6.7 A Resum&eacute; of the Transport Model's Derivation</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 20 Generation-Recombination and Mobility</li>
<ul>	<li>20.1 Introduction</li>
	<li>20.2 Net Thermal Recombinations</li>
<ul>	<li>20.2.1 Direct Thermal Recombinations</li>
	<li>20.2.2 Trap-Assisted Thermal Recombinations</li>
	<li>20.2.3 Shockley-Read-Hall Theory</li>
<ul>	<li>20.2.3.1 Limiting Cases of the Shockley-Read-Hall Theory</li>
</ul>
</ul>
	<li>20.3 Auger Recombination and Impact Ionization</li>
<ul>	<li>20.3.1 Strong Impact Ionization</li>
</ul>
	<li>20.4 Optical Transitions</li>
	<li>20.5 Macroscopic Mobility Models</li>
<ul>	<li>20.5.1 Example of Phonon Collision</li>
	<li>20.5.2 Example of Ionized-Impurity Collision</li>
	<li>20.5.3 Bulk and Surface Mobilities</li>
	<li>20.5.4 Beyond Analytical Modeling of Mobility</li>
</ul>
	<li>20.6 Complements</li>
<ul>	<li>20.6.1 Transition Rates in the SRH Recombination Function</li>
	<li>20.6.2 Coefficients of the Auger and Impact-Ionization Events</li>
	<li>20.6.3 Total Recombination-Generation Rate</li>
	<li>20.6.4 Screened Coulomb Potential</li>
</ul>
</ul>
</ul>
	<li>Part VII Basic Semiconductor Devices</li>
<ul>	<li>Chapter 21 Bipolar Devices</li>
<ul>	<li>21.1 Introduction</li>
	<li>21.2 P--N Junction in Equilibrium</li>
<ul>	<li>21.2.1 Built-In Potential</li>
	<li>21.2.2 Space-Charge and Quasi-Neutral Regions</li>
</ul>
	<li>21.3 Shockley Theory of the P--N Junction</li>
<ul>	<li>21.3.1 Derivation of the I(V) Characteristic</li>
</ul>
	<li>21.4 Depletion Capacitance of the Abrupt P--N Junction</li>
	<li>21.5 Avalanche Due to Impact Ionization</li>
	<li>21.6 Complements</li>
<ul>	<li>21.6.1 Weak-Injection Limit of the Drift-Diffusion Equations</li>
	<li>21.6.2 Shockley's Boundary Conditions</li>
	<li>21.6.3 Depletion Capacitance---Arbitrary Doping Profile</li>
	<li>21.6.4 Order of Magnitude of Junction's Parameters</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 22 MOS Devices</li>
<ul>	<li>22.1 Introduction</li>
	<li>22.2 Metal--Insulator--Semiconductor Capacitor</li>
<ul>	<li>22.2.1 Surface Potential</li>
	<li>22.2.2 Relation Between Surface Potential and Gate Voltage</li>
</ul>
	<li>22.3 Capacitance of the MOS Structure</li>
	<li>22.4 Simplified Expression of the Inversion Charge</li>
<ul>	<li>22.4.1 Quantitative Relations in the MOS Capacitor</li>
</ul>
	<li>22.5 Insulated-Gate Field-Effect Transistor---MOSFET</li>
	<li>22.6 N-Channel MOSFET---Current-Voltage Characteristics</li>
<ul>	<li>22.6.1 Gradual-Channel Approximation</li>
	<li>22.6.2 Differential Conductances and Drain Current</li>
<ul>	<li>22.6.2.1 Linear--Parabolic Model</li>
</ul>
</ul>
	<li>22.7 Complements</li>
<ul>	<li>22.7.1 Poisson's Equation in the MOSFET Channel</li>
	<li>22.7.2 Inversion-Layer Charge and Mobility Degradation</li>
</ul>
	<li>Problems</li>
</ul>
</ul>
	<li>Part VIII Miscellany</li>
<ul>	<li>Chapter 23 Thermal Diffusion</li>
<ul>	<li>23.1 Introduction</li>
	<li>23.2 Continuity Equation</li>
	<li>23.3 Diffusive Transport</li>
	<li>23.4 Diffusion Equation---Model Problem</li>
	<li>23.5 Predeposition and Drive-in Diffusion</li>
<ul>	<li>23.5.1 Predeposition</li>
	<li>23.5.2 Drive-in Diffusion</li>
</ul>
	<li>23.6 Generalization of the Model Problem</li>
	<li>23.7 Complements</li>
<ul>	<li>23.7.1 Generation and Destruction of Particles</li>
	<li>23.7.2 Balance Relations</li>
	<li>23.7.3 Lateral Diffusion</li>
	<li>23.7.4 Alternative Expression of the Dose</li>
	<li>23.7.5 The Initial Condition of the Predeposition Step</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 24 Thermal Oxidation---Layer Deposition</li>
<ul>	<li>24.1 Introduction</li>
	<li>24.2 Silicon Oxidation</li>
	<li>24.3 Oxide-Growth Kinetics</li>
	<li>24.4 Linear--Parabolic Model of the Oxide Growth</li>
	<li>24.5 Layer Deposition and Selective Oxide Growth</li>
	<li>24.6 Epitaxy</li>
	<li>24.7 Kinetics of Epitaxy</li>
	<li>24.8 Complements</li>
<ul>	<li>24.8.1 An Apparent Contradiction</li>
	<li>24.8.2 Elementary Contributions to the Layer's Volume</li>
	<li>24.8.3 Features of the Oxide Growth and Epitaxial Growth</li>
	<li>24.8.4 Reaction Velocity</li>
	<li>24.8.5 Molecular Beam Epitaxy</li>
	<li>24.8.6 Secondary Reaction in the Epitaxial Growth</li>
</ul>
	<li>Problems</li>
</ul>
	<li>Chapter 25 Measuring the Semiconductor Parameters</li>
<ul>	<li>25.1 Introduction</li>
	<li>25.2 Lifetime Measurement</li>
<ul>	<li>25.2.0.1 Thermal Velocity and Capture Cross-Section</li>
</ul>
	<li>25.3 Mobility Measurement---Haynes-Shockley Experiment</li>
	<li>25.4 Hall-Voltage Measurement</li>
	<li>25.5 Measurement of Doping Profiles</li>
</ul>
</ul>
	<li>Appendix A Vector and Matrix Analysis</li>
<ul>	<li>A.1 Scalar Product</li>
	<li>A.2 Schwarz Inequality and Generalizations</li>
	<li>A.3 Nabla Operator</li>
	<li>A.4 Dyadic Products</li>
	<li>A.5 Divergence Theorem</li>
	<li>A.6 Vector Product</li>
	<li>A.7 Mixed Product</li>
	<li>A.8 Rotational of a Vector</li>
	<li>A.9 Rotational Theorem</li>
	<li>A.10 Helmholtz Theorem</li>
	<li>A.11 Doubly-Stochastic Matrices</li>
	<li>A.12 Wronskian Determinant</li>
</ul>
	<li>Appendix B Coordinates</li>
<ul>	<li>B.1 Spherical Coordinates</li>
	<li>B.2 Polar Coordinates</li>
	<li>B.3 Coordinate Rotation</li>
	<li>B.4 Differential Operators Under Coordinate Transformations</li>
	<li>B.5 Density of States</li>
</ul>
	<li>Appendix C Special Integrals</li>
<ul>	<li>C.1 Sine Integral</li>
	<li>C.2 Fourier Transform</li>
	<li>C.3 Gauss Integral</li>
	<li>C.4 Dirac&rsquo;s Î´</li>
	<li>C.5 Some Properties of Dirac&rsquo;s Î´</li>
	<li>C.6 Moments Expansion</li>
	<li>C.7 Error Function</li>
	<li>C.8 Parametrized Gaussian Function</li>
	<li>C.9 Euler&rsquo;s Beta Function</li>
	<li>C.10 Euler&rsquo;s Gamma Function</li>
	<li>C.11 Gamma Function&rsquo;s Asymptotic Behavior</li>
	<li>C.12 Integrals Related to the Harmonic Oscillator</li>
	<li>C.13 Fermi Integrals</li>
	<li>C.14 H&ouml;lder&rsquo;s Inequality</li>
	<li>C.15 Integrals Related to the Electromagnetic Modes</li>
	<li>C.16 Riemann&rsquo;s Zeta Function</li>
</ul>
	<li>Appendix D &#13;Tables</li>
	<li>Solutions</li>
	<li>Bibliography</li>
</ul>
</body></html>