<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Untitled</title>
</head>
<body><div class="page"><p/>
<p>Probability 
and Statistics 
for Computer 
Science
</p>
<p>David Forsyth</p>
<p/>
</div>
<div class="page"><p/>
<p>Probability and Statistics for Computer Science</p>
<p/>
</div>
<div class="page"><p/>
<p>David Forsyth
</p>
<p>Probability and Statistics for Computer
Science
</p>
<p>123</p>
<p/>
</div>
<div class="page"><p/>
<p>David Forsyth
Computer Science Department
University of Illinois at Urbana Champaign
Urbana, IL, USA
</p>
<p>ISBN 978-3-319-64409-7 ISBN 978-3-319-64410-3 (eBook)
https://doi.org/10.1007/978-3-319-64410-3
</p>
<p>Library of Congress Control Number: 2017950289
</p>
<p>&copy; Springer International Publishing AG 2018
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights
of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or
information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific
statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date
of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied, with respect to the material contained herein or for
any errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in published maps and institutional
affiliations.
</p>
<p>Printed on acid-free paper
</p>
<p>This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3">https://doi.org/10.1007/978-3-319-64410-3</a></div>
</div>
<div class="page"><p/>
<p>To my family</p>
<p/>
</div>
<div class="page"><p/>
<p>Preface
</p>
<p>An understanding of probability and statistics is an essential tool for a modern computer scientist. If your tastes run to
</p>
<p>theory, then you need to know a lot of probability (e.g., to understand randomized algorithms, to understand the probabilistic
</p>
<p>method in graph theory, to understand a lot of work on approximation, and so on) and at least enough statistics to bluff
</p>
<p>successfully on occasion. If your tastes run to the practical, you will find yourself constantly raiding the larder of statistical
</p>
<p>techniques (particularly classification, clustering, and regression). For example, much of modern artificial intelligence is built
</p>
<p>on clever pirating of statistical ideas. As another example, thinking about statistical inference for gigantic datasets has had a
</p>
<p>tremendous influence on how people build modern computer systems.
</p>
<p>Computer science undergraduates traditionally are required to take either a course in probability, typically taught by
</p>
<p>the math department, or a course in statistics, typically taught by the statistics department. A curriculum committee in my
</p>
<p>department decided that the curricula of these courses could do with some revision. So I taught a trial version of a course, for
</p>
<p>which I wrote notes; these notes became this book. There is no new fact about probability or statistics here, but the selection
</p>
<p>of topics is my own; I think it&rsquo;s quite different from what one sees in other books.
</p>
<p>The key principle in choosing what to write about was to cover the ideas in probability and statistics that I thought every
</p>
<p>computer science undergraduate student should have seen, whatever their chosen specialty or career. This means the book is
</p>
<p>broad and coverage of many areas is shallow. I think that&rsquo;s fine, because my purpose is to ensure that all have seen enough
</p>
<p>to know that, say, firing up a classification package will make many problems go away. So I&rsquo;ve covered enough to get you
</p>
<p>started and to get you to realize that it&rsquo;s worth knowing more.
</p>
<p>The notes I wrote have been useful to graduate students as well. In my experience, many learned some or all of this
</p>
<p>material without realizing how useful it was and then forgot it. If this happened to you, I hope the book is a stimulus to your
</p>
<p>memory. You really should have a grasp of all of this material. You might need to know more, but you certainly shouldn&rsquo;t
</p>
<p>know less.
</p>
<p>Reading and Teaching This Book
</p>
<p>I wrote this book to be taught, or read, by starting at the beginning and proceeding to the end. Different instructors or readers
</p>
<p>may have different needs, and so I sketch some pointers to what can be omitted below.
</p>
<p>Describing Datasets
</p>
<p>This part covers:
</p>
<p>&bull; Various descriptive statistics (mean, standard deviation, variance) and visualization methods for 1D datasets
</p>
<p>&bull; Scatter plots, correlation, and prediction for 2D datasets
</p>
<p>Most people will have seen some, but not all, of this material. In my experience, it takes some time for people to really
</p>
<p>internalize just how useful it is to make pictures of datasets. I&rsquo;ve tried to emphasize this point strongly by investigating a
</p>
<p>variety of datasets in worked examples. When I teach this material, I move through these chapters slowly and carefully.
</p>
<p>vii</p>
<p/>
</div>
<div class="page"><p/>
<p>viii Preface
</p>
<p>Probability
</p>
<p>This part covers:
</p>
<p>&bull; Discrete probability, developed fairly formally
</p>
<p>&bull; Conditional probability, with a particular emphasis on examples, because people find this topic counterintuitive
</p>
<p>&bull; Random variables and expectations
</p>
<p>&bull; Just a little continuous probability (probability density functions and how to interpret them)
</p>
<p>&bull; Markov&rsquo;s inequality, Chebyshev&rsquo;s inequality, and the weak law of large numbers
</p>
<p>&bull; A selection of facts about an assortment of useful probability distributions
</p>
<p>&bull; The normal approximation to a binomial distribution with large N
</p>
<p>I&rsquo;ve been quite careful developing discrete probability fairly formally. Most people find conditional probability counterintu-
</p>
<p>itive (or, at least, behave as if they do&mdash;you can still start a fight with the Monty Hall problem), and so I&rsquo;ve used a number
</p>
<p>of (sometimes startling) examples to emphasize how useful it is to tread carefully here. In my experience, worked examples
</p>
<p>help learning, but I found that too many worked examples in any one section could become distracting, so there&rsquo;s an entire
</p>
<p>section of extra worked examples. You can&rsquo;t omit anything here, except perhaps the extra worked examples.
</p>
<p>The chapter on random variables largely contains routine material, but there I&rsquo;ve covered Markov&rsquo;s inequality,
</p>
<p>Chebyshev&rsquo;s inequality, and the weak law of large numbers. In my experience, computer science undergraduates find
</p>
<p>simulation absolutely natural (why do sums when you can write a program?) and enjoy the weak law as a license to do
</p>
<p>what they would do anyway. You could omit the inequalities and just describe the weak law, though most students run into
</p>
<p>the inequalities in later theory courses; the experience is usually happier if they&rsquo;ve seen them once before.
</p>
<p>The chapter on useful probability distributions again largely contains routine material. When I teach this course, I skim
</p>
<p>through the chapter fairly fast and rely on students reading the chapter. However, there is a detailed discussion of a normal
</p>
<p>approximation to a binomial distribution with large N. In my experience, no one enjoys the derivation, but you should know
</p>
<p>the approximation is available, and roughly how it works. I lecture this topic in some detail, mainly by giving examples.
</p>
<p>Inference
</p>
<p>This part covers:
</p>
<p>&bull; Samples and populations
</p>
<p>&bull; Confidence intervals for sampled estimates of population means
</p>
<p>&bull; Statistical significance, including t-tests, F-tests, and �2-tests
</p>
<p>&bull; Very simple experimental design, including one-way and two-way experiments
</p>
<p>&bull; ANOVA for experiments
</p>
<p>&bull; Maximum likelihood inference
</p>
<p>&bull; Simple Bayesian inference
</p>
<p>&bull; A very brief discussion of filtering
</p>
<p>The material on samples covers only sampling with replacement; if you need something more complicated, this will get you
</p>
<p>started. Confidence intervals are not much liked by students, I think because the true definition is quite delicate; but getting
</p>
<p>a grasp of the general idea is useful. You really shouldn&rsquo;t omit these topics.
</p>
<p>You shouldn&rsquo;t omit statistical significance either, though you might feel the impulse. I have never dealt with anyone who
</p>
<p>found their first encounter with statistical significance pleasurable (such a person might exist, the population being very
</p>
<p>large). But the idea is so useful and so valuable that you just have to take your medicine. Statistical significance is often seen
</p>
<p>and sometimes taught as a powerful but fundamentally mysterious apotropaic ritual. I try very hard not to do this.
</p>
<p>I have often omitted teaching simple experimental design and ANOVA, but in retrospect this was a mistake. The ideas are
</p>
<p>straightforward and useful. There&rsquo;s a bit of hypocrisy involved in teaching experimental design using other people&rsquo;s datasets.
</p>
<p>The (correct) alternative is to force students to plan and execute experiments; there just isn&rsquo;t enough time in a usual course
</p>
<p>to fit this in.
</p>
<p>Finally, you shouldn&rsquo;t omit maximum likelihood inference or Bayesian inference. Many people don&rsquo;t need to know about
</p>
<p>filtering, though.</p>
<p/>
</div>
<div class="page"><p/>
<p>Preface ix
</p>
<p>Tools
</p>
<p>This part covers:
</p>
<p>&bull; Principal component analysis
</p>
<p>&bull; Simple multidimensional scaling with principal coordinate analysis;
</p>
<p>&bull; Basic ideas in classification;
</p>
<p>&bull; Nearest neighbors classification;
</p>
<p>&bull; Naive Bayes classification;
</p>
<p>&bull; Classifying with a linear SVM trained with stochastic gradient descent;
</p>
<p>&bull; Classifying with a random forest;
</p>
<p>&bull; The curse of dimension;
</p>
<p>&bull; Agglomerative and divisive clustering;
</p>
<p>&bull; K-means clustering;
</p>
<p>&bull; Vector quantization;
</p>
<p>&bull; A superficial mention of the multivariate normal distribution;
</p>
<p>&bull; Linear regression;
</p>
<p>&bull; A variety of tricks to analyze and improve regressions;
</p>
<p>&bull; Nearest neighbors regression;
</p>
<p>&bull; Simple Markov chains;
</p>
<p>&bull; Hidden Markov models.
</p>
<p>Most students in my institution take this course at the same time they take a linear algebra course. When I teach the
</p>
<p>course, I try and time things so they hit PCA shortly after hitting eigenvalues and eigenvectors. You shouldn&rsquo;t omit PCA. I
</p>
<p>lecture principal coordinate analysis very superficially, just describing what it does and why it&rsquo;s useful.
</p>
<p>I&rsquo;ve been told, often quite forcefully, you can&rsquo;t teach classification to undergraduates. I think you have to, and in my
</p>
<p>experience, they like it a lot. Students really respond to being taught something that is extremely useful and really easy to
</p>
<p>do. Please, please, don&rsquo;t omit any of this stuff.
</p>
<p>The clustering material is quite simple and easy to teach. In my experience, the topic is a little baffling without an
</p>
<p>application. I always set a programming exercise where one must build a classifier using features derived from vector
</p>
<p>quantization. This is a great way of identifying situations where people think they understand something, but don&rsquo;t really.
</p>
<p>Most students find the exercise challenging, because they must use several concepts together. But most students overcome
</p>
<p>the challenges and are pleased to see the pieces intermeshing well. The discussion of the multivariate normal distribution is
</p>
<p>not much more than a mention. I don&rsquo;t think you could omit anything in this chapter.
</p>
<p>The regression material is also quite simple and is also easy to teach. The main obstacle here is that students feel something
</p>
<p>more complicated must necessarily work better (and they&rsquo;re not the only ones). I also don&rsquo;t think you could omit anything in
</p>
<p>this chapter.
</p>
<p>In my experience, computer science students find simple Markov chains natural (though they might find the notation
</p>
<p>annoying) and will suggest simulating a chain before the instructor does. The examples of using Markov chains to produce
</p>
<p>natural language (particularly Garkov and wine reviews) are wonderful fun and you really should show them in lectures. You
</p>
<p>could omit the discussion of ranking the Web. About half of each class I&rsquo;ve dealt with has found hidden Markov models easy
</p>
<p>and natural, and the other half has been wishing the end of the semester was closer. You could omit this topic if you sense
</p>
<p>likely resistance, and have those who might find it interesting read it.
</p>
<p>Mathematical Bits and Pieces
</p>
<p>This is a chapter of collected mathematical facts some readers might find useful, together with some slightly deeper
</p>
<p>information on decision tree construction. Not necessary to lecture this.
</p>
<p>Urbana, IL, USA David Forsyth</p>
<p/>
</div>
<div class="page"><p/>
<p>Acknowledgments
</p>
<p>I acknowledge a wide range of intellectual debts, starting at kindergarten. Important figures in the very long list of my
</p>
<p>creditors include Gerald Alanthwaite, Mike Brady, Tom Fair, Margaret Fleck, Jitendra Malik, Joe Mundy, Jean Ponce, Mike
</p>
<p>Rodd, Charlie Rothwell, and Andrew Zisserman.
</p>
<p>I have benefited from looking at a variety of sources, though this work really is my own. I particularly enjoyed the
</p>
<p>following books:
</p>
<p>&bull; Elementary Probability, D. Stirzaker; Cambridge University Press, 2e, 2003.
</p>
<p>&bull; What is a p-value anyway? 34 Stories to Help You Actually Understand Statistics, A. J. Vickers; Pearson, 2009.
</p>
<p>&bull; Elementary Probability for Applications, R. Durrett; Cambridge University Press, 2009.
</p>
<p>&bull; Statistics, D. Freedman, R. Pisani and R. Purves; W. W. Norton &amp; Company, 4e, 2007.
</p>
<p>&bull; Data Analysis and Graphics Using R: An Example-Based Approach, J. Maindonald and W. J. Braun; Cambridge
</p>
<p>University Press, 2e, 2003.
</p>
<p>&bull; The Nature of Statistical Learning Theory, V. Vapnik; Springer, 1999.
</p>
<p>A wonderful feature of modern scientific life is the willingness of people to share data on the Internet. I have roamed the
</p>
<p>Internet widely looking for datasets, and have tried to credit the makers and sharers of data accurately and fully when I use
</p>
<p>the dataset. If, by some oversight, I have left you out, please tell me and I will try and fix this. I have been particularly
</p>
<p>enthusiastic about using data from the following repositories:
</p>
<p>&bull; The UC Irvine Machine Learning Repository, at http://archive.ics.uci.edu/ml/.
</p>
<p>&bull; Dr. John Rasp&rsquo;s Statistics Website, at http://www2.stetson.edu/~jrasp/.
</p>
<p>&bull; OzDASL: The Australasian Data and Story Library, at http://www.statsci.org/data/.
</p>
<p>&bull; The Center for Genome Dynamics, at the Jackson Laboratory, at http://cgd.jax.org/ (which contains staggering amounts
</p>
<p>of information about mice).
</p>
<p>I looked at Wikipedia regularly when preparing this manuscript, and I&rsquo;ve pointed readers to neat stories there when they&rsquo;re
</p>
<p>relevant. I don&rsquo;t think one could learn the material in this book by reading Wikipedia, but it&rsquo;s been tremendously helpful in
</p>
<p>restoring ideas that I have mislaid, mangled, or simply forgotten.
</p>
<p>Typos spotted by Han Chen (numerous!), Henry Lin (numerous!), Eric Huber, Brian Lunt, Yusuf Sobh, and Scott Walters.
</p>
<p>Some names might be missing due to poor record-keeping on my part; I apologize. Jian Peng and Paris Smaragdis taught
</p>
<p>courses from versions of these notes and improved them by detailed comments, suggestions, and typo lists. TAs for this
</p>
<p>course have helped improve the notes. Thanks to Minje Kim, Henry Lin, Zicheng Liao, Karthik Ramaswamy, Saurabh
</p>
<p>Singh, Michael Sittig, Nikita Spirin, and Daphne Tsatsoulis. TAs for related classes have also helped improve the notes.
</p>
<p>Thanks to Tanmay Gangwani, Sili Hui, Ayush Jain, Maghav Kumar, Jiajun Lu, Jason Rock, Daeyun Shin, Mariya Vasileva,
</p>
<p>and Anirud Yadav.
</p>
<p>I have benefited hugely from reviews organized by the publisher. Reviewers made many extremely helpful suggestions,
</p>
<p>which I have tried to adopt; among many other things, the current material on inference is the product of a complete
</p>
<p>xi</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/">http://www2.stetson.edu/~jrasp/</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/">http://www.statsci.org/data/</a></div>
<div class="annotation"><a href="http://cgd.jax.org/">http://cgd.jax.org/</a></div>
</div>
<div class="page"><p/>
<p>xii Acknowledgments
</p>
<p>overhaul recommended by a reviewer. Reviewers were anonymous to me at time of review, but their names were later
</p>
<p>revealed so I can thank them by name. Thanks to:
</p>
<p>University of Texas, Arlington Dr. Ashis Biswas
</p>
<p>University of California, Davis Dr. Dipak Ghosal
</p>
<p>St. Louis University James Mixco
</p>
<p>University of Tulsa Sabrina Ripp
</p>
<p>University of Rhode Island Catherine Robinson
</p>
<p>Morgan State University Dr. Eric Sakk
</p>
<p>University of Texas, Dallas Dr. William Semper
</p>
<p>Remaining typos, errors, howlers, infelicities, clich&eacute;, slang, jargon, cant, platitude, attitude, inaccuracy, fatuousness, etc.,
</p>
<p>are all my fault: Sorry.</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents
</p>
<p>Part I Describing Datasets
</p>
<p>1 First Tools for Looking at Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
</p>
<p>1.1 Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
</p>
<p>1.2 What&rsquo;s Happening? Plotting Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
</p>
<p>1.2.1 Bar Charts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
</p>
<p>1.2.2 Histograms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
</p>
<p>1.2.3 How to Make Histograms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
</p>
<p>1.2.4 Conditional Histograms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
</p>
<p>1.3 Summarizing 1D Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
</p>
<p>1.3.1 The Mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
</p>
<p>1.3.2 Standard Deviation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
</p>
<p>1.3.3 Computing Mean and Standard Deviation Online . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
</p>
<p>1.3.4 Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
</p>
<p>1.3.5 The Median . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
</p>
<p>1.3.6 Interquartile Range . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
</p>
<p>1.3.7 Using Summaries Sensibly . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
</p>
<p>1.4 Plots and Summaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
</p>
<p>1.4.1 Some Properties of Histograms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
</p>
<p>1.4.2 Standard Coordinates and Normal Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
</p>
<p>1.4.3 Box Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
</p>
<p>1.5 Whose is Bigger? Investigating Australian Pizzas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
</p>
<p>1.6 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
</p>
<p>1.6.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
</p>
<p>1.6.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
</p>
<p>1.6.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
</p>
<p>1.6.4 Be Able to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
</p>
<p>2 Looking at Relationships . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
</p>
<p>2.1 Plotting 2D Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
</p>
<p>2.1.1 Categorical Data, Counts, and Charts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
</p>
<p>2.1.2 Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
</p>
<p>2.1.3 Scatter Plots for Spatial Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
</p>
<p>2.1.4 Exposing Relationships with Scatter Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
</p>
<p>2.2 Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
</p>
<p>2.2.1 The Correlation Coefficient . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
</p>
<p>2.2.2 Using Correlation to Predict . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
</p>
<p>2.2.3 Confusion Caused by Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
</p>
<p>2.3 Sterile Males in Wild Horse Herds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
</p>
<p>2.4 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
</p>
<p>2.4.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
</p>
<p>2.4.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
</p>
<p>xiii</p>
<p/>
</div>
<div class="page"><p/>
<p>xiv Contents
</p>
<p>2.4.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
</p>
<p>2.4.4 Use These Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
</p>
<p>2.4.5 Be Able to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
</p>
<p>Part II Probability
</p>
<p>3 Basic Ideas in Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
</p>
<p>3.1 Experiments, Outcomes and Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
</p>
<p>3.1.1 Outcomes and Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
</p>
<p>3.2 Events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
</p>
<p>3.2.1 Computing Event Probabilities by Counting Outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
</p>
<p>3.2.2 The Probability of Events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
</p>
<p>3.2.3 Computing Probabilities by Reasoning About Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
</p>
<p>3.3 Independence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
</p>
<p>3.3.1 Example: Airline Overbooking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
</p>
<p>3.4 Conditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
</p>
<p>3.4.1 Evaluating Conditional Probabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
</p>
<p>3.4.2 Detecting Rare Events Is Hard . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
</p>
<p>3.4.3 Conditional Probability and Various Forms of Independence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
</p>
<p>3.4.4 Warning Example: The Prosecutor&rsquo;s Fallacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
</p>
<p>3.4.5 Warning Example: The Monty Hall Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
</p>
<p>3.5 Extra Worked Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
</p>
<p>3.5.1 Outcomes and Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
</p>
<p>3.5.2 Events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
</p>
<p>3.5.3 Independence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
</p>
<p>3.5.4 Conditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
</p>
<p>3.6 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
</p>
<p>3.6.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
</p>
<p>3.6.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
</p>
<p>3.6.3 Remember and Use These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
</p>
<p>3.6.4 Remember These Points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
</p>
<p>3.6.5 Be Able to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
</p>
<p>4 Random Variables and Expectations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
</p>
<p>4.1 Random Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
</p>
<p>4.1.1 Joint and Conditional Probability for Random Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
</p>
<p>4.1.2 Just a Little Continuous Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
</p>
<p>4.2 Expectations and Expected Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
</p>
<p>4.2.1 Expected Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
</p>
<p>4.2.2 Mean, Variance and Covariance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
</p>
<p>4.2.3 Expectations and Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
</p>
<p>4.3 The Weak Law of Large Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
</p>
<p>4.3.1 IID Samples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
</p>
<p>4.3.2 Two Inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
</p>
<p>4.3.3 Proving the Inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
</p>
<p>4.3.4 The Weak Law of Large Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
</p>
<p>4.4 Using the Weak Law of Large Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
</p>
<p>4.4.1 Should You Accept a Bet? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
</p>
<p>4.4.2 Odds, Expectations and Bookmaking: A Cultural Diversion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
</p>
<p>4.4.3 Ending a Game Early . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
</p>
<p>4.4.4 Making a Decision with Decision Trees and Expectations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
</p>
<p>4.4.5 Utility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents xv
</p>
<p>4.5 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
</p>
<p>4.5.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
</p>
<p>4.5.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
</p>
<p>4.5.3 Use and Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
</p>
<p>4.5.4 Remember These Points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
</p>
<p>4.5.5 Be Able to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
</p>
<p>5 Useful Probability Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
</p>
<p>5.1 Discrete Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
</p>
<p>5.1.1 The Discrete Uniform Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
</p>
<p>5.1.2 Bernoulli Random Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
</p>
<p>5.1.3 The Geometric Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
</p>
<p>5.1.4 The Binomial Probability Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
</p>
<p>5.1.5 Multinomial Probabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
</p>
<p>5.1.6 The Poisson Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
</p>
<p>5.2 Continuous Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
</p>
<p>5.2.1 The Continuous Uniform Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
</p>
<p>5.2.2 The Beta Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
</p>
<p>5.2.3 The Gamma Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
</p>
<p>5.2.4 The Exponential Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
</p>
<p>5.3 The Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
</p>
<p>5.3.1 The Standard Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
</p>
<p>5.3.2 The Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
</p>
<p>5.3.3 Properties of the Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
</p>
<p>5.4 Approximating Binomials with Large N . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
</p>
<p>5.4.1 Large N . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
</p>
<p>5.4.2 Getting Normal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
</p>
<p>5.4.3 Using a Normal Approximation to the Binomial Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
</p>
<p>5.5 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
</p>
<p>5.5.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
</p>
<p>5.5.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
</p>
<p>5.5.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
</p>
<p>5.5.4 Remember These Points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
</p>
<p>Part III Inference
</p>
<p>6 Samples and Populations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
</p>
<p>6.1 The Sample Mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
</p>
<p>6.1.1 The Sample Mean Is an Estimate of the Population Mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
</p>
<p>6.1.2 The Variance of the Sample Mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
</p>
<p>6.1.3 When The Urn Model Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
</p>
<p>6.1.4 Distributions Are Like Populations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
</p>
<p>6.2 Confidence Intervals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
</p>
<p>6.2.1 Constructing Confidence Intervals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
</p>
<p>6.2.2 Estimating the Variance of the Sample Mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
</p>
<p>6.2.3 The Probability Distribution of the Sample Mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
</p>
<p>6.2.4 Confidence Intervals for Population Means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
</p>
<p>6.2.5 Standard Error Estimates from Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
</p>
<p>6.3 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
</p>
<p>6.3.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
</p>
<p>6.3.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
</p>
<p>6.3.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154</p>
<p/>
</div>
<div class="page"><p/>
<p>xvi Contents
</p>
<p>6.3.4 Use These Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
</p>
<p>6.3.5 Be Able to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
</p>
<p>7 The Significance of Evidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
</p>
<p>7.1 Significance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
</p>
<p>7.1.1 Evaluating Significance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
</p>
<p>7.1.2 P-Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
</p>
<p>7.2 Comparing the Mean of Two Populations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
</p>
<p>7.2.1 Assuming Known Population Standard Deviations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
</p>
<p>7.2.2 Assuming Same, Unknown Population Standard Deviation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
</p>
<p>7.2.3 Assuming Different, Unknown Population Standard Deviation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168
</p>
<p>7.3 Other Useful Tests of Significance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
</p>
<p>7.3.1 F-Tests and Standard Deviations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
</p>
<p>7.3.2 �2 Tests of Model Fit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
</p>
<p>7.4 P-Value Hacking and Other Dangerous Behavior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
</p>
<p>7.5 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
</p>
<p>7.5.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
</p>
<p>7.5.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
</p>
<p>7.5.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
</p>
<p>7.5.4 Use These Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
</p>
<p>7.5.5 Be Able to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
</p>
<p>8 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
</p>
<p>8.1 A Simple Experiment: The Effect of a Treatment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
</p>
<p>8.1.1 Randomized Balanced Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
</p>
<p>8.1.2 Decomposing Error in Predictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
</p>
<p>8.1.3 Estimating the Noise Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
</p>
<p>8.1.4 The ANOVA Table . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
</p>
<p>8.1.5 Unbalanced Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
</p>
<p>8.1.6 Significant Differences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
</p>
<p>8.2 Two Factor Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
</p>
<p>8.2.1 Decomposing the Error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
</p>
<p>8.2.2 Interaction Between Effects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
</p>
<p>8.2.3 The Effects of a Treatment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
</p>
<p>8.2.4 Setting Up An ANOVA Table . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
</p>
<p>8.3 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
</p>
<p>8.3.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
</p>
<p>8.3.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
</p>
<p>8.3.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
</p>
<p>8.3.4 Use These Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
</p>
<p>8.3.5 Be Able to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
</p>
<p>9 Inferring Probability Models from Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
</p>
<p>9.1 Estimating Model Parameters with Maximum Likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
</p>
<p>9.1.1 The Maximum Likelihood Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
</p>
<p>9.1.2 Binomial, Geometric and Multinomial Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
</p>
<p>9.1.3 Poisson and Normal Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
</p>
<p>9.1.4 Confidence Intervals for Model Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204
</p>
<p>9.1.5 Cautions About Maximum Likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
</p>
<p>9.2 Incorporating Priors with Bayesian Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
</p>
<p>9.2.1 Conjugacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
</p>
<p>9.2.2 MAP Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
</p>
<p>9.2.3 Cautions About Bayesian Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents xvii
</p>
<p>9.3 Bayesian Inference for Normal Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
</p>
<p>9.3.1 Example: Measuring Depth of a Borehole . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212
</p>
<p>9.3.2 Normal Prior and Normal Likelihood Yield Normal Posterior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212
</p>
<p>9.3.3 Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
</p>
<p>9.4 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
</p>
<p>9.4.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
</p>
<p>9.4.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216
</p>
<p>9.4.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216
</p>
<p>9.4.4 Use These Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
</p>
<p>9.4.5 Be Able to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
</p>
<p>Part IV Tools
</p>
<p>10 Extracting Important Relationships in High Dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
</p>
<p>10.1 Summaries and Simple Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
</p>
<p>10.1.1 The Mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
</p>
<p>10.1.2 Stem Plots and Scatterplot Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
</p>
<p>10.1.3 Covariance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
</p>
<p>10.1.4 The Covariance Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
</p>
<p>10.2 Using Mean and Covariance to Understand High Dimensional Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
</p>
<p>10.2.1 Mean and Covariance Under Affine Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
</p>
<p>10.2.2 Eigenvectors and Diagonalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
</p>
<p>10.2.3 Diagonalizing Covariance by Rotating Blobs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
</p>
<p>10.2.4 Approximating Blobs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
</p>
<p>10.2.5 Example: Transforming the Height-Weight Blob . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
</p>
<p>10.3 Principal Components Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
</p>
<p>10.3.1 The Low Dimensional Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
</p>
<p>10.3.2 The Error Caused by Reducing Dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
</p>
<p>10.3.3 Example: Representing Colors with Principal Components . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
</p>
<p>10.3.4 Example: Representing Faces with Principal Components . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242
</p>
<p>10.4 Multi-Dimensional Scaling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242
</p>
<p>10.4.1 Choosing Low D Points Using High D Distances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243
</p>
<p>10.4.2 Factoring a Dot-Product Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
</p>
<p>10.4.3 Example: Mapping with Multidimensional Scaling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246
</p>
<p>10.5 Example: Understanding Height and Weight . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247
</p>
<p>10.6 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
</p>
<p>10.6.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
</p>
<p>10.6.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
</p>
<p>10.6.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
</p>
<p>10.6.4 Use These Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
</p>
<p>10.6.5 Be Able to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
</p>
<p>11 Learning to Classify . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
</p>
<p>11.1 Classification: The Big Ideas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
</p>
<p>11.1.1 The Error Rate, and Other Summaries of Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>11.1.2 More Detailed Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>11.1.3 Overfitting and Cross-Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
</p>
<p>11.2 Classifying with Nearest Neighbors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256
</p>
<p>11.2.1 Practical Considerations for Nearest Neighbors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256
</p>
<p>11.3 Classifying with Naive Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
</p>
<p>11.3.1 Cross-Validation to Choose a Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259</p>
<p/>
</div>
<div class="page"><p/>
<p>xviii Contents
</p>
<p>11.4 The Support Vector Machine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
</p>
<p>11.4.1 The Hinge Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
</p>
<p>11.4.2 Regularization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
</p>
<p>11.4.3 Finding a Classifier with Stochastic Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
</p>
<p>11.4.4 Searching for � . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
</p>
<p>11.4.5 Example: Training an SVM with Stochastic Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
</p>
<p>11.4.6 Multi-Class Classification with SVMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
</p>
<p>11.5 Classifying with Random Forests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
</p>
<p>11.5.1 Building a Decision Tree: General Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
</p>
<p>11.5.2 Building a Decision Tree: Choosing a Split . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
</p>
<p>11.5.3 Forests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
</p>
<p>11.6 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
</p>
<p>11.6.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
</p>
<p>11.6.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
</p>
<p>11.6.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
</p>
<p>11.6.4 Use These Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
</p>
<p>11.6.5 Be Able to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276
</p>
<p>12 Clustering: Models of High Dimensional Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281
</p>
<p>12.1 The Curse of Dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281
</p>
<p>12.1.1 Minor Banes of Dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281
</p>
<p>12.1.2 The Curse: Data Isn&rsquo;t Where You Think It Is . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
</p>
<p>12.2 Clustering Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
</p>
<p>12.2.1 Agglomerative and Divisive Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
</p>
<p>12.2.2 Clustering and Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
</p>
<p>12.3 The K-Means Algorithm and Variants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
</p>
<p>12.3.1 How to Choose K . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288
</p>
<p>12.3.2 Soft Assignment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
</p>
<p>12.3.3 Efficient Clustering and Hierarchical K Means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
</p>
<p>12.3.4 K-Mediods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292
</p>
<p>12.3.5 Example: Groceries in Portugal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292
</p>
<p>12.3.6 General Comments on K-Means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
</p>
<p>12.4 Describing Repetition with Vector Quantization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294
</p>
<p>12.4.1 Vector Quantization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296
</p>
<p>12.4.2 Example: Activity from Accelerometer Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
</p>
<p>12.5 The Multivariate Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300
</p>
<p>12.5.1 Affine Transformations and Gaussians . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301
</p>
<p>12.5.2 Plotting a 2D Gaussian: Covariance Ellipses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301
</p>
<p>12.6 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302
</p>
<p>12.6.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302
</p>
<p>12.6.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302
</p>
<p>12.6.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
</p>
<p>12.6.4 Use These Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
</p>
<p>13 Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
</p>
<p>13.1 Regression to Make Predictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
</p>
<p>13.2 Regression to Spot Trends . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306
</p>
<p>13.3 Linear Regression and Least Squares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308
</p>
<p>13.3.1 Linear Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308
</p>
<p>13.3.2 Choosing ˇ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
</p>
<p>13.3.3 Solving the Least Squares Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
</p>
<p>13.3.4 Residuals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310
</p>
<p>13.3.5 R-Squared . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents xix
</p>
<p>13.4 Producing Good Linear Regressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
</p>
<p>13.4.1 Transforming Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
</p>
<p>13.4.2 Problem Data Points Have Significant Impact . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314
</p>
<p>13.4.3 Functions of One Explanatory Variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
</p>
<p>13.4.4 Regularizing Linear Regressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318
</p>
<p>13.5 Exploiting Your Neighbors for Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321
</p>
<p>13.5.1 Using Your Neighbors to Predict More than a Number . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
</p>
<p>13.6 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
</p>
<p>13.6.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
</p>
<p>13.6.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
</p>
<p>13.6.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
</p>
<p>13.6.4 Remember These Procedures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
</p>
<p>14 Markov Chains and Hidden Markov Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331
</p>
<p>14.1 Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331
</p>
<p>14.1.1 Transition Probability Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333
</p>
<p>14.1.2 Stationary Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335
</p>
<p>14.1.3 Example: Markov Chain Models of Text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336
</p>
<p>14.2 Estimating Properties of Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338
</p>
<p>14.2.1 Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338
</p>
<p>14.2.2 Simulation Results as Random Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339
</p>
<p>14.2.3 Simulating Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
</p>
<p>14.3 Example: Ranking the Web by Simulating a Markov Chain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342
</p>
<p>14.4 Hidden Markov Models and Dynamic Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
</p>
<p>14.4.1 Hidden Markov Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
</p>
<p>14.4.2 Picturing Inference with a Trellis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
</p>
<p>14.4.3 Dynamic Programming for HMM&rsquo;s: Formalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346
</p>
<p>14.4.4 Example: Simple Communication Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348
</p>
<p>14.5 You Should . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349
</p>
<p>14.5.1 Remember These Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349
</p>
<p>14.5.2 Remember These Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349
</p>
<p>14.5.3 Remember These Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350
</p>
<p>14.5.4 Be Able to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350
</p>
<p>Part V Mathematical Bits and Pieces
</p>
<p>15 Resources and Extras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355
</p>
<p>15.1 Useful Material About Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355
</p>
<p>15.1.1 The Singular Value Decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 356
</p>
<p>15.1.2 Approximating A Symmetric Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 356
</p>
<p>15.2 Some Special Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 358
</p>
<p>15.3 Splitting a Node in a Decision Tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359
</p>
<p>15.3.1 Accounting for Information with Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359
</p>
<p>15.3.2 Choosing a Split with Information Gain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360
</p>
<p>Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363</p>
<p/>
</div>
<div class="page"><p/>
<p>About the Author
</p>
<p>David Forsyth grew up in Cape Town. He received a B.Sc. (Elec. Eng.) from the University of the Witwatersrand,
</p>
<p>Johannesburg, in 1984, an M.Sc. (Elec. Eng.) from that university in 1986, and a D.Phil. from Balliol College, Oxford,
</p>
<p>in 1989. He spent 3 years on the faculty at the University of Iowa and 10 years on the faculty at the University of California
</p>
<p>at Berkeley and then moved to the University of Illinois. He served as program cochair for IEEE Computer Vision and
</p>
<p>Pattern Recognition in 2000, 2011, and 2018; general cochair for CVPR 2006 and ICCV 2019; and program cochair for the
</p>
<p>European Conference on Computer Vision 2008 and is a regular member of the program committee of all major international
</p>
<p>conferences on computer vision. He has served six terms on the SIGGRAPH program committee. In 2006, he received an
</p>
<p>IEEE technical achievement award, in 2009 he was named an IEEE Fellow, and in 2014 he was named an ACM Fellow. He
</p>
<p>served as editor in chief of IEEE TPAMI from 2014 to 2017. He is lead coauthor of Computer Vision: A Modern Approach, a
</p>
<p>textbook of computer vision that ran to two editions and four languages. Among a variety of odd hobbies, he is a compulsive
</p>
<p>diver, certified up to normoxic trimix level.
</p>
<p>xxi</p>
<p/>
</div>
<div class="page"><p/>
<p>Notation and Conventions
</p>
<p>A dataset is a collection of d-tuples (a d-tuple is an ordered list of d elements). Tuples differ from vectors, because we can
</p>
<p>always add and subtract vectors, but we cannot necessarily add or subtract tuples. There are always N items in any dataset.
</p>
<p>There are always d elements in each tuple in a dataset. The number of elements will be the same for every tuple in any given
</p>
<p>tuple. Sometimes we may not know the value of some elements in some tuples.
</p>
<p>We use the same notation for a tuple and for a vector. Most of our data will be vectors. We write a vector in bold, so x
</p>
<p>could represent a vector or a tuple (the context will make it obvious which is intended).
</p>
<p>The entire dataset is fxg. When we need to refer to the ith data item, we write xi. Assume we have N data items, and we
wish to make a new dataset out of them; we write the dataset made out of these items as fxig (the i is to suggest you are
taking a set of items and making a dataset out of them). If we need to refer to the jth component of a vector xi, we will write
</p>
<p>x
.j/
i (notice this isn&rsquo;t in bold, because it is a component, not a vector, and the j is in parentheses because it isn&rsquo;t a power).
</p>
<p>Vectors are always column vectors.
</p>
<p>When I write fkxg, I mean the dataset created by taking each element of the dataset fxg and multiplying by k; and when I
write fxC cg, I mean the dataset created by taking each element of the dataset fxg and adding c.
</p>
<p>Terms
</p>
<p>&bull; mean .fxg/ is the mean of the dataset fxg (Definition 1.1, page 7).
&bull; std .fxg/ is the standard deviation of the dataset fxg (Definition 1.2, page 10).
&bull; var .fxg/ is the standard deviation of the dataset fxg (Definition 1.3, page 13).
&bull; median .fxg/ is the standard deviation of the dataset fxg (Definition 1.4, page 13).
&bull; percentile.fxg; k/ is the k% percentile of the dataset fxg (Definition 1.5, page 14).
&bull; iqrfxg is the interquartile range of the dataset fxg (Definition 1.7, page 15).
&bull; fOxg is the dataset fxg, transformed to standard coordinates (Definition 1.8, page 18).
&bull; Standard normal data is defined in Definition 18 (page 19).
</p>
<p>&bull; Normal data is defined in Definition 1.10 (page 19).
</p>
<p>&bull; corr .f.x; y/g/ is the correlation between two components x and y of a dataset (Definition 2.1, page 39).
&bull; ; is the empty set.
&bull; &#127; is the set of all possible outcomes of an experiment.
</p>
<p>&bull; Sets are written as A.
</p>
<p>&bull; Ac is the complement of the set A (i.e., &#127; �A).
&bull; E is an event (page 341).
</p>
<p>&bull; P.fEg/ is the probability of event E (page 341).
&bull; P.fEgjfFg/ is the probability of event E , conditioned on event F (page 341).
&bull; p.x/ is the probability that random variable X will take the value x, also written as P.fX D xg/ (page 341).
&bull; p.x; y/ is the probability that random variable X will take the value x and random variable Y will take the value y, also
</p>
<p>written as P.fX D xg \ fY D yg/ (page 341).
&bull;
</p>
<p>argmax
x
</p>
<p>f .x/ means the value of x that maximizes f .x/.
</p>
<p>&bull;
argmin
</p>
<p>x
f .x/ means the value of x that minimizes f .x/.
</p>
<p>&bull; maxi.f .xi// means the largest value that f takes on different elements of the dataset fxig.
&bull; O� is an estimated value of a parameter � .
</p>
<p>xxiii</p>
<p/>
</div>
<div class="page"><p/>
<p>xxiv Notation and Conventions
</p>
<p>Background Information
</p>
<p>Cards: A standard deck of playing cards contains 52 cards. These cards are divided into four suits. The suits are spades and
</p>
<p>clubs (which are black) and hearts and diamonds (which are red). Each suit contains 13 cards: ace, 2, 3, 4, 5, 6, 7, 8, 9, 10,
</p>
<p>jack (sometimes called knave), queen, and king. It is common to call jack, queen, and king court cards.
</p>
<p>Dice: If you look hard enough, you can obtain dice with many different numbers of sides (though I&rsquo;ve never seen a three-
</p>
<p>sided die). We adopt the convention that the sides of an N-sided die are labeled with numbers 1 : : :N and that no number is
</p>
<p>used twice. Most dice are like this.
</p>
<p>Fairness: Each face of a fair coin or die has the same probability of landing upmost in a flip or roll.
</p>
<p>Roulette: A roulette wheel has a collection of slots. There are 36 slots numbered with digits 1 : : : 36, and then one, two, or
</p>
<p>even three slots numbered with zero. There are no other slots. Odd-numbered slots are colored red, and even-numbered slots
</p>
<p>are colored black. Zeros are green. A ball is thrown at the wheel when it is spinning, and it bounces around and eventually
</p>
<p>falls into a slot. If the wheel is properly balanced, the ball has the same probability of falling into each slot. The number of
</p>
<p>the slot the ball falls into is said to &ldquo;come up.&rdquo;</p>
<p/>
</div>
<div class="page"><p/>
<p>Part I
</p>
<p>Describing Datasets</p>
<p/>
</div>
<div class="page"><p/>
<p>1First Tools for Looking at Data
</p>
<p>The single most important question for a working scientist&mdash;perhaps the single most useful question anyone can ask&mdash;is:
</p>
<p>&ldquo;what&rsquo;s going on here?&rdquo; Answering this question requires creative use of different ways to make pictures of datasets, to
</p>
<p>summarize them, and to expose whatever structure might be there. This is an activity that is sometimes known as &ldquo;Descriptive
</p>
<p>Statistics&rdquo;. There isn&rsquo;t any fixed recipe for understanding a dataset, but there is a rich variety of tools we can use to get
</p>
<p>insights.
</p>
<p>1.1 Datasets
</p>
<p>A dataset is a collection of descriptions of different instances of the same phenomenon. These descriptions could take a
</p>
<p>variety of forms, but it is important that they are descriptions of the same thing. For example, my grandfather collected the
</p>
<p>daily rainfall in his garden for many years; we could collect the height of each person in a room; or the number of children
</p>
<p>in each family on a block; or whether 10 classmates would prefer to be &ldquo;rich&rdquo; or &ldquo;famous&rdquo;. There could be more than
</p>
<p>one description recorded for each item. For example, when he recorded the contents of the rain gauge each morning, my
</p>
<p>grandfather could have recorded (say) the temperature and barometric pressure. As another example, one might record the
</p>
<p>height, weight, blood pressure and body temperature of every patient visiting a doctor&rsquo;s office.
</p>
<p>The descriptions in a dataset can take a variety of forms. A description could be categorical, meaning that each data
</p>
<p>item can take a small set of prescribed values. For example, we might record whether each of 100 passers-by preferred to
</p>
<p>be &ldquo;Rich&rdquo; or &ldquo;Famous&rdquo;. As another example, we could record whether the passers-by are &ldquo;Male&rdquo; or &ldquo;Female&rdquo;. Categorical
</p>
<p>data could be ordinal, meaning that we can tell whether one data item is larger than another. For example, a dataset giving
</p>
<p>the number of children in a family for some set of families is categorical, because it uses only non-negative integers, but it is
</p>
<p>also ordinal, because we can tell whether one family is larger than another.
</p>
<p>Some ordinal categorical data appears not to be numerical, but can be assigned a number in a reasonably sensible fashion.
</p>
<p>For example, many readers will recall being asked by a doctor to rate their pain on a scale of 1&ndash;10&mdash;a question that is usually
</p>
<p>relatively easy to answer, but is quite strange when you think about it carefully. As another example, we could ask a set of
</p>
<p>users to rate the usability of an interface in a range from &ldquo;very bad&rdquo; to &ldquo;very good&rdquo;, and then record that using �2 for &ldquo;very
bad&rdquo;, �1 for &ldquo;bad&rdquo;, 0 for &ldquo;neutral&rdquo;, 1 for &ldquo;good&rdquo;, and 2 for &ldquo;very good&rdquo;.
</p>
<p>Many interesting datasets involve continuous variables (like, for example, height or weight or body temperature) when
</p>
<p>you could reasonably expect to encounter any value in a particular range. For example, we might have the heights of all
</p>
<p>people in a particular room, or the rainfall at a particular place for each day of the year.
</p>
<p>You should think of a dataset as a collection of d-tuples (a d-tuple is an ordered list of d elements). Tuples differ from
</p>
<p>vectors, because we can always add and subtract vectors, but we cannot necessarily add or subtract tuples. We will always
</p>
<p>write N for the number of tuples in the dataset, and d for the number of elements in each tuple. The number of elements will
</p>
<p>be the same for every tuple, though sometimes we may not know the value of some elements in some tuples (which means
</p>
<p>we must figure out how to predict their values, which we will do much later).
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_1
</p>
<p>3</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_1">https://doi.org/10.1007/978-3-319-64410-3_1</a></div>
</div>
<div class="page"><p/>
<p>4 1 First Tools for Looking at Data
</p>
<p>Each element of a tuple has its own type. Some elements might be categorical. For example, one dataset we shall see
</p>
<p>several times has entries for Gender; Grade; Age; Race; Urban/Rural; School; Goals; Grades; Sports; Looks; and Money for
</p>
<p>478 children, so d D 11 and N D 478. In this dataset, each entry is categorical data. Clearly, these tuples are not vectors
because one cannot add or subtract (say) Gender, or add Age to Grades.
</p>
<p>Most of our data will be vectors. We use the same notation for a tuple and for a vector. We write a vector in bold, so x
</p>
<p>could represent a vector or a tuple (the context will make it obvious which is intended).
</p>
<p>The entire data set is fxg. When we need to refer to the i&rsquo;th data item, we write xi. Assume we have N data items, and
we wish to make a new dataset out of them; we write the dataset made out of these items as fxig (the i is to suggest you are
taking a set of items and making a dataset out of them).
</p>
<p>In this chapter, we will work mainly with continuous data. We will see a variety of methods for plotting and summarizing
</p>
<p>1-tuples. We can build these plots from a dataset of d-tuples by extracting the r&rsquo;th element of each d-tuple. All through the
</p>
<p>book, we will see many datasets downloaded from various web sources, because people are so generous about publishing
</p>
<p>interesting datasets on the web. In the next chapter, we will look at two-dimensional data, and we look at high dimensional
</p>
<p>data in Chap. 10.
</p>
<p>1.2 What&rsquo;s Happening? Plotting Data
</p>
<p>The very simplest way to present or visualize a dataset is to produce a table. Tables can be helpful, but aren&rsquo;t much use for
</p>
<p>large datasets, because it is difficult to get any sense of what the data means from a table. As a continuous example, Table 1.1
</p>
<p>gives a table of the net worth of a set of people you might meet in a bar (I made this data up). You can scan the table and
</p>
<p>have a rough sense of what is going on; net worths are quite close to $100,000, and there aren&rsquo;t any very big or very small
</p>
<p>numbers. This sort of information might be useful, for example, in choosing a bar.
</p>
<p>People would like to measure, record, and reason about an extraordinary variety of phenomena. Apparently, one can score
</p>
<p>the goodness of the flavor of cheese with a number (bigger is better); Table 1.1 gives a score for each of thirty cheeses (I did
</p>
<p>not make up this data, but downloaded it from http://lib.stat.cmu.edu/DASL/Datafiles/Cheese.html). You should notice that
</p>
<p>a few cheeses have very high scores, and most have moderate scores. It&rsquo;s difficult to draw more significant conclusions from
</p>
<p>the table, though.
</p>
<p>Table 1.2 shows a table for a set of categorical data. Psychologists collected data from students in grades 4&ndash;6 in three
</p>
<p>school districts to understand what factors students thought made other students popular. This fascinating data set can be
</p>
<p>found at http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html, and was prepared by Chase and Dunner in a paper &ldquo;The
</p>
<p>Role of Sports as a Social Determinant for Children,&rdquo; published in Research Quarterly for Exercise and Sport in 1992.
</p>
<p>Among other things, for each student they asked whether the student&rsquo;s goal was to make good grades (&ldquo;Grades&rdquo;, for short);
</p>
<p>to be popular (&ldquo;Popular&rdquo;); or to be good at sports (&ldquo;Sports&rdquo;). They have this information for 478 students, so a table would
</p>
<p>Table 1.1 On the left, net
worths of people you meet in a
bar, in US $; I made this data up,
using some information from the
US Census
</p>
<p>Index Net worth
</p>
<p>1 100, 360
</p>
<p>2 109, 770
</p>
<p>3 96, 860
</p>
<p>4 97, 860
</p>
<p>5 108, 930
</p>
<p>6 124, 330
</p>
<p>7 101, 300
</p>
<p>8 112, 710
</p>
<p>9 106, 740
</p>
<p>10 120, 170
</p>
<p>Index Taste score Index Taste score
</p>
<p>1 12.3 11 34.9
</p>
<p>2 20.9 12 57.2
</p>
<p>3 39 13 0.7
</p>
<p>4 47.9 14 25.9
</p>
<p>5 5.6 15 54.9
</p>
<p>6 25.9 16 40.9
</p>
<p>7 37.3 17 15.9
</p>
<p>8 21.9 18 6.4
</p>
<p>9 18.1 19 18
</p>
<p>10 21 20 38.9
</p>
<p>The index column, which tells you which data item is
being referred to, is usually not displayed in a table
because you can usually assume that the first line is the
first item, and so on. On the right, the taste score (I&rsquo;m not
making this up; higher is better) for 20 different cheeses.
This data is real (i.e. not made up), and it comes from
http://lib.stat.cmu.edu/DASL/Datafiles/Cheese.html</p>
<p/>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/Cheese.html">http://lib.stat.cmu.edu/DASL/Datafiles/Cheese.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html">http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/Cheese.html">http://lib.stat.cmu.edu/DASL/Datafiles/Cheese.html</a></div>
</div>
<div class="page"><p/>
<p>1.2 What&rsquo;s Happening? Plotting Data 5
</p>
<p>Table 1.2 Chase and Dunner, in
a study described in the text,
collected data on what students
thought made other students
popular
</p>
<p>Gender Goal Gender Goal
</p>
<p>Boy Sports Girl Sports
</p>
<p>Boy Popular Girl Grades
</p>
<p>Girl Popular Boy Popular
</p>
<p>Girl Popular Boy Popular
</p>
<p>Girl Popular Boy Popular
</p>
<p>Girl Popular Girl Grades
</p>
<p>Girl Popular Girl Sports
</p>
<p>Girl Grades Girl Popular
</p>
<p>Girl Sports Girl Grades
</p>
<p>Girl Sports Girl Sports
</p>
<p>As part of this effort, they collected information on
(a) the gender and (b) the goal of students. This table
gives the gender (&ldquo;boy&rdquo; or &ldquo;girl&rdquo;) and the goal (to make
good grades&mdash;&ldquo;Grades&rdquo;; to be popular&mdash;&ldquo;Popular&rdquo;; or
to be good at sports&mdash;&ldquo;Sports&rdquo;). The table gives this
information for the first 20 of 478 students; the rest
can be found at http://lib.stat.cmu.edu/DASL/Datafiles/
PopularKids.html. This data is clearly categorical, and
not ordinal
</p>
<p>boy girl
0
</p>
<p>50
</p>
<p>100
</p>
<p>150
</p>
<p>200
</p>
<p>250
</p>
<p>300
</p>
<p>Number of children of each gender
</p>
<p>Sports Grades Popular
0
</p>
<p>50
</p>
<p>100
</p>
<p>150
</p>
<p>200
</p>
<p>250
</p>
<p>Number of children choosing each goal
</p>
<p>Fig. 1.1 On the left, a bar chart of the number of children of each gender in the Chase and Dunner study. Notice that there are about the same
number of boys and girls (the bars are about the same height). On the right, a bar chart of the number of children selecting each of three goals. You
can tell, at a glance, that different goals are more or less popular by looking at the height of the bars
</p>
<p>be very hard to read. Table 1.2 shows the gender and the goal for the first 20 students in this group. It&rsquo;s rather harder to draw
</p>
<p>any serious conclusion from this data, because the full table would be so big. We need a more effective tool than eyeballing
</p>
<p>the table.
</p>
<p>1.2.1 Bar Charts
</p>
<p>A bar chart is a set of bars, one per category, where the height of each bar is proportional to the number of items in that
</p>
<p>category. A glance at a bar chart often exposes important structure in data, for example, which categories are common, and
</p>
<p>which are rare. Bar charts are particularly useful for categorical data. Figure 1.1 shows such bar charts for the genders and
</p>
<p>the goals in the student dataset of Chase and Dunner. You can see at a glance that there are about as many boys as girls, and
</p>
<p>that there are more students who think grades are important than students who think sports or popularity is important. You
</p>
<p>couldn&rsquo;t draw either conclusion from Table 1.2, because I showed only the first 20 items; but a 478 item table is very difficult
</p>
<p>to read.</p>
<p/>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html">http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html">http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html</a></div>
</div>
<div class="page"><p/>
<p>6 1 First Tools for Looking at Data
</p>
<p>0.95 1 1.05 1.1 1.15 1.2 1.25
0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
</p>
<p>N
u
m
</p>
<p>b
er
</p>
<p> o
f 
</p>
<p>d
at
</p>
<p>a 
it
</p>
<p>em
s
</p>
<p>Net worth, in $100, 000s
</p>
<p>Histogram of net worth for 10 individuals
</p>
<p>0 10 20 30 40 50 60 70
0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>12
</p>
<p>14
</p>
<p>N
u
m
</p>
<p>b
er
</p>
<p> o
f 
</p>
<p>d
at
</p>
<p>a 
it
</p>
<p>em
s
</p>
<p>Cheese goodness, in cheese goodness units
</p>
<p>Histogram of cheese goodness score for 30 cheeses
</p>
<p>Fig. 1.2 On the left, a histogram of net worths from the dataset described in the text and shown in Table 1.1. On the right, a histogram of cheese
goodness scores from the dataset described in the text and shown in Table 1.1
</p>
<p>1.2.2 Histograms
</p>
<p>Data is continuous when a data item could take any value in some range or set of ranges. In turn, this means that we can
</p>
<p>reasonably expect a continuous dataset contains few or no pairs of items that have exactly the same value. Drawing a bar
</p>
<p>chart in the obvious way&mdash;one bar per value&mdash;produces a mess of unit height bars, and seldom leads to a good plot. Instead,
</p>
<p>we would like to have fewer bars, each representing more data items. We need a procedure to decide which data items count
</p>
<p>in which bar.
</p>
<p>A simple generalization of a bar chart is a histogram. We divide the range of the data into intervals, which do not need
</p>
<p>to be equal in length. We think of each interval as having an associated pigeonhole, and choose one pigeonhole for each
</p>
<p>data item. We then build a set of boxes, one per interval. Each box sits on its interval on the horizontal axis, and its height is
</p>
<p>determined by the number of data items in the corresponding pigeonhole. In the simplest histogram, the intervals that form
</p>
<p>the bases of the boxes are equally sized. In this case, the height of the box is given by the number of data items in the box.
</p>
<p>Figure 1.2 shows a histogram of the data in Table 1.1. There are five bars&mdash;by my choice; I could have plotted ten bars&mdash;
</p>
<p>and the height of each bar gives the number of data items that fall into its interval. For example, there is one net worth in the
</p>
<p>range between $102,500 and $107,500. Notice that one bar is invisible, because there is no data in that range. This picture
</p>
<p>suggests conclusions consistent with the ones we had from eyeballing the table&mdash;the net worths tend to be quite similar, and
</p>
<p>around $100,000.
</p>
<p>Figure 1.2 also shows a histogram of the data in Table 1.1. There are six bars (0&ndash;10, 10&ndash;20, and so on), and the height
</p>
<p>of each bar gives the number of data items that fall into its interval&mdash;so that, for example, there are 9 cheeses in this dataset
</p>
<p>whose score is greater than or equal to 10 and less than 20. You can also use the bars to estimate other properties. So, for
</p>
<p>example, there are 14 cheeses whose score is less than 20, and 3 cheeses with a score of 50 or greater. This picture is much
</p>
<p>more helpful than the table; you can see at a glance that quite a lot of cheeses have relatively low scores, and few have high
</p>
<p>scores.
</p>
<p>1.2.3 How toMake Histograms
</p>
<p>Usually, one makes a histogram by finding the appropriate command or routine in your programming environment. I use
</p>
<p>Matlab and R, depending on what I feel like. It is useful to understand the procedures used to make and plot histograms.
</p>
<p>Histograms with Even Intervals: The easiest histogram to build uses equally sized intervals. Write xi for the i&rsquo;th number
</p>
<p>in the dataset, xmin for the smallest value, and xmax for the largest value. We divide the range between the smallest and
</p>
<p>largest values into n intervals of even width .xmax � xmin/=n. In this case, the height of each box is given by the number
of items in that interval. We could represent the histogram with an n-dimensional vector of counts. Each entry represents the
</p>
<p>count of the number of data items that lie in that interval. Notice we need to be careful to ensure that each point in the range</p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 Summarizing 1D Data 7
</p>
<p>of values is claimed by exactly one interval. For example, we could have intervals of Œ0 � 1/ and Œ1 � 2/, or we could have
intervals of .0� 1&#141; and .1� 2&#141;. We could not have intervals of Œ0� 1&#141; and Œ1� 2&#141;, because then a data item with the value 1
would appear in two boxes. Similarly, we could not have intervals of .0 � 1/ and .1 � 2/, because then a data item with the
value 1 would not appear in any box.
</p>
<p>Histograms with Uneven Intervals: For a histogram with even intervals, it is natural that the height of each box is the
</p>
<p>number of data items in that box. But a histogram with even intervals can have empty boxes (see Fig. 1.2). In this case, it can
</p>
<p>be more informative to have some larger intervals to ensure that each interval has some data items in it. But how high should
</p>
<p>we plot the box? Imagine taking two consecutive intervals in a histogram with even intervals, and fusing them. It is natural
</p>
<p>that the height of the fused box should be the average height of the two boxes. This observation gives us a rule.
</p>
<p>Write dx for the width of the intervals; n1 for the height of the box over the first interval (which is the number of elements
</p>
<p>in the first box); and n2 for the height of the box over the second interval. The height of the fused box will be .n1 C n2/=2.
Now the area of the first box is n1dx; of the second box is n2dx; and of the fused box is .n1 C n2/dx. For each of these boxes,
the area of the box is proportional to the number of elements in the box. This gives the correct rule: plot boxes such that the
</p>
<p>area of the box is proportional to the number of elements in the box.
</p>
<p>1.2.4 Conditional Histograms
</p>
<p>Most people believe that normal body temperature is 98:4ı in Fahrenheit. If you take other people&rsquo;s temperatures often (for
example, you might have children), you know that some individuals tend to run a little warmer or a little cooler than this
</p>
<p>number. I found data giving the body temperature of a set of individuals at http://www2.stetson.edu/~jrasp/data.htm. This
</p>
<p>data appears on Dr. John Rasp&rsquo;s statistics data website, and apparently first came from a paper in the Journal of Statistics
</p>
<p>Education. As you can see from the histogram (Fig. 1.3), the body temperatures cluster around a small set of numbers. But
</p>
<p>what causes the variation?
</p>
<p>One possibility is gender. We can investigate this possibility by comparing a histogram of temperatures for males with
</p>
<p>histogram of temperatures for females. The dataset gives genders as 1 or 2&mdash;I don&rsquo;t know which is male and which female.
</p>
<p>Histograms that plot only part of a dataset are sometimes called conditional histograms or class-conditional histograms,
</p>
<p>because each histogram is conditioned on something. In this case, each histogram uses only data that comes from a particular
</p>
<p>gender. Figure 1.3 gives the class conditional histograms. It does seem like individuals of one gender run a little cooler than
</p>
<p>individuals of the other. Being certain takes considerably more work than looking at these histograms, because the difference
</p>
<p>might be caused by an unlucky choice of subjects. But the histograms suggests that this work might be worth doing.
</p>
<p>1.3 Summarizing 1D Data
</p>
<p>For the rest of this chapter, we will assume that data items take values that are continuous real numbers. Furthermore, we
</p>
<p>will assume that values can be added, subtracted, and multiplied by constants in a meaningful way. Human heights are one
</p>
<p>example of such data; you can add two heights, and interpret the result as a height (perhaps one person is standing on the
</p>
<p>head of the other). You can subtract one height from another, and the result is meaningful. You can multiply a height by a
</p>
<p>constant&mdash;say, 1/2&mdash;and interpret the result (A is half as high as B).
</p>
<p>1.3.1 TheMean
</p>
<p>One simple and effective summary of a set of data is its mean. This is sometimes known as the average of the data.
</p>
<p>Definition 1.1 (Mean) Assume we have a dataset fxg of N data items, x1; : : : ; xN . Their mean is
</p>
<p>mean .fxg/ D 1
N
</p>
<p>iDN
X
</p>
<p>iD1
xi:</p>
<p/>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
</div>
<div class="page"><p/>
<p>8 1 First Tools for Looking at Data
</p>
<p>96 98 100 102
0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>12
</p>
<p>14
</p>
<p>Histogram of body temperatures in Fahrenheit
</p>
<p>96 98 100 102
0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>12
</p>
<p>14
</p>
<p>Gender 1 body temperatures in Fahrenheit
</p>
<p>96 98 100 102
0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>12
</p>
<p>14
</p>
<p>Gender 2 body temperatures in Fahrenheit
</p>
<p>Fig. 1.3 On top, a histogram of body temperatures, from the dataset published at http://www2.stetson.edu/~jrasp/data.htm. These seem to be
clustered fairly tightly around one value. The bottom row shows histograms for each gender (I don&rsquo;t know which is which). It looks as though one
gender runs slightly cooler than the other
</p>
<p>For example, assume you&rsquo;re in a bar, in a group of ten people who like to talk about money. They&rsquo;re average people, and
</p>
<p>their net worth is given in Table 1.1 (you can choose who you want to be in this story). The mean of this data is $107,903.
</p>
<p>The mean has several important properties you should remember. These properties are easy to prove (and so easy to
</p>
<p>remember). I have broken these out into a box of useful facts below, to emphasize them.
</p>
<p>Useful Facts 1.1 (Properties of the Mean)
</p>
<p>&bull; Scaling data scales the mean: or
</p>
<p>mean .fkxig/ D kmean .fxig/:
</p>
<p>&bull; Translating data translates the mean: or
</p>
<p>mean .fxi C cg/ D mean .fxig/C c:
</p>
<p>&bull; The sum of signed differences from the mean is zero: or,
</p>
<p>N
X
</p>
<p>iD1
.xi � mean .fxig// D 0:
</p>
<p>(continued)</p>
<p/>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
</div>
<div class="page"><p/>
<p>1.3 Summarizing 1D Data 9
</p>
<p>&bull; Choose the number � such that the sum of squared distances of data points to � is minimized. That number is the
</p>
<p>mean. In notation
argmin
</p>
<p>�
</p>
<p>X
</p>
<p>i
</p>
<p>.xi � �/2 D mean .fxig/:
</p>
<p>All this means that the mean is a location parameter; it tells you where the data lies along a number line.
</p>
<p>I prove
argmin
</p>
<p>�
</p>
<p>P
</p>
<p>i.xi � �/2 D mean .fxg/ below. This result means that the mean is the single number that is closest to
all the data items. The mean tells you where the overall blob of data lies. For this reason, it is often referred to as a location
</p>
<p>parameter. If you choose to summarize the dataset with a number that is as close as possible to each data item, the mean
</p>
<p>is the number to choose. The mean is also a guide to what new values will look like, if you have no other information. For
</p>
<p>example, in the case of the bar, a new person walks in, and I must guess that person&rsquo;s net worth. Then the mean is the best
</p>
<p>guess, because it is closest to all the data items we have already seen. In the case of the bar, if a new person walked into this
</p>
<p>bar, and you had to guess that person&rsquo;s net worth, you should choose $107,903.
</p>
<p>Property 1.1 The Average Squared Distance to the Mean is Minimized
</p>
<p>Proposition
argmin
</p>
<p>�
</p>
<p>P
</p>
<p>i.xi � �/2 D mean .fxg/
</p>
<p>Proof Choose the number � such that the sum of squared distances of data points to � is minimized. That number is
</p>
<p>the mean. In notation:
argmin
</p>
<p>�
</p>
<p>X
</p>
<p>i
</p>
<p>.xi � �/2 D mean .fxg/
</p>
<p>We can show this by actually minimizing the expression. We must have that the derivative of the expression we are
</p>
<p>minimizing is zero at the value of � we are seeking. So we have
</p>
<p>d
</p>
<p>d�
</p>
<p>N
X
</p>
<p>iD1
.xi � �/2 D
</p>
<p>N
X
</p>
<p>iD1
2.xi � �/
</p>
<p>D 2
N
X
</p>
<p>iD1
.xi � �/
</p>
<p>D 0
</p>
<p>so that 2Nmean .fxg/ � 2N� D 0, which means that � D mean .fxg/.
</p>
<p>1.3.2 Standard Deviation
</p>
<p>We would also like to know the extent to which data items are close to the mean. This information is given by the standard
</p>
<p>deviation, which is the root mean square of the offsets of data from the mean.
</p>
<p>Definition 1.2 (Standard Deviation) Assume we have a dataset fxg of N data items, x1; : : : ; xN . The standard
deviation of this dataset is:
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>10 1 First Tools for Looking at Data
</p>
<p>std .fxig/D
</p>
<p>v
</p>
<p>u
</p>
<p>u
</p>
<p>t
</p>
<p>1
</p>
<p>N
</p>
<p>iDN
X
</p>
<p>iD1
.xi � mean .fxg//2
</p>
<p>D
p
</p>
<p>mean .f.xi � mean .fxg//2g/:
</p>
<p>You should think of the standard deviation as a scale. It measures the size of the average deviation from the mean for a
</p>
<p>dataset, or how wide the spread of data is. For this reason, it is often referred to as a scale parameter. When the standard
</p>
<p>deviation of a dataset is large, there are many items with values much larger than, or much smaller than, the mean. When the
</p>
<p>standard deviation is small, most data items have values close to the mean. This means it is helpful to talk about how many
</p>
<p>standard deviations away from the mean a particular data item is. Saying that data item xj is &ldquo;within k standard deviations
</p>
<p>from the mean&rdquo; means that
</p>
<p>abs
�
</p>
<p>xj � mean .fxg/
�
</p>
<p>� kstd .fxig/:
</p>
<p>Similarly, saying that data item xj is &ldquo;more than k standard deviations from the mean&rdquo; means that
</p>
<p>abs .xi � mean .fxg// &gt; kstd .fxg/:
</p>
<p>As I will show below, there must be some data at least one standard deviation away from the mean, and there can be very few
</p>
<p>data items that are many standard deviations away from the mean. Standard deviation has very important properties. Again,
</p>
<p>for emphasis, I have broken these properties out in a box below.
</p>
<p>Useful Facts 1.2 (Properties of Standard Deviation)
</p>
<p>&bull; Translating data does not change the standard deviation, i.e. std .fxi C cg/ D std .fxig/.
&bull; Scaling data scales the standard deviation, i.e. std .fkxig/ D kstd .fxig/.
&bull; For any dataset, there can be only a few items that are many standard deviations away from the mean. For N data
</p>
<p>items, xi, whose standard deviation is � , there are at most
1
k2
</p>
<p>data points lying k or more standard deviations away
</p>
<p>from the mean.
</p>
<p>&bull; For any dataset, there must be at least one data item that is at least one standard deviation away from the mean, that
</p>
<p>is, .std .fxg//2 � maxi.xi � mean .fxg//2:
</p>
<p>The standard deviation is often referred to as a scale parameter; it tells you how broadly the data spreads about the
</p>
<p>mean.
</p>
<p>Property 1.2 For any dataset, it is hard for data items to get many standard deviations away from the mean.
</p>
<p>Proposition Assume we have a dataset fxg of N data items, x1; : : : ; xN . Assume the standard deviation of this dataset
is std .fxg/ D � . Then there are at most 1
</p>
<p>k2
data points lying k or more standard deviations away from the mean.
</p>
<p>Proof Assume the mean is zero. There is no loss of generality here, because translating data translates the mean, but
</p>
<p>doesn&rsquo;t change the standard deviation. Now we must construct a dataset with the largest possible fraction r of data
</p>
<p>points lying k or more standard deviations from the mean. To achieve this, our data should have N.1 � r/ data points
each with the value 0, because these contribute 0 to the standard deviation. It should have Nr data points with the value
</p>
<p>k� ; if they are further from zero than this, each will contribute more to the standard deviation, so the fraction of such
</p>
<p>points will be fewer. Because
</p>
<p>std .fxg/ D � D
</p>
<p>s
</p>
<p>P
</p>
<p>i x
2
i
</p>
<p>N
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 Summarizing 1D Data 11
</p>
<p>we have that, for this rather specially constructed dataset,
</p>
<p>� D
</p>
<p>s
</p>
<p>Nrk2�2
</p>
<p>N
</p>
<p>so that
</p>
<p>r D 1
k2
:
</p>
<p>We constructed the dataset so that r would be as large as possible, so
</p>
<p>r � 1
k2
</p>
<p>for any kind of data at all.
</p>
<p>The bound in proof 1.2 is true for any kind of data. The crucial point about the standard deviation is that you won&rsquo;t see
</p>
<p>much data that lies many standard deviations from the mean, because you can&rsquo;t. This bound implies that, for example, at most
</p>
<p>100% of any dataset could be one standard deviation away from the mean, 25% of any dataset is 2 standard deviations away
</p>
<p>from the mean and at most 11% of any dataset could be 3 standard deviations away from the mean. But the configuration of
</p>
<p>data that achieves this bound is very unusual. This means the bound tends to wildly overstate how much data is far from the
</p>
<p>mean for most practical datasets. Most data has more random structure, meaning that we expect to see very much less data
</p>
<p>far from the mean than the bound predicts. For example, much data can reasonably be modelled as coming from a normal
</p>
<p>distribution (a topic we&rsquo;ll go into later). For such data, we expect that about 68% of the data is within one standard deviation
</p>
<p>of the mean, 95% is within two standard deviations of the mean, and 99% is within three standard deviations of the mean,
</p>
<p>and the percentage of data that is within (say) ten standard deviations of the mean is essentially indistinguishable from 100%.
</p>
<p>Property 1.3 For any dataset, there must be at least one data item that is at least one standard deviation away from the
</p>
<p>mean.
</p>
<p>Proposition
</p>
<p>.std .fxg//2 � max
i
.xi � mean .fxg//2:
</p>
<p>Proof You can see this by looking at the expression for standard deviation. We have
</p>
<p>std .fxg/ D
</p>
<p>v
</p>
<p>u
</p>
<p>u
</p>
<p>t
</p>
<p>1
</p>
<p>N
</p>
<p>iDN
X
</p>
<p>iD1
.xi � mean .fxg//2:
</p>
<p>Now, this means that
</p>
<p>N.std .fxg//2 D
iDN
X
</p>
<p>iD1
.xi � mean .fxg//2:
</p>
<p>But
</p>
<p>iDN
X
</p>
<p>iD1
.xi � mean .fxg//2 � N max
</p>
<p>i
.xi � mean .fxg//2
</p>
<p>so
</p>
<p>.std .fxg//2 � max
i
.xi � mean .fxg//2:</p>
<p/>
</div>
<div class="page"><p/>
<p>12 1 First Tools for Looking at Data
</p>
<p>The properties proved in proof 1.2 and proof 1.3 mean that the standard deviation is quite informative. Very little data is
</p>
<p>many standard deviations away from the mean; similarly, at least some of the data should be one or more standard deviations
</p>
<p>away from the mean. So the standard deviation tells us how data points are scattered about the mean.
</p>
<p>There is an ambiguity that comes up often here because two (very slightly) different numbers are called the standard
</p>
<p>deviation of a dataset. One&mdash;the one we use in this chapter&mdash;is an estimate of the scale of the data, as we describe it. The
</p>
<p>other differs from our expression very slightly; one computes
</p>
<p>stdunbiased .fxg/ D
</p>
<p>s
</p>
<p>P
</p>
<p>i.xi � mean .fxg//2
N � 1
</p>
<p>(notice the N�1 for our N). If N is large, this number is basically the same as the number we compute, but for smaller N there
is a difference that can be significant. Irritatingly, this number is also called the standard deviation; even more irritatingly, we
</p>
<p>will have to deal with it, but not yet. I mention it now because you may look up terms I have used, find this definition, and
</p>
<p>wonder whether I know what I&rsquo;m talking about. In this case, I do (although I would say that).
</p>
<p>The confusion arises because sometimes the datasets we see are actually samples of larger datasets. For example, in some
</p>
<p>circumstances you could think of the net worth dataset as a sample of all the net worths in the USA. In such cases, we are
</p>
<p>often interested in the standard deviation of the underlying dataset that was sampled (rather than of the dataset of samples
</p>
<p>that you have). The second number is a slightly better way to estimate this standard deviation than the definition we have
</p>
<p>been working with. Don&rsquo;t worry&mdash;the N in our expressions is the right thing to use for what we&rsquo;re doing.
</p>
<p>1.3.3 ComputingMean and Standard Deviation Online
</p>
<p>One useful feature of means and standard deviations is that you can estimate them online. Assume that, rather than seeing N
</p>
<p>elements of a dataset in one go, you get to see each one once in some order, and you cannot store them. This means that after
</p>
<p>seeing k elements, you will have an estimate of the mean based on those k elements. Write O�k for this estimate. Because
</p>
<p>mean .fxg/ D
P
</p>
<p>i xi
</p>
<p>N
</p>
<p>and
</p>
<p>kC1
X
</p>
<p>iD1
xi D
</p>
<p> 
</p>
<p>k
X
</p>
<p>iD1
xi
</p>
<p>!
</p>
<p>C xkC1;
</p>
<p>we have the following recursion
</p>
<p>O�kC1 D
.k O�k/C xkC1
</p>
<p>.kC 1/ :
</p>
<p>Similarly, after seeing k elements, you will have an estimate of the standard deviation based on those k elements. Write O�k
for this estimate. We have the recursion
</p>
<p>O�kC1 D
</p>
<p>s
</p>
<p>.k O�2k /C .xkC1 � O�kC1/2
.kC 1/ :
</p>
<p>1.3.4 Variance
</p>
<p>It turns out that thinking in terms of the square of the standard deviation, which is known as the variance, will allow us to
</p>
<p>generalize our summaries to apply to higher dimensional data.</p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 Summarizing 1D Data 13
</p>
<p>Definition 1.3 (Variance) Assume we have a dataset fxg of N data items, x1; : : : ; xN . where N &gt; 1. Their variance is:
</p>
<p>var .fxg/ D 1
N
</p>
<p> 
</p>
<p>iDN
X
</p>
<p>iD1
.xi � mean .fxg//2
</p>
<p>!
</p>
<p>D mean
�˚
</p>
<p>.xi � mean .fxg//2
��
</p>
<p>:
</p>
<p>One good way to think of the variance is as the mean-square error you would incur if you replaced each data item with
</p>
<p>the mean. Another is that it is the square of the standard deviation. The properties of the variance follow from the fact that it
</p>
<p>is the square of the standard deviation. I have broken these out in a box, for emphasis.
</p>
<p>Useful Facts 1.3 (Properties of Variance)
</p>
<p>&bull; var .fxC cg/ D var .fxg/.
&bull; var .fkxg/ D k2var .fxg/.
</p>
<p>While one could restate the other two properties of the standard deviation in terms of the variance, it isn&rsquo;t really natural
</p>
<p>to do so. The standard deviation is in the same units as the original data, and should be thought of as a scale. Because the
</p>
<p>variance is the square of the standard deviation, it isn&rsquo;t a natural scale (unless you take its square root!).
</p>
<p>1.3.5 TheMedian
</p>
<p>One problem with the mean is that it can be affected strongly by extreme values. Go back to the bar example, of Sect. 1.3.1.
</p>
<p>Now Warren Buffett (or Bill Gates, or your favorite billionaire) walks in. What happened to the average net worth?
</p>
<p>Assume your billionaire has net worth $1,000,000,000. Then the mean net worth suddenly has become
</p>
<p>10�$107; 903C$1; 000; 000; 000
11
</p>
<p>D$91; 007; 184
</p>
<p>But this mean isn&rsquo;t a very helpful summary of the people in the bar. It is probably more useful to think of the net worth data
</p>
<p>as ten people together with one billionaire. The billionaire is known as an outlier.
</p>
<p>One way to get outliers is that a small number of data items are very different, due to minor effects you don&rsquo;t want to
</p>
<p>model. Another is that the data was misrecorded, or mistranscribed. Another possibility is that there is just too much variation
</p>
<p>in the data to summarize it well. For example, a small number of extremely wealthy people could change the average net
</p>
<p>worth of US residents dramatically, as the example shows. An alternative to using a mean is to use a median.
</p>
<p>Definition 1.4 (Median) The median of a set of data points is obtained by sorting the data points, and finding the
</p>
<p>point halfway along the list. If the list is of even length, it&rsquo;s usual to average the two numbers on either side of the
</p>
<p>middle. We write
</p>
<p>median .fxg/
</p>
<p>for the operator that returns the median.
</p>
<p>For example,
</p>
<p>median .f3; 5; 7g/ D 5;
</p>
<p>median .f3; 4; 5; 6; 7g/ D 5;</p>
<p/>
</div>
<div class="page"><p/>
<p>14 1 First Tools for Looking at Data
</p>
<p>and
</p>
<p>median .f3; 4; 5; 6g/ D 4:5:
</p>
<p>For much, but not all, data, you can expect that roughly half the data is smaller than the median, and roughly half is larger
</p>
<p>than the median. Sometimes this property fails. For example,
</p>
<p>median .f1; 2; 2; 2; 2; 2; 2; 2; 3g/ D 2:
</p>
<p>With this definition, the median of our list of net worths is $107;835. If we insert the billionaire, the median becomes
</p>
<p>$108;930. Notice by how little the number has changed&mdash;it remains an effective summary of the data. You can think of
</p>
<p>the median of a dataset as giving the &ldquo;middle&rdquo; or &ldquo;center&rdquo; value. It is another way of estimating where the dataset lies on
</p>
<p>a number line (and so is another location parameter). This means it is rather like the mean, which also gives a (slightly
</p>
<p>differently defined) &ldquo;middle&rdquo; or &ldquo;center&rdquo; value. The mean has the important properties that if you translate the dataset, the
</p>
<p>mean translates, and if you scale the dataset, the mean scales. The median has these properties, too, which I have broken out
</p>
<p>in a box. Each is easily proved, and proofs are relegated to the exercises.
</p>
<p>Useful Facts 1.4 (Properties of the Median)
</p>
<p>&bull; median .fxC cg/ D median .fxg/C c.
&bull; median .fkxg/ D kmedian .fxg/.
</p>
<p>1.3.6 Interquartile Range
</p>
<p>Outliers are a nuisance in all sorts of ways. Plotting the histogram of the net worth data with the billionaire included will be
</p>
<p>tricky. Either you leave the billionaire out of the plot, or all the histogram bars are tiny. Visualizing this plot shows outliers
</p>
<p>can affect standard deviations severely, too. For our net worth data, the standard deviation without the billionaire is $9265,
</p>
<p>but if we put the billionaire in there, it is $3:014 � 108. When the billionaire is in the dataset, the mean is about 91M$ and
the standard deviation is about 300M$&mdash;so all but one of the data items lie about a third of a standard deviation away from
</p>
<p>the mean on the small side. The other data item (the billionaire) is about three standard deviations away from the mean on
</p>
<p>the large side. In this case, the standard deviation has done its work of informing us that there are huge changes in the data,
</p>
<p>but isn&rsquo;t really helpful as a description of the data.
</p>
<p>The problem is this: describing the net worth data with billionaire as a having a mean of $9:101 � 107 with a standard
deviation of $3:014 � 108 isn&rsquo;t really helpful. Instead, the data really should be seen as a clump of values that are near
$100;000 and moderately close to one another, and one massive number (the billionaire outlier).
</p>
<p>One thing we could do is simply remove the billionaire and compute mean and standard deviation. This isn&rsquo;t always easy
</p>
<p>to do, because it&rsquo;s often less obvious which points are outliers. An alternative is to follow the strategy we did when we used
</p>
<p>the median. Find a summary that describes scale, but is less affected by outliers than the standard deviation. This is the
</p>
<p>interquartile range; to define it, we need to define percentiles and quartiles, which are useful anyway.
</p>
<p>Definition 1.5 (Percentile) The k&rsquo;th percentile is the value such that k% of the data is less than or equal to that value.
</p>
<p>We write percentile.fxg; k/ for the k&rsquo;th percentile of dataset fxg.
</p>
<p>Definition 1.6 (Quartiles) The first quartile of the data is the value such that 25% of the data is less than or equal to
</p>
<p>that value (i.e. percentile.fxg; 25/). The second quartile of the data is the value such that 50% of the data is less than
or equal to that value, which is usually the median (i.e. percentile.fxg; 50/). The third quartile of the data is the value
such that 75% of the data is less than or equal to that value (i.e. percentile.fxg; 75/).</p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 Summarizing 1D Data 15
</p>
<p>Definition 1.7 (Interquartile Range) The interquartile range of a dataset fxg is iqrfxg D percentile.fxg; 75/ �
percentile.fxg; 25/.
</p>
<p>Like the standard deviation, the interquartile range gives an estimate of how widely the data is spread out. But it is quite
</p>
<p>well-behaved in the presence of outliers. For our net worth data without the billionaire, the interquartile range is $12;350;
</p>
<p>with the billionaire, it is $17;710. You can think of the interquartile range of a dataset as giving an estimate of the scale of the
</p>
<p>difference from the mean. This means it is rather like the standard deviation, which also gives a (slightly differently defined)
</p>
<p>scale. The standard deviation has the important properties that if you translate the dataset, the standard deviation translates,
</p>
<p>and if you scale the dataset, the standard deviation scales. The interquartile range has these properties, too, which I have
</p>
<p>broken out into a box. Each is easily proved, and proofs are relegated to the exercises.
</p>
<p>Useful Facts 1.5 (Properties of the Interquartile Range)
</p>
<p>&bull; iqrfxC cg D iqrfxg.
&bull; iqrfkxg D kiqrfxg.
</p>
<p>For most datasets, interquartile ranges tend to be somewhat larger than standard deviations. This isn&rsquo;t really a problem.
</p>
<p>Each is a method for estimating the scale of the data&mdash;the range of values above and below the mean that you are likely
</p>
<p>to see. It is neither here nor there if one method yields slightly larger estimates than another, as long as you don&rsquo;t compare
</p>
<p>estimates across methods.
</p>
<p>1.3.7 Using Summaries Sensibly
</p>
<p>One should be careful how one summarizes data. For example, the statement that &ldquo;the average US family has 2.6 children&rdquo;
</p>
<p>invites mockery (the example is from Andrew Vickers&rsquo; book What is a p-value anyway?), because you can&rsquo;t have fractions
</p>
<p>of a child&mdash;no family has 2.6 children. A more accurate way to say things might be &ldquo;the average of the number of children in
</p>
<p>a US family is 2.6&rdquo;, but this is clumsy. What is going wrong here is the 2.6 is a mean, but the number of children in a family
</p>
<p>is a categorical variable. Reporting the mean of a categorical variable is often a bad idea, because you may never encounter
</p>
<p>this value (the 2.6 children). For a categorical variable, giving the median value and perhaps the interquartile range often
</p>
<p>makes much more sense than reporting the mean.
</p>
<p>For continuous variables, reporting the mean is reasonable because you could expect to encounter a data item with this
</p>
<p>value, even if you haven&rsquo;t seen one in the particular data set you have. It is sensible to look at both mean and median; if
</p>
<p>they&rsquo;re significantly different, then there is probably something going on that is worth understanding. You&rsquo;d want to plot the
</p>
<p>data using the methods of the next section before you decided what to report.
</p>
<p>You should also be careful about how precisely numbers are reported (equivalently, the number of significant figures).
</p>
<p>Numerical and statistical software will produce very large numbers of digits freely, but not all are always useful. This is a
</p>
<p>particular nuisance in the case of the mean, because you might add many numbers, then divide by a large number; in this
</p>
<p>case, you will get many digits, but some might not be meaningful. For example, Vickers (in the same book) describes a paper
</p>
<p>reporting the mean length of pregnancy as 32.833 weeks. That fifth digit suggests we know the mean length of pregnancy
</p>
<p>to about 0.001 weeks, or roughly 10 min. Neither medical interviewing nor people&rsquo;s memory for past events is that detailed.
</p>
<p>Furthermore, when you interview them about embarrassing topics, people quite often lie. There is no prospect of knowing
</p>
<p>this number with this precision.
</p>
<p>People regularly report silly numbers of digits because it is easy to miss the harm caused by doing so. But the harm is
</p>
<p>there: you are implying to other people, and to yourself, that you know something more accurately than you do. At some
</p>
<p>point, someone may suffer for it.</p>
<p/>
</div>
<div class="page"><p/>
<p>16 1 First Tools for Looking at Data
</p>
<p>1.4 Plots and Summaries
</p>
<p>Knowing the mean, standard deviation, median and interquartile range of a dataset gives us some information about what its
</p>
<p>histogram might look like. In fact, the summaries give us a language in which to describe a variety of characteristic properties
</p>
<p>of histograms that are worth knowing about (Sect. 1.4.1). Quite remarkably, many different datasets have histograms that have
</p>
<p>about the same shape (Sect. 1.4.2). For such data, we know roughly what percentage of data items are how far from the mean.
</p>
<p>Complex datasets can be difficult to interpret with histograms alone, because it is hard to compare many histograms by
</p>
<p>eye. Section 1.4.3 describes a clever plot of various summaries of datasets that makes it easier to compare many cases.
</p>
<p>1.4.1 Some Properties of Histograms
</p>
<p>The tails of a histogram are the relatively uncommon values that are significantly larger (resp. smaller) than the value at the
</p>
<p>peak (which is sometimes called the mode). A histogram is unimodal if there is only one peak; if there are more than one,
</p>
<p>it is multimodal, with the special term bimodal sometimes being used for the case where there are two peaks (Fig. 1.4).
</p>
<p>The histograms we have seen have been relatively symmetric, where the left and right tails are about as long as one another.
</p>
<p>Another way to think about this is that values a lot larger than the mean are about as common as values a lot smaller than the
</p>
<p>mean. Not all data is symmetric. In some datasets, one or another tail is longer (Fig. 1.5). This effect is called skew.
</p>
<p>Skew appears often in real data. SOCR (the Statistics Online Computational Resource) publishes a number of datasets.
</p>
<p>Here we discuss a dataset of citations to faculty publications. For each of five UCLA faculty members, SOCR collected the
</p>
<p>number of times each of the papers they had authored had been cited by other authors (data at http://wiki.stat.ucla.edu/socr/
</p>
<p>index.php/SOCR_Data_Dinov_072108_H_Index_Pubs). Generally, a small number of papers get many citations, and many
</p>
<p>papers get few citations. We see this pattern in the histograms of citation numbers (Fig. 1.6). These are very different from
</p>
<p>mode
</p>
<p>Bimodal modes
</p>
<p>Population 1 Population 2
Population 1 Population 2
</p>
<p>Multimodal modes
</p>
<p>Population 3
</p>
<p>Fig. 1.4 Many histograms are unimodal, like the example on the top; there is one peak, or mode. Some are bimodal (two peaks; bottom left) or
even multimodal (two or more peaks; bottom right). One common reason (but not the only reason) is that there are actually two populations being
conflated in the histograms. For example, measuring adult heights might result in a bimodal histogram, if male and female heights were slightly
different. As another example, measuring the weight of dogs might result in a multimodal histogram if you did not distinguish between breeds (eg
chihauhau, terrier, german shepherd, pyranean mountain dog, etc.)</p>
<p/>
<div class="annotation"><a href="http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_072108_H_Index_Pubs">http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_072108_H_Index_Pubs</a></div>
<div class="annotation"><a href="http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_072108_H_Index_Pubs">http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_072108_H_Index_Pubs</a></div>
</div>
<div class="page"><p/>
<p>1.4 Plots and Summaries 17
</p>
<p>left
</p>
<p>tail
</p>
<p>right
</p>
<p>tail
</p>
<p>mode
median
</p>
<p>mean
</p>
<p>Left Skew
</p>
<p>left
</p>
<p>tail
right
</p>
<p>tail
</p>
<p>mode
median
</p>
<p>mean
</p>
<p>Right Skew
</p>
<p>left
</p>
<p>tail
</p>
<p>right
</p>
<p>tail
</p>
<p>mode, median, mean,  all on top of
</p>
<p>one another
</p>
<p>Symmetric Histogram
</p>
<p>Fig. 1.5 On the top, an example of a symmetric histogram, showing its tails (relatively uncommon values that are significantly larger or smaller
than the peak or mode). Lower left, a sketch of a left-skewed histogram. Here there are few large values, but some very small values that occur with
significant frequency. We say the left tail is &ldquo;long&rdquo;, and that the histogram is left skewed. You may find this confusing, because the main bump is
to the right&mdash;one way to remember this is that the left tail has been stretched. Lower right, a sketch of a right-skewed histogram. Here there are
few small values, but some very large values that occur with significant frequency. We say the right tail is &ldquo;long&rdquo;, and that the histogram is right
skewed
</p>
<p>0 100 200 300 400 500
0
</p>
<p>100
</p>
<p>200
</p>
<p>300
</p>
<p>400
</p>
<p>Histogram of citations for faculty member A
</p>
<p>1000 2000 3000 4000 5000
0
</p>
<p>5
</p>
<p>10
</p>
<p>15
</p>
<p>Birth weights for 44 babies born in Brisbane
</p>
<p>Fig. 1.6 On the left, a histogram of citations for a faculty member, from data at http://wiki.stat.ucla.edu/socr/index.php/
SOCR_Data_Dinov_072108_H_Index_Pubs. Very few publications have many citations, and many publications have few. This means the
histogram is strongly right-skewed. On the right, a histogram of birth weights for 44 babies borne in Brisbane in 1997. This histogram looks
slightly left-skewed</p>
<p/>
<div class="annotation"><a href="http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_072108_H_Index_Pubs">http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_072108_H_Index_Pubs</a></div>
<div class="annotation"><a href="http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_072108_H_Index_Pubs">http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_072108_H_Index_Pubs</a></div>
</div>
<div class="page"><p/>
<p>18 1 First Tools for Looking at Data
</p>
<p>(say) the body temperature pictures. In the citation histograms, there are many data items that have very few citations, and
</p>
<p>few that have many citations. This means that the right tail of the histogram is longer, so the histogram is skewed to the
</p>
<p>right.
</p>
<p>One way to check for skewness is to look at the histogram; another is to compare mean and median (though this is not
</p>
<p>foolproof). For the first citation histogram, the mean is 24.7 and the median is 7.5; for the second, the mean is 24.4, and the
</p>
<p>median is 11. In each case, the mean is a lot bigger than the median. Recall the definition of the median (form a ranked list
</p>
<p>of the data points, and find the point halfway along the list). For much data, the result is larger than about half of the data set
</p>
<p>and smaller than about half the dataset. So if the median is quite small compared to the mean, then there are many small data
</p>
<p>items and a small number of data items that are large&mdash;the right tail is longer, so the histogram is skewed to the right.
</p>
<p>Left-skewed data also occurs; Fig. 1.6 shows a histogram of the birth weights of 44 babies born in Brisbane, in 1997
</p>
<p>(from http://www.amstat.org/publications/jse/jse_data_archive.htm). This data appears to be somewhat left-skewed, as birth
</p>
<p>weights can be a lot smaller than the mean, but tend not to be much larger than the mean.
</p>
<p>Skewed data is often, but not always, the result of constraints. For example, good obstetrical practice tries to ensure that
</p>
<p>very large birth weights are rare (birth is typically induced before the baby gets too heavy), but it may be quite hard to avoid
</p>
<p>some small birth weights. This could skew birth weights to the left (because large babies will get born, but will not be as
</p>
<p>heavy as they could be if obstetricians had not interfered). Similarly, income data can be skewed to the right by the fact that
</p>
<p>income is always positive. Test mark data is often skewed&mdash;whether to right or left depends on the circumstances&mdash;by the
</p>
<p>fact that there is a largest possible mark and a smallest possible mark.
</p>
<p>1.4.2 Standard Coordinates and Normal Data
</p>
<p>It is useful to look at lots of histograms, because it is often possible to get some useful insights about data. However, in
</p>
<p>their current form, histograms are hard to compare. This is because each is in a different set of units. A histogram for length
</p>
<p>data will consist of boxes whose horizontal units are, say, metres; a histogram for mass data will consist of boxes whose
</p>
<p>horizontal units are in, say, kilograms. Furthermore, these histograms typically span different ranges.
</p>
<p>We can make histograms comparable by (a) estimating the &ldquo;location&rdquo; of the plot on the horizontal axis and (b) estimating
</p>
<p>the &ldquo;scale&rdquo; of the plot. The location is given by the mean, and the scale by the standard deviation. We could then normalize
</p>
<p>the data by subtracting the location (mean) and dividing by the standard deviation (scale). The resulting values are unitless,
</p>
<p>and have zero mean. They are often known as standard coordinates.
</p>
<p>Definition 1.8 (Standard Coordinates) Assume we have a dataset fxg of N data items, x1; : : : ; xN . We represent
these data items in standard coordinates by computing
</p>
<p>Oxi D
.xi � mean .fxg//
</p>
<p>std .fxg/ :
</p>
<p>We write fOxg for a dataset that happens to be in standard coordinates.
</p>
<p>Standard coordinates have some important properties. Assume we have N data items. Write xi for the i&rsquo;th data item, and
</p>
<p>Oxi for the i&rsquo;th data item in standard coordinates (I sometimes refer to these as &ldquo;normalized data items&rdquo;). Then we have
</p>
<p>mean .fOxg/ D 0:
</p>
<p>We also have that
</p>
<p>std .fOxg/ D 1:
</p>
<p>An extremely important fact about data is that, for many kinds of data, histograms of these standard coordinates look the
</p>
<p>same. Many completely different datasets produce a histogram that, in standard coordinates, has a very specific appearance.
</p>
<p>It is symmetric and unimodal, and it looks like a bump. If there were enough data points and the histogram boxes were small
</p>
<p>enough, the histogram would look like the curve in Fig. 1.7. This phenomenon is so important that data of this form has a
</p>
<p>special name.</p>
<p/>
<div class="annotation"><a href="http://www.amstat.org/publications/jse/jse_data_archive.htm">http://www.amstat.org/publications/jse/jse_data_archive.htm</a></div>
</div>
<div class="page"><p/>
<p>1.4 Plots and Summaries 19
</p>
<p>&minus;4 &minus;3 &minus;2 &minus;1 0 1 2 3 4
0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>0.4
</p>
<p>0.5
</p>
<p>The Standard Normal Curve
</p>
<p>&minus;6 &minus;4 &minus;2 0 2 4 6
0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
</p>
<p>Volumes of oysters, standard coordinates
</p>
<p>&minus;6 &minus;4 &minus;2 0 2 4 6
0
</p>
<p>10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>60
</p>
<p>Human heights, standard coordinates
</p>
<p>&minus;6 &minus;4 &minus;2 0 2 4 6
0
</p>
<p>10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>60
</p>
<p>Human weights, standard coordinates
</p>
<p>Fig. 1.7 Data is standard normal data when its histogram takes a stylized, bell-shaped form, plotted above. One usually requires a lot of data and
very small histogram boxes for this form to be reproduced closely. Nonetheless, the histogram for normal data is unimodal (has a single bump)
and is symmetric; the tails fall off fairly fast, and there are few data items that are many standard deviations from the mean. Many quite different
data sets have histograms that are similar to the normal curve; I show three such datasets here
</p>
<p>Definition 1.9 (Standard Normal Data) Data is standard normal data if, when we have a great deal of data, the
</p>
<p>histogram of the data in standard coordinates is a close approximation to the standard normal curve. This curve is
</p>
<p>given by
</p>
<p>y.x/ D 1p
2�
</p>
<p>e.�x
2=2/
</p>
<p>(which is shown in Fig. 1.7).
</p>
<p>Definition 1.10 (Normal Data) Data is normal data if, when we subtract the mean and divide by the standard
</p>
<p>deviation (i.e. compute standard coordinates), it becomes standard normal data.
</p>
<p>It is not always easy to tell whether data is normal or not, and there are a variety of tests one can use, which we
</p>
<p>discuss later. However, there are many examples of normal data. Figure 1.7 shows a diverse variety of data sets, plotted
</p>
<p>as histograms in standard coordinates. These include: the volumes of 30 oysters (from http://www.amstat.org/publications/
</p>
<p>jse/jse_data_archive.htm; look for 30oysters.dat.txt); human heights (from http://www2.stetson.edu/~jrasp/data.htm; look</p>
<p/>
<div class="annotation"><a href="http://www.amstat.org/publications/jse/jse_data_archive.htm">http://www.amstat.org/publications/jse/jse_data_archive.htm</a></div>
<div class="annotation"><a href="http://www.amstat.org/publications/jse/jse_data_archive.htm">http://www.amstat.org/publications/jse/jse_data_archive.htm</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
</div>
<div class="page"><p/>
<p>20 1 First Tools for Looking at Data
</p>
<p>for bodyfat.xls, and notice that I removed two outliers); and human weights (from http://www2.stetson.edu/~jrasp/data.htm;
</p>
<p>look for bodyfat.xls, again, I removed two outliers).
</p>
<p>For the moment, assume we know that a dataset is normal. Then we expect it to have the properties in the following
</p>
<p>box. In turn, these properties imply that data that contains outliers (points many standard deviations away from the mean) is
</p>
<p>not normal. This is usually a very safe assumption. It is quite common to model a dataset by excluding a small number of
</p>
<p>outliers, then modelling the remaining data as normal. For example, if I exclude two outliers from the height and weight data
</p>
<p>from http://www2.stetson.edu/~jrasp/data.htm, the data looks pretty close to normal.
</p>
<p>Useful Facts 1.6 (Properties of Normal Data)
</p>
<p>&bull; If we normalize it, its histogram will be close to the standard normal curve. This means, among other things, that
</p>
<p>the data is not significantly skewed.
</p>
<p>&bull; About 68% of the data lie within one standard deviation of the mean. We will prove this later.
</p>
<p>&bull; About 95% of the data lie within two standard deviations of the mean. We will prove this later.
</p>
<p>&bull; About 99% of the data lie within three standard deviations of the mean. We will prove this later.
</p>
<p>1.4.3 Box Plots
</p>
<p>It is usually hard to compare multiple histograms by eye. One problem with comparing histograms is the amount of space they
</p>
<p>take up on a plot, because each histogram involves multiple vertical bars. This means it is hard to plot multiple overlapping
</p>
<p>histograms cleanly. If you plot each one on a separate figure, you have to handle a large number of separate figures; either
</p>
<p>you print them too small to see enough detail, or you have to keep flipping over pages.
</p>
<p>A box plot is a way to plot data that simplifies comparison. A box plot displays a dataset as a vertical picture. There is
</p>
<p>a vertical box whose height corresponds to the interquartile range of the data (the width is just to make the figure easy to
</p>
<p>interpret). Then there is a horizontal line for the median; and the behavior of the rest of the data is indicated with whiskers
</p>
<p>and/or outlier markers. This means that each dataset makes is represented by a vertical structure, making it easy to show
</p>
<p>multiple datasets on one plot and interpret the plot (Fig. 1.8).
</p>
<p>To build a box plot, we first plot a box that runs from the first to the third quartile. We then show the median with a
</p>
<p>horizontal line. We then decide which data items should be outliers. A variety of rules are possible; for the plots I show, I
</p>
<p>used the rule that data items that are larger than q3C1:5.q3�q1/ or smaller than q1�1:5.q3�q1/, are outliers. This criterion
looks for data items that are more than one and a half interquartile ranges above the third quartile, or more than one and a
</p>
<p>half interquartile ranges below the first quartile.
</p>
<p>Once we have identified outliers, we plot these with a special symbol (crosses in the plots I show). We then plot whiskers,
</p>
<p>which show the range of non-outlier data. We draw a whisker from q1 to the smallest data item that is not an outlier, and from
</p>
<p>q3 to the largest data item that is not an outlier. While all this sounds complicated, any reasonable programming environment
</p>
<p>will have a function that will do it for you. Figure 1.8 shows an example box plot. Notice that the rich graphical structure
</p>
<p>means it is quite straightforward to compare two histograms.
</p>
<p>1.5 Whose is Bigger? Investigating Australian Pizzas
</p>
<p>At http://www.amstat.org/publications/jse/jse_data_archive.htm), there is a dataset giving the diameter of pizzas, measured
</p>
<p>in Australia (search for the word &ldquo;pizza&rdquo;). This website also gives the backstory for this dataset. Apparently, EagleBoys
</p>
<p>pizza claims that their pizzas are always bigger than Dominos pizzas, and published a set of measurements to support this
</p>
<p>claim (the measurements were available at http://www.eagleboys.com.au/realsizepizza as of Feb 2012, but seem not to be
</p>
<p>there anymore).
</p>
<p>Whose pizzas are bigger? and why? A histogram of all the pizza sizes appears in Fig. 1.9. We would not expect every
</p>
<p>pizza produced by a restaurant to have exactly the same diameter, but the diameters are probably pretty close to one another,
</p>
<p>and pretty close to some standard value. This would suggest that we&rsquo;d expect to see a histogram which looks like a single,</p>
<p/>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
<div class="annotation"><a href="http://www.amstat.org/publications/jse/jse_data_archive.htm">http://www.amstat.org/publications/jse/jse_data_archive.htm</a></div>
<div class="annotation"><a href="http://www.eagleboys.com.au/realsizepizza">http://www.eagleboys.com.au/realsizepizza</a></div>
</div>
<div class="page"><p/>
<p>1.5 Whose is Bigger? Investigating Australian Pizzas 21
</p>
<p>26
</p>
<p>27
</p>
<p>28
</p>
<p>29
</p>
<p>30
</p>
<p>31
</p>
<p>Dominos EagleBoys
</p>
<p>Box
</p>
<p>q
</p>
<p>q
</p>
<p>1
</p>
<p>3
</p>
<p>e
g
</p>
<p>na
r
</p>
<p>el
it
</p>
<p>ra
u
</p>
<p>qr
et
</p>
<p>nI
</p>
<p>Median
</p>
<p>Whisker
</p>
<p>Outlier
</p>
<p>Fig. 1.8 A box plot showing the box, the median, the whiskers and two outliers. Notice that we can compare the two datasets rather easily; the
next section explains the comparison
</p>
<p>Fig. 1.9 A histogram of pizza
diameters from the dataset
described in the text. Notice that
there seem to be two populations
</p>
<p>24 26 28 30 32
0
</p>
<p>10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>Histogram of pizza diameters, in inches
</p>
<p>rather narrow, bump about a mean. This is not what we see in Fig. 1.9&mdash;instead, there are two bumps, which suggests two
</p>
<p>populations of pizzas. This isn&rsquo;t particularly surprising, because we know that some pizzas come from EagleBoys and some
</p>
<p>from Dominos.
</p>
<p>If you look more closely at the data in the dataset, you will notice that each data item is tagged with the company it comes
</p>
<p>from. We can now easily plot conditional histograms, conditioning on the company that the pizza came from. These appear
</p>
<p>in Fig. 1.10. Notice that EagleBoys pizzas seem to follow the pattern we expect&mdash;the diameters are clustered tightly around
</p>
<p>one value&mdash;but Dominos pizzas do not seem to be like that. This is reflected in a box plot (Fig. 1.11), which shows the range</p>
<p/>
</div>
<div class="page"><p/>
<p>22 1 First Tools for Looking at Data
</p>
<p>26 28 30 32
0
</p>
<p>5
</p>
<p>10
</p>
<p>15
</p>
<p>20
</p>
<p>25
</p>
<p>30
</p>
<p>Dominos pizza diameters, in inches
</p>
<p>26 28 30 32
0
</p>
<p>5
</p>
<p>10
</p>
<p>15
</p>
<p>20
</p>
<p>25
</p>
<p>30
</p>
<p>EagleBoys pizza diameters, in inches
</p>
<p>Fig. 1.10 On the left, the class-conditional histogram of Dominos pizza diameters from the pizza data set; on the right, the class-conditional
histogram of EagleBoys pizza diameters. Notice that EagleBoys pizzas seem to follow the pattern we expect&mdash;the diameters are clustered tightly
around a mean, and there is a small standard deviation&mdash;but Dominos pizzas do not seem to be like that. There is more to understand about this
data
</p>
<p>26
</p>
<p>27
</p>
<p>28
</p>
<p>29
</p>
<p>30
</p>
<p>31
</p>
<p>Dominos EagleBoys
</p>
<p>Box plots of pizzas by maker
</p>
<p>Fig. 1.11 Box Plots of the pizza data, comparing EagleBoys and Dominos pizza. There are several curiosities here: why is the range for Dominos
so large (25.5&ndash;29)? EagleBoys has a smaller range, but has several substantial outliers; why? One would expect pizza manufacturers to try and
control diameter fairly closely, because pizzas that are too small present risks (annoying customers; publicity; hostile advertising) and pizzas that
are too large should affect profits</p>
<p/>
</div>
<div class="page"><p/>
<p>1.5 Whose is Bigger? Investigating Australian Pizzas 23
</p>
<p>26
</p>
<p>27
</p>
<p>28
</p>
<p>29
</p>
<p>30
</p>
<p>31
</p>
<p>D&minus;ThinNCrispy D&minus;DeepPan D&minus;ClassicCrust E&minus;MidCrust E&minus;DeepPan E&minus;ThinCrust
</p>
<p>Box plots of pizzas by maker and type
</p>
<p>Fig. 1.12 Box Plots for the pizza data, broken out by type (thin crust, etc.)
</p>
<p>of Dominos pizza sizes is surprisingly large, and that EagleBoys pizza sizes have several large outliers. There is more to
</p>
<p>understand about this data. The dataset contains labels for the type of crust and the type of topping&mdash;perhaps these properties
</p>
<p>affect the size of the pizza?
</p>
<p>EagleBoys produces DeepPan, MidCrust and ThinCrust pizzas, and Dominos produces DeepPan, ClassicCrust and
</p>
<p>ThinNCrispy pizzas. This may have something to do with the observed patterns, but comparing six histograms by eye is
</p>
<p>unattractive. A box plot is the right way to compare these cases (Fig. 1.12). The box plot gives some more insight into the
</p>
<p>data. Dominos thin crust appear to have a narrow range of diameters (with several outliers), where the median pizza is rather
</p>
<p>larger than either the deep pan or the classic crust pizza. EagleBoys pizzas all have a range of diameters that is (a) rather
</p>
<p>similar across the types and (b) rather a lot like the Dominos thin crust. There are outliers, but few for each type.
</p>
<p>Another possibility is that the variation in size is explained by the topping. We can compare types and toppings by
</p>
<p>producing a set of conditional box plots (i.e. the diameters for each type and each topping). This leads to rather a lot of
</p>
<p>boxes (Fig. 1.13), but they&rsquo;re still easy to compare by eye. The main difficulty is that the labels on the plot have to be
</p>
<p>shortened. I made labels using the first letter from the manufacturer (&ldquo;D&rdquo; or &ldquo;E&rdquo;); the first letter from the crust type (previous
</p>
<p>paragraph); and the first and last letter of the topping. Toppings for Dominos are: Hawaiian; Supreme; BBQMeatlovers.
</p>
<p>For EagleBoys, toppings are: Hawaiian; SuperSupremo; and BBQMeatlovers. This gives the labels: &lsquo;DCBs&rsquo;; (Dominos;
</p>
<p>ClassicCrust; BBQMeatlovers); &lsquo;DCHn&rsquo;; &lsquo;DCSe&rsquo;; &lsquo;DDBs&rsquo;; &lsquo;DDHn&rsquo;; &lsquo;DDSe&rsquo;; &lsquo;DTBs&rsquo;; &lsquo;DTHn&rsquo;; &lsquo;DTSe&rsquo;; &lsquo;EDBs&rsquo;; &lsquo;EDHn&rsquo;;
</p>
<p>&lsquo;EDSo&rsquo;; &lsquo;EMBs&rsquo;; &lsquo;EMHn&rsquo;; &lsquo;EMSo&rsquo;; &lsquo;ETBs&rsquo;; &lsquo;ETHn&rsquo;; &lsquo;ETSo&rsquo;. Figure 1.13 suggests that the topping isn&rsquo;t what is important,
</p>
<p>but the crust (group the box plots by eye).
</p>
<p>What could be going on here? One possible explanation is that Eagleboys have tighter control over the size of the final
</p>
<p>pizza. One way this could happen is that all EagleBoys pizzas start the same size and shrink the same amount in baking,
</p>
<p>whereas all Dominos pizzas start a standard diameter, but different Dominos crusts shrink differently in baking. Another</p>
<p/>
</div>
<div class="page"><p/>
<p>24 1 First Tools for Looking at Data
</p>
<p>26
</p>
<p>27
</p>
<p>28
</p>
<p>29
</p>
<p>30
</p>
<p>31
</p>
<p>DCBsDCHnDCSeDDBsDDHnDDSeDTBsDTHnDTSeEDBsEDHnEDSoEMBsEMHnEMSoETBsETHnETSo
</p>
<p>Box plots of pizzas by maker, type, and topping
</p>
<p>EagleBoysDominos
</p>
<p>ClassicCrust DeepPan
</p>
<p>ThinCrust
</p>
<p>ThinCrust
</p>
<p>MidCrust
</p>
<p>DeepPan
</p>
<p>Fig. 1.13 The pizzas are now broken up by topping as well as crust type (look at the source for the meaning of the names). I have separated
Dominos from Eagleboys with a vertical line, and grouped each crust type with a box. It looks as though the issue is not the type of topping, but
the crust. Eagleboys seems to have tighter control over the size of the final pizza
</p>
<p>way is that Dominos makes different size crusts for different types, but that the cooks sometimes get confused. Yet another
</p>
<p>possibility is that Dominos controls portions by the mass of dough (so thin crust diameters tend to be larger), but Eagleboys
</p>
<p>controls by the diameter of the crust.
</p>
<p>You should notice that this is more than just a fun story. If you were a manager at a pizza firm, you&rsquo;d need to make choices
</p>
<p>about how to control costs. Labor costs, rent, and portion control (i.e. how much pizza, topping, etc. a customer gets for their
</p>
<p>money) are the main thing to worry about. If the same kind of pizza has a wide range of diameters, you have a problem,
</p>
<p>because some customers are getting too much (which affects your profit) or too little (which means they might call someone
</p>
<p>else next time). But making more regular pizzas might require more skilled (and so more expensive) labor. The fact that
</p>
<p>Dominos and EagleBoys seem to be following different strategies successfully suggests that more than one strategy might
</p>
<p>work. But you can&rsquo;t choose if you don&rsquo;t know what&rsquo;s happening. As I said at the start, &ldquo;what&rsquo;s going on here?&rdquo; is perhaps
</p>
<p>the single most useful question anyone can ask.
</p>
<p>1.6 You Should
</p>
<p>1.6.1 Remember These Definitions
</p>
<p>Mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
</p>
<p>Standard deviation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
</p>
<p>Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
</p>
<p>Median . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13</p>
<p/>
</div>
<div class="page"><p/>
<p>1.6 You Should 25
</p>
<p>Percentile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
</p>
<p>Quartiles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
</p>
<p>Interquartile Range . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
</p>
<p>Standard coordinates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
</p>
<p>Standard normal data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
</p>
<p>Normal data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
</p>
<p>1.6.2 Remember These Terms
</p>
<p>categorical . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
</p>
<p>ordinal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
</p>
<p>continuous . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
</p>
<p>bar chart . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
</p>
<p>histogram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
</p>
<p>conditional histograms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
</p>
<p>class-conditional histograms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
</p>
<p>average . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
</p>
<p>location parameter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
</p>
<p>scale parameter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
</p>
<p>outlier . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
</p>
<p>tails . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
</p>
<p>mode . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
</p>
<p>unimodal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
</p>
<p>multimodal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
</p>
<p>bimodal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
</p>
<p>skew . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
</p>
<p>standard normal curve . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
</p>
<p>box plot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
</p>
<p>1.6.3 Remember These Facts
</p>
<p>Properties of the mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
</p>
<p>Properties of standard deviation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
</p>
<p>Properties of variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
</p>
<p>Properties of the median . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
</p>
<p>Properties of the interquartile range . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
</p>
<p>Properties of normal data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
</p>
<p>1.6.4 Be Able to
</p>
<p>&bull; Plot a bar chart for a dataset.
</p>
<p>&bull; Plot a histogram for a dataset.
</p>
<p>&bull; Tell whether the histogram is skewed or not, and in which direction.
</p>
<p>&bull; Plot and interpret conditional histograms.
</p>
<p>&bull; Compute basic summaries for a dataset, including mean, median, standard deviation and interquartile range.
</p>
<p>&bull; Plot a box plot for one or several datasets.
</p>
<p>&bull; Interpret a box plot.
</p>
<p>&bull; Use histograms, summaries and box plots to investigate datasets.</p>
<p/>
</div>
<div class="page"><p/>
<p>26 1 First Tools for Looking at Data
</p>
<p>Problems
</p>
<p>1.1 Show that mean .fkxg/ D kmean .fxg/ by substituting into the definition.
</p>
<p>1.2 Show that mean .fxC cg/ D mean .fxg/C c by substituting into the definition.
</p>
<p>1.3 Show that
PN
</p>
<p>iD1.xi � mean .fxg// D 0 by substituting into the definition.
</p>
<p>1.4 Show that std .fxC cg/ D std .fxg/ by substituting into the definition (you&rsquo;ll need to recall the properties of the mean
to do this).
</p>
<p>1.5 Show that std .fkxg/ D kstd .fxg/ by substituting into the definition (you&rsquo;ll need to recall the properties of the mean to
do this).
</p>
<p>1.6 Show that median .fxCcg/Dmedian .fxg/C c by substituting into the definition.
</p>
<p>1.7 Show that median .fkxg/ D kmedian .fxg/ by substituting into the definition.
</p>
<p>1.8 Show that iqrfxC cg D iqrfxg by substituting into the definition.
</p>
<p>1.9 Show that iqrfkxg D kiqrfxg by substituting into the definition.
</p>
<p>Programming Exercises
</p>
<p>1.10 You can find a data set showing the number of barrels of oil produced, per year for the years 1880&ndash;1984 at http://lib.
</p>
<p>stat.cmu.edu/DASL/Datafiles/Oilproduction.html. Is a mean a useful summary of this dataset? Why?
</p>
<p>1.11 You can find a dataset giving the cost (in 1976 US dollars), number of megawatts, and year of construction of a set of
</p>
<p>nuclear power plants at http://lib.stat.cmu.edu/DASL/Datafiles/NuclearPlants.html.
</p>
<p>(a) Are there outliers in this data?
</p>
<p>(b) What is the mean cost of a power plant? What is the standard deviation?
</p>
<p>(c) What is the mean cost per megawatt? What is the standard deviation?
</p>
<p>(d) Plot a histogram of the cost per megawatt. Is it skewed? Why?
</p>
<p>1.12 You can find a dataset giving the sodium content and calorie content of three types of hot dog at http://lib.stat.cmu.
</p>
<p>edu/DASL/Datafiles/Hotdogs.html. The types are Beef, Poultry, and Meat (a rather disturbingly vague label). Use class-
</p>
<p>conditional histograms to compare these three types of hot dog with respect to sodium content and calories.
</p>
<p>1.13 You will find a dataset giving (among other things) the number of 3 or more syllable words in advertising copy
</p>
<p>appearing in magazines at http://lib.stat.cmu.edu/DASL/Datafiles/magadsdat.html. The magazines are grouped by the
</p>
<p>education level of their readers; the groups are 1, 2, and 3 (the variable is called GRP in the data).
</p>
<p>(a) Use a box plot to compare the number of three or more syllable words for the ads in magazines in these three groups.
</p>
<p>What do you see?
</p>
<p>(b) Use a box plot to compare the number of sentences appearing in the ads in magazines in these three groups. What do
</p>
<p>you see?</p>
<p/>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/Oilproduction.html">http://lib.stat.cmu.edu/DASL/Datafiles/Oilproduction.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/Oilproduction.html">http://lib.stat.cmu.edu/DASL/Datafiles/Oilproduction.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/NuclearPlants.html">http://lib.stat.cmu.edu/DASL/Datafiles/NuclearPlants.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/Hotdogs.html">http://lib.stat.cmu.edu/DASL/Datafiles/Hotdogs.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/Hotdogs.html">http://lib.stat.cmu.edu/DASL/Datafiles/Hotdogs.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/magadsdat.html">http://lib.stat.cmu.edu/DASL/Datafiles/magadsdat.html</a></div>
</div>
<div class="page"><p/>
<p>Programming Exercises 27
</p>
<p>1.14 You can find a dataset recording a variety of properties of secondary school students in Portugal athttp://archive.ics.
</p>
<p>uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION. This dataset was collected by P. Cortez and A. Silva, and
</p>
<p>is hosted by the UC Irvine Machine Learning Repository. There are two datasets; one for students in a math course, and
</p>
<p>another for students in a Portugese language course.
</p>
<p>(a) Use plots of conditional histograms to investigate whether math students drink more alcohol during the week than
</p>
<p>Portugese language students.
</p>
<p>(b) Use plots of conditional histograms to investigate whether students from small families drink more alcohol at the
</p>
<p>weekend than those from large families.
</p>
<p>(c) Each of the variables school, sex, famsize and romantic has two possible values. This means that if we characterize
</p>
<p>students by the values of these variables, there are sixteen possible types of student. Use box plots to investigate which
</p>
<p>of these types drinks more alcohol in total.
</p>
<p>1.15 You can find a dataset recording some properties of Taiwanese credit card holders at http://archive.ics.uci.edu/ml/
</p>
<p>datasets/default+of+credit+card+clients. This dataset was collected by I-Cheng Yeh, and is hosted by the UC Irvine Machine
</p>
<p>Learning Repository. There is a variable indicating whether a holder defaulted or not, and a variety of other variables.
</p>
<p>(a) Use plots of conditional histograms to investigate whether people who default have more debt (use the variable X1 for
</p>
<p>debt) than those who don&rsquo;t default.
</p>
<p>(b) Use box plots to investigate whether gender, education or marital status has any effect on the amount of debt (again, use
</p>
<p>X1 for debt).
</p>
<p>1.16 You will find a dataset giving the effects of three poisons and four antidotes at http://www.statsci.org/data/general/
</p>
<p>poison.html. This dataset records survival times of animals poisoned with one of three poisons and supplied with one of four
</p>
<p>antidotes. There is no detail supplied on species, protocol, ethical questions, etc.
</p>
<p>(a) Use box plots to investigate whether the poisons have different effects for antidote 1.
</p>
<p>(b) Use box plots to investigate whether the antidote has any effect for poison 2.</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION">http://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION">http://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients">http://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients">http://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/general/poison.html">http://www.statsci.org/data/general/poison.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/general/poison.html">http://www.statsci.org/data/general/poison.html</a></div>
</div>
<div class="page"><p/>
<p>2Looking at Relationships
</p>
<p>We think of a dataset as a collection of d-tuples (a d-tuple is an ordered list of d elements). For example, the Chase and
</p>
<p>Dunner dataset had entries for Gender; Grade; Age; Race; Urban/Rural; School; Goals; Grades; Sports; Looks; and Money
</p>
<p>(so it consisted of 11-tuples). The previous chapter explored methods to visualize and summarize a set of values obtained
</p>
<p>by extracting a single element from each tuple. For example, I could visualize the heights or the weights of a population (as
</p>
<p>in Fig. 1.7). But I could say nothing about the relationship between the height and weight. In this chapter, we will look at
</p>
<p>methods to visualize and summarize the relationships between pairs of elements of a dataset.
</p>
<p>2.1 Plotting 2D Data
</p>
<p>We take a dataset, choose two different entries, and extract the corresponding elements from each tuple. The result is a
</p>
<p>dataset consisting of 2-tuples, and we think of this as a two dimensional dataset. The first step is to plot this dataset in a
</p>
<p>way that reveals relationships. The topic of how best to plot data fills many books, and we can only scratch the surface here.
</p>
<p>Categorical data can be particularly tricky, because there are a variety of choices we can make, and the usefulness of each
</p>
<p>tends to depend on the dataset and to some extent on one&rsquo;s cleverness in graphic design (Sect. 2.1.1).
</p>
<p>For some continuous data, we can plot the one entry as a function of the other (so, for example, our tuples might consist
</p>
<p>of the date and the number of robberies; or the year and the price of lynx pelts; and so on, Sect. 2.1.2).
</p>
<p>Mostly, we use a simple device, called a scatter plot. Using and thinking about scatter plots will reveal a great deal about
</p>
<p>the relationships between our data items (Sect. 2.1.3).
</p>
<p>2.1.1 Categorical Data, Counts, and Charts
</p>
<p>Categorical data is a bit special. Assume we have a dataset with several categorical descriptions of each data item. One way to
</p>
<p>plot this data is to think of it as belonging to a richer set of categories. Assume the dataset has categorical descriptions, which
</p>
<p>are not ordinal. Then we can construct a new set of categories by looking at each of the cases for each of the descriptions.
</p>
<p>For example, in the Chase and Dunner data of Table 1.2, our new categories would be: &ldquo;boy-sports&rdquo;; &ldquo;girl-sports&rdquo;; &ldquo;boy-
</p>
<p>popular&rdquo;; &ldquo;girl-popular&rdquo;; &ldquo;boy-grades&rdquo;; and &ldquo;girl-grades&rdquo;. A large set of categories like this can result in a poor bar chart,
</p>
<p>though, because there may be too many bars to group the bars successfully. Figure 2.1 shows such a bar chart. Notice that it
</p>
<p>is hard to group categories by eye to compare; for example, you can see that slightly more girls think grades are important
</p>
<p>than boys do, but to do so you need to compare two bars that are separated by two other bars. An alternative is a pie chart,
</p>
<p>where a circle is divided into sections whose angle is proportional to the size of the data item. You can think of the circle
</p>
<p>as a pie, and each section as a slice of pie. Figure 2.1 shows a pie chart, where each section is proportional to the number of
</p>
<p>students in its category. In this case, I&rsquo;ve used my judgement to lay the categories out in a way that makes comparisons easy.
</p>
<p>I&rsquo;m not aware of any tight algorithm for doing this, though.
</p>
<p>Pie charts have problems, because it is hard to judge small differences in area accurately by eye. For example, from the
</p>
<p>pie chart in Fig. 2.1, it&rsquo;s hard to tell that the &ldquo;boy-sports&rdquo; category is slightly bigger than the &ldquo;boy-popular&rdquo; category (try it;
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_2
</p>
<p>29</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_2">https://doi.org/10.1007/978-3-319-64410-3_2</a></div>
</div>
<div class="page"><p/>
<p>30 2 Looking at Relationships
</p>
<p>b&minus;P b&minus;G b&minus;S g&minus;S g&minus;G g&minus;P
0
</p>
<p>50
</p>
<p>100
</p>
<p>150
boy
</p>
<p>Popular
</p>
<p>boy
</p>
<p>Grades
</p>
<p>boy
</p>
<p>Sports
girl
</p>
<p>Sports
</p>
<p>girl
</p>
<p>Grades
</p>
<p>girl
</p>
<p>Popular
</p>
<p>Fig. 2.1 I sorted the children in the Chase and Dunner study into six categories (two genders by three goals), and counted the number of children
that fell into each cell. I then produced the bar chart on the left, which shows the number of children of each gender, selecting each goal. On the
right, a pie chart of this information. I have organized the pie chart so it is easy to compare boys and girls by eye&mdash;start at the top; going down on
the left side are boy goals, and on the right side are girl goals. Comparing the size of the corresponding wedges allows you to tell what goals boys
(resp. girls) identify with more or less often
</p>
<p>check using the bar chart). For either kind of chart, it is quite important to think about what you plot. For example, the plot
</p>
<p>of Fig. 2.1 shows the total number of respondents, and if you refer to Fig. 1.1, you will notice that there are slightly more
</p>
<p>girls in the study. Is the percentage of boys who think grades are important smaller (or larger) than the percentage of girls
</p>
<p>who think so? you can&rsquo;t tell from these plots, and you&rsquo;d have to plot the percentages instead.
</p>
<p>An alternative is to use a stacked bar chart. You can (say) regard the data as of two types, &ldquo;Boys&rdquo; and &ldquo;Girls&rdquo;. Within
</p>
<p>those types, there are subtypes (&ldquo;Popularity&rdquo;, &ldquo;Grades&rdquo; and &ldquo;Sport&rdquo;). The height of the bar is given by the number of elements
</p>
<p>in the type, and the bar is divided into sections corresponding to the number of elements of that subtype. Alternatively, if you
</p>
<p>want the plot to show relative frequencies, the bars could all be the same height, but the shading corresponds to the fraction
</p>
<p>of elements of that subtype. This is all much harder to say than to see or to do (Fig. 2.2).
</p>
<p>An alternative to a pie chart that is very useful for two dimensional data is a heat map. This is a method of displaying a
</p>
<p>matrix as an image. Each entry of the matrix is mapped to a color, and the matrix is represented as an image. For the Chase
</p>
<p>and Dunner study, I constructed a matrix where each row corresponds to a choice of &ldquo;sports&rdquo;, &ldquo;grades&rdquo;, or &ldquo;popular&rdquo;, and
</p>
<p>each column corresponds to a choice of &ldquo;boy&rdquo; or &ldquo;girl&rdquo;. Each entry contains the count of data items of that type. Zero values
</p>
<p>are represented as white; the largest values as red; and as the value increases, we use an increasingly saturated pink. This
</p>
<p>plot is shown in Fig. 2.3
</p>
<p>If the categorical data is ordinal, the ordering offers some hints for making a good plot. For example, imagine we are
</p>
<p>building a user interface. We build an initial version, and collect some users, asking each to rate the interface on scales for
</p>
<p>&ldquo;ease of use&rdquo; (�2;�1, 0, 1, 2, running from bad to good) and &ldquo;enjoyability&rdquo; (again, �2;�1, 0, 1, 2, running from bad to
good). It is natural to build a 5�5 table, where each cell represents a pair of &ldquo;ease of use&rdquo; and &ldquo;enjoyability&rdquo; values. We then
count the number of users in each cell, and build graphical representations of this table. One natural representation is a 3D
</p>
<p>bar chart, where each bar sits on its cell in the 2D table, and the height of the bars is given by the number of elements in the
</p>
<p>cell. Table 2.1 shows a table and Fig. 2.4 shows a 3D bar chart for some simulated data. The main difficulty with a 3D bar
</p>
<p>chart is that some bars are hidden behind others. This is a regular nuisance. You can improve things by using an interactive
</p>
<p>tool to rotate the chart to get a nice view, but this doesn&rsquo;t always work. Heatmaps don&rsquo;t suffer from this problem (Fig. 2.4),
</p>
<p>another reason they are a good choice.
</p>
<p>Remember this: There are a variety of tools for plotting categorical data. It&rsquo;s difficult to give strict rules for which
</p>
<p>to use when, but usually one tries to avoid pie charts (angles are hard to judge by eye) and 3D bar charts (where
</p>
<p>occlusion can hide important effects).</p>
<p/>
</div>
<div class="page"><p/>
<p>2.1 Plotting 2D Data 31
</p>
<p>boy girl
</p>
<p>Gender by goals
</p>
<p>Gender
</p>
<p>Goals by gender, 
</p>
<p>relative frequencies
</p>
<p>Grades Popular Sports
</p>
<p>Goals by gender
</p>
<p>Goals
</p>
<p>Gender by goals, 
</p>
<p>relative frequencies
</p>
<p>0
5
0
</p>
<p>1
0
0
</p>
<p>1
5
0
</p>
<p>2
0
0
</p>
<p>2
5
0
</p>
<p>0
.0
</p>
<p>0
.2
</p>
<p>0
.4
</p>
<p>0
.6
</p>
<p>0
.8
</p>
<p>1
.0
</p>
<p>0
5
0
</p>
<p>1
0
0
</p>
<p>1
5
0
</p>
<p>2
0
0
</p>
<p>0
.0
</p>
<p>0
.2
</p>
<p>0
.4
</p>
<p>0
.6
</p>
<p>0
.8
</p>
<p>1
.0
</p>
<p>Grades Popular Sports
</p>
<p>Goals
</p>
<p>boy girl
</p>
<p>Gender
</p>
<p>Sports
</p>
<p>Popular
</p>
<p>Grades
</p>
<p>girl
</p>
<p>boy
</p>
<p>Fig. 2.2 These bar charts use stacked bars. In the top row, the overall height of the bar is given by the number of elements of that type but each
different subtype is identified by shading, so you can tell by eye, for example, how many of the &ldquo;Grades&rdquo; in the study were &ldquo;Boys&rdquo;. This layout
makes it hard to tell what fraction of, say, &ldquo;Boys&rdquo; aspire to &ldquo;Popularity&rdquo;. In the bottom row, all bars have the same height, but the shading of the
bar identifies the fraction of that type that has a corresponding subtype. This means you can tell by eye what fraction of, for example, &ldquo;Girls&rdquo; aspire
to &ldquo;Sports&rdquo;
</p>
<p>2.1.2 Series
</p>
<p>Sometimes one component of a dataset gives a natural ordering to the data. For example, we might have a dataset giving the
</p>
<p>maximum rainfall for each day of the year. We could record this either by using a two-dimensional representation, where
</p>
<p>one dimension is the number of the day and the other is the temperature, or with a convention where the i&rsquo;th data item is the
</p>
<p>rainfall on the i&rsquo;th day. For example, at http://lib.stat.cmu.edu/DASL/Datafiles/timeseriesdat.html, you can find four datasets
</p>
<p>indexed in this way. It is natural to plot data like this as a function of time. From this dataset, I extracted data giving the
</p>
<p>number of burglaries each month in a Chicago suburb, Hyde Park. I have plotted part this data in Fig. 2.5 (I left out the data
</p>
<p>to do with treatment effects). It is natural to plot a graph of the burglaries as a function of time (in this case, the number
</p>
<p>of the month). The plot shows each data point explicitly. I also told the plotting software to draw lines joining data points,
</p>
<p>because burglaries do not all happen on a specific day. The lines suggest, reasonably enough, the rate at which burglaries are
</p>
<p>happening between data points.</p>
<p/>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/timeseriesdat.html">http://lib.stat.cmu.edu/DASL/Datafiles/timeseriesdat.html</a></div>
</div>
<div class="page"><p/>
<p>32 2 Looking at Relationships
</p>
<p>bo
y
</p>
<p>gi
rl
</p>
<p>Sports
</p>
<p>Grades
</p>
<p>Popular
 40
</p>
<p> 60
</p>
<p> 80
</p>
<p>100
</p>
<p>120
</p>
<p>Fig. 2.3 A heat map of the Chase and Dunner data. The color of each cell corresponds to the count of the number of elements of that type. The
colorbar at the side gives the correspondence between color and count. You can see at a glance that the number of boys and girls who prefer grades
is about the same; that about the same number of boys prefer sports and popularity, with sports showing a mild lead; and that more girls prefer
popularity to sports
</p>
<p>Table 2.1 I simulated data
representing user evaluations of a
user interface
</p>
<p>�2 �1 0 1 2
�2 24 5 0 0 1
�1 6 12 3 0 0
</p>
<p>0 2 4 13 6 0
</p>
<p>1 0 0 3 13 2
</p>
<p>2 0 0 0 1 5
</p>
<p>Each cell in the table on the left contains the count
of users rating &ldquo;ease of use&rdquo; (horizontal, on a scale
of �2&mdash;very bad&mdash;to 2&mdash;very good) vs. &ldquo;enjoyability&rdquo;
(vertical, same scale). Users who found the interface hard
to use did not like using it either. While this data is
categorical, it&rsquo;s also ordinal, so that the order of the cells
is determined. It wouldn&rsquo;t make sense, for example, to
reorder the columns of the table or the rows of the table
</p>
<p>&minus;2
&minus;1
</p>
<p>0
1
</p>
<p>2
</p>
<p>&minus;2
&minus;1
</p>
<p>0
1
</p>
<p>2
</p>
<p>0
</p>
<p>10
</p>
<p>20
</p>
<p>30
</p>
<p>Ease of use
</p>
<p>Counts of user responses for a user interface
</p>
<p>Enjoyability
Ease of use
</p>
<p>E
n
jo
</p>
<p>y
ab
</p>
<p>il
it
</p>
<p>y
</p>
<p>&minus;2 &minus;1 0 1 2
</p>
<p>&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p> 0
</p>
<p> 5
</p>
<p>10
</p>
<p>15
</p>
<p>20
</p>
<p>Fig. 2.4 On the left, a 3D bar chart of the data. The height of each bar is given by the number of users in each cell. This figure immediately reveals
that users who found the interface hard to use did not like using it either. However, some of the bars at the back are hidden, so some structure might
be hard to infer. On the right, a heat map of this data. Again, this figure immediately reveals that users who found the interface hard to use did not
like using it either. It&rsquo;s more apparent that everyone disliked the interface, though, and it&rsquo;s clear that there is no important hidden structure</p>
<p/>
</div>
<div class="page"><p/>
<p>2.1 Plotting 2D Data 33
</p>
<p>0 10 20 30 40
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>100
</p>
<p>month
</p>
<p>n
u
m
</p>
<p>b
er
</p>
<p> o
f 
</p>
<p>b
u
rg
</p>
<p>la
ri
</p>
<p>es
</p>
<p>Burglaries each month in Hyde Park
</p>
<p>1840 1860 1880 1900 1920
0
</p>
<p>500
</p>
<p>1000
</p>
<p>1500
</p>
<p>year
</p>
<p>Lynx pelts traded at Hudson Bay and price
</p>
<p>number of pelts/100
</p>
<p>price in pence
</p>
<p>Fig. 2.5 Left, the number of burglaries in Hyde Park, by month. Right, a plot of the number of lynx pelts traded at Hudson Bay and of the price
paid per pelt, as a function of the year. Notice the scale, and the legend box (the number of pelts is scaled by 100)
</p>
<p>As another example, at http://lib.stat.cmu.edu/datasets/Andrews/ you can find a dataset that records the number of lynx
</p>
<p>pelts traded to the Hudson&rsquo;s Bay company and the price paid for each pelt. This version of the dataset appeared first in
</p>
<p>Table 3.2 of Data: a Collection of Problems from many Fields for the Student and Research Worker by D.F. Andrews and
</p>
<p>A.M. Herzberg, published by Springer in 1985. I have plotted it in Fig. 2.5. The dataset is famous, because it shows a periodic
</p>
<p>behavior in the number of pelts (which is a good proxy for the number of lynx), which is interpreted as a result of predator-
</p>
<p>prey interactions. Lynx eat rabbits. When there are many rabbits, lynx kittens thrive, and soon there will be many lynx; but
</p>
<p>then they eat most of the rabbits, and starve, at which point the rabbit population rockets. You should also notice that after
</p>
<p>about 1900, prices seem to have gone up rather quickly. I don&rsquo;t know why this is. There is also some suggestion, as there
</p>
<p>should be, that prices are low when there are many pelts, and high when there are few.
</p>
<p>2.1.3 Scatter Plots for Spatial Data
</p>
<p>It isn&rsquo;t always natural to plot data as a function. For example, in a dataset containing the temperature and blood pressure
</p>
<p>of a set of patients, there is no reason to believe that temperature is a function of blood pressure, or the other way round.
</p>
<p>Two people could have the same temperature, and different blood pressures, or vice-versa. As another example, we could be
</p>
<p>interested in what causes people to die of cholera. We have data indicating where each person died in a particular outbreak.
</p>
<p>It isn&rsquo;t helpful to try and plot such data as a function.
</p>
<p>The scatter plot is a powerful way to deal with this situation. In the first instance, assume that our data points actually
</p>
<p>describe points on the a real map. Then, to make a scatter plot, we make a mark on the map at a place indicated by each data
</p>
<p>point. What the mark looks like, and how we place it, depends on the particular dataset, what we are looking for, how much
</p>
<p>we are willing to work with complex tools, and our sense of graphic design.
</p>
<p>Figure 2.6 is an extremely famous scatter plot, due to John Snow. Snow&mdash;one of the founders of epidemiology&mdash;used
</p>
<p>a scatter plot to reason about a cholera outbreak centered on the Broad Street pump in London in 1854. At that time, the
</p>
<p>mechanism that causes cholera was not known. Snow plotted cholera deaths as little bars (more bars, more deaths) on the
</p>
<p>location of the house where the death occurred. More bars means more deaths, fewer bars means fewer deaths. There are
</p>
<p>more bars per block close to the pump, and few far away. This plot offers quite strong evidence of an association between
</p>
<p>the pump and death from cholera. Snow used this scatter plot as evidence that cholera was associated with water, and that
</p>
<p>the Broad Street pump was the source of the tainted water.
</p>
<p>Remember this: Scatter plots are a most effective tool for geographic data and 2D data in general. A scatter plot
</p>
<p>should be your first step with a new 2D dataset.</p>
<p/>
<div class="annotation"><a href="http://lib.stat.cmu.edu/datasets/Andrews/">http://lib.stat.cmu.edu/datasets/Andrews/</a></div>
</div>
<div class="page"><p/>
<p>34 2 Looking at Relationships
</p>
<p>Fig. 2.6 Snow&rsquo;s scatter plot of cholera deaths on the left. Each cholera death is plotted as a small bar on the house in which the bar occurred (for
example, the black arrow points to one stack of these bars, indicating many deaths, in the detail on the right). Notice the fairly clear pattern of
many deaths close to the Broad street pump (grey arrow in the detail), and fewer deaths further away (where it was harder to get water from the
pump)
</p>
<p>2.1.4 Exposing Relationships with Scatter Plots
</p>
<p>A scatter plot is a useful, simple tool for ferreting out associations in data. Now we need some notation. Assume we have a
</p>
<p>dataset fxg of N data items, x1; : : : ; xN . Each data item is a d dimensional vector (so its components are numbers). We wish
to investigate the relationship between two components of the dataset. For example, we might be interested in the 7&rsquo;th and
</p>
<p>the 13&rsquo;th component of the dataset. We will produce a two-dimensional plot, one dimension for each component. It does not
</p>
<p>really matter which component is plotted on the x-coordinate and which on the y-coordinate (though it will be some pages
</p>
<p>before this is clear). But it is very difficult to write sensibly without talking about the x and y coordinates.
</p>
<p>We will make a two-dimensional dataset out of the components that interest us. We must choose which component goes
</p>
<p>first in the resulting 2-vector. We will plot this component on the x-coordinate (and we refer to it as the x-coordinate), and to
</p>
<p>the other component as the y-coordinate. This is just to make it easier to describe what is going on; there&rsquo;s no important idea
</p>
<p>here. It really will not matter which is x and which is y. The two components make a dataset fxig D f.xi; yi/g. To produce a
scatter plot of this data, we plot a small shape at the location of each data item.
</p>
<p>Such scatter plots are very revealing. For example, Fig. 2.7 shows a scatter plot of body temperature against heart rate for
</p>
<p>humans. In this dataset, the gender of the subject was recorded (as &ldquo;1&rdquo; or &ldquo;2&rdquo;&mdash;I don&rsquo;t know which is which), and so I have
</p>
<p>plotted a &ldquo;1&rdquo; at each data point with gender &ldquo;1&rdquo;, and so on. Looking at the data suggests there isn&rsquo;t much difference between
</p>
<p>the blob of &ldquo;1&rdquo; labels and the blob of &ldquo;2&rdquo; labels, which suggests that females and males are about the same in this respect.
</p>
<p>The scale used for a scatter plot matters. For example, plotting lengths in meters gives a very different scatter from plotting
</p>
<p>lengths in millimeters. Figure 2.8 shows two scatter plots of weight against height. Each plot is from the same dataset, but
</p>
<p>one is scaled so as to show two outliers. Keeping these outliers means that the rest of the data looks quite concentrated, just
</p>
<p>because the axes are in large units. In the other plot, the axis scale has changed (so you can&rsquo;t see the outliers), but the data
</p>
<p>looks more scattered. This may or may not be a misrepresentation. Figure 2.9 compares the data with outliers removed, with
</p>
<p>the same plot on a somewhat different set of axes. One plot looks as though increasing height corresponds to increasing
</p>
<p>weight; the other looks as though it doesn&rsquo;t. This is purely due to deceptive scaling&mdash;each plot shows the same dataset.
</p>
<p>Dubious data can also contribute to scaling problems. Recall that, in Fig. 2.5, price data before and after 1900 appeared
</p>
<p>to behave differently. Figure 2.10 shows a scatter plot of the lynx data, where I have plotted number of pelts against price. I</p>
<p/>
</div>
<div class="page"><p/>
<p>2.1 Plotting 2D Data 35
</p>
<p>96 98 100 102
</p>
<p>60
</p>
<p>70
</p>
<p>80
</p>
<p>90
</p>
<p>1 1
1
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
</p>
<p>1
</p>
<p>111
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>11
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
1
</p>
<p>1
</p>
<p>1
</p>
<p>11
1
</p>
<p>11
</p>
<p>1
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
1
</p>
<p>1
1
</p>
<p>11
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>11
1
1
1
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
22
</p>
<p>2
2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>22
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>22
22
2
</p>
<p>22
</p>
<p>222
22
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>22
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
2
22
</p>
<p>2
2
</p>
<p>2
2
</p>
<p>2
22 2
</p>
<p>Body temperature
</p>
<p>H
ea
</p>
<p>rt
 r
</p>
<p>at
e
</p>
<p>&minus;6 &minus;4 &minus;2 0 2 4 6
&minus;6
</p>
<p>&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>1 1
1
</p>
<p>1
</p>
<p>11
</p>
<p>1
</p>
<p>1
111
1
</p>
<p>1
</p>
<p>1
11
1
1
1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>111
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
1
</p>
<p>1
1
</p>
<p>111
</p>
<p>11
</p>
<p>1
</p>
<p>1
11
</p>
<p>11
</p>
<p>1
1
</p>
<p>11
1
</p>
<p>1
1
</p>
<p>1
</p>
<p>1
11
1
11
1
11
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
1
</p>
<p>2
2
</p>
<p>2
</p>
<p>22
</p>
<p>2
2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>222
</p>
<p>22
</p>
<p>2
</p>
<p>2
2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>22
</p>
<p>2
2
</p>
<p>2
</p>
<p>22222
</p>
<p>22
</p>
<p>2222
2
</p>
<p>2
2
2
</p>
<p>2
22
</p>
<p>2
</p>
<p>2
2
</p>
<p>2
2
</p>
<p>2
2
</p>
<p>2
</p>
<p>22
22
22
</p>
<p>22
</p>
<p>2 22 2
</p>
<p>Normalized body temperature
</p>
<p>N
o
rm
</p>
<p>al
iz
</p>
<p>ed
 h
</p>
<p>ea
rt
</p>
<p> r
at
</p>
<p>e
</p>
<p>Fig. 2.7 A scatter plot of body temperature against heart rate, from the dataset at http://www2.stetson.edu/~jrasp/data.htm; normtemp.xls. I have
separated the two genders by plotting a different symbol for each (though I don&rsquo;t know which gender is indicated by which letter); if you view this
in color, the differences in color makes for a greater separation of the scatter. This picture suggests, but doesn&rsquo;t conclusively establish, that there
isn&rsquo;t much dependence between temperature and heart rate, and any dependence between temperature and heart rate isn&rsquo;t affected by gender
</p>
<p>20 40 60 80
100
</p>
<p>150
</p>
<p>200
</p>
<p>250
</p>
<p>300
</p>
<p>350
</p>
<p>400
</p>
<p>Heights
</p>
<p>W
ei
</p>
<p>g
h
ts
</p>
<p>60 65 70 75 80
100
</p>
<p>150
</p>
<p>200
</p>
<p>250
</p>
<p>300
</p>
<p>Heights, outliers removed
</p>
<p>W
ei
</p>
<p>g
h
ts
</p>
<p>, 
o
u
tl
</p>
<p>ie
rs
</p>
<p> r
em
</p>
<p>o
v
ed
</p>
<p>Fig. 2.8 Scatter plots of weight against height, from the dataset at http://www2.stetson.edu/~jrasp/data.htm. Left: Notice how two outliers
dominate the picture, and to show the outliers, the rest of the data has had to be bunched up. Right shows the data with the outliers removed.
The structure is now somewhat clearer
</p>
<p>60 65 70 75 80
100
</p>
<p>150
</p>
<p>200
</p>
<p>250
</p>
<p>300
</p>
<p>Heights, outliers removed
</p>
<p>W
ei
</p>
<p>g
h
ts
</p>
<p>, 
o
u
tl
</p>
<p>ie
rs
</p>
<p> r
em
</p>
<p>o
v
ed
</p>
<p>60 65 70 75 80
0
</p>
<p>100
</p>
<p>200
</p>
<p>300
</p>
<p>400
</p>
<p>Heights
</p>
<p>W
ei
</p>
<p>g
h
ts
</p>
<p>Fig. 2.9 Scatter plots of weight against height, from the dataset at http://www2.stetson.edu/~jrasp/data.htm. Left: data with two outliers removed,
as in Fig. 2.8. Right: this data, rescaled slightly. Notice how the data looks less spread out. But there is no difference between the datasets. Instead,
your eye is easily confused by a change of scale</p>
<p/>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
</div>
<div class="page"><p/>
<p>36 2 Looking at Relationships
</p>
<p>Fig. 2.10 A scatter plot of the
price of lynx pelts against the
number of pelts. I have plotted
data for 1901 to the end of the
series as circles, and the rest of
the data as *&rsquo;s. It is quite hard to
draw any conclusion from this
data, because the scale is
confusing. Furthermore, the data
from 1900 on behaves quite
differently from the other data
</p>
<p>0 2 4 6 8
</p>
<p>x 10
4
</p>
<p>0
</p>
<p>500
</p>
<p>1000
</p>
<p>1500
</p>
<p>number of pelts traded
</p>
<p>p
ri
</p>
<p>ce
 o
</p>
<p>f 
p
el
</p>
<p>ts
, 
in
</p>
<p> p
en
</p>
<p>n
ie
</p>
<p>s
</p>
<p>plotted the post-1900 data as circles, and the rest as asterisks. Notice how the circles seem to form a quite different figure,
</p>
<p>which supports the suggestion that something interesting happened around 1900. We can reasonably choose to analyze data
</p>
<p>after 1900 separately from before 1900. A choice like this should be made with care. If you exclude every data point that
</p>
<p>might disagree with your hypothesis, you may miss the fact that you are wrong. Leaving out data is an essential component
</p>
<p>of many kinds of fraud. You should always reveal whether you have excluded data, and why, to allow the reader to judge the
</p>
<p>evidence.
</p>
<p>When you look at Fig. 2.10, you should notice the scatter plot does not seem to support the idea that prices go up when
</p>
<p>supply goes down. This is puzzling because it&rsquo;s generally a pretty reliable idea. In fact, the plot is just hard to interpret
</p>
<p>because it is poorly scaled. Scale is an important nuisance, and it&rsquo;s easy to get misled by scale effects.
</p>
<p>The way to avoid the problem is to plot in standard coordinates. We can normalize without worrying about the dimension
</p>
<p>of the data&mdash;we normalize each dimension independently by subtracting the mean of that dimension and dividing by the
</p>
<p>standard deviation of that dimension. This means we can normalize the x and y coordinates of the two-dimensional data
</p>
<p>separately. We continue to use the convention of writing the normalized x coordinate as Ox and the normalized y coordinate
as Oy. So, for example, we can write Oxj D .xj � mean .fxg//=std .fxg// for the Ox value of the j&rsquo;th data item in normalized
coordinates. Normalizing shows us the dataset on a standard scale. Once we have done this, it is quite straightforward to read
</p>
<p>off simple relationships between variables from a scatter plot.
</p>
<p>Remember this: The plot scale can mask effects in scatter plots, and it&rsquo;s usually a good idea to plot in standard
</p>
<p>coordinates.
</p>
<p>2.2 Correlation
</p>
<p>Plotting data in standard coordinates can be very revealing. For example, it is pretty clear from Fig. 2.11 that someone who
</p>
<p>is taller than the mean will tend to be heavier than the mean too. This relationship isn&rsquo;t in the form of a function. There
</p>
<p>are some people who are quite a lot taller than the mean, and quite a lot lighter, too. But taller people are mostly heavier,
</p>
<p>too. There isn&rsquo;t always a relationship, as Fig. 2.12 suggests. There really doesn&rsquo;t seem to be any reason to suspect that heart
</p>
<p>rate and temperature are related. Sometimes the relationship goes the other way, i.e. when one variable increases, another
</p>
<p>decreases. Figure 2.13 strongly suggests that when more pelts were traded, the price tended to be lower.
</p>
<p>The simplest, and most important, relationship to look for in a scatter plot is this: when Ox increases, does Oy tend to increase,
decrease, or stay the same? This is straightforward to spot in a normalized scatter plot, because each case produces a very
</p>
<p>clear shape on the scatter plot. Any relationship is called correlation (we will see later how to measure this), and the three
</p>
<p>cases are: positive correlation, which means that larger Ox values tend to appear with larger Oy values; zero correlation, which
means no relationship; and negative correlation, which means that larger Ox values tend to appear with smaller Oy values. You
should notice that this relationship isn&rsquo;t a function&mdash;the data forms blobs, rather than lying on curves&mdash;and it isn&rsquo;t affected
</p>
<p>by swapping Ox and Oy. If larger Ox tends to occur with larger Oy, then larger Oy tends to occur with larger Ox, and so on. Figure 2.14
compares a plot of height against weight to one of weight against height. Usually, one just does this by rotating the page,</p>
<p/>
</div>
<div class="page"><p/>
<p>2.2 Correlation 37
</p>
<p>Fig. 2.11 A normalized scatter
plot of weight against height,
from the dataset at http://www2.
stetson.edu/~jrasp/data.htm. Now
you can see that someone who is
a standard deviation taller than
the mean will tend to be
somewhat heavier than the mean
too
</p>
<p>&minus;4 &minus;2 0 2 4
&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>Heights, outliers removed, normalized
</p>
<p>W
ei
</p>
<p>g
h
ts
</p>
<p>, 
o
u
tl
</p>
<p>ie
rs
</p>
<p> r
em
</p>
<p>o
v
ed
</p>
<p>, 
n
o
rm
</p>
<p>al
iz
</p>
<p>ed
</p>
<p>96 98 100 102
</p>
<p>60
</p>
<p>70
</p>
<p>80
</p>
<p>90
</p>
<p>1 1
1
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
</p>
<p>1
</p>
<p>111
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>11
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
1
</p>
<p>1
</p>
<p>1
</p>
<p>11
1
</p>
<p>11
</p>
<p>1
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
1
</p>
<p>1
1
</p>
<p>11
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>11
1
1
1
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
22
</p>
<p>2
2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>22
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>22
22
2
</p>
<p>22
</p>
<p>222
22
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>22
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
2
22
</p>
<p>2
2
</p>
<p>2
2
</p>
<p>2
22 2
</p>
<p>Body temperature
</p>
<p>H
ea
</p>
<p>rt
 r
</p>
<p>at
e
</p>
<p>&minus;6 &minus;4 &minus;2 0 2 4 6
&minus;6
</p>
<p>&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>1 1
1
</p>
<p>1
</p>
<p>11
</p>
<p>1
</p>
<p>1
111
1
</p>
<p>1
</p>
<p>1
11
1
1
1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>111
</p>
<p>1
</p>
<p>1
1
</p>
<p>1
1
</p>
<p>1
1
</p>
<p>111
</p>
<p>11
</p>
<p>1
</p>
<p>1
11
</p>
<p>11
</p>
<p>1
1
</p>
<p>11
1
</p>
<p>1
1
</p>
<p>1
</p>
<p>1
11
1
11
1
11
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
1
</p>
<p>2
2
</p>
<p>2
</p>
<p>22
</p>
<p>2
2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>222
</p>
<p>22
</p>
<p>2
</p>
<p>2
2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>22
</p>
<p>2
2
</p>
<p>2
</p>
<p>22222
</p>
<p>22
</p>
<p>2222
2
</p>
<p>2
2
2
</p>
<p>2
22
</p>
<p>2
</p>
<p>2
2
</p>
<p>2
2
</p>
<p>2
2
</p>
<p>2
</p>
<p>22
22
22
</p>
<p>22
</p>
<p>2 22 2
</p>
<p>Normalized body temperature
</p>
<p>N
o
rm
</p>
<p>al
iz
</p>
<p>ed
 h
</p>
<p>ea
rt
</p>
<p> r
at
</p>
<p>e
</p>
<p>Fig. 2.12 Left: A scatter plot of body temperature against heart rate, from the dataset at http://www2.stetson.edu/~jrasp/data.htm; normtemp.xls.
I have separated the two genders by plotting a different symbol for each (though I don&rsquo;t know which gender is indicated by which letter); if you
view this in color, the differences in color makes for a greater separation of the scatter. This picture suggests, but doesn&rsquo;t conclusively establish,
that there isn&rsquo;t much dependence between temperature and heart rate, and any dependence between temperature and heart rate isn&rsquo;t affected by
gender. The scatter plot of the normalized data, in standard coordinates, on the right supports this view
</p>
<p>0 2 4 6 8
</p>
<p>x 10
4
</p>
<p>0
</p>
<p>500
</p>
<p>1000
</p>
<p>1500
</p>
<p>number of pelts traded
</p>
<p>p
ri
</p>
<p>ce
 o
</p>
<p>f 
p
el
</p>
<p>ts
, 
in
</p>
<p> p
en
</p>
<p>n
ie
</p>
<p>s
</p>
<p>&minus;2 &minus;1 0 1 2 3
&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>normalized number of pelts
</p>
<p>n
o
rm
</p>
<p>al
iz
</p>
<p>ed
 p
</p>
<p>ri
ce
</p>
<p>Fig. 2.13 Left: A scatter plot of the price of lynx pelts against the number of pelts (this is a repeat of Fig. 2.10 for reference). I have plotted data
for 1901 to the end of the series as circles, and the rest of the data as *&rsquo;s. It is quite hard to draw any conclusion from this data, because the scale
is confusing. Right: A scatter plot of the price of pelts against the number of pelts for lynx pelts. I excluded data for 1901 to the end of the series,
and then normalized both price and number of pelts. Notice that there is now a distinct trend; when there are fewer pelts, they are more expensive,
and when there are more, they are cheaper</p>
<p/>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
</div>
<div class="page"><p/>
<p>38 2 Looking at Relationships
</p>
<p>&minus;4 &minus;2 0 2 4
&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>Heights, outliers removed, normalized
</p>
<p>W
ei
</p>
<p>g
h
ts
</p>
<p>, 
o
u
tl
</p>
<p>ie
rs
</p>
<p> r
em
</p>
<p>o
v
ed
</p>
<p>, 
n
o
rm
</p>
<p>al
iz
</p>
<p>ed
</p>
<p>&minus;4 &minus;2 0 2 4
&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>H
ei
</p>
<p>g
h
ts
</p>
<p>, 
o
u
tl
</p>
<p>ie
rs
</p>
<p> r
em
</p>
<p>o
v
ed
</p>
<p>, 
n
o
rm
</p>
<p>al
iz
</p>
<p>ed
</p>
<p>Weights, outliers removed, normalized
</p>
<p>Fig. 2.14 On the left, a normalized scatter plot of weight (y-coordinate) against height (x-coordinate). On the right, a scatter plot of height (y-
coordinate) against weight (x-coordinate). I&rsquo;ve put these plots next to one another so you don&rsquo;t have to mentally rotate (which is what you should
usually do)
</p>
<p>or by imagining the new picture. The left plot tells you that data points with higher height value tend to have higher weight
</p>
<p>value; the right plot tells you that data points with higher weight value tend to have higher height value&mdash;i.e. the plots tell
</p>
<p>you the same thing. It doesn&rsquo;t really matter which one you look at. Again, the important word is &ldquo;tend&rdquo;&mdash;the plot doesn&rsquo;t tell
</p>
<p>you anything about why, it just tells you that when one variable is larger the other tends to be, too.
</p>
<p>Positive correlation occurs when larger Ox values tend to appear with larger Oy values. This means that data points with
small (i.e. negative with large magnitude) Ox values must have small Oy values, otherwise the mean of Ox (resp. Oy) would be too
big. In turn, this means that the scatter plot should look like a &ldquo;smear&rdquo; of data from the bottom left of the graph to the top
</p>
<p>right. The smear might be broad or narrow, depending on some details we&rsquo;ll discuss below. Figure 2.11 shows normalized
</p>
<p>scatter plots of weight against height, and of body temperature against heart rate. In the weight-height plot, you can clearly
</p>
<p>see that individuals who are higher tend to weigh more. The important word here is &ldquo;tend&rdquo;&mdash;taller people could be lighter,
</p>
<p>but mostly they tend not to be. Notice, also, that I did NOT say that they weighed more because they were taller, but only
</p>
<p>that they tend to be heavier.
</p>
<p>Negative correlation occurs when larger Ox values tend to appear with smaller Oy values. This means that data points with
small Ox values must have large Oy values, otherwise the mean of Ox (resp. Oy) would be too big. In turn, this means that the
scatter plot should look like a &ldquo;smear&rdquo; of data from the top left of the graph to the bottom right. The smear might be broad
</p>
<p>or narrow, depending on some details we&rsquo;ll discuss below. Figure 2.13 shows a normalized scatter plot of the lynx pelt-price
</p>
<p>data, where I have excluded the data from 1901 on. I did so because there seemed to be some other effect operating to drive
</p>
<p>prices up, which was inconsistent with the rest of the series. This plot suggests that when there were more pelts, prices were
</p>
<p>lower, as one would expect.
</p>
<p>Zero correlation occurs when there is no relationship. This produces a characteristic shape in a scatter plot, but it takes
</p>
<p>a moment to understand why. If there really is no relationship, then knowing Ox will tell you nothing about Oy. All we know is
that mean .fOyg/ D 0, and var .fOyg/ D 1. This is enough information to predict what the plot will look like. We know that
mean .fOxg/ D 0 and var .fOxg/ D 1; so there will be many data points with Ox value close to zero, and few with a much larger
or much smaller Ox value. The same applies to Oy. Now consider the data points in a strip of Ox values. If this strip is far away
from the origin, there will be few data points in the strip, because there aren&rsquo;t many big Ox values. If there is no relationship,
we don&rsquo;t expect to see large or small Oy values in this strip, because there are few data points in the strip and because large or
small Oy values are uncommon&mdash;we see them only if there are many data points, and then seldom. So for a strip with Ox close
to zero, we might see some Oy values that are far from zero because we will see many Oy values. For a strip with Ox that is far
from zero, we expect to see few Oy values that are far from zero, because we see few points in this strip. This reasoning means
the data should form a round blob, centered at the origin. In the temperature-heart rate plot of Fig. 2.12, it looks as though
</p>
<p>nothing of much significance is happening. The average heart rate seems to be about the same for people who run warm or
</p>
<p>who run cool. There is probably not much relationship here.
</p>
<p>I have shown the three cases together in one figure using a real data example (Fig. 2.15), so you can compare the
</p>
<p>appearance of the plots.</p>
<p/>
</div>
<div class="page"><p/>
<p>2.2 Correlation 39
</p>
<p>&minus;4 &minus;2 0 2 4
&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>Heights, outliers removed, normalized
</p>
<p>W
ei
</p>
<p>g
h
</p>
<p>ts
, 
</p>
<p>o
u
</p>
<p>tl
ie
</p>
<p>rs
 r
</p>
<p>em
o
</p>
<p>v
ed
</p>
<p>, 
n
</p>
<p>o
rm
</p>
<p>al
iz
</p>
<p>ed
</p>
<p>&minus;6 &minus;4 &minus;2 0 2 4 6
&minus;6
</p>
<p>&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>1 1
1
1
</p>
<p>11
</p>
<p>1
</p>
<p>1
111
1
1
</p>
<p>1
11
1
1
1
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>111
1
</p>
<p>1
1
</p>
<p>1
1
</p>
<p>1
1
111
</p>
<p>11
</p>
<p>1
</p>
<p>1
11
</p>
<p>11
</p>
<p>1
1
11
1
</p>
<p>1
1
</p>
<p>1
</p>
<p>1
11
1
11
1
11
</p>
<p>1
</p>
<p>1
</p>
<p>1
</p>
<p>1
1
</p>
<p>2
2
</p>
<p>2
22
</p>
<p>2
2
</p>
<p>2
</p>
<p>2
</p>
<p>2
</p>
<p>2
222
</p>
<p>22
</p>
<p>2
2
2
</p>
<p>2
2
2
22
2
2
</p>
<p>2
</p>
<p>22222
22
</p>
<p>2222
2
2
2
2
</p>
<p>2
22
</p>
<p>2
</p>
<p>2
2
</p>
<p>2
2
</p>
<p>2
2
</p>
<p>2
22
22
22
</p>
<p>22
2 22 2
</p>
<p>Normalized body temperature
</p>
<p>N
o
rm
</p>
<p>al
iz
</p>
<p>ed
 h
</p>
<p>ea
rt
</p>
<p> r
at
</p>
<p>e
</p>
<p>&minus;2 &minus;1 0 1 2 3
&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>normalized number of pelts
</p>
<p>n
o
rm
</p>
<p>al
iz
</p>
<p>ed
 p
</p>
<p>ri
ce
</p>
<p>No Correlation Positive Correlation Negative Correlation
</p>
<p>Fig. 2.15 The three kinds of scatter plot: I used the body temperature vs heart rate data for the zero correlation; the height-weight data for positive
correlation; and the lynx data for negative correlation. The pictures aren&rsquo;t idealized&mdash;real data tends to be messy&mdash;but you can still see the basic
structures
</p>
<p>2.2.1 The Correlation Coefficient
</p>
<p>Consider a normalized data set of N two-dimensional vectors. We can write the i&rsquo;th data point in standard coordinates .Oxi; Oyi/.
We already know many important summaries of this data, because it is in standard coordinates. We have mean .fOxg/ D 0;
mean .fOyg/ D 0; std .fOxg/ D 1; and std .fOyg/ D 1. Each of these summaries is itself the mean of some monomial. So
std .fOxg/2 D mean
</p>
<p>�˚
</p>
<p>Ox2
��
</p>
<p>D 1; std .fOyg/2 D mean
�˚
</p>
<p>Oy2
��
</p>
<p>(the other two are easy). We can rewrite this information in terms
</p>
<p>of means of monomials, giving mean .fOxg/ D 0; mean .fOyg/ D 0; mean
�˚
</p>
<p>Ox2
��
</p>
<p>D 1; and mean
�˚
</p>
<p>Oy2
��
</p>
<p>D 1. There is one
monomial missing here, which is OxOy. The term mean .fOxOyg/ captures correlation between x and y. The term is known as the
correlation coefficient or correlation.
</p>
<p>Definition 2.1 (Correlation Coefficient) Assume we have N data items which are 2-vectors .x1; y1/; : : : ; .xN ; yN/,
</p>
<p>where N &gt; 1. These could be obtained, for example, by extracting components from larger vectors. We compute
</p>
<p>the correlation coefficient by first normalizing the x and y coordinates to obtain Oxi D
.xi � mean .fxg//
</p>
<p>std .x/
, Oyi D
</p>
<p>.yi � mean .fyg//
std .y/
</p>
<p>. The correlation coefficient is the mean value of OxOy, and can be computed as:
</p>
<p>corr .f.x; y/g/ D
P
</p>
<p>i Oxi Oyi
N
</p>
<p>Correlation is a measure of our ability to predict one value from another. The correlation coefficient takes values between
</p>
<p>�1 and 1 (we&rsquo;ll prove this below). If the correlation coefficient is close to 1, then we are likely to predict very well. Small
correlation coefficients (under about 0.5, say, but this rather depends on what you are trying to achieve) tend not to be all that
</p>
<p>interesting, because (as we shall see) they result in rather poor predictions.
</p>
<p>Figure 2.16 gives a set of scatter plots of different real data sets with different correlation coefficients. These all come from
</p>
<p>data set of age-height-weight, which you can find at http://www2.stetson.edu/~jrasp/data.htm (look for bodyfat.xls). In each
</p>
<p>case, two outliers have been removed. Age and height are hardly correlated, as you can see from the figure. Younger people do
</p>
<p>tend to be slightly taller, and so the correlation coefficient is �0:25. You should interpret this as a small correlation. However,
the variable called &ldquo;adiposity&rdquo; (which isn&rsquo;t defined, but is presumably some measure of the amount of fatty tissue) is quite
</p>
<p>strongly correlated with weight, with a correlation coefficient is 0.86. Average tissue density is quite strongly negatively
</p>
<p>correlated with adiposity, because muscle is much denser than fat, so these variables are negatively correlated&mdash;we expect
</p>
<p>high density to appear with low adiposity, and vice versa. The correlation coefficient is �0:86. Finally, density is very strongly
correlated with body weight. The correlation coefficient is �0:98.</p>
<p/>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
</div>
<div class="page"><p/>
<p>40 2 Looking at Relationships
</p>
<p>&minus;4 &minus;2 0 2 4
&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>Age, normalized
</p>
<p>H
ei
</p>
<p>g
h
t,
</p>
<p> n
o
rm
</p>
<p>al
iz
</p>
<p>ed
Age and height, correlation=&minus;0.25
</p>
<p>&minus;4 &minus;2 0 2 4
&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>Adiposity, normalized
</p>
<p>W
ei
</p>
<p>g
h
ts
</p>
<p>, 
n
o
rm
</p>
<p>al
iz
</p>
<p>ed
</p>
<p>Adiposity and weight, correlation=0.86
</p>
<p>&minus;4 &minus;2 0 2 4
&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>Density, normalized
</p>
<p>B
o
d
y
fa
</p>
<p>t,
 n
</p>
<p>o
rm
</p>
<p>al
iz
</p>
<p>ed
</p>
<p>Density and Body Fat, correlation=&minus;0.98
</p>
<p>Fig. 2.16 Scatter plots for various pairs of variables for the age-height-weight dataset from http://www2.stetson.edu/~jrasp/data.htm; bodyfat.xls.
In each case, two outliers have been removed, and the plots are in standard coordinates (compare to Fig. 2.17, which shows these data sets plotted
in their original units). The legend names the variables
</p>
<p>20 40 60 80 100
60
</p>
<p>65
</p>
<p>70
</p>
<p>75
</p>
<p>80
</p>
<p>Age, NOT normalized
</p>
<p>H
ei
</p>
<p>g
h
t,
</p>
<p> N
O
</p>
<p>T
 n
</p>
<p>o
rm
</p>
<p>al
iz
</p>
<p>ed
</p>
<p>Age and height, correlation=&minus;0.25
</p>
<p>15 20 25 30 35 40
100
</p>
<p>150
</p>
<p>200
</p>
<p>250
</p>
<p>300
</p>
<p>Adiposity, NOT normalized
</p>
<p>W
ei
</p>
<p>g
h
ts
</p>
<p>, 
N
</p>
<p>O
T
</p>
<p> n
o
rm
</p>
<p>al
iz
</p>
<p>ed
</p>
<p>Adiposity and weight, correlation=0.86
</p>
<p>0.9 1 1.1 1.2 1.3
0
</p>
<p>10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>Density, NOT normalized
</p>
<p>B
o
d
y
fa
</p>
<p>t,
 N
</p>
<p>O
T
</p>
<p> n
o
rm
</p>
<p>al
iz
</p>
<p>ed
</p>
<p>Density and Body Fat, correlation=&minus;0.98
</p>
<p>Fig. 2.17 Scatter plots for various pairs of variables for the age-height-weight dataset from http://www2.stetson.edu/~jrasp/data.htm; bodyfat.xls.
In each case, two outliers have been removed, and the plots are NOT in standard coordinates (compare to Fig. 2.16, which shows these data sets
plotted in normalized coordinates). The legend names the variables
</p>
<p>It&rsquo;s not always convenient or a good idea to produce scatter plots in standard coordinates (among other things, doing so
</p>
<p>hides the units of the data, which can be a nuisance). Fortunately, scaling or translating data does not change the value of
</p>
<p>the correlation coefficient (though it can change the sign if one scale is negative). This means that it&rsquo;s worth being able to
</p>
<p>spot correlation in a scatter plot that isn&rsquo;t in standard coordinates (even though correlation is always defined in standard
</p>
<p>coordinates). Figure 2.17 shows different correlated datasets plotted in their original units. These data sets are the same as
</p>
<p>those used in Fig. 2.16.
</p>
<p>You should memorize the properties of the correlation coefficient in the box. The first property is easy, and we relegate
</p>
<p>that to the exercises. One way to see that the correlation coefficient isn&rsquo;t changed by translation or scale is to notice that it
</p>
<p>is defined in standard coordinates, and scaling or translating data doesn&rsquo;t change those. Another way to see this is to scale
</p>
<p>and translate data, then write out the equations; notice that taking standard coordinates removes the effects of the scale and
</p>
<p>translation. In each case, notice that if the scale is negative, the sign of the correlation coefficient changes.
</p>
<p>Useful Facts 2.1 (Properties of the Correlation Coefficient)
</p>
<p>&bull; The correlation coefficient is symmetric (it doesn&rsquo;t depend on the order of its arguments), so
</p>
<p>corr .f.x; y/g/ D corr .f.y; x/g/
</p>
<p>(continued)</p>
<p/>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
</div>
<div class="page"><p/>
<p>2.2 Correlation 41
</p>
<p>&bull; The value of the correlation coefficient is not changed by translating the data. Scaling the data can change the sign,
</p>
<p>but not the absolute value. For constants a &curren; 0, b, c &curren; 0, d we have
</p>
<p>corr .f.axC b; cxC d/g/ D sign.ab/corr .f.x; y/g/
</p>
<p>&bull; If Oy tends to be large (resp. small) for large (resp. small) values of Ox, then the correlation coefficient will be positive.
&bull; If Oy tends to be small (resp. large) for large (resp. small) values of Ox, then the correlation coefficient will be negative.
&bull; If Oy doesn&rsquo;t depend on Ox, then the correlation coefficient is zero (or close to zero).
&bull; The largest possible value is 1, which happens when Ox D Oy.
&bull; The smallest possible value is �1, which happens when Ox D �Oy.
</p>
<p>The property that, if Oy tends to be large (resp. small) for large (resp. small) values of Ox, then the correlation coefficient
will be positive, doesn&rsquo;t really admit a formal statement. But it&rsquo;s relatively straightforward to see what&rsquo;s going on. Because
</p>
<p>mean .fOxg/ D 0, small values of mean .fOxg/ must be negative and large values must be positive. But corr .f.x; y/g/ D
P
</p>
<p>i OxiOyi
N
</p>
<p>;
</p>
<p>and for this sum to be positive, it should contain mostly positive terms. It can contain few or no hugely positive (or hugely
</p>
<p>negative) terms, because std .Ox/ D std .Oy/ D 1 so there aren&rsquo;t many large (or small) numbers. For the sum to contain mostly
positive terms, then the sign of Oxi should be the same as the sign Oyi for most data items. Small changes to this argument work
to show that if if Oy tends to be small (resp. large) for large (resp. small) values of Ox, then the correlation coefficient will be
negative.
</p>
<p>Showing that no relationship means zero correlation requires slightly more work. Divide the scatter plot of the dataset up
</p>
<p>into thin vertical strips. There are S strips. Each strip is narrow, so the Ox value does not change much for the data points in a
particular strip. For the s&rsquo;th strip, write N.s/ for the number of data points in the strip, Ox.s/ for the Ox value at the center of the
strip, and Oy.s/ for the mean of the Oy values within that strip. Now the strips are narrow, so we can approximate all data points
within a strip as having the same value of Ox. This yields
</p>
<p>mean .fOxOyg/ � 1
S
</p>
<p>X
</p>
<p>s2strips
</p>
<p>Ox.s/
h
</p>
<p>N.s/Oy.s/
i
</p>
<p>(where you could replace � with D if the strips were narrow enough). Now assume that Oy.s/ does not change from strip to
strip, meaning that there is no relationship between Ox and Oy in this dataset (so the picture is like the left hand side in Fig. 2.15).
Then each value of Oy.s/ is the same&mdash;we write Oy&mdash;and we can rearrange to get
</p>
<p>mean .fOxOyg/ � Oy1
S
</p>
<p>X
</p>
<p>s2strips
</p>
<p>Ox.s/:
</p>
<p>Now notice that
</p>
<p>0 D mean .fOyg/ � 1
S
</p>
<p>X
</p>
<p>s2strips
</p>
<p>N.s/Oy.s/
</p>
<p>(where again you could replace � with D if the strips were narrow enough). This means that if every strip has the
same value of Oy.s/, then that value must be zero. In turn, if there is no relationship between Ox and Oy, we must have
mean .fOxOyg/ D 0.
</p>
<p>Property 2.1 The largest possible value of the correlation is 1, and this occurs when Oxi D Oyi for all i. The smallest
possible value of the correlation is �1, and this occurs when Oxi D �Oyi for all i.
</p>
<p>Proposition
</p>
<p>�1 � corr .f.x; y/g/ � 1
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>42 2 Looking at Relationships
</p>
<p>Proof Writing Ox, Oy for the normalized coefficients, we have
</p>
<p>corr .f.x; y/g/ D
P
</p>
<p>i Oxi Oyi
N
</p>
<p>and you can think of the value as the inner product of two vectors. We write
</p>
<p>x D 1p
N
</p>
<p>ŒOx1; Ox2; : : : OxN &#141; and
</p>
<p>y D 1p
N
</p>
<p>ŒOy1; Oy2; : : : OyN &#141;
</p>
<p>and we have corr .f.x; y/g/ D xTy. Notice xTx D std .x/2 D 1, and similarly for y. But the inner product of two
vectors is at its maximum when the two vectors are the same, and this maximum is 1. This argument is also sufficient
</p>
<p>to show that smallest possible value of the correlation is �1, and this occurs when Oxi D �Oyi for all i.
</p>
<p>2.2.2 Using Correlation to Predict
</p>
<p>Assume we have N data items which are 2-vectors .x1; y1/; : : : ; .xN ; yN/, where N &gt; 1. These could be obtained, for example,
</p>
<p>by extracting components from larger vectors. As usual, we will write Oxi for xi in normalized coordinates, and so on. Now
assume that we know the correlation coefficient is r (this is an important, traditional notation). What does this mean?
</p>
<p>One (very useful) interpretation is in terms of prediction. Assume we have a data point .x0; &lsaquo;/ where we know the x-
</p>
<p>coordinate, but not the y-coordinate. We can use the correlation coefficient to predict the y-coordinate. First, we transform to
</p>
<p>standard coordinates. Now we must obtain the best Oy0 value to predict, using the Ox0 value we have.
We want to construct a prediction function which gives a prediction for any value of Ox. This predictor should behave as
</p>
<p>well as possible on our existing data. For each of the .Oxi; Oyi/ pairs in our data set, the predictor should take Oxi and produce a
result as close to Oyi as possible. We can choose the predictor by looking at the errors it makes at each data point.
</p>
<p>We write Oypi for the value of Oyi predicted at Oxi. The simplest form of predictor is linear. If we predict using a linear function,
then we have, for some unknown a, b, that Oypi D aOxiCb. Now think about ui D Oyi�Oy
</p>
<p>p
</p>
<p>i , which is the error in our prediction. We
</p>
<p>would like to have mean .fug/ D 0 (otherwise, we could reduce the error of the prediction just by subtracting a constant).
</p>
<p>mean .fug/ D mean .fOy � Oypg/
</p>
<p>D mean .fOyg/ � mean .faOxi C bg/
</p>
<p>D mean .fOyg/ � amean .fOxg/C b
</p>
<p>D 0 � a0C b
</p>
<p>D 0:
</p>
<p>This means that we must have b D 0.
To estimate a, we need to think about var .fug/. We should like var .fug/ to be as small as possible, so that the errors are
</p>
<p>as close to zero as possible (remember, small variance means small standard deviation which means the data is close to the
</p>
<p>mean). We have</p>
<p/>
</div>
<div class="page"><p/>
<p>2.2 Correlation 43
</p>
<p>var .fug/ D var .fOy � Oypg/
</p>
<p>D mean
�˚
</p>
<p>.Oy � aOx/2
��
</p>
<p>because mean .fug/ D 0
</p>
<p>D mean
�˚
</p>
<p>.Oy/2 � 2aOxOyC a2.Ox/2
��
</p>
<p>D mean
�˚
</p>
<p>.Oy/2
��
</p>
<p>� 2amean .fOxOyg/C a2mean
�˚
</p>
<p>.Ox/2
��
</p>
<p>D 1 � 2arC a2;
</p>
<p>which we want to minimize by choice of a. At the minimum, we must have
</p>
<p>dvar .fuig/
da
</p>
<p>D 0 D �2rC 2a
</p>
<p>so that a D r and the correct prediction is
Oyp0 D rOx0
</p>
<p>You can use a version of this argument to establish that if we have .&lsaquo;; Oy0/, then the best prediction for Ox0 (which is in
standard coordinates) is rOy0. It is important to notice that the coefficient of Oy0 is NOT 1=r; you should work this example,
which appears in the exercises. We now have a prediction procedure, outlined below.
</p>
<p>Procedure 2.1 (Predicting a Value Using Correlation) Assume we have N data items which are 2-vectors
</p>
<p>.x1; y1/; : : : ; .xN ; yN/, where N &gt; 1. These could be obtained, for example, by extracting components from larger
</p>
<p>vectors. Assume we have an x value x0 for which we want to give the best prediction of a y value, based on this data.
</p>
<p>The following procedure will produce a prediction:
</p>
<p>&bull; Transform the data set into standard coordinates, to get
</p>
<p>Oxi D
1
</p>
<p>std .x/
.xi � mean .fxg//
</p>
<p>Oyi D
1
</p>
<p>std .y/
.yi � mean .fyg//
</p>
<p>Ox0 D
1
</p>
<p>std .x/
.x0 � mean .fxg//:
</p>
<p>&bull; Compute the correlation
</p>
<p>r D corr .f.x; y/g/ D mean .fOxOyg/:
</p>
<p>&bull; Predict Oy0 D rOx0.
&bull; Transform this prediction into the original coordinate system, to get
</p>
<p>y0 D std .y/rOx0 C mean .fyg/
</p>
<p>Now assume we have a y value y0, for which we want to give the best prediction of an x value, based on this data. The
</p>
<p>following procedure will produce a prediction:
</p>
<p>&bull; Transform the data set into standard coordinates.
</p>
<p>&bull; Compute the correlation.
</p>
<p>&bull; Predict Ox0 D rOy0.
&bull; Transform this prediction into the original coordinate system, to get
</p>
<p>x0 D std .x/rOy0 C mean .fxg/</p>
<p/>
</div>
<div class="page"><p/>
<p>44 2 Looking at Relationships
</p>
<p>There is another way of thinking about this prediction procedure, which is often helpful. Assume we need to predict a
</p>
<p>value for x0. In normalized coordinates, our prediction is Oyp D rOx0; if we revert back to the original coordinate system, the
prediction becomes
</p>
<p>.yp � mean .fyg//
std .y/
</p>
<p>D r
�
</p>
<p>.x0 � mean .fxg//
std .x/
</p>
<p>�
</p>
<p>:
</p>
<p>This gives a really useful rule of thumb, which I have broken out in the box below.
</p>
<p>Procedure 2.2 (Predicting a Value Using Correlation: Rule of Thumb&mdash;1) If x0 is k standard deviations from the
</p>
<p>mean of x, then the predicted value of y will be rk standard deviations away from the mean of y, and the sign of r tells
</p>
<p>whether y increases or decreases.
</p>
<p>An even more compact version of the rule of thumb is in the following box.
</p>
<p>Procedure 2.3 (Predicting a Value Using Correlation: Rule of Thumb&mdash;2) The predicted value of y goes up by r
</p>
<p>standard deviations when the value of x goes up by one standard deviation.
</p>
<p>We can compute the average root mean square error that this prediction procedure will make. The square of this error
</p>
<p>must be
</p>
<p>mean
�˚
</p>
<p>u2
��
</p>
<p>D mean
�˚
</p>
<p>y2
��
</p>
<p>� 2rmean .fxyg/C r2mean
�˚
</p>
<p>x2
��
</p>
<p>D 1 � 2r2 C r2
</p>
<p>D 1 � r2
</p>
<p>so the root mean square error will be
p
1 � r2. This is yet another interpretation of correlation; if x and y have correlation
</p>
<p>close to one, then predictions could have very small root mean square error, and so might be very accurate. In this case,
</p>
<p>knowing one variable is about as good as knowing the other. If they have correlation close to zero, then the root mean square
</p>
<p>error in a prediction might be as large as the root mean square error in Oy&mdash;which means the prediction is nearly a pure
guess.
</p>
<p>The prediction argument means that we can spot correlations for data in other kinds of plots&mdash;one doesn&rsquo;t have to make
</p>
<p>a scatter plot. For example, if we were to observe a child&rsquo;s height from birth to their 10&rsquo;th year (you can often find these
</p>
<p>observations in ballpen strokes, on kitchen walls), we could plot height as a function of year. If we also had their weight (less
</p>
<p>easily found), we could plot weight as a function of year, too. The prediction argument above say that, if you can predict the
</p>
<p>weight from the height (or vice versa) then they&rsquo;re correlated. One way to spot this is to look and see if one curve goes up
</p>
<p>when the other does (or goes down when the other goes up). You can see this effect in Fig. 2.5, where (before 19h00), prices
</p>
<p>go down when the number of pelts goes up, and vice versa. These two variables are negatively correlated.
</p>
<p>2.2.3 Confusion Caused by Correlation
</p>
<p>There is one very rich source of potential (often hilarious) mistakes in correlation. When two variables are correlated, they
</p>
<p>change together. If the correlation is positive, that means that, in typical data, if one is large then the other is large, and if
</p>
<p>one is small the other is small. In turn, this means that one can make a reasonable prediction of one from the other. However,
</p>
<p>correlation DOES NOT mean that changing one variable causes the other to change (sometimes known as causation).
</p>
<p>Two variables in a dataset could be correlated for a variety of reasons. One important reason is pure accident. If you look
</p>
<p>at enough pairs of variables, you may well find a pair that appears to be correlated just because you have a small set of
</p>
<p>observations. Imagine, for example, you have a dataset consisting of only two high dimensional vectors&mdash;there is a pretty
</p>
<p>good chance that there is some correlation between the components. Such accidents can occur in large datasets, particularly
</p>
<p>if the dimensions are high.
</p>
<p>Another reason variables could be correlated is that there is some causal relationship&mdash;for example, pressing the
</p>
<p>accelerator tends to make the car go faster, and so there will be some correlation between accelerator position and car</p>
<p/>
</div>
<div class="page"><p/>
<p>2.3 Sterile Males in Wild Horse Herds 45
</p>
<p>acceleration. As another example, adding fertilizer does tend to make a plant grow bigger. Imagine you record the amount of
</p>
<p>fertilizer you add to each pot, and the size of the resulting potplant. There should be some correlation.
</p>
<p>Yet another reason variables could be correlated is that there is some other background variable&mdash;often called a latent
</p>
<p>variable&mdash;linked causally to each of the observed variables. For example, in children (as Freedman, Pisani and Purves note
</p>
<p>in their excellent Statistics), shoe size is correlated with reading skills. This DOES NOT mean that making your feet grow
</p>
<p>will make you read faster, or that you can make your feet shrink by forgetting how to read. The real issue here is the age of
</p>
<p>the child. Young children tend to have small feet, and tend to have weaker reading skills (because they&rsquo;ve had less practice).
</p>
<p>Older children tend to have larger feet, and tend to have stronger reading skills (because they&rsquo;ve had more practice). You
</p>
<p>can make a reasonable prediction of reading skills from foot size, because they&rsquo;re correlated, even though there is no direct
</p>
<p>connection.
</p>
<p>This kind of effect can mask correlations, too. Imagine you want to study the effect of fertilizer on potplants. You collect
</p>
<p>a set of pots, put one plant in each, and add different amounts of fertilizer. After some time, you record the size of each
</p>
<p>plant. You expect to see correlation between fertilizer amount and plant size. But you might not if you had used a different
</p>
<p>species of plant in each pot. Different species of plant can react quite differently to the same fertilizer (some plants just die if
</p>
<p>over-fertilized), so the species could act as a latent variable. With an unlucky choice of the different species, you might even
</p>
<p>conclude that there was a negative correlation between fertilizer and plant size. This sort of thing happens often, and it&rsquo;s an
</p>
<p>effect you should watch out for.
</p>
<p>2.3 Sterile Males inWild Horse Herds
</p>
<p>Large herds of wild horses are (apparently) a nuisance, but keeping down numbers by simply shooting surplus animals would
</p>
<p>provoke outrage. One strategy that has been adopted is to sterilize males in the herd; if a herd contains sufficient sterile males,
</p>
<p>fewer foals should result. But catching stallions, sterilizing them, and reinserting them into a herd is a performance&mdash;does
</p>
<p>this strategy work?
</p>
<p>We can get some insight by plotting data. At http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html, you can find a
</p>
<p>dataset covering herd management in wild horses. I have plotted part of this dataset in Fig. 2.18. In this dataset, there are
</p>
<p>counts of all horses, sterile males, and foals made on each of a small number of days in 1986, 1987, and 1988 for each
</p>
<p>of two herds. I extracted data for one herd. I have plotted this data as a function of the count of days since the first data
</p>
<p>point, because this makes it clear that some measurements were taken at about the same time, but there are big gaps in the
</p>
<p>measurements. In this plot, the data points are shown with a marker. Joining them leads to a confusing plot because the data
</p>
<p>points vary quite strongly. However, notice that the size of the herd drifts down slowly (you could hold a ruler against the
</p>
<p>plot to see the trend), as does the number of foals, when there is a (roughly) constant number of sterile males.
</p>
<p>Does sterilizing males result in fewer foals? This is likely hard to answer for this dataset, but we could ask whether herds
</p>
<p>with more sterile males have fewer foals. A scatter plot is a natural tool to attack this question. However, the scatter plots of
</p>
<p>Fig. 2.19 suggest, rather surprisingly, that when there are more sterile males there are more adults (and vice versa), and when
</p>
<p>there are more sterile males there are more foals (and vice versa). This is borne out by a correlation analysis. The correlation
</p>
<p>Fig. 2.18 A plot of the number
of adult horses, sterile males, and
foals in horse herds over a period
of 3 years. The plot suggests that
introducing sterile males might
cause the number of foals to go
down. Data from http://lib.stat.
cmu.edu/DASL/Datafiles/
WildHorses.html
</p>
<p>0 200 400 600 800
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>Day
</p>
<p>N
u
</p>
<p>m
b
</p>
<p>er
 o
</p>
<p>f 
h
</p>
<p>o
rs
</p>
<p>es
</p>
<p>Number of horses vs. day
</p>
<p>Adults
</p>
<p>Sterile Males
</p>
<p>Foals</p>
<p/>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html">http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html">http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html">http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html">http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html</a></div>
</div>
<div class="page"><p/>
<p>46 2 Looking at Relationships
</p>
<p>0 5 10 15
0
</p>
<p>5
</p>
<p>10
</p>
<p>15
</p>
<p>20
</p>
<p>Number of sterile adults
</p>
<p>N
u
m
</p>
<p>b
er
</p>
<p> o
f 
</p>
<p>fo
al
</p>
<p>s
</p>
<p>Foals vs. sterile adults
</p>
<p>20 30 40 50 60 70
0
</p>
<p>5
</p>
<p>10
</p>
<p>15
</p>
<p>Number of adults
</p>
<p>N
u
m
</p>
<p>b
er
</p>
<p> o
f 
</p>
<p>st
er
</p>
<p>il
e 
</p>
<p>ad
u
lt
</p>
<p>s
</p>
<p>Sterile adults vs. adults
</p>
<p>&minus;2 &minus;1 0 1 2 3
&minus;1
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>N sterile adults (standard coordinates)
</p>
<p>N
 f
</p>
<p>o
al
</p>
<p>s 
(s
</p>
<p>ta
n
</p>
<p>d
ar
</p>
<p>d
 c
</p>
<p>o
o
</p>
<p>rd
in
</p>
<p>at
es
</p>
<p>)
</p>
<p>Foals vs. sterile adults  (standard coordinates)
</p>
<p>&minus;2 &minus;1 0 1 2
&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>N adults (standard coordinates)N
 s
</p>
<p>te
ri
</p>
<p>le
 a
</p>
<p>d
u
lt
</p>
<p>s 
(s
</p>
<p>ta
n
d
ar
</p>
<p>d
 c
</p>
<p>o
o
rd
</p>
<p>in
at
</p>
<p>es
)
</p>
<p>Sterile adults vs. adults  (standard coordinates)
</p>
<p>Fig. 2.19 Scatter plots of the number of sterile males in a horse herd against the number of adults, and the number of foals against the number of
sterile males, from data of http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html. Top: unnormalized; bottom: standard coordinates
</p>
<p>coefficient between foals and sterile males is 0.74, and the correlation coefficient between adults and sterile males is 0.68.
</p>
<p>You should find this very surprising&mdash;how do the horses know how many sterile males there are in the herd? You might
</p>
<p>think that this is an effect of scaling the plot, but there is a scatter plot in normalized coordinates in Fig. 2.19 that is entirely
</p>
<p>consistent with the conclusions suggested by the unnormalized plot. What is going on here?
</p>
<p>The answer is revealed by the scatter plots of Fig. 2.20. Here, rather than plotting a &lsquo;*&rsquo; at each data point, I have plotted
</p>
<p>the day number of the observation. This is in days from the first observation. You can see that the whole herd is shrinking&mdash;
</p>
<p>observations where there are many adults (resp. sterile adults, foals) occur with small day numbers, and observations where
</p>
<p>there are few have large day numbers. Because the whole herd is shrinking, it is true that when there are more adults and more
</p>
<p>sterile males, there are also more foals. Alternatively, you can see the plots of Fig. 2.18 as a scatter plot of herd size (resp.
</p>
<p>number of foals, number of sterile males) against day number. Then it becomes clear that the whole herd is shrinking, as is
</p>
<p>the size of each group. To drive this point home, we can look at the correlation coefficient between adults and days (�0:24),
between sterile adults and days (�0:37), and between foals and days (�0:61). We can use the rule of thumb in box 2.3 to
interpret this. This means that every 282 days, the herd loses about three adults; about one sterile adult; and about three foals.
</p>
<p>For the herd to have a stable size, it needs to gain by birth as many foals as it loses both to growing up and to death. If the herd
</p>
<p>is losing three foals every 282 days, then if they all grow up to replace the missing adults, the herd will be shrinking slightly
</p>
<p>(because it is losing four adults in this time); but if it loses foals to natural accidents, etc., then it is shrinking rather fast.
</p>
<p>The message of this example is important. To understand a simple dataset, you might need to plot it several ways. You
</p>
<p>should make a plot, look at it and ask what it says, and then try to use another type of plot to confirm or refute what you think
</p>
<p>might be going on.</p>
<p/>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html">http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html</a></div>
</div>
<div class="page"><p/>
<p>2.4 You Should 47
</p>
<p>&minus;2 &minus;1 0 1 2
</p>
<p>&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p>0
</p>
<p>6
</p>
<p>39
</p>
<p>40
</p>
<p>66
</p>
<p>67
</p>
<p>335
</p>
<p>336
</p>
<p>360
</p>
<p>361
</p>
<p>374
375
</p>
<p>404
</p>
<p>696
700
</p>
<p>710
738 742
</p>
<p>772
</p>
<p>N adults (standard coordinates)
</p>
<p>N
 f
</p>
<p>o
al
</p>
<p>s 
(s
</p>
<p>ta
n
d
ar
</p>
<p>d
 c
</p>
<p>o
o
rd
</p>
<p>in
at
</p>
<p>es
)
</p>
<p>Foals vs. adults  (standard coordinates)
</p>
<p>&minus;2 &minus;1 0 1 2
</p>
<p>&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p>0
</p>
<p>6
</p>
<p>39
</p>
<p>40
</p>
<p>66
</p>
<p>67
</p>
<p>335
</p>
<p>336
</p>
<p>360
</p>
<p>361 374
</p>
<p>375
</p>
<p>404
</p>
<p>696
</p>
<p>700
</p>
<p>837017
</p>
<p>742772
</p>
<p>N adults (standard coordinates)
</p>
<p>N
 s
</p>
<p>te
ri
</p>
<p>le
 a
</p>
<p>d
u
lt
</p>
<p>s 
(s
</p>
<p>ta
n
d
ar
</p>
<p>d
 c
</p>
<p>o
o
rd
</p>
<p>in
at
</p>
<p>es
) Sterile adults vs. adults  (standard coordinates)
</p>
<p>Fig. 2.20 Scatter plots of the number of foals vs. the number of adults and the number of adults vs. the number of sterile adults for the wild
horse herd, from http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html. Rather than plot data points as dots, I have plotted the day on which the
observation was made. Notice how the herd starts large, and then shrinks
</p>
<p>2.4 You Should
</p>
<p>2.4.1 Remember These Definitions
</p>
<p>Correlation coefficient . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
</p>
<p>2.4.2 Remember These Terms
</p>
<p>pie chart . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
</p>
<p>stacked bar chart . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
</p>
<p>heat map . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
</p>
<p>3D bar chart . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
</p>
<p>scatter plot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
</p>
<p>correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
</p>
<p>correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
</p>
<p>latent variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
</p>
<p>2.4.3 Remember These Facts
</p>
<p>Properties of the correlation coefficient . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
</p>
<p>2.4.4 Use These Procedures
</p>
<p>To predict a value using correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
</p>
<p>To predict a value using correlation (rule of thumb) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
</p>
<p>To predict a value using correlation (rule of thumb, compact) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
</p>
<p>2.4.5 Be Able to
</p>
<p>&bull; Plot a bar chart, a heat map, and a pie chart for a categorical dataset.
</p>
<p>&bull; Plot a dataset as a graph, making sensible choices about markers, lines and the like.</p>
<p/>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html">http://lib.stat.cmu.edu/DASL/Datafiles/WildHorses.html</a></div>
</div>
<div class="page"><p/>
<p>48 2 Looking at Relationships
</p>
<p>&bull; Plot a scatter plot for a dataset.
</p>
<p>&bull; Plot a normalized scatter plot for a dataset.
</p>
<p>&bull; Interpret the scatter plot to tell the sign of the correlation between two variables, and estimate the size of the correlation
</p>
<p>coefficient.
</p>
<p>&bull; Compute a correlation coefficient.
</p>
<p>&bull; Interpret a correlation coefficient.
</p>
<p>&bull; Use correlation to make predictions.
</p>
<p>Problems
</p>
<p>2.1 In a population, the correlation coefficient between weight and adiposity is 0.9. The mean weight is 150lb. The standard
</p>
<p>deviation in weight is 30lb. Adiposity is measured on a scale such that the mean is 0.8, and the standard deviation is 0.1.
</p>
<p>(a) Using this information, predict the expected adiposity of a subject whose weight is 170lb
</p>
<p>(b) Using this information, predict the expected weight of a subject whose adiposity is 0.75
</p>
<p>(c) How reliable do you expect this prediction to be? Why? (your answer should be a property of correlation, not an opinion
</p>
<p>about adiposity or weight)
</p>
<p>2.2 In a population, the correlation coefficient between family income and child IQ is 0.30. The mean family income was
</p>
<p>$60,000. The standard deviation in income is $20,000. IQ is measured on a scale such that the mean is 100, and the standard
</p>
<p>deviation is 15.
</p>
<p>(a) Using this information, predict the expected IQ of a child whose family income is $70,000
</p>
<p>(b) How reliable do you expect this prediction to be? Why? (your answer should be a property of correlation, not an opinion
</p>
<p>about IQ)
</p>
<p>(c) The family income now rises&mdash;does the correlation predict that the child will have a higher IQ? Why?
</p>
<p>2.3 Show that corr .f.x; y/g/ D corr .f.y; x/g/ by substituting into the definition.
</p>
<p>2.4 Show that if Oy tends to be small (resp. large) for large (resp. small) values of Ox, then the correlation coefficient will be
negative.
</p>
<p>2.5 We have a 2D dataset consisting of N pairs .Oxi; Oyi/ in normalized coordinates. This data has correlation coefficient r. We
observe a new Oy value Oy0, and wish to predict the (unknown) x value. We will do so with a linear prediction, choosing a, b, to
predict an Ox for any Oy using the rule Oxp D aOyp C b. Write ui D Oxi � Oxpi for the error that this rule makes on each data item.
</p>
<p>(a) We require mean .fug/ D 0. Show that this means that b D 0.
(b) We require that var .fug/ is minimized. Show that this means that a D r.
(c) We now have a result that seems paradoxical&mdash;if I have .Ox0; &lsaquo;/ I predict .Ox0; rOx0/ and if I have .&lsaquo;; y0/, I predict .rOy0; Oy0/.
</p>
<p>Use Fig. 2.21 to explain why this is right. The important difference between the two lines is that lies (approximately) in
</p>
<p>the middle of each vertical span of data, and the other lies (approximately) in the middle of each horizontal span of data.
</p>
<p>2.6 I did the programming exercise about the earth temperature below. I looked at the years 1965&ndash;2012. Write f.y;T/g for
the dataset giving the temperature (T) of the earth in year y. I computed: mean .fyg/ D 1988:5, std .y/ D 14, mean .fTg/ D
0:175, std .T/ D 0:231 and corr .fyg/T D 0:892. What is the best prediction using this information for the temperature in
mid 2014? in mid 2028? in mid 2042?
</p>
<p>2.7 I did the programming exercise about the earth temperature below. It is straightforward to build a dataset f.T; nt/g where
each entry contains the temperature of the earth (T) and the number of counties where FEMA declared tornadoes nt (for each
</p>
<p>year, you look up T and nt, and make a data item). I computed: mean .fTg/ D 0:175, std .T/ D 0:231, mean .fntg/ D 31:6,</p>
<p/>
</div>
<div class="page"><p/>
<p>Programming Exercises 49
</p>
<p>Fig. 2.21 This figure shows two
lines, y D 0:86x and x D 0:86y,
superimposed on the normalized
adiposity-weight scatter plot
</p>
<p>&minus;4 &minus;2 0 2 4
&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>Adiposity, normalized
</p>
<p>W
ei
</p>
<p>g
h
</p>
<p>ts
, 
</p>
<p>n
o
</p>
<p>rm
al
</p>
<p>iz
ed
</p>
<p>Adiposity and weight, correlation=0.86
</p>
<p>y=0.86 x
</p>
<p>x=0.86 y
</p>
<p>std .nt/ D 30:8, and corr .fTg/nt D 0:471. What is the best prediction using this information for the number of tornadoes if
the global earth temperature is 0.5? 0.6? 0.7?
</p>
<p>Programming Exercises
</p>
<p>2.8 At http://lib.stat.cmu.edu/DASL/Datafiles/cigcancerdat.html, you will find a dataset recording per capita cigarette sales
</p>
<p>and cancer deaths per 100 K population for a variety of cancers, recorded for 43 states and the District of Columbia in
</p>
<p>1960.
</p>
<p>(a) Plot a scatter plot of lung cancer deaths against cigarette sales, using the two letter abbreviation for each state as a
</p>
<p>marker. You should see two fairly obvious outliers. The backstory at http://lib.stat.cmu.edu/DASL/Stories/cigcancer.
</p>
<p>html suggests that the unusual sales in Nevada are generated by tourism (tourists go home, and die there) and the unusual
</p>
<p>sales in DC are generated by commuting workers (who also die at home).
</p>
<p>(b) What is the correlation coefficient between per capita cigarette sales and lung cancer deaths per 100 K population?
</p>
<p>Compute this with, and without the outliers. What effect did the outliers have? Why?
</p>
<p>(c) What is the correlation coefficient between per capita cigarette sales and bladder cancer deaths per 100 K population?
</p>
<p>Compute this with, and without the outliers. What effect did the outliers have? Why?
</p>
<p>(d) What is the correlation coefficient between per capita cigarette sales and kidney cancer deaths per 100 K population?
</p>
<p>Compute this with, and without the outliers. What effect did the outliers have? Why?
</p>
<p>(e) What is the correlation coefficient between per capita cigarette sales and leukemia deaths per 100 K population? Compute
</p>
<p>this with, and without the outliers. What effect did the outliers have? Why?
</p>
<p>(f) You should have computed a positive correlation between cigarette sales and lung cancer deaths. Does this mean that
</p>
<p>smoking causes lung cancer? Why?
</p>
<p>(g) You should have computed a negative correlation between cigarette sales and leukemia deaths. Does this mean that
</p>
<p>smoking cures leukemia? Why?
</p>
<p>2.9 At http://www.cru.uea.ac.uk/cru/info/warming/gtc.csv, you can find a dataset of global temperature by year. When I
</p>
<p>accessed this, the years spanned 1880&ndash;2012. I don&rsquo;t know what units the temperatures are measured in. Keep in mind that
</p>
<p>measuring the temperature of the earth has non-trivial difficulties (you can&rsquo;t just insert an enormous thermometer!), and if
</p>
<p>you look at http://www.cru.uea.ac.uk/cru and http://www.cru.uea.ac.uk/cru/data/temperature/ you can see some discussion
</p>
<p>of the choices made to get these measurements. There are two kinds of data in this dataset, smoothed and unsmoothed. I
</p>
<p>used the unsmoothed data, which should be fine for our purposes. The government publishes a great deal of data at http://
</p>
<p>data.gov. From there, I found a dataset, published by the Federal Emergency Management Agency (FEMA), of all federally
</p>
<p>declared disasters (which I found at http://www.fema.gov/media-library/assets/documents/28318?id=6292). We would like
</p>
<p>to see whether weather related disasters are correlated to global temperature.</p>
<p/>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/cigcancerdat.html">http://lib.stat.cmu.edu/DASL/Datafiles/cigcancerdat.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Stories/cigcancer.html">http://lib.stat.cmu.edu/DASL/Stories/cigcancer.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Stories/cigcancer.html">http://lib.stat.cmu.edu/DASL/Stories/cigcancer.html</a></div>
<div class="annotation"><a href="http://www.cru.uea.ac.uk/cru/info/warming/gtc.csv">http://www.cru.uea.ac.uk/cru/info/warming/gtc.csv</a></div>
<div class="annotation"><a href="http://www.cru.uea.ac.uk/cru">http://www.cru.uea.ac.uk/cru</a></div>
<div class="annotation"><a href="http://www.cru.uea.ac.uk/cru/data/temperature/">http://www.cru.uea.ac.uk/cru/data/temperature/</a></div>
<div class="annotation"><a href="http://data.gov">http://data.gov</a></div>
<div class="annotation"><a href="http://data.gov">http://data.gov</a></div>
<div class="annotation"><a href="http://www.fema.gov/media-library/assets/documents/28318?id=6292">http://www.fema.gov/media-library/assets/documents/28318?id=6292</a></div>
</div>
<div class="page"><p/>
<p>50 2 Looking at Relationships
</p>
<p>1960 1970 1980 1990 2000 2010 2020
</p>
<p>&minus;0.4
</p>
<p>&minus;0.2
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>Global temperature
</p>
<p>1960 1970 1980 1990 2000 2010 2020
</p>
<p>0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>100
</p>
<p>120
</p>
<p>N counties with  tornado disasters
</p>
<p>Fig. 2.22 Plots I prepared from left uea data on temperature and right FEMA data on tornadoes by county. These should help you tell if you&rsquo;re
on the right track
</p>
<p>(a) The first step is preprocessing the data. The FEMA data has all sorts of information. From 1965 on, a disaster was
</p>
<p>declared per county (so you get one line in the data set for each county), but before 1965, it seems to have been by state.
</p>
<p>We divide the disasters into four types: TORNADO, FLOOD, STORM, HURRICANE. (FEMA seems to have a much
</p>
<p>richer type system). We want to know how many counties declare a disaster of each type, in each year. This is a really
</p>
<p>rough estimate of the number of people affected by the disaster. If a disaster has two types (in some rows, you will see
</p>
<p>&ldquo;SEVERE STORMS, HEAVY RAINS &amp; FLOODING&rdquo; we will allocate the credit evenly between the types (i.e. for
</p>
<p>this case we would count 1/2 for STORM and 1/2 for FLOOD). You should write code that will (a) read the dataset and
</p>
<p>then (b) compute a table with the count of the number of counties where a disaster of each type has occurred for each
</p>
<p>year. This takes a bit of work. Notice you only need to deal with two columns of the data (the date it was declared, and
</p>
<p>the type). Notice also that FEMA changed the way it represented dates somewhere through the first column (they added
</p>
<p>times), which can cause problems. You can tell the type of the disaster by just using a string match routine with the four
</p>
<p>keywords. Figure 2.22 shows the plot of temperature and of number of counties where FEMA declared a tornado disaster
</p>
<p>for this data.
</p>
<p>(b) Plot a normalized scatter plot of the number of counties where FEMA declared the disaster against temperature, for each
</p>
<p>kind.
</p>
<p>(c) For each kind of disaster, compute the correlation coefficient between the number of counties where FEMA declared the
</p>
<p>disaster and the year. For each kind of disaster, use this correlation coefficient to predict the number of disasters of this
</p>
<p>kind for 2013. Compare this to the true number, and explain what you see.
</p>
<p>(d) For each kind of disaster, compute the correlation coefficient between the number of counties where FEMA declared
</p>
<p>the disaster and the global temperature. For each kind of disaster, use this correlation coefficient to predict the number of
</p>
<p>disasters of this kind when the earth reaches 0.6 temperature units and 0.7 temperature units (on the absolute temperature
</p>
<p>scale).
</p>
<p>(e) Does this data show that warming of the earth causes weather disasters? Why?
</p>
<p>(f) Does this data suggest that more people will be affected by disasters in the US in the future? Why?
</p>
<p>(g) Does this data suggest that the earth will be warmer in the future? Why?
</p>
<p>2.10 If you go to https://github.com/TheUpshot/Military-Surplus-Gear, you will find data on purchases of military weapons
</p>
<p>by US police departments. This data is organized by state and county. There&rsquo;s a fair amount of data here, and you&rsquo;ll need to
</p>
<p>do some data jockeying.
</p>
<p>(a) Prepare a plot showing how much each Illinois county spent under this program.
</p>
<p>(b) Now look up population levels in the counties. Prepare a plot showing how much each county spent per capita.
</p>
<p>(c) Prepare a graphic illustrating what the overall most popular items were&mdash;i.e., those items counties bought the most of.
</p>
<p>(d) Prepare a graphic illustrating on what items the most money was spent&mdash;for example, was more money spent on &ldquo;RIFLE,
</p>
<p>5.56 MILLIMETER&rdquo; or on &ldquo;MINE RESISTANT VEHICLE&rdquo;?
</p>
<p>(e) Prepare a graphic illustrating the pattern of purchases across counties for the ten overall most popular items.
</p>
<p>(f) Can you draw any interesting conclusions?</p>
<p/>
<div class="annotation"><a href="https://github.com/TheUpshot/Military-Surplus-Gear">https://github.com/TheUpshot/Military-Surplus-Gear</a></div>
</div>
<div class="page"><p/>
<p>Part II
</p>
<p>Probability</p>
<p/>
</div>
<div class="page"><p/>
<p>3Basic Ideas in Probability
</p>
<p>We will perform experiments&mdash;which could be pretty much anything, from flipping a coin, to eating too much saturated fat,
</p>
<p>to smoking, to crossing the road without looking&mdash;and reason about the outcomes (mostly bad for the examples I gave). But
</p>
<p>these outcomes are uncertain, and we need to weigh those uncertainties against one another. If I flip a coin, I could get heads
</p>
<p>or tails, and there&rsquo;s no reason to expect to see one more often than the other. If I eat too much saturated fat or smoke, I will
</p>
<p>very likely have problems, though I might not. If I cross the road without looking, I may be squashed by a truck or I may not.
</p>
<p>Our methods need also to account for information. If I look before I cross the road, I am much less likely to be squashed.
</p>
<p>Probability is the machinery we use to describe and account for the fact that some outcomes are more frequent than others.
</p>
<p>3.1 Experiments, Outcomes and Probability
</p>
<p>Imagine you repeat the same experiment numerous times. You do not necessarily expect to see the same result each time.
</p>
<p>Some results might occur more frequently than others. We account for this tendency using probability. To do so, we need
</p>
<p>to be clear about what results an experiment can have. For example, you flip a coin. We might agree that the only possible
</p>
<p>results are a head or a tail, thus ignoring the possibilities that (say) a bird swoops down and steals the coin; the coin lands
</p>
<p>and stays on edge; the coin falls between the cracks in the floor and disappears; and so on. By doing so, we have idealized
</p>
<p>the experiment.
</p>
<p>3.1.1 Outcomes and Probability
</p>
<p>We will formalize experiments by specifying the set of outcomes that we expect from the experiment. Every run of
</p>
<p>the experiment produces exactly one of the set of possible outcomes. We never see two or more outcomes from a single
</p>
<p>experiment, and we never see no outcome. The advantage of doing this is that we can count how often each outcome
</p>
<p>appears.
</p>
<p>Definition 3.1 (Sample Space) The sample space is the set of all outcomes, which we usually write &#127;.
</p>
<p>Worked example 3.1 (Find the Lady) We have three playing cards. One is a queen; one is a king, and one is a jack.
</p>
<p>All are shown face down, and one is chosen at random and turned up. What is the set of outcomes?
</p>
<p>Solution Write Q for queen, K for king, J for jack; the outcomes are fQ;K; Jg
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_3
</p>
<p>53</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_3">https://doi.org/10.1007/978-3-319-64410-3_3</a></div>
</div>
<div class="page"><p/>
<p>54 3 Basic Ideas in Probability
</p>
<p>Worked example 3.2 (Find the Lady, Twice) We play find the lady twice, replacing the card we have chosen. What
</p>
<p>is the sample space?
</p>
<p>Solution We now have fQQ;QK;QN;KQ; KK;KJ; JQ; JK; JJg
</p>
<p>Worked example 3.3 (A Poor Choice of Strategy for Planning a Family) A couple decides to have children. As
</p>
<p>they know no mathematics, they decide to have children until a girl then a boy are born. What is the sample space?
</p>
<p>Does this strategy bound the number of children they could be planning to have?
</p>
<p>Solution Write B for boy, G for girl. The sample space looks like any string of B&rsquo;s and G&rsquo;s that (a) ends in GB and (b)
</p>
<p>does not contain any other GB. In regular expression notation, you can write such strings as B�GCB. There is a lower
bound on the length of the string (two), but no upper bound. As a family planning strategy, this is unrealistic, but it
</p>
<p>serves to illustrate the point that sample spaces don&rsquo;t have to be finite to be tractable.
</p>
<p>Remember this: Sample spaces are required, and need not be finite
</p>
<p>We represent our model of how often a particular outcome will occur in a repeated experiment with a probability, a
</p>
<p>non-negative number. This number gives the relative frequency of the outcome of interest, when an experiment is repeated a
</p>
<p>very large number of times.
</p>
<p>Assume that we repeat an experiment N times. Assume also that the coins, dice, whatever involved in each repetition of
</p>
<p>the experiment don&rsquo;t communicate with one another from experiment to experiment (or, equivalently, that experiments don&rsquo;t
</p>
<p>&ldquo;know&rdquo; about one another). We say that an outcome A has probability P if (a) outcome A occurs in about N � P of those
experiments and (b) as N gets larger, the fraction of experiments where outcome A occurs will get closer to P. We write #.A/
</p>
<p>for the number of times outcome A occurs. We interpret P as
</p>
<p>lim
N!1
</p>
<p>#.A/
</p>
<p>N
:
</p>
<p>We can draw two important conclusions immediately.
</p>
<p>&bull; For any outcome A, 0 � P.A/ � 1.
&bull;
P
</p>
<p>Ai2&#127; P.Ai/ D 1.
</p>
<p>Remember that every run of the experiment produces exactly one outcome. The probabilities add up to one because each
</p>
<p>experiment must have one of the outcomes in the sample space. Some problems can be handled by building a set of outcomes
</p>
<p>and reasoning about the probability of each outcome. This is particularly useful when the outcomes must have the same
</p>
<p>probability, which happens rather a lot.
</p>
<p>Worked example 3.4 (A Biased Coin) Assume we have a coin where the probability of getting heads is P.H/ D 1
3
,
</p>
<p>and so the probability of getting tails is P.T/ D 2
3
. We flip this coin three million times. How many times do we see
</p>
<p>heads?
</p>
<p>Solution P.H/ D 1
3
, so we expect this coin will come up heads in 1
</p>
<p>3
of experiments. This means that we will very
</p>
<p>likely see very close to a million heads. Later on, we will be able to be more precise.
</p>
<p>Remember this: The probability of an outcome is the frequency of that outcome in a very large number of repeated
</p>
<p>experiments. The sum of probabilities over all outcomes must be one.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.2 Events 55
</p>
<p>3.2 Events
</p>
<p>Assume we run an experiment and get an outcome. We know what the outcome is (that&rsquo;s the whole point of a sample space).
</p>
<p>This means we can tell whether the outcome we get belongs to some particular known set of outcomes. We just look in the
</p>
<p>set and see if our outcome is there. This means that we should be able to predict the probability of a set of outcomes from
</p>
<p>any reasonable model of an experiment. For example, we might roll a die and ask what the probability of getting an even
</p>
<p>number is. We would like our probability models to be able to predict the probability of sets of outcomes.
</p>
<p>Definition 3.2 (Event) An event is a set of outcomes. I will usually write events as sets (so, for example, E/.
</p>
<p>Assume we are given a discrete sample space &#127;. A natural choice of an event space is the collection of all subsets of &#127;.
</p>
<p>It turns out that this is not the only possible choice, but we will ignore this point. So far, we have described the probability of
</p>
<p>each outcome with a non-negative number. We can extend this idea of probability to deal with events in a straightforward way.
</p>
<p>The set of all outcomes, which we wrote &#127;, must be an event. We must have P.&#127;/ D 1 (because we said that every run
of an experiment produces one outcome, and that outcome must be in &#127;). In principle, there could be no outcome, although
</p>
<p>this never happens. This means that the empty set, which we write &iquest;, is an event, and we have P.&iquest;/ D 0.
Any given outcome must be an event, because an event is a set of outcomes. Now assume A and B are two distinct
</p>
<p>outcomes, and write E D fA;Bg for the event that contains both. We must have that P.E/ D P.A/ C P.B/, because the
number of times repeated experiments produce an outcome in E is given by the number of times we see A plus the number
</p>
<p>of times we see B. Now assume that Ci are N distinct outcomes, and F is the event that contains all of them, and no other
</p>
<p>outcomes. Then we must have P.F/ D
P
</p>
<p>i P.Ci/ (because we observe an outcome in F whenever we see any of the outcomes
</p>
<p>Ci). In turn, this means that if E and F are disjoint events, P.E [F/ D P.E/C P.F/. All this yields a straightforward set of
properties, collected in a box below.
</p>
<p>Useful Facts 3.1 (Basic Properties of the Probability Events)
</p>
<p>We have
</p>
<p>&bull; The probability of every event is between zero and one; in equations
</p>
<p>0 � P.A/ � 1
</p>
<p>for any event A.
</p>
<p>&bull; Every experiment has an outcome; in equations,
</p>
<p>P.&#127;/ D 1:
</p>
<p>&bull; The probability of disjoint events is additive; writing this in equations requires some notation. Assume that we have
</p>
<p>a collection of events Ai, indexed by i. We require that these have the property Ai\Aj D &iquest; when i &curren; j. This means
that there is no outcome that appears in more than one Ai. In turn, if we interpret probability as relative frequency,
</p>
<p>we must have that
</p>
<p>P.[iAi/ D
X
</p>
<p>i
</p>
<p>P.Ai/</p>
<p/>
</div>
<div class="page"><p/>
<p>56 3 Basic Ideas in Probability
</p>
<p>3.2.1 Computing Event Probabilities by Counting Outcomes
</p>
<p>If you can compute the probability of each outcome in an event F , computing the probability of the event is straightforward.
</p>
<p>The outcomes are each disjoint events, so you just add the probabilities. A common, and particularly useful, case occurs
</p>
<p>when you know each outcome in the sample space has the same probability. In this case, computing the probability of an
</p>
<p>event is an exercise in counting. You can show
</p>
<p>P.F/ D Number of outcomes in F
Total number of outcomes in &#127;
</p>
<p>(look at the exercises).
</p>
<p>Worked example 3.5 (Odd Numbers with Fair Dice) We throw a fair (each number has the same probability)
</p>
<p>six-sided die twice, then add the two numbers. What is the probability of getting an odd number?
</p>
<p>Solution There are 36 outcomes. Each has the same probability (1=36). Eighteen of them give an odd number, and the
</p>
<p>other 18 give an even number, so the probability is 18=36 D 1=2
</p>
<p>Worked example 3.6 (Numbers Divisible by Five with Fair Dice) We throw a fair (each number has the same
</p>
<p>probability) six-sided die twice, then add the two numbers. What is the probability of getting a number divisible by
</p>
<p>five?
</p>
<p>Solution There are 36 outcomes. Each has the same probability (1=36). For this event, the spots must add to either 5
</p>
<p>or to 10. There are 4 ways to get 5. There are 3 ways to get 10, so the probability is 7=36.
</p>
<p>Sometimes a bit of fiddling with the space of outcomes makes it easy to compute what we want. Examples 3.8 and 3.47
</p>
<p>show cases where you can use fictitious outcomes as an accounting device to simplify a computation.
</p>
<p>Worked example 3.7 (Children&mdash;1) A couple decides to have children. They decide simply to have three children.
</p>
<p>Assume that three births occur, each birth results in one child, and boys and girls are equally likely at each birth. Let
</p>
<p>Bi be the event that there are i boys, and C be the event there are more girls than boys. Compute P.B1/ and P.C/.
</p>
<p>Solution There are eight outcomes. Each has the same probability. Three of them have a single boy, so P.B1/ D 3=8.
Four of these outcomes have more girls than boys, so P.C/ D 1=2.
</p>
<p>Worked example 3.8 (Children&mdash;2) A couple decides to have children. They decide to have children until the first
</p>
<p>girl is born, or until there are three, and then stop. Assume that each birth results in one child, and boys and girls are
</p>
<p>equally likely at each birth. Let Bi be the event that there are i boys, and C be the event there are more girls than boys.
</p>
<p>Compute P.B1/ and P.C/.
</p>
<p>Solution In this case, we could write the outcomes as fG;BG;BBGg, but if we think about them like this, we have no
simple way to compute their probability. Instead, we could use the sample space from the previous answer, but assume
</p>
<p>that some of the later births are fictitious. This gives us natural collection of events for which it is easy to compute
</p>
<p>probabilities. Having one girl corresponds to the event fGbb;Gbg;Ggb;Gggg, where I have used lowercase letters to
write the fictitious later births; the probability is 1=2. Having a boy then a girl corresponds to the event fBGb;BGgg
(and so has probability 1=4). Having two boys then a girl corresponds to the event fBBGg (and so has probability 1=8).
Finally, having three boys corresponds to the event fBBBg (and so has probability 1=8). This means that P.B1/ D 1=4
and P.C/ D 1=2.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.2 Events 57
</p>
<p>Counting outcomes in an event can require pretty elaborate combinatorial arguments. One form of argument that is
</p>
<p>particularly important is to reason about permutations and combinations. You should recall that the number of distinct
</p>
<p>permutations of N items is NŠ.
</p>
<p>Worked example 3.9 (Card Hands) You draw a hand of seven cards from a properly shuffled standard deck of cards.
</p>
<p>With what probability do receive 2&ndash;8 of hearts, in that order?
</p>
<p>Solution There are numerous ways to do this, but I&rsquo;ll use permutations. There are 52! different orderings of a properly
</p>
<p>shuffled deck of cards. This is the total number of outcomes. The number of outcomes in the event comes by noticing
</p>
<p>that any outcome in the event is an ordering of the cards where the first seven cards are 2&ndash;8 of hearts, in that order.
</p>
<p>So there are 45! outcomes in the event, because you can reorder the remaining 45 cards arbitrarily. This means the
</p>
<p>probability is
45Š
</p>
<p>52Š
:
</p>
<p>The number of combinations of k items, chosen from N, where the order does not matter, is given by
</p>
<p>NŠ
</p>
<p>kŠ.N � k/Š D
�
</p>
<p>N
</p>
<p>k
</p>
<p>�
</p>
<p>:
</p>
<p>Worked example 3.10 (Card Hands&mdash;2) You draw a hand of seven cards from a properly shuffled standard deck of
</p>
<p>cards. With what probability do receive 2&ndash;8 of hearts, in any order?
</p>
<p>Solution There are 52! different orderings of a properly shuffled deck of cards, so 52! outcomes Of these, 45! have
</p>
<p>the first seven cards 2&ndash;8 of hearts. There are 7! orderings of these cards. So the number of outcomes in the event is 45!
</p>
<p>7! and the probability is
7Š45Š
</p>
<p>52Š
</p>
<p>Alternatively, there are
</p>
<p>�
</p>
<p>N
</p>
<p>k
</p>
<p>�
</p>
<p>hands of seven distinct cards, ignoring the order in which they are obtained. Only one
</p>
<p>such hand contains 2&ndash;8 of hearts, so the probability is
</p>
<p>1
�
</p>
<p>52
</p>
<p>7
</p>
<p>�
</p>
<p>(and you should check this reasoning got us to the same answer as the previous argument).
</p>
<p>Worked example 3.11 (Card Hands&mdash;3) You draw a hand of seven cards from a properly shuffled standard deck of
</p>
<p>cards. With what probability does your hand contain 2&ndash;8 of any suit? The cards don&rsquo;t have to have the same suit, and
</p>
<p>they can arrive in any order.
</p>
<p>Solution From the previous example, there are 52! orderings of a properly shuffled deck and so 52! outcomes in total.
</p>
<p>There are 45! orderings that fix the first seven cards to some specified values, as in Worked example 3.9. The number
</p>
<p>of hands of seven cards that works is obtained by (a) choosing a suit for each card then (b) counting the number of
</p>
<p>different orders. This yields 477Š45Š outcomes in the event, so the probability is
</p>
<p>477Š45Š
</p>
<p>52Š
:</p>
<p/>
</div>
<div class="page"><p/>
<p>58 3 Basic Ideas in Probability
</p>
<p>A
</p>
<p>B
</p>
<p>A B
</p>
<p>A
</p>
<p>Ω Ω
</p>
<p>Fig. 3.1 If you think of the probability of an event as measuring its &ldquo;size&rdquo;, many of the rules are quite straightforward to remember. Venn diagrams
can sometimes help. On the left, a Venn diagram to help remember that P.A/C P.Ac/ D 1. The &ldquo;size&rdquo; of &#127; is 1, outcomes lie either in A or Ac,
and the two don&rsquo;t intersect. On the right, you can see that P.A� B/ D P.A/� P.A \ B/ by noticing that P.A� B/ is the &ldquo;size&rdquo; of the part of
A that isn&rsquo;t B. This is obtained by taking the &ldquo;size&rdquo; of A and subtracting the &ldquo;size&rdquo; of the part that is also in B, i.e. the &ldquo;size&rdquo; of A\ B. Similarly,
you can see that P.A[ B/ D P.A/C P.B/� P.A\ B/ by noticing that you can get the &ldquo;size&rdquo; of A[ B by adding the &ldquo;sizes&rdquo; of A and B, then
subtracting the &ldquo;size&rdquo; of the intersection to avoid double counting
</p>
<p>Remember this: In some problems, you can compute the probabilities of events by counting outcomes.
</p>
<p>3.2.2 The Probability of Events
</p>
<p>There is an analogy between probability and &ldquo;size&rdquo; which is helpful in deriving and remembering expressions for the
</p>
<p>probability of events. Think about the probability of an event as the &ldquo;size&rdquo; of that event. This &ldquo;size&rdquo; is relative to &#127;, which
</p>
<p>has &ldquo;size&rdquo; 1. I find this a good way to remember equations. Some people find Venn diagrams a useful way to keep track of
</p>
<p>this argument, and Fig. 3.1 is for them.
</p>
<p>Notice that A and Ac don&rsquo;t overlap, and together make up all of &#127;. So the &ldquo;size&rdquo; of A and the &ldquo;size&rdquo; of Ac should add to
</p>
<p>the &ldquo;size&rdquo; of &#127; and so
</p>
<p>P.A/C P.Ac/ D 1:
</p>
<p>Notice the &ldquo;size&rdquo; of the part of A that isn&rsquo;t in B is obtained by taking the &ldquo;size&rdquo; of A and subtracting the &ldquo;size&rdquo; of
</p>
<p>A \ B&mdash;that is, the part of A that is also in B. This means that
</p>
<p>P.A � B/ D P.A/ � P.A \ B/
</p>
<p>Notice the &ldquo;size&rdquo; of A [ B is obtained by adding the two &ldquo;sizes&rdquo;, then subtracting the &ldquo;size&rdquo; of the intersection because
otherwise you would double-count the part where the two sets overlap. This means that
</p>
<p>P.A [ B/ D P.A/C P.B/ � P.A \ B/:
</p>
<p>I have collected these expressions, which you should remember, in box 3.2. The &ldquo;size&rdquo; analogy can be made precise by
</p>
<p>thinking about &ldquo;size&rdquo; in the right way; I won&rsquo;t bother, because doing so takes effort without really enhancing the underlying
</p>
<p>intuition. I prove the expressions are right without using the &ldquo;size&rdquo; analogy below.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.2 Events 59
</p>
<p>Useful Facts 3.2 (Properties of the Probability of Events)
</p>
<p>&bull; P.Ac/ D 1 � P.A/
&bull; P.&iquest;/ D 0
&bull; P.A � B/ D P.A/ � P.A \ B/
&bull; P.A [ B/ D P.A/C P.B/ � P.A \ B/
&bull; P.[n1Ai/ D
</p>
<p>P
</p>
<p>i P.Ai/ �
P
</p>
<p>i&lt;j P.Ai \Aj/C
P
</p>
<p>i&lt;j&lt;k P.Ai \Aj \Ak/C : : : .�1/.nC1/P.A1 \A2 \ : : : \An/
</p>
<p>Proposition P.Ac/ D 1 � P.A/
</p>
<p>Proof Ac and A are disjoint, so that P.Ac [A/ D P.Ac/C P.A/ D P.&#127;/ D 1.
</p>
<p>Proposition P.&iquest;/ D 0
</p>
<p>Proof P.&iquest;/ D P.&#127;c/ D P.&#127; �&#127;/ D 1 � P.&#127;/ D 1 � 1 D 0.
</p>
<p>Proposition P.A � B/ D P.A/ � P.A \ B/
</p>
<p>Proof A � B is disjoint from A \ B, and .A � B/[ .A \ B/ D A. This means that P.A � B/C P.A \ B/ D P.A/.
</p>
<p>Proposition P.A [ B/ D P.A/C P.B/ � P.A \ B/
</p>
<p>Proof P.A [ B/ D P.A [ .B \ Ac// D P.A/ C P..B \ Ac//. Now B D .B \A/ [ .B \Ac/. Furthermore,
.B \A/ is disjoint from .B \Ac/, so we have P.B/ D P..B \A// C P..B \Ac//. This means that P.A [ B/ D
P.A/C P..B \Ac// D P.A/C P.B/ � P..B \A//.
</p>
<p>Proposition P.[n1Ai/ D
P
</p>
<p>i P.Ai/�
P
</p>
<p>i&lt;j P.Ai\Aj/C
P
</p>
<p>i&lt;j&lt;k P.Ai\Aj\Ak/C : : : .�1/.nC1/P.A1\A2\ : : :\An/
</p>
<p>Proof This can be proven by repeated application of the previous result. As an example, we show how to work the
</p>
<p>case where there are three sets (you can get the rest by induction).
</p>
<p>P.A1 [A2 [A3/
</p>
<p>D P.A1 [ .A2 [A3//
</p>
<p>D P.A1/C P.A2 [A3/
</p>
<p>�P.A1 \ .A2 [A3//
</p>
<p>D P.A1/C .P.A2/C P.A3/ � P.A2 \A3//
</p>
<p>�P..A1 \A2/ [ .A1 \A3//
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>60 3 Basic Ideas in Probability
</p>
<p>D P.A1/C .P.A2/C P.A3/ � P.A2 \A3//
</p>
<p>�P.A1 \A2/ � P.A1 \A3/
</p>
<p>�.�P..A1 \A2/ \ .A1 \A3///
</p>
<p>D P.A1/C P.A2/C P.A3/
</p>
<p>�P.A2 \A3/ � P.A1 \A2/ � P.A1 \A3/
</p>
<p>CP.A1 \A2 \A3/
</p>
<p>3.2.3 Computing Probabilities by Reasoning About Sets
</p>
<p>The rule P.Ac/ D 1 � P.A/ is occasionally useful for computing probabilities on its own. More commonly, you need other
reasoning as well. The next problem illustrates an important feature of questions in probability: your intuition can be quite
</p>
<p>misleading. One problem is that the number of outcomes can be bigger or smaller than you expect.
</p>
<p>Worked example 3.12 (Shared Birthdays) What is the probability that, in a room of 30 people, there is a pair of
</p>
<p>people who have the same birthday?
</p>
<p>Solution We simplify, and assume that each year has 365 days, and that none of them are special (i.e. each day has the
</p>
<p>same probability of being chosen as a birthday). This model isn&rsquo;t perfect (there tend to be slightly more births roughly
</p>
<p>9 months after: the start of spring; blackouts; major disasters; and so on) but it&rsquo;s workable. The easy way to attack this
</p>
<p>question is to notice that our probability, P.fshared birthdayg/, is
</p>
<p>1 � P.fall birthdays differentg/:
</p>
<p>This second probability is rather easy to compute. Each outcome in the sample space is a list of 30 days (one birthday
</p>
<p>per person). Each outcome has the same probability. So
</p>
<p>P.fall birthdays differentg/
</p>
<p>D Number of outcomes in the event
Total number of outcomes
</p>
<p>:
</p>
<p>The total number of outcomes is easily seen to be 36530, which is the total number of possible lists of 30 days. The
</p>
<p>number of outcomes in the event is the number of lists of 30 days, all different. To count these, we notice that there are
</p>
<p>365 choices for the first day; 364 for the second; and so on. So we have
</p>
<p>P.fshared birthdayg/
</p>
<p>D 1 � 365 � 364 � : : : 336
36530
</p>
<p>� 1 � 0:29 D 0:71
</p>
<p>which means there&rsquo;s really a pretty good chance that two people in a room of 30 share a birthday.
</p>
<p>If we change the birthday example slightly, the problem changes drastically. If you stand up in a room of 30 people and
</p>
<p>bet that two people in the room have the same birthday, you have a probability of winning of about 0:71. If you bet that there
</p>
<p>is someone else in the room who has the same birthday that you do, your probability of winning is very different.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 Independence 61
</p>
<p>Worked example 3.13 (Shared Birthdays) You bet there is someone else in a room of 30 people who has the same
</p>
<p>birthday that you do. Assuming you know nothing about the other 29 people, what is the probability of winning?
</p>
<p>Solution The easy way to do this is
</p>
<p>P.fwinningg/ D 1 � P.flosingg/:
</p>
<p>Now you will lose if everyone has a birthday different from you. You can think of the birthdays of the others in the
</p>
<p>room as a list of 29 days of the year. If your birthday is on the list, you win; if it&rsquo;s not, you lose. The number of losing
</p>
<p>lists is the number of lists of 29 days of the year such that your birthday is not in the list. This number is easy to get.
</p>
<p>We have 364 days of the year to choose from for each of 29 locations in the list. The total number of lists is the number
</p>
<p>of lists of 29 days of the year. Each list has the same probability. So
</p>
<p>P.flosingg/ D 364
29
</p>
<p>36529
</p>
<p>and
</p>
<p>P.fwinningg/ � 0:0765:
</p>
<p>There is a wide variety of problems like this; if you&rsquo;re so inclined, you can make a small but quite reliable profit off
</p>
<p>people&rsquo;s inability to estimate probabilities for this kind of problem correctly (Examples 3.12 and 3.13 are reliably profitable;
</p>
<p>you could probably do quite well out of Examples 3.45 and 3.46).
</p>
<p>The rule P.A�B/ D P.A/�P.A\B/ is also occasionally useful for computing probabilities on its own; more commonly,
you need other reasoning as well.
</p>
<p>Worked example 3.14 (Dice) You flip two fair six-sided dice, and add the number of spots. What is the probability
</p>
<p>of getting a number divisible by 2, but not by 5?
</p>
<p>Solution There is an interesting way to work the problem. Write Dn for the event the number is divisible by n. Now
</p>
<p>P.D2/ D 1=2 (count the cases; or, more elegantly, notice that each die has the same number of odd and even faces, and
work from there). Now P.D2 �D5/ D P.D2/�P.D2 \D5/. But D2 \D5 contains only three outcomes (6; 4, 5; 5 and
4; 6), so P.D2 �D5/ D 18=36 � 3=36 D 5=12
</p>
<p>Sometimes it is easier to reason about unions than to count outcomes directly.
</p>
<p>Worked example 3.15 (Two Fair Dice) I roll two fair six-sided dice. What is the probability that the result is divisible
</p>
<p>by either 2 or 5, or both?
</p>
<p>Solution Write Dn for the event the number is divisible by n. We want P.D2 [D5/ D P.D2/C P.D5/� P.D2 \D5/.
From Example 3.14, we know P.D2/ D 1=2 and P.D2 \ D5/ D 3=36. By counting outcomes, P.D5/ D 7=36. So
P.D2 [D5/ D .18C 7 � 3/=36 D 22=36.
</p>
<p>3.3 Independence
</p>
<p>Some experimental results do not affect others. For example, if I flip a coin twice, whether I get heads on the first flip has no
</p>
<p>effect on whether I get heads on the second flip. As another example, I flip a coin; the outcome does not affect whether I get
</p>
<p>hit on the head by a falling apple later in the day. We refer to events with this property as independent.
</p>
<p>Here is a pair of events that is not independent. Imagine I throw a six-sided die. Write A for the event that the die comes
</p>
<p>up with an odd number of spots, and write B for the event that the number of spots is either 3 or 5. Now these events are</p>
<p/>
</div>
<div class="page"><p/>
<p>62 3 Basic Ideas in Probability
</p>
<p>A
</p>
<p>B
</p>
<p>A
</p>
<p>B
</p>
<p>Independent Events Dependent Events
</p>
<p>Ω Ω
</p>
<p>Fig. 3.2 On the left, A and B are independent. A spans 1=4 of &#127;, and A\ B spans 1=4 of B. This means that knowing whether an outcome is in
A or not doesn&rsquo;t affect the probability that it is in B. 1=4 of the outcomes of &#127; lie in A, and 1=4 of theoutcomes in B lie in A\ B. On the right,
they are not. Very few of the outcomes in B lie in B\A, so that observing B means that A becomes less likely, because very few of the outcomes
in B also lie in A\ B
</p>
<p>interrelated in an important way. If I know that B has occurred, I also know that A has occurred&mdash;I don&rsquo;t need to check
</p>
<p>separately, because B implies A.
</p>
<p>Here is an example of a weaker interaction that results in events not being independent. Write C for the event that the die
</p>
<p>comes up with an odd number of spots, and write D for the event that the number of spots is larger than 3. These events are
</p>
<p>interrelated. The probability of each event separately is 1/2. If I know that C has occurred, then I know that the die shows
</p>
<p>either 1, 3, or 5 spots. One of these outcomes belongs to D, and two do not. This means that knowing that C has occurred tells
</p>
<p>you something about whether D has occurred. Independent events do not have this property. This means that the probability
</p>
<p>that they occur together has an important property, given in the box below.
</p>
<p>Definition 3.3 (Independent Events) Two events A and B are independent if and only if
</p>
<p>P.A \ B/ D P.A/P.B/
</p>
<p>The &ldquo;size&rdquo; analogy helps motivate this expression. We think of P.A/ as the &ldquo;size&rdquo; of A relative to &#127;, and so on. Now
</p>
<p>P.A \ B/ measures the &ldquo;size&rdquo; of A \ B&mdash;that is, the part of A that lies inside B. But if A and B are independent, then the
&ldquo;size&rdquo; of A \ B relative to B should be the same as the &ldquo;size&rdquo; of A relative to &#127; (Fig. 3.2). Otherwise, B affects A, because
A is more (or less) likely when B has occurred.
</p>
<p>So for A and B to be independent, we must have
</p>
<p>&ldquo;Size&rdquo; of A D &ldquo;Size&rdquo; of piece of A in B
&ldquo;Size&rdquo; of B
</p>
<p>;
</p>
<p>or, equivalently,
</p>
<p>P.A/ D P.A \ B/
P.B/
</p>
<p>which yields our expression.
</p>
<p>Worked example 3.16 (Fair Dice) The space of outcomes for a fair six-sided die is
</p>
<p>f1; 2; 3; 4; 5; 6g :
</p>
<p>The die is fair, so each outcome has the same probability. Now we toss two fair six-sided dice. The outcome for each
</p>
<p>die is independent of that for the other. With what probability do we get two threes?
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 Independence 63
</p>
<p>Solution
</p>
<p>P .first die yields 3 \ second die yields 3/
</p>
<p>D P.first die yields 3/ �
</p>
<p>P.second die yields 3/
</p>
<p>D .1=6/.1=6/
</p>
<p>D 1=36
</p>
<p>Worked example 3.17 (Find the Lady, Twice) Recall the setup of Worked example 3.1. Assume that the card that
</p>
<p>is chosen is chosen fairly&mdash;that is, each card is chosen with the same probability. The game is played twice, and the
</p>
<p>cards are reshuffled between games. What is the probability of turning up a Queen and then a Queen again?
</p>
<p>Solution The events are independent, so 1=9.
</p>
<p>You can use Definition 3.3 (i.e. A and B are independent if and only if P.A \ B/ D P.A/P.B/) to tell whether events
are independent or not. Quite small changes to a problem affect whether events are independent, as in the worked example
</p>
<p>below.
</p>
<p>Worked example 3.18 (Cards and Independence) We shuffle a standard deck of 52 cards and draw one card. The
</p>
<p>event A is &ldquo;the card is a red suit&rdquo; and the event B is &ldquo;the card is a 10&rdquo;. (1): Are A and B independent?
</p>
<p>Now we take a standard deck of cards, and remove the ten of hearts. We shuffle this deck, and draw one card. The
</p>
<p>event C is &ldquo;the card drawn from the modified deck is a red suit&rdquo; and the event D is &ldquo;the card drawn from the modified
</p>
<p>deck is a 10&rdquo;. (2): Are C and D independent?
</p>
<p>Solution (1): P.A/ D 1=2, P.B/ D 1=13 and in Example 3.44 we determined P.A\B/ D 2=52. But 2=52 D 1=26 D
P.A/P.B/, so they are independent.
</p>
<p>(2): These are not independent because P.C/ D 25=51, P.D/ D 3=51 and P.C \ D/ D 1=51 &curren; P.C/P.D/ D
75=.512/
</p>
<p>The probability of a sequence of independent events can become very small very quickly, and this often misleads people.
</p>
<p>Worked example 3.19 (Accidental DNA Matches) I search a DNA database with a sample. Each time I attempt to
</p>
<p>match this sample to an entry in the database, there is a probability of an accidental chance match of 1e � 4. Chance
matches are independent. There are 20,000 people in the database. What is the probability I get at least one match,
</p>
<p>purely by chance?
</p>
<p>Solution This is 1 � P(no chance matches). But P.no chance matches/ is much smaller than you think. We have
</p>
<p>P.no chance matches/
</p>
<p>D P
</p>
<p>0
</p>
<p>B
</p>
<p>B
</p>
<p>@
</p>
<p>no chance match to record 1\
no chance match to record 2\
</p>
<p>: : :\
no chance match to record 20,000
</p>
<p>1
</p>
<p>C
</p>
<p>C
</p>
<p>A
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>64 3 Basic Ideas in Probability
</p>
<p>D P.no chance match to a record/20;000
</p>
<p>D .1 � 1e � 4/20;000
</p>
<p>� 0:14
</p>
<p>so the probability is about 0:86 that you get at least one match by chance. If you&rsquo;re surprised, look at the exponent.
</p>
<p>Notice that if the database gets bigger, the probability grows; so at 40,000 the probability of one match by
</p>
<p>chance is 0:98.
</p>
<p>People quite often reason poorly about independent events. The most common problem is known as the gambler&rsquo;s fallacy.
</p>
<p>This occurs when you reason that the probability of an independent event has been changed by previous outcomes. For
</p>
<p>example, imagine I toss a coin that is known to be fair 20 times and get 20 heads. The probability that the next toss will
</p>
<p>result in a head has not changed at all&mdash;it is still 0.5&mdash;but many people will believe that it has changed. At time of writing,
</p>
<p>Wikipedia has some fascinating stories about the gambler&rsquo;s fallacy which suggest that it&rsquo;s quite a common mistake. People
</p>
<p>may interpret, say, a run of 20 heads as evidence that either the coin isn&rsquo;t fair, or the tosses aren&rsquo;t independent.
</p>
<p>Remember this: Independence can mislead your intuition. There are two common problems. The first happens because
</p>
<p>the probability of a set of independent events can become very small very quickly, so that modelling events that aren&rsquo;t
</p>
<p>independent as independent can lead to trouble (as in Worked example 3.19). The second happens because most people
</p>
<p>want to believe that the universe keeps track of independent events to ensure that probability calculations work (the
</p>
<p>gambler&rsquo;s fallacy).
</p>
<p>3.3.1 Example: Airline Overbooking
</p>
<p>We can now quite easily study airline overbooking. Airlines generally sell more tickets for a flight than there are seats on the
</p>
<p>aircraft, because some passengers don&rsquo;t turn up on time, usually for random reasons. If the airline only sold one ticket per seat,
</p>
<p>their planes would likely have empty seats&mdash;which are lost profit&mdash;on each flight. If too many passengers turn up for a flight,
</p>
<p>the airline hopes that someone will accept a reasonable sum of money to take the next flight. Overbooking is sensible, efficient
</p>
<p>behavior and good for passengers if sensibly administered by the airline. This is because ticket prices should be at their lowest
</p>
<p>when each plane is just full, and there is quite likely some passenger who will take money to fly at some other time.
</p>
<p>To choose the number of extra tickets sold, the airline needs to think about the probability of having to pay out (which
</p>
<p>we compute below) and the amount of money they will need to pay. We don&rsquo;t have the tools to discuss how much the airline
</p>
<p>may need to pay, which depends quite a lot on passenger behavior, details of the schedule for the next flight, and so on. On
</p>
<p>occasion, the strategy can get expensive for the airline. While I was revising this text for publication, an airline managed to
</p>
<p>hit headlines by having airport security drag a passenger off a flight. Details of the resulting settlement were not publicised,
</p>
<p>but it can&rsquo;t have been cheap for the airline.
</p>
<p>Worked example 3.20 (Overbooking&mdash;1) An airline has a regular flight with six seats. It always sells seven tickets.
</p>
<p>Passengers turn up for the flight with probability p, and do so independent of other passengers. What is the probability
</p>
<p>that the flight is overbooked?
</p>
<p>Solution This is like a coin-flip problem; think of each passenger as a biased coin. With probability p, the biased coin
</p>
<p>comes up T (for turn up) and with probability .1 � p/, it turns up H (for no-show). This coin is flipped seven times,
and we are interested in the probability that there are seven T&rsquo;s. This is p7, because the flips are independent.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 Independence 65
</p>
<p>Worked example 3.21 (Overbooking&mdash;2) An airline has a regular flight with six seats. It always sells eight tickets.
</p>
<p>Passengers turn up for the flight with probability p, and do so independent of other passengers. What is the probability
</p>
<p>that the flight is overbooked?
</p>
<p>Solution Now we flip the coin eight times, and are interested in the probability of getting more than six T&rsquo;s. This is
</p>
<p>the union of two disjoint events (seven T&rsquo;s and eight T&rsquo;s). For the case of seven T&rsquo;s, one flip must be H; there are eight
</p>
<p>choices for this flip. For the case of eight T&rsquo;s, all eight flips must be T , and there is only one way to achieve this. So
</p>
<p>the probability the flight is overbooked is
</p>
<p>P.overbooked/ D P.7 T&rsquo;s [ 8 T&rsquo;s/
</p>
<p>D P.7 T&rsquo;s/C P.8 T&rsquo;s/
</p>
<p>D 8p7.1 � p/C p8
</p>
<p>Worked example 3.22 (Overbooking&mdash;3) An airline has a regular flight with six seats. It always sells eight tickets.
</p>
<p>Passengers turn up for the flight with probability p, and do so independent of other passengers. What is the probability
</p>
<p>that six passengers arrive? (i.e. the flight is not overbooked or underbooked).
</p>
<p>Solution Now we flip the coin eight times, and are interested in the probability of getting exactly six T&rsquo;s. The
</p>
<p>probability that a particular set of six passengers arrives is given by the probability of getting any given string of
</p>
<p>six T&rsquo;s and two H&rsquo;s. This must have probability p6.1 � p/2. But there are a total of 8Š
2Š6Š
</p>
<p>distinct such strings. So the
</p>
<p>probability that six passengers arrive is
</p>
<p>8Š
</p>
<p>2Š6Š
p6.1 � p/2 D 28p6.1 � p/2:
</p>
<p>Worked example 3.23 (Overbooking&mdash;4) An airline has a regular flight with s seats. It always sells t tickets.
</p>
<p>Passengers turn up for the flight with probability p, and do so independent of other passengers. What is the probability
</p>
<p>that u passengers turn up?
</p>
<p>Solution Now we flip the coin t times, and are interested in the probability of getting u T&rsquo;s. There are
</p>
<p>tŠ
</p>
<p>uŠ.t � u/Š
</p>
<p>disjoint outcomes with u T&rsquo;s and t � u H&rsquo;s. Each such outcome is independent, and has probability pu.1 � p/t�u. So
</p>
<p>P.u passengers turn up/ D tŠ
uŠ.t � u/Š p
</p>
<p>u.1 � p/t�u</p>
<p/>
</div>
<div class="page"><p/>
<p>66 3 Basic Ideas in Probability
</p>
<p>Worked example 3.24 (Overbooking&mdash;5) An airline has a regular flight with s seats. It always sells t tickets.
</p>
<p>Passengers turn up for the flight with probability p, and do so independent of other passengers. What is the probability
</p>
<p>that the flight is oversold?
</p>
<p>Solution We need P.fsC 1 turn upg [ fsC 2 turn upg [ : : : [ ft turn upg/. But the events fi turn upg and fj turn upg
are disjoint if i &curren; j. So we can exploit Example 3.23, and write
</p>
<p>P.overbooked/ D P.fsC 1 turn upg/
</p>
<p>CP.fsC 2 turn upg/C
</p>
<p>: : :P.ft turn upg/
</p>
<p>D
t
X
</p>
<p>iDsC1
P.fi turn upg/
</p>
<p>D
t
X
</p>
<p>iDsC1
</p>
<p>tŠ
</p>
<p>iŠ.t � i/Šp
i.1 � p/t�i
</p>
<p>3.4 Conditional Probability
</p>
<p>Imagine we have two events A and B. If they are independent, then the probability that they occur together is straightforward
</p>
<p>to compute. But if A and B are not independent, then knowing that one event has occurred can have a significant effect on
</p>
<p>the probability the other will occur. Here are two extreme examples. If A and B are the same, then knowing that A occurred
</p>
<p>means you know that B occurred, too. If A D Bc, then knowing that A occurred means you know that B did not occur. A
less extreme example appears below.
</p>
<p>Worked example 3.25 (The Probability of Events That Are Not Independent) You throw a fair six-sided die twice
</p>
<p>and add the numbers. First, compute the probability of getting a number less than six. Second, imagine you know that
</p>
<p>the first die came up three. Compute the probability the sum will be less than six. Third, imagine you know that the
</p>
<p>first die came up four. Compute the probability the sum will be less than six. Finally, imagine you know that the first
</p>
<p>die came up one. Compute the probability the sum will be less than six.
</p>
<p>Solution The probability of getting a number less than six is 10
36
</p>
<p>. If the first die comes up three, then the question is
</p>
<p>what is the probability of getting a number less than three on the second die, which is 1
3
. If the first die comes up four,
</p>
<p>then the question is what is the probability of getting a number less than two on the second die, which is 1
6
. Finally, if
</p>
<p>the first die comes up one, then the question is what is the probability of getting a number less than five on the second
</p>
<p>die, which is 2
3
.
</p>
<p>Notice how, in Worked example 3.25, knowing what happened to the first die can have a significant effect on the
</p>
<p>probability of the event.
</p>
<p>Definition 3.4 (Conditional Probability) We assume we have a space of outcomes and a collection of events. The
</p>
<p>conditional probability of B, conditioned on A, is the probability that B occurs given that A has definitely occurred.
</p>
<p>We write this as
</p>
<p>P.BjA/:
</p>
<p>From the examples, it should be clear to you that for some cases P.BjA/ is the same as P.B/, and for other cases it is not.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.4 Conditional Probability 67
</p>
<p>3.4.1 Evaluating Conditional Probabilities
</p>
<p>To get an expression for P.BjA/, notice that, because A is known to have occurred, our space of outcomes or sample space
is now reduced to A. We know that our outcome lies in A; P.BjA/ is the probability that it also lies in B \A.
</p>
<p>The outcome lies in A, and so it must lie in either B \A or in Bc \A, and it cannot lie in both. This means that
</p>
<p>P.BjA/C P.BcjA/ D 1:
</p>
<p>Now recall the idea of probabilities as relative frequencies. If P.C \ A/ D kP.B \ A/, this means that outcomes in C \ A
will appear k times as often as outcomes in B\A. But this must apply even if we know in advance that the outcome is in A.
This means that, if P.C \A/ D kP.B \A/, then P.CjA/ D kP.BjA/. In turn, we must have
</p>
<p>P.BjA/ / P.B \A/:
</p>
<p>Now we need to determine the constant of proportionality; write c for this constant, meaning
</p>
<p>P.BjA/ D cP.B \A/:
</p>
<p>We have that
</p>
<p>P.BjA/C P.BcjA/ D cP.B \A/C cP.Bc \A/ D cP.A/ D 1;
</p>
<p>so that
</p>
<p>P.BjA/ D P.B \A/
P.A/
</p>
<p>:
</p>
<p>I find the &ldquo;size&rdquo; metaphor helpful here. We have that P.BjA/ measures the probability that an outcome is in B, given we
know it is in A. From the &ldquo;size&rdquo; perspective, P.BjA/ measures the &ldquo;size&rdquo; of .A\B/ relative to A. So our expression makes
sense, because the fraction of the event A that is also part of the event B is given by the &ldquo;size&rdquo; of the intersection divided by
</p>
<p>the &ldquo;size&rdquo; of A.
</p>
<p>Another, very useful, way to write the expression P.BjA/ D P.B \A/=P.A/ is:
</p>
<p>P.BjA/P.A/ D P.B \A/:
</p>
<p>Now, since B \A D A \ B, we must have that
</p>
<p>P.BjA/ D P.AjB/P.B/
P.A/
</p>
<p>Worked example 3.26 (Car Factories) There are two car factories, A and B. Each year, factory A produces 1000
</p>
<p>cars, of which 10 are lemons. Factory B produces 2 cars, each of which is a lemon. All cars go to a single lot, where
</p>
<p>they are thoroughly mixed up. I buy a car.
</p>
<p>&bull; What is the probability it is a lemon?
</p>
<p>&bull; What is the probability it came from factory B?
</p>
<p>&bull; The car is now revealed to be a lemon. What is the probability it came from factory B, conditioned on the fact it is
</p>
<p>a lemon?
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>68 3 Basic Ideas in Probability
</p>
<p>Solution
</p>
<p>&bull; Write the event the car is a lemon as L. There are 1002 cars, of which 12 are lemons. The probability that I select
</p>
<p>any given car is the same, so we have P.L/ D 12=1002.
&bull; Same argument yields P.B/ D 2=1002.
&bull; Write B for the event the car comes from factory B. I need P.BjL/ D P.L\B/=P.L/ D P.LjB/P.B/=P.L/. I have
</p>
<p>P.LjB/P.B/=P.L/ D .1 � 2=1002/=.12=1002/ D 1=6.
</p>
<p>Worked example 3.27 (Royal Flushes in Poker&mdash;1) You are playing a straightforward version of poker, where you
</p>
<p>are dealt five cards face down. A royal flush is a hand of AKQJ10 all in one suit. What is the probability that you are
</p>
<p>dealt a royal flush?
</p>
<p>Solution This is
number of hands that are royal flushes, ignoring card order
</p>
<p>total number of different five card hands, ignoring card order
:
</p>
<p>There are four hands that are royal flushes (one for each suit). Now the total number of five card hands is
</p>
<p>�
</p>
<p>52
</p>
<p>5
</p>
<p>�
</p>
<p>D 2;598;960
</p>
<p>so we have
4
</p>
<p>2;598;960
D 1
</p>
<p>649;740
:
</p>
<p>Worked example 3.28 (Royal Flushes in Poker&mdash;2) You are playing a straightforward version of poker, where you
</p>
<p>are dealt five cards face down. A royal flush is a hand of AKQJ10 all in one suit. The fifth card that you are dealt lands
</p>
<p>face up. What is the conditional probability of getting a royal flush, conditioned on the event that this card is the nine
</p>
<p>of spades?
</p>
<p>Solution No hand containing a nine of spades is a royal flush, so this is easily zero.
</p>
<p>Worked example 3.29 (Royal Flushes in Poker&mdash;3) You are playing a straightforward version of poker, where you
</p>
<p>are dealt five cards face down. A royal flush is a hand of AKQJ10 all in one suit. The fifth card that you are dealt lands
</p>
<p>face up. It is the Ace of spades. What now is the probability that your have been dealt a royal flush? (i.e. what is the
</p>
<p>conditional probability of getting a royal flush, conditioned on the event that one card is the Ace of spades)
</p>
<p>Solution Now consider the events
</p>
<p>A D you get a royal flush and the last card
is the ace of spades
</p>
<p>and
</p>
<p>BD the last card you get is the ace of spades;
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.4 Conditional Probability 69
</p>
<p>and the expression
</p>
<p>P.AjB/ D P.A \ B/
P.B/
</p>
<p>:
</p>
<p>Now P.B/ D 1
52
</p>
<p>. P.A \ B/ is given by
</p>
<p>number of five card royal flushes where card five is Ace of spades
</p>
<p>total number of different five card hands
:
</p>
<p>This is
4 � 3 � 2 � 1
</p>
<p>52 � 51 � 50 � 49 � 48
yielding
</p>
<p>P.AjB/ D 1
249;900
</p>
<p>:
</p>
<p>Notice the interesting part: seeing this card has really made a difference.
</p>
<p>Worked example 3.30 (Two Dice) We throw two fair six-sided dice. What is the conditional probability that the sum
</p>
<p>of spots on both dice is greater than six, conditioned on the event that the first die comes up five?
</p>
<p>Solution Write the event that the first die comes up 5 as F , and the event the sum is greater than six as S . There are
</p>
<p>five outcomes where the first die comes up 5 and the number is greater than 6, so P.F \ S/ D 5=36. Now
</p>
<p>P.SjF/DP.F \ S/=P.F/D.5=36/=.1=6/
</p>
<p>D5=6:
</p>
<p>Notice that A\B and A\Bc are disjoint sets, and that A D .A\B/[.A\Bc/. So, because P.A/ D P.A\B/CP.A\Bc/,
we have
</p>
<p>P.A/ D P.AjB/P.B/C P.AjBc/P.Bc/
</p>
<p>a tremendously important and useful fact. Another version of this fact is also very useful. Assume we have a collection
</p>
<p>of disjoint sets Bi. These sets must have the property that (a) Bi \ Bj D &iquest; for i &curren; j and (b) they cover A, meaning that
A \ .[iBi/ D A. Then, because P.A/ D
</p>
<p>P
</p>
<p>i P.A \ Bi/, so we have
</p>
<p>P.A/ D
X
</p>
<p>i
</p>
<p>P.AjBi/P.Bi/
</p>
<p>It is wise to be suspicious of your intuitions when thinking about problems in conditional probability. There is a really big
</p>
<p>difference between P.AjB/ and P.BjA/P.A/. Not respecting this difference can lead to serious problems (Sect. 3.4.4), and
seems to be easy to do. The division sign in the expression
</p>
<p>P.AjB/ D P.BjA/P.A/=P.B/
</p>
<p>can have alarming effects; as a result, most people have quite poor intuitions about conditional probability.
</p>
<p>Remember this: Here is one helpful example. If you buy a lottery ticket (L), the probability of winning (W) is small.
</p>
<p>So P.WjL/ may be very small. But P.LjW/ is 1&mdash;the winner is always someone who bought a ticket.</p>
<p/>
</div>
<div class="page"><p/>
<p>70 3 Basic Ideas in Probability
</p>
<p>Useful Facts 3.3 (Conditional Probability Formulas)
</p>
<p>You should remember the following formulas:
</p>
<p>&bull; P.BjA/ D P.AjB/P.B/
P.A/
</p>
<p>&bull; P.A/ D P.AjB/P.B/C P.AjBc/P.Bc/
&bull; Assume (a) Bi \ Bj D &iquest; for i &curren; j and (b) A \ .[iBi/ D A; then P.A/ D
</p>
<p>P
</p>
<p>i P.AjBi/P.Bi/
</p>
<p>3.4.2 Detecting Rare Events Is Hard
</p>
<p>It is hard to detect rare events. This nuisance is exposed by conditional probability reasoning. I have set these examples
</p>
<p>in a medical framework, but the problem occurs in pretty much any application domain. The issue comes up again and
</p>
<p>again in discussions of screening tests for diseases. Two recent important controversies have been around whether screening
</p>
<p>mammograms are a good idea, and whether screening for prostate cancer is a good idea. There is an important issue here.
</p>
<p>There are real harms that occur when a test falsely labels a patient as ill. First, the patient is distressed and frightened.
</p>
<p>Second, necessary medical interventions might be quite unpleasant and dangerous. This means it takes thought to tell whether
</p>
<p>screening does more good (by finding and helping sick people) than harm (by frightening and hurting well people).
</p>
<p>Worked example 3.31 (False Positives) You have a blood test for a rare disease that occurs by chance in 1 person
</p>
<p>in 100,000. If you have the disease, the test will report that you do with probability 0.95 (and that you do not with
</p>
<p>probability 0.05). If you do not have the disease, the test will report a false positive with probability 1e-3. If the test
</p>
<p>says you do have the disease, what is the probability it that you actually have the disease?
</p>
<p>Solution Write S for the event you are sick and R for the event the test reports you are sick. We need P.SjR/. We
have
</p>
<p>P.SjR/ D P.RjS/P.S/
P.R/
</p>
<p>D P.RjS/P.S/
P.RjS/P.S/C P.RjSc/P.Sc/
</p>
<p>D 0:95�1e � 5
0:95�1e � 5C 1e � 3�.1�1e�5/
</p>
<p>D 0:0094
</p>
<p>which should strike you as being a bit alarming. Notice what is happening here. There are two ways that the test could
</p>
<p>come back positive: either you have the disease, or the test is producing a false positive. But the disease is so rare that
</p>
<p>it&rsquo;s much more likely you have a false positive result than you have the disease.
</p>
<p>If you want to be strongly confident you have detected a very rare event, you need an extremely accurate detector. The
</p>
<p>next example shows how to compute how accurate the detector needs to be. The degree of accuracy required is often well
</p>
<p>beyond anything current technologies can reach. You should remember this example the next time someone tells you their
</p>
<p>test is, say, 90% accurate&mdash;such a test could also be completely useless.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.4 Conditional Probability 71
</p>
<p>Worked example 3.32 (False Positives �2) You want to design a blood test for a rare disease that occurs by chance
in 1 person in 100,000. If you have the disease, the test will report that you do with probability p (and that you do not
</p>
<p>with probability .1 � p/). If you do not have the disease, the test will report a false positive with probability q. You
want to choose the value of p so that if the test says you have the disease, there is at least a 50% probability that you
</p>
<p>do.
</p>
<p>Solution Write S for the event you are sick and R for the event the test reports you are sick. We need P.SjR/. We
have
</p>
<p>P.SjR/ D P.RjS/P.S/
P.R/
</p>
<p>D P.RjS/P.S/
P.RjS/P.S/C P.RjSc/P.Sc/
</p>
<p>D p � 1e � 5
p � 1e � 5C q � .1 � 1e � 5/
</p>
<p>� 0:5
</p>
<p>which means that p � 99999q which should strike you as being very alarming indeed, because p � 1 and q � 0. One
plausible pair of values is q D 1e � 5, p D 1 � 1e � 5. The test has to be spectacularly accurate to be of any use.
</p>
<p>3.4.3 Conditional Probability and Various Forms of Independence
</p>
<p>Two events are independent if
</p>
<p>P.A \ B/ D P.A/P.B/:
</p>
<p>In turn, if two events A and B are independent, then
</p>
<p>P.AjB/ D P.A/
</p>
<p>and
</p>
<p>P.BjA/ D P.B/:
</p>
<p>This means that knowing that A occurred tells you nothing about B&mdash;the probability that B will occur is the same whether
</p>
<p>you know that A occurred or not.
</p>
<p>Useful Facts 3.4 (Conditional Probability for Independent Events)
</p>
<p>If two events A and B are independent, then
</p>
<p>P.AjB/ D P.A/
</p>
<p>and
</p>
<p>P.BjA/ D P.B/:
</p>
<p>We usually do not have the information required to prove that events are independent. Instead, we use intuition (for
</p>
<p>example, two flips of the same coin are likely to be independent unless there is something very funny going on) or simply
</p>
<p>choose to apply models in which some variables are independent. There are weaker kinds of independence that are sometimes
</p>
<p>useful.</p>
<p/>
</div>
<div class="page"><p/>
<p>72 3 Basic Ideas in Probability
</p>
<p>Definition 3.5 (Pairwise Independence) Events A1 : : :An are pairwise independent if each pair is independent (i.e.
</p>
<p>A1 and A2 are independent, etc.).
</p>
<p>Worked example 3.33 (Pairwise Independence is a Weaker Property than Independence) This means that you
</p>
<p>can have events that are pairwise independent, but not independent. We draw three cards from a properly shuffled
</p>
<p>standard deck, with replacement and reshuffling (i.e., draw a card, make a note, return to deck, shuffle, draw the next,
</p>
<p>make a note, shuffle, draw the third). Let A be the event that &ldquo;card 1 and card 2 have the same suit&rdquo;; let B be the event
</p>
<p>that &ldquo;card 2 and card 3 have the same suit&rdquo;; let C be the event that &ldquo;card 1 and card 3 have the same suit&rdquo;. Show these
</p>
<p>events are pairwise independent, but not independent.
</p>
<p>Solution By counting, you can check that P.A/ D 1=4; P.B/ D 1=4; and P.A \ B/ D 1=16, so that these two are
independent. This argument works for other pairs, too. But P.C \A\ B/ D 1=16 which is not 1=43, so the events are
not independent; this is because the third event is logically implied by the first two.
</p>
<p>Definition 3.6 (Conditional Independence) Events A1 : : :An are conditionally independent conditioned on event
</p>
<p>B if
</p>
<p>P.A1 \ : : : \AnjB/ D P.A1jB/ : : :P.AnjB/
</p>
<p>Worked example 3.34 (Cards and Conditional Independence) We remove a red 10 and a red 6 from a standard
</p>
<p>deck of playing cards. We shuffle the remaining cards, and draw one card. Write A for the event that the card drawn is
</p>
<p>a 10, B for the event the card drawn is red, and C for the event that the card drawn is either a 10 or a 6. Show that A
</p>
<p>and B are not independent, but are conditionally independent conditioned on C.
</p>
<p>Solution We have P.A/ D 3=50, P.B/ D 24=50, P.A \ B/ D 1=50, so
</p>
<p>P.AjB/ D 1=50
24=50
</p>
<p>D 1
24
</p>
<p>&curren; P.A/
</p>
<p>so A and B are not independent. We have also that P.AjC/ D 1=2 and P.BjC/ D 2=6 D 1=3. Now
</p>
<p>P.A \ BjC/ D 1=6 D P.AjC/P.BjC/
</p>
<p>so A and B are conditionally independent conditioned on C.
</p>
<p>3.4.4 Warning Example: The Prosecutor&rsquo;s Fallacy
</p>
<p>Treat conditional probability with great care, because the topic confuses a lot of people, even people you might expect not
</p>
<p>to be confused. One important mistake is the prosecutor&rsquo;s fallacy, which has a name because it&rsquo;s such a common error. A
</p>
<p>prosecutor has evidence E against a suspect. Write I for the event that the suspect is innocent. Things get interesting when
</p>
<p>P.E jI/ is small. The prosecutor argues, incorrectly, that the suspect must be guilty, because P.E jI/ is so small. The argument
is incorrect because P.E jI/ is irrelevant to the issue. What matters is P.IjE/, which is the probability you are innocent, given
the evidence.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.4 Conditional Probability 73
</p>
<p>The distinction is very important, because P.IjE/ could be big even if P.E jI/ is small. In the expression
</p>
<p>P.IjE/ D P.E jI/P.I/
P.E/
</p>
<p>D P.E jI/P.I/
.P.E jI/P.I/C P.E jIc/.1 � P.I///
</p>
<p>notice that if P.I/ is large or if P.E jIc/ is much smaller than P.E jI/, then P.IjE/ could be close to one even if P.E jI/ is
small.
</p>
<p>This fallacy can be made even more mischievous. Assume the prosecutor incorrectly adopts a model that items of evidence
</p>
<p>are independent (or even just conditionally independent, conditioned on I) when they&rsquo;re not. Then this model could result
</p>
<p>in an estimate of P.E jI/ that is much smaller than it should be.
The prosecutor&rsquo;s fallacy has contributed to a variety of miscarriages of justice, with real, and shocking, consequences. One
</p>
<p>famous incident occurred in the UK, involving a mother, Sally Clark, who was convicted of murdering two of her children.
</p>
<p>Expert evidence by paediatrician Roy Meadow argued that the probability of both deaths resulting from Sudden Infant Death
</p>
<p>Syndrome was extremely small. Her first appeal cited, among other grounds, statistical error in the evidence. The appeals
</p>
<p>court rejected this appeal, calling the statistical point &ldquo;a sideshow&rdquo;. This prompted a great deal of controversy, both in the
</p>
<p>public press and various professional journals, including a letter from the then president of the Royal Statistical Society
</p>
<p>to the Lord Chancellor, pointing out that &ldquo;statistical evidence . . . (should be) . . . presented only by appropriately qualified
</p>
<p>statistical experts&rdquo;. A second appeal (on other grounds) followed, and was successful. The appellate judges specifically
</p>
<p>criticized the statistical evidence, although it was not a point of appeal. Clark never recovered from this horrific set of events
</p>
<p>and died in tragic circumstances shortly after the second appeal. Roy Meadow was then struck off the rolls for serious
</p>
<p>professional misconduct as an expert witness, a ruling he appealed successfully. You can find a more detailed account of
</p>
<p>this case, with pointers to important documents including the letter to the Lord Chancellor (which is well worth reading),
</p>
<p>at http://en.wikipedia.org/wiki/Roy_Meadow; there is further material on the prosecutors fallacy at http://en.wikipedia.org/
</p>
<p>wiki/Prosecutor%27s_fallacy.
</p>
<p>This story is not just about problems with the criminal law. There is a very significant difference between the meaning of
</p>
<p>P.E jI/ and the meaning of P.IjE/. When you use conditional probabilities, you need to be sure which one is important to
you.
</p>
<p>Remember this: You need to be careful reasoning about conditional probability and about independent events. These
</p>
<p>topics mislead intuition so regularly that some errors have names. Be very careful.
</p>
<p>3.4.5 Warning Example: TheMonty Hall Problem
</p>
<p>There are three doors. Behind one is a car. Behind each of the others is a goat. The car and goats are placed randomly and
</p>
<p>fairly, so that the probability that there is a car behind each door is the same. You will get the object that lies behind the door
</p>
<p>you choose at the end of the game. The goats are interchangeable, and, for reasons of your own, you would prefer the car to
</p>
<p>a goat. You select a door. The host then opens a door and shows you a goat. You must now choose to either keep your door,
</p>
<p>or switch to the other door. What should you do?
</p>
<p>This problem is known as the Monty Hall problem, and is a relatively simple exercise in conditional probability. But
</p>
<p>careless thinking about probability, particularly conditional probability, can cause wonderful confusion. The Monty Hall
</p>
<p>problem has been the subject of extensive, lively, and often quite inaccurate correspondence in various national periodicals&mdash;
</p>
<p>it seems to catch the attention, which is why I describe it in some detail.
</p>
<p>Notice that you cannot tell what to do using the information provided, by the following argument. Label the door you
</p>
<p>chose at the start of the game 1; the other doors 2 and 3. Write Ci for the event that the car lies behind door i. Write Gm for
</p>
<p>the event that a goat is revealed behind door m, where m is the number of the door where the goat was revealed (which could
</p>
<p>be 1, 2, or 3). You need to know P.C1jGm/. But
</p>
<p>P.C1jGm/ D
P.GmjC1/P.C1/
</p>
<p>P.GmjC1/P.C1/C P.GmjC2/P.C2/C P.GmjC3/P.C3/</p>
<p/>
<div class="annotation"><a href="http://en.wikipedia.org/wiki/Roy_Meadow">http://en.wikipedia.org/wiki/Roy_Meadow</a></div>
<div class="annotation"><a href="http://en.wikipedia.org/wiki/Prosecutor%27s_fallacy">http://en.wikipedia.org/wiki/Prosecutor%27s_fallacy</a></div>
<div class="annotation"><a href="http://en.wikipedia.org/wiki/Prosecutor%27s_fallacy">http://en.wikipedia.org/wiki/Prosecutor%27s_fallacy</a></div>
</div>
<div class="page"><p/>
<p>74 3 Basic Ideas in Probability
</p>
<p>and you do not know P.GmjC1/, P.GmjC2/, P.GmjC3/, because you don&rsquo;t know the rule by which the host chooses which
door to open to reveal a goat. Different rules lead to quite different analyses.
</p>
<p>Here are some possible rules for the host to show a goat:
</p>
<p>&bull; Rule 1: choose a door uniformly at random.
</p>
<p>&bull; Rule 2: choose from the doors with goats behind them that are not door 1 uniformly and at random.
</p>
<p>&bull; Rule 3: if the car is at 1, then choose 2; if at 2, choose 3; if at 3, choose 1.
</p>
<p>&bull; Rule 4: choose from the doors with goats behind them uniformly and at random.
</p>
<p>It should be straightforward for you to come up with other possible rules. We should keep track of the rules in the
</p>
<p>conditioning, so we write P.GmjC1; r1/ for the conditional probability that a goat was revealed behind door m when the
car is behind door 1, using rule 1 (and so on). This means we are interested in
</p>
<p>P.C1jGm; rn/ D
P.GmjC1; rn/P.C1/
</p>
<p>P.GmjC1; rn/P.C1/C P.GmjC2; rn/P.C2/C P.GmjC3; rn/P.C3/
:
</p>
<p>Notice that each of these rules is consistent with your observations&mdash;what you saw could have occurred under any of
</p>
<p>these rules. You have to know which rule the host uses to proceed. You should be aware that in many of the discussions of
</p>
<p>this problem, people assume without comment that the host uses rule 2, then proceed with this assumption.
</p>
<p>Worked example 3.35 (Monty Hall, Rule One) Assume the host uses rule one, and shows you a goat behind door
</p>
<p>two. What is P.C1jG2; r1/?
</p>
<p>Solution To work this out, we need to know P.G2jC1; r1/, P.G2jC2; r1/ and P.G2jC3; r1/. Now P.G2jC2; r1/ must be
zero, because the host could not reveal a goat behind door two if there was a car behind that door. Write O2 for the
</p>
<p>event the host chooses to open door two, and B2 for the event there happens to be a goat behind door two. These two
</p>
<p>events are independent&mdash;the host chose the door uniformly at random. We can compute
</p>
<p>P.G2jC1; r1/ D P.O2 \ B2jC1; r1/
</p>
<p>D P.O2jC1; r1/P.B2jC1; r1/
</p>
<p>D .1=3/.1/
</p>
<p>D 1=3
</p>
<p>where P.B2jC1; r1/ D 1 because we conditioned on the fact there was a car behind door one, so there is a goat behind
each other door. This argument establishes P.G2jC3; r1/ D 1=3, too. So P.C1jG2; r1/ D 1=2&mdash;the host showing you
the goat does not motivate you to do anything, because if P.C1jG2; r1/ D 1=2, then P.C3jG2; r1/ D 1=2, too&mdash;there&rsquo;s
nothing to choose between the two closed doors.
</p>
<p>Worked example 3.36 (Monty Hall, Rule Two) Assume the host uses rule two, and shows you a goat behind door
</p>
<p>two. What is P.C1jG2; r2/?
</p>
<p>Solution To work this out, we need to know P.G2jC1; r2/, P.G2jC2; r2/ and P.G2jC3; r2/. Now P.G2jC2; r2/ D 0,
because the host chooses from doors with goats behind them. P.G2jC1; r2/ D 1=2, because the host chooses uniformly
and at random from doors with goats behind them that are not door one; if the car is behind door one, there are
</p>
<p>two such doors. P.G2jC3; r2/ D 1, because there is only one door that (a) has a goat behind it and (b) isn&rsquo;t door
one. Plug these numbers into the formula, to get P.C1jG2; r2/ D 1=3. This is the source of all the fuss. It says
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.5 Extra Worked Examples 75
</p>
<p>that, if you know the host is using rule two, you should switch doors if the host shows you a goat behind door two
</p>
<p>(because P.C3jG2; r2/ D 2=3).
</p>
<p>Notice what is happening: if the car is behind door three, then the only choice of goat for the host is the goat behind two.
</p>
<p>So by choosing a door under rule two, the host is signalling some information to you, which you can use. By using rule three,
</p>
<p>the host can tell you precisely where the car is (exercises).
</p>
<p>Many people find the result of Example 3.36 counterintuitive. Each time I&rsquo;ve taught this material, I&rsquo;ve had lively
</p>
<p>discussions with students and with teaching assistants. Some people object to the extent of newspaper columns, letters
</p>
<p>to the editor, arguments on the internet, etc. One example that some people find helpful is an extreme case. Imagine that,
</p>
<p>instead of three doors, there are 1002. The host is using rule two, modified in the following way: open all but one of the doors
</p>
<p>that are not door one, choosing only doors that have goats behind them to open. You choose door one; the host opens 1000
</p>
<p>doors&mdash;say, all but doors one and 1002. What would you do?
</p>
<p>3.5 ExtraWorked Examples
</p>
<p>3.5.1 Outcomes and Probability
</p>
<p>Worked example 3.37 (Children) A co-uple decides to have children until either (a) they have both a boy and a girl
</p>
<p>or (b) they have three children. What is the set of outcomes?
</p>
<p>Solution Write B for boy, G for girl, and write them in birth order; we have fBG;GB;BBG;BBB;GGB;GGGg.
</p>
<p>Worked example 3.38 (Monty Hall (Sigh!) with Indistinguishable Goats) There are three boxes. There is a goat,
</p>
<p>a second goat, and a car. These are placed into the boxes at random. The goats are indistinguishable for our purposes;
</p>
<p>equivalently, we do not care about the difference between goats. What is the sample space?
</p>
<p>Solution Write G for goat, C for car. Then we have fCGG;GCG;GGCg.
</p>
<p>Worked example 3.39 (Monty Hall with Distinguishable Goats) There are three boxes. There is a goat, a second
</p>
<p>goat, and a car. These are placed into the boxes at random. One goat is male, the other female, and the distinction is
</p>
<p>important. What is the sample space?
</p>
<p>Solution Write M for male goat, F for female goat, C for car. Then we have fCFM;CMF;FCM;MCF;FMC;MFCg.
Notice how the number of outcomes has increased, because we now care about the distinction
</p>
<p>between goats.
</p>
<p>Worked example 3.40 (Find the Lady, with Even Probabilities) Recall the problem of Worked example 3.1.
</p>
<p>Assume that the card that is chosen is chosen fairly&mdash;that is, each card is chosen with the same probability. What
</p>
<p>is the probability of turning up a Queen?
</p>
<p>Solution There are three outcomes, and each is chosen with the same probability, so the probability is 1=3.</p>
<p/>
</div>
<div class="page"><p/>
<p>76 3 Basic Ideas in Probability
</p>
<p>Worked example 3.41 (Monty Hall, Indistinguishable Goats, Even Probabilities) Recall the problem of Worked
</p>
<p>example 3.39. Each outcome has the same probability. We choose to open the first box. With what probability will we
</p>
<p>find a goat (any goat)?
</p>
<p>Solution There are three outcomes, each has the same probability, and two give a goat, so 2=3
</p>
<p>Worked example 3.42 (Monty Hall, Yet Again) Each outcome has the same probability. We choose to open the first
</p>
<p>box. With what probability will we find the car?
</p>
<p>Solution There are three places the car could be, each has the same probability, so 1=3
</p>
<p>Worked example 3.43 (Monty Hall, with Distinct Goats, Again) Each outcome has the same probability. We
</p>
<p>choose to open the first box. With what probability will we find a female goat?
</p>
<p>Solution Using the reasoning of the previous example, but substituting &ldquo;female goat&rdquo; for &ldquo;car&rdquo;, 1=3. The point of this
</p>
<p>example is that the sample space matters. If you care about the gender of the goat, then it&rsquo;s important to keep track of
</p>
<p>it; if you don&rsquo;t, it&rsquo;s a good idea to omit it from the sample space.
</p>
<p>3.5.2 Events
</p>
<p>Worked example 3.44 (Drawing a Red Ten) I shuffle a standard pack of cards, and draw one card. What is the
</p>
<p>probability that it is a red ten?
</p>
<p>Solution There are 52 cards, and each is an outcome. Two of these outcomes are red tens; so we have 2=52 D 1=26.
</p>
<p>Worked example 3.45 (Birthdays in Succession) We stop three people at random, and ask the day of the week on
</p>
<p>which they are born. What is the probability that they are born on 3 days of the week in succession (for example, the
</p>
<p>first on Monday; the second on Tuesday; the third on Wednesday; or Saturday-Sunday-Monday; and so on).
</p>
<p>Solution We assume that births are equally common on each day of the week. The space of outcomes consists of triples
</p>
<p>of days, and each outcome has the same probability. The event is the set of triples of 3 days in succession (which has
</p>
<p>seven elements, one for each starting day). The space of outcomes has 73 elements in it, so the probability is
</p>
<p>Number of outcomes in the event
</p>
<p>Total number of outcomes
D 7
</p>
<p>73
</p>
<p>D 1
49
</p>
<p>:
</p>
<p>Worked example 3.46 (Shared Birth-days) We stop two people at random. What is the probability that they were
</p>
<p>born on the same day of the week?
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.5 Extra Worked Examples 77
</p>
<p>Solution The day the first person was born doesn&rsquo;t matter; the probability the second person was born on that day is
</p>
<p>1=7. Or you could count outcomes explicitly to get
</p>
<p>Number of outcomes in the event
</p>
<p>Total number of outcomes
D 7
</p>
<p>7 � 7
</p>
<p>D 1
7
:
</p>
<p>Worked example 3.47 (Children&mdash;3) This example is a version of example 1.12, p44, in Stirzaker, &ldquo;Elementary
</p>
<p>Probability&rdquo;. A couple decides to have children. They decide to have children until there is one of each gender, or
</p>
<p>until there are three, and then stop. Assume that each birth results in one child, and each gender is equally likely
</p>
<p>at each birth. Let Bi be the event that there are i boys, and C be the event there are more girls than boys. Compute
</p>
<p>P.B1/ and P.C/.
</p>
<p>Solution We could write the outcomes as fGB;BG;GGB;GGG;BBG;BBBg. Again, if we think about them like this,
we have no simple way to compute their probability; so we use the sample space from the previous example with the
</p>
<p>device of the fictitious births again. The important events are fGBb;GBgg; fBGb;BGgg; fGGBg; fGGGg; fBBGg; and
fBBBg. Like this, we get P.B1/ D 5=8 and P.C/ D 1=4.
</p>
<p>3.5.3 Independence
</p>
<p>Worked example 3.48 (Children) A couple decides to have two children. Genders are assigned to children at
</p>
<p>random, fairly, at birth and independently at each birth (our models have to abstract a little!). What is the probability
</p>
<p>of having a boy and then a girl?
</p>
<p>Solution
</p>
<p>P.first is boy \ second is girl/
</p>
<p>D .1=2/.1=2/
</p>
<p>D 1=4
</p>
<p>Worked example 3.49 (Programs) We sample the processes on a computer at random intervals. Write A for the
</p>
<p>event that program A is observed to be running in a sample, B for the event that program B is observed to be running
</p>
<p>in a sample, and N for the (Nasty) event that program C is observed to be behaving badly in a sample. We find
</p>
<p>P.A \ N / D 0:07; P.B \ N / D 0:05; P.A \ B \ N / D 0:04; and P.N / D 0:1. Are A and B conditionally
independent conditioned on N ?
</p>
<p>Solution This is a straightforward calculation. You should get P.AjN / D 0:7; P.BjN / D 0:5; P.A \ BjN / D 0:4;
and so P.A \ BjN / &curren; P.AjN / � P.BjN /, and they are not conditionally independent&mdash;there is some form of
interaction here.</p>
<p/>
</div>
<div class="page"><p/>
<p>78 3 Basic Ideas in Probability
</p>
<p>Worked example 3.50 (Independent Test Results) You have a blood test for a rare disease. We study the effect
</p>
<p>of repeated tests. Write S for the event that the patient is sick; DCi for the event that the i&rsquo;th repetition of the test
reports positive; and D�i for the event that the i&rsquo;th repetition of the test reports negative. The test has P.D
</p>
<p>CjS/ D 0:8
and P.D�jS/ D 0:8, and P.S/ D 1e � 5. This blood test has the property that, if you repeat the test, results
are conditionally independent conditioned on the true result, meaning that P.DC1 \ DC2 jS/ D P.DC1 jS/P.DC2 jS/.
Assume you test positive once; twice; and ten times. In each case, what is the posterior probability that you
</p>
<p>are sick?
</p>
<p>Solution I will work the case for two positive tests. We need P.SjDC1 \DC2 /. We have
</p>
<p>P.SjDC1 \DC2 / D
P.DC1 \DC2 jS/P.S/
</p>
<p>P.DC1 \DC2 /
</p>
<p>D P.D
C
1 \DC2 jS/P.S/
</p>
<p>P.DC1 \DC2 jS/P.S/CP.DC1 \DC2 jS/P.S/
</p>
<p>D 0:8 � 0:8 � 1e�5
0:8 � 0:8 � 1e�5C0:2 � 0:2 � .1�1e�5/
</p>
<p>� 1:6e � 4:
</p>
<p>You should check that once yields a posterior of approximately 4e-5, and ten times yields a posterior of approximately
</p>
<p>0.91. This isn&rsquo;t an argument for repeating tests; rather, you should regard it as an indication of how implausible the
</p>
<p>assumption of conditional independence of test results is.
</p>
<p>3.5.4 Conditional Probability
</p>
<p>Worked example 3.51 (Card Games) You have two decks of 52 standard playing cards. One has been shuffled
</p>
<p>properly. The other is organized as 26 black cards, then 26 red cards. You are shown one card from one deck, which
</p>
<p>turns out to be black; what is the posterior probability that you have a card from the shuffled deck?
</p>
<p>Solution Write S for the event the card comes from the shuffled deck, and B the event you are given a black card. We
</p>
<p>want
</p>
<p>P.SjB/ D P.BjS/P.S/
P.B/
</p>
<p>D P.BjS/P.S/
P.BjS/P.S/C P.BjS/P.S/
</p>
<p>D .1=2/ � .1=2/
.1=2/ � .1=2/C 1 � .1=2/
</p>
<p>D 1=3</p>
<p/>
</div>
<div class="page"><p/>
<p>3.5 Extra Worked Examples 79
</p>
<p>Worked example 3.52 (Finding a Common Disease) A disease occurs with probability 0.4 (i.e. it is present in 40%
</p>
<p>of the population). You have a test that detects the disease with probability 0.6, and produces a false positive with
</p>
<p>probability 0.1. What is the posterior probability you have the disease if the test comes back positive?
</p>
<p>Solution Write S for the event you are sick, and P for the event the test comes back positive. We want
</p>
<p>P.SjP/ D P.PjS/P.S/
P.P/
</p>
<p>D P.PjS/P.S/
P.PjS/P.S/C P.PjS/P.S/
</p>
<p>D 0:6 � 0:4
0:6 � 0:4C 0:1 � 0:6
</p>
<p>D 0:8
</p>
<p>Notice that if the disease is quite common, even a rather weak test is helpful.
</p>
<p>Worked example 3.53 (Which Disease Do You Have?) Disease A occurs with probability 0.1 (i.e. it is present in
</p>
<p>20% of the population), and disease B occurs with probability 0.2. It is not possible to have both diseases. You have a
</p>
<p>single test. This test reports positive with probability 0.8 for a patient with disease A, with probability 0.5 for a patient
</p>
<p>with disease B, and with probability 0.01 for a patient with no disease. What is the posterior probability you have either
</p>
<p>disease, or neither, if the test comes back positive?
</p>
<p>Solution We are interested in A (the event you have disease A), B (the event you have disease B), and W (the
</p>
<p>event you are well). Write P for the event the test comes back positive. We want P.AjP/, P.BjP/ and P.WjP/ D
1 � P.AjP/ � P.BjP/. We have
</p>
<p>P.AjP/ D P.PjA/P.A/
P.P/
</p>
<p>D P.PjA/P.A/
P.PjA/P.A/C P.PjB/P.B/C P.PjW/P.W/
</p>
<p>D 0:8 � 0:1
0:8 � 0:1C 0:5 � 0:2C 0:01 � 0:7
</p>
<p>� 0:43
</p>
<p>A similar calculation yields P.BjP// � 0:53 and P.WjP/ � 0:04. The low probability of a false positive means
that a positive result very likely comes from some disease. Even though the test isn&rsquo;t particularly sensitive to disease
</p>
<p>B, the fact B is twice as common as A means a positive result is somewhat more likely to have come from B than
</p>
<p>from A.
</p>
<p>Worked example 3.54 (Fraud or Psychic Powers?) You want to investigate the powers of a putative psychic. You
</p>
<p>blindfold this person, then flip a fair coin 10 times. Each time, the subject correctly tells you whether it came up heads
</p>
<p>or tails. There are three possible explanations: chance, fraud, or psychic powers. What is the posterior probability of
</p>
<p>each, conditioned on the evidence.
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>80 3 Basic Ideas in Probability
</p>
<p>Solution We have to do some modelling here. We must choose reasonable numbers for the prior of chance (C), fraud
</p>
<p>(F), and psychic powers (P/. There&rsquo;s little reliable evidence for psychic powers to date, so we can choose P.P/ D 2�
(where � is a very small number), and allocate the remaining probability evenly between C and F . Write E for the event
</p>
<p>the subject correctly calls 10 flips of a fair coin. We have P.E jC/ D .1=2/10. Assume that fraud and psychic powers
are efficient, so that P.E jF/ D P.E jP/ D 1. Then we have
</p>
<p>P.PjE/ D P.E jP/P.P/
P.E jP/P.P/C P.E jC/P.C/C P.E jF/P.F/
</p>
<p>D 2�
2� C .1=2/10 � .0:5 � �/C .0:5 � �/
</p>
<p>� 4�
</p>
<p>and P.F jE/ is rather close to 1. I&rsquo;d check how well the blindfold works; it&rsquo;s a traditional failure point in experiments
like this.
</p>
<p>3.6 You Should
</p>
<p>3.6.1 Remember These Definitions
</p>
<p>Sample space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
</p>
<p>Event . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
</p>
<p>Independent events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
</p>
<p>Conditional probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
</p>
<p>Pairwise independence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
</p>
<p>Conditional independence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
</p>
<p>3.6.2 Remember These Terms
</p>
<p>outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
</p>
<p>probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
</p>
<p>gambler&rsquo;s fallacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
</p>
<p>prosecutor&rsquo;s fallacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
</p>
<p>3.6.3 Remember and Use These Facts
</p>
<p>Basic properties of the probability events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
</p>
<p>Properties of the probability of events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
</p>
<p>Conditional probability formulas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
</p>
<p>Conditional probability for independent events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
</p>
<p>3.6.4 Remember These Points
</p>
<p>Sample spaces are required, and need not be finite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
</p>
<p>Probability is frequency. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
</p>
<p>You can compute the probability of events by counting outcomes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 81
</p>
<p>Warning: independence can mislead . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
</p>
<p>Conditional probability: lottery example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
</p>
<p>Intuitions about conditional probability are likely wrong; be careful . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
</p>
<p>3.6.5 Be Able to
</p>
<p>&bull; Write out a set of outcomes for an experiment.
</p>
<p>&bull; Construct an event space.
</p>
<p>&bull; Compute the probabilities of outcomes and events.
</p>
<p>&bull; Determine when events are independent.
</p>
<p>&bull; Compute the probabilities of outcomes by counting events, when the count is straightforward.
</p>
<p>&bull; Compute a conditional probability.
</p>
<p>Problems
</p>
<p>Outcomes
</p>
<p>3.1 You roll a four sided die. What is the space of outcomes?
</p>
<p>3.2 King Lear decides to allocate three provinces (1, 2, and 3) to his daughters (Goneril, Regan and Cordelia&mdash;read the
</p>
<p>book) at random. Each gets one province. What is the space of outcomes?
</p>
<p>3.3 You randomly wave a flyswatter at a fly. What is the space of outcomes?
</p>
<p>3.4 You read the book, so you know that King Lear had family problems. As a result, he decides to allocate two provinces
</p>
<p>to one daughter, one province to another daughter, and no provinces to the third. Because he&rsquo;s a bad problem solver, he does
</p>
<p>so at random. What is the space of outcomes?
</p>
<p>The Probability of an Outcome
</p>
<p>3.5 You roll a fair four sided die. What is the probability of getting a 3?
</p>
<p>3.6 You shuffle a standard deck of playing cards and draw a card. What is the probability that this is the king of hearts?
</p>
<p>3.7 A roulette wheel has 36 slots numbered 1&ndash;36. Of these slots, the odd numbers are red and the even numbers are black.
</p>
<p>There are two slots numbered zero, which are green. The croupier spins the wheel, and throws a ball onto the surface; the
</p>
<p>ball bounces around and ends up in a slot (which is chosen fairly and at random). What is the probability the ball ends up in
</p>
<p>slot 2?
</p>
<p>Events
</p>
<p>3.8 At a particular University, 1=2 of the students drink alcohol and 1=3 of the students smoke cigarettes.
</p>
<p>(a) What is the largest possible fraction of students who do neither?
</p>
<p>(b) It turns out that, in fact, 1=3 of the students do neither. What fraction of the students does both?</p>
<p/>
</div>
<div class="page"><p/>
<p>82 3 Basic Ideas in Probability
</p>
<p>Computing Probabilities by Counting Outcomes
</p>
<p>3.9 Assume each outcome in &#127; has the same probability. In this case, show
</p>
<p>P.E/ D Number of outcomes in E
Total number of outcomes in &#127;
</p>
<p>3.10 You roll a fair four sided die, and then a fair six sided die. You add the numbers on the two dice. What is the probability
</p>
<p>the result is even?
</p>
<p>3.11 You roll a fair 20 sided die. What is the probability of getting an even number?
</p>
<p>3.12 You roll a fair five sided die. What is the probability of getting an even number?
</p>
<p>3.13 I am indebted to Amin Sadeghi for this exercise. You must sort four balls into two buckets. There are two white, one
</p>
<p>red and one green ball.
</p>
<p>(a) For each ball, you choose a bucket independently and at random, with probability 1
2
. Show that the probability each
</p>
<p>bucket has a colored ball in it is 1
2
.
</p>
<p>(b) You now choose to sort these balls in such a way that each bucket has two balls in it. You can do so by generating a
</p>
<p>permutation of the balls uniformly and at random, then placing the first two balls in the first bucket and the second two
</p>
<p>balls in the second bucket. Show that there are 16 permutations where there is one colored ball in each bucket.
</p>
<p>(c) Use the results of the previous step to show that, using the sorting procedure of that step, the probability of having a
</p>
<p>colored ball in each bucket is 2
3
.
</p>
<p>(d) Why do the two sorting procedures give such different outcomes?
</p>
<p>The Probability of Events
</p>
<p>3.14 You flip a fair coin three times. What is the probability of seeing HTH? (i.e. Heads, then Tails, then Heads)
</p>
<p>3.15 You shuffle a standard deck of playing cards and draw a card.
</p>
<p>(a) What is the probability that this is a king?
</p>
<p>(b) What is the probability that this is a heart?
</p>
<p>(c) What is the probability that this is a red card (i.e. a heart or a diamond)?
</p>
<p>3.16 A roulette wheel has 36 slots numbered 1&ndash;36. Of these slots, the odd numbers are red and the even numbers are black.
</p>
<p>There are two slots numbered zero, which are green. The croupier spins the wheel, and throws a ball onto the surface; the
</p>
<p>ball bounces around and ends up in a slot (which is chosen fairly and at random).
</p>
<p>(a) What is the probability the ball ends up in a green slot?
</p>
<p>(b) What is the probability the ball ends up in a red slot with an even number?
</p>
<p>(c) What is the probability the ball ends up in a red slot with a number divisible by 7?
</p>
<p>3.17 You flip a fair coin three times. What is the probability of seeing two heads and one tail?
</p>
<p>3.18 You remove the king of hearts from a standard deck of cards, then shuffle it and draw a card.
</p>
<p>(a) What is the probability this card is a king?
</p>
<p>(b) What is the probability this card is a heart?
</p>
<p>3.19 You shuffle a standard deck of cards, then draw four cards.</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 83
</p>
<p>(a) What is the probability all four are the same suit?
</p>
<p>(b) What is the probability all four are red?
</p>
<p>(c) What is the probability each has a different suit?
</p>
<p>3.20 You roll three fair six-sided dice and add the numbers. What is the probability the result is even?
</p>
<p>3.21 You roll three fair six-sided dice and add the numbers. What is the probability the result is even and not divisible by
</p>
<p>20?
</p>
<p>3.22 You shuffle a standard deck of cards, then draw seven cards. What is the probability that you see no aces?
</p>
<p>3.23 Show that P.A � .B [ C// D P.A/ � P.A \ B/ � P.A \ C/C P.A \ B \ C/.
</p>
<p>3.24 You draw a single card from a standard 52 card deck. What is the probability that it is red?
</p>
<p>3.25 You remove all heart cards from a standard 52 card deck, then draw a single card from the result.
</p>
<p>(a) What is the probability that the card you draw is a red king?
</p>
<p>(b) What is the probability that the card you draw is a spade?
</p>
<p>Permutations and Combinations
</p>
<p>3.26 You shuffle a standard deck of playing cards, and deal a hand of 10 cards. With what probability does this hand have
</p>
<p>five red cards?
</p>
<p>3.27 Magic the Gathering is a popular card game. Cards can be land cards, or other cards. We consider a game with two
</p>
<p>players. Each player has a deck of 40 cards. Each player shuffles their deck, then deals seven cards, called their hand.
</p>
<p>(a) Assume that player one has 10 land cards in their deck and player two has 20. With what probability will each player
</p>
<p>have four lands in their hand?
</p>
<p>(b) Assume that player one has 10 land cards in their deck and player two has 20. With what probability will player one have
</p>
<p>two lands and player two have three lands in hand?
</p>
<p>(c) Assume that player one has 10 land cards in their deck and player two has 20. With what probability will player two
</p>
<p>have more lands in hand than player one?
</p>
<p>3.28 The previous exercise divided Magic the Gathering cards into lands vs. other. We now recognize four kinds of cards:
</p>
<p>land, spell, creature and artifact. We consider a game with two players. Each player has a deck of 40 cards. Each player
</p>
<p>shuffles their deck, then deals seven cards, called their hand.
</p>
<p>(a) Assume that player one has 10 land cards, 10 spell cards, 10 creature cards and 10 artifact cards in their deck. With what
</p>
<p>probability will player one have at least one of each kind of card in hand?
</p>
<p>(b) Assume that player two has 20 land cards, 5 spell cards, 7 creature cards and 8 artifact cards in their deck. With what
</p>
<p>probability will player two have at least one of each kind of card in hand?
</p>
<p>(c) Assume that player one has 10 land cards, 10 spell cards, 10 creature cards and 10 artifact cards in their deck;. and player
</p>
<p>two has 20 land cards, 5 spell cards, 7 creature cards and 8 artifact cards in their deck. With what probability will at least
</p>
<p>one of the players have at least one of each kind card in hand?
</p>
<p>3.29 You take a standard deck of 52 playing cards and shuffle it. Compute the probability that, in the shuffled deck, there is
</p>
<p>at least one pair of cards following one another in increasing order (i.e. a 2 followed by a 3, or a 3 followed by a 4, etc.). This
</p>
<p>isn&rsquo;t particularly easy, but the probability is higher than most people realize; you can surprise your friends and make money
</p>
<p>with this information.</p>
<p/>
</div>
<div class="page"><p/>
<p>84 3 Basic Ideas in Probability
</p>
<p>Independence
</p>
<p>3.30 Event A has P.A/ D 0:5. Event B has P.B/ D 0:2. We also know that P.A [ B/ D 0:65. Are A and B independent?
Why?
</p>
<p>3.31 Event A has P.A/ D 0:5. Event B has P.B/ D 0:5. These events are independent. What is P.A [ B/?
</p>
<p>3.32 You take a standard deck of cards, shuffle it, and remove both red kings. You then draw a card.
</p>
<p>(a) Is the event fcard is redg independent of the event fcard is a queeng?
(b) Is the event fcard is blackg independent of the event fcard is a kingg?
</p>
<p>3.33 You flip a fair coin seven times. What is the probability that you see three H&rsquo;s and two T&rsquo;s?
</p>
<p>3.34 An airline sells T tickets for a flight with S seats, where T &gt; S. Passengers turn up for the flight independently, and the
</p>
<p>probability that a passenger with a ticket will turn up for a flight is pt. The pilot is eccentric, and will fly only if precisely E
</p>
<p>passengers turn up, where E &lt; S. Write an expression for the probability the pilot will fly.
</p>
<p>Conditional Probability
</p>
<p>3.35 You roll two fair six-sided dice. What is the conditional probability the sum of numbers is greater than three,
</p>
<p>conditioned on the first die coming up even.
</p>
<p>3.36 I claim event B has probability �, that P.AjB/ D 1, and that P.BjA/ D �=2. Can such a probability distribution exist?
</p>
<p>3.37 You take a standard deck of cards, shuffle it, and remove one card. You then draw a card.
</p>
<p>(a) What is the conditional probability that the card you draw is a red king, conditioned on the removed card being a king?
</p>
<p>(b) What is the conditional probability that the card you draw is a red king, conditioned on the removed card being a red
</p>
<p>king?
</p>
<p>(c) What is the conditional probability that the card you draw is a red king, conditioned on the removed card being a black
</p>
<p>ace?
</p>
<p>3.38 A royal flush is a hand of five cards, consisting of Ace, King, Queen, Jack and 10 of a single suit. Poker players like
</p>
<p>this hand, but don&rsquo;t see it all that often.
</p>
<p>(a) You draw three cards from a standard deck of playing cards. These are Ace, King, Queen of hearts. What is the probability
</p>
<p>that the next two cards you draw will result in a getting a royal flush? (this is the conditional probability of getting a
</p>
<p>royal flush, conditioned on the first three cards being AKQ of hearts).
</p>
<p>3.39 You roll a fair five-sided die, and a fair six-sided die.
</p>
<p>(a) What is the probability that the sum of numbers is even?
</p>
<p>(b) What is the conditional probability that the sum of numbers is even, conditioned on the six-sided die producing an odd
</p>
<p>number?
</p>
<p>3.40 You take a standard deck of playing cards, shuffle it, and remove 13 cards without looking at them. You then shuffle
</p>
<p>the resulting deck of 39 cards, and draw three cards. Each of these three cards is red. What is the conditional probability that
</p>
<p>every card you removed is black?</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 85
</p>
<p>3.41 Magic the Gathering is a popular card game. Cards can be land cards, or other cards. We will consider a deck of 40
</p>
<p>cards, containing 10 land cards and 30 other cards. A player shuffles that deck, and draws seven cards but does not look at
</p>
<p>them. The player then chooses one of these cards at random; it is a land.
</p>
<p>(a) What is the conditional probability that the original hand of seven cards is all lands?
</p>
<p>(b) What is the conditional probability that the original hand of seven cards contains only one land?
</p>
<p>3.42 Magic the Gathering is a popular card game. Cards can be land cards, or other cards. We will consider a deck of 40
</p>
<p>cards, containing 10 land cards and 30 other cards. A player shuffles that deck, and draws seven cards but does not look at
</p>
<p>them. The player then chooses three of these cards at random; each of these three is a land.
</p>
<p>(a) What is the conditional probability that the original hand of seven cards is all lands?
</p>
<p>(b) What is the conditional probability that the original hand of seven cards contains only three lands?
</p>
<p>3.43 You take a standard deck of playing cards, and remove one card at random. You then draw a single card. Write S for
</p>
<p>the event that the card you remove is a six. Write N for the event that the card you remove is not a six. Write R for the event
</p>
<p>that the card you remove is red. Write B for the event the card you remove is black.
</p>
<p>(a) Write A for the event you draw a 6. What is P.AjS/?
(b) Write A for the event you draw a 6. What is P.AjN /?
(c) Write A for the event you draw a 6. What is P.A/?
</p>
<p>(d) Write D for the event you draw a red six. Are D and A independent? why?
</p>
<p>(e) Write D for the event you draw a red six. What is P.D/?
</p>
<p>3.44 A student takes a multiple choice test. Each question has N answers. If the student knows the answer to a question,
</p>
<p>the student gives the right answer, and otherwise guesses uniformly and at random. The student knows the answer to 70% of
</p>
<p>the questions. Write K for the event a student knows the answer to a question and R for the event the student answers the
</p>
<p>question correctly.
</p>
<p>(a) What is P.K/?
</p>
<p>(b) What is P.RjK/?
(c) What is P.KjR/, as a function of N?
(d) What values of N will ensure that P.KjR/ &gt; 99%?
</p>
<p>3.45 Write the event a patient has an illness as I. Write the event that a test reports the patient has the illness as R. Assume
</p>
<p>that P.RjIc/ D 0:1. We have that P.IjR/ D 0:5.
</p>
<p>(a) Compute P.I/ as a function of P.RjI/, and plot it.
(b) What is the smallest possible value of P.I/? For what value of P.RjI/ does this occur?
(c) Now plot the smallest possible value of P.I/ for different values of P.RjIc/, assuming that P.RjI/ D 0:99.
</p>
<p>TheMonty Hall Problem
</p>
<p>3.46 Monty Hall, Rule 3: If the host uses rule 3, then what is P.C1jG2; r3/? Do this by computing conditional probabilities.
</p>
<p>3.47 Monty Hall, Rule 4: If the host uses rule 4, and shows you a goat behind door 2, what is P.C1jG2; r4/? Do this by
computing conditional probabilities.</p>
<p/>
</div>
<div class="page"><p/>
<p>4RandomVariables and Expectations
</p>
<p>We have machinery to describe experiments with random outcomes, but we mostly care about numbers that are random. It
</p>
<p>is straightforward to link a number to the outcome of an experiment. The result is a random variable, a useful new idea.
</p>
<p>Random variables turn up in all sorts of places. For example, the amount of money you win or lose on a bet is a random
</p>
<p>variable. Now if you take the same bet repeatedly, you could wonder how much money will change hands in total, per bet.
</p>
<p>This yields a new and useful idea, the expected value of a random variable.
</p>
<p>Expected values have strong properties. When one knows some expected values, you can bound various probabilities.
</p>
<p>This phenomenon parallels the property of data that we saw earlier&mdash;you don&rsquo;t find a large fraction of the dataset many
</p>
<p>standard deviations away from the mean. Particularly important to computer scientists (and gamblers!) is the weak law of
</p>
<p>large numbers. This law says, loosely, that the value, per bet, of repeating a bet many times will almost certainly be the
</p>
<p>expected value. Among other things, this law legitimizes estimating expectations and probabilities that are hard to calculate
</p>
<p>by using a simulation. This turns out to be really useful, because simulations are often easy programs to write and can often
</p>
<p>replace rather nasty calculations.
</p>
<p>4.1 RandomVariables
</p>
<p>Quite commonly, we would like to deal with numbers that are random. We can do so by linking numbers to the outcome of
</p>
<p>an experiment. We define a random variable:
</p>
<p>Definition 4.1 (Discrete Random Variable) Given a sample space &#127;, a set of events F , a probability function P,
</p>
<p>and a countable set of real numbers D, a discrete random variable is a function with domain &#127; and range D.
</p>
<p>This means that for any outcome ! there is a number X.!/. P will play an important role, but first we give some examples.
</p>
<p>Example 4.1 (Numbers from Coins) We flip a coin. Whenever the coin comes up heads, we report 1; when it comes
</p>
<p>up tails, we report 0. This is a random variable.
</p>
<p>Example 4.2 (Numbers from Coins II) We flip a coin 32 times. We record a 1 when it comes up heads, and when it
</p>
<p>comes up tails, we record a 0. This produces a 32 bit random number, which is a random variable.
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_4
</p>
<p>87</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_4">https://doi.org/10.1007/978-3-319-64410-3_4</a></div>
</div>
<div class="page"><p/>
<p>88 4 Random Variables and Expectations
</p>
<p>Example 4.3 (The Number of Pairs in a Poker Hand) We draw a hand of five cards. The number of pairs in this hand
</p>
<p>is a random variable, which takes the values 0; 1; 2 (depending on which hand we draw)
</p>
<p>A function that takes a discrete random variable to a set of numbers is also a discrete random variable.
</p>
<p>Example 4.4 (Parity of Coin Flips) We flip a coin 32 times. We record a 1 when it comes up heads, and when it comes
</p>
<p>up tails, we record a 0. This produces a 32 bit random number, which is a random variable. The parity of this number
</p>
<p>is also a random variable.
</p>
<p>Associated with any value x of the random variable X are a series of events. The most important is the set of outcomes !
</p>
<p>such that X.!/ D x, which we can write f! W X.!/ D xg; it is usual to simplify to fX D xg, and we will do so. The probability
that a random variable X takes the value x is given by P.f! W X.!/ D xg/, which is more usually written P.fX D xg/. This is
sometimes written as P.X D x/, and rather often written as P.x/.
</p>
<p>We could also be interested in the set of outcomes ! such that X.!/ � x (i.e. in f! W X.!/ � xg), which we will write
fX � xg; The probability that X takes a value less than or equal to x is given by P.f! W X.!/ � xg/, which is more usually
written P.fX � xg/. Similarly, we could be interested in ! such that fX.!/ &gt; xg, and so on.
</p>
<p>Definition 4.2 (Probability Distribution of a Discrete Random Variable) The probability distribution of a discrete
</p>
<p>random variable is the set of numbers P.fX D xg/ for each value x that X can take. The distribution takes the value 0
at all other numbers. Notice that the distribution is non-negative. The probability distribution is sometimes known as
</p>
<p>the probability mass function.
</p>
<p>Definition 4.3 (Cumulative Distribution of a Discrete Random Variable) The cumulative distribution of a discrete
</p>
<p>random variable is the set of numbers P.fX &lt;D xg/ for each value x that X can take. Notice that this is a non-decreasing
function of x.
</p>
<p>Worked example 4.1 (Numbers from Coins III) We flip a biased coin 2 times. The flips are independent. The coin
</p>
<p>has P.H/ D p, P.T/ D 1 � p. We record a 1 when it comes up heads, and when it comes up tails, we record a 0.
This produces a 2 bit random number, which is a random variable taking the values 0, 1, 2, 3. What is the probability
</p>
<p>distribution and cumulative distribution of this random variable?
</p>
<p>Solution Probability distribution: P.0/ D .1 � p/2; P.1/ D .1 � p/p; P.2/ D p.1 � p/; P.3/ D p2. Cumulative
distribution: f .0/ D .1 � p/2; f .1/ D .1 � p/; f .2/ D p.1 � p/C .1 � p/ D .1 � p2/; f .3/ D 1.
</p>
<p>Worked example 4.2 (Betting on Coins) One way to get a random variable is to think about the reward for a bet. We
</p>
<p>agree to play the following game. I flip a coin. The coin has P.H/ D p, P.T/ D 1� p. If the coin comes up heads, you
pay me q; if the coin comes up tails, I pay you r. The number of dollars that change hands is a random variable. What
</p>
<p>is its probability distribution?
</p>
<p>Solution We see this problem from my perspective. If the coin comes up heads, I get q; if it comes up tails, I get �r.
So we have P.X D q/ D p and P.X D �r/ D .1 � p/, and all other probabilities are zero.</p>
<p/>
</div>
<div class="page"><p/>
<p>4.1 Random Variables 89
</p>
<p>4.1.1 Joint and Conditional Probability for RandomVariables
</p>
<p>All the concepts of probability that we described for events carry over to random variables. This is as it should be, because
</p>
<p>random variables are really just a way of getting numbers out of events. However, terminology and notation change a bit.
</p>
<p>Definition 4.4 (Joint Probability Distribution of Two Discrete Random Variables) Assume we have two random
</p>
<p>variables X and Y . The probability that X takes the value x and Y takes the value y could be written as P.fX D xg \
fY D yg/. It is more usual to write it as
</p>
<p>P.x; y/:
</p>
<p>This is referred to as the joint probability distribution of the two random variables (or, quite commonly, the joint).
</p>
<p>You can think of this as a table of probabilities, one for each possible pair of x and y values.
</p>
<p>We will simplify notation further. Usually, we are interested in random variables, rather than potentially arbitrary outcomes
</p>
<p>or sets of outcomes. We will write P.X/ to denote the probability distribution of a random variable, and P.x/ or P.X D x/ to
denote the probability that random variable takes a particular value. This means that, for example, the rule we could write as
</p>
<p>P.fX D xg j fY D yg/P.fY D yg/
</p>
<p>D P.fX D xg \ fY D yg/
</p>
<p>will be written as
P.xjy/P.y/ D P.x; y/:
</p>
<p>Recall the rule from Sect. 3.4.1:
</p>
<p>P.AjB/ D P.BjA/P.A/
P.B/
</p>
<p>:
</p>
<p>This rule can be rewritten in our notation for random variables. This is the most familiar form of Bayes&rsquo; rule, which is
</p>
<p>important enough to appear in its own box.
</p>
<p>Definition 4.5 (Bayes&rsquo; Rule)
</p>
<p>P.xjy/ D P.yjx/P.x/
P.y/
</p>
<p>Random variables have another useful property. If x0 &curren; x1, then the event fX D x0g must be disjoint from the event
fX D x1g. This means that
</p>
<p>X
</p>
<p>x
</p>
<p>P.x/ D 1
</p>
<p>and that, for any y,
X
</p>
<p>x
</p>
<p>P.xjy/ D 1
</p>
<p>(if you&rsquo;re uncertain on either of these points, check them by writing them out in the language of events).
</p>
<p>Now assume we have the joint probability distribution of two random variables, X and Y . Recall that we write P.fX D xg\
fY D yg/ as P.x; y/. Now consider the sets of outcomes fY D yg for each different value of y. These sets must be disjoint,
because y cannot take two values at the same time. Furthermore, each element of the set of outcomes fX D xg must lie in
one of the sets fY D yg. So we have
</p>
<p>X
</p>
<p>y
</p>
<p>P.fX D xg \ fY D yg/ D P.fX D xg/</p>
<p/>
</div>
<div class="page"><p/>
<p>90 4 Random Variables and Expectations
</p>
<p>Definition 4.6 (Marginal Probability of a Random Variable) Write P.x; y/ for the joint probability distribution of
</p>
<p>two random variables X and Y . Then
</p>
<p>P.x/ D
X
</p>
<p>y
</p>
<p>P.x; y/ D
X
</p>
<p>y
</p>
<p>P.fX D xg \ fY D yg/ D P.fX D xg/
</p>
<p>is referred to as the marginal probability distribution of X.
</p>
<p>Definition 4.7 (Independent Random Variables) The random variables X and Y are independent if the events
</p>
<p>fX D xg and fY D yg are independent for all values x and y. This means that
</p>
<p>P.fX D xg \ fY D yg/ D P.fX D xg/P.fY D yg/;
</p>
<p>which we can rewrite as
</p>
<p>P.x; y/ D P.x/P.y/
</p>
<p>Worked example 4.3 (Sums and Differences of Dice) You throw two dice. The number of spots on the first die is
</p>
<p>a random variable (call it X); so is the number of spots on the second die (Y). X and Y are independent. Now define
</p>
<p>S D X C Y and D D X � Y . What is the probability distribution of S and of D?
</p>
<p>Solution S can have values in the range 2; : : : ; 12. There is only one way to get a S D 2; two
ways to get S D 3; and so on. Using the methods of Chap. 3 for each case, the probabilities for
Œ2; 3; 4; 5; 6; 7; 8; 9; 10; 11; 12&#141; are Œ1; 2; 3; 4; 5; 6; 5; 4; 3; 2; 1&#141;=36. Similarly, D can have values in the range �5; : : : ; 5.
Again, using the methods of chapter Worked example 14.13, the probabilities for Œ�5;�4;�3;�2;�1; 0; 1; 2; 3; 4; 5&#141;
are Œ1; 2; 3; 4; 5; 6; 5; 4; 3; 2; 1&#141;=36.
</p>
<p>Worked example 4.4 (Sums and Differences of Dice, II) Using the terminology of Example 4.3, what is the joint
</p>
<p>probability distribution of S and D?
</p>
<p>Solution This is more interesting to display, because it&rsquo;s an 11 � 11 table. Each entry of the table represents a pair of
S, D values. Many pairs can&rsquo;t occur (for example, for S D 2, D can only be zero; if S is even, then D must be even; and
so on). You can work out the table by checking each case; it&rsquo;s in Table 4.1.
</p>
<p>Worked example 4.5 (Sums and Differences of Dice, III) Using the terminology of Example 4.3, are X and Y
</p>
<p>independent? are S and D independent?
</p>
<p>Solution X and Y are clearly independent. But S and D are not. There are several ways to see this. One way is to notice
</p>
<p>that, if you know S D 2, then you know the value of D precisely; but if you know S D 3, D could be either 1 or �1.
This means that P.SjD/ depends on D, so they&rsquo;re not independent. Another way is to notice that the rank of the table,
as a matrix, is 6, which means that it can&rsquo;t be the outer product of two vectors.</p>
<p/>
</div>
<div class="page"><p/>
<p>4.1 Random Variables 91
</p>
<p>Table 4.1 A table of the joint
probability distribution of S
(vertical axis; scale 2; : : : ; 12)
and D (horizontal axis; scale
�5; : : : ; 5) from Example 4.4
</p>
<p>1
</p>
<p>36
�
</p>
<p>0
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>@
</p>
<p>0 0 0 0 0 1 0 0 0 0 0
</p>
<p>0 0 0 0 1 0 1 0 0 0 0
</p>
<p>0 0 0 1 0 1 0 1 0 0 0
</p>
<p>0 0 1 0 1 0 1 0 1 0 0
</p>
<p>0 1 0 1 0 1 0 1 0 1 0
</p>
<p>1 0 1 0 1 0 1 0 1 0 1
</p>
<p>0 1 0 1 0 1 0 1 0 1 0
</p>
<p>0 0 1 0 1 0 1 0 1 0 0
</p>
<p>0 0 0 1 0 1 0 1 0 0 0
</p>
<p>0 0 0 0 1 0 1 0 0 0 0
</p>
<p>0 0 0 0 0 1 0 0 0 0 0
</p>
<p>1
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>A
</p>
<p>Worked example 4.6 (Sums and Differences of Dice, IV) Using the terminology of Example 4.3, what is P.SjD D
0/? what is P.DjS D 11/?
</p>
<p>Solution You could work it out either of these from the table, or by first principles. If D D 0, S can have values
2; 4; 6; 8; 10; 12, and each value has conditional probability 1=6. If S D 11, D can have values 1, or �1, and each value
has conditional probability 1=2.
</p>
<p>4.1.2 Just a Little Continuous Probability
</p>
<p>Our random variables take values from a discrete set of numbers D. This makes the underlying machinery somewhat simpler
</p>
<p>to describe, and is often, but not always, enough for model building. Some phenomena are more naturally modelled as being
</p>
<p>continuous &mdash; for example, human height; human weight; the mass of a distant star; and so on. Giving a complete formal
</p>
<p>description of probability on a continuous space is surprisingly tricky, and would involve us in issues that do not arise much
</p>
<p>in practice.
</p>
<p>These issues are caused by two interrelated facts: real numbers have infinite precision; and you can&rsquo;t count real numbers.
</p>
<p>A continuous random variable is still a random variable, and comes with all the stuff that a random variable comes with.
</p>
<p>We will not speculate on what the underlying sample space is, nor on the underlying events. This can all be sorted out, but
</p>
<p>requires moderately heavy lifting that isn&rsquo;t particularly illuminating for us. The most interesting thing for us is specifying
</p>
<p>the probability distribution. Rather than talk about the probability that a real number takes a particular value (which we can&rsquo;t
</p>
<p>really do satisfactorily most of the time), we will instead talk about the probability that it lies in some interval. So we can
</p>
<p>specify a probability distribution for a continuous random variable by giving a set of (very small) intervals, and for each
</p>
<p>interval providing the probability that the random variable lies in this interval.
</p>
<p>The easiest way to do this is to supply a probability density function. Let p.x/ be a probability density function (often
</p>
<p>called a pdf or density) for a continuous random variable X. We interpret this function by thinking in terms of small intervals.
</p>
<p>Assume that dx is an infinitesimally small interval. Then
</p>
<p>p.x/dx D P.fevent that X takes a value in
</p>
<p>the range Œx; xC dx&#141;g/:
</p>
<p>Important properties of probability density functions follow from this definition.</p>
<p/>
</div>
<div class="page"><p/>
<p>92 4 Random Variables and Expectations
</p>
<p>Useful Facts 4.1 (Properties of Probability Density Functions)
</p>
<p>&bull; Probability density functions are non-negative. This follows from the definition; a negative value at some u would
</p>
<p>imply that P.fx 2 Œu; uC du&#141;g/ was negative, and this cannot occur.
&bull; For a &lt; b
</p>
<p>P.fX takes a value in the range Œa; b&#141;g/ D
Z b
</p>
<p>a
</p>
<p>p.x/dx:
</p>
<p>which we obtain by summing p.x/dx over all the infinitesimal intervals between a and b.
</p>
<p>&bull; We must have that
Z 1
</p>
<p>�1
p.x/dx D 1:
</p>
<p>This is because
</p>
<p>P.fX takes a value in the range Œ�1;1&#141;g/ D 1 D
Z 1
</p>
<p>�1
p.x/dx
</p>
<p>The property that
Z 1
</p>
<p>�1
p.x/dx D 1
</p>
<p>is useful, because when we are trying to determine a probability density function, we can ignore a constant factor. So if g.x/
</p>
<p>is a non-negative function that is proportional to the probability density function (often pdf) we are interested in, we can
</p>
<p>recover the pdf by computing
</p>
<p>p.x/ D 1R1
�1 g.x/dx
</p>
<p>g.x/:
</p>
<p>This procedure is sometimes known as normalizing, and
R1
�1 g.x/dx is the normalizing constant.
</p>
<p>One good way to think about pdf&rsquo;s is as the limit of a histogram. Imagine you collect an arbitrarily large dataset of data
</p>
<p>items, each of which is independent. You build a histogram of that dataset, using arbitrarily narrow boxes. You scale the
</p>
<p>histogram so that the sum of the box areas is one. The result is a probability density function.
</p>
<p>The pdf doesn&rsquo;t represent the probability that a random variable takes a value. Instead, you should think of p.x/ as being
</p>
<p>the limit of a ratio (which is why it&rsquo;s called a density):
</p>
<p>the probability that the random variable will lie in a small interval centered on x
</p>
<p>the length of the small interval centered on x
</p>
<p>Notice that, while a pdf has to be non-negative, and it has to integrate to 1, it does not have to be smaller than one. A ratio
</p>
<p>like this could be a lot larger than one, as long as it isn&rsquo;t larger than one for too many x (because the integral must be one).
</p>
<p>In fact, probability density functions can be strange functions (exercises).
</p>
<p>Worked example 4.7 (A Probability Density Function that is Larger than One) Assume we have a physical
</p>
<p>system that can produce random numbers. It produces numbers in the range 0 to �, where � &gt; 0. Each number has
</p>
<p>the same probability of appearing. No number larger than � or smaller than 0 can ever appear. What is the probability
</p>
<p>density function?
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>4.2 Expectations and Expected Values 93
</p>
<p>Solution Write p.x/ for the probability density function. We must have that p.x/ D 0 for x &lt; 0 and p.x/ D 0 for
x &gt; �. We must have that p.x/ is constant between 0 and � and that
</p>
<p>Z 1
</p>
<p>�1
p.x/dx D 1:
</p>
<p>So
</p>
<p>p.x/ D
</p>
<p>8
</p>
<p>&lt;
</p>
<p>:
</p>
<p>0 if x &lt; 0
</p>
<p>0 if x &gt; �
1
�
</p>
<p>otherwise
</p>
<p>Notice that if � &lt; 1, we have that p.x/ &gt; 1 for all x.
</p>
<p>Remember this: Probability notation can be quirky. Usually, one uses a big P for actual probabilities, and a small p
</p>
<p>for probability densities. The argument, or context, is supposed to tell you which probability distribution is meant (i.e
</p>
<p>P.X/ likely refers to a different probability distribution than P.Y/, which should strike a computer scientist familiar
</p>
<p>with dummy variables as bizarre). Because the probability distribution for a discrete random variable is a collection of
</p>
<p>probabilities, following this convention requires that such a probability distribution be written with a big P. However,
</p>
<p>having different notation for discrete and continuous random variables can get quite clunky. In application areas it
</p>
<p>is usual to write a small p for a probability distribution, and whether a density or a distribution is intended depends
</p>
<p>on whether the random variable is continuous or discrete. However, if you want to emphasize that a probability is
</p>
<p>intended, you can write P. I will follow this convention. To add to the fun, you may encounter p.x/ with the meaning
</p>
<p>&ldquo;some probability distribution&rdquo; or p.x/ meaning &ldquo;the value of the probability distribution P.fX D xg/ at the point
x&rdquo; or p.x/ with the meaning &ldquo;the probability distribution P.fX D xg/ as a function of x&rdquo;. You can usually figure out
what is intended as long as you don&rsquo;t think too closely about it (authors are often quite inconsistent); context may
</p>
<p>help disambiguate different intended meanings, too. Cumulative distributions are often written with an f , so that an
</p>
<p>unexpected f .x/ might mean P.fX &lt;D xg/.
</p>
<p>4.2 Expectations and Expected Values
</p>
<p>Example 4.2 described a simple game. I flip a coin. The coin has P.H/ D p, P.T/ D 1 � p. If the coin comes up heads, you
pay me q; if the coin comes up tails, I pay you r. Now imagine we play this game many times. Our frequency definition of
</p>
<p>probability means that in N games, we expect to see about pN heads and .1 � p/N tails. In turn, this means that my total
income from these N games should be about .pN/q � ..1 � p/N/r. The N in this expression is inconvenient; instead, we
could say that for any single game, my expected income is
</p>
<p>pq � .1 � p/r:
</p>
<p>This isn&rsquo;t the actual income from a single game (which would be either q or �r, depending on what the coin did). Instead,
it&rsquo;s an estimate of what would happen over a large number of games, on a per-game basis. This is an example of an expected
</p>
<p>value.
</p>
<p>4.2.1 Expected Values
</p>
<p>Definition 4.8 (Expected Value) Given a discrete random variable X which takes values in the set D and which has
</p>
<p>probability distribution P, we define the expected value
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>94 4 Random Variables and Expectations
</p>
<p>EŒX&#141; D
X
</p>
<p>x2D
xP.X D x/:
</p>
<p>This is sometimes written EPŒX&#141;, to clarify which distribution one has in mind.
</p>
<p>Notice that an expected value could take a value that the random variable doesn&rsquo;t take.
</p>
<p>Example 4.5 (Betting on Coins) We agree to play the following game. I flip a fair coin (i.e. P.H/ D P.T/ D 1=2). If
the coin comes up heads, you pay me 1; if the coin comes up tails, I pay you 1. The expected value of my income is 0,
</p>
<p>even though the random variable never takes that value.
</p>
<p>Worked example 4.8 (Betting on Coins, Again) We agree to play the following game. I flip a fair coin (i.e. P.H/ D
P.T/ D 1=2). If the coin comes up heads, you pay me 2; if the coin comes up tails, I pay you 1. What is the expected
value of this game?
</p>
<p>Solution The expected value of my income is
</p>
<p>.
1
</p>
<p>2
/ � 2 � .1
</p>
<p>2
/ � 1 D 1
</p>
<p>2
:
</p>
<p>Notice this isn&rsquo;t even an integer, and there&rsquo;s no way that any one instance of the game would yield a payoff of 1=2. But
</p>
<p>this is what I would get, per game, if I played many times.
</p>
<p>Your intuition is likely to tell you that the game of Example 4.8 is good for me and bad for you. This intuition is correct. It
</p>
<p>turns out that an even stronger statement is possible: playing this game repeatedly is pretty much guaranteed to be excellent
</p>
<p>for me and disastrous for you. It&rsquo;ll take some pages before I can be crisp about precisely what I mean here and why it is true.
</p>
<p>Definition 4.9 (Expectation) Assume we have a function f that maps a discrete random variable X into a set of
</p>
<p>numbers Df . Then f .X/ is a discrete random variable, too, which we write F. The expected value of this random
</p>
<p>variable is written
</p>
<p>EŒf &#141; D
X
</p>
<p>u2Df
uP.F D u/ D
</p>
<p>X
</p>
<p>x2D
f .x/P.X D x/
</p>
<p>which is sometimes referred to as &ldquo;the expectation of f &rdquo;. The process of computing an expected value is sometimes
</p>
<p>referred to as &ldquo;taking expectations&rdquo;. This is sometimes written EPŒf &#141; or even EP.X/Œf &#141;, to clarify which distribution one
</p>
<p>has in mind.
</p>
<p>We can compute expectations for continuous random variables, too, though summing over all values now turns into an
</p>
<p>integral. Assume I have a continuous random variable X with probability density function p.x/. Remember I interpret the
</p>
<p>probability density function as meaning that, for an infinitesimal interval size dx, p.x/dx D P.fX 2 Œx; xC dx&#141;g/). Divide the
set of possible values that X can take into small intervals of width &#129;x, centered on xi. We can construct a discrete random
</p>
<p>variable OX which takes values xi. We have that P.f OX D xig/ � p.xi/&#129;x, where I used the approximation sign because &#129;x
may not be infinitesimally small.
</p>
<p>Now write E
h
</p>
<p>OX
i
</p>
<p>for the expected value of OX. We have
</p>
<p>E
</p>
<p>h
</p>
<p>OX
i
</p>
<p>D
X
</p>
<p>xi
</p>
<p>xiP.xi/ �
X
</p>
<p>xi
</p>
<p>xip.xi/&#129;x:</p>
<p/>
</div>
<div class="page"><p/>
<p>4.2 Expectations and Expected Values 95
</p>
<p>As the intervals limit to infinitesimal intervals, OX limits to X (think of a picture of a histogram with infinitely narrow boxes).
Then E
</p>
<p>h
</p>
<p>OX
i
</p>
<p>has a limit which is an integral, and this defines the expected value. So we have the expressions in the boxes
</p>
<p>below.
</p>
<p>Definition 4.10 (Expected Value of a Continuous Random Variable) Given a continuous random variable X which
</p>
<p>takes values in the set D and which has probability distribution P, we define the expected value
</p>
<p>EŒX&#141; D
Z
</p>
<p>x2D
xp.x/dx:
</p>
<p>This is sometimes written EpŒX&#141;, to clarify which distribution one has in mind.
</p>
<p>The expected value of a continuous random variable could be a value that the random variable doesn&rsquo;t take, too. Notice
</p>
<p>one attractive feature of the EŒX&#141; notation; we don&rsquo;t need to make any commitment to whether X is a discrete random variable
</p>
<p>(where we would write a sum) or a continuous random variable (where we would write an integral). The reasoning by which
</p>
<p>we turned a sum into an integral works for functions of continuous random variables, too.
</p>
<p>Definition 4.11 (Expectation of a Continuous Random Variable) Assume we have a function f that maps a
</p>
<p>continuous random variable X into a set of numbers Df . Then f .X/ is a continuous random variable, too, which we
</p>
<p>write F. The expected value of this random variable is
</p>
<p>EŒf &#141; D
Z
</p>
<p>x2D
f .x/p.x/dx
</p>
<p>which is sometimes referred to as &ldquo;the expectation of f &rdquo;. The process of computing an expected value is sometimes
</p>
<p>referred to as &ldquo;taking expectations&rdquo;.
</p>
<p>Under some circumstances the expected value may not exist. The integral needs to exist, and be finite, for us to interpret the
</p>
<p>expected value meaningfully, and that isn&rsquo;t guaranteed for every continuous random variable. Nothing we do will encounter
</p>
<p>this issue, and so we will ignore it.
</p>
<p>You can see an expectation as an operation you apply to a random variable. It doesn&rsquo;t matter whether the random variable
</p>
<p>is discrete or continuous; that just changes the recipe for computing the value of the expectation. The crucial property of this
</p>
<p>operation is that it is linear; this is so important I have put it in its own box.
</p>
<p>Useful Facts 4.2 (Expectations Are Linear)
</p>
<p>Write f , g for functions of random variables.
</p>
<p>&bull; EŒ0&#141; D 0
&bull; for any constant k, EŒkf &#141; D kEŒf &#141;
&bull; EŒf C g&#141; D EŒf &#141;C EŒg&#141;.
</p>
<p>I have written this box in a rather compact form. This is because the expression EŒX&#141; for the expected value of a random
</p>
<p>variable is actually a special case of EŒf &#141;&mdash;one just uses the identity function for f . So the box also tells us that EŒX C Y&#141; D
EŒX&#141;C EŒY&#141;, and so on.
</p>
<p>4.2.2 Mean, Variance and Covariance
</p>
<p>There are three very important expectations with special names.</p>
<p/>
</div>
<div class="page"><p/>
<p>96 4 Random Variables and Expectations
</p>
<p>Definition 4.12 (Mean or Expected Value) The mean or expected value of a random variable X is
</p>
<p>EŒX&#141;
</p>
<p>Worked example 4.9 (Mean of a Coin Flip) We flip a biased coin, with P.H/ D p. The random variable X has value
1 if the coin comes up heads, 0 otherwise. What is the mean of X? (i.e. EŒX&#141;).
</p>
<p>Solution EŒX&#141; D
P
</p>
<p>x2D xP.X D x/ D 1pC 0.1 � p/ D p
</p>
<p>Definition 4.13 (Variance) The variance of a random variable X is
</p>
<p>varŒX&#141; D E
�
</p>
<p>.X � EŒX&#141;/2
�
</p>
<p>Useful Facts 4.3 (Properties of Variance)
</p>
<p>We have:
</p>
<p>&bull; For any constant k, varŒk&#141; D 0;
&bull; varŒX&#141; � 0;
&bull; varŒkX&#141; D k2varŒX&#141;;
&bull; and, if X and Y are independent, then varŒX C Y&#141; D varŒX&#141;C varŒY&#141;.
</p>
<p>The first three are obvious, and the fourth appears in the exercises.
</p>
<p>Useful Facts 4.4 (Variance, a Useful Expression)
</p>
<p>varŒX&#141; D E
�
</p>
<p>.X � EŒX&#141;/2
�
</p>
<p>D E
h
</p>
<p>.X2 � 2XEŒX&#141;C EŒX&#141;2/
i
</p>
<p>D E
�
</p>
<p>X2
�
</p>
<p>� 2EŒX&#141;EŒX&#141;C EŒX&#141;2
</p>
<p>D E
�
</p>
<p>X2
�
</p>
<p>� .EŒX&#141;/2
</p>
<p>Worked example 4.10 (Variance of a Coin Flip) We flip a biased coin, with P.H/ D p. The random variable X has
value 1 if the coin comes up heads, 0 otherwise. What is the variance of X? (i.e. varŒX&#141;).
</p>
<p>Solution varŒX&#141; D E
�
</p>
<p>.X � EŒX&#141;/2
�
</p>
<p>D E
�
</p>
<p>X2
�
</p>
<p>� EŒX&#141;2 D .1p � 0.1 � p// � p2 D p.1 � p/</p>
<p/>
</div>
<div class="page"><p/>
<p>4.2 Expectations and Expected Values 97
</p>
<p>Worked example 4.11 (Variance) Can a random variable have EŒX&#141; &gt;
p
</p>
<p>EŒX2&#141;?
</p>
<p>Solution No, because that would mean that E
�
</p>
<p>.X � EŒX&#141;/2
�
</p>
<p>&lt; 0. But this is the expected value of a non-negative
</p>
<p>quantity; it must be non-negative.
</p>
<p>Worked example 4.12 (More Variance) We just saw that a random variable can&rsquo;t have EŒX&#141; &gt;
p
</p>
<p>EŒX2&#141;. But I can
</p>
<p>easily have a random variable with large mean and small variance&mdash;isn&rsquo;t this a contradiction?
</p>
<p>Solution No, you&rsquo;re confused. Your question means you think that the variance of X is given by E
�
</p>
<p>X2
�
</p>
<p>; but actually
</p>
<p>varŒX&#141; D E
�
</p>
<p>X2
�
</p>
<p>� EŒX&#141;2
</p>
<p>Now assume that we have a probability distribution P.X/ defined on some discrete set of numbers. There is some random
</p>
<p>variable that produced this probability distribution. This means that we could talk about the mean of a probability distribution
</p>
<p>P (rather than the mean of a random variable whose probability distribution is P.X/). It is quite usual to talk about the mean
</p>
<p>of a probability distribution. Furthermore, we could talk about the variance of a probability distribution P (rather than the
</p>
<p>variance of a random variable whose probability distribution is P.X/).
</p>
<p>Definition 4.14 (Covariance) The covariance of two random variables X and Y is
</p>
<p>cov .X;Y/ D EŒ.X � EŒX&#141;/.Y � EŒY&#141;/&#141;
</p>
<p>Useful Facts 4.5 (Covariance, Useful Expression)
</p>
<p>cov .X;Y/ D EŒ.X � EŒX&#141;/.Y � EŒY&#141;/&#141;
</p>
<p>D EŒ.XY�YEŒX&#141;�XEŒY&#141;
</p>
<p>CEŒX&#141;EŒY&#141;/&#141;
</p>
<p>D EŒXY&#141;�2EŒY&#141;EŒX&#141;CEŒX&#141;EŒY&#141;
</p>
<p>D EŒXY&#141; � EŒX&#141;EŒY&#141;:
</p>
<p>Useful Facts 4.6 (Independent Random Variables Have Zero Covariance)
</p>
<p>We have:
</p>
<p>&bull; if X and Y are independent, then EŒXY&#141; D EŒX&#141;EŒY&#141;;
&bull; if X and Y are independent, then cov .X;Y/ D 0.
</p>
<p>If the first is true, then the second is obviously true (apply the expression of useful facts 4.5).</p>
<p/>
</div>
<div class="page"><p/>
<p>98 4 Random Variables and Expectations
</p>
<p>Proposition If X and Y are independent random variables, then EŒXY&#141; D EŒX&#141;EŒY&#141;.
</p>
<p>Proof Recall that EŒX&#141; D
P
</p>
<p>x2D xP.X D x/, so that
</p>
<p>EŒXY&#141; D
X
</p>
<p>.x;y/2Dx�Dy
xyP.X D x;Y D y/
</p>
<p>D
X
</p>
<p>x2Dx
</p>
<p>X
</p>
<p>y2Dy
.xyP.X D x;Y D y//
</p>
<p>D
X
</p>
<p>x2Dx
</p>
<p>X
</p>
<p>y2Dy
.xyP.X D x/P.Y D y//
</p>
<p>because X and Y are independent
</p>
<p>D
X
</p>
<p>x2Dx
</p>
<p>X
</p>
<p>y2Dy
.xP.X D x// .yP.Y D y//
</p>
<p>D
</p>
<p>0
</p>
<p>@
</p>
<p>X
</p>
<p>x2Dx
xP.XDx/
</p>
<p>1
</p>
<p>A
</p>
<p>0
</p>
<p>@
</p>
<p>X
</p>
<p>y2Dy
yP.YDy/
</p>
<p>1
</p>
<p>A
</p>
<p>D .EŒX&#141;/.EŒY&#141;/:
</p>
<p>This is certainly not true when X and Y are not independent (try Y D �X).
</p>
<p>Useful Facts 4.7 (Variance as Covariance)
</p>
<p>We have
</p>
<p>varŒX&#141; D cov .X;X/
</p>
<p>(substitute into definitions).
</p>
<p>The variance of a random variable is often inconvenient, because its units are the square of the units of the random
</p>
<p>variable. Instead, we could use the standard deviation.
</p>
<p>Definition 4.15 (Standard Deviation) The standard deviation of a random variable X is defined as
</p>
<p>std .fXg/ D
p
</p>
<p>varŒX&#141;
</p>
<p>You do need to be careful with standard deviations. If X and Y are independent random variables, then varŒX C Y&#141; D
varŒX&#141; C varŒY&#141;, but std .fX C Yg/ D
</p>
<p>q
</p>
<p>std .fXg/2 C std .fYg/2. One way to avoid getting mixed up is to remember that
variances add, and derive expressions for standard deviations from that.
</p>
<p>4.2.3 Expectations and Statistics
</p>
<p>I have now used each of the terms mean, variance, covariance, and standard deviation in two slightly different ways. One
</p>
<p>sense of each term, expounded in Sect. 1.3, describes a property of a dataset. These are known as descriptive statistics. The</p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 The Weak Law of Large Numbers 99
</p>
<p>other sense, described above, is a property of probability distributions. These are known as expectations. The reason we use
</p>
<p>one name for two notions is that the notions are not really all that different.
</p>
<p>Here is a useful construction to illustrate the point. Imagine we have a dataset fxg of N items, where the i&rsquo;th item is xi.
Build a random variable X using this dataset by placing the same probability on each data item. This means that each data
</p>
<p>item has probability 1=N. Write EŒX&#141; for the mean of this distribution. We have
</p>
<p>EŒX&#141; D
X
</p>
<p>i
</p>
<p>xiP.xi/ D
1
</p>
<p>N
</p>
<p>X
</p>
<p>i
</p>
<p>xi D mean .fxg/
</p>
<p>and, by the same reasoning,
</p>
<p>varŒX&#141; D var .fxg/:
</p>
<p>This construction works for standard deviation and covariance, too. For this particular distribution (sometimes called
</p>
<p>the empirical distribution), the expectations have the same value as the descriptive statistics.
</p>
<p>In Sect. 4.3.4, we will see a form of converse to this fact. Imagine we have a dataset that consists of independent, identically
</p>
<p>distributed samples from a probability distribution (i.e. we know that each data item was obtained independently from the
</p>
<p>distribution). For example, we might have a count of heads in each of a number of coin flip experiments. Then the descriptive
</p>
<p>statistics will turn out to be accurate estimates of the expectations.
</p>
<p>4.3 TheWeak Law of Large Numbers
</p>
<p>Assume you see repeated values of a random variable. For example, let X be the random variable which has value 1 if a
</p>
<p>coin comes up heads (which happens with probability p) and �1 if it comes up tails. You now actually flip a coin N times,
recording 1 for heads and �1 for tails. Intuition should say that the average of these numbers should be a good estimate
of the value of EŒX&#141;, by the following argument. You should see 1 about pN times, and �1 about .1 � p/N times. So the
average should be close to p � .1 � p/, which is EŒX&#141;. Furthermore, intuition should suggest that this estimate gets better as
the number of flips goes up.
</p>
<p>These intuitions are correct. You can estimate expectations accurately by experiment. This is extremely useful, because
</p>
<p>it means that you can use quite simple programs to estimate values that might take a great deal of work to obtain any other
</p>
<p>way. Most people find it natural that something of this sort should be true. What is neat is that it is quite easy to prove.
</p>
<p>4.3.1 IID Samples
</p>
<p>We need first to be crisp about what we are averaging. Imagine a random variable X, obtained by flipping a fair coin and
</p>
<p>reporting 1 for an H and �1 for a T . We can talk about the probability distribution P.X/ of this random variable; we can
talk about the expected value that the random variable takes; but the random variable itself doesn&rsquo;t have a value. However, if
</p>
<p>we actually flip a coin, we get either a 1 or a �1. Observing a value is sometimes called a trial. The resulting value is often
called a sample of the random variable (or of its probability distribution); it is sometimes called a realization. So flipping
</p>
<p>the coin is a trial, and the number you get is a sample. If we flipped a coin many times, we&rsquo;d have a set of numbers (or
</p>
<p>samples). These numbers would be independent. Their histogram would look like P.X/. Collections of data items like this
</p>
<p>are important enough to have their own name.
</p>
<p>Assume we have a set of data items xi such that (a) they are independent; and (b) the histogram of a very large set of data
</p>
<p>items looks increasingly like the probability distribution P.X/ as the number of data items increases. Then we refer to these
</p>
<p>data items as independent identically distributed samples of P.X/; for short, iid samples or even just samples. It&rsquo;s worth
</p>
<p>knowing that it can be a difficult computational problem to get IID samples from some given probability distribution. For all
</p>
<p>of the cases we will deal with, it will be obvious how to get IID samples. Usually, they were generated for us&mdash;i.e. somebody
</p>
<p>flipped the coin, etc.
</p>
<p>Now assume you take N IID samples, and average them. The weak law of large numbers states that, as N gets larger,
</p>
<p>this average is an increasingly good estimate of EŒX&#141;. This fact allows us estimate expectations (and so probabilities) by
</p>
<p>simulation. Furthermore, it will allow us to make strong statements about how repeated games with random outcomes will
</p>
<p>behave. Finally, it will allow us to build a theory of decision making.</p>
<p/>
</div>
<div class="page"><p/>
<p>100 4 Random Variables and Expectations
</p>
<p>4.3.2 Two Inequalities
</p>
<p>To go further, we need two useful inequalities. Consider
</p>
<p>EŒjXj&#141; D
X
</p>
<p>x2D
jxjP.fX D xg/:
</p>
<p>Now notice that all the terms in the sum are non-negative. Then the only way to have a small value of EŒjXj&#141; is to be sure
that, when jxj is large, P.fX D xg/ is small. It turns out to be possible (and useful!) to be more crisp about how quickly
P.fX D xg/ falls as jxj grows, resulting in Markov&rsquo;s inequality (which I&rsquo;ll prove below)
</p>
<p>Definition 4.16 (Markov&rsquo;s Inequality) Markov&rsquo;s inequality is
</p>
<p>P.fjXj � ag/ � EŒjXj&#141;
a
</p>
<p>:
</p>
<p>Notice that we&rsquo;ve seen something like this before (the result about standard deviation in Sect. 1.3.2 has this form). The
</p>
<p>reason this is worth proving is that it leads to a second result, and that gives us the weak law of large numbers. It should seem
</p>
<p>clear that the probability of a random variable taking a particular value must fall off rather fast as that value moves away
</p>
<p>from the mean, in units scaled to the standard deviation. This is because values of a random variable that are many standard
</p>
<p>deviations above the mean must have low probability, otherwise the values would occur more often and so the standard
</p>
<p>deviation would be bigger. This result is Chebyshev&rsquo;s inequality, which I shall also prove below.
</p>
<p>Definition 4.17 (Chebyshev&rsquo;s Inequality) Chebyshev&rsquo;s inequality is
</p>
<p>P.fjX � EŒX&#141;j � ag/ � varŒX&#141;
a2
</p>
<p>:
</p>
<p>It is common to see this in another form, obtained by writing � for the standard deviation of X, substituting k� for a,
</p>
<p>and rearranging
</p>
<p>P.fjX � EŒX&#141;j � k�g/ � 1
k2
</p>
<p>We care about Chebyshev&rsquo;s inequality because it gives us the weak law of large numbers.
</p>
<p>4.3.3 Proving the Inequalities
</p>
<p>An indicator function is a function that is one when some condition is true, and zero otherwise. The reason indicator
</p>
<p>functions are useful is that their expected values have interesting properties.
</p>
<p>Definition 4.18 (Indicator Functions) An indicator function for an event is a function that takes the value zero for
</p>
<p>values of x where the event does not occur, and one where the event occurs. For the event E , we write
</p>
<p>IŒE&#141;.x/
</p>
<p>for the relevant indicator function.</p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 The Weak Law of Large Numbers 101
</p>
<p>I used a small x in the definition, because this is a function; the argument doesn&rsquo;t need to be a random variable. You should
</p>
<p>think about an indicator function as testing the value of its argument to tell whether it lies in the event or not, and reporting
</p>
<p>1 or 0 accordingly. For example,
</p>
<p>IŒfjxjg�a&#141;.x/ D
�
</p>
<p>1 if � a &lt; x &lt; a
0 otherwise
</p>
<p>Indicator functions have one useful property.
</p>
<p>EP
</p>
<p>�
</p>
<p>IŒE&#141;
</p>
<p>�
</p>
<p>D P.E/
</p>
<p>which you can establish by checking the definition of expectations.
</p>
<p>Proposition Markov&rsquo;s inequality: for X a random variable, a &gt; 0,
</p>
<p>P.fjXj � ag/ � EŒjXj&#141;
a
</p>
<p>:
</p>
<p>Proof (from Wikipedia). Notice that, for a &gt; 0,
</p>
<p>aIŒfjXj�ag&#141;.X/ � jXj
</p>
<p>(because if jXj � a, the LHS is a; otherwise it is zero). Now we have
</p>
<p>E
�
</p>
<p>aIŒfjXj�ag&#141;
�
</p>
<p>� EŒjXj&#141;
</p>
<p>but, because expectations are linear, we have
</p>
<p>E
�
</p>
<p>aIŒfjXj�ag&#141;
�
</p>
<p>DaE
�
</p>
<p>IŒfjXj�ag&#141;
�
</p>
<p>DaP.fjXj�ag/
</p>
<p>and so we have
</p>
<p>aP.fjXj � ag/ � EŒjXj&#141;
</p>
<p>and we get the inequality by division, which we can do because a &gt; 0.
</p>
<p>Proposition Chebyshev&rsquo;s inequality: for X a random variable, a &gt; 0,
</p>
<p>P.fjX � EŒX&#141;j � ag/ � varŒX&#141;
a2
</p>
<p>:
</p>
<p>Proof Write U for the random variable .X � EŒX&#141;/2. Markov&rsquo;s inequality gives us
</p>
<p>P.fjUj � wg/ � EŒjUj&#141;
w
</p>
<p>Now notice that, if w D a2,
P.fjUj � wg/ D P.fjX � EŒX&#141;j � ag/
</p>
<p>so we have
P.fjUj � wg/ D P.fjX � EŒX&#141;j � ag/
</p>
<p>� EŒjUj&#141;
w
</p>
<p>D varŒX&#141;
a2</p>
<p/>
</div>
<div class="page"><p/>
<p>102 4 Random Variables and Expectations
</p>
<p>4.3.4 TheWeak Law of Large Numbers
</p>
<p>Assume we have a set of N IID samples xi of a probability distribution P.X/. Write
</p>
<p>XN D
PN
</p>
<p>iD1 xi
N
</p>
<p>:
</p>
<p>Now XN is a random variable (the xi are IID samples, and for a different set of samples you will get a different, random, XN).
</p>
<p>Notice that P.X D x1;X D x2; : : : ;X D xn/ D P.X D x1/P.X D x2/ : : :P.X D xn/, because the samples are independent
and each is a sample of P.X/. This means that
</p>
<p>EŒXN &#141; D EŒX&#141;
</p>
<p>because
</p>
<p>EŒXN &#141; D
�
</p>
<p>1
</p>
<p>N
</p>
<p>� N
X
</p>
<p>iD1
EŒX&#141;:
</p>
<p>This means that
PN
</p>
<p>iD1 xi
N
</p>
<p>should be an accurate estimate of EŒX&#141;. The weak law of large numbers states that, as N gets large, the estimate becomes
</p>
<p>more accurate.
</p>
<p>Definition 4.19 (Weak Law of Large Numbers) If P.X/ has finite variance, then for any positive number �
</p>
<p>lim
N!1
</p>
<p>P.fjXN � EŒX&#141;j � �g/ D 0:
</p>
<p>Equivalently, we have
</p>
<p>lim
N!1
</p>
<p>P.fjXN � EŒX&#141;j &lt; �g/ D 1:
</p>
<p>Proposition Weak law of large numbers
</p>
<p>lim
N!1
</p>
<p>P.fjXN � EŒX&#141;j � �g/ D 0:
</p>
<p>Proof Write var .fXg/ D �2. Choose � &gt; 0. Now we have that
</p>
<p>var .fXNg/ D var
 (
</p>
<p>PN
iD1 xi
N
</p>
<p>)!
</p>
<p>D . 1
N2
</p>
<p>/var
</p>
<p> (
</p>
<p>N
X
</p>
<p>iD1
xi
</p>
<p>)!
</p>
<p>D . 1
N2
</p>
<p>/.N�2/
</p>
<p>the xi are independent
</p>
<p>D �
2
</p>
<p>N
</p>
<p>and that
</p>
<p>EŒXN &#141; D EŒX&#141;:
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4 Using the Weak Law of Large Numbers 103
</p>
<p>Now Chebyshev&rsquo;s inequality gives
</p>
<p>P.fjXN � EŒX&#141;j � �g/ �
�2
</p>
<p>N�2
</p>
<p>so
</p>
<p>lim
N!1
</p>
<p>P.fjXN�EŒX&#141;j � �g/D lim
N!1
</p>
<p>�2
</p>
<p>N�2
D0:
</p>
<p>The weak law of large numbers gives us a very valuable way of thinking about expectations. Assume we have a random
</p>
<p>variable X. Then the weak law says that, if you observe a large number of IID samples of this random variable, the average
</p>
<p>of the values you observe should be very close to EŒX&#141;. This result is extremely powerful. The next section explores some
</p>
<p>applications. The weak law allows us to estimate expectations (and so probabilities, which are expectations of indicator
</p>
<p>functions) by observing random behavior. The weak law can be used to build a theory of decision making.
</p>
<p>4.4 Using theWeak Law of Large Numbers
</p>
<p>4.4.1 Should You Accept a Bet?
</p>
<p>We can&rsquo;t answer this as a moral question, but we can as a practical question, using expectations. Generally, a bet involves an
</p>
<p>agreement that amounts of money will change hands, depending on the outcome of an experiment. Mostly, you are interested
</p>
<p>in how much you get from the bet, so it is natural to give sums of money you receive a positive sign, and sums of money
</p>
<p>you pay out a negative sign. The weak law says that if you repeat a bet many times, you are increasingly likely to receive
</p>
<p>the expected value of the bet, per bet. Under this convention, the practical answer is easy: accept a bet enthusiastically if
</p>
<p>its expected value is positive, otherwise decline it. It is interesting to notice how poorly this advice describes actual human
</p>
<p>behavior.
</p>
<p>Worked example 4.13 (Red or Black?) On a roulette wheel (see p. xxiii if you can&rsquo;t remember how these work),
</p>
<p>you can bet on (among other things) whether a red number or a black number comes up. If you bet 1 on red, and a red
</p>
<p>number comes up, you keep your stake and get 1; if a black number or a zero comes up, you get �1 (i.e. the house
keeps your bet). What is the expected value of a bet of 1 on a wheel with one, two and three zeros?
</p>
<p>Solution Write pr for the probability a red number comes up. The expected value is 1 � pr C .�1/.1 � pr/ which is
2pr � 1. For one zero, pr D .number of red numbers// .total number of numbers/ D 18=37. So the expected value is
�1=37 (you lose about three cents each time you bet a dollar). For two zeros, pr D 18=38. So the expected value is
�2=38 D �1=19 (you lose slightly more than five cents each time you bet a dollar). For three zeros, pr D 18=39. So
the expected value is �3=39 D �1=13 (you lose slightly less than eight cents each time you bet a dollar).
</p>
<p>Notice that in the roulette game, the money you lose will go to the house. So the expected value to the house is just the
</p>
<p>negative of the expected value to you. You might not play the wheel often, but the house plays the wheel very often when
</p>
<p>there are many players. The weak law means a house with many players can rely on receiving about three, five, or eight cents
</p>
<p>per dollar bet, depending on the number of zeros on the wheel. This is a partial explanation of why there are lots of roulette
</p>
<p>wheels, and usually free food nearby. Not all bets are like this, though.
</p>
<p>Worked example 4.14 (Coin Game) In this game, P1 flips a fair coin and P2 calls &ldquo;H&rdquo; or &ldquo;T&rdquo;. If P2 calls right, then
</p>
<p>P1 throws the coin into the river; otherwise, P1 keeps the coin. The coin belongs to P1, and has value 1. What is the
</p>
<p>expected value of this game to P2? and to P1?
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>104 4 Random Variables and Expectations
</p>
<p>Solution To P2, which we do first, because it&rsquo;s easiest: P2 gets 0 if P2 calls right, and 0 if P2 calls wrong; these are
</p>
<p>the only cases, so the expected value is 0. To P1: P1 gets �1 if P2 calls right, and 0 if P1 calls wrong. The coin is fair,
so the probability P2 calls right is 1/2. The expected value is �1=2. While I can&rsquo;t explain why people would play such
a game, I&rsquo;ve actually seen this done.
</p>
<p>We call a bet fair when its expected value is zero. Taking a bet with a negative expected value is unwise, because, on
</p>
<p>average, you will lose money. Worse, the more times you play, the more you lose. Similarly, repeatedly taking a bet with a
</p>
<p>positive expected value is reliably profitable. However, you do need to be careful you computed the expected value right.
</p>
<p>Worked example 4.15 (Birthdays in Succession) P1 and P2 agree to the following bet. P1 gives P2 a stake of 1. If
</p>
<p>three people, stopped at random on the street, have birthdays in succession (i.e. Mon-Tue-Wed, and so on), then P2
</p>
<p>gives P1 100. Otherwise, P1 loses the stake. What is the expected value of this bet to P1?
</p>
<p>Solution Write p for the probability of winning. Then the expected value is p � 100� .1� p/ � 1. We computed p in
Example 3.45 (it was 1=49). So the bet is worth .52=49/, or slightly more than a dollar, to P1. P1 should be happy to
</p>
<p>agree to this as often as possible.
</p>
<p>The reason P2 agrees to bets like that of Example 4.15 is most likely that P2 can&rsquo;t compute the probability exactly. P2
</p>
<p>thinks the event is quite unlikely, so the expected value is negative; but it isn&rsquo;t as unlikely as P2 thought it was, and this is
</p>
<p>how P1 makes a profit. This is one of the many reasons you should be careful accepting a bet from a stranger: they might be
</p>
<p>able to compute better than you.
</p>
<p>4.4.2 Odds, Expectations and Bookmaking: A Cultural Diversion
</p>
<p>Gamblers sometimes use a terminology that is a bit different from ours. In particular, the term odds is important. The term
</p>
<p>comes from the following idea: P1 pays a bookmaker b (the stake) to make a bet; if the bet is successful, P1 receives a and
</p>
<p>the stake back, and if not, loses the original stake. This bet is referred to as odds of a W b (read &ldquo;odds of a to b&rdquo;).
Assume the bet is fair, so that the expected value is zero. Write p for the probability of winning. The net income to P1 is
</p>
<p>ap�b.1�p/. If this is zero, then p D b=.aCb/. So you can interpret odds in terms of probability, if you assume the bet is fair.
A bookmaker sets odds at which to accept bets from gamblers. The bookmaker does not wish to lose money at this
</p>
<p>business, and so must set odds which are potentially profitable. Doing so is not simple (bookmakers can, and occasionally
</p>
<p>do, lose catastrophically, and go out of business). In the simplest case, assume that the bookmaker knows the probability p
</p>
<p>that a particular bet will win. Then the bookmaker could set odds of .1 � p/=p W 1. In this case, the expected value of the bet
is zero; this is fair, but not attractive business, so the bookmaker will set odds assuming that the probability is a bit higher
</p>
<p>than it really is. There are other bookmakers out there, so there is some reason for the bookmaker to try to set odds that are
</p>
<p>close to fair.
</p>
<p>In some cases, you can tell when you are dealing with a bookmaker who is likely to go out of business soon. For example,
</p>
<p>imagine there are two horses running in a race, both at 10 W 1 odds&mdash;whatever happens, you could win by betting 1 on each.
There is a more general version of this phenomenon. Assume the bet is placed on a horse race, and that bets pay off only for
</p>
<p>the winning horse. Assume also that exactly one horse will win (i.e. the race is never scratched, there aren&rsquo;t any ties, etc.),
</p>
<p>and write the probability that the i&rsquo;th horse will win as pi. Then
</p>
<p>X
</p>
<p>i2horses
</p>
<p>pi
</p>
<p>must be 1. Now if the bookmaker&rsquo;s odds yield a set of probabilities that is less than 1, their business should fail, because
</p>
<p>there is at least one horse on which they are paying out too much. Bookmakers deal with this possibility by writing odds so
</p>
<p>that
P
</p>
<p>i2horses pi is larger than one.</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4 Using the Weak Law of Large Numbers 105
</p>
<p>But this is not the only problem a bookmaker must deal with. The bookmaker doesn&rsquo;t actually know the probability that
</p>
<p>a particular horse will win, and must account for errors in this estimate. One way to do so is to collect as much information
</p>
<p>as possible (talk to grooms, jockeys, etc.). Another is to look at the pattern of bets that have been placed already. If the
</p>
<p>bookmaker and the gamblers agree on the probability that each horse will win, then there should be no expected advantage
</p>
<p>to choosing one horse over another&mdash;each should pay out slightly less than zero to the gambler (otherwise the bookmaker
</p>
<p>doesn&rsquo;t eat). But if the bookmaker has underestimated the probability that a particular horse will win, a gambler may get
</p>
<p>a positive expected payout by betting on that horse. This means that if one particular horse attracts a lot of money from
</p>
<p>bettors, it is wise for the bookmaker to offer less generous odds on that horse. There are two reasons: first, the bettors might
</p>
<p>know something the bookmaker doesn&rsquo;t, and they&rsquo;re signalling it; second, if the bets on this horse are very large and it wins,
</p>
<p>the bookmaker may not have enough capital left to pay out or to stay in business. All this means that real bookmaking is a
</p>
<p>complex, skilled business.
</p>
<p>4.4.3 Ending a Game Early
</p>
<p>Imagine two people are playing a game for a stake, but must stop early&mdash;who should get what percentage of the stake? One
</p>
<p>way to do this is to give each player what they put in at the start, but this is (mildly) unfair if one has an advantage over the
</p>
<p>other. The alternative is to give each player the expected value of the game at that state for that player. Sometimes one can
</p>
<p>compute that expectation quite easily.
</p>
<p>Worked example 4.16 (Ending a Game Early) Two players each pay 25 to play the following game. They toss a
</p>
<p>fair coin. If it comes up heads, player H wins that toss; if tails, player T wins. The first player to reach 10 wins takes
</p>
<p>the stake of 50. But one player is called away when the state is 8&ndash;7 (H-T)&mdash;how should the stake be divided?
</p>
<p>Solution In this state, each player can either win&mdash;and so get 50&mdash;or lose&mdash;and so get 0. The expectation for H
</p>
<p>is 50P.fH wins from 8-7g/ C 0P.fT wins from 8-7g/, so we need to compute P.fH wins from 8-7g/. Similarly, the
expectation for T is 50P.fT wins from 8-7g/C 0P.fH wins from 8-7g/, so we need to compute P.fT wins from 8-7g/;
but P.fT wins from 8-7g/ D 1 � P.fH wins from 8-7g/. Now it is slightly easier to compute P.fT wins from 8-7g/,
because T can only win in two ways: 8&ndash;10 or 9&ndash;10. These are independent. For T to win 8&ndash;10, the next three flips
</p>
<p>must come up T, so that event has probability 1=8. For T to win 9&ndash;10, the next four flips must have one H in them,
</p>
<p>but the last flip may not be H (or else H wins); so the next four flips could be HTTT, THTT, or TTHT. The probability
</p>
<p>of this is 3=16. This means the total probability that T wins is 5=16. So T should get 15:625 and H should get the rest
</p>
<p>(although they might have to flip for the odd half cent).
</p>
<p>4.4.4 Making a Decision with Decision Trees and Expectations
</p>
<p>Imagine we have to choose an action. Once we have chosen, a sequence of random events occurs, and we get a reward with
</p>
<p>some probability. Which action should we choose? A good answer is to choose the action with the best expected outcome. If
</p>
<p>we encounter this situation repeatedly, the weak law tells us that choosing any other action than the one with best expected
</p>
<p>outcome is unwise. If we make a choice that is even only slightly worse than the best, we will reliably do worse than we
</p>
<p>could. This is a very common recipe, and it can be applied to many situations. Usually, but not always, the reward is in
</p>
<p>money, and we will compute with money rewards for the first few examples.
</p>
<p>For such problems, it can be useful to draw a decision tree. A decision tree is a drawing of possible outcomes of decisions,
</p>
<p>which makes costs, benefits and random elements explicit. Each node of the tree represents a test of an attribute (which could
</p>
<p>be either a decision, or a random variable), and each edge represents a possible outcome of a test. The final outcomes are
</p>
<p>leaves. Usually, decision nodes are drawn as squares, chance elements as circles, and leaves as triangles.</p>
<p/>
</div>
<div class="page"><p/>
<p>106 4 Random Variables and Expectations
</p>
<p>Fig. 4.1 A decision tree for the
vaccination problem. The only
decision is whether to vaccinate
or not (the box at the root of the
tree). I have only labelled edges
where this is essential, so I did
not annotate the &ldquo;no vaccination&rdquo;
edge with zero cost. Once you
decide whether to vaccinate or
not, there is a circle, indicating a
random node (a random event;
whether you get the disease or
not) and, if you get it, another
(minor or major)
</p>
<p>No disease $0
</p>
<p>Minor disease -$1000
</p>
<p>Major disease -$1e6
</p>
<p>Minor disease -$1000
</p>
<p>Major disease -$1e6
</p>
<p>Vaccinate -$10
</p>
<p>0.95
</p>
<p>0.9
</p>
<p>0.95
</p>
<p>1e-7
</p>
<p>Worked example 4.17 (Vaccination) It costs 10 to be vaccinated against a common disease. If you have the
</p>
<p>vaccination, the probability you will get the disease is 1e � 7. If you do not, the probability is 0:1. The disease is
unpleasant; with probability 0:95, you will experience effects that cost you 1000 (eg several days in bed), but with
</p>
<p>probability 0:05, you will experience effects that cost you 1e6. Should you be vaccinated?
</p>
<p>Solution Figure 4.1 shows a decision tree for this problem. I have annotated some edges with the choices represented,
</p>
<p>and some edges with probabilities; the sum of probabilities over all rightward (downgoing) edges leaving a random
</p>
<p>node is 1. It is straightforward to compute expectations. The expected cost of the disease is 0:95�1000C0:05�1e6 D
50; 950. If you are vaccinated, your expected income will be �.10C 1e� 7� 50; 950/ � �10:01. If you are not, your
expected income is �5; 095. You should be vaccinated.
</p>
<p>Example 4.17 has some subtleties. The conclusion is a rather shaky, though very common, use of the weak law. It&rsquo;s shaky,
</p>
<p>because the weak law has nothing to say about the outcome of a decision that you make only once. The proper interpretation
</p>
<p>of the example is that, if you had to make the choice many times over under the same set of circumstances, you should choose
</p>
<p>to be vaccinated. Notice you have to be careful using the example to argue that everyone should be vaccinated, because if
</p>
<p>lots of people were vaccinated then the probability of getting the disease would change. Since this probability goes down,
</p>
<p>the conclusion is fine, but you have to be careful about how you get there.
</p>
<p>Sometimes there is more than one decision. We can still do simple examples, though drawing a decision tree is now quite
</p>
<p>important, because it allows us to keep track of cases and avoid missing anything. For example, assume I wish to buy a
</p>
<p>cupboard. Two nearby towns have used furniture shops (usually called antique shops these days). One is further away than
</p>
<p>the other. If I go to town A, I will have time to look in two (of three) shops; if I go to town B, I will have time to look in
</p>
<p>one (of two) shops. I could lay out this sequence of decisions (which town to go to; which shop to visit when I get there) as
</p>
<p>Fig. 4.2.
</p>
<p>You should notice that this figure is missing a lot of information. What is the probability that I will find what I&rsquo;m looking
</p>
<p>for in the shops? What is the value of finding it? What is the cost of going to each town? and so on. This information is
</p>
<p>not always easy to obtain. In fact, I might simply need to give my best subjective guess of these numbers. Furthermore,
</p>
<p>particularly if there are several decisions, computing the expected value of each possible sequence could get difficult. There
</p>
<p>are some kinds of model where one can compute expected values easily, but a good viable hypothesis about why people
</p>
<p>don&rsquo;t make optimal decisions is that optimal decisions are actually too hard to compute.
</p>
<p>4.4.5 Utility
</p>
<p>Sometimes it is hard to work with money. For example, in the case of a serious disease, choosing treatments often boils down
</p>
<p>to expected survival times, rather than money.</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4 Using the Weak Law of Large Numbers 107
</p>
<p>Town A
</p>
<p>Town B
</p>
<p>Shops 1, 2
</p>
<p>Shops 2, 3
</p>
<p>Shops 1, 3
</p>
<p>Shop 1
</p>
<p>Shop 2
</p>
<p>Fig. 4.2 The decision tree for the example of visiting furniture shops. Town A is nearer than town B, so if I go there I can choose to visit two of
the three shops there; if I go to town B, I can visit only one of the two shops there. To decide what to do, I could fill in the probabilities and values
of outcomes, compute the expected value of each pair of decisions, and choose the best. This could be tricky to do (where do I get the probabilities
from?) but offers a rational and principled way to make the decision
</p>
<p>Radical
</p>
<p>Standard
</p>
<p>Toxicity
</p>
<p>Can&rsquo;t complete
</p>
<p>Complete
</p>
<p>Minor response
</p>
<p>No response
</p>
<p>Major response
</p>
<p>0
</p>
<p>6
</p>
<p>60
</p>
<p>10
</p>
<p>10
</p>
<p>6
</p>
<p>m
o
n
th
</p>
<p>s su
rv
</p>
<p>iv
al
</p>
<p>0.1
</p>
<p>0.3
</p>
<p>0.6
0.1
</p>
<p>0.9
</p>
<p>0.5
</p>
<p>0.5
</p>
<p>Minor response
</p>
<p>Fig. 4.3 A decision tree for Example 4.18
</p>
<p>Worked example 4.18 (Radical Treatment) Imagine you have a nasty disease. There are two kinds of treatment:
</p>
<p>standard, and radical. Radical treatment might kill you (with probability 0:1); might be so damaging that doctors stop
</p>
<p>(with probability 0:3); but otherwise you will complete the treatment. If you do complete radical treatment, there could
</p>
<p>be a major response (probability 0:1) or a minor response. If you follow standard treatment, there could be a major
</p>
<p>response (probability 0:5) or a minor response, but the outcomes are less good. All this is best summarized in a decision
</p>
<p>tree (Fig. 4.3). What gives the longest expected survival time?
</p>
<p>Solution In this case, expected survival time with radical treatment is .0:1�0C0:3�6C0:6�.0:1�60C0:9�10// D
10:8 months; expected survival time without radical treatment is 0:5 � 10C 0:5 � 6 D 8 months.
</p>
<p>Working with money values is not always a good idea. For example, many people play state lotteries. The expected value
</p>
<p>of a 1 bet on a state lottery is well below 1&mdash;why do people play? It&rsquo;s easy to assume that all players just can&rsquo;t do sums, but
</p>
<p>many players are well aware that the expected value of a bet is below the cost. It seems to be the case that people value money
</p>
<p>in a way that doesn&rsquo;t depend linearly on the amount of money. So, for example, people may value a million dollars rather
</p>
<p>more than a million times the value they place on one dollar. If this is true, we need some other way to keep track of value;
</p>
<p>this is sometimes called utility. It turns out to be quite hard to know how people value things, and there is quite good evidence
</p>
<p>that (a) human utility is complicated and (b) it is difficult to explain human decision making in terms of expected utility.</p>
<p/>
</div>
<div class="page"><p/>
<p>108 4 Random Variables and Expectations
</p>
<p>Worked example 4.19 (Human Utility is Not Expected Payoff) Here are four games:
</p>
<p>&bull; Game 1: The player is given 1. A biased coin is flipped, and the money is taken back with probability p; otherwise,
</p>
<p>the player keeps it.
</p>
<p>&bull; Game 2: The player stakes 1, and a fair coin is flipped; if the coin comes up heads, the player gets r and the stake
</p>
<p>back, but otherwise loses the original stake.
</p>
<p>&bull; Game 3: The player bets nothing; a biased coin is flipped, and if it comes up heads (probability q), the player gets
</p>
<p>1e6.
</p>
<p>&bull; Game 4: The player stakes 1000; a fair coin is flipped, and if it comes up heads, the player gets s and the stake
</p>
<p>back, but otherwise loses the original stake.
</p>
<p>In particular, what happens if r D 3 � 2p and q D .1 � p/=1e6 and s D 2 � 2pC 1000?
</p>
<p>Solution Game 1 has expected value .1 � p/1. Game 2 has expected value .1=2/.r � 1/. Game 3 has expected value
q1e6. Game 4 has expected value .1=2/s � 500.
</p>
<p>In the case given, each game has the same expected value. Nonetheless, people usually have decided preferences
</p>
<p>for which game they would play. Generally, 4 is unattractive (seems expensive to play); 3 seems like free money, and
</p>
<p>so a good thing; 2 might be OK but is often seen as uninteresting; and 1 is unattractive. This should suggest to you that
</p>
<p>people&rsquo;s reasoning about money and utility is not what simple expectations predict.
</p>
<p>4.5 You Should
</p>
<p>4.5.1 Remember These Definitions
</p>
<p>Discrete random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
</p>
<p>Probability distribution of a discrete random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
</p>
<p>Cumulative distribution of a discrete random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
</p>
<p>Joint probability distribution of two discrete random variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
</p>
<p>Bayes&rsquo; rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
</p>
<p>Marginal probability of a random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
</p>
<p>Independent random variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
</p>
<p>Expected value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
</p>
<p>Expectation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94
</p>
<p>Expected value of a continuous random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
</p>
<p>Expectation of a continuous random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
</p>
<p>Mean or expected value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
</p>
<p>Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
</p>
<p>Covariance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
</p>
<p>Standard deviation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
</p>
<p>Markov&rsquo;s inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
</p>
<p>Chebyshev&rsquo;s inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
</p>
<p>Indicator functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
</p>
<p>Weak Law of Large Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
</p>
<p>4.5.2 Remember These Terms
</p>
<p>probability mass function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
</p>
<p>probability density function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
</p>
<p>pdf . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 109
</p>
<p>density . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
</p>
<p>normalizing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
</p>
<p>normalizing constant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
</p>
<p>standard deviation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
</p>
<p>descriptive statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
</p>
<p>empirical distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
</p>
<p>trial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
</p>
<p>sample . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
</p>
<p>realization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
</p>
<p>independent identically distributed samples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
</p>
<p>iid samples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
</p>
<p>indicator function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
</p>
<p>odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
</p>
<p>decision tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
</p>
<p>utility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
</p>
<p>4.5.3 Use and Remember These Facts
</p>
<p>Properties of probability density functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
</p>
<p>Expectations are linear . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
</p>
<p>Properties of variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
</p>
<p>Variance, a useful expression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
</p>
<p>Covariance, useful expression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
</p>
<p>Independent random variables have zero covariance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
</p>
<p>Variance as covariance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
</p>
<p>4.5.4 Remember These Points
</p>
<p>4.5.5 Be Able to
</p>
<p>&bull; Interpret notation for joint and conditional probability for random variables; in particular, understand notation such as:
</p>
<p>P.fXg/, P.fX D xg/, p.x/, p.x; y/, p.xjy/
&bull; Interpret a probability density function p.x/ as P.fX 2 Œx; xC dx&#141;g/.
&bull; Interpret the expected value of a discrete random variable.
</p>
<p>&bull; Interpret the expected value of a continuous random variable.
</p>
<p>&bull; Compute expected values of random variables for straightforward cases.
</p>
<p>&bull; Write down expressions for mean, variance and covariance for random variables.
</p>
<p>&bull; Write out a decision tree.
</p>
<p>&bull; Exploit the weak law of large numbers.
</p>
<p>Problems
</p>
<p>Joint and Conditional Probability for RandomVariables
</p>
<p>4.1 A roulette wheel has one zero. Write X for the random variable representing the number that will come up on the wheel.
</p>
<p>What is the probability distribution of X?
</p>
<p>4.2 Define a random variable X by the following procedure. Draw a card from a standard deck of playing cards. If the card
</p>
<p>is knave, queen, or king, then X D 11. If the card is an ace, then X D 1; otherwise, X is the number of the card (i.e. two
through ten). Now define a second random variable Y by the following procedure. When you evaluate X, you look at the
</p>
<p>color of the card. If the card is red, then Y D X � 1; otherwise, Y D X C 1.</p>
<p/>
</div>
<div class="page"><p/>
<p>110 4 Random Variables and Expectations
</p>
<p>(a) What is P.fX � 2g/?
(b) What is P.fX � 10g/?
(c) What is P.fX � Yg/?
(d) What is the probability distribution of Y � X?
(e) What is P.fY � 12g?
</p>
<p>4.3 Define a random variable by the following procedure. Flip a fair coin. If it comes up heads, the value is 1. If it comes up
</p>
<p>tails, roll a die: if the outcome is 2 or 3, the value of the random variable is 2. Otherwise, the value is 3.
</p>
<p>(a) What is the probability distribution of this random variable?
</p>
<p>(b) What is the cumulative distribution of this random variable?
</p>
<p>4.4 Define three random variables, X, Y and Z by the following procedure. Roll a six-sided die and a four-sided die. Now
</p>
<p>flip a coin. If the coin comes up heads, then X takes the value of the six-sided die and Y takes the value of the four-sided die.
</p>
<p>Otherwise, X takes the value of the four-sided die and Y takes the value of the six-sided die. Z always takes the value of the
</p>
<p>sum of the dice.
</p>
<p>(a) What is P.X/, the probability distribution of this random variable?
</p>
<p>(b) What is P.X;Y/, the joint probability distribution of these two random variables?
</p>
<p>(c) Are X and Y independent?
</p>
<p>(d) Are X and Z independent?
</p>
<p>4.5 Define two random variables X and Y by the following procedure. Flip a fair coin; if it comes up heads, then X D 1,
otherwise X D �1. Now roll a six-sided die, and call the value U. We define Y D U C X.
</p>
<p>(a) What is P.YjX D 1/?
(b) What is P.XjY D 0/?
(c) What is P.XjY D 7/?
(d) What is P.XjY D 3/?
(e) Are X and Y independent?
</p>
<p>4.6 Magic the Gathering is a popular card game. Cards can be land cards, or other cards. We consider a game with two
</p>
<p>players. Each player has a deck of 40 cards. Each player shuffles their deck, then deals seven cards, called their hand. The
</p>
<p>rest of each player&rsquo;s deck is called their library. Assume that player one has 10 land cards in their deck and player two has
</p>
<p>20. Write L1 for the number of lands in player one&rsquo;s hand and L2 for the number of lands in player two&rsquo;s hand. Write Lt for
</p>
<p>the number of lands in the top 10 cards of player one&rsquo;s library.
</p>
<p>(a) Write S D L1 C L2. What is P.fS D 0g/?
(b) Write D D L1 � L2. What is P.fD D 0g/?
(c) What is the probability distribution for L1?
</p>
<p>(d) Write out the probability distribution for P.L1jLt D 10/.
(e) Write out the probability distribution P.L1jLt D 5/.
</p>
<p>Continuous RandomVariables
</p>
<p>4.7 A continuous random variable has probability density function p.x/ which is proportional to g.x/, where
</p>
<p>g.x/ D
</p>
<p>8
</p>
<p>&lt;
</p>
<p>:
</p>
<p>0 if x &lt; ��
2
</p>
<p>0 if x &gt; �
2
</p>
<p>cos.x/ otherwise
</p>
<p>:</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 111
</p>
<p>Write c for the constant of proportionality, so that p.x/ D cg.x/.
</p>
<p>(a) What is c? (you can look up the integral if you want)
</p>
<p>(b) What is P.fX � 0g/ (i.e. the probability you will observe a value greater than 0)? (you can look up the integral if you
want)
</p>
<p>(c) What is P.fjX j� 1g/? (you can look up the integral if you want)
</p>
<p>4.8 There is some (small!) voltage over the terminals of a warm resistor caused by noise (electrons moving around in the
</p>
<p>heat and banging into one another). This is a good example of a continuous random variable, and we can assume there is
</p>
<p>some probability density function for it, say p.x/. We assume that p.x/ has the property that
</p>
<p>lim
�!0
</p>
<p>Z vC�
</p>
<p>v��
p.x/dx D 0
</p>
<p>which is what you&rsquo;d expect for any function you&rsquo;re likely to have dealt with. Now imagine I define a new random variable
</p>
<p>by the following procedure: I flip a coin; if it comes up heads, I report 0; if tails, I report the voltage over the resistor.
</p>
<p>This random variable, u, has a probability 1/2 of taking the value 0, and 1/2 of taking a value from p.x/. Write this random
</p>
<p>variable&rsquo;s probability density function q.u/.
</p>
<p>(a) Show that
</p>
<p>lim
�!0
</p>
<p>Z �
</p>
<p>��
q.u/du D 1
</p>
<p>2
</p>
<p>(b) Explain why this is odd behavior.
</p>
<p>Expected Values
</p>
<p>4.9 Magic the Gathering is a popular card game. Cards can be land cards, or other cards. We consider a game with two
</p>
<p>players. Each player has a deck of 40 cards. Each player shuffles their deck, then deals seven cards, called their hand. The
</p>
<p>rest of each player&rsquo;s deck is called their library. Assume that player one has 10 land cards in their deck and player two has
</p>
<p>20. Write L1 for the number of lands in player one&rsquo;s hand and L2 for the number of lands in player two&rsquo;s hand. Write Lt for
</p>
<p>the number of lands in the top 10 cards of player one&rsquo;s library.
</p>
<p>(a) What is EŒL1&#141;?
</p>
<p>(b) What is EŒL2&#141;?
</p>
<p>(c) What is varŒL1&#141;?
</p>
<p>4.10 A simple coin game is as follows: we have a box, which starts empty. P1 flips a fair coin. If it comes up heads, P2 gets
</p>
<p>the contents of the box, and the game ends. If it comes up tails, P1 puts a dollar in the box and they flip again; this repeats
</p>
<p>until it comes up heads
</p>
<p>(a) With what probability will P2 win exactly 10 units?
</p>
<p>(b) Write S1 D
P1
</p>
<p>iD0 r
i. Show that .1 � r/S1 D 1, so that
</p>
<p>S1 D
1
</p>
<p>1 � r
</p>
<p>(c) Show that
1
X
</p>
<p>iD0
iri D .
</p>
<p>1
X
</p>
<p>iD1
ri/C r.
</p>
<p>1
X
</p>
<p>iD1
ri/C r2.
</p>
<p>1
X
</p>
<p>iD1
ri/C : : :
</p>
<p>(look carefully at the limits of the sums!) and so show that
</p>
<p>1
X
</p>
<p>iD0
iri D r
</p>
<p>.1 � r/2 :</p>
<p/>
</div>
<div class="page"><p/>
<p>112 4 Random Variables and Expectations
</p>
<p>(d) What is the expected value of the game? (you may find the results of the two previous subexercises helpful; they&rsquo;re not
</p>
<p>there just for show).
</p>
<p>(e) How much should P2 pay to play, to make the game fair?
</p>
<p>4.11 A simple card game is as follows. P1 pays a stake of 1 to play. P1 and P2 then each draw a card. If both cards are the
</p>
<p>same color, P2 keeps the stake and the game ends. If they are different colors, P2 pays P1 the stake and 1 extra (a total of
</p>
<p>2).
</p>
<p>(a) What is the expected value of the game to P1?
</p>
<p>(b) P2 modifies the game, as follows. If both cards are court cards (that is, knave, queen, king), then P2 keeps the stake and
</p>
<p>the game ends; otherwise, the game works as before. Now what is the expected value of the game to P1?
</p>
<p>4.12 A coin game that is occasionally played is &ldquo;odd one out&rdquo;. In this game, there are rounds. In a round, each person flips
</p>
<p>a coin. There is an odd person out in that round if all but one have H and the other has T, OR all but one have T and the other
</p>
<p>has H.
</p>
<p>(a) Three people play one round. What is the probability that there is an odd person out?
</p>
<p>(b) Now four people play one round. What is the probability that there is an odd person out?
</p>
<p>(c) Five people play until there is an odd person out. What is the expected number of rounds that they will play? (you can
</p>
<p>save yourself quite a lot of calculation by reading Sect. 5.1.3, if you don&rsquo;t mind skipping ahead a bit).
</p>
<p>Mean, Variance and Covariance
</p>
<p>4.13 Show that varŒkX&#141; D k2varŒX&#141;.
</p>
<p>4.14 Show that if X and Y are independent random variables, then varŒX C Y&#141; D varŒX&#141;C varŒY&#141;. You will find it helpful
to remember that, for X and Y independent, EŒXY&#141; D EŒX&#141;EŒY&#141;.
</p>
<p>Expectations and Descriptive Statistics
</p>
<p>4.15 We have a dataset fxg of N numbers, where the i&rsquo;th number is xi. Write X for the random variable that takes the i&rsquo;th
value with probability 1=N, and every other value with zero probability; write P.X/ for the probability distribution of that
</p>
<p>random variable.
</p>
<p>(a) Show that
</p>
<p>mean .fxg/ D EP.X/ŒX&#141;:
</p>
<p>(b) Show that
</p>
<p>var .fxg/ D varŒX&#141;:
</p>
<p>(c) Choose some function f . Write ff g for the dataset whose i&rsquo;th item is f .xi/. Write F for the random variable f .X/. Show
that
</p>
<p>mean .ff g/ D EŒF&#141; D EP.X/Œf &#141;:
</p>
<p>Markov and Chebyshev Inequalities
</p>
<p>4.16 The random variable X takes the values �2, �1, 0, 1, 2, but has an unknown probability distribution. You know that
EŒjjXjj&#141; D 0:2. Use Markov&rsquo;s inequality to give a lower bound on P.fX D 0g/. Hint: Notice that P.fX D 0g/ D 1�P.fjjXjj D
1g/ � P.fjjXjjg D 2/.</p>
<p/>
</div>
<div class="page"><p/>
<p>Programming Exercises 113
</p>
<p>4.17 The random variable X takes the values 1, 2, 3, 4, 5, but has unknown probability distribution. You know that EŒX&#141; D 2
and var .fXg/ D 0:01. Use Chebyshev&rsquo;s inequality to give a lower bound on P.fX D 2g/.
</p>
<p>4.18 You have a biased random number generator. This generator produces a random number with mean value �1, and
standard deviation 0.5. Write A for the event that the number generator produces a non-negative number. Use Chebyshev&rsquo;s
</p>
<p>inequality to bound P.A/.
</p>
<p>4.19 You observe a random number generator. You know that it can produce the values �2;�1, 0, 1, or 2. You are told that
it has been adjusted so that: (1) the mean value it produces is zero and; (2) the standard deviation of the numbers it produces
</p>
<p>is 1.
</p>
<p>(a) Write A for the event that the number generator produces a number that is not 0. Use Chebyshev&rsquo;s inequality to bound
</p>
<p>P.A/.
</p>
<p>(b) Write B for the event that the number generator produces �2 or 2. Use Chebyshev&rsquo;s inequality to bound P.B/.
</p>
<p>Using Expectations
</p>
<p>4.20 Two players P1 and P2 agree to play the following game. Each puts up a stake of 1 unit. They will
</p>
<p>play seven rounds, where each round involves flipping a fair coin. If the coin comes up H, P1 wins the
</p>
<p>round, otherwise P2 wins. The first player to win four rounds gets both stakes. After four rounds, P1 has
</p>
<p>won three rounds and P2 has won one round, but they have to stop. What is the fairest way to divide the
</p>
<p>stakes?
</p>
<p>4.21 Imagine we have a game with two players, who are playing for a stake. There are no draws, the winner gets the whole
</p>
<p>stake, and the loser gets nothing. The game must end early. We decide to give each player the expected value of the game for
</p>
<p>that player, from that state. Show that the expected values add up to the value of the stake (i.e. there won&rsquo;t be too little or too
</p>
<p>much money in the stake.
</p>
<p>Programming Exercises
</p>
<p>4.22 An airline company runs a flight that has six seats. Each passenger who buys a ticket has a probability p of turning up
</p>
<p>for the flight. These events are independent.
</p>
<p>(a) The airline sells six tickets. What is the expected number of passengers, if p D 0:9?
(b) How many tickets should the airline sell to ensure that the expected number of passengers is greater than six, if p D 0:7?
</p>
<p>Hint: The easiest way to do this is to write a quick program that computes the expected value of passengers that turn up
</p>
<p>for each the number of tickets sold, then search the number of tickets sold.
</p>
<p>4.23 An airline company runs a flight that has 10 seats. Each passenger who buys a ticket has a probability p of turning up
</p>
<p>for the flight. The gender of the passengers is not known until they turn up for a flight, and women buy tickets with the same
</p>
<p>frequency that men do. The pilot is eccentric, and will not fly unless at least two women turn up.
</p>
<p>(a) How many tickets should the airline sell to ensure that the expected number of passengers that turn up is greater than 10?
</p>
<p>(b) The airline sells 10 tickets. What is the expected number of passengers on the aircraft, given that it flies? (i.e. that at least
</p>
<p>two women turn up). Estimate this value with a simulation.
</p>
<p>4.24 We will investigate the weak law of large numbers using simulations. Write X for a random variable that takes the
</p>
<p>values -1 and 1 with equal probability, and no other value. Clearly, EŒX&#141; D 0. Write X.N/ for the random variable obtained
by drawing N samples of X, then averaging them.</p>
<p/>
</div>
<div class="page"><p/>
<p>114 4 Random Variables and Expectations
</p>
<p>(a) For each N in f1; 10; 20; : : : ; 100g, simulate 1000 samples of X.N/. Produce a graph showing a boxplot of these samples
for each N, plotted against N. What do you notice?
</p>
<p>(b) For each N in f1; 10; 20; : : : ; 100g, simulate 1000 samples of X.N/. Produce a graph showing the variance of these samples
as a function of 1=N. What do you notice?
</p>
<p>(c) Show that the normal approximation of a binomial distribution suggests that about 68% of the observed values of X.N/
</p>
<p>lie in the range
�
</p>
<p>� 1
2
p
N
;
</p>
<p>1
</p>
<p>2
p
N
</p>
<p>�
</p>
<p>:
</p>
<p>(d) For each N in f1; 10; 20; : : : ; 100g, simulate 1000 samples of X.N/. For each N, compute the 84% quantile (q84%) and the
16% quantile (q16%). Now compute
</p>
<p>˛ D max.jq84%j; jq16%j/:
</p>
<p>This ˛ should have the property that about 68% of the observed values lie in the range Œ�˛; ˛&#141;. Now plot 1=˛2 as a
function of N. What do you notice?</p>
<p/>
</div>
<div class="page"><p/>
<p>5Useful Probability Distributions
</p>
<p>We will use probability as a tool to resolve practical questions about data. Here are important example questions. We could
</p>
<p>ask what process produced the data? For example, I observe a set of independent coin flips. I would now like to know
</p>
<p>the probability of observing a head when the coin is flipped. We could ask what sort of data can we expect in the future?
</p>
<p>For example, what will be the outcome of the next election? Answering this requires collecting information about voters,
</p>
<p>preferences, and the like, then using it to build a model that predicts the outcome. We could ask what labels should we attach
</p>
<p>to unlabelled data? For example, we might see a large number of credit card transactions, some known to be legitimate and
</p>
<p>others known to be fraudulent. We now see a new transaction: is it legitimate? We could ask is an effect easily explained by
</p>
<p>chance variations, or is it real? For example, a medicine appears to help patients with a disease. Is there a real effect, or is
</p>
<p>it possible that by chance the patients we tested the medicine on felt better?
</p>
<p>These questions do not lend themselves to &ldquo;right&rdquo; answers. Instead, we will need to produce estimates and perhaps some
</p>
<p>measure of our confidence in those estimates. Sensible answers to questions like these have great practical value. Producing
</p>
<p>sensible answers to these questions requires some form of probability model. In this chapter, I describe the properties of
</p>
<p>some probability distributions that are used again and again in model building.
</p>
<p>5.1 Discrete Distributions
</p>
<p>5.1.1 The Discrete Uniform Distribution
</p>
<p>Assume we have a random variable that can take one of k different values. We can relabel these values 1; : : : ; k without
</p>
<p>losing anything significant. If each of these values has the same probability (and all others have probability zero), then
</p>
<p>the probability distribution is the discrete uniform distribution. We have seen this distribution before, numerous times. For
</p>
<p>example, I define a random variable by the number that shows face-up on the throw of a fair die. This has a uniform
</p>
<p>distribution. As another example, write the numbers 1&ndash;52 on the face of each card of a standard deck of playing cards. The
</p>
<p>number on the face of the first card drawn from a well-shuffled deck is a random variable with a uniform distribution.
</p>
<p>Definition 5.1 (Uniform Random Variable, Discrete) A random variable has the discrete uniform distribution if it
</p>
<p>takes each of k values with the same probability 1=k, and all other values with probability zero.
</p>
<p>One can construct expressions for the mean and variance of a discrete uniform distribution, but they&rsquo;re not usually much
</p>
<p>use (too many terms, not often used). Keep in mind that if two random variables have a uniform distribution, their sum and
</p>
<p>difference will not (recall Example 4.3).
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_5
</p>
<p>115</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_5">https://doi.org/10.1007/978-3-319-64410-3_5</a></div>
</div>
<div class="page"><p/>
<p>116 5 Useful Probability Distributions
</p>
<p>5.1.2 Bernoulli RandomVariables
</p>
<p>A Bernoulli random variable models a biased coin with probability p of coming up heads in any one flip.
</p>
<p>Definition 5.2 (Bernoulli Random Variable) A Bernoulli random variable takes the value 1 with probability p and
</p>
<p>0 with probability 1 � p. This is a model for a coin toss, among other things.
</p>
<p>Useful Facts 5.1 (Mean and Variance of a Bernoulli Random Variable)
</p>
<p>A Bernoulli random variable that takes the value 1 with probability p has:
</p>
<p>1. mean p;
</p>
<p>2. variance p.1 � p/.
</p>
<p>5.1.3 The Geometric Distribution
</p>
<p>We have a biased coin. The probability it will land heads up, P.fHg/ is given by p. We flip this coin until the first head
appears. The number of flips required is a discrete random variable which takes integer values greater than or equal to one,
</p>
<p>which we shall call X. To get n flips, we must have n � 1 tails followed by 1 head. This event has probability .1 � p/.n�1/p.
We can now write out the probability distribution that n flips are required.
</p>
<p>Definition 5.3 (Geometric Distribution) The geometric distribution is a probability distribution on positive integers
</p>
<p>n (i.e. n &gt; 0). It has the form
</p>
<p>P.fX D ng/ D .1 � p/.n�1/p:
</p>
<p>for 0 � p � 1 and n � 1 (for other n the distribution is zero). p is called the parameter of the distribution.
</p>
<p>Notice that the geometric distribution is non-negative everywhere. It is straightforward to show that it sums to one, and so
</p>
<p>is a probability distribution (exercises).
</p>
<p>Useful Facts 5.2 (Mean and Variance of a Geometric Distribution)
</p>
<p>A geometric distribution with parameter p has
</p>
<p>1. mean 1
p
;
</p>
<p>2. variance 1�p
p2
</p>
<p>.
</p>
<p>It should be clear that this model isn&rsquo;t really about coins, but about repeated trials. The trial could be anything that has
</p>
<p>some probability of failing. Each trial is independent, and the rule for repeating is that you keep trying until the first success.
</p>
<p>Textbooks often set exercises involving missiles and aircraft; I&rsquo;ll omit these on grounds of taste.
</p>
<p>5.1.4 The Binomial Probability Distribution
</p>
<p>Assume we have a biased coin with probability p of coming up heads in any one flip. The binomial probability distribution
</p>
<p>gives the probability that it comes up heads h times in N flips. Recall there are
</p>
<p>�
</p>
<p>N
</p>
<p>h
</p>
<p>�
</p>
<p>D NŠ
hŠ.N � h/Š</p>
<p/>
</div>
<div class="page"><p/>
<p>5.1 Discrete Distributions 117
</p>
<p>outcomes of N coin flips that have h heads. These outcomes are disjoint, and each has probability ph.1� p/.N�h/. As a result,
we must have the probability distribution below.
</p>
<p>Definition 5.4 (Binomial Distribution) In N independent repetitions of an experiment with a binary outcome (ie
</p>
<p>heads or tails; 0 or 1; and so on) with P.H/ D p and P.T/ D 1 � p, the probability of observing a total of h H&rsquo;s and
.N � h/T&rsquo;s is
</p>
<p>Pb.hIN; p/ D
�
</p>
<p>N
</p>
<p>h
</p>
<p>�
</p>
<p>ph.1 � p/.N�h/
</p>
<p>as long as 0 � h � N; in any other case, the probability is zero.
</p>
<p>The binomial distribution really is a probability distribution. For 0 � p � 1, it is clearly non-negative for any i. It also
sums to one. Write Pb.iIN; p/ for the binomial distribution that one observes i H&rsquo;s in N trials. Then, by pattern matching to
the binomial theorem, we have
</p>
<p>.pC .1 � p//N D
N
X
</p>
<p>iD0
Pb.iIN; p/ D 1:
</p>
<p>The binomial distribution satisfies a recurrence relation. You can get h heads in N flips either by having h� 1 heads in N � 1
flips, then flipping another head, or by having h heads in N flips then flipping a tail. This means that
</p>
<p>Pb.hIN; p/ D pPb.h � 1IN � 1; p/
</p>
<p>C.1 � p/Pb.hIN � 1; p/
</p>
<p>(exercises).
</p>
<p>Useful Facts 5.3 (Mean and Variance of the Binomial Distribution)
</p>
<p>The binomial distribution
</p>
<p>Pb.hIN; p/ D
�
</p>
<p>N
</p>
<p>h
</p>
<p>�
</p>
<p>ph.1 � p/.N�h/
</p>
<p>has:
</p>
<p>1. mean Np;
</p>
<p>2. variance Np.1 � p/.
</p>
<p>The proofs are informative, and so are not banished to the exercises.
</p>
<p>Property 5.1 Mean and variance of binomial distribution.
</p>
<p>Proposition The mean of the binomial distribution Pb.hIN; p/ is Np. The variance is Np.1 � p/.
</p>
<p>Proof Write X for a random variable with distribution Pb.hIN; p/. Notice that the number of heads in N coin tosses
can be obtained by adding the number of heads in each toss. Write Yi for the Bernoulli random variable representing
</p>
<p>the i&rsquo;th toss. If the coin comes up heads, Yi D 1, otherwise Yi D 0. The Yi are independent. Now
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>118 5 Useful Probability Distributions
</p>
<p>EŒX&#141; D E
</p>
<p>2
</p>
<p>4
</p>
<p>N
X
</p>
<p>jD1
Yi
</p>
<p>3
</p>
<p>5
</p>
<p>D
N
X
</p>
<p>jD1
EŒYi&#141;
</p>
<p>D NEŒY1&#141; because the Yi are independent
</p>
<p>D Np:
</p>
<p>The variance is easy, too. Each coin toss is independent, so the variance of the sum of coin tosses is the sum of the
</p>
<p>variances. This gives
</p>
<p>varŒX&#141; D var
</p>
<p>2
</p>
<p>4
</p>
<p>N
X
</p>
<p>jD1
Yi
</p>
<p>3
</p>
<p>5
</p>
<p>D NvarŒY1&#141;
</p>
<p>D Np.1 � p/
</p>
<p>5.1.5 Multinomial Probabilities
</p>
<p>The binomial distribution describes what happens when a coin is flipped multiple times. But we could toss a die multiple
</p>
<p>times too. Assume this die has k sides, and we toss it N times. The distribution of outcomes is known as the multinomial
</p>
<p>distribution.
</p>
<p>We can guess the form of the multinomial distribution in rather a straightforward way. The die has k sides. We toss the die
</p>
<p>N times. This gives us a sequence of N numbers. Each toss of the die is independent. Assume that side 1 appears n1 times,
</p>
<p>side 2 appears n2 times, : : : side k appears nk times. Any single sequence with this property will appear with probability
</p>
<p>p
n1
1 p
</p>
<p>n2
2 : : : p
</p>
<p>nk
k , because the tosses are independent. However, there are
</p>
<p>NŠ
</p>
<p>n1Šn2Š : : : nkŠ
</p>
<p>such sequences. Using this reasoning, we arrive at the distribution below
</p>
<p>Definition 5.5 (Multinomial Distribution) Perform N independent repetitions of an experiment with k possible
</p>
<p>outcomes. The i&rsquo;th such outcome has probability pi. The probability of observing outcome 1 n1 times, outcome 2 n2
times, etc. (where n1 C n2 C n3 C : : :C nk D N) is
</p>
<p>Pm.n1; : : : ; nkIN; p1; : : : ; pk/ D
NŠ
</p>
<p>n1Šn2Š : : : nkŠ
p
n1
1 p
</p>
<p>n2
2 : : : p
</p>
<p>nk
k :
</p>
<p>I don&rsquo;t recall ever using the mean and variance of a multinomial distribution, so they&rsquo;re not in a box. If you happen to
</p>
<p>need this information, you can derive it with using the reasoning of proof 5.1.
</p>
<p>5.1.6 The Poisson Distribution
</p>
<p>Assume we are interested in counts that occur in an interval of time (e.g. within a particular hour). Because they are counts,
</p>
<p>they are non-negative and integer valued. We know these counts have two important properties. First, they occur with some</p>
<p/>
</div>
<div class="page"><p/>
<p>5.1 Discrete Distributions 119
</p>
<p>fixed average rate. Second, an observation occurs independent of the interval since the last observation. Then the Poisson
</p>
<p>distribution is an appropriate model.
</p>
<p>There are numerous such cases. For example, the marketing phone calls you receive during the day time are likely to
</p>
<p>be well modelled by a Poisson distribution. They come at some average rate&mdash;perhaps 5 a day as I write, during the last
</p>
<p>phases of an election year&mdash;and the probability of getting one clearly doesn&rsquo;t depend on the time since the last one arrived.
</p>
<p>Classic examples include the number of Prussian soldiers killed by horse-kicks each year; the number of calls arriving at a
</p>
<p>call center each minute; the number of insurance claims occurring in a given time interval (outside of a special event like a
</p>
<p>hurricane, etc.).
</p>
<p>Definition 5.6 (Poisson Distribution) A non-negative, integer valued random variable X has a Poisson distribution
</p>
<p>when its probability distribution takes the form
</p>
<p>P.fX D kg/ D �
ke��
</p>
<p>kŠ
;
</p>
<p>where � &gt; 0 is a parameter often known as the intensity of the distribution.
</p>
<p>Notice that the Poisson distribution is a probability distribution, because it is non-negative and because
</p>
<p>1
X
</p>
<p>iD0
</p>
<p>�i
</p>
<p>iŠ
D e�
</p>
<p>so that
1
X
</p>
<p>kD0
</p>
<p>�ke��
</p>
<p>kŠ
D 1
</p>
<p>Useful Facts 5.4 (Mean and Variance of the Poisson Distribution)
</p>
<p>A Poisson distribution with intensity � has:
</p>
<p>1. mean �;
</p>
<p>2. variance � (no, that&rsquo;s not an accidentally repeated line or typo).
</p>
<p>I described the Poisson distribution as a natural model for counts of randomly distributed points along a time axis. But it
</p>
<p>doesn&rsquo;t really matter that this is a time axis&mdash;it could be a space axis instead. For example, you could take a length of road,
</p>
<p>divide it into even intervals, then count the number of road-killed animals is in each interval. If the location of each animal is
</p>
<p>independent of the location of any other animal, then you could expect a Poisson model to apply to the count data. Assume
</p>
<p>that the Poisson model that best describes the data has parameter �. One property of such models is that if you doubled the
</p>
<p>length of the intervals, then the resulting dataset would be described by a Poisson model with parameter 2�; similarly, if you
</p>
<p>halved the length of the intervals, the best model would have parameter �=2. This corresponds to our intuition about such
</p>
<p>data; roughly, the number of road-killed animals in two miles of road should be twice the number in one mile of road. This
</p>
<p>property means that no pieces of the road are &ldquo;special&rdquo;&mdash;each behaves the same as the other.
</p>
<p>We can build a really useful model of spatial randomness by observing this fact and generalizing very slightly. A Poisson
</p>
<p>point process with intensity � is a set of random points with the property that the number of points in an interval of length
</p>
<p>s is a Poisson random variable with parameter �s. Notice how this captures our intuition that if points are &ldquo;very randomly&rdquo;
</p>
<p>distributed, there should be twice as many of them in an interval that is twice as long.
</p>
<p>This model is easily, and very usefully, extended to points on the plane, on surfaces, and in 3D. In each case, the process
</p>
<p>is defined on a domain D (which has to meet some very minor conditions that are of no interest to us). The number of points
</p>
<p>in any subset s of D is a Poisson random variable, with intensity �m.s/, where m.s/ is the area (resp. volume) of s. These
</p>
<p>models are useful, because they capture the property that (a) the points are random and (b) the probability you find a point</p>
<p/>
</div>
<div class="page"><p/>
<p>120 5 Useful Probability Distributions
</p>
<p>doesn&rsquo;t depend on where you are. You could reasonably believe models like this apply to, say, dead flies on windscreens;
</p>
<p>the places where you find acorns at the foot of an oak tree; the distribution of cowpats in a field; the distribution of cherries
</p>
<p>in a fruitcake; and so on.
</p>
<p>5.2 Continuous Distributions
</p>
<p>5.2.1 The Continuous UniformDistribution
</p>
<p>Some continuous random variables have a natural upper bound and a natural lower bound but otherwise we know nothing
</p>
<p>about them. For example, imagine we are given a coin of unknown properties by someone who is known to be a skillful
</p>
<p>maker of unfair coins. The manufacturer makes no representations as to the behavior of the coin. The probability that this
</p>
<p>coin will come up heads is a random variable, about which we know nothing except that it has a lower bound of zero and an
</p>
<p>upper bound of one. If we know nothing about a random variable apart from the fact that it has a lower and an upper bound,
</p>
<p>then a uniform distribution is a natural model. A continuous random variable whose probability distribution is the uniform
</p>
<p>distribution is often called a uniform random variable.
</p>
<p>Definition 5.7 (Uniform Distribution, Continuous) Write l for the lower bound and u for the upper bound. The
</p>
<p>probability density function for the uniform distribution is
</p>
<p>p.x/ D
</p>
<p>8
</p>
<p>&lt;
</p>
<p>:
</p>
<p>0 x &lt; l
</p>
<p>1=.u � l/ l � x � u
0 x &gt; u
</p>
<p>5.2.2 The Beta Distribution
</p>
<p>It&rsquo;s hard to explain now why the Beta (or ˇ) distribution is useful, but it will come in useful later (Sect. 9.2.1). The Beta
</p>
<p>distribution is a probability distribution for a continuous random variable x in the range 0 � x � 1. There are two parameters,
˛ &gt; 0 and ˇ &gt; 0. Recall the definition of the &#128; function from Sect. 15.2.
</p>
<p>Definition 5.8 (Beta Distribution) A continuous random variable x in the range 0 � x � 1 has a Beta distribution if
its probability density function has the form
</p>
<p>Pˇ.xj˛; ˇ/ D
&#128;.˛ C ˇ/
&#128;.˛/&#128;.ˇ/
</p>
<p>x.˛�1/.1 � x/.ˇ�1/:
</p>
<p>where ˛ &gt; 0 and ˇ &gt; 0.
</p>
<p>From the expression for the Beta distribution, you can see that:
</p>
<p>&bull; Pˇ.xj1; 1/ is a uniform distribution on the unit interval.
&bull; For ˛ &gt; 1, ˇ &gt; 1/, Pˇ.xj˛; ˇ/ has a single maximum at x D .˛ � 1/=.˛ C ˇ � 2/ (differentiate and set to zero).
&bull; Generally, as ˛ and ˇ get larger, this peak gets narrower.
</p>
<p>&bull; For ˛ D 1, ˇ &gt; 1 the largest value of Pˇ.xj˛; ˇ/ is at x D 0.
&bull; For ˛ &gt; 1, ˇ D 1 the largest value of Pˇ.xj˛; ˇ/ is at x D 1.
</p>
<p>Figure 5.1 shows plots of the probability density function of the Beta distribution for a variety of different values of ˛ and ˇ.</p>
<p/>
</div>
<div class="page"><p/>
<p>5.2 Continuous Distributions 121
</p>
<p>0 0.2 0.4 0.6 0.8 1
0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>12
</p>
<p>PDF of Beta(x) for various alpha, beta
</p>
<p>alpha: 1, beta: 1
</p>
<p>alpha: 10, beta: 10
</p>
<p>alpha: 50, beta: 50
</p>
<p>0 0.2 0.4 0.6 0.8 1
0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>12
</p>
<p>PDF of Beta(x) for various alpha, beta
</p>
<p>alpha: 1, beta: 10
</p>
<p>alpha: 10, beta: 1
</p>
<p>alpha: 3, beta: 15
</p>
<p>alpha: 20, beta: 100
</p>
<p>Fig. 5.1 Probability density functions for the Beta distribution with a variety of different choices of ˛ and ˇ
</p>
<p>Useful Facts 5.5 (Mean and Variance of a Beta Distribution)
</p>
<p>A Beta distribution with parameters ˛, ˇ has:
</p>
<p>1. mean ˛
˛Cˇ I
</p>
<p>2. variance ˛ˇ
.˛Cˇ/2.˛CˇC1/ :
</p>
<p>5.2.3 The GammaDistribution
</p>
<p>The Gamma (or &#13; ) distribution will also come in useful later on (Sect. 9.2.1). The Gamma distribution is a probability
</p>
<p>distribution for a non-negative continuous random variable x � 0. There are two parameters, ˛ &gt; 0 and ˇ &gt; 0.
</p>
<p>Definition 5.9 (Gamma Distribution) A non-negative continuous random variable x has a Gamma distribution if its
</p>
<p>probability density function is
</p>
<p>P&#13; .xj˛; ˇ/ D
ˇ˛
</p>
<p>&#128;.˛/
x.˛�1/e�ˇx:
</p>
<p>where ˛ &gt; 0 and ˇ &gt; 0.
</p>
<p>Figure 5.2 shows plots of the probability density function of the Gamma distribution for a variety of different values of ˛
</p>
<p>and ˇ.
</p>
<p>Useful Facts 5.6 (Mean and Variance of the Gamma Distribution)
</p>
<p>A Gamma distribution with parameters ˛, ˇ has:
</p>
<p>1. mean ˛
ˇ
I
</p>
<p>2. variance ˛
ˇ2
:</p>
<p/>
</div>
<div class="page"><p/>
<p>122 5 Useful Probability Distributions
</p>
<p>0 2 4 6 8 10
0
</p>
<p>0.5
</p>
<p>1
</p>
<p>1.5
</p>
<p>2
</p>
<p>PDF of Gamma(x) for various alpha, beta
</p>
<p>alpha: 1, beta: 1
</p>
<p>alpha: 5, beta: 5
</p>
<p>alpha: 15, beta: 15
</p>
<p>0 2 4 6 8 10
0
</p>
<p>0.5
</p>
<p>1
</p>
<p>1.5
</p>
<p>2
</p>
<p>PDF of Gamma(x) for various alpha, beta
</p>
<p>alpha: 1, beta: 5
</p>
<p>alpha: 5, beta: 1
</p>
<p>alpha: 15, beta: 5
</p>
<p>Fig. 5.2 Probability density functions for the Gamma distribution with a variety of different choices of ˛ and ˇ
</p>
<p>5.2.4 The Exponential Distribution
</p>
<p>Assume we have an infinite interval of time or space, with points distributed on it. Assume these points form a Poisson
</p>
<p>point process, as above. For example, we might consider the times at which email arrives; or the times at which phone calls
</p>
<p>arrive at a large telephone exchange; or the locations of roadkill on a road. The distance (or span of time) between two
</p>
<p>consecutive points is a random variable X. This random variable takes an exponential distribution, defined below. There is a
</p>
<p>single parameter, � &gt; 0. This distribution is often useful in modelling the failure of objects. We assume that failures form a
</p>
<p>Poisson process in time; then the time to the next failure is exponentially distributed.
</p>
<p>Definition 5.10 (Exponential Distribution) A continuous random variable x has an exponential distribution when
</p>
<p>its probability density function takes the form
</p>
<p>Pexp.xj�/ D
�
</p>
<p>�e��x for x � 0
0 otherwise
</p>
<p>:
</p>
<p>where � &gt; 0 is a parameter.
</p>
<p>Useful Facts 5.7 (Mean and Variance of the Exponential Distribution)
</p>
<p>An exponential distribution with parameter � has
</p>
<p>1. mean 1
�
I
</p>
<p>2. variance 1
�2
:
</p>
<p>Notice the relationship between this parameter and the parameter of the Poisson distribution. If (say) the phone calls are
</p>
<p>distributed with Poisson distribution with intensity � (per hour), then your expected number of calls per hour is �. The time
</p>
<p>between calls will be exponentially distributed with parameter �, and the expected time to the next call is 1=� (in hours).</p>
<p/>
</div>
<div class="page"><p/>
<p>5.3 The Normal Distribution 123
</p>
<p>Fig. 5.3 A plot of the
probability density function of
the standard normal distribution.
Notice how probability is
concentrated around zero, and
how there is relatively little
probability density for numbers
with large absolute values
</p>
<p>&minus;4 &minus;3 &minus;2 &minus;1 0 1 2 3 4
0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>0.4
</p>
<p>0.5
The Standard Normal Curve
</p>
<p>5.3 The Normal Distribution
</p>
<p>Many real datasets have histograms that look like a &ldquo;bump&rdquo;, and the probability density function for a normal distribution
</p>
<p>looks like a &ldquo;bump&rdquo;, too. Some of this is just an experimental fact of life. But there are important mathematical reasons that
</p>
<p>normal distributions should be common. Imagine your data is a sum of random variables (say, you are measuring the weight
</p>
<p>of a net full of fishes). Then pretty much however the original random variables are distributed, your data will be normally
</p>
<p>distributed.
</p>
<p>5.3.1 The Standard Normal Distribution
</p>
<p>Definition 5.11 (Standard Normal Distribution) The probability density function
</p>
<p>p.x/ D
�
</p>
<p>1p
2�
</p>
<p>�
</p>
<p>exp
</p>
<p>��x2
2
</p>
<p>�
</p>
<p>:
</p>
<p>is known as the standard normal distribution
</p>
<p>The first step is to plot this probability density function (Fig. 5.3). You should notice it is quite familiar from work on
</p>
<p>histograms, etc. in chapter Worked example 14.13. It has the shape of the histogram of standard normal data, or at least the
</p>
<p>shape that the histogram of standard normal data aspires to.
</p>
<p>Useful Facts 5.8 (Mean and Variance of the Standard Normal Distribution)
</p>
<p>The standard normal distribution has:
</p>
<p>1. mean 0;
</p>
<p>2. variance 1.
</p>
<p>These results are easily established by looking up (or doing!) the relevant integrals; they are relegated to the exercises.
</p>
<p>A continuous random variable is a standard normal random variable if its probability density function is a standard
</p>
<p>normal distribution.</p>
<p/>
</div>
<div class="page"><p/>
<p>124 5 Useful Probability Distributions
</p>
<p>5.3.2 The Normal Distribution
</p>
<p>Any probability density function that is a standard normal distribution in standard coordinates is a normal distribution.
</p>
<p>Now write � for the mean of a random variable and � for its standard deviation; we are saying that, if
</p>
<p>x � �
�
</p>
<p>has a standard normal distribution, then p.x/ is a normal distribution. We can work out the form of the probability density
</p>
<p>function of a general normal distribution in two steps: first, we notice that for any normal distribution, we must have
</p>
<p>p.x/ / exp
�
</p>
<p>� .x � �/
2
</p>
<p>2�2
</p>
<p>�
</p>
<p>:
</p>
<p>But, for this to be a probability density function, we must have
R1
�1 p.x/dx D 1. This yields the constant of proportionality,
</p>
<p>and we get
</p>
<p>Definition 5.12 (Normal Distribution) The probability density function
</p>
<p>p.x/ D
�
</p>
<p>1p
2��
</p>
<p>�
</p>
<p>exp
</p>
<p>��.x � �/2
2�2
</p>
<p>�
</p>
<p>:
</p>
<p>is a normal distribution.
</p>
<p>Useful Facts 5.9 (Mean and Variance of the Normal Distribution)
</p>
<p>The probability density function
</p>
<p>p.x/ D
�
</p>
<p>1p
2��
</p>
<p>�
</p>
<p>exp
</p>
<p>��.x � �/2
2�2
</p>
<p>�
</p>
<p>:
</p>
<p>has:
</p>
<p>1. mean �;
</p>
<p>2. and variance �2.
</p>
<p>These results are easily established by looking up (or doing!) the relevant integrals; they are relegated to the exercises.
</p>
<p>A continuous random variable is a normal random variable if its probability density function is a normal distribution.
</p>
<p>Notice that it is quite usual to call normal distributions gaussian distributions.
</p>
<p>5.3.3 Properties of the Normal Distribution
</p>
<p>Normal distributions are important, because one often runs into data that is well described by a normal distribution. It turns
</p>
<p>out that anything that behaves like a binomial distribution with a lot of trials&mdash;for example, the number of heads in many coin
</p>
<p>tosses; as another example, the percentage of times you get the outcome of interest in a simulation in many runs&mdash;should
</p>
<p>produce a normal distribution (Sect. 5.4). For this reason, pretty much any experiment where you perform a simulation, then
</p>
<p>count to estimate a probability or an expectation, should give you an answer that has a normal distribution.
</p>
<p>It is a remarkable and deep fact that adding many independent random variables produces a normal distribution pretty
</p>
<p>much whatever the distributions of those random variables. Because it&rsquo;s important, exciting and non-obvious, this has been
</p>
<p>proved in various forms by many major mathematicians. It was the subject of Alan Turing&rsquo;s Fellowship Thesis in 1934,</p>
<p/>
</div>
<div class="page"><p/>
<p>5.3 The Normal Distribution 125
</p>
<p>where the story goes that examiners didn&rsquo;t quite know how to react: enthusiasm for a novel and brilliant form of proof, or
</p>
<p>irritation because he didn&rsquo;t already know the theorem.
</p>
<p>I&rsquo;ve not done this in detail because it&rsquo;s a nuisance to state in detail and to prove. However, you should remember that, if
</p>
<p>you add together many random variables, each of pretty much any distribution, then the answer has a distribution close to
</p>
<p>the normal distribution. It turns out that many of the processes we observe add up subsidiary random variables. This means
</p>
<p>that you will see normal distributions very often in practice.
</p>
<p>Remember this: The central limit theorem means that, under some not very worrying technical conditions, the sum
</p>
<p>of a large number of independent random variables will be very close to normal. The details are beyond our reach
</p>
<p>technically; the fact is extremely important.
</p>
<p>A normal random variable tends to take values that are quite close to the mean, measured in standard deviation units. We
</p>
<p>can demonstrate this important fact by computing the probability that a standard normal random variable lies between u and
</p>
<p>v. We form
Z v
</p>
<p>u
</p>
<p>1p
2�
</p>
<p>exp
</p>
<p>�
</p>
<p>�u
2
</p>
<p>2
</p>
<p>�
</p>
<p>du:
</p>
<p>It turns out that this integral can be evaluated relatively easily using a special function. The error function is defined by
</p>
<p>erf.x/ D 2p
�
</p>
<p>Z x
</p>
<p>0
</p>
<p>exp
�
</p>
<p>�t2
�
</p>
<p>dt
</p>
<p>so that
1
</p>
<p>2
erf
</p>
<p>�
</p>
<p>.
xp
2
/
</p>
<p>�
</p>
<p>D
Z x
</p>
<p>0
</p>
<p>1p
2�
</p>
<p>exp
</p>
<p>�
</p>
<p>�u
2
</p>
<p>2
</p>
<p>�
</p>
<p>du:
</p>
<p>Notice that erf.x/ is an odd function (i.e. erf.�x/ D erf.x/). From this (and tables for the error function, or your favorite
math package) we get that, for a standard normal random variable
</p>
<p>1p
2�
</p>
<p>Z 1
</p>
<p>�1
exp
</p>
<p>�
</p>
<p>�x
2
</p>
<p>2
</p>
<p>�
</p>
<p>dx � 0:68
</p>
<p>and
1p
2�
</p>
<p>Z 2
</p>
<p>�2
exp
</p>
<p>�
</p>
<p>�x
2
</p>
<p>2
</p>
<p>�
</p>
<p>dx � 0:95
</p>
<p>and
1p
2�
</p>
<p>Z 3
</p>
<p>�3
exp
</p>
<p>�
</p>
<p>�x
2
</p>
<p>2
</p>
<p>�
</p>
<p>dx � 0:99:
</p>
<p>These are very strong statements. They measure how often a standard normal random variable has values that are in the
</p>
<p>range �1; 1, �2; 2, and �3; 3 respectively. But these measurements apply to normal random variables if we recognize that
they now measure how often the normal random variable is some number of standard deviations away from the mean. In
</p>
<p>particular, it is worth remembering that:
</p>
<p>Useful Facts 5.10 (How Often a Normal Random Variable is How Far from the Mean)
</p>
<p>&bull; About 68% of the time, a normal random variable takes a value within one standard deviation of the mean.
</p>
<p>&bull; About 95% of the time, a normal random variable takes a value within two standard deviations of the mean.
</p>
<p>&bull; About 99% of the time, a normal random variable takes a value within three standard deviations of the mean.</p>
<p/>
</div>
<div class="page"><p/>
<p>126 5 Useful Probability Distributions
</p>
<p>5.4 Approximating Binomials with Large N
</p>
<p>The Binomial distribution appears to be a straightforward thing. We assume we flip a coin N times, where N is a very large
</p>
<p>number. The coin has probability p of coming up heads, and so probability q D 1 � p of coming up tails. The number of
heads h follows the binomial distribution, so
</p>
<p>P.h/ D NŠ
hŠ.N � h/Šp
</p>
<p>hq.N�h/
</p>
<p>The mean of this distribution is Np, the variance is Npq, and the standard deviation is
p
Npq.
</p>
<p>Evaluating this probability distribution for large N is very difficult, because factorials grow fast. We will construct an
</p>
<p>approximation to the binomial distribution for large N that allows us to evaluate the probability that h lies in some range.
</p>
<p>Notice that h=N is particularly interesting, because this is the fraction of flips that comes up heads. We are dividing by
</p>
<p>a constant, so the expected value of h=N is p and the standard deviation is pq=
p
N. Our approximation will show that the
</p>
<p>probability that h=N is within one standard deviation of the mean is approximately 68%. Note the standard deviation of
</p>
<p>the mean falls as N grows. This is important, because it shows that our model of probability as frequency is consistent. As
</p>
<p>N ! 1,
</p>
<p>0 1 2 3 4
0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>P(k heads) in 4 flips
</p>
<p>Number of heads
</p>
<p>P
ro
</p>
<p>b
ab
</p>
<p>il
it
</p>
<p>y
</p>
<p>0 2 4 6 8 10
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
</p>
<p>0.25
</p>
<p>P(k heads) in 10 flips
</p>
<p>Number of heads
</p>
<p>P
ro
</p>
<p>b
ab
</p>
<p>il
it
</p>
<p>y
</p>
<p>0 10 20 30 40
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>P(k heads) in 40 flips
</p>
<p>Number of heads
</p>
<p>P
ro
</p>
<p>b
ab
</p>
<p>il
it
</p>
<p>y
</p>
<p>0 20 40 60 80
0
</p>
<p>0.02
</p>
<p>0.04
</p>
<p>0.06
</p>
<p>0.08
</p>
<p>P(k heads) in 80 flips
</p>
<p>Number of heads
</p>
<p>P
ro
</p>
<p>b
ab
</p>
<p>il
it
</p>
<p>y
</p>
<p>Fig. 5.4 Plots of the binomial distribution for p D q D 0:5 for different values of N. You should notice that the set of values of h (the number
of heads) that have substantial probability is quite narrow compared to the range of possible values. This set gets narrower as the number of flips
increases. This is because the mean is pN and the standard deviation is
</p>
<p>p
Npq&mdash;so the fraction of values that is within one standard deviation of
</p>
<p>the mean is O.1=
p
N/</p>
<p/>
</div>
<div class="page"><p/>
<p>5.4 Approximating Binomials with Large N 127
</p>
<p>h
</p>
<p>N
! p
</p>
<p>because h=N will tend to land in an interval around p that gets narrower as N gets larger.
</p>
<p>The main difficulty with Fig. 5.4 (and with the argument above) is that the mean and standard deviation of the binomial
</p>
<p>distribution tends to infinity as the number of coin flips tends to infinity. This can confuse issues. For example, the plots of
</p>
<p>Fig. 5.4 show narrowing probability distributions&mdash;but is this because the scale is compacted, or is there a real effect? It turns
</p>
<p>out there is a real effect, and a good way to see it is to consider the normalized number of heads.
</p>
<p>5.4.1 Large N
</p>
<p>Recall that to normalize a dataset, you subtract the mean and divide the result by the standard deviation. We can do the same
</p>
<p>for a random variable. We now consider
</p>
<p>x D h � Npp
Npq
</p>
<p>:
</p>
<p>&minus;20 &minus;10 0 10 20
</p>
<p>0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>P(k heads) in 4 flips, normalized
</p>
<p>Number of heads
</p>
<p>P
ro
</p>
<p>b
ab
</p>
<p>il
it
</p>
<p>y
</p>
<p>&minus;20 &minus;10 0 10 20
</p>
<p>0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
</p>
<p>0.25
</p>
<p>P(k heads) in 10 flips, normalized
</p>
<p>Number of heads
</p>
<p>P
ro
</p>
<p>b
ab
</p>
<p>il
it
</p>
<p>y
</p>
<p>&minus;20 &minus;10 0 10 20
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>P(k heads) in 40 flips, normalized
</p>
<p>Number of heads
</p>
<p>P
ro
</p>
<p>b
ab
</p>
<p>il
it
</p>
<p>y
</p>
<p>&minus;20 &minus;10 0 10 20
0
</p>
<p>0.02
</p>
<p>0.04
</p>
<p>0.06
</p>
<p>0.08
</p>
<p>P(k heads) in 80 flips, normalized
</p>
<p>Number of heads
</p>
<p>P
ro
</p>
<p>b
ab
</p>
<p>il
it
</p>
<p>y
</p>
<p>Fig. 5.5 Plots of the distribution for the normalized variable x, with P.x/ given in the text, obtained from the binomial distribution with p D q D
0:5 for different values of N. These distributions are normalized (mean 0, variance 1. They look increasingly like a standard normal distribution
EXCEPT that the value at their mode gets smaller as N gets bigger (look at the vertical axis; this occurs because there are more possible outcomes).
In the text, we will establish that the standard normal distribution is a limit, in a useful sense</p>
<p/>
</div>
<div class="page"><p/>
<p>128 5 Useful Probability Distributions
</p>
<p>The probability distribution of x can be obtained from the probability distribution for h, because h D NpC x
p
Npq, so
</p>
<p>P.x/ D
�
</p>
<p>NŠ
</p>
<p>.NpC x
p
Npq/Š.Nq � x
</p>
<p>p
Npq/Š
</p>
<p>�
</p>
<p>p.NpCx
p
Npq/q.Nq�x
</p>
<p>p
Npq/:
</p>
<p>I have plotted this probability distribution for various values of N in Fig. 5.5.
</p>
<p>But it is hard to work with this distribution for very large N. The factorials become very difficult to evaluate. Second, it is
</p>
<p>a discrete distribution on N points, spaced 1=
p
Npq apart. As N becomes very large, the number of points that have non-zero
</p>
<p>probability becomes very large, and x can be very large, or very small. For example, there is some probability, though there
</p>
<p>may be very little indeed, on the point where h D N, or, equivalently, x D N.pC
p
Npq/. For sufficiently large N, we think
</p>
<p>of this probability distribution as a probability density function. We can do so, for example, by spreading the probability for
</p>
<p>xi (the i&rsquo;th value of x) evenly over the interval between xi and xiC1. We then have a probability density function that looks
like a histogram, with bars that become narrower as N increases. But what is the limit?
</p>
<p>5.4.2 Getting Normal
</p>
<p>To proceed, we need Stirling&rsquo;s approximation, which says that, for large N,
</p>
<p>NŠ �
p
2�
</p>
<p>p
N
</p>
<p>�
</p>
<p>N
</p>
<p>e
</p>
<p>�N
</p>
<p>:
</p>
<p>This yields
</p>
<p>P.h/ �
�
</p>
<p>Np
</p>
<p>h
</p>
<p>�h �
Nq
</p>
<p>N � h
</p>
<p>�.N�h/
s
</p>
<p>N
</p>
<p>2�h.N � h/
</p>
<p>Recall we used the normalized variable
</p>
<p>x D h � Npp
Npq
</p>
<p>:
</p>
<p>We will encounter the term
p
Npq often, and we use � D
</p>
<p>p
Npq as a shorthand. We can compute h and N � h from x by the
</p>
<p>equalities
</p>
<p>h D NpC �x N � h D Nq � �x:
</p>
<p>So the probability distribution written in this new variable x is
</p>
<p>P.x/ �
�
</p>
<p>Np
</p>
<p>.NpC�x/
</p>
<p>�.NpC�x/ �
Nq
</p>
<p>.Nq��x/
</p>
<p>�.Nq��x/
s
</p>
<p>N
</p>
<p>2�.NpC �x/.Nq � �x/
</p>
<p>There are three terms to deal with here. It is easiest to work with logP. Now
</p>
<p>log.1C x/ D x � 1
2
x2 C O.x3/
</p>
<p>so we have
</p>
<p>log
</p>
<p>�
</p>
<p>Np
</p>
<p>.NpC �x/
</p>
<p>�
</p>
<p>D � log
�
</p>
<p>1C �x
Np
</p>
<p>�
</p>
<p>� � �x
Np
</p>
<p>C .1
2
/.
�x
</p>
<p>Np
/2</p>
<p/>
</div>
<div class="page"><p/>
<p>5.4 Approximating Binomials with Large N 129
</p>
<p>and
</p>
<p>log
</p>
<p>�
</p>
<p>Nq
</p>
<p>.Nq � �x/
</p>
<p>�
</p>
<p>� �x
Nq
</p>
<p>C .1
2
/.
�x
</p>
<p>Nq
/2:
</p>
<p>From this, we have that
</p>
<p>log
</p>
<p>"
</p>
<p>�
</p>
<p>Np
</p>
<p>NpC �x
</p>
<p>�.NpC�x/ �
Nq
</p>
<p>Nq � �x
</p>
<p>�.Nq��x/#
</p>
<p>is approximately
</p>
<p>ŒNpC �x&#141;
"
</p>
<p>� �x
Np
</p>
<p>C
�
</p>
<p>1
</p>
<p>2
</p>
<p>��
</p>
<p>�x
</p>
<p>Np
</p>
<p>�2
#
</p>
<p>C ŒNq � �x&#141;
"
</p>
<p>�x
</p>
<p>Nq
C
�
</p>
<p>1
</p>
<p>2
</p>
<p>��
</p>
<p>�x
</p>
<p>Nq
</p>
<p>�2
#
</p>
<p>which is
</p>
<p>�
�
</p>
<p>1
</p>
<p>2
</p>
<p>�
</p>
<p>x2 C O..�x/3/
</p>
<p>(recall � D
p
Npq if you&rsquo;re having trouble with the last step). Now we look at the square-root term. We have
</p>
<p>log
</p>
<p>s
</p>
<p>N
</p>
<p>2�.NpC �x/.Nq � �x/ D �
1
</p>
<p>2
</p>
<p>0
</p>
<p>B
</p>
<p>B
</p>
<p>@
</p>
<p>log ŒNpC �x&#141;
C log ŒNq � �x&#141;
� logN
C log 2�
</p>
<p>1
</p>
<p>C
</p>
<p>C
</p>
<p>A
</p>
<p>D �1
2
</p>
<p>0
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>@
</p>
<p>logNpC O
��
</p>
<p>�x
Np
</p>
<p>��
</p>
<p>C logNq � O
��
</p>
<p>�x
Nq
</p>
<p>��
</p>
<p>� logN
C log 2�
</p>
<p>1
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>A
</p>
<p>but, since N is very large compared to �x, we can ignore the O.
�
</p>
<p>�x
Np
</p>
<p>�
</p>
<p>/ terms. Then this term is not a function of x. So we
</p>
<p>have
</p>
<p>logP.x/ � �x
2
</p>
<p>2
C constant:
</p>
<p>Now because N is very large, our probability distribution P limits to a probability density function p, with
</p>
<p>p.x/ / exp
��x2
</p>
<p>2
</p>
<p>�
</p>
<p>:
</p>
<p>We can get the constant of proportionality from integrating, to
</p>
<p>p.x/ D
�
</p>
<p>1p
2�
</p>
<p>�
</p>
<p>exp
</p>
<p>��x2
2
</p>
<p>�
</p>
<p>:
</p>
<p>This constant of proportionality deals with the effect in Fig. 5.5, where the mode of the distribution gets smaller as N gets
</p>
<p>bigger. It does so because there are more points with non-zero probability to be accounted for. But we are interested in the
</p>
<p>limit where N tends to infinity. This must be a probability density function, so it must integrate to one.
</p>
<p>Review this blizzard of terms. We started with a binomial distribution, but standardized the variables so that the mean was
</p>
<p>zero and the standard deviation was one. We then assumed there was a very large number of coin tosses, so large that the
</p>
<p>distribution started to look like a continuous function. The function we get is the standard normal distribution.
</p>
<p>5.4.3 Using a Normal Approximation to the Binomial Distribution
</p>
<p>I have proven an extremely useful fact, which I shall now put in a box.</p>
<p/>
</div>
<div class="page"><p/>
<p>130 5 Useful Probability Distributions
</p>
<p>Useful Facts 5.11 (Binomial Distribution for Large N)
</p>
<p>Assume h follows the binomial distribution with parameters p and q. Write
</p>
<p>x D h � Npp
Npq
</p>
<p>:
</p>
<p>Then, for sufficiently large N, the probability distribution P.x/ can be approximated by the probability density function
</p>
<p>�
</p>
<p>1p
2�
</p>
<p>�
</p>
<p>exp
</p>
<p>��x2
2
</p>
<p>�
</p>
<p>in the sense that
</p>
<p>P.fx 2 Œa; b&#141;g/�
Z b
</p>
<p>a
</p>
<p>�
</p>
<p>1p
2�
</p>
<p>�
</p>
<p>exp
</p>
<p>��u2
2
</p>
<p>�
</p>
<p>du
</p>
<p>This justifies our model of probability as frequency. I interpreted an event having probability p to mean that, if I had a
</p>
<p>large number N of independent repetitions of the experiment, the number that produced the event would be close to Np, and
</p>
<p>would get closer as N got larger. We know that, for example, 68% of the time a standard normal random variable takes a
</p>
<p>value between 1 and �1. In this case, the standard normal random variable is
</p>
<p>h � .Np/p
Npq
</p>
<p>so that 68% of the time, h must take a value in the range ŒNp�
p
Npq;NpC
</p>
<p>p
Npq&#141;. Equivalently, the relative frequency h=N
</p>
<p>must take a value in the range
</p>
<p>Œp � pqp
N
; pC pqp
</p>
<p>N
&#141;
</p>
<p>but as N ! 1 this range gets smaller and smaller, and h=N limits to p. So our view of probability as a frequency is consistent.
</p>
<p>5.5 You Should
</p>
<p>5.5.1 Remember These Definitions
</p>
<p>Uniform random variable, discrete . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
</p>
<p>Bernoulli random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
</p>
<p>Geometric distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
</p>
<p>Binomial distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
</p>
<p>Multinomial distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
</p>
<p>Poisson distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
</p>
<p>Uniform distribution, continuous . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
</p>
<p>Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
</p>
<p>Gamma distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
</p>
<p>Exponential distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
</p>
<p>Standard Normal distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
</p>
<p>Normal distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
</p>
<p>5.5.2 Remember These Terms
</p>
<p>intensity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
</p>
<p>Poisson point process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 131
</p>
<p>uniform distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
</p>
<p>uniform random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
</p>
<p>standard normal distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
</p>
<p>standard normal random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
</p>
<p>normal distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
</p>
<p>normal random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
</p>
<p>normal distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
</p>
<p>gaussian distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
</p>
<p>error function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
</p>
<p>5.5.3 Remember These Facts
</p>
<p>Mean and variance of a Bernoulli random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
</p>
<p>Mean and variance of a geometric distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
</p>
<p>Mean and variance of the binomial distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
</p>
<p>Mean and variance of the Poisson distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
</p>
<p>Mean and variance of a Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
</p>
<p>Mean and variance of the gamma distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
</p>
<p>Mean and variance of the exponential distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
</p>
<p>Mean and variance of the standard normal distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
</p>
<p>Mean and variance of the normal distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
</p>
<p>How often a normal random variable is how far from the mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
</p>
<p>Binomial distribution for large N . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
</p>
<p>5.5.4 Remember These Points
</p>
<p>CLT means normal distributions are common . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
</p>
<p>Problems
</p>
<p>Sums and Differences of Discrete RandomVariables
</p>
<p>5.1 Assume X and Y are discrete random variables which take integer values in the range 1 : : : 100 (inclusive). Write S D
X C Y .
</p>
<p>(a) Show that
</p>
<p>P.S D k/D
uD100
X
</p>
<p>uD1
P.ffX D k � ug \ fY D ugg/:
</p>
<p>(b) Now assume that both X and Y are uniform random variables. Show that S is not uniform by considering P.S D 2/,
P.S D 3/, and P.S D 100/.
</p>
<p>5.2 Assume X and Y are discrete random variables which take integer values in the range 1 : : : 100 (inclusive). Write D D
X � Y .
</p>
<p>(a) Show that
</p>
<p>P.D D k/D
uD100
X
</p>
<p>uD1
P.fX D kC ug/P.fY D ug/:
</p>
<p>(b) Now assume that both X and Y are uniform random variables. Show that D is not uniform by considering P.D D �99/,
P.D D 99/, and P.D D 0/.</p>
<p/>
</div>
<div class="page"><p/>
<p>132 5 Useful Probability Distributions
</p>
<p>The Geometric Distribution
</p>
<p>5.3 Write S1 D
P1
</p>
<p>iD0 r
i. Show that .1 � r/S1 D 1, so that
</p>
<p>S1 D
1
</p>
<p>1 � r
</p>
<p>5.4 Write P.fX D ng/ for the probability that an experiment requires n repeats for success under the geometric distribution
model with probability of success in one experiment p. Use the result of the previous exercise to show that
</p>
<p>1
X
</p>
<p>nD1
P.fX D ng/ D p
</p>
<p>1
X
</p>
<p>nD1
.1 � p/.n�1/
</p>
<p>D 1
</p>
<p>5.5 Show that
1
X
</p>
<p>iD0
iri D .
</p>
<p>1
X
</p>
<p>iD1
ri/C r.
</p>
<p>1
X
</p>
<p>iD1
ri/C r2.
</p>
<p>1
X
</p>
<p>iD1
ri/C : : :
</p>
<p>(look carefully at the limits of the sums!) and so show that
</p>
<p>1
X
</p>
<p>iD0
iri D r
</p>
<p>.1 � r/2 :
</p>
<p>5.6 Write S1 D
P1
</p>
<p>iD0 r
i. Show that
</p>
<p>1
X
</p>
<p>iD0
i2ri D .S1 � 1/C 3r.S1 � 1/C 5r2.S1 � 1/C 7r3.&divide;1 � 1/C : : :
</p>
<p>and so that 1
X
</p>
<p>iD0
i2ri D r.1C r/
</p>
<p>.1 � r/3
</p>
<p>5.7 Show that, for a geometric distribution with parameter p, the mean is
</p>
<p>1
X
</p>
<p>iD1
i.1 � p/.i�1/p D
</p>
<p>1
X
</p>
<p>uD0
.uC 1/.1 � p/up:
</p>
<p>Now by rearranging and using the previous results, show that the mean is
</p>
<p>1
X
</p>
<p>iD1
i.1 � p/.i�1/p D 1
</p>
<p>p
</p>
<p>5.8 Show that a geometric distribution with parameter p has variance .1 � p/=p2. To do this, note the variance is E
�
</p>
<p>X2
�
</p>
<p>�
EŒX&#141;2. Now use the results of the previous exercises to show that
</p>
<p>E
�
</p>
<p>X2
�
</p>
<p>D
1
X
</p>
<p>iD1
i2.1�p/.i�1/p D p
</p>
<p>1�p
.1�p/.2 � p/
</p>
<p>p3
;
</p>
<p>then rearrange to get the expression for variance.
</p>
<p>5.9 You have a coin with unknown probability p of coming up heads. You wish to generate a random variable which takes
</p>
<p>the values 0 and 1, each with probability 1=2. Assume 0 &lt; p &lt; 1. You adopt the following procedure. You start by flipping</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 133
</p>
<p>the coin twice. If both flips produce the same side of the coin, you start again. If the result of the first flip is different from
</p>
<p>the result of the second flip, you report the result of the first flip and you are finished (this is a trick originally due to John
</p>
<p>von Neumann).
</p>
<p>(a) Show that, in this case, the probability of reporting heads is 1=2.
</p>
<p>(b) What is the expected number of flips you must make before you report a result?
</p>
<p>Bernoulli RandomVariables
</p>
<p>5.10 Write X for a Bernoulli random variable which takes the value 1 with probability p (and 0 with probability .1� p/).
</p>
<p>(a) Show that EŒX&#141; D p.
(b) Show that the variance of X is p.1 � p/:
</p>
<p>5.11 Write X.N/ for
1
</p>
<p>N
.X1 C X2 C : : :XN/
</p>
<p>where the Xi are independent Bernoulli random variables. Each of these takes the value 1 with probability p (and 0 with
</p>
<p>probability .1 � p/).
</p>
<p>(a) Show that E
�
</p>
<p>X.N/
�
</p>
<p>D p.
(b) Show that the variance of X.N/ is p.1 � p/
</p>
<p>5.12 Write S.N/ for
</p>
<p>.X1 C X2 C : : :XN/
</p>
<p>where the Xi are independent Bernoulli random variables. Each of these takes the value 1 with probability p (and 0 with
</p>
<p>probability .1 � p/).
</p>
<p>(a) Show that, for 0 � k � N, P.fX D kg/ is
�
</p>
<p>N
</p>
<p>k
</p>
<p>�
</p>
<p>pk.1 � p/.N�k/
</p>
<p>(b) Show that E
�
</p>
<p>S.N/
�
</p>
<p>D Np:
(c) Show that the variance of S.N/ is Np.1 � p/:
</p>
<p>The Binomial Distribution
</p>
<p>5.13 Show that Pb.N � iIN; p/ D Pb.iIN; .1 � p// for all i.
</p>
<p>5.14 Show that
</p>
<p>Pb.iIN; p/
</p>
<p>D pPb.i�1IN�1; p/C.1�p/Pb.iIN�1; p/:
</p>
<p>5.15 Write hr for the number of heads obtained in r flips of a coin which has probability p of coming up heads. Compare
</p>
<p>the following two ways to compute the probability of getting i heads in five coin flips:
</p>
<p>&bull; Flip the coin three times, count h3, then flip the coin twice, count h2, then form w D h3 C h2.
&bull; Flip the coin five times, and count h5.</p>
<p/>
</div>
<div class="page"><p/>
<p>134 5 Useful Probability Distributions
</p>
<p>Show that the probability distribution for w is the same as the probability distribution for h5. Do this by showing that
</p>
<p>P.fw D ig/ D
</p>
<p>2
</p>
<p>4
</p>
<p>5
X
</p>
<p>jD0
P.fh3 D jg \ fh2 D i � jg/
</p>
<p>3
</p>
<p>5 D P.fh5 D ig/:
</p>
<p>5.16 Now we will do the previous exercise in a more general form. Again, write hr for the number of heads obtained in r
</p>
<p>flips of a coin which has probability p of coming up heads. Compare the following two ways to compute the probability of
</p>
<p>getting i heads in N coin flips:
</p>
<p>&bull; Flip the coin t times, count ht, then flip the coin N � t times, count hN�t, then form w D ht C hN�t.
&bull; Flip the coin N times, and count hN .
</p>
<p>Show that the probability distribution for w is the same as the probability distribution for hN . Do this by showing that
</p>
<p>P.fw D ig/ D
</p>
<p>2
</p>
<p>4
</p>
<p>N
X
</p>
<p>jD0
P.fht D jg \ fhN�t D i � jg/
</p>
<p>3
</p>
<p>5 D P.fhN D ig/:
</p>
<p>5.17 An airline runs a regular flight with six seats on it. The airline sells six tickets. The gender of the passengers is unknown
</p>
<p>at time of sale, but women are as common as men in the population. All passengers always turn up for the flight. The pilot is
</p>
<p>eccentric, and will not fly a plane unless at least one passenger is female. What is the probability that the pilot flies?
</p>
<p>5.18 An airline runs a regular flight with s seats on it. The airline always sells t tickets for this flight. The probability a
</p>
<p>passenger turns up for departure is p, and passengers do this independently. What is the probability that the plane travels
</p>
<p>with exactly three empty seats?
</p>
<p>5.19 An airline runs a regular flight with s seats on it. The airline always sells t tickets for this flight. The probability a
</p>
<p>passenger turns up for departure is p, and passengers do this independently. What is the probability that the plane travels
</p>
<p>with 1 or more empty seats?
</p>
<p>TheMultinomial Distribution
</p>
<p>5.20 Show that the multinomial distribution
</p>
<p>Pm.n1; : : : ; nkIN; p1; : : : ; nk/ D
NŠ
</p>
<p>n1Šn2Š : : : nkŠ
</p>
<p>p
n1
1 p
</p>
<p>n2
2 : : : p
</p>
<p>nk
k
</p>
<p>must satisfy the recurrence relation
</p>
<p>Pm.n1; : : : ; nkIN; p1; : : : ; pk/
</p>
<p>D p1Pm.n1 � 1; : : : ; nkIN � 1; p1; : : : ; pk/C
</p>
<p>p2Pm.n1; n2 � 1; : : : ; nkIN � 1; p1; : : : ; pk/C : : :
</p>
<p>pkPm.n1; n2; : : : ; nk � 1IN � 1; p1; : : : ; pk/</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 135
</p>
<p>The Poisson Distribution
</p>
<p>5.21 The exponential function ex can be represented by the series
</p>
<p>1
X
</p>
<p>iD0
</p>
<p>xi
</p>
<p>iŠ
</p>
<p>(which converges absolutely; try the ratio test). Use this information to show that the Poisson distribution sums to one.
</p>
<p>5.22 You will show that the mean of the Poisson distribution with intensity parameter � is �.
</p>
<p>(a) Show that Taylor series for xex around x D 0 is given by
</p>
<p>1
X
</p>
<p>iD0
</p>
<p>ixi
</p>
<p>iŠ
</p>
<p>and use the ratio test to show that this series converges absolutely.
</p>
<p>(b) Now use this series and pattern matching to show the mean of the Poisson distribution with intensity parameter � is �.
</p>
<p>5.23 Compute the Taylor series for .x2 C x/ex around x D 0. Show that this series converges absolutely, using the ratio test.
Use this and pattern matching to show that the variance of the Poisson distribution with intensity parameter � is �.
</p>
<p>Sums of Continuous RandomVariables
</p>
<p>5.24 Write px for the probability density function of a continuous random variable X and py for the probability density
</p>
<p>function of a continuous random variable Y . Show that the probability density function of S D X C Y is
</p>
<p>p.s/ D
Z 1
</p>
<p>�1
px.s � u/py.u/du D
</p>
<p>Z 1
</p>
<p>�1
px.u/py.s � u/du
</p>
<p>The Normal Distribution
</p>
<p>5.25 Write
</p>
<p>f .x/ D
�
</p>
<p>1p
2�
</p>
<p>�
</p>
<p>exp
</p>
<p>��x2
2
</p>
<p>�
</p>
<p>:
</p>
<p>(a) Show that f .x/ is non-negative for all x.
</p>
<p>(b) By integration, show that
Z 1
</p>
<p>�1
f .x/dx D 1;
</p>
<p>so that f .x/ is a probability density function (you can look up the integral; few people remember how to do this integral
</p>
<p>these days).
</p>
<p>(c) Show that
</p>
<p>Z 1
</p>
<p>�1
xf .x/dx D 0:
</p>
<p>The easiest way to do this is to notice that f .x/ D f .�x/
(d) Show that
</p>
<p>Z 1
</p>
<p>�1
xf .x � �/dx D �:</p>
<p/>
</div>
<div class="page"><p/>
<p>136 5 Useful Probability Distributions
</p>
<p>The easiest way to do this is to change variables, and use the previous two exercises.
</p>
<p>(e) Show that
Z 1
</p>
<p>�1
x2f .x/dx D 1:
</p>
<p>You&rsquo;ll need to either do, or look up, the integral to do this exercise.
</p>
<p>5.26 Write
</p>
<p>g.x/ D exp
�
</p>
<p>� .x � �/
2
</p>
<p>2�2
</p>
<p>�
</p>
<p>Show that
Z 1
</p>
<p>�1
g.x/dx D
</p>
<p>p
2��:
</p>
<p>You can do this by a change of variable, and the results of the previous exercises.
</p>
<p>5.27 Write
</p>
<p>p.x/ D
�
</p>
<p>1p
2��
</p>
<p>�
</p>
<p>exp
</p>
<p>��.x � �/2
2�2
</p>
<p>�
</p>
<p>:
</p>
<p>(a) Show that
Z 1
</p>
<p>�1
xp.x/dx D �
</p>
<p>using the results of the previous exercises.
</p>
<p>(b) Show that
Z 1
</p>
<p>�1
.x � �/2p.x/dx D �2
</p>
<p>using the results of the previous exercises.
</p>
<p>The Binomial Distribution for Large N
</p>
<p>5.28 I flip a fair coin N times and count heads. We consider the probability that h, the fraction of heads, is in some range
</p>
<p>of numbers. For each of these questions, you should just write an expression, rather than evaluate the integral. Hint: If you
</p>
<p>know the range of numbers for h, you know the range for h=N.
</p>
<p>(a) For N D 1e6, use the normal approximation to estimate
</p>
<p>P.fh 2 Œ49;500; 50;500&#141;g/:
</p>
<p>(b) For N D 1e4, use the normal approximation to estimate
</p>
<p>P.fh &gt; 9000g/:
</p>
<p>(c) For N D 1e2, use the normal approximation to estimate
</p>
<p>P.fh &gt; 60g [ fh &lt; 40g/:</p>
<p/>
</div>
<div class="page"><p/>
<p>Programming Exercises 137
</p>
<p>Programming Exercises
</p>
<p>5.29 An airline runs a regular flight with 10 seats on it. The probability that a passenger turns up for the flight is 0.95. What
</p>
<p>is the smallest number of seats the airline should sell to ensure that the probability the flight is full (i.e. 10 or more passengers
</p>
<p>turn up) is bigger than 0.99? You&rsquo;ll need to write a simple simulation; estimate the probability by counting.
</p>
<p>5.30 You will plot a series of figures showing how the binomial distribution for large N increasingly &ldquo;looks like&rdquo; the normal
</p>
<p>distribution. We will consider the number of heads h in N flips of an unbiased coin (so P.H/ D P.T/ D 1=2 D p, and in this
case q D 1 � p D 1=2). Write x D h�Npp
</p>
<p>Npq
.
</p>
<p>(a) Prepare plots of the probability distribution of x for N D 10, N D 30, N D 60, and N D 100. These should be
superimposed on the same set of axes. On this set of axes, you should also plot the normal probability distribution.
</p>
<p>(b) Evaluate P.fx � 2g/ for each case by summing over the appropriate terms in the binomial distribution. Now compare
this to the prediction that the approximation would make, which is
</p>
<p>Z 1
</p>
<p>2
</p>
<p>1p
2�
</p>
<p>eŒ�u
2=2&#141;du:
</p>
<p>You can obtain this number by appropriate evaluation of error functions.
</p>
<p>(c) Now you will write a program to simulate coin flips and evaluate the variance of the simulated value of x for different
</p>
<p>numbers of flips. Again, the coin should be fair. For each N from 10; 40; 90; 160; 250; 490; 640; 810; 1000, estimate the
</p>
<p>value of x by simulating that number of flips. You should run each simulation 100 times, and use the set of estimates to
</p>
<p>evaluate the variance of your estimate of x. Plot this variance against N and against 1=
p
N&mdash;what do you see?</p>
<p/>
</div>
<div class="page"><p/>
<p>Part III
</p>
<p>Inference</p>
<p/>
</div>
<div class="page"><p/>
<p>6Samples and Populations
</p>
<p>Very often the data we see is a small part of the data we could have seen. The data we could have observed, if we could have
</p>
<p>seen everything, is the population. I will write populations like random variables with capital letters to emphasize we don&rsquo;t
</p>
<p>actually know the whole population. The data we actually have is the sample (lower case, as usual). We would like to know
</p>
<p>the population mean, which we write popmean .fXg/. We must estimate this using the sample.
This situation occurs very often. For example, imagine we wish to know the average weight of a rat. This isn&rsquo;t random;
</p>
<p>you could weigh every rat on the planet, and then average the answers. But doing so would absurd (among other things,
</p>
<p>you&rsquo;d have to weigh them all at the same time, which would be tricky). Instead, we weigh a small set of rats, chosen at
</p>
<p>random but rather carefully so. If we have chosen sufficiently carefully, then we can say a great deal from the sample alone.
</p>
<p>6.1 The Sample Mean
</p>
<p>Assume we have a population fXg, for i D 1; : : : ;Np. Notice the subscript here&mdash;this is the number of items in the population.
The population could be unreasonably big: for example, it could consist of all the people in the world. We want to know the
</p>
<p>mean of this population, but we do not get to see the whole thing. Instead, we see a sample.
</p>
<p>How the sample is obtained is key to describing the population. We will focus on only one model (there are lots of others).
</p>
<p>In our model, the sample is obtained by choosing a fixed number of data items. Write N for the number of data items in the
</p>
<p>sample. I use N to remind you of the size of a dataset, because most datasets are samples. We expect N is a lot smaller than
</p>
<p>Np. Each item is chosen independently, and fairly. This means that each time we choose, we choose one from the entire
</p>
<p>set of Np data items, and each has the same probability of being chosen. This is sometimes referred to as &ldquo;sampling with
</p>
<p>replacement&rdquo;.
</p>
<p>One natural way to think about sampling with replacement is to imagine the data items as being written on tickets, which
</p>
<p>are placed in an urn (old-fashioned word for a jar, now used mainly by statisticians and morticians). You obtain the sample
</p>
<p>by repeating the following experiment N times: shake the urn; take a ticket from the urn and write down the data on the
</p>
<p>ticket; put it back in the urn. Notice that, in this case, each sample is drawn from the same urn. This is important, and makes
</p>
<p>the analysis easier. If we had not put the ticket back, the urn would change between samples.
</p>
<p>6.1.1 The Sample Mean Is an Estimate of the PopulationMean
</p>
<p>We would like to estimate the mean of the whole dataset from the items that we actually see. Imagine we draw N tickets
</p>
<p>from the urn as above, and average the values. The result is a random variable, because different draws of N tickets will give
</p>
<p>us different values. Write X.N/ for this random variable, which is referred to as the sample mean. Because expectations are
</p>
<p>linear, we must have that
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_6
</p>
<p>141</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_6">https://doi.org/10.1007/978-3-319-64410-3_6</a></div>
</div>
<div class="page"><p/>
<p>142 6 Samples and Populations
</p>
<p>E
�
</p>
<p>X.N/
�
</p>
<p>D 1
N
</p>
<p>�
</p>
<p>E
�
</p>
<p>X.1/
�
</p>
<p>C : : :C E
�
</p>
<p>X.1/
��
</p>
<p>D E
�
</p>
<p>X.1/
�
</p>
<p>(where X.1/ is the random variable whose value is obtained by drawing one ticket from the urn). Now
</p>
<p>E
�
</p>
<p>X.1/
�
</p>
<p>D
X
</p>
<p>i21;:::Np
xip.i/
</p>
<p>D
X
</p>
<p>i21;:::Np
xi
</p>
<p>1
</p>
<p>Np
because we draw fairly from the urn
</p>
<p>D
P
</p>
<p>i21;:::Np xi
</p>
<p>Np
</p>
<p>D popmean .fXg/
</p>
<p>which is the mean value of the items in the urn. This means that
</p>
<p>E
�
</p>
<p>X.N/
�
</p>
<p>D popmean .fXg/:
</p>
<p>Under our sampling model, the expected value of the sample mean is the population mean.
</p>
<p>Useful Facts 6.1 (Properties of Sample and Population Means)
</p>
<p>The sample mean is a random variable. It is random, because different samples from the population will have different
</p>
<p>values of the sample mean. The expected value of this random variable is the population mean.
</p>
<p>6.1.2 The Variance of the Sample Mean
</p>
<p>We will not get the same value of X.N/ each time we perform the experiment, because we see different data items in each
</p>
<p>sample. So X.N/ has variance, and this variance is important. If it is large, then the estimate from each different sample will
</p>
<p>be quite different. If it is small, then the estimates will be similar. Knowing the variance of X.N/ would tell us how accurate
</p>
<p>our estimate of the population mean is.
</p>
<p>We write popsd .fXg/ for the standard deviation of the whole population fXg. Again, we write it like this to keep track of
the facts that (a) it&rsquo;s for the whole population and (b) we don&rsquo;t&mdash;and usually can&rsquo;t&mdash;know it. We can compute the variance
</p>
<p>of X.N/ (the sample mean) easily. We have
</p>
<p>var
�
</p>
<p>X.N/
�
</p>
<p>D E
�
</p>
<p>.X.N//2
�
</p>
<p>� E
�
</p>
<p>X.N/
�2 D E
</p>
<p>�
</p>
<p>.X.N//2
�
</p>
<p>� .popmean .fXg//2
</p>
<p>so we need to know E
�
</p>
<p>.X.N//2
�
</p>
<p>. We can compute this by writing
</p>
<p>X.N/ D 1
N
.X1 C X2 C : : :XN/
</p>
<p>where X1 is the value of the first ticket drawn from the urn, etc. We then have
</p>
<p>X.N/
2 D
</p>
<p>�
</p>
<p>1
</p>
<p>N
</p>
<p>�2 �
X21 C X22 C : : :X2N C X1X2 C : : :
X1Xk C X2X1 C : : :X2XN C : : :XN�1XN
</p>
<p>�
</p>
<p>:</p>
<p/>
</div>
<div class="page"><p/>
<p>6.1 The Sample Mean 143
</p>
<p>Expectations are linear, so we have that
</p>
<p>E
�
</p>
<p>.X.N//2
�
</p>
<p>D
�
</p>
<p>1
</p>
<p>N
</p>
<p>�2 �
E
�
</p>
<p>X21
�
</p>
<p>C E
�
</p>
<p>X22
�
</p>
<p>C : : :E
�
</p>
<p>X2N
�
</p>
<p>C EŒX1X2&#141;C
: : :EŒX1XN &#141;C EŒX2X1&#141;C : : :EŒXN�1XN &#141;
</p>
<p>�
</p>
<p>:
</p>
<p>The order in which the tickets are drawn from the urn doesn&rsquo;t matter, because each time we draw a ticket we draw from the
</p>
<p>same urn. This means that E
�
</p>
<p>X21
�
</p>
<p>D E
�
</p>
<p>X22
�
</p>
<p>D : : : D E
�
</p>
<p>X2N
�
</p>
<p>. You can think of this term as the expected value of the
</p>
<p>random variable generated by: drawing a single number out of the urn; squaring that number; and reporting the square.
</p>
<p>Notice that E
�
</p>
<p>X21
�
</p>
<p>D E
�
</p>
<p>.X.1//2
�
</p>
<p>(look at the definition of X.1/).
</p>
<p>Because the order doesn&rsquo;t matter, we also have that EŒX1X2&#141; D EŒX1X3&#141; D : : :EŒXN�1XN &#141;. You can think of this term as
the expected value of the random variable generated by: drawing a number out of the urn; writing it down; returning it to the
</p>
<p>urn; then drawing a second number from the urn; and reporting the product of these two numbers. So we can write
</p>
<p>E
</p>
<p>h
</p>
<p>X.N/
2
i
</p>
<p>D
�
</p>
<p>1
</p>
<p>N
</p>
<p>�2
�
</p>
<p>NE
�
</p>
<p>.X.1//2
�
</p>
<p>C N.N � 1/EŒX1X2&#141;
�
</p>
<p>and these two terms are quite easy to evaluate.
</p>
<p>Worked example 6.1 (Urn Variances) Show that
</p>
<p>E
�
</p>
<p>.X.1//2
�
</p>
<p>D
PNp
</p>
<p>iD1 x
2
i
</p>
<p>Np
D popsd .fXg/2 C popmean .fXg/2
</p>
<p>Solution First, we have .X.1//2 is the number obtained by taking a ticket out of the urn uniformly and at random and
</p>
<p>squaring its data item. Now
</p>
<p>popsd .fXg/2DE
�
</p>
<p>.X.1//2
�
</p>
<p>�E
�
</p>
<p>X.1/
�2
</p>
<p>DE
�
</p>
<p>.X.1//2
�
</p>
<p>�popmean.fXg/2
</p>
<p>so
</p>
<p>E
�
</p>
<p>.X.1//2
�
</p>
<p>Dpopsd.fXg/2Cpopmean.fXg/2
</p>
<p>Worked example 6.2 (Urn Variances) Show that
</p>
<p>EŒX1X2&#141; D popmean .fXg/2
</p>
<p>Solution This looks hard, but isn&rsquo;t. Recall from the facts in Chap. 4 (useful facts 4.6, page 97) that if X and Y are
</p>
<p>independent random variables, EŒXY&#141; D EŒX&#141;EŒY&#141;. But X1 and X2 are independent&mdash;they are different random draws
from the same urn. So
</p>
<p>EŒX1X2&#141; D EŒX1&#141;EŒX2&#141;
but EŒX1&#141; D EŒX2&#141; (they are draws from the same urn) and EŒX&#141; D popmean .fXg/. So
</p>
<p>EŒX1X2&#141; D popmean .fXg/2:
</p>
<p>Now
</p>
<p>E
�
</p>
<p>.X.N//2
�
</p>
<p>D
NE
</p>
<p>�
</p>
<p>.X.1//2
�
</p>
<p>C N.N � 1/EŒX1X2&#141;
N2
</p>
<p>D
E
�
</p>
<p>.X.1//2
�
</p>
<p>C .N � 1/EŒX1X2&#141;
N</p>
<p/>
</div>
<div class="page"><p/>
<p>144 6 Samples and Populations
</p>
<p>D .popsd .fXg/
2 C popmean .fXg/2/C .N � 1/popmean .fXg/2
</p>
<p>N
</p>
<p>D popsd .fXg/
2
</p>
<p>N
C popmean .fXg/2
</p>
<p>so we have
</p>
<p>var
�
</p>
<p>X.N/
�
</p>
<p>D E
�
</p>
<p>.X.N//2
�
</p>
<p>� E
�
</p>
<p>X.N/
�2
</p>
<p>D popsd .fXg/
2
</p>
<p>N
C popmean .fXg/2 � popmean .fXg/2
</p>
<p>D popsd .fXg/
2
</p>
<p>N
:
</p>
<p>This is a very useful result which is well worth remembering together with our facts on the sample mean, so we&rsquo;ll put them
</p>
<p>in a box together.
</p>
<p>Useful Facts 6.2 (Expressions for Mean and Variance of the Sample Mean)
</p>
<p>The sample mean is a random variable. Write X.N/ for the mean of N samples. We have that:
</p>
<p>E
�
</p>
<p>X.N/
�
</p>
<p>D popmean .fXg/
</p>
<p>var
�
</p>
<p>X.N/
�
</p>
<p>D popsd .fXg/
2
</p>
<p>N
</p>
<p>std
�
</p>
<p>X.N/
�
</p>
<p>D popsd .fXg/p
N
</p>
<p>The consequence is this: If you draw N samples, the standard deviation of your estimate of the mean is
</p>
<p>popsd .fXg/p
N
</p>
<p>which means that (a) the more samples you draw, the better your estimate becomes and (b) the estimate improves rather
</p>
<p>slowly&mdash;for example, to halve the standard deviation in your estimate, you need to draw four times as many samples.
</p>
<p>6.1.3 When The UrnModel Works
</p>
<p>In our model, there was a population of Np data items xi, and we saw N of them, chosen at random. In particular, each choice
</p>
<p>was fair (in the sense that each data item had the same probability of being chosen) and independent. These assumptions
</p>
<p>are very important for our analysis to apply. If our data does not have these properties, bad things can happen. For example,
</p>
<p>assume we wish to estimate the percentage of the population that has beards. This is a mean (the data items take the value 1
</p>
<p>for a person with a beard, and 0 without a beard). If we select people according to our model, then ask them whether they
</p>
<p>have a beard, then our estimate of the percentage of beards should behave as above.
</p>
<p>The first thing that should strike you is that it isn&rsquo;t at all easy to select people according to this model. For example,
</p>
<p>we might select phone numbers at random, then call and ask the first person to answer the phone whether they have a
</p>
<p>beard; but many children won&rsquo;t answer the phone because they are too small. The next important problem is that errors in</p>
<p/>
</div>
<div class="page"><p/>
<p>6.1 The Sample Mean 145
</p>
<p>selecting people can lead to massive errors in your estimate. For example, imagine you decide to survey all of the people at
</p>
<p>a kindergarten on a particular day; or all of the people in a women&rsquo;s clothing store; or everyone attending a beard growing
</p>
<p>competition (they do exist). In each case, you will get an answer that is a very poor estimate of the right answer, and the
</p>
<p>standard deviation of this estimate might look very small. Of course, it is easy to tell that these cases are a bad choice.
</p>
<p>It may not be easy to tell what a good choice is. You should notice the similarity between estimating the percentage of
</p>
<p>the population that wears a beard, and estimating the percentage that will vote for a particular candidate. There is a famous
</p>
<p>example of a survey that mispredicted the result of the Dewey-Truman presidential election in 1948; poll-takers phoned
</p>
<p>random phone numbers, and asked for an opinion. But at that time, telephones tended to be owned by a small percentage of
</p>
<p>rather comfortable households, who tended to prefer one candidate, and so the polls mispredicted the result rather badly.
</p>
<p>Sometimes, we don&rsquo;t really have a choice of samples. For example, we might be presented with a small dataset of (say)
</p>
<p>human body temperatures. If we can be satisfied that the people were selected rather randomly, we might be able to use
</p>
<p>this dataset to predict expected body temperature. But if we knew that the subjects had their temperatures measured because
</p>
<p>they presented themselves at the doctor with a suspected fever, then we most likely cannot use it to predict expected body
</p>
<p>temperature without a lot of extra work.
</p>
<p>One important and valuable case where this model works is in simulation. If you can guarantee that your simulations are
</p>
<p>independent (which isn&rsquo;t always easy), this model applies to estimates obtained from a simulation. Notice that it is usually
</p>
<p>straightforward to build a simulation so that the i&rsquo;th simulation reports an xi where popmean .fXg/ gives you the thing you
want to measure. For example, imagine you wish to measure the probability of winning a game; then the simulation should
</p>
<p>report one when the game is won, and zero when it is lost. As another example, imagine you wish to measure the expected
</p>
<p>number of turns before a game is won; then your simulation should report the number of turns elapsed before the game
</p>
<p>was won.
</p>
<p>6.1.4 Distributions Are Like Populations
</p>
<p>Up to now, we have assumed that there is a large population of data items from which we drew a sample. The sample was
</p>
<p>drawn from the population uniformly at random, and with replacement. We used this sample to reason about the population.
</p>
<p>But the ideas depended on the population only to the extent that (a) the population is very big; (b) there was a population
</p>
<p>mean; and (c) the population was sampled uniformly at random, and with replacement. This suggests that we can replace the
</p>
<p>population with a probability distribution and the sampling process with drawing IID samples from the population.
</p>
<p>Now imagine that we have a set of N data items xi drawn as IID samples from some distribution P.X/. We require that
</p>
<p>the mean and variance of this distribution exist (there are some distributions for which this criterion does not apply; they&rsquo;re
</p>
<p>of no interest to us). The derivations of Sects. 6.1.1 and 6.1.2 work fine for this case. We have that
</p>
<p>X.N/ D
P
</p>
<p>i xi
</p>
<p>N
</p>
<p>is a random variable, because different sets of IID samples will have different values. We will have that
</p>
<p>E
�
</p>
<p>X.N/
�
</p>
<p>D EP.X/ŒX&#141;
</p>
<p>(i.e. the expected value of X.N/ will be the mean of P.X/) and that
</p>
<p>var
�
</p>
<p>X.N/
�
</p>
<p>D varŒP.X/&#141;
N
</p>
<p>(i.e. the variance of the estimate of the mean is the variance of P.X/ divided by N). It&rsquo;s important to keep track of the
</p>
<p>difference between the variance of the estimate of the mean&mdash;which describes how estimates of the mean from different
</p>
<p>samples will differ&mdash;and the variance of the original probability distribution.</p>
<p/>
</div>
<div class="page"><p/>
<p>146 6 Samples and Populations
</p>
<p>6.2 Confidence Intervals
</p>
<p>It can be important to know what range a parameter could take, and still be consistent with the data. This is particularly true
</p>
<p>when there are safety or legal considerations to worry about. Imagine you have a machine that fills cereal boxes. Each box
</p>
<p>gets a quantity of cereal that is random, but has low variance. If the weight of cereal in any box is below the amount printed
</p>
<p>on the label, you might be in trouble. When you choose the amount to print on the label, estimating the mean weight of
</p>
<p>cereal as a number might not be particularly helpful. If that estimate is a little low, you could have problems. Instead, what
</p>
<p>you&rsquo;d like to know is an interval that the mean lies in with very high probability. Then you can print a label number that is
</p>
<p>smaller than the smallest in the interval, and be confident that the amount in the box is more than the amount on the label.
</p>
<p>6.2.1 Constructing Confidence Intervals
</p>
<p>A statistic is a function of a dataset. One example of a statistic is the mean of dataset. You should notice that you can write
</p>
<p>out this function without actually drawing a sample. We observe the value of a statistic by applying the function to the dataset
</p>
<p>we obtained by drawing a sample. The dataset is random, because it is either a sample from a population or an IID sample
</p>
<p>from a distribution model. This means that we should think of the value of the statistic as the observed value of a random
</p>
<p>variable&mdash;if we had a different sample from the same population (resp. IID sample from the same distribution) we would
</p>
<p>compute a different value of the statistic. We are interested in the expected value of this random variable, rather than the
</p>
<p>observed value. We would like to use the observed value of the statistic to construct an interval where we have a specified
</p>
<p>confidence that the expected value lies in the interval.
</p>
<p>The meaning of these intervals can be somewhat delicate (and so can the constructions). I will show how to build these
</p>
<p>intervals in the case of a population mean. Here we wish to use the value of the sample mean to construct an interval for
</p>
<p>the population mean. We need to be careful about the meaning of the interval, because there is nothing random once the
</p>
<p>sample has been drawn. We can&rsquo;t talk sensibly about the probability that the population mean lies inside the interval, because
</p>
<p>the population mean isn&rsquo;t random. The interval will depend on the value of the sample mean, and so will differ from sample
</p>
<p>to sample. Choose some fraction f ; we will construct an interval so that, for that fraction of samples, the population mean will
</p>
<p>lie inside the interval constructed from the sample mean. The construction requires some detailed study of the distribution of
</p>
<p>sample means.
</p>
<p>Definition 6.1 (Confidence Interval for a Population Mean) Choose some fraction f . An f confidence interval for
</p>
<p>a population mean is an interval constructed using the sample mean. It has the property that for that fraction f of all
</p>
<p>samples, the population mean will lie inside the interval constructed from each sample&rsquo;s mean.
</p>
<p>Definition 6.2 (Centered Confidence Interval for a Population Mean) Choose some 0 &lt; ˛ &lt; 0:5. A 1 � 2˛
centered confidence interval for a population mean is an interval Œa; b&#141; constructed using the sample mean. It has the
</p>
<p>property that for ˛ of all samples, the population mean is greater than b, and for another ˛ of all samples, the population
</p>
<p>mean is less than a. For all other samples, the population mean will lie inside the interval.
</p>
<p>6.2.2 Estimating the Variance of the Sample Mean
</p>
<p>Recall the variance of the sample mean is
</p>
<p>popsd .fXg/2
</p>
<p>N
</p>
<p>which isn&rsquo;t much help currently, because we do not know popsd .fXg/. But we might estimate popsd .fXg/ by computing
the standard deviation of the examples that we have. I will write the sample using the notation for datasets, and will use
</p>
<p>mean .fxg/ D
P
</p>
<p>i xi
</p>
<p>N</p>
<p/>
</div>
<div class="page"><p/>
<p>6.2 Confidence Intervals 147
</p>
<p>for the mean of the sample&mdash;that is, the mean of the data we actually see. Similarly, I will write
</p>
<p>std .fxg/ D
</p>
<p>s
</p>
<p>P
</p>
<p>i2sample.xi � mean .fxg//2
</p>
<p>N
</p>
<p>for the sample standard deviation. Again, this is the standard deviation of the data we actually see; and again, this is
</p>
<p>consistent with our old notation. We could estimate
</p>
<p>popsd .fXg/ � std .fxg/
</p>
<p>and as long as we have enough examples, this estimate is good. It turns out that, if the number of samples N is small, it is
</p>
<p>better to use
</p>
<p>popsd .fXg/ �
</p>
<p>s
</p>
<p>P
</p>
<p>i.xi � mean .fxg//2
N � 1 :
</p>
<p>The exercises show that
</p>
<p>EŒpopsd .fXg/&#141; D std .x/
s
</p>
<p>�
</p>
<p>N
</p>
<p>N � 1
</p>
<p>�
</p>
<p>:
</p>
<p>This means that estimating popsd .fXg/ using std .x/ will produce a number that is reliably slightly too small. The estimate
is referred to as a biased estimate, because the expected value of the estimate is not what we want it to be. In this case, it is
</p>
<p>straightforward to produce an unbiased estimate, and an unbiased estimate of popsd .fXg/ is
</p>
<p>stdunbiased .fxg/ D
</p>
<p>s
</p>
<p>P
</p>
<p>i.xi � mean .fxg//2
N � 1 :
</p>
<p>The standard deviation of the estimate of the mean is often known as the standard error of the mean. I will write
</p>
<p>stderr .fxg/ D stdunbiased .fxg/p
N
</p>
<p>:
</p>
<p>This term allows us to draw a helpful distinction: the population has a standard deviation, and our estimate of its mean has a
</p>
<p>standard error.
</p>
<p>Definition 6.3 (Standard Error) Write X.N/ for the mean of N samples xi. X
.N/ is a random variable. An estimate of
</p>
<p>the standard deviation of X.N/ is
</p>
<p>stdunbiased .fxg/p
N
</p>
<p>:
</p>
<p>This estimate is the standard error of the mean.
</p>
<p>Here is what is causing the bias in our estimate of �2. The numerator of S2 is a sum of N numbers, but these numbers are
</p>
<p>not independent, because
X
</p>
<p>i
</p>
<p>.xi � mean .fxg// D 0:
</p>
<p>This means that there are only N � 1 independent numbers. Another way to see this is that, if you have N � 1 of the terms in
the sum, you can infer the N&rsquo;th; in turn, counting the N&rsquo;th number in the mean is unwise. Statisticians say that this average
</p>
<p>has N � 1 degrees of freedom.</p>
<p/>
</div>
<div class="page"><p/>
<p>148 6 Samples and Populations
</p>
<p>Number of items in sample
</p>
<p>0 20 40 60 80 100
</p>
<p>V
al
</p>
<p>u
e 
</p>
<p>in
 i
</p>
<p>n
ch
</p>
<p>es
67
</p>
<p>70
</p>
<p>73
</p>
<p>Sample means for human heights
</p>
<p>Fig. 6.1 A simple demonstration that sample means behave as described, by computing sample means from the heights dataset. I sampled elements
with replacement to form random subsets of sizes .9; 16; : : : ; 81/. For each of 100 subsets of each size, I computed the sample mean. This means
that there are 100 sample means for each sample size. I have represented these means by a boxplot. I then computed the population mean, and the
standard error as measured by the population standard deviation. The x to the side of each column is the population mean, and the vertical bars are
one standard error above and below the population mean. Notice how (a) the sample means vary less as the sample gets bigger and (b) the sample
means largely lie within the error bars, as they should
</p>
<p>Worked example 6.3 (Simulations Confirm the Standard Error Estimate) Compare the standard error of a mean
</p>
<p>estimate with the standard deviation predicted using the population from which the sample was drawn.
</p>
<p>Solution I used the heights column from the bodyfat dataset (from http://www2.stetson.edu/~jrasp/data.htm; look for
</p>
<p>bodyfat.xls). I removed the single height outlier. I simulated the population using the whole dataset (251 items), then
</p>
<p>drew numerous samples of various sizes, with replacement. I computed the mean of each of these sets of samples.
</p>
<p>Figure 6.1 shows a scatter plot of sample means for different samples, using a set of sizes .9; 16; : : : ; 81/. I have also
</p>
<p>plotted the population mean, and the true 1-standard error bars (i.e. using the population standard deviation) for each
</p>
<p>of these sample sizes. Notice how most sample means lie within the 1-standard error bars, as they should.
</p>
<p>6.2.3 The Probability Distribution of the Sample Mean
</p>
<p>The sample mean is a random variable. We know an expression for its mean and for its variance in terms of population mean
</p>
<p>and variance, and we know that for sufficiently large samples the sample mean is a normal random variable. We have that
</p>
<p>mean .fxg/ � popmean .fXg/
popsd .fXg/=
</p>
<p>p
N
</p>
<p>is a standard normal random variable. But we have to estimate the variance of the sample mean, and that estimate will be
</p>
<p>slightly wrong. Recall the notation
</p>
<p>stderr .fxg/ D stdunbiased .fxg/p
N
</p>
<p>:
</p>
<p>We are interested in the distribution of
</p>
<p>T D mean .fxg/ � popmean .fXg/
stderr .fxg/
</p>
<p>which is a random variable, because the samples are random.</p>
<p/>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
</div>
<div class="page"><p/>
<p>6.2 Confidence Intervals 149
</p>
<p>When N is small, the estimate of the population standard deviation using the sample standard deviation is more likely
</p>
<p>to be smaller than it should be, because there some probability of choosing a sample whose variance is smaller than the
</p>
<p>population&rsquo;s variance. In turn, the distance between the population mean and the sample mean in standard error units may
</p>
<p>be larger than a normal distribution predicts. This means the distribution of T must depend on N. It does so through the
</p>
<p>number of degrees of freedom in the estimate of the variance of the sample mean (which is N � 1). This means that there is
a family of distributions for T , indexed by the number of degrees of freedom. This family is of known form, and is known
</p>
<p>as t-distribution. A random variable whose distribution is a t-distribution is often known as a t-random variable. You will
</p>
<p>often see this referred to as Student&rsquo;s t-distribution, after the inventor who wrote very important statistical papers under a
</p>
<p>pseudonym because he was concerned his employer wouldn&rsquo;t like them (the story is worth looking up).
</p>
<p>When the number of degrees of freedom is small, the t-distribution has rather heavier tails than the normal distribution.
</p>
<p>However, when the number of degrees of freedom is large, the t-distribution is very similar to the normal distribution. If N
</p>
<p>is large (for some reason, 30 seems to be the magic number), then it is usually safe to regard the t-distribution as being the
</p>
<p>same as a normal distribution.
</p>
<p>Definition 6.4 (T-Distribution) Student&rsquo;s t-distribution is a probability distribution taken from a family, indexed by
</p>
<p>a number (the degrees of freedom of the distribution). The form of the distribution is not important to us. We will
</p>
<p>obtain values from tables or from software, and typically only need values of the cumulative distribution. When the
</p>
<p>number of degrees of freedom is large, the distribution is very similar to a normal distribution; otherwise, the tails are
</p>
<p>somewhat heavier than those of a normal distribution.
</p>
<p>Definition 6.5 (T-Random Variable) A t-random variable is a random variable whose distribution is a Student&rsquo;s
</p>
<p>t-distribution.
</p>
<p>Remember this: The sample mean yields the value of a t random variable. In particular,
</p>
<p>T D mean .fxg/ � popmean .fXg/
stderr .fxg/
</p>
<p>has a t-distribution with N � 1 degrees of freedom.
</p>
<p>Remember this: If N is large enough, the sample mean yields the value of a standard normal random variable. In
</p>
<p>particular, if N is large enough,
</p>
<p>Z D mean .fxg/ � popmean .fXg/
stderr .fxg/
</p>
<p>is a standard normal random variable.
</p>
<p>6.2.4 Confidence Intervals for PopulationMeans
</p>
<p>Here is a construction for a confidence interval for the mean of a population. Draw a sample randomly and with replacement
</p>
<p>of N items (write fxg for the sample), and compute the sample mean. The sample mean is the value of a random variable&mdash;
random, because it depends on the randomly drawn sample&mdash;whose probability distribution we know. Our estimate of the
</p>
<p>unknown number popmean .fXg/ is the mean of the sample we have, which we write mean .fxg/. We know that
</p>
<p>T D mean .fxg/ � popmean .fXg/
stderr .fxg/</p>
<p/>
</div>
<div class="page"><p/>
<p>150 6 Samples and Populations
</p>
<p>has a t-distribution. Now assume that N is large, so that the t-distribution is very similar to a standard normal distribution.
</p>
<p>But we know rather a lot about the behaviour of standard normal random variables. For about 68% of samples, t (the value
</p>
<p>of T) will lie between -1 and 1, and so on. In turn, this means that for about 68% of samples, popmean .fXg/ will lie in the
interval between mean .fxg/ � stderr .fxg/ and mean .fxg/C stderr .fxg/, and so on.
</p>
<p>Useful Facts 6.3 (Easy Confidence Intervals for a Big Sample)
</p>
<p>Assume the sample is large enough so that mean .fxg/ � popmean .fXg/=stderr .fxg/ is a standard normal random
variable. Recall the facts in box 5.10 (page 125). These yield
</p>
<p>For about 68% of samples:
</p>
<p>mean .fxg/ � stderr .fxg/ � popmean .fXg/ � mean .fxg/C stderr .fxg/:
</p>
<p>For about 95% of samples:
</p>
<p>mean.fxg/ � 2stderr.fxg/ � popmean.fXg/ � mean .fxg/C 2stderr .fxg/:
</p>
<p>For about 99% of samples:
</p>
<p>mean.fxg/ � 3stderr.fxg/ � popmean.fXg/ � mean .fxg/C 3stderr .fxg/:
</p>
<p>Worked example 6.4 (The Weight of Female Mice Eating Chow) Give a 95% confidence interval for the weight of
</p>
<p>a female mouse who ate chow, based on the dataset at http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml.
</p>
<p>Solution There are great datasets dealing with a wide range of genotype and phenotype variations in mice at this URL.
</p>
<p>The one to look at is Churchill.Mamm.Gen.2012.phenotypes.csv, which has information about 150 mice. 100 were fed
</p>
<p>with chow, and 50 with a high fat diet. You should look at Weight2, which seems to be a weight around the time the
</p>
<p>mouse was sacrificed. If we focus on the female mice who ate chow and whose weights are available (48 by my count),
</p>
<p>we find a mean weight of 27.78 gr, and a standard error of 0.70 gr (remember to divide by the square root of 48). This
</p>
<p>means that the interval we want runs from 26.38 to 29.18 gr.
</p>
<p>The authors ask that anyone using this data should cite the papers: High-Resolution Genetic Mapping Using the
</p>
<p>Mouse Diversity Outbred Population, Svenson KL, Gatti DM, Valdar W, Welsh CE, Cheng R, Chesler EJ, Palmer
</p>
<p>AA, McMillan L, Churchill GA. Genetics. 2012 Feb;190(2):437&ndash;47; and The Diversity Outbred Mouse Population
</p>
<p>Churchill GA, Gatti DM, Munger SC, Svenson KL Mammalian Genome 2012, Aug 15.
</p>
<p>We can plot the confidence interval by drawing error bars&mdash;draw a bar one (or two, or three) standard errors up and
</p>
<p>down from the estimate. We interpret this interval as representing the effect of sampling uncertainty on our estimate. If the
</p>
<p>urn model really did apply, then the confidence intervals have the property that the true mean lies inside the interval for about
</p>
<p>68% of possible samples (for one standard error bars; or 95% for two; etc.).
</p>
<p>Procedure 6.1 (Constructing a Centered 1� 2˛ Confidence Interval for a Population Mean for a Large Sample)
Draw a sample fxg of N items from a population. Recall
</p>
<p>stdunbiased.fxg/D
</p>
<p>s
</p>
<p>P
</p>
<p>i.xi�mean.fxg//2
N�1 :
</p>
<p>Estimate the standard error using
</p>
<p>stderr .fxg/ D stdunbiased .fxg/p
N
</p>
<p>:
</p>
<p>(continued)</p>
<p/>
<div class="annotation"><a href="http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml">http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml</a></div>
<div class="annotation"><a href="Churchill.Mamm.Gen.2012.phenotypes.csv">Churchill.Mamm.Gen.2012.phenotypes.csv</a></div>
</div>
<div class="page"><p/>
<p>6.2 Confidence Intervals 151
</p>
<p>If N is large enough, the variable
</p>
<p>T D mean .fxg/ � popmean .fXg/
stderr .fxg/
</p>
<p>is a standard normal random variable.
</p>
<p>Compute b such that for a standard normal random variable, P.fT � bg/ D ˛. You can do this using tables or
software. The confidence interval is then
</p>
<p>Œmean.fxg/ � b � stderr .fxg/;
</p>
<p>mean .fxg/C b � stderr .fxg/&#141; :
</p>
<p>Now assume that N is small enough so that T is a t-random variable (which will have N � 1 degrees of freedom).
Assume we wish to have a centered, 1 � 2˛ confidence interval. We can use tables or software to choose a value a so that
P.fT � ag/ D ˛ and a value b such that P.fT � bg/ D ˛. In fact, we will have a D �b. This is because t-random variables
have the property that P.fT � bg/ D P.fT � �bg/ (just like standard normal random variables; if you&rsquo;re in doubt, check
this point). Then for 1 � 2˛ of all samples, we have
</p>
<p>�b � T � b:
</p>
<p>This means that for 1 � 2˛ of all samples,
</p>
<p>mean .fxg/�b�stderr .fxg/�popmean .fXg/
</p>
<p>�mean .fxg/Cb�stderr .fxg/
</p>
<p>and so we have a centered, 1 � 2˛ confidence interval.
</p>
<p>Procedure 6.2 (Constructing a Centered 1� 2˛ Confidence Interval for a Population Mean for a Small Sample)
Draw a sample fxg of N items from a population. Recall
</p>
<p>stdunbiased.fxg/D
</p>
<p>s
</p>
<p>P
</p>
<p>i.xi�mean.fxg//2
N�1 :
</p>
<p>Estimate the standard error using
</p>
<p>stderr .fxg/ D stdunbiased .fxg/p
N
</p>
<p>:
</p>
<p>If N is small, the variable
</p>
<p>T D mean .fxg/ � popmean .fXg/
stderr .fxg/
</p>
<p>is a t-random variable.
</p>
<p>Compute b such that for a t-random variable, P.fT � bg/ D ˛. You can do this using tables or software. The
confidence interval is then
</p>
<p>Œmean .fxg/ � b � stderr .fxg/;
</p>
<p>mean .fxg/C b � stderr .fxg/&#141; :</p>
<p/>
</div>
<div class="page"><p/>
<p>152 6 Samples and Populations
</p>
<p>160 180 200 220
0
</p>
<p>100
</p>
<p>200
</p>
<p>300
</p>
<p>Median weight, 20 per sample
</p>
<p>Median weight
</p>
<p>N
u
</p>
<p>m
b
</p>
<p>er
 o
</p>
<p>f 
sa
</p>
<p>m
p
</p>
<p>le
s
</p>
<p>160 180 200 220
0
</p>
<p>100
</p>
<p>200
</p>
<p>300
</p>
<p>Median weight, 100 per sample
</p>
<p>Median weight
</p>
<p>N
u
</p>
<p>m
b
</p>
<p>er
 o
</p>
<p>f 
sa
</p>
<p>m
p
</p>
<p>le
s
</p>
<p>Fig. 6.2 I took the weights dataset used all 253 measurements to represent a population. Rather than compute the median of the whole population,
I chose to compute the median of a randomly chosen sample. The figures show a histogram of 1000 different values of the median, computed for
1000 different samples (of size 20 on the left, and of size 100 on the right). Notice that (a) there is a moderate amount of variation in the median
of the sample; (b) these histograms look normal, and appear to have about the same mean; (c) increasing the size of the sample has reduced the
spread of the histogram
</p>
<p>6.2.5 Standard Error Estimates from Simulation
</p>
<p>We were able to produce convenient and useful estimates of standard error for sample means. But what happens if we want
</p>
<p>to reason about, say, the median of a population? Estimating the standard error of a median is difficult mathematically, and
</p>
<p>estimating the standard error of other interesting statistics can be difficult, too. This is an important problem, because our
</p>
<p>methods for building confidence intervals and for testing hypotheses rely on being able to construct standard error estimates.
</p>
<p>Quite simple simulation methods give very good estimates of standard error.
</p>
<p>The distribution of median values for different samples of a population looks normal by simple tests. For Fig. 6.2, I
</p>
<p>assumed that all 253 weight measurements represented the entire population, then simulated what would happen for different
</p>
<p>random samples (with replacement) of different sizes. Figure 6.2 suggests that the sample median behaves quite like the
</p>
<p>sample mean as the random sample changes. Different samples have different medians, but the distribution of values looks
</p>
<p>fairly normal. When there are more elements in the sample, the standard deviation of median values is smaller, but we have
</p>
<p>no expression for this standard deviation in terms of the sample.
</p>
<p>There is a method, known as the bootstrap, which gives a very good estimate of the standard error of any statistic.
</p>
<p>Assume we wish to estimate the standard error of a statistic S.fxg/, which is a function of our dataset fxg of N data items.
We compute r bootstrap replicates of this sample. Each replicate is obtained by sampling the dataset uniformly, and with
</p>
<p>replacement. One helpful way to think of this is that we are modelling our dataset as a sample of a probability distribution.
</p>
<p>This distribution, sometimes known as the empirical distribution, has probability 1=N at each of the data items we see,
</p>
<p>and zero elsewhere. Now to obtain replicates, we simply draw new sets of IID samples from this probability distribution.
</p>
<p>Notice that the bootstrap replicates are not a random permutation of the dataset; instead, we select one data item fairly and
</p>
<p>at random from the whole dataset N times. This means we expect a particular bootstrap replicate will have multiple copies
</p>
<p>of some data items, and no copies of others.
</p>
<p>We write fxgi for the i&rsquo;th bootstrap replicate of the dataset. We now compute
</p>
<p>S D
P
</p>
<p>i S.fxgi/
r
</p>
<p>and the standard error estimate for S is given by:
</p>
<p>stderr .fSg/ D
</p>
<p>s
</p>
<p>P
</p>
<p>i
</p>
<p>�
</p>
<p>S.fxgi/ � S
�2
</p>
<p>r � 1</p>
<p/>
</div>
<div class="page"><p/>
<p>6.2 Confidence Intervals 153
</p>
<p>0 500 1000 1500
0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>Histogram of CEO Salaries, $thousands
</p>
<p>200 300 400 500 600
0
</p>
<p>500
</p>
<p>1000
</p>
<p>1500
</p>
<p>2000
</p>
<p>2500
</p>
<p>3000
</p>
<p>Medians of 10000 Bootstrap replicates
</p>
<p>Fig. 6.3 On the left, a histogram of salaries for CEO&rsquo;s of small companies in 1993, from the dataset of http://lib.stat.cmu.edu/DASL/Datafiles/
ceodat.html. On the right, a histogram of the medians of 10,000 bootstrap replicates of this data. This simulates the effect of sampling variation on
the median; see Worked example 6.5
</p>
<p>Worked example 6.5 (The Bootstrap Standard Error of the Median) You can find a dataset giving the salaries
</p>
<p>of CEO&rsquo;s at small firms in 1993 at http://lib.stat.cmu.edu/DASL/Datafiles/ceodat.html. Construct a 90% confidence
</p>
<p>interval for the median salary.
</p>
<p>Solution Salaries are in thousands of dollars, and one salary isn&rsquo;t given (we omit this value in what follows). Figure 6.3
</p>
<p>shows a histogram of the salaries; notice there are some values that look like outliers. This justifies using a median. The
</p>
<p>median of the dataset is 350 (i.e. $350,000&mdash;this is 1993 data!). I constructed 10,000 bootstrap replicates. Figure 6.3
</p>
<p>shows a histogram of the medians of the replicates. I used the matlab prctile function to extract the 5% and 95%
</p>
<p>percentiles of these medians, yielding the interval between 298 and 390. This means that we can expect that, for 90%
</p>
<p>of samples of CEO salaries for small companies, the median salary will be in the given range.
</p>
<p>Procedure 6.3 (The Bootstrap) Estimate the standard error for a statistic S evaluated on a dataset of N items fxg.
</p>
<p>1. Compute r bootstrap replicates of the dataset. Write the i&rsquo;th replicate fxgi Obtain each by:
(a) Building a uniform probability distribution on the numbers 1 : : :N.
</p>
<p>(b) Drawing N independent samples from this distribution. Write s.i/ for the i&rsquo;th such sample.
</p>
<p>(c) Building a new dataset
˚
</p>
<p>xs.1/; : : : ; xs.N/
�
</p>
<p>.
</p>
<p>2. For each replicate, compute S.fxgi/.
3. Compute
</p>
<p>S D
P
</p>
<p>i S.fxgi/
r
</p>
<p>4. The standard error estimate for S is given by:
</p>
<p>stderr .fSg/ D
</p>
<p>s
</p>
<p>P
</p>
<p>i
</p>
<p>�
</p>
<p>S.fxgi/ � S
�2
</p>
<p>r � 1</p>
<p/>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/ceodat.html">http://lib.stat.cmu.edu/DASL/Datafiles/ceodat.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/ceodat.html">http://lib.stat.cmu.edu/DASL/Datafiles/ceodat.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/ceodat.html">http://lib.stat.cmu.edu/DASL/Datafiles/ceodat.html</a></div>
</div>
<div class="page"><p/>
<p>154 6 Samples and Populations
</p>
<p>6.3 You Should
</p>
<p>6.3.1 Remember These Definitions
</p>
<p>Confidence interval for a population mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
</p>
<p>Centered confidence interval for a population mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
</p>
<p>Standard error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
</p>
<p>T-distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
</p>
<p>T-random variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
</p>
<p>6.3.2 Remember These Terms
</p>
<p>population . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
</p>
<p>sample . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
</p>
<p>population mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
</p>
<p>sample mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
</p>
<p>statistic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
</p>
<p>biased estimate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
</p>
<p>unbiased estimate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
</p>
<p>degrees of freedom . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
</p>
<p>error bars . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
</p>
<p>bootstrap . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
</p>
<p>bootstrap replicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
</p>
<p>empirical distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
</p>
<p>6.3.3 Remember These Facts
</p>
<p>Properties of sample and population means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
</p>
<p>Expressions for mean and variance of the sample mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
</p>
<p>Easy confidence intervals for a big sample . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
</p>
<p>6.3.4 Use These Procedures
</p>
<p>To compute a confidence interval for a population mean, large sample . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
</p>
<p>To compute a confidence interval for a population mean, small sample . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
</p>
<p>To compute a bootstrap estimate of standard error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
</p>
<p>6.3.5 Be Able to
</p>
<p>&bull; Compute the standard error of a sample mean.
</p>
<p>&bull; Plot and interpret error bars.
</p>
<p>&bull; Compute a confidence interval for a population mean using a sample.
</p>
<p>&bull; Compute a confidence interval for a population median using bootstrap samples.</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 155
</p>
<p>Problems
</p>
<p>Estimating the Population Standard Deviation
</p>
<p>6.1 We have a population fXg, and we study random samples of N items (drawn with replacement). We write any particular
sample fxg. Now consider std .fxg/2. This is a random variable (because different random samples of data would produce
different values, at random).
</p>
<p>(a) Show that E
h
</p>
<p>std .fxg/2
i
</p>
<p>is equal to
</p>
<p>E
�
P
</p>
<p>i.xi � popmean .fXg//2=N
�
</p>
<p>�
</p>
<p>.2=N/E
�
</p>
<p>.mean .fxg/ � popmean .fXg//
P
</p>
<p>i.xi � popmean .fXg//
�
</p>
<p>C
</p>
<p>E
�
</p>
<p>.mean .fxg/ � popmean .fXg//2
�
</p>
<p>:
</p>
<p>(here the expectation is over sampling, though this has nothing to do with the point).
</p>
<p>(b) Now show that for any sample
</p>
<p>X
</p>
<p>i
</p>
<p>.xi � popmean .fXg// D N.mean .fxg/ � popmean .fXg//:
</p>
<p>(c) Now use the methods of Sect. 6.1.1 to show that
</p>
<p>E
�
</p>
<p>.mean .fxg/ � popmean .fXg//2
�
</p>
<p>D popsd .fXg/
2
</p>
<p>N
:
</p>
<p>(d) Now show that
</p>
<p>E
</p>
<p>h
</p>
<p>std .fXg/2
i
</p>
<p>D popsd .fXg/2
�
</p>
<p>N � 1
N
</p>
<p>�
</p>
<p>:
</p>
<p>Samples and Populations
</p>
<p>6.2 The Average Mouse: You wish to estimate the average weight of a mouse. You obtain 10 mice, sampled uniformly
</p>
<p>at random and with replacement from the mouse population. Their weights are 21; 23; 27; 19; 17; 18; 20; 15; 17; 22 grams
</p>
<p>respectively.
</p>
<p>(a) What is the best estimate for the average weight of a mouse, from this data?
</p>
<p>(b) What is the standard error of this estimate?
</p>
<p>(c) How many mice would you need to reduce the standard error to 0.1?
</p>
<p>6.3 Sample Variance and Standard Error: You encounter a deck of Martian playing cards. There are 87 cards in the deck.
</p>
<p>You cannot read Martian, and so the meaning of the cards is mysterious. However, you notice that some cards are blue, and
</p>
<p>others are yellow.
</p>
<p>(a) You shuffle the deck, and draw one card. You repeat this exercise 10 times, replacing the card you drew each time before
</p>
<p>shuffling. You see 7 yellow and 3 blue cards in the deck. As you know, the maximum likelihood estimate of the fraction
</p>
<p>of blue cards in the deck is 0.3. What is the standard error of this estimate?
</p>
<p>(b) How many times would you need to repeat the exercise to reduce the standard error to 0.05?</p>
<p/>
</div>
<div class="page"><p/>
<p>156 6 Samples and Populations
</p>
<p>Confidence Intervals for PopulationMeans
</p>
<p>6.4 The Weight of Rats You wish to estimate the average weight of a pet rat. You obtain 40 rats (eas-
</p>
<p>ily and cheaply done; keep them, because they make excellent pets), sampled uniformly at random and with
</p>
<p>replacement from the pet rat population. The mean weight is 340 grams, with a standard deviation of 75
</p>
<p>grams.
</p>
<p>(a) Give a 68% confidence interval for the weight of a pet rat, from this data.
</p>
<p>(b) Give a 99% confidence interval for the weight of a pet rat, from this data.
</p>
<p>6.5 The Weight of Mice You wish to estimate the average weight of a mouse. You obtain 10 mice, sampled uniformly
</p>
<p>at random and with replacement from the mouse population. Their weights are 21; 23; 27; 19; 17; 18; 20; 15; 17; 22 grams
</p>
<p>respectively. Notice there are too few mice to use a normal model.
</p>
<p>(a) Give an 80% confidence interval for the weight of a mouse, from this data.
</p>
<p>(b) Give a 95% confidence interval for the weight of a mouse, from this data.
</p>
<p>6.6 The Probability of a Female Birth In Carcelle-le-Grignon at the end of the eighteenth century, there were 2009 births.
</p>
<p>There were 983 boys and 1026 girls. You can regard this as a fair random sample (with replacement, though try not to think
</p>
<p>too hard about what that means) of births. If you map each female birth to 1 and each male birth to 0, the probability of a
</p>
<p>female birth is the population mean of this random variable. You have a sample of 2009 births.
</p>
<p>(a) Using the reasoning and data above, construct a 99% confidence interval for the probability of a female birth.
</p>
<p>(b) Using the reasoning and data above, construct a 99% confidence interval for the probability of a male birth.
</p>
<p>(c) Do these intervals overlap? what does this suggest?
</p>
<p>6.7 Carcinomas vs Adipose Tissue The UC Irvine Machine Learning data repository hosts a dataset giving various
</p>
<p>electromagnetic measurements for different kinds of breast tissue. You can find the data at http://archive.ics.uci.edu/ml/
</p>
<p>datasets/Breast+Tissue. It was submitted by JP. Marques de S&aacute; and J. Jossinet.
</p>
<p>(a) Using this data, construct a 99% confidence interval for the mean value of the I0 variable for tissue from a carcinoma.
</p>
<p>(b) Using this data, construct a 99% confidence interval for the mean value of the I0 variable for adipose tissue.
</p>
<p>(c) Do these intervals overlap? what does this suggest?
</p>
<p>6.8 Wine The UC Irvine Machine Learning data repository hosts a dataset giving various measurements of wine from three
</p>
<p>different regions of Italy. You can find the data at http://archive.ics.uci.edu/ml/datasets/Wine. This data was submitted by S.
</p>
<p>Aeberhard and seems to have originally been owned by M. Forina
</p>
<p>(a) Using this data, construct a 99% confidence interval for the mean value of the flavanoids variable for wine from region
</p>
<p>1.
</p>
<p>(b) Using this data, construct a 99% confidence interval for the mean value of the flavanoids variable for wine from region
</p>
<p>3.
</p>
<p>(c) Do these intervals overlap? what does this suggest?
</p>
<p>Programming Exercises
</p>
<p>6.9 Investigating the construction of confidence intervals The UC Irvine Machine Learning data repository hosts a dataset
</p>
<p>giving various measurements of abalone at https://archive.ics.uci.edu/ml/datasets/Abalone. This data comes from an original
</p>
<p>study by W.J. Nash, T.L. Sellers, S.R. Talbot, A.J. Cawthorn and W. B. Ford, called &ldquo;The Population Biology of Abalone
</p>
<p>(Haliotis species) in Tasmania. I. Blacklip Abalone (H. rubra) from the North Coast and Islands of Bass Strait&rdquo;, Sea Fisheries
</p>
<p>Division, Technical Report No. 48 (ISSN 1034-3288) (1994). The data was donated by S. Waugh. There are 4177 records.</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Breast+Tissue">http://archive.ics.uci.edu/ml/datasets/Breast+Tissue</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Breast+Tissue">http://archive.ics.uci.edu/ml/datasets/Breast+Tissue</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Wine">http://archive.ics.uci.edu/ml/datasets/Wine</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Abalone">https://archive.ics.uci.edu/ml/datasets/Abalone</a></div>
</div>
<div class="page"><p/>
<p>Programming Exercises 157
</p>
<p>We will use the Length measurement. We will assume that the 4177 records is the entire population. Compute the population
</p>
<p>mean.
</p>
<p>(a) Draw 10,000 samples of 20 records at random with replacement. Use each sample to compute a centered 90% confidence
</p>
<p>interval for the population mean, using the t-distribution. For what fraction of samples does the true population mean lie
</p>
<p>inside the interval?
</p>
<p>(b) Draw 10,000 samples of 10 records at random with replacement. Use each sample to compute a centered 90% confidence
</p>
<p>interval for the population mean, using the t-distribution. For what fraction of samples does the true population mean lie
</p>
<p>inside the interval?
</p>
<p>(c) Draw 10,000 samples of 10 records at random with replacement. Use each sample to compute a centered 90% confidence
</p>
<p>interval for the population mean, using a normal model (which you really shouldn&rsquo;t, because the sample is too small).
</p>
<p>For what fraction of samples does the true population mean lie inside the interval?
</p>
<p>(d) Now repeat the last two subexercises, but using only three records. What conclusion do you draw?
</p>
<p>6.10 Investigating the construction of bootstrap confidence intervals The UC Irvine Machine Learning data repository
</p>
<p>hosts a dataset giving various measurements of abalone at https://archive.ics.uci.edu/ml/datasets/Abalone. This data comes
</p>
<p>from an original study by W.J. Nash, T.L. Sellers, S.R. Talbot, A.J. Cawthorn and W. B. Ford, called &ldquo;The Population Biology
</p>
<p>of Abalone (Haliotis species) in Tasmania. I. Blacklip Abalone (H. rubra) from the North Coast and Islands of Bass Strait&rdquo;,
</p>
<p>Sea Fisheries Division, Technical Report No. 48 (ISSN 1034-3288) (1994). The data was donated by S. Waugh. There are
</p>
<p>4177 records. We will use the Length measurement. We will assume that the 4177 records is the entire population. Compute
</p>
<p>the population median.
</p>
<p>(a) Draw 10,000 samples of 100 records at random with replacement. Use each sample to produce a bootstrap estimate of
</p>
<p>a centered 90% confidence interval for the population median. For what fraction of samples does the true population
</p>
<p>median lie inside the interval?
</p>
<p>(b) Draw 10,000 samples of 30 records at random with replacement. Use each sample to produce a bootstrap estimate of
</p>
<p>a centered 90% confidence interval for the population median. For what fraction of samples does the true population
</p>
<p>median lie inside the interval?
</p>
<p>(c) Draw 10,000 samples of 10 records at random with replacement. Use each sample to produce a bootstrap estimate of
</p>
<p>a centered 90% confidence interval for the population median. For what fraction of samples does the true population
</p>
<p>median lie inside the interval?
</p>
<p>(d) What conclusion do you draw?</p>
<p/>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Abalone">https://archive.ics.uci.edu/ml/datasets/Abalone</a></div>
</div>
<div class="page"><p/>
<p>7The Significance of Evidence
</p>
<p>Imagine you believe the mean human body weight is 72 kg. The mean human weight isn&rsquo;t a random number, but it&rsquo;s very
</p>
<p>hard to measure directly. You are forced to take a sample, and compute the sample mean. This sample mean is a random
</p>
<p>variable, and it will have different values for different samples. You need to know how to tell whether the difference between
</p>
<p>the observed value and 72 kg is just an effect of variance caused by sampling, or is because the mean weight actually isn&rsquo;t
</p>
<p>72 kg. One strategy is to construct an interval around the sample mean within which the true value will lie for (say) 99% of
</p>
<p>possible samples. If 72 kg is outside that interval, then very few samples are consistent with the idea that 72 kg is the mean
</p>
<p>human body weight. If you want to believe the mean human body weight is 72 kg, you have to believe that you obtained a
</p>
<p>very odd sample.
</p>
<p>You should think of the procedure I described as assessing the extent to which the evidence you have contradicts the
</p>
<p>original hypothesis. At first glance, this may seem strange to you&mdash;surely one wants to assess the extent to which the
</p>
<p>evidence supports the hypothesis&mdash;but in fact it&rsquo;s natural. You can&rsquo;t prove that a scientific hypothesis is true; you can only
</p>
<p>fail to show that it&rsquo;s false. Just one piece of evidence can destroy a scientific hypothesis, but no amount of evidence can
</p>
<p>remove all doubt.
</p>
<p>There is an important, quite general, line of reasoning here. It is a bad idea to try and explain data using a hypothesis
</p>
<p>that makes the data you observed a rare event. We can use the reasoning of Sect. 6.2 to assess how rare the observed data is.
</p>
<p>In that section, we used the distribution that the sample mean would take to construct a confidence interval. This meant we
</p>
<p>could plot an interval in which the population mean would lie with (say) 95% confidence. To assess the rarity of the sample,
</p>
<p>we could ask how large a confidence interval we would have to draw around the hypothesized mean to cover the observed
</p>
<p>sample mean. If that interval is relatively small (say 50%), then it&rsquo;s quite possible that the population mean takes the value we
</p>
<p>hypothesized. A cleaner way to say this is we do not have enough evidence to reject the hypothesis. If that interval requires
</p>
<p>(say) 99.99% of possible samples, that&rsquo;s a strong suggestion that the sample is extremely unusual. Assessing the rarity of the
</p>
<p>sample using methods like this is usually talked about as testing the significance of evidence against the hypothesis.
</p>
<p>Example 7.1 (Patriot Missiles) I got this example from &ldquo;Dueling idiots&rdquo;, a nice book by P.J. Nahin, Princeton
</p>
<p>University Press. Apparently in 1992, the Boston Globe of Jan 24 reported on this controversy. The pentagon claimed
</p>
<p>that the patriot missile successfully engaged SCUD missiles in 80% of encounters. An MIT physicist, Theodore Postol,
</p>
<p>pointed out there was a problem. He viewed tapes of 14 patriot/SCUD encounters, with one hit and 13 misses. We can
</p>
<p>reasonably assume each encounter is independent. We can extract the probability of getting one hit and 13 misses if
</p>
<p>P.hit/ D 0:8 from the binomial model, to get a number around 1e-8. Now you could look at this information and make
several arguments: (a) the pentagon is right and the probability really is 0.8, but Postol looked at a really unlucky set
</p>
<p>of videotapes; (b) the probability is not 0.8, because you would need to fire 14 patriots at 14 SCUD missiles about
</p>
<p>1e8 times to see this set of videotapes once; (c) for some reason, the videotapes are not independent&mdash;perhaps only
</p>
<p>unsuccessful encounters get filmed. If Postol viewed tapes at random (i.e. he didn&rsquo;t select only unsuccessful tapes,
</p>
<p>etc.), then argument (a) is easily dismissed, because the pentagon would have had to be unreasonably unlucky&mdash;it&rsquo;s a
</p>
<p>bad idea to try to explain data with a hypothesis that makes the data very unlikely.
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_7
</p>
<p>159</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_7">https://doi.org/10.1007/978-3-319-64410-3_7</a></div>
</div>
<div class="page"><p/>
<p>160 7 The Significance of Evidence
</p>
<p>This reasoning can be extended to compare populations. Imagine I want to know whether mice weigh more than rats. For
</p>
<p>practical reasons, I will estimate the weights using a sample. But this means that two different estimates will have different
</p>
<p>values purely because I used different samples. I am now in a difficult position&mdash;perhaps my observed sample mean for the
</p>
<p>weight of mice is smaller than that for rats because of random variation in the sample value. But now imagine drawing a
</p>
<p>(say) 95% confidence interval about each mean&mdash;if these don&rsquo;t overlap, then the population means are likely not the same.
</p>
<p>If you did the exercises for the last section, you will have noticed that I was signalling this idea. The principle here is that
</p>
<p>a very large difference may be hard to explain with random variation unless you are willing to believe in very odd samples.
</p>
<p>This leads to a procedure that can be used to decide whether (say) mice weigh more than rats.
</p>
<p>7.1 Significance
</p>
<p>Imagine we hypothesize that the average human body temperature is 95ı. We collect temperature measurements xi from a
random sample of N people. The mean of this sample is unlikely to be 95ı. The sample will likely have too many people
who run too hot, or too cool, to get exactly the number we expect. We must now find what caused the difference between
</p>
<p>the sample mean and the value we hypothesized. We could be wrong about the average body temperature. Alternatively, we
</p>
<p>could be right, and the difference might just be because the sample is randomly chosen. We can assess the significance of
</p>
<p>the evidence against the hypothesis by finding out what fraction of samples would give us sample means like the one we
</p>
<p>observe if the hypothesis is true.
</p>
<p>7.1.1 Evaluating Significance
</p>
<p>We hypothesize that a population mean has some value popmean .fXg/ (a big letter, because we don&rsquo;t see the whole
population). Write S for the random variable representing a possible sample mean. The mean of this random variable is
</p>
<p>the population mean, and the standard deviation of this random variable is estimated by the standard error, which we write
</p>
<p>stderr .fxg/ (small letters, because we got this from the sample) Now consider the random variable
</p>
<p>T D .S � popmean .fXg//
stderr .fxg/ :
</p>
<p>This random variable has a t-distribution with N�1 degrees of freedom (or, if N is big enough, we can regard it as a standard
normal random variable). We now have a way to tell whether the evidence supports our hypothesis. We assess how strange
</p>
<p>the sample would have to be to yield the value that we actually see, if the hypothesis is true. We can do this, because we
</p>
<p>can compute the fraction of samples that would have a less extreme value. Write s for the value of S that we observe. This
</p>
<p>yields t (the observed value of T , which is usually known as the test statistic). Write pt.uIN � 1/ for the probability density
function of a t-distribution with N � 1 degrees of freedom. Now the fraction of samples that will have less extreme values of
s if the population mean was, indeed, popmean .fXg/ is:
</p>
<p>f D 1p
2�
</p>
<p>Z jsj
</p>
<p>�jsj
pt.uIN � 1/du:
</p>
<p>Remember that, if N is sufficiently large, we can use a standard normal distribution in place of pt.uIN � 1/. Now
assume we see a very large (or very small) value of v. The value of f will be close to one, which implies that most samples
</p>
<p>from the population will have a v value closer to zero if the hypothesis were true. Equivalently, this says that, if the hypothesis
</p>
<p>were true, our sample is highly unusual, which implies the data fails to support the hypothesis.</p>
<p/>
</div>
<div class="page"><p/>
<p>7.1 Significance 161
</p>
<p>Worked example 7.1 (Samples of 44 Male Chow Eating Mice) Assume the mean weight of a male chow eating
</p>
<p>mouse is 35 gr. and the standard error of a sample of 44 such mice is 0.827 gr. What fraction of samples of 44 such
</p>
<p>mice will have a sample mean in the range 33&ndash;37 grams?
</p>
<p>Solution You could use the data at http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml, but you don&rsquo;t really need
</p>
<p>it to answer this question. Write S for the sample mean weight of a sample of 44 male chow eating mice. Because we
</p>
<p>assumed that the true mean weight is 35 gr, we have
</p>
<p>T D S � 35
0:827
</p>
<p>is a t-distributed random variable, with 43 degrees of freedom. The question is asking for the probability that T takes
</p>
<p>a value in the range Œ.33� 35/=0:827; .37� 35/=0:827&#141;, which is Œ�2:41; 2:41&#141;. There are enough degrees of freedom
to regard S as normal, so this probability is
</p>
<p>Z 2:41
</p>
<p>�2:41
</p>
<p>1p
2�
</p>
<p>exp .�u2=2/du � 0:984
</p>
<p>a number I found in tables. In turn, this means about 98.4% of samples of 44 chow eating male mice will give a mean
</p>
<p>weight in this range, if the population mean is truly 35 gr.
</p>
<p>Worked example 7.2 (Samples of 48 Chow-Eating Female Mice) Assume the population mean of the weight of
</p>
<p>a chow-eating female mouse is 27.8 gr. Use the data at http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml to
</p>
<p>estimate the fraction of samples that will have mean weight greater than 29 gr.
</p>
<p>Solution From Worked example 6.4, the standard error of a sample of 48 chow-eating female mice is 0.70 gr. Write S
</p>
<p>for a sample mean of a sample of 48 chow-eating female mice. Because we assumed that the true mean was 27.8 gr,
</p>
<p>we have
</p>
<p>T D S � 27:8
0:70
</p>
<p>is a t-distributed random variable, with 47 degrees of freedom. The question is asking for the probability that T takes
</p>
<p>a value greater than .29 � 27:8/=0:7 D 1:7143. There are enough degrees of freedom to regard T as normal, so this
probability is
</p>
<p>Z 1
</p>
<p>1:7143
</p>
<p>1p
2�
</p>
<p>exp .�x2=2/dx � 0:043
</p>
<p>a number I found in tables. In turn, this means about 4% of samples of 48 chow eating female mice will give a mean
</p>
<p>weight greater than 29 gr, if the population mean is truly 27.8 gr
</p>
<p>7.1.2 P-Values
</p>
<p>The procedure of the previous section computes the fraction of samples that would give a smaller absolute value of T than
</p>
<p>the one we observed if the hypothesis was true. I called this fraction f . It is easier (and more traditional) to think about
</p>
<p>p D 1� f than about f . You should think of p as representing the fraction of samples that would give a larger absolute value
of T than the one observed, if the hypothesis was true. If this fraction is very small, then there is significant evidence against
</p>
<p>the hypothesis. The fraction is sometimes referred to as a p-value.</p>
<p/>
<div class="annotation"><a href="http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml">http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml</a></div>
<div class="annotation"><a href="http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml">http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml</a></div>
</div>
<div class="page"><p/>
<p>162 7 The Significance of Evidence
</p>
<p>Definition 7.1 (p-Value) The p-value represents the fraction of samples that would give a more extreme value of the
</p>
<p>test statistic than that observed, if the hypothesis was true.
</p>
<p>Here is one useful interpretation of a p-value. Assume that you are willing to believe the hypothesis when the p-value is
</p>
<p>˛ or less, and will reject it otherwise. Then the probability that you accept a hypothesis that is false (i.e. a false positive, or
</p>
<p>type I error) is the fraction of samples that would give you that p-value or less even though the hypothesis is true. But this
</p>
<p>is ˛&mdash;so you can interpret a p-value as the probability that you have accepted a hypothesis that is false. This view yields the
</p>
<p>definition of significance, which is delicate.
</p>
<p>Definition 7.2 (Statistical Significance) Statistical significance is a term that is used in a variety of ways. One can
</p>
<p>refer to the significance of a set of measurements. In this context, the term means the p-value for the relevant test
</p>
<p>statistic for those measurements. One can refer to the significance of a study. In this context, the term refers to the
</p>
<p>value against which the p-value of the test statistic will be tested. This value is, ideally, chosen in advance. It should be
</p>
<p>interpreted as meaning the fraction of all possible samples that the study could encounter that would cause the chosen
</p>
<p>procedure to reject the null hypothesis, given that it was true.
</p>
<p>The procedure I have described for evaluating evidence against a hypothetical population mean is known as a T-test. I
</p>
<p>have put the details in box 7.1. The procedure is worth knowing because it is useful and very widely used. It also sketches the
</p>
<p>general form for tests of significance. You determine a statistic which can be used to test the particular proposition you have
</p>
<p>in mind. This statistic needs to: (a) depend on your data; (b) depend on your hypothesis; and (c) have a known distribution
</p>
<p>under sampling variation. You compute the value of this statistic. You then look at the distribution to determine what fraction
</p>
<p>of samples would have a more extreme value. If this fraction is small, the evidence suggests your hypothesis isn&rsquo;t true.
</p>
<p>Procedure 7.1 (The T-Test of Significance for a Hypothesized Mean) The initial hypothesis is that the population
</p>
<p>has a known mean, which we write �. Write fxg for the sample, and N for the sample size.
</p>
<p>&bull; Compute the sample mean, which we write mean .fxg/.
&bull; Estimate the standard error stderr .fxg/ using
</p>
<p>stderr .fxg/ D stdunbiased .fxg/p
N
</p>
<p>:
</p>
<p>&bull; Compute the test statistic using
</p>
<p>v D .� � mean .fxg//
stderr .fxg/ :
</p>
<p>&bull; Compute the p-value, using one of the recipes below.
</p>
<p>&bull; The p-value summarizes the extent to which the data contradicts the hypothesis. A small p-value implies that, if the
</p>
<p>hypothesis is true, the sample is very unusual. The smaller the p-value, the more strongly the evidence contradicts
</p>
<p>the hypothesis.
</p>
<p>It is common to think that a hypothesis can be rejected only if the p-value is less than 5% (or some number). You
</p>
<p>should not think this way; the p-value summarizes the extent to which the data contradicts the hypothesis, and your
</p>
<p>particular application logic affects how you interpret it.
</p>
<p>There is more than one way to compute a p-value. In one approach, we compute the fraction of experiments that would
</p>
<p>give us a larger absolute value of t than the one we saw, computing</p>
<p/>
</div>
<div class="page"><p/>
<p>7.1 Significance 163
</p>
<p>p D .1 � f / D 1 �
Z jsj
</p>
<p>�jsj
pt.uIN � 1/du
</p>
<p>Here the probability distribution we use is either a t-distribution with N � 1 degrees of freedom, or a normal distribution if N
is sufficiently large. Recall I wrote S for the sample mean as a random variable (i.e. before we&rsquo;ve actually drawn a sample)
</p>
<p>and s for the value of that random variable. You should interpret p using
</p>
<p>p D P.fS &gt; jsjg/ [ P.fS &lt; �jsjg/:
</p>
<p>It&rsquo;s usual to look this number up in tables; alternatively, any reasonable math computing environment will produce a number.
</p>
<p>This is known as a two-sided p-value (because you are computing the probability that either fS &gt; jsjg or fS &lt; �jsjg).
</p>
<p>Procedure 7.2 (Computing a Two-Sided p-Value for a T-Test) Evaluate
</p>
<p>p D .1 � f / D 1 �
Z jtj
</p>
<p>�jtj
pt.uIN � 1/du D P.fS &gt; jsjg/ [ P.fS &lt; �jsjg/
</p>
<p>where pt.uIN � 1/ is the probability density of a t-distribution. If N &gt; 30, it is enough to replace pt with the density of
a standard normal distribution.
</p>
<p>Under some circumstances, one might compute a one-sided p-value. Here one computes either
</p>
<p>p D P.fS &gt; jsjg/
</p>
<p>or
</p>
<p>p D P.fS &lt; �jsjg/:
</p>
<p>Generally, it is more conservative to use a two-sided test, and one should do so unless there is a good reason not to. Very
</p>
<p>often, authors use one-sided tests because they result in smaller p-values, and small p-values are often a requirement for
</p>
<p>publication. This is not sensible behavior.
</p>
<p>Procedure 7.3 (Computing a One-Sided p-Value for a T-Test) First, don&rsquo;t do this unless you have a good reason
</p>
<p>(getting a value less than 0.05 doesn&rsquo;t count). Now determine which side is important to you&mdash;which of P.fS &gt; jsjg/
or P.fS &lt; �jsjg/ do you care about, and why? If this process of thought hasn&rsquo;t dissuaded you, compute
</p>
<p>p D P.fS &gt; jsjg/
</p>
<p>or
</p>
<p>p D P.fS &lt; �jsjg/
</p>
<p>using the probability density of a t-distribution, as above. If N &gt; 30, it is enough to replace pt with the density of a
</p>
<p>standard normal distribution.
</p>
<p>Once we have the p-value, evaluating significance is straightforward. A small p-value means that very few samples would
</p>
<p>display more extreme behavior than what we saw, if the null hypothesis is true. In turn, a small p-value means that, to believe
</p>
<p>our null hypothesis, we are forced to believe we have an extremely odd sample. More formally, the p-value that we compute
</p>
<p>is described as an assessment of the significance of the evidence against the null hypothesis. The p-value is smaller when
</p>
<p>the evidence against the null hypothesis is stronger. We get to decide how small a p-value means we should reject the null
</p>
<p>hypothesis.</p>
<p/>
</div>
<div class="page"><p/>
<p>164 7 The Significance of Evidence
</p>
<p>Worked example 7.3 (If the Mean Length of an Adult Male Mouse is 10 cm, How Unusual is the Sample in
</p>
<p>the Mouse Dataset?) The mouse dataset is the one at http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml. The
</p>
<p>variable to look at is Length2 (which appears to be the length of the mouse at the point it is sacrificed). We need to
</p>
<p>compute the p value.
</p>
<p>Solution The mean length of male mice in this data is 9.5 cm, and the standard error is 0.045 cm. Write S for the
</p>
<p>sample mean length of some sample of male mice. This (unknown) value is a random variable. Assuming that the
</p>
<p>mean length really is 10, we have that
</p>
<p>T D S � 10
0:045
</p>
<p>and there are enough mice to assume that this is a normal random variable. The value we observe is t D .9:5 �
10/=0:045 D �11:1 We are asking for the probability that T � �jtj OR T � jtj. This is so close to 0 that the difference
is of no interest to us. In turn, the sample in the mouse dataset is quite implausibly unlikely if the mean length of an
</p>
<p>adult mouse were 10 cm. We can interpret this as overwhelming evidence that the mean length isn&rsquo;t 10 cm.
</p>
<p>It is conventional to reject the null hypothesis when the p-value is less than 0.05. This is sometimes called &ldquo;a significance
</p>
<p>level of 5%&rdquo;. The phrase can mislead: the term &ldquo;significance&rdquo; seems to imply the result is important, or meaningful. Instead,
</p>
<p>you should interpret a p-value of 0.05 as meaning that you would see evidence this unusual in about one experiment in twenty
</p>
<p>if the null hypothesis was true. It&rsquo;s quite usual to feel that this means the hypothesis is unlikely to be true.
</p>
<p>Sometimes, the p-value is even smaller, and this can be interpreted as very strong evidence the null hypothesis is wrong.
</p>
<p>A p-value of less than 0.01 allows one to reject the null hypothesis at &ldquo;a significance level of 1%&rdquo;. Similarly, you should
</p>
<p>interpret a p-value of 0.01 as meaning that you would see evidence this unusual in about one experiment in a hundred if the
</p>
<p>null hypothesis was true.
</p>
<p>Worked example 7.4 (Average Human Body Weight) Assess the significance of the evidence against the hypothesis
</p>
<p>that the average human body weight is 175 lb, using the height and weight data set of http://www2.stetson.edu/~jrasp/
</p>
<p>data.htm (called bodyfat.xls).
</p>
<p>Solution The dataset contains 252 samples, so we can use a normal model. The average weight is 178.9 lb. This results
</p>
<p>in a two-sided p-value of 0.02. We can interpret this as quite strong evidence that the average human body weight is not,
</p>
<p>in fact, 175 lb. This p-value says that, if (a) the average human body weight is 175 lb and (b) we repeat the experiment
</p>
<p>(weigh 252 people and average their weights) 50 times, we would see a value as far from 175 lb about once.
</p>
<p>Worked example 7.5 (Cholesterol Levels After Heart Attacks) At http://www.statsci.org/data/general/cholest.
</p>
<p>html, you can find data on 28 patients whose cholesterol level was measured at various days after a heart attack.
</p>
<p>The data is attributed to &ldquo;a study conducted by a major northeastern medical center&rdquo; (here northeastern refers to a
</p>
<p>location in the USA). Assess the significance of the evidence that, on day 2, the mean cholesterol level is 240 mg/dL.
</p>
<p>Solution N is small enough to use a t-distribution. We have the sample mean is 253.9; the standard error is 9.02;
</p>
<p>and so the test statistic is 1.54. A two-sided test, using 27 degrees of freedom, gives a p-value of 0:135, too large to
</p>
<p>comfortably reject the hypothesis.</p>
<p/>
<div class="annotation"><a href="http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml">http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/general/cholest.html">http://www.statsci.org/data/general/cholest.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/general/cholest.html">http://www.statsci.org/data/general/cholest.html</a></div>
</div>
<div class="page"><p/>
<p>7.2 Comparing the Mean of Two Populations 165
</p>
<p>7.2 Comparing theMean of Two Populations
</p>
<p>We have two samples, and we need to know whether these samples come from populations that have the same mean. For
</p>
<p>example, we might observe people using two different interfaces, measure how quickly they perform a task, then ask are
</p>
<p>their performances different? As another example, we might run an application with no other applications running, and test
</p>
<p>how long it takes to run some standard tasks. Because we don&rsquo;t know what the operating system, cache, etc. are up to, this
</p>
<p>number behaves a bit like a random variable, so it is worthwhile to do several experiments, yielding one set of samples. We
</p>
<p>now do this with other applications running as well, yielding another set of samples&mdash;is this set different from the first set?
</p>
<p>For realistic datasets, the answer is always yes, because they&rsquo;re random samples. A better question is: could the differences
</p>
<p>be the result of chance, or are these datasets really samples of two different populations?
</p>
<p>Worked example 7.6 (Male and Female Chow Eating Mice) Give a centered 95% confidence interval for the weight
</p>
<p>of a female mouse who ate chow and for the weight of a male mouse who ate chow, based on the dataset at http://cgd.
</p>
<p>jax.org/datasets/phenotype/SvensonDO.shtml. Compare these intervals.
</p>
<p>Solution We know from Worked example 6.4 that the interval we want runs from 26.38 to 29.18 gr. For male mice, the
</p>
<p>same procedure yields the interval 34.75&ndash;38.06 gr. Now these two ranges are quite distinct. This means that, to believe
</p>
<p>the two populations are the same, we&rsquo;d have to believe we have a really strange sample of at least one population.
</p>
<p>Here is rather compelling evidence that male and female chow-eating mice do not have the same mean weight.
</p>
<p>As Worked example 7.6 shows, we can use confidence intervals on the means to reason about populations. There&rsquo;s an
</p>
<p>alternative&mdash;we could look at the significance of the difference between means. We need some notation: write fXg for the
first population and fYg for the second population. Write fxg for the first dataset, which has size kx, and fyg for the second,
which has size ky. These datasets need not be of the same size.
</p>
<p>7.2.1 Assuming Known Population Standard Deviations
</p>
<p>In the simplest case, assume the two populations each have known standard deviation, i.e. popsd .fXg/ and popsd .fYg/ are
known. In this case, the distribution of sample means is normal. We can use some simple facts about normal random variables
</p>
<p>to come up with a measure of significance.
</p>
<p>Useful Facts 7.1 (Sums and Differences of Normal Random Variables)
</p>
<p>Let X1 be a normal random variable with mean �1 and standard deviation �1. Let X2 be a normal random variable with
</p>
<p>mean �2 and standard deviation �2. Let X1 and X2 be independent. Then we have that:
</p>
<p>&bull; for any constant c1 &curren; 0, c1X1 is a normal random variable with mean c1�1 and standard deviation c1�1;
&bull; for any constant c2, X1 C c2 is a normal random variable with mean �1 C c2 and standard deviation �1;
&bull; X1 C X2 is a normal random variable with mean �1 C �2 and standard deviation
</p>
<p>q
</p>
<p>�21 C �22 .
</p>
<p>I will not prove these facts; we already know the expressions for means and standard deviations from our results on
</p>
<p>expectations. The only open question is to show that the distributions are normal. This is easy for the first two results.
</p>
<p>The third requires a bit of integration that isn&rsquo;t worth our trouble; you could reconstruct the proof from section Worked
</p>
<p>example 14.13&rsquo;s notes on sums of random variables and some work with tables of integrals.</p>
<p/>
<div class="annotation"><a href="http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml">http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml</a></div>
<div class="annotation"><a href="http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml">http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml</a></div>
</div>
<div class="page"><p/>
<p>166 7 The Significance of Evidence
</p>
<p>Now write X.kx/ for the random variable obtained by: drawing a random sample with replacement of kx elements from the
</p>
<p>first population, then averaging this sample. Write Y.ky/ for the random variable obtained by: drawing a random sample with
</p>
<p>replacement of ky elements from the first population, then averaging this sample. Each random variable is normal, because
</p>
<p>the population standard deviations are known. This means that X.kx/ � Y.ky/ is a normal random variable.
Now write D for X.kx/ � Y.ky/. If the two populations have the same mean, then
</p>
<p>EŒD&#141; D 0:
</p>
<p>Furthermore,
</p>
<p>std .D/ D
q
</p>
<p>std
�
</p>
<p>X.kx/
�2 C std
</p>
<p>�
</p>
<p>X.ky/
�2
</p>
<p>D
</p>
<p>s
</p>
<p>popsd .fXg/2
</p>
<p>kx
C popsd .fYg/
</p>
<p>2
</p>
<p>ky
;
</p>
<p>which we can evaluate because we assumed popsd .fXg/ and popsd .fYg/ were known. We can now use the same reasoning
we used to test the significance of the evidence that a population had a particular, known mean. We have identified a number
</p>
<p>we can compute from the two samples. We know how this number would vary under random choices of sample. If the value
</p>
<p>we observe is too many standard deviations away from the mean, the evidence is against our hypothesis. If we wanted to
</p>
<p>believe the hypothesis, we would be forced to believe that the sample is extremely strange. I have summarized this reasoning
</p>
<p>in box 7.4.
</p>
<p>Procedure 7.4 (Testing Whether Two Populations Have the Same Mean, for Known Population Standard
</p>
<p>Deviations) The initial hypothesis is that the populations have the same, unknown, mean. Write fxg for the sample of
the first population, fyg for the sample of the second population, and kx, ky for the sample sizes.
</p>
<p>&bull; Compute the sample means for each population, mean .fxg/ and mean .fyg/.
&bull; Compute the standard error for the difference between the means,
</p>
<p>sed D
s
</p>
<p>popsd .fXg/
kx
</p>
<p>C popsd .fYg/
ky
</p>
<p>:
</p>
<p>&bull; Compute the value of the test statistic using
</p>
<p>s D .mean .fxg/ � mean .fyg//
sed
</p>
<p>:
</p>
<p>&bull; Compute the p-value, using
</p>
<p>p D .1 � f / D .1 �
Z jsj
</p>
<p>�jsj
exp
</p>
<p>��u2
2
</p>
<p>�
</p>
<p>du/
</p>
<p>&bull; The p-value summarizes the extent to which the data contradicts the hypothesis. A small p-value implies that, if the
</p>
<p>hypothesis is true, the sample is very unusual. The smaller the p-value, the more strongly the evidence contradicts
</p>
<p>the hypothesis.
</p>
<p>It is common to think that a hypothesis can be rejected only if the p-value is less than 5% (or some number). You
</p>
<p>should not think this way; the p-value summarizes the extent to which the data contradicts the hypothesis, and your
</p>
<p>particular application logic affects how you interpret it.</p>
<p/>
</div>
<div class="page"><p/>
<p>7.2 Comparing the Mean of Two Populations 167
</p>
<p>7.2.2 Assuming Same, Unknown Population Standard Deviation
</p>
<p>Now assume the two populations each have the same, unknown standard deviation, i.e. popsd .fXg/ D popsd .fYg/ D � ,
with � unknown. If popmean .fXg/ D popmean .fYg/, then we have that mean .fxg/ � mean .fyg/ is the value of a
random variable whose mean is 0, and whose variance is
</p>
<p>�2
</p>
<p>kx
C �
</p>
<p>2
</p>
<p>ky
D �2 kxky
</p>
<p>kx C ky
</p>
<p>We don&rsquo;t know this variance, but must estimate it. Because the variance is the same in each population, we can pool the
</p>
<p>samples when estimating the variance. This yields the following estimate of the standard error:
</p>
<p>s2ed D
 
</p>
<p>std .fxg/2.kx � 1/C std .fyg/2.ky � 1/
kx C ky � 2
</p>
<p>!
</p>
<p>�
</p>
<p>kxky
</p>
<p>kx C ky
</p>
<p>�
</p>
<p>:
</p>
<p>Using our previous reasoning, we have that
</p>
<p>mean .fxg/ � mean .fyg/
sed
</p>
<p>is the value of a random variable with a t-distribution with kx C ky � 2 degrees of freedom. I have summarized this reasoning
in box 7.5.
</p>
<p>Procedure 7.5 (Testing Whether Two Populations Have the Same Mean, for Same But Unknown Population
</p>
<p>Standard Deviations) The initial hypothesis is that the populations have the same, unknown, mean. Write fxg for the
sample of the first population, fyg for the sample of the second population, and kx, ky for the sample sizes.
</p>
<p>&bull; Compute the sample means for each population, mean .fxg/ and mean .fyg/.
&bull; Compute the standard error for the difference between the means,
</p>
<p>s2ed D
 
</p>
<p>std .fxg/2.kx�1/Cstd .fyg/2.ky�1/
kxCky�2
</p>
<p>!
</p>
<p>�
</p>
<p>kxky
</p>
<p>kx C ky
</p>
<p>�
</p>
<p>:
</p>
<p>&bull; Compute the test statistic using
</p>
<p>s D .mean .fxg/ � mean .fyg//
sed
</p>
<p>:
</p>
<p>&bull; Compute the p-value, using the recipe of Procedure 7.2; the number of degrees of freedom is kx C ky � 2.
&bull; The p-value summarizes the extent to which the data contradicts the hypothesis. A small p-value implies that, if the
</p>
<p>hypothesis is true, the sample is very unusual. The smaller the p-value, the more strongly the evidence contradicts
</p>
<p>the hypothesis.
</p>
<p>It is common to think that a hypothesis can be rejected only if the p-value is less than 5% (or some number). You
</p>
<p>should not think this way; the p-value summarizes the extent to which the data contradicts the hypothesis, and your
</p>
<p>particular application logic affects how you interpret it.</p>
<p/>
</div>
<div class="page"><p/>
<p>168 7 The Significance of Evidence
</p>
<p>7.2.3 Assuming Different, Unknown Population Standard Deviation
</p>
<p>Now assume the two populations each have the different, unknown standard deviations. If popmean .fXg/ D
popmean .fYg/, then we have that mean .fxg/ � mean .fyg/ is the value of a random variable whose mean is 0, and
whose variance is
</p>
<p>popsd .fXg/2
</p>
<p>kx
C popsd .fYg/
</p>
<p>2
</p>
<p>ky
</p>
<p>We don&rsquo;t know this variance, but must estimate it. Because the two populations have different standard deviations, we can&rsquo;t
</p>
<p>pool the estimate. An estimate is
</p>
<p>s2edD
stdunbiased .fxg/2
</p>
<p>kx
C stdunbiased .fyg/
</p>
<p>2
</p>
<p>ky
:
</p>
<p>We can form the test statistic in the natural way, yielding
</p>
<p>mean .fxg/ � mean .fyg/
sed
</p>
<p>:
</p>
<p>But there is an issue here. This statistic does not have a t-distribution, and the form of its distribution is complicated. It can
</p>
<p>be approximated satisfactorily with a t-distribution. Write
</p>
<p>W D
</p>
<p>0
</p>
<p>B
</p>
<p>@
</p>
<p>h
</p>
<p>stdunbiased .fxg/2=kx
i2
</p>
<p>kx � 1
C
</p>
<p>h
</p>
<p>stdunbiased .fyg/2=ky
i2
</p>
<p>ky � 1
</p>
<p>1
</p>
<p>C
</p>
<p>A
:
</p>
<p>Then the approximating t-distribution has
</p>
<p>h�
</p>
<p>stdunbiased .fxg/2=kx
�
</p>
<p>C
�
</p>
<p>stdunbiased .fyg/2=ky
�i2
</p>
<p>W
</p>
<p>degrees of freedom. With this, everything proceeds as before.
</p>
<p>Procedure 7.6 (Testing Whether Two Populations Have the Same Mean, for Different Population Standard
</p>
<p>Deviations) The initial hypothesis is that the populations have the same, unknown, mean. Write fxg for the sample of
the first population, fyg for the sample of the second population, and kx, ky for the sample sizes.
</p>
<p>&bull; Compute the sample means for each population, mean .fxg/ and mean .fyg/.
&bull; Compute the standard error for the difference between the means,
</p>
<p>s2ed D
stdunbiased .fxg/2
</p>
<p>kx
</p>
<p>Cstdunbiased .fyg/
2
</p>
<p>ky
:
</p>
<p>&bull; Compute the test statistic using
</p>
<p>s D .mean .fxg/ � mean .fyg//
sed
</p>
<p>:
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3 Other Useful Tests of Significance 169
</p>
<p>&bull; Compute the p-value, using the recipe of Procedure 7.2; the number of degrees of freedom is
</p>
<p>�
</p>
<p>stdunbiased .fxg/2=kxCstdunbiased .fyg/2=ky
�2
</p>
<p>0
</p>
<p>B
</p>
<p>@
</p>
<p>h
</p>
<p>stdunbiased .fxg/2=kx
i2
</p>
<p>= .kx�1/C
h
</p>
<p>stdunbiased .fyg/2=ky
i2
</p>
<p>=
�
</p>
<p>ky�1
�
</p>
<p>1
</p>
<p>C
</p>
<p>A
</p>
<p>:
</p>
<p>&bull; The p-value summarizes the extent to which the data contradicts the hypothesis. A small p-value implies that, if the
</p>
<p>hypothesis is true, the sample is very unusual. The smaller the p-value, the more strongly the evidence contradicts
</p>
<p>the hypothesis.
</p>
<p>It is common to think that a hypothesis can be rejected only if the p-value is less than 5% (or some number). You
</p>
<p>should not think this way; the p-value summarizes the extent to which the data contradicts the hypothesis, and your
</p>
<p>particular application logic affects how you interpret it.
</p>
<p>Worked example 7.7 (Are US and Japanese Cars Different) At http://www.itl.nist.gov/div898/handbook/eda/
</p>
<p>section3/eda3531.htm you can find a dataset, published by NIST, giving measurements of miles per gallon for Japanese
</p>
<p>and US cars. Assess the evidence these two populations have the same mean MPG.
</p>
<p>Solution There are 249 measurements for Japanese cars, and 79 for US cars. The mean for Japanese cars is 20.14, and
</p>
<p>for US cars is 30.48. The standard error is 0.798. The value of the test statistic is
</p>
<p>.mean .fxg/ � mean .fyg//
sed
</p>
<p>D 12:95
</p>
<p>and the number of degrees of freedom is about 214. There are enough degrees of freedom here that the t-distribution
</p>
<p>could be approximated with a normal distribution, so a reasonable approximate p-value is the probability of
</p>
<p>encountering a standard normal random variable of this value or greater. This is so close to zero I had some trouble
</p>
<p>getting sensible numbers; the evidence very strongly rejects this hypothesis. A version of this example is worked in the
</p>
<p>NIST/SEMATECH e-Handbook of Statistical Methods, at http://www.itl.nist.gov/div898/handbook/, as of 2017.
</p>
<p>7.3 Other Useful Tests of Significance
</p>
<p>There are many forms of significance test. Significance testing can get quite elaborate, because determining distributions
</p>
<p>under sampling variation can get tricky. Furthemore, there are still arguments about precisely what significance means
</p>
<p>(or should mean). Mostly, we can ignore these difficulties. There are two more of the very many available procedures that
</p>
<p>will be very useful for us.
</p>
<p>7.3.1 F-Tests and Standard Deviations
</p>
<p>Imagine we have two datasets. There are Nx items in fxg, and Ny items in fyg. We believe that each dataset is normally
distributed (i.e. that the values are IID samples from a normal distribution). We wish to evaluate the significance of the
</p>
<p>evidence against the belief that the two datasets have the same variance. This test will prove useful in the discussion of
</p>
<p>experiments (Chap. 8).
</p>
<p>The procedure we adopt follows that of the T-test. We assume the dataset are samples drawn from a population. We
</p>
<p>compute a statistic representing the data that we actually see. This statistic will have a known distribution under sampling.
</p>
<p>We then compute the probability of observing a value of the statistic even more unusual than the value we observe, if the</p>
<p/>
<div class="annotation"><a href="http://www.itl.nist.gov/div898/handbook/eda/section3/eda3531.htm">http://www.itl.nist.gov/div898/handbook/eda/section3/eda3531.htm</a></div>
<div class="annotation"><a href="http://www.itl.nist.gov/div898/handbook/eda/section3/eda3531.htm">http://www.itl.nist.gov/div898/handbook/eda/section3/eda3531.htm</a></div>
<div class="annotation"><a href="http://www.itl.nist.gov/div898/handbook/">http://www.itl.nist.gov/div898/handbook/</a></div>
</div>
<div class="page"><p/>
<p>170 7 The Significance of Evidence
</p>
<p>two dataset have the same variance. If that probability is small, then if we want to believe the two datasets have the same
</p>
<p>variance, we will have to believe we have an extremely strange sample.
</p>
<p>The statistic: In the cases I will deal with, it is clear which of the two populations has largest variance if they are different.
</p>
<p>I will assume that the X population might have larger variance. If these two populations had the same variance, we would
</p>
<p>expect that
</p>
<p>F D stdunbiased .fxg/
2
</p>
<p>stdunbiased .fyg/2
</p>
<p>should be close to one. This statistic is known as the F-statistic, and we are concerned that it could be greater than or equal
</p>
<p>to one, justifying the use of a one sided p-value.
</p>
<p>The distribution: The F-statistic has a known distribution (called the F-distribution), assuming that fxg and fyg are IID
samples from normal distributions. The form of the distribution isn&rsquo;t particularly important to us. Appropriate values can
</p>
<p>be looked up in tables, or obtained from a computing environment. However, it is important to keep track of one detail.
</p>
<p>As the number of samples in either dataset goes up, the estimate of the variance obtained from the samples must get more
</p>
<p>accurate. This means that the distribution depends on the number of degrees of freedom for each dataset (i.e. Nx � 1 and
Ny � 1). We write pf .uINx � 1;Ny � 1/ for the probability density of the F-statistic. We chose the ratio that was greater than,
or equal to, one. Write r for the ratio we observed. The probability of observing a value of the statistic that is even more
</p>
<p>unusual (i.e. bigger) than the one we observe is
</p>
<p>Z 1
</p>
<p>r
</p>
<p>pf .uINx � 1;Ny � 1/du:
</p>
<p>I write this integral for completeness, rather than because you&rsquo;d ever need to actually work with it. In practice, one either
</p>
<p>works with tables or with a function from a software package.
</p>
<p>Procedure 7.7 (The F-Test of Significance for Equality of Variance) Given two datasets fxg of Nx items and fyg
of Ny items, we wish to assess the significance of evidence against the hypothesis that the populations represented by
</p>
<p>these two datasets have the same variance. We assume that the alternative possibility is that the population represented
</p>
<p>by fxg has the larger variance. We compute
</p>
<p>F D stdunbiased .fxg/
2
</p>
<p>stdunbiased .fyg/2
</p>
<p>and obtain a p-value using tables or software to recover
</p>
<p>Z 1
</p>
<p>r
</p>
<p>pf .uINx � 1;Ny � 1/du:
</p>
<p>where pf is the probability distribution for the F-statistic.
</p>
<p>Worked example 7.8 (Yet More Male and Female Chow Eating Mice) Does the data support the idea that the
</p>
<p>variance of the weight of female mice who ate chow and the variance of the weight of male mice who ate chow are the
</p>
<p>same? Use the dataset at http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml, and an F-test.
</p>
<p>Solution The value of the F-statistic is 1.686 (male mice have the larger variance). The p-value for this F-statistic is
</p>
<p>0.035, which we can interpret as evidence that only 3.5% of samples would have a more unusual value of the F-statistic
</p>
<p>if the two populations actually had the same variance. In turn, this means the evidence quite strongly contradicts the
</p>
<p>hypothesis they have the same variance. One note for careful readers: F-tests have a reputation for being somewhat
</p>
<p>unreliable when the data isn&rsquo;t normally distributed. Good sense suggests that I should check that mouse weights are
</p>
<p>normally distributed before releasing the result we have here to the newspapers. Fortunately, Worked example 7.10
</p>
<p>below suggests that mouse weights are normally distributed, so we&rsquo;re safe on this point.</p>
<p/>
<div class="annotation"><a href="http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml">http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml</a></div>
</div>
<div class="page"><p/>
<p>7.3 Other Useful Tests of Significance 171
</p>
<p>7.3.2 �2 Tests of Model Fit
</p>
<p>Sometimes we have a model, and we would like to know whether the data is consistent with that model. For example, imagine
</p>
<p>we have a six-sided die. We throw it many times, and record which number comes up each time. We would like to know if
</p>
<p>the die is fair (i.e. is the data consistent with the model that the die is fair). It is highly unlikely that each face comes up the
</p>
<p>same number of times, even if the die is fair. Instead, there will be some variation in the frequencies observed; with what
</p>
<p>probability is that variation, or bigger, the result of chance effects?
</p>
<p>As another example, we decide that the number of calls by a telemarketer in each hour is distributed with a Poisson
</p>
<p>distribution. We don&rsquo;t know the intensity. We could collect call data, and use maximum likelihood to determine the intensity.
</p>
<p>Once we have the best estimate of the intensity, we still want to know whether the model is consistent with the data.
</p>
<p>In each case, the model predicts the frequencies of events. For the six-sided die case, the model tells us how often we
</p>
<p>expect to see each side. For the call case, the model predicts how often we would see no calls, one call, two calls, three calls,
</p>
<p>etc. in each hour. To tell whether the model fits the data, we need to compare the frequencies we observed with theoretical
</p>
<p>frequencies.
</p>
<p>We adopt the following procedure, which should now be familiar. We assume the dataset are samples drawn from a
</p>
<p>population. We compute a statistic representing the data that we actually see. This statistic will have a known distribution
</p>
<p>under sampling. We then compute the probability of observing a value of the statistic even more unusual than the value we
</p>
<p>observe, if the model correctly predicts the frequencies of events. If that probability is small, then if we want to believe the
</p>
<p>model correctly predicts the frequencies of events, we will have to be believe we have an extremely small sample.
</p>
<p>The statistic: The appropriate statistic is computed as follows. Assume we have a set of k disjoint events E1; : : : ; Ek which
</p>
<p>cover the space of outcomes (i.e. any outcome lies in one of these events). Assume we perform N experiments, and record
</p>
<p>the number of times each event occurs. We have a hypothesis regarding the probability of events. We can take the probability
</p>
<p>of each event and multiply by N to get a frequency under that hypothesis. Now write fo.Ei/ for the observed frequency of
</p>
<p>event i; ft.Ei/ for the theoretical frequency of the event under the null hypothesis. We form the statistic
</p>
<p>C D
X
</p>
<p>i
</p>
<p>.fo.Ei/ � ft.Ei//2
</p>
<p>ft.Ei/
</p>
<p>which compares the observed and actual frequency of events. This statistic is known as the �2-statistic (say &ldquo;khi-squared&rdquo;).
</p>
<p>The distribution: It turns out that this statistic C has a distribution very close to a known form, called the �2-distribution,
</p>
<p>as long as each count is five or more. The distribution has two parameters; the statistic, and the number of degrees of freedom.
</p>
<p>The degrees of freedom refers to the dimension of the space of measurement values that you could have. We will need to
</p>
<p>fix some values. The number of values to fix has to do with the type of test you are doing. In the most common case, you
</p>
<p>want to inspect the counts in each of k bins to tell whether they are consistent with some distribution. We know the sum of
</p>
<p>counts is N. It turns out that we should compare what we observe with what we could have observed with the same N. In
</p>
<p>this case, the dimension of the space of measurement value is k� 1, because you have k numbers but they must add up to N.
Now assume we have to estimate p parameters for the model. For example, rather than asking whether the data comes from a
</p>
<p>standard normal distribution, we might use the data to estimate the mean. We then test whether the data comes from a normal
</p>
<p>distribution with the estimated mean, but unit standard deviation. As another example, we could estimate both mean and
</p>
<p>standard deviation from the data. If we estimate p parameters from the data, then the number of degrees of freedom becomes
</p>
<p>k � p � 1 (because there are k counts, they must lead to p parameter values, and they must add to 1).
After this, things follow the usual recipe. We compute the statistic; we then look at tables, or use our programming
</p>
<p>environment, to find the probability that the statistic takes this value or greater under the null hypothesis. If this is small, then
</p>
<p>we reject the null hypothesis.
</p>
<p>Procedure 7.8 (The �2-Test of Significance of Fit to a Model) The model consists of k disjoint events E1; : : : ; Ek
which cover the space of outcomes and the probability P.E/ of each event. The model has p unknown parameters.
</p>
<p>Perform N experiments and record the number of times each event occurs in the experiments. The theoretical frequency
</p>
<p>of the i&rsquo;th event for this experiment is NP.E/. Write fo.Ei/ for the observed frequency of event i; ft.Ei/ for the theoretical
</p>
<p>frequency of the event under the null hypothesis. We form the statistic
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>172 7 The Significance of Evidence
</p>
<p>C D
X
</p>
<p>i
</p>
<p>.fo.Ei/ � ft.Ei//2
</p>
<p>ft.Ei/
</p>
<p>which has k � p � 1 degrees of freedom, and compute a p-value by using tables or software to evaluate
Z 1
</p>
<p>C
</p>
<p>p�2.uI k � p � 1/du
</p>
<p>where p�2.uI k�p�1/ is the �2 probability density function with k�p�1 degrees of freedom. This test is safest when
there are at least five instances of each event. This test is extremely elastic and can be used in a variety of non-obvious
</p>
<p>ways as sketched in the worked examples.
</p>
<p>Worked example 7.9 (�2 Test for Dice) I throw a die 100 times. I record the outcomes, in the table below. Is this a
</p>
<p>fair die?
</p>
<p>Face 1 2 3 4 5 6
</p>
<p>Count 46 13 12 11 9 9
</p>
<p>Solution The expected frequency is 100/6 for each face. The �2 statistic has the value 62.7, and there are 5 degrees of
</p>
<p>freedom. We get a p-value of about 3e-12. You would have to run this experiment 3e11 times to see a table as skewed
</p>
<p>as this once, by chance. It&rsquo;s quite unreasonable to believe the die is fair&mdash;or, at least, if you wanted to do so, you would
</p>
<p>have to believe you did a quite extraordinary unusual experiment.
</p>
<p>Worked example 7.10 (Are Mouse Weights Normally Distributed?) Assess the evidence against the hypothesis
</p>
<p>that the weights of all mice who ate chow are normally distributed, based on the dataset at http://cgd.jax.org/datasets/
</p>
<p>phenotype/SvensonDO.shtml.
</p>
<p>Solution This example takes a little thought. The way to check whether a set of data is (roughly) normally
</p>
<p>distributed, is to break the values into intervals, and count how many data items fall into each interval. This gives the
</p>
<p>observed frequencies. You can then also compute theoretical frequencies for those intervals with a normal distribution
</p>
<p>(or simulate). Then you use a �2 test to tell whether the two are consistent. The choice of intervals matters. It is
</p>
<p>natural to have intervals that are some fraction of a standard deviation wide, with the mean at the center. You should
</p>
<p>have one running to infinity, and one to minus infinity. You&rsquo;d like to have enough intervals so that you can tell any
</p>
<p>big difference from normal, but it&rsquo;s important to have at least five data items in each interval. There are 92 mice
</p>
<p>who make it to whenever Weight2 is evaluated (sacrifice, I think). The mean of Weight2 is 31.91 and the standard
</p>
<p>deviation is 6.72. I broke the data into 10 intervals at breakpoints Œ�1;�1:2;�0:9;�0:6;�0:3; 0; 0:3; 0:6; 0:9;
1:2;1&#141; � 6:72 C 31:91. This gave me a count vector Œ10; 9; 12; 9; 7; 11; 7; 9; 8; 10&#141;. I simulated 2000 draws from
a normal distribution with the given mean and standard deviation and sorted them into these intervals, getting
</p>
<p>Œ250; 129; 193; 191; 255; 240; 192; 192; 137; 221&#141; (if you are less idle, you&rsquo;ll evaluate the integrals, but this shouldn&rsquo;t
</p>
<p>make much difference). I found a statistic with value 5.6338. Using 7 degrees of freedom (10 counts, but there are two
</p>
<p>parameters estimated), I found a p-value of 0.5830979, meaning there is no reason to reject the idea that the weights
</p>
<p>are normally distributed.</p>
<p/>
<div class="annotation"><a href="http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml">http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml</a></div>
<div class="annotation"><a href="http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml">http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml</a></div>
</div>
<div class="page"><p/>
<p>7.3 Other Useful Tests of Significance 173
</p>
<p>Worked example 7.11 (Is Swearing Poisson?) A famously sweary politician gives a talk. You listen to the talk, and
</p>
<p>for each of 30 intervals 1 min long, you record the number of swearwords. You record this as a histogram (i.e. you
</p>
<p>count the number of intervals with zero swear words, with one, etc.), obtaining the table below.
</p>
<p>No. of swear words 0 1 2 3 4
</p>
<p>No. of intervals 13 9 8 5 5
</p>
<p>The null hypothesis is that the politician&rsquo;s swearing is Poisson distributed, with intensity (�) one. Can you reject this
</p>
<p>null hypothesis?
</p>
<p>Solution If the null hypothesis is true, then the probability of getting n swear words in a fixed length interval would
</p>
<p>be �
ne��
nŠ
</p>
<p>. There are 10 intervals, so the theoretical frequencies are 10 times the following probabilities
</p>
<p>No. of swear words 0 1 2 3 4
</p>
<p>No. of intervals 0.368 0.368 0.184 0.061 0.015
</p>
<p>so the �2 statistic takes the value 243.1 and there are 4 degrees of freedom. The significance is indistinguishable from
</p>
<p>zero by my programming environment, so you can firmly reject the null hypothesis. Of course, it may just be that the
</p>
<p>intensity is wrong (exercises).
</p>
<p>Worked example 7.12 (Are Goals Independent of Gender?) Assess the evidence that student goals are independent
</p>
<p>of student gender in the dataset of Chase and Dunner, which you can find at http://lib.stat.cmu.edu/DASL/Datafiles/
</p>
<p>PopularKids.html.
</p>
<p>Solution This is an example of a common use of the �2 test. The table below shows the count of students in the study
</p>
<p>by gender and goal. I have inserted row and column totals for convenience. In total, there were 478 students.
</p>
<p>Boy Girl Total
</p>
<p>Grades 117 130 247
</p>
<p>Popular 50 91 141
</p>
<p>Sports 60 30 90
</p>
<p>Total 227 251 478
</p>
<p>We will test whether the counts observed are different from those predicted if gender and goal are independent. If they
</p>
<p>are independent, then P.boy/ D 227=478 D 0:47, and P.Grades/ D 247=478 D 0:52 (and so on). This means that we
can produce a table of theoretical counts under the model (below).
</p>
<p>Boy Girl
</p>
<p>Grades 117.29916 129.70084
</p>
<p>Popular 66.96025 74.03975
</p>
<p>Sports 42.74059 47.25941
</p>
<p>There are 6 cells in our table. One degree of freedom is used up by requiring that there are 478 students. Two further
</p>
<p>degrees of freedom are used up by insisting that the Grades/Popular/Sports counts yield the distribution we observed.
</p>
<p>One further degree of freedom is used up by insisting that the gender counts yield the distribution we observe. This
</p>
<p>means that there are a total of two degrees of freedom. We compute a �2 value of 21:46. The p-value is 2e-5. In
</p>
<p>turn, if the two factors were independent, you&rsquo;d see counts like these by chance about twice in a hundred thousand
</p>
<p>experiments. It&rsquo;s very hard to believe they are independent.</p>
<p/>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html">http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html</a></div>
<div class="annotation"><a href="http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html">http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html</a></div>
</div>
<div class="page"><p/>
<p>174 7 The Significance of Evidence
</p>
<p>7.4 P-Value Hacking and Other Dangerous Behavior
</p>
<p>Significance is a very useful way of telling whether an experimental observation might be the result of chance effects, but it
</p>
<p>is important to follow the logic of the method carefully. If you don&rsquo;t, you can fairly easily come to false conclusions.
</p>
<p>There is an important danger here.
</p>
<p>Removing data points and recomputing p-values is one way to have a serious problem. One context where this occurs in
</p>
<p>evaluating medical procedures. We would test the hypothesis that some sample mean of a treated population is the same as
</p>
<p>that of an untreated population. If this hypothesis fails, then the procedure did something. However, we might see outliers in
</p>
<p>the dataset. If we remove these outliers, then (of course) the p-value changes. This presents an temptation to remove outliers
</p>
<p>that shift the p-value in some desired direction. Of course, doing this consciously is fraud; but it&rsquo;s quite easy to simply fool
</p>
<p>yourself into removing data points whose absence is helpful.
</p>
<p>Another way to fool yourself is to look at a lot of samples, take the one with the smallest p-value, then declare the
</p>
<p>evidence is against the hypothesis. The more samples you look at, the better your chance of seeing one which has a small
</p>
<p>p-value (that&rsquo;s what the p-value means). If you look at lots of samples or do lots of experiments, looking for one with a small
</p>
<p>p-value, then use that to argue the hypothesis is false, you are fooling yourself. Because fooling other people can be quite
</p>
<p>profitable, this practice is common enough to have a name: it&rsquo;s referred to as p-value hacking.
</p>
<p>t&rsquo;s pretty clear that searching samples for one with a low p-value is bad behavior, but a subtle version of this mistake is
</p>
<p>to intermingle computing p-values with collecting data, then stop when you get the p-value you want. This is quite common
</p>
<p>behavior. A good example of how badly things can go wrong when you do this is described in the paper &ldquo;False-Positive
</p>
<p>Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant&rdquo;, by J.P
</p>
<p>Simmons, L.D. Nelson and U. Simonsohn (Psychological Science, 2011). The authors were able to use this strategy to
</p>
<p>collect data that showed that listening to a particular song would cause your chronological age to go down. I advise you to
</p>
<p>look at this paper, which is a good, easy, and highly informative read
</p>
<p>Yet another way to fool yourself is to change hypotheses halfway through an experiment. Imagine we want to test the
</p>
<p>effect of a medical procedure. We decide to look at one particular sample mean, but halfway through collecting data it looks
</p>
<p>as though there won&rsquo;t be anything interesting to say about that mean. It&rsquo;s tempting to change measurements and focus on
</p>
<p>another statistic instead. If you do, the logic underlying the procedures we describe here fails. Essentially, you will bias the
</p>
<p>test to reject a hypothesis to a degree we can&rsquo;t go into.
</p>
<p>Yet another way to fool yourself is to test multiple hypotheses at the same time, and reject the one with the smallest p-
</p>
<p>value. The problem here is that the test isn&rsquo;t taking into account that you&rsquo;re testing multiple hypotheses. If you repeatedly test
</p>
<p>different hypotheses using the same dataset, the chances go up that the data you observed are inconsistent with a hypothesis
</p>
<p>that is true, purely as a result of sampling. Special procedures are required for this case.
</p>
<p>One solution is for these problems is really strict protocols, where you describe everything you will do and everything you
</p>
<p>will test before doing the experiment and then don&rsquo;t vary from that plan. But such protocols can be expensive and clumsy in
</p>
<p>practice.
</p>
<p>You should not get confused about what a test means. The tests I have described are referred to as tests of statistical
</p>
<p>significance. I use this terminology because that&rsquo;s what everyone else uses, but personally I don&rsquo;t find it helpful, because
</p>
<p>there is an insidious suggestion that a statistically significant difference actually matters&mdash;i.e. is significant. What significance
</p>
<p>testing procedures tell you is what fraction of random samples of data have the mean that you observe, if your hypothesis is
</p>
<p>true, and if you have collected the data correctly, tested correctly, and so on. The procedures don&rsquo;t tell you that you&rsquo;ve done
</p>
<p>important, or even interesting, science.
</p>
<p>7.5 You Should
</p>
<p>7.5.1 Remember These Definitions
</p>
<p>p-value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
</p>
<p>Statistical significance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162</p>
<p/>
</div>
<div class="page"><p/>
<p>7.5 You Should 175
</p>
<p>7.5.2 Remember These Terms
</p>
<p>test statistic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
</p>
<p>T-test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
</p>
<p>two-sided p-value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
</p>
<p>one-sided p-value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
</p>
<p>F-statistic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
</p>
<p>F-distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
</p>
<p>�2-statistic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
</p>
<p>�2-distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
</p>
<p>p-value hacking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
</p>
<p>7.5.3 Remember These Facts
</p>
<p>Sums and differences of normal random variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
</p>
<p>7.5.4 Use These Procedures
</p>
<p>The T-test of significance for a hypothesized mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
</p>
<p>Compute a two-sided p-value for a T-test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
</p>
<p>Compute a one-sided p-value for a T-test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
</p>
<p>Assess whether means are the same (known population sds) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166
</p>
<p>Assess whether means are the same (same, unknown population sds) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
</p>
<p>Assess whether means are the same (different population sds) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
</p>
<p>The F-test of significance for equality of variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
</p>
<p>The �2-test of significance of fit to a model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
</p>
<p>7.5.5 Be Able to
</p>
<p>&bull; Compute the fraction of samples that would have a more extreme mean than some value, if the population mean had a
</p>
<p>given value.
</p>
<p>&bull; Evaluate the significance of the evidence against the hypothesis that a population mean has a given value using a normal
</p>
<p>distribution model (i.e. for a large sample).
</p>
<p>&bull; Evaluate the significance of the evidence against the hypothesis that a population mean has a given value using a
</p>
<p>t-distribution model (i.e. for a sample that isn&rsquo;t large).
</p>
<p>&bull; Evaluate the significance of the evidence against the hypothesis that two population means are the same using a t-
</p>
<p>distribution model (i.e. for a sample that isn&rsquo;t large).
</p>
<p>&bull; Evaluate the significance of the evidence against the hypothesis that two population standard deviations are the same using
</p>
<p>an F-test.
</p>
<p>&bull; Evaluate the significance of the evidence against a model using a �2 test.
</p>
<p>&bull; Avoid thinking that the significance of evidence is the same as the significance of a piece of science.
</p>
<p>&bull; Avoid &ldquo;adjusting&rdquo; your experimental data to improve the p-value, and avoid p-value hacking in general.</p>
<p/>
</div>
<div class="page"><p/>
<p>176 7 The Significance of Evidence
</p>
<p>Problems
</p>
<p>Fractions of Samples
</p>
<p>7.1 In 1998, the average height of an adult male in South Africa was estimated to be 169 cm. Assume that this estimate is
</p>
<p>exact; assume also that the population standard deviation is 10 cm. What fraction of samples consisting of 50 adult males
</p>
<p>from South Africa (selected uniformly at random, and with replacement) will have average height greater than 200 cm?
</p>
<p>7.2 Assume the average weight of an adult male short-hair house cat is 5 kg, and the standard deviation is 0.7 kg (these
</p>
<p>numbers are reasonable, but there&rsquo;s quite a lively fight between cat fanciers about the true numbers).
</p>
<p>(a) What fraction of samples consisting of 30 adult male short-hair house cats (selected uniformly at random, and with
</p>
<p>replacement) will have average weight less than 4 kg?
</p>
<p>(b) What fraction of samples consisting of 300 adult male short-hair house cats (selected uniformly at random, and with
</p>
<p>replacement) will have average weight less than 4 kg?
</p>
<p>(c) Why are these numbers different?
</p>
<p>Significance
</p>
<p>7.3 Yet more Mouse-weighing I claim the average weight of a mouse is 25 grams. You decide to evaluate the evidence in
</p>
<p>support of this claim. You obtain 10 mice, sampled uniformly at random and with replacement from the mouse population.
</p>
<p>Their weights are 21; 23; 27; 19; 17; 18; 20; 15; 17; 22 grams respectively. Does the evidence support my claim? to what
</p>
<p>extent? Why?
</p>
<p>7.4 How big are Parktown Prawns? The Parktown prawn is an impressively repellent large insect, common in
</p>
<p>Johannesburg (look them up on the Web). I claim that their average length is 10 cm. You collect 100 Parktown prawns
</p>
<p>(this will take about 10 mins, in the right places in Johannesburg; more difficult from the US). The mean length of these
</p>
<p>prawns is 7 cm. The standard deviation is 1 cm. Assess the evidence against my claim.
</p>
<p>7.5 Two Populations of Rats Zucker rats are specially bred to have curious weight properties, related to their genetics (look
</p>
<p>them up on the Web). You measure 30 lean Zucker rats, obtaining an average weight of 500 grams with a standard deviation
</p>
<p>of 50 grams. You measure 20 fatty Zucker rats, obtaining an average weight of 1000 grams with a standard deviation of 100
</p>
<p>grams. Assess the evidence against the claim that these populations have the same weight.
</p>
<p>7.6 Male and Female pet Rats You measure 35 female pet rats, obtaining an average weight of 300 grams with a standard
</p>
<p>deviation of 30 grams. You measure 30 male pet rats, obtaining an average weight of 400 grams with a standard deviation of
</p>
<p>100 grams. Assess the evidence against the claim that these populations have the same weight.
</p>
<p>7.7 Lean and Fatty Zucker Rats Zucker rats are specially bred to have curious weight properties, related to their genetics
</p>
<p>(look them up on the Web). You measure 30 lean Zucker rats, obtaining an average weight of 500 grams with a standard
</p>
<p>deviation of 50 grams. You measure 35 fatty Zucker rats, obtaining an average weight of 1000 grams with a standard deviation
</p>
<p>of 100 grams. In steps, you will assess the evidence against the claim that a fatty Zucker rat has exactly twice the weight
</p>
<p>of a lean Zucker rat. You know that the product of a normal random variable and a constant is a normal random variable.
</p>
<p>You should assume (and accept, because I won&rsquo;t prove it) that the sum of two normal random variables is a normal random
</p>
<p>variable.
</p>
<p>(a) Write L.k/ for the random variable obtained by drawing a uniform sample of k lean rats and averaging their weights. You
</p>
<p>can assume that k is large enough that this is normal.
</p>
<p>&bull; What is E
�
</p>
<p>L.k/
�
</p>
<p>? (write an expression, no need to prove anything)
</p>
<p>&bull; What is std
�
</p>
<p>L.k/
�
</p>
<p>? (write an expression, no need to prove anything)</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 177
</p>
<p>(b) Now write F.s/ for the random variable obtained by drawing a uniform sample of s fatty rats and averaging their weights.
</p>
<p>You can assume that s is large enough that this is normal.
</p>
<p>&bull; What is E
�
</p>
<p>F.s/
�
</p>
<p>? (write an expression, no need to prove anything)
</p>
<p>&bull; What is std
�
</p>
<p>F.s/
�
</p>
<p>? (write an expression, no need to prove anything)
</p>
<p>(c) Write popmean .fLg/ for the population mean weight of lean rats, and popmean .fFg/ for the population mean weight
of fatty rats. Assume that 2popmean .fLg/ D popmean .fFg/.
</p>
<p>&bull; In this case, what is E
�
</p>
<p>F.s/ � 2L.k/
�
</p>
<p>?
</p>
<p>&bull; In this case, what is std
�
</p>
<p>F.s/ � 2L.k/
�
</p>
<p>?
</p>
<p>&bull; Your expression for std
�
</p>
<p>F.s/ � 2L.k/
�
</p>
<p>will have contained terms in the population standard deviation of F and L. What
</p>
<p>is the standard error of F.s/ � 2L.k/?
</p>
<p>(d) Now assess the evidence against the hypothesis that a fatty Zucker rat weighs exactly twice as much as a lean Zucker rat.
</p>
<p>7.8 Are boys and girls equiprobable? In Carcelle-le-Grignon at the end of the eighteenth century, there were 2009 births.
</p>
<p>There were 983 boys and 1026 girls. You can regard this as a fair random sample (with replacement, though try not to think
</p>
<p>too hard about what that means) of births. Assess the evidence against the hypothesis that a boy is born with probability
</p>
<p>exactly 0.5.
</p>
<p>Chi-Squared Tests
</p>
<p>7.9 You can find a dataset of the passenger list for the Titanic disaster at http://www.statsci.org/data/general/titanic.html.
</p>
<p>(a) Assess the evidence that survival is independent of passenger ticket class.
</p>
<p>(b) Assess the evidence that survival is independent of passenger gender.
</p>
<p>7.10 You can find a dataset giving income data for US citizens at the UC Irvine Machine Learning data archive, at http://
</p>
<p>archive.ics.uci.edu/ml/datasets/Adult. Each item consists of a set of numeric and categorical features describing a person,
</p>
<p>together with whether their annual income is larger than or smaller than 50 K$.
</p>
<p>(a) Assess the evidence that income category is independent of gender.
</p>
<p>(b) Assess the evidence that income category is independent of education level.
</p>
<p>7.11 Assess the evidence that the swearing behavior of the politician of Worked example 7.11 follows a Poisson distribution.
</p>
<p>Hint: Once you&rsquo;ve estimated the intensity, the rest is like that example; be careful about the number of degrees of freedom.</p>
<p/>
<div class="annotation"><a href="http://www.statsci.org/data/general/titanic.html">http://www.statsci.org/data/general/titanic.html</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Adult">http://archive.ics.uci.edu/ml/datasets/Adult</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Adult">http://archive.ics.uci.edu/ml/datasets/Adult</a></div>
</div>
<div class="page"><p/>
<p>8Experiments
</p>
<p>An experiment tries to evaluate the effects of one or more treatments. Imagine you wish to evaluate the effect of some
</p>
<p>treatment. One natural strategy is: choose groups of subjects; apply this treatment at different levels to different groups; then
</p>
<p>see if the groups are different after treatment. For example, you might wish to investigate whether consuming a painkiller
</p>
<p>affected headaches. Different levels of treatment would correspond to different numbers of pills (say, none, one or two).
</p>
<p>Different subjects would be different people. We would then divide the subjects into groups, apply different levels of
</p>
<p>treatment (i.e. give them different numbers of pills), and record outcomes. Now we need to tell whether the groups are
</p>
<p>different.
</p>
<p>Telling whether the groups are different requires care, because the subjects will differ for a variety of irrelevant reasons
</p>
<p>(bodyweight, susceptibility to medication, and so on), so there will be differences between groups&mdash;we need to be able to tell
</p>
<p>whether these differences are due to the treatment, or to the irrelevant reasons. One powerful strategy is to allocate subjects
</p>
<p>to groups before treatment at random, so that each group looks similar (i.e. each group has the same variation in bodyweight,
</p>
<p>and so on). We can then use the significance machinery of the previous chapter to tell whether the differences between groups
</p>
<p>are due to the effects of treatment.
</p>
<p>The procedures we use can be extended to deal with multiple treatments. We deal with the case of two treatments, because
</p>
<p>it captures important phenomena. Rather than do experiments for each treatment separately, it is a good idea to look at the
</p>
<p>results for different levels of both treatments together. Doing so allows us to identify possible interactions, and to treat fewer
</p>
<p>subjects in total. The machinery doesn&rsquo;t change (though there is more of it) when we pass to more than two treatments.
</p>
<p>8.1 A Simple Experiment: The Effect of a Treatment
</p>
<p>I use the term &ldquo;treatment&rdquo; very broadly here. The subject of experimental design started around the question of how to
</p>
<p>evaluate fertilizers, and it&rsquo;s natural to think about medical treatments, but many other things can be a treatment. Examples
</p>
<p>include: the amount of RAM you put into a computer; different interface design decisions; different choices of algorithm for
</p>
<p>rendering pictures; and so on. We will evaluate the effect of some treatment by dividing subjects into groups, applying the
</p>
<p>treatment at different levels to different groups, then seeing if the groups are &ldquo;different&rdquo; after treatment. For this procedure
</p>
<p>to work, we need: (a) the groups to be the &ldquo;same&rdquo; before treatment, and (b) a sensible way to tell whether the groups are
</p>
<p>different.
</p>
<p>Randomization is a very strong strategy for allocating subjects to groups. Randomization ensures that each group &ldquo;looks
</p>
<p>like&rdquo; each other group. Differences between group then result from either sampling variation or from the effects of the
</p>
<p>treatment, and we know how to assess the effects of sampling. Randomization is a strong strategy for setting up experiments,
</p>
<p>but it doesn&rsquo;t cover every contingency. For example, imagine one treatment involves using a particular machine at a particular
</p>
<p>setting. Changing the setting of the machine again and again might be a problem. Furthermore, the order in which you do
</p>
<p>the experiments might matter&mdash;if the machine overheats, for example, while handling a subject at one setting, you may find
</p>
<p>that the results on the next subject are affected. We will assume that the experimental equipment doesn&rsquo;t have a memory, and
</p>
<p>that changing settings and so on is trivial.
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_8
</p>
<p>179</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_8">https://doi.org/10.1007/978-3-319-64410-3_8</a></div>
</div>
<div class="page"><p/>
<p>180 8 Experiments
</p>
<p>8.1.1 Randomized Balanced Experiments
</p>
<p>Assume you wish to use L levels of treatment (so there are L groups; not treating a subject is one level of treatment). We will
</p>
<p>evaluate the results of the experiment by comparing the outcome for each group of subjects. This means it is helpful if there
</p>
<p>are the same number of subjects in each group&mdash;we say the experiment is balanced&mdash;so that the error resulting from chance
</p>
<p>effects in each group is the same. We will have G subjects in each group, and so there is a total of LG subjects. We must
</p>
<p>now choose which treatment each subject gets. We allocate subjects to groups at random, ensuring that each group gets G
</p>
<p>subjects. You could do this, for example, by permuting the subjects randomly, then allocating the first G to group 1, etc.
</p>
<p>We now perform the experiment, by treating each group of subjects at the prescribed level, and recording the results. For
</p>
<p>each subject, we will observe a measurement. Write xij for the observed value for the j&rsquo;th subject in the i&rsquo;th group. We want
</p>
<p>to know if the groups are different. We assume that differences in observed values in each group are purely due to noise. This
</p>
<p>means that we could model
</p>
<p>xij D �i C �ij
where �ij is &ldquo;noise&rdquo;&mdash;unmodelled effects that have zero mean, and do not depend on the treatment. If the treatment has no
</p>
<p>effect, then each of the �i will be the same. We can model the treatment at level i as having an effect ti, so that
</p>
<p>�i D �C ti:
</p>
<p>We would like � to be the average of the �i, so we must have
X
</p>
<p>u
</p>
<p>tu D 0:
</p>
<p>All this yields a model
xij D �C ti C �ij
</p>
<p>We assume that the noise is independent of the treatment level. This assumption is satisfied by randomizing the allocation
</p>
<p>of subjects to treatment groups. We will assume that the noise is normally distributed, with variance �2. This makes it
</p>
<p>straightforward to estimate � and �i with least squares. We write O� for our estimate of �, and so on. We then choose O� to
be the value of � that minimizes the overall sum of squared differences
</p>
<p>O� D argmin
�
</p>
<p>X
</p>
<p>ij
</p>
<p>.xij � �/2:
</p>
<p>We choose each O�i to be the value of �i that minimizes the sum of squared differences within the i&rsquo;th group
</p>
<p>O�i D argmin�i
X
</p>
<p>j
</p>
<p>.xij � �i/2:
</p>
<p>All this yields
</p>
<p>O� D
P
</p>
<p>ij xij
</p>
<p>GL
and O�i D
</p>
<p>P
</p>
<p>j xij
</p>
<p>G
:
</p>
<p>8.1.2 Decomposing Error in Predictions
</p>
<p>The results are in L groups, one for each level of treatment. The overall sum of squared differences from the estimated mean
</p>
<p>O� is
SST D
</p>
<p>X
</p>
<p>ij
</p>
<p>.xij � O�/2:
</p>
<p>This can be decomposed into two terms, as the exercises show. We have
</p>
<p>X
</p>
<p>ij
</p>
<p>.xij � O�/2 D
</p>
<p>2
</p>
<p>4
</p>
<p>X
</p>
<p>ij
</p>
<p>.xij � O�i/2
3
</p>
<p>5C G
"
</p>
<p>X
</p>
<p>i
</p>
<p>. O� � O�i/2
#
</p>
<p>:</p>
<p/>
</div>
<div class="page"><p/>
<p>8.1 A Simple Experiment: The Effect of a Treatment 181
</p>
<p>This expression breaks the total sum of squared errors SST into two components. The first,
</p>
<p>SSW D
X
</p>
<p>ij
</p>
<p>.xij � O�i/2;
</p>
<p>is due to within-group variation; and the second,
</p>
<p>SSB D G
"
</p>
<p>X
</p>
<p>i
</p>
<p>. O� � O�i/2
#
</p>
<p>is due to between-group variation. The relative size of these two terms should tell us whether the treatment has any effect
</p>
<p>or not. For example, assume there are large effects. Then SSB should be &ldquo;big&rdquo;, because the O�i should be different from one
another, and the SSW should be &ldquo;small&rdquo;, because measurements should be rather closer to their group means than to the
</p>
<p>overall mean (and because SST D SSW C SSB, so when one goes up the other must go down). Now assume there is no
effect. Then the O�i should be quite similar to O�, and so to each other. This means SSB should be &ldquo;small&rdquo;, and so on. Using
this line of reasoning requires some quantitative notion of what is &ldquo;big&rdquo; and what is &ldquo;small&rdquo;.
</p>
<p>8.1.3 Estimating the Noise Variance
</p>
<p>The trick to knowing whether SSB is &ldquo;big&rdquo; or not runs as follows. If there is no effect, then SSB and SSW can each be used
</p>
<p>to produce estimates of the noise variance. We produce these estimates, and then determine whether the difference between
</p>
<p>estimates can be explained by sampling variation. If it can&rsquo;t, then the treatment has some effect.
</p>
<p>Using the ith treatment group, we can estimate �2 by
</p>
<p>O�2 D
P
</p>
<p>j.xij � O�i/2
</p>
<p>.G � 1/ :
</p>
<p>An even better estimate would be to average these estimates across groups. This yields
</p>
<p>O�2 D 1
L
</p>
<p>X
</p>
<p>i
</p>
<p>�
P
</p>
<p>i.xij � O�j/2
.G � 1/
</p>
<p>�
</p>
<p>:
</p>
<p>This estimate is sometimes known as the within group variation or residual variation. We write
</p>
<p>MSW D
1
</p>
<p>L
</p>
<p>X
</p>
<p>i
</p>
<p>"
P
</p>
<p>j.xij � O�i/2
</p>
<p>.G � 1/
</p>
<p>#
</p>
<p>D
�
</p>
<p>1
</p>
<p>L.G � 1/
</p>
<p>�
</p>
<p>SSW: (8.1)
</p>
<p>This estimate has L.G� 1/ degrees of freedom, because we have LG data items, but we lose one degree of freedom for each
of the L means we have estimated.
</p>
<p>Assume the treatment has no effect. Then we expect that all the ti D �i �� are zero. In turn, each of the O�i is an estimate
of �. These estimates are the values of a random variable whose expected value is �, and whose variance is �2=G. This
</p>
<p>means that
P
</p>
<p>i. O�i � O�/2
L � 1 �
</p>
<p>�2
</p>
<p>G
:
</p>
<p>We can use this to produce another estimate of �2, where
</p>
<p>O�2 D G
P
</p>
<p>j. O�j � O�/2
</p>
<p>L � 1</p>
<p/>
</div>
<div class="page"><p/>
<p>182 8 Experiments
</p>
<p>This estimate is sometimes known as the between group variation or treatment variation. We write
</p>
<p>MSB D G
P
</p>
<p>j. O�j � O�/2
</p>
<p>.L � 1/ D
�
</p>
<p>1
</p>
<p>L � 1
</p>
<p>�
</p>
<p>SSB:
</p>
<p>This estimate has L � 1 degrees of freedom, because we have used L data items (the O�j), but estimated one mean (the O�).
If the treatment has no effect, then any difference between these estimates would have to be the result of sampling effects.
</p>
<p>We can apply an F-test of significance (Sect. 7.3.1) to the ratio of the estimates. Now imagine that at least one of the treatment
</p>
<p>levels has an effect. In turn, this would mean that one of the O�j was more different from O� than would occur if the treatment
had no effect. This means that MSB would be larger than would happen if the treatment had no effect. This means that, if
</p>
<p>there is no effect of treatment, the statistic
</p>
<p>F D MSB
MSW
</p>
<p>would be &ldquo;about&rdquo; one, with a known distribution (the F-distribution; Sect. 7.3.1). If there is a treatment effect, then we expect
</p>
<p>F to be larger than one. Finally, we need the degrees of freedom. The estimate MSW has L.G � 1/ degrees of freedom. The
estimate MSB has L�1 degrees of freedom. We can now use the F-test to obtain a p-value for F with L�1, L.G�1/ degrees
of freedom. In other words, we use tables or a software environment to evaluate
</p>
<p>Z 1
</p>
<p>F
</p>
<p>pf .uIL � 1;L.G � 1//du
</p>
<p>(where pf is the probability density for the F-statistic, Sect. 7.3.1).
</p>
<p>8.1.4 The ANOVA Table
</p>
<p>We now have a powerful and useful procedure that I can name and put in a box. Analyzing data by comparing variances in
</p>
<p>this way is sometimes known as analysis of variance or ANOVA. It is usual to lay out the information in a table, sometimes
</p>
<p>called an ANOVA table. We have only one kind of treatment we are varying in the experiment, so the experiment is known
</p>
<p>as a one factor experiment. The form of the table appears in Procedure 8.1.
</p>
<p>Procedure 8.1 (Evaluating Whether a Treatment Has Significant Effects with a One-Way ANOVA for Balanced
</p>
<p>Experiments)
</p>
<p>Perform a randomized experiment: Choose L levels of treatment. Randomize LG subjects into L treatment groups
</p>
<p>of G subjects each. Treat each subject, and record the results.
</p>
<p>Terminology: xij value for the j&rsquo;th subject
</p>
<p>in the i&rsquo;th treatment level group
</p>
<p>O� overall mean
�
</p>
<p>P
</p>
<p>ij xij
</p>
<p>�
</p>
<p>= .GL/
</p>
<p>O�i i&rsquo;th group mean
�
</p>
<p>P
</p>
<p>j xij
</p>
<p>�
</p>
<p>=G
</p>
<p>SSW within group sum of squares
P
</p>
<p>ij.xij � O�i/2
SSB between group sum of squares G
</p>
<p>�
P
</p>
<p>i. O� � O�i/2
�
</p>
<p>MSW within group mean squares SSW= .L.G � 1//
MSB between group mean squares SSB= .L � 1/
F value of F-statistic MSB=MSW
p-value from tables or software
</p>
<p>R1
F
</p>
<p>pf .uIL � 1;L.G � 1//du
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>8.1 A Simple Experiment: The Effect of a Treatment 183
</p>
<p>Make the ANOVA table: Form the table
</p>
<p>DOF Sum Sq Mean Sq F value Pr(&gt;F)
</p>
<p>Treatment L-1 SSB MSB MSB=MSW p-value
</p>
<p>Residuals L (G-1) SSW MSW
</p>
<p>Interpretation: If the p-value is small enough, then only an extremely unlikely set of samples could explain the
</p>
<p>difference between the levels of treatment as sampling error; it is more likely the treatment has an effect.
</p>
<p>Worked example 8.1 (Does Depth Affect Aldrin Concentration?) Jaffe et al measured the concentration of various
</p>
<p>pollutants in the Wolf river. Assess the evidence supporting the belief that the concentration of aldrin does not depend
</p>
<p>on depth. You can find the dataset at http://www.statsci.org/data/general/wolfrive.html.
</p>
<p>Solution The original measurements are described in Jaffe, P. R., Parker, F. L., and Wilson, D. J. (1982). Distribution
</p>
<p>of toxic substances in rivers. Journal of the Environmental Engineering Division, 108, 639&ndash;649. I obtained the
</p>
<p>ANOVA table below.
</p>
<p>DOF Sum Sq Mean Sq F value Pr(&gt;F)
</p>
<p>Depth 2 16.83 8.415 6.051 0.00674
</p>
<p>Residuals 27 37.55 1.391
</p>
<p>The very small p-value suggests that the evidence is very strongly against the idea that concentration does not depend
</p>
<p>on depth.
</p>
<p>8.1.5 Unbalanced Experiments
</p>
<p>In an ideal experiment, each group has the same number of subjects. This is known as a balanced experiment. Such
</p>
<p>experiments can be difficult to arrange. A measurement might be impossible, or a subject might get lost, meaning that some
</p>
<p>levels of treatment may have fewer than others. The result is an unbalanced experiment. This doesn&rsquo;t affect the reasoning
</p>
<p>of the section above, though subtleties can arise. We do need to be careful about the number of degrees of freedom, though.
</p>
<p>Assume that the i&rsquo;th group has Gi items in it. Then the estimate of �
2 based on residual variation becomes
</p>
<p>MSW D
1
</p>
<p>L
</p>
<p>X
</p>
<p>j
</p>
<p>�
P
</p>
<p>i.xij � O�i/2
.Gi � 1/
</p>
<p>�
</p>
<p>:
</p>
<p>This estimate has
P
</p>
<p>i Gi � L degrees of freedom, because there are
P
</p>
<p>i Gi items and we had to estimate L means, one for
</p>
<p>each treatment level.
</p>
<p>The estimate of �2 based on treatment variation is slightly more interesting. For the i&rsquo;th group, the standard error of the
</p>
<p>estimate of O� is
s
</p>
<p>�2
</p>
<p>Gi
</p>
<p>which means that
p
</p>
<p>Gj. O�j � O�/ is the value of a normal random variable with mean 0 and variance �2. In turn, this means
that
</p>
<p>MSB D
P
</p>
<p>i
</p>
<p>�
</p>
<p>Gi. O�i � O�/2
�
</p>
<p>.L � 1/ :
</p>
<p>is an estimate of �2. This estimate has L � 1 degrees of freedom, because we used L data items but estimated one mean.</p>
<p/>
<div class="annotation"><a href="http://www.statsci.org/data/general/wolfrive.html">http://www.statsci.org/data/general/wolfrive.html</a></div>
</div>
<div class="page"><p/>
<p>184 8 Experiments
</p>
<p>In the balanced case, the sums of squares were meaningful because one scales them to get the estimates of �2. There&rsquo;s
</p>
<p>an established tradition of supplying them in the ANOVA table. In the unbalanced case, it&rsquo;s hard to turn the sums of squares
</p>
<p>into anything useful by eye. This is the result of the weighting terms in the expressions for the mean square error. I omit them
</p>
<p>from the ANOVA tables in the worked examples below.
</p>
<p>Worked example 8.2 (Does Olestra in Potato Chips Produce Gastro-Intestinal Symptoms?) Olestra is a fat that is
</p>
<p>edible, but cannot be digested. This means the effective calorie content of chips containing olestra is reduced, but there
</p>
<p>might be gastro-intestinal consequences. The paper &ldquo;Gastrointestinal Symptoms Following Consumption of Olestra or
</p>
<p>Regular Triglyceride Potato Chips&rdquo;, JAMA, 279: 150&ndash;152, L. Cheskin, R. Miday, N. Zorich, and T. Filloon (1998).
</p>
<p>ran a double blind randomized trial. They observed 89 people eating chips with olestra who had a GI outcome; 474
</p>
<p>who did not; 93 eating chips without olestra who had a GI outcome; and 436 eating chips without olestra who did not.
</p>
<p>Subjects ate chips ad libitem (i.e. until they felt like stopping). Assess the evidence that olestra causes a GI outcome
</p>
<p>under these circumstances using an ANOVA.
</p>
<p>Solution Each subject gets a 1 if there is a GI effect, and a 0 otherwise. For this data, I found
</p>
<p>DOF Mean Sq F value Pr(&gt;F)
</p>
<p>Fat 1 0.086 0.63 0.43
</p>
<p>Residuals 1090 0.14
</p>
<p>suggesting that there is no reason to feel that consumption of olestra in potato chips eaten ad libitem causes GI effects.
</p>
<p>Worked example 8.2 should give you pause. You should think carefully about what the experiment actually shows.
</p>
<p>It should not be interpreted as saying that eating quantities of indigestible fat has no GI consequences, and the authors
</p>
<p>didn&rsquo;t make this claim. The claim might be true, but the experiment is silent on the point. Interpreting an experiment often
</p>
<p>requires scrupulousl precision. What this experiment says is there is no reason to conclude that eating a particular indigestible
</p>
<p>fat in potato chips eaten ad libitem causes GI consequences. One would really like to know how much of the relevant fats
</p>
<p>each group of subjects ate. As an extreme example, think about chips cooked in axle grease eaten ad libitem. These would
</p>
<p>very likely not cause GI symptoms because you wouldn&rsquo;t eat any at all.
</p>
<p>Worked example 8.2 is not really all that interesting, because there are only two levels of treatment. You could analyze
</p>
<p>these experiments with the methods of Sect. 7.2. Here is a more interesting example.
</p>
<p>Worked example 8.3 (Does Hair Color Affect Pain Threshold?) An experiment at the University of Melbourne
</p>
<p>tested the dependency of the pain threshold of human subjects on their hair color. You can find the dataset at http://
</p>
<p>www.statsci.org/data/oz/blonds.html. Assess the evidence that pain threshold depends on hair color.
</p>
<p>Solution If you download the dataset, you&rsquo;ll find that there are four hair colors and nineteen data items. For each
</p>
<p>subject, there is a number. Larger values of this number represent higher tolerable pain thresholds. I obtained the
</p>
<p>ANOVA table below.
</p>
<p>DOF Mean Sq F value Pr(&gt;F)
</p>
<p>HairColour 3 454.0 7.04 0.0035
</p>
<p>Residuals 15 64.5
</p>
<p>This dataset appears in various places on the web, but its status as a &ldquo;real&rdquo; dataset is a bit marginal. I wasn&rsquo;t able
</p>
<p>to find out who conducted this experiment, where the results were published, and whether it conformed to human
</p>
<p>subjects requirements when conducted.</p>
<p/>
<div class="annotation"><a href="http://www.statsci.org/data/oz/blonds.html">http://www.statsci.org/data/oz/blonds.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/oz/blonds.html">http://www.statsci.org/data/oz/blonds.html</a></div>
</div>
<div class="page"><p/>
<p>8.1 A Simple Experiment: The Effect of a Treatment 185
</p>
<p>8.1.6 Significant Differences
</p>
<p>We know how to reject the hypothesis that the treatment has no effect by computing a p-value from an ANOVA. We&rsquo;d like
</p>
<p>to do more. Generally, it is dangerous to fish around in the data produced by an experiment to see if anything fits; if there is
</p>
<p>enough data, something should have a low p-value. It is important to avoid this danger if you want to interpret the experimen-
</p>
<p>tal results correctly (sometimes, it is profitable, though shameful, not to). A natural first step here is a boxplot of what happens
</p>
<p>at each treatment level (Fig. 8.1). With luck, the effect of the treatment will be so strong that significance testing is a formality.
</p>
<p>One way to avoid this danger is to declare a set of hypotheses we want to evaluate in advance of the experiment, then
</p>
<p>investigate those. The procedure is particularly straightforward for hypotheses known as contrasts. These are linear functions
</p>
<p>of the treatment means. Recall I wrote �i for the treatment means. A contrast takes the form
</p>
<p>X
</p>
<p>i
</p>
<p>ci�i
</p>
<p>for some set of constants ci. There are two relatively straightforward procedures. We could produce a confidence interval
</p>
<p>for a contrast. Alternatively, we can evaluate the significance of the evidence against a contrast being zero. Each of these
</p>
<p>procedures relies on the fact that we know the distribution of the estimate O�i for the treatment means. In particular, O�i is the
value of a random variable Mj which is normally distributed (assuming that �ij are normally distributed); has mean �i; and,
</p>
<p>writing Gi for the number of subjects in the i&rsquo;th group, has variance
</p>
<p>�2
</p>
<p>Gi
:
</p>
<p>In turn, this means that
X
</p>
<p>i
</p>
<p>ci O�i
</p>
<p>is the value of a random variable C which is normally distributed; has mean
P
</p>
<p>i ci�i; and has variance
</p>
<p>Boxplots of Aldrin concentration at three depths
</p>
<p>Bottom Middepth Surface DarkBlond DarkBrunette LightBlond LightBrunette
</p>
<p>3
4
</p>
<p>5
6
</p>
<p>7
8
</p>
<p>9
</p>
<p>3
0
</p>
<p>4
0
</p>
<p>5
0
</p>
<p>6
0
</p>
<p>7
0
</p>
<p>Boxplots of pain resistance for three hair colors
</p>
<p>Fig. 8.1 On the left, a boxplot of concentration of Aldrin at three different depths (see Worked example 8.1). There&rsquo;s a strong suggestion here that
the concentration is affected by depth level, which is the treatment. Notice how the box for the &ldquo;Surface&rdquo; measurements does not intersect the box
for the &ldquo;Deep&rdquo; measurements. On the right, a boxplot of the tolerable pain level by hair color for the data of Worked example 8.3. There&rsquo;s a strong
suggestion here that hair color affects pain threshold, though you should be careful relying on this conclusion. As the worked example points out,
it isn&rsquo;t clear where the data came from, or what it means</p>
<p/>
</div>
<div class="page"><p/>
<p>186 8 Experiments
</p>
<p>�2
X
</p>
<p>i
</p>
<p>c2i
</p>
<p>Gi
</p>
<p>Now producing a confidence interval for a contrast follows the lines of Sect. 6.2. Evaluating the significance of the evidence
</p>
<p>against a contrast being zero follows the lines of Sect. 7.1. Notice that we do not know �2, but must estimate it. This means
</p>
<p>we should use a T-test. We estimate �2 as MSW (Sect. 8.1.3), so the number of degrees of freedom is
P
</p>
<p>i.Gi � 1/.
One natural set of contrasts are the differences between treatment means. You should notice that if there are L treatment
</p>
<p>levels there are L.L � 1/=2 differences, which will get inconvenient if there are many treatment means. With that said, it
is quite usual to look for significant difference between treatment means. The simplest procedure for doing so follows the
</p>
<p>recipe for contrasts, above.
</p>
<p>Worked example 8.4 (How Significant are the Differences in Aldrin Concentration at Different Depths?) Jaffe
</p>
<p>et al measured the concentration of various pollutants in the Wolf river. Assess how different the mean concentration
</p>
<p>is at each depth. You can find the dataset at http://www.statsci.org/data/general/wolfrive.html.
</p>
<p>Solution There are three depths: Surface, Middepth, and Bottom. I found
</p>
<p>O�Middepth � O�Surface D 0:83
</p>
<p>O�Bottom � O�Middepth D 1:00
</p>
<p>O�Bottom � O�Surface D 1:83
</p>
<p>and the standard error for each was 0:56. This means that the difference between Middepth and Surface is about one
</p>
<p>and half standard errors, and is quite possibly due to sampling effects (using a one sided t-test with 9 degrees of
</p>
<p>freedom, I got a p-value of 0:086). The difference between Bottom and Middepth is unlikely to be due to sampling
</p>
<p>effects (p-value: 0:053); and the difference between Bottom and Surface is extremely unlikely to be due to sampling
</p>
<p>effects (p-value: 0:0049). I used a one-sided test here, because I wanted to assess the fraction of samples likely to have
</p>
<p>even larger differences than the one observed.
</p>
<p>You need to approach this procedure with moderate caution. If L is large, it is possible that you will think more differences
</p>
<p>are significant than is really the case, because you are looking at multiple differences and samples. The significance test hasn&rsquo;t
</p>
<p>taken this into account. More advanced methods&mdash;beyond the scope of this account&mdash;are required to do deal with this.
</p>
<p>8.2 Two Factor Experiments
</p>
<p>Now imagine there are two factors that likely affect the outcome of an experiment. For example, we might be testing the
</p>
<p>effect of having more RAM and having a higher clock speed on the speed of some program. The treatments here are obvious:
</p>
<p>different levels of treatment correspond to different amounts of RAM and different clock speeds (say, small, medium and
</p>
<p>large RAM; low, medium and high clock speeds). One possibility is to set up one experiment to test the effect of RAM and
</p>
<p>another to test the effect of the clock speed. But this is not a good idea.
</p>
<p>First, the treatments might interact in some way, and the experiment we set up should be able to identify this if it happens.
</p>
<p>Second, it turns out that a sensible design that investigates both factors together will involve fewer treatments than if we
</p>
<p>investigate the factors separately.
</p>
<p>This will become clear as we set up the experiment for two factors. We will deal only with balanced experiments, because
</p>
<p>they&rsquo;re easier to interpret. We will assume that the first factor has L1 levels, and the second factor has L2 levels. It&rsquo;s natural to
</p>
<p>visualize the experiment as an L1 � L2 table of cells, where each cell contains the subjects for the experiment at those levels
(Fig. 8.2). Each cell will contain G subjects. Performing this experiment will involve measuring L1 � L2 �G measurements.
</p>
<p>Now assume the factors do not interact. Then we can use the rows to estimate the effect of factor one at L1 different
</p>
<p>levels using G � L2 measurements per cell. Similarly, we can use the columns to estimate the effect of factor two at L2
different levels using G � L1 measurements per cell. To obtain the same number of measurements per cell for each factor</p>
<p/>
<div class="annotation"><a href="http://www.statsci.org/data/general/wolfrive.html">http://www.statsci.org/data/general/wolfrive.html</a></div>
</div>
<div class="page"><p/>
<p>8.2 Two Factor Experiments 187
</p>
<p>Fig. 8.2 Think about a two
factor experiment as an L1 � L2
table of cells, each containing G
subjects chosen at random. The
subjects in each cell get the level
of treatments one and two chosen
by the cell&rsquo;s indices in the table.
We write xijk for the response
observed for the k&rsquo;th subject in
cell i; j
</p>
<p>G 
</p>
<p>subjects
</p>
<p>G 
</p>
<p>subjects
</p>
<p>G 
</p>
<p>subjects
</p>
<p>G 
</p>
<p>subjects
</p>
<p>...
</p>
<p>......
</p>
<p>...
</p>
<p>...
</p>
<p>L
1
</p>
<p> le
v
el
</p>
<p>s 
o
f 
</p>
<p>tr
ea
</p>
<p>tm
en
</p>
<p>t 
o
n
e
</p>
<p>L2 levels of treatment one
</p>
<p>with independent experiments would take more experiments. You would have to use L1 � .G � L2/ experiments for factor
one and another L2 � .G � L1/ experiments for factor two.
</p>
<p>Randomization is still a strong strategy for assigning groups to cells. Again, we will assume that the experimental
</p>
<p>equipment doesn&rsquo;t have a memory, and that changing settings and so on is trivial. We allocate subjects to groups at random,
</p>
<p>ensuring that each group gets G subjects. You could do this, for example, by permuting the subjects randomly, then allocating
</p>
<p>the first G to group 1; 1, etc.
</p>
<p>We then perform the experiment, by treating each group of subjects at the prescribed level, and recording the results. For
</p>
<p>each subject, we will observe a measurement. We want to know if there is an interaction between the treatments, and if either
</p>
<p>treatment has any effect. We can investigate this question using methods like those for one-factor experiments.
</p>
<p>We assume that differences in observed values in each group are purely due to noise. Write xijk for the observed value for
</p>
<p>the k&rsquo;th subject in the treatment group that has the i&rsquo;th level of the first treatment and the j&rsquo;th level of the second treatment.
</p>
<p>This means that we could model
</p>
<p>xijk D �ij C �ij
where �ij is &ldquo;noise&rdquo;&mdash;unmodelled effects that have zero mean. There are three effects that could cause the groups to have
</p>
<p>different mij. The first treatment might have an effect; the second treatment might have an effect; or there could be an
</p>
<p>interaction between the treatments that could have an effect. Write ai for the effects caused by the first treatment, bj for the
</p>
<p>effects caused by the second treatment, and cij for interaction effects. We can model
</p>
<p>�ij D �C ai C bj C cij:
</p>
<p>As in the case for single factor experiments, we constrain ai, bj and cij so that the mean of the �ij terms is �. This means that
P
</p>
<p>u au D 0,
P
</p>
<p>v bv D 0,
P
</p>
<p>u cuv D 0, and
P
</p>
<p>v cuv D 0 (notice this means that
P
</p>
<p>uv cuv D 0, too).
As in the single factor case, we assume that the noise is independent of the treatment level. This assumption is satisfied
</p>
<p>by randomizing the allocation of subjects to treatment groups. We will assume that the noise is normally distributed, with
</p>
<p>variance �2. We will use traditional notation, and write �i� D �Cai and ��j D �Cbj. Again, it is straightforward to estimate
�, �i�, ��j, and �ij with least squares. As before, we write O� for our estimate of �, and so on. As before, we then choose O�
to be the value of � that minimizes the overall sum of squared differences
</p>
<p>X
</p>
<p>ijk
</p>
<p>.xijk � �/2:
</p>
<p>We choose each O�ij to be the value of �ij that minimizes the sum of squared differences within the i, j&rsquo;th group
</p>
<p>O�ij D argmin�ij
X
</p>
<p>k
</p>
<p>.xijk � �ij/2:</p>
<p/>
</div>
<div class="page"><p/>
<p>188 8 Experiments
</p>
<p>Now consider O�i�. There are L1 different values, one for each level of the first factor. These account for the effects of the first
factor alone, so we choose O�i� to minimize the sum of squared differences to every measurement at the i&rsquo;th level of the first
factor. This is
</p>
<p>O�i� D argmin�i�
X
</p>
<p>jk
</p>
<p>.xijk � �i�/2:
</p>
<p>A similar argument works for O��j. There are L2 different values, one for each level of the first factor. These account for the
effects of the second factor alone, so we choose O��j to minimize the sum of squared differences to every measurement at the
j&rsquo;th level of the second factor. This is
</p>
<p>O��j D argmin��j
X
</p>
<p>ik
</p>
<p>.xijk � ��j/2:
</p>
<p>All this yields
</p>
<p>O� D
P
</p>
<p>ijk xijk
</p>
<p>GL1L2
</p>
<p>O�ij D
P
</p>
<p>k xijk
</p>
<p>G
</p>
<p>O�i� D
P
</p>
<p>jk xijk
</p>
<p>GL2
</p>
<p>O��j D
P
</p>
<p>ik xijk
</p>
<p>GL1
:
</p>
<p>8.2.1 Decomposing the Error
</p>
<p>Think of the results as sitting in a table of L1 � L2 cells, one for each pair of treatment levels. The overall sum of squared
differences from the estimated mean O� is
</p>
<p>SST D
X
</p>
<p>ijk
</p>
<p>.xijk � O�/2:
</p>
<p>This can be decomposed into four terms, rather like the pattern in Sect. 8.1.2. We have that
</p>
<p>X
</p>
<p>ijk
</p>
<p>.xijk � O�/2 D
X
</p>
<p>ijk
</p>
<p>2
</p>
<p>6
</p>
<p>6
</p>
<p>6
</p>
<p>6
</p>
<p>6
</p>
<p>6
</p>
<p>4
</p>
<p>.xijk � O�ij/C
</p>
<p>. O�i� � O�/C
</p>
<p>. O��j � O�/C
</p>
<p>. O�ij � O�i� � O��j C O�/
</p>
<p>3
</p>
<p>7
</p>
<p>7
</p>
<p>7
</p>
<p>7
</p>
<p>7
</p>
<p>7
</p>
<p>5
</p>
<p>2
</p>
<p>D
</p>
<p>2
</p>
<p>6
</p>
<p>6
</p>
<p>6
</p>
<p>6
</p>
<p>6
</p>
<p>6
</p>
<p>4
</p>
<p>P
</p>
<p>ijk.xijk � O�ij/2C
</p>
<p>GL2
P
</p>
<p>i. O�i� � O�/2C
</p>
<p>GL1
P
</p>
<p>j. O��j � O�/2C
</p>
<p>G
P
</p>
<p>ij. O�ij � O�i� � O��j C O�/2
</p>
<p>3
</p>
<p>7
</p>
<p>7
</p>
<p>7
</p>
<p>7
</p>
<p>7
</p>
<p>7
</p>
<p>5
</p>
<p>;
</p>
<p>which you can establish using (a lot more of) the same reasoning as in Sect. 8.1.2. We label these terms</p>
<p/>
</div>
<div class="page"><p/>
<p>8.2 Two Factor Experiments 189
</p>
<p>SST D
X
</p>
<p>ijk
</p>
<p>.xijk � O�/2
</p>
<p>SSW D
X
</p>
<p>ijk
</p>
<p>.xijk � O�ij/2
</p>
<p>SSTr1 D GL2
X
</p>
<p>i
</p>
<p>. O�i� � O�/2
</p>
<p>SSTr2 D GL1
X
</p>
<p>j
</p>
<p>. O��j � O�/2
</p>
<p>SSI D G
X
</p>
<p>ij
</p>
<p>. O�ij � O�i� � O��j C O�/2:
</p>
<p>The same line of reasoning as in Sect. 8.1.2 applies to these terms. Imagine neither treatment has any effect, and there is no
</p>
<p>interaction. Then each of O�ij, O�i� and O��j should be similar, meaning that SSW should be large compared to the other terms.
Now imagine there is a strong interaction between the treatments. This means that cij is &ldquo;large&rdquo;; but . O�ij � O�i� � O��j C O�/ is
an estimate of cij, so we expect that SSI will be &ldquo;large&rdquo;. Again, we need to be crisp about what it means to be &ldquo;large&rdquo;, and
</p>
<p>we can do this using ideas of significance.
</p>
<p>As before, we will use estimates of the noise variance to compute measures of significance. We can estimate the variance
</p>
<p>of the noise using any of the cells. A better estimate is obtained by averaging over the cells, so we have as an estimate of the
</p>
<p>noise variance, sometimes called the within group mean squares and written MSW. We have
</p>
<p>O�2cellave D
�
</p>
<p>1
</p>
<p>L1L2
</p>
<p>�
</p>
<p>X
</p>
<p>ijk
</p>
<p>.xijk � O�ij/2
G � 1
</p>
<p>D SSW
�
</p>
<p>1
</p>
<p>L1L2.G � 1/
</p>
<p>�
</p>
<p>D MSW:
</p>
<p>This estimate has L1L2.G � 1/ degrees of freedom, because we used L1L2G data items, and estimated L1L2 means.
</p>
<p>8.2.2 Interaction Between Effects
</p>
<p>Assume there is no interaction between the treatments. Then the true cij should be zero. Notice that we have the following
</p>
<p>estimates
</p>
<p>�C ai C bj C cij � O�ij
�C ai � O�i�
�C bj � O��j
� � O�
</p>
<p>so that we can estimate cij as O�ij� O�i�� O��jC O�. Now each subject&rsquo;s response has some noise in it, with variance �2 which is
unknown, but is the same for all subjects and all treatment levels. This means that O�ij� O�i�� O��jC O� is the value of a random
variable whose mean is zero. This estimate is averaged over G subjects, so the variance of the random variable is �2=G. So
</p>
<p>we can estimate
</p>
<p>O�2inter D G
P
</p>
<p>ij. O�ij � O�i� � O��j C O�/2
</p>
<p>.L1 � 1/.L2 � 1/
</p>
<p>D
�
</p>
<p>1
</p>
<p>.L1 � 1/.L2 � 1/
</p>
<p>�
</p>
<p>SSI D MSI:
</p>
<p>This estimate is sometimes called the interaction mean squares, and written MSI.</p>
<p/>
</div>
<div class="page"><p/>
<p>190 8 Experiments
</p>
<p>If there is no interaction, then any difference between MSI and MSW would have to be the result of sampling
</p>
<p>effects. We can apply an F-test of significance (Sect. 7.3.1), applied to the ratio of the estimates. In turn, this would
</p>
<p>mean that
</p>
<p>F D MSI
MSW
</p>
<p>would be &ldquo;about&rdquo; one, with a known distribution (the F-distribution; Sect. 7.3.1). Now imagine there is some interaction.
</p>
<p>Then we expect that MSI is larger than MSW, because the O�ij differ from predictions made assuming no interaction, so we
expect F is larger than one. Finally, we need the degrees of freedom. The estimate MSI has .L1L2 � 1/ degrees of freedom.
The estimate MSW has L1L2.G�1/ degrees of freedom. We can now use the F-test to obtain a p-value for F with .L1L2�1/,
L1L2.G � 1/ degrees of freedom. In other words, we use tables or a software environment to evaluate
</p>
<p>Z 1
</p>
<p>F
</p>
<p>pf .uI .L1L2 � 1/;L1L2.G � 1//du
</p>
<p>(where pf is the probability density for the F-statistic, Sect. 7.3.1).
</p>
<p>8.2.3 The Effects of a Treatment
</p>
<p>Assume we find no interaction between the treatments. Now we investigate the effect of treatment one. If there is no effect,
</p>
<p>then the true ai should be zero. Recall that ai can be estimated by O�i� � O�. Each subject&rsquo;s response has some noise in it, with
variance �2 which is unknown, but is the same for all subjects and all treatment levels. This means that, for each i, we have
</p>
<p>O�i�� O� is the value of a random variable whose mean is zero. The estimate of ai has been obtained by averaging GL2 subjects
(all those who have level i of treatment one) so the variance of this random variable is �2=.GL2/. We can estimate �
</p>
<p>2 using
</p>
<p>treatment one means. This estimate is sometimes called the treatment one mean squares, and written MST1. We have
</p>
<p>O�2T1 D GL2
P
</p>
<p>i. O�i� � O�/2
L1 � 1
</p>
<p>D SSTr1
�
</p>
<p>1
</p>
<p>L1 � 1
</p>
<p>�
</p>
<p>D MST1:
</p>
<p>If there is no effect, then any difference between MST1 and MSW would have to be the result of sampling effects. We
</p>
<p>can apply an F-test of significance (Sect. 7.3.1), applied to the ratio of the estimates. Now imagine there is some effect of
</p>
<p>treatment. This would mean that
</p>
<p>F D MST1
MSW
</p>
<p>would be &ldquo;about&rdquo; one, with a known distribution (the F-distribution; Sect. 7.3.1). If there is a treatment effect, then we expect
</p>
<p>F to be larger than one. Finally, we need the degrees of freedom. The estimate MST1 has .L1 � 1/ degrees of freedom. The
estimate MSW has L1L2.G � 1/ degrees of freedom. We can now use the F-test to obtain a p-value for F with .L1 � 1/,
L1L2.G�1/ degrees of freedom. If the p-value is small enough, then only an extremely unlikely set of samples could explain
the difference between the levels of treatment one as sampling error; it is more likely the treatment has an effect.
</p>
<p>Treatment two works like treatment one. The estimate of �2 from the treatment two means is called the treatment two
</p>
<p>mean squares, and written MST2. We have
</p>
<p>O�2T2 D GL1
P
</p>
<p>j. O��j � O�/2
</p>
<p>L2 � 1
</p>
<p>D SSTr2
�
</p>
<p>1
</p>
<p>L2 � 1
</p>
<p>�
</p>
<p>D MST2:
</p>
<p>We end up using the F-test to obtain a p-value for the statistic
</p>
<p>F D MST2
MSW
</p>
<p>with .L2 � 1/, L1L2.G � 1/ degrees of freedom.</p>
<p/>
</div>
<div class="page"><p/>
<p>8.2 Two Factor Experiments 191
</p>
<p>8.2.4 Setting Up An ANOVA Table
</p>
<p>We now have a powerful and useful procedure that I can name. The analysis is referred to as a two-factor ANOVA (or two-
</p>
<p>way ANOVA. Because there is so much of it, it is hard to put in one box, and I have used two. Again, we compute a set of
</p>
<p>terms, put them in a highly informative table, and then draw conclusions by inspecting the table.
</p>
<p>Procedure 8.2 (Setting up a Two-Way ANOVA) Perform a randomized experiment: Choose L1 levels of
</p>
<p>treatment for the first treatment, and L2 levels for the second. Randomize L1L2G subjects into L1 � L2 treatment
groups of G subjects each. Treat each subject, and record the results.
</p>
<p>Terminology:
</p>
<p>xijk value for the k&rsquo;th subjectfor level i of treatment one
</p>
<p>and level j of treatment two
</p>
<p>O� overall mean
P
</p>
<p>ijk xijk=.GL1L2/
</p>
<p>O�ij group means
P
</p>
<p>k xijk=.G/
</p>
<p>O�i� treatmentone means
P
</p>
<p>jk xijk=.GL2/
</p>
<p>O��j treatmenttwo means
P
</p>
<p>ik xijk=.GL1/
</p>
<p>SSW within group sum of squares
P
</p>
<p>ijk.xijk � O�ij/2
SSI interaction sum of squares G
</p>
<p>P
</p>
<p>ij. O�ij � O�i� � O��j C O�/2
SSTr1 treatment one sum of squares GL2
</p>
<p>P
</p>
<p>i. O�i� � O�/2
SSTr2 treatment two sum of squares GL1
</p>
<p>P
</p>
<p>j. O��j � O�/2
MSW within group mean squares .1=.L1L2.G � 1/// SSW
MSI interaction mean squares .1=Œ.L1 � 1/.L2 � 1/&#141;/ SSI
MST1 treatment one mean squares .1=.L1 � 1//SSTr1
MST2 treatment two mean squares .1=.L2 � 1//SSTr2
Fi interaction F-statistic MSI=MSW
F1 treatment F-statistic MST1=MSW
F2 treatment two F-statistic MST2=MSW
p-values Statistic DOF
</p>
<p>interaction Fi ŒL1L2 � 1&#141; ;
ŒL1L2.G � 1/&#141;
</p>
<p>treatment one F1 ŒL1 � 1&#141;
ŒL1L2.G � 1/&#141;
</p>
<p>treatment two F2 ŒL2 � 1&#141; ;
ŒL1L2.G � 1/&#141;
</p>
<p>Procedure 8.3 (Forming and Interpreting a Two-Way ANOVA Table) Make the ANOVA table: Form the table
</p>
<p>DOF Sum Sq Mean Sq F value Pr(&gt;F)
</p>
<p>Tr 1 L1 � 1 SSTr1 MST1 MST1=MSW tr 1 p-value
Tr 2 L2 � 1 SSTr2 MST2 MST2=MSW tr 2 p-value
Tr 1:Tr 2 L1 L2 � 1 SSI MSI MSI=MSW int p-value
Res L1L2 .G � 1/ SSW MSW
</p>
<p>Interpretation: If the interaction p-value is small enough, it is likely the treatments interact. If the treatments interact,
</p>
<p>they must have an effect. If the treatments appear not to interact, then a small value of either of the treatment p-values
</p>
<p>implies that only an extremely unlikely set of samples could explain the difference between groups.</p>
<p/>
</div>
<div class="page"><p/>
<p>192 8 Experiments
</p>
<p>Survival time against treatment, for poison 1
</p>
<p>1 2 3 4 1 2 3 4
</p>
<p>0
.2
</p>
<p>0
.4
</p>
<p>0
.6
</p>
<p>0
.8
</p>
<p>1
.0
</p>
<p>1
.2
</p>
<p>0
.2
</p>
<p>0
.4
</p>
<p>0
.6
</p>
<p>0
.8
</p>
<p>1
.0
</p>
<p>1
.2
</p>
<p>Survival time against treatment, for poison 2
</p>
<p>Fig. 8.3 On the left, boxplots of the survival time of subjects (animals of unrecorded species) poisoned with poison 1, by antidote type, for the
experiment of Worked example 8.6. On the right, for poison 2. Generally, if there is no effect of a treatment the boxes in a graph should look the
same; if there is no interaction, the pattern formed by the boxes should look the same, with perhaps a shift up or down of all boxes. The poisons
clearly have an effect, the antidotes clearly have an effect, and (though the shape of the box patterns looks a bit different), there really isn&rsquo;t evidence
that there is an interaction
</p>
<p>Worked example 8.5 (Poison and Treatment) Investigate the effects of poison and treatment, using the data at http://
</p>
<p>www.statsci.org/data/general/poison.html
</p>
<p>Solution This dataset records survival times of animals poisoned with one of three poisons and supplied with one of
</p>
<p>four antidotes. I obtained the following ANOVA table
</p>
<p>DOF Sum Sq Mean Sq F value Pr(&gt;F)
</p>
<p>Poison 2 1.03301 0.51651 23.2217 3.331e-07
</p>
<p>Antidote 3 0.92121 0.30707 13.8056 3.777e-06
</p>
<p>Poison: Antidote 6 0.25014 0.04169 1.8743 0.1123
</p>
<p>Residuals 36 0.80073 0.02224
</p>
<p>From which it seems safe to conclude that there isn&rsquo;t any interaction, but the antidotes work, and the poison does have
</p>
<p>an effect on survival time. Figure 8.3 drives home these conclusions.
</p>
<p>Worked example 8.6 (Memory and Older People) Use Eysenck&rsquo;s data from http://www.statsci.org/data/general/
</p>
<p>eysenck.html to determine whether Age interacts with Processing, and whether either Age or Processing have
</p>
<p>significant effects on the number of words memorized
</p>
<p>Solution In 1974, Eysenck investigated memory in people. There were two effects of interest. First, the age of the
</p>
<p>subjects (Age). Eysenck used two groups, one of subjects between 55 and 65 years old, and another of younger
</p>
<p>subjects. Second, the extent to which material to be memorized was processed (Process). Eysenck used five groups.
</p>
<p>Each was given a list of words, and asked to perform a task. Afterward, each was asked to write down all the words
</p>
<p>(continued)</p>
<p/>
<div class="annotation"><a href="http://www.statsci.org/data/general/poison.html">http://www.statsci.org/data/general/poison.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/general/poison.html">http://www.statsci.org/data/general/poison.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/general/eysenck.html">http://www.statsci.org/data/general/eysenck.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/general/eysenck.html">http://www.statsci.org/data/general/eysenck.html</a></div>
</div>
<div class="page"><p/>
<p>8.2 Two Factor Experiments 193
</p>
<p>Words remembered against process, for Younger subjects
</p>
<p>Adjective Counting Imagery Intentional Rhyming Adjective Counting Imagery Intentional Rhyming
</p>
<p>5
1
</p>
<p>0
1
</p>
<p>5
2
</p>
<p>0
</p>
<p>5
1
</p>
<p>0
1
</p>
<p>5
2
</p>
<p>0
</p>
<p>Words remembered against process, for Older subjects
</p>
<p>Fig. 8.4 On the left, boxplots of the number of words remembered using different processes for younger subjects in the experiment of Worked
example 8.6. On the right, for older subjects. Generally, if there is no effect of a treatment the boxes in a graph should look the same; if there is no
interaction, the pattern formed by the boxes should look the same, with perhaps a shift up or down of all boxes. The interaction between age and
process should be clear. Both age groups find Counting and Rhyming hard, but the effect is much more pronounced for younger subjects
</p>
<p>they could remember, and the number of words remembered is the response. The Intentional group was told they were
</p>
<p>to remember the words. The other four groups were asked to perform a task with the words. These four were: Adjective
</p>
<p>(give an adjective for each word); Counting (count the number of letters in each word); Imagery (form vivid images
</p>
<p>of each word); and Rhyming (think of a word that rhymed with each word). There are 10 subjects in each group.
</p>
<p>The original study was published as: Eysenck, M. W. (1974). Age differences in incidental learning. Developmental
</p>
<p>Psychology, 10, 936&ndash;941.
</p>
<p>I obtained the ANOVA table
</p>
<p>DOF Sum Sq Mean Sq F value Pr(&gt;F)
</p>
<p>Age 1 240.25 240.25 29.9356 3.981e-07
</p>
<p>Process 4 1514.94 378.74 47.1911 &lt; 2.2e-16
</p>
<p>Age: 4 190.30 47.58 5.9279 0.0002793
</p>
<p>Process
</p>
<p>Residuals 90 722.30 8.03
</p>
<p>(where the &ldquo;Age:Process&rdquo; line is the interaction term). Here there is an interaction, and each treatment has an effect, i.e.
</p>
<p>Age affects how you remember things, the process by which you interact with them affects it too, and the two factors
</p>
<p>affect one another. Figure 8.4 shows boxplots which make the interactions pretty clear.</p>
<p/>
</div>
<div class="page"><p/>
<p>194 8 Experiments
</p>
<p>8.3 You Should
</p>
<p>8.3.1 Remember These Definitions
</p>
<p>8.3.2 Remember These Terms
</p>
<p>Randomization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
</p>
<p>balanced . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
</p>
<p>within group variation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
</p>
<p>residual variation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
</p>
<p>between group variation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
</p>
<p>treatment variation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
</p>
<p>analysis of variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
</p>
<p>ANOVA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
</p>
<p>ANOVA table . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
</p>
<p>one factor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
</p>
<p>balanced experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
</p>
<p>unbalanced experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
</p>
<p>contrasts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
</p>
<p>within group mean squares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
</p>
<p>interaction mean squares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
</p>
<p>treatment one mean squares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
</p>
<p>treatment two mean squares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
</p>
<p>two-factor ANOVA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
</p>
<p>two-way ANOVA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
</p>
<p>8.3.3 Remember These Facts
</p>
<p>8.3.4 Use These Procedures
</p>
<p>Evaluate treatment effects with a one-way ANOVA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
</p>
<p>Set up a two-way ANOVA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
</p>
<p>Evaluate two treatments with a two-way ANOVA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
</p>
<p>8.3.5 Be Able to
</p>
<p>&bull; Set up a simple randomized balanced one factor experiment.
</p>
<p>&bull; Construct an ANOVA table for the resulting data, and use it to tell whether the treatment has an effect or not.
</p>
<p>&bull; Estimate the significance of differences in results for different treatment levels.
</p>
<p>&bull; Set up a simple randomized balanced two factor experiment.
</p>
<p>&bull; Construct an ANOVA table for the resulting data, and use it to tell whether there are interactions, and whether either
</p>
<p>treatment has an effect or not.
</p>
<p>&bull; Estimate the significance of differences in results for different treatment levels.
</p>
<p>&bull; Interpret data from an unbalanced one-factor experiment.</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 195
</p>
<p>Problems
</p>
<p>Decomposing the Squared Error
</p>
<p>8.1 You will show that the squared error of a one-way experiment decomposes into two terms, as in Sect. 8.1.2. Write
</p>
<p>X
</p>
<p>ij
</p>
<p>.xij � O�/2 D
X
</p>
<p>ij
</p>
<p>..xij � O�i/C . O�i � O�//2:
</p>
<p>(a) Show that the square can be expanded and rearranged to obtain
</p>
<p>2
</p>
<p>4
</p>
<p>X
</p>
<p>ij
</p>
<p>.xij � O�i/2
3
</p>
<p>5C G
"
</p>
<p>X
</p>
<p>i
</p>
<p>. O� � O�i/2
#
</p>
<p>C 2
X
</p>
<p>i
</p>
<p>2
</p>
<p>4
</p>
<p>0
</p>
<p>@
</p>
<p>X
</p>
<p>j
</p>
<p>.xij � O�i/
</p>
<p>1
</p>
<p>A . O� � O�i/
</p>
<p>3
</p>
<p>5 :
</p>
<p>(b) Show that, because O�i minimizes
P
</p>
<p>j.xij � �i/2,
0
</p>
<p>@
</p>
<p>X
</p>
<p>j
</p>
<p>.xij � O�i/
</p>
<p>1
</p>
<p>A D 0
</p>
<p>(c) Now show
</p>
<p>X
</p>
<p>ij
</p>
<p>.xij � O�/2 D
</p>
<p>2
</p>
<p>4
</p>
<p>X
</p>
<p>ij
</p>
<p>.xij � O�i/2
3
</p>
<p>5C G
"
</p>
<p>X
</p>
<p>i
</p>
<p>. O� � O�i/2
#
</p>
<p>:
</p>
<p>8.2 You will show that the squared error of a two-way experiment decomposes into four terms, after the pattern of the
</p>
<p>previous exercise.
</p>
<p>(a) Show that
</p>
<p>X
</p>
<p>ijk
</p>
<p>.xijk � O�/2 D
X
</p>
<p>ijk
</p>
<p>2
</p>
<p>6
</p>
<p>6
</p>
<p>4
</p>
<p>.xijk � O�ij/C
</p>
<p>. O�i� � O�/C
</p>
<p>. O��j � O�/C
</p>
<p>. O�ij � O�i� � O��j C O�/
</p>
<p>3
</p>
<p>7
</p>
<p>7
</p>
<p>5
</p>
<p>2
</p>
<p>:
</p>
<p>(b) Show that
X
</p>
<p>k
</p>
<p>.xijk � O�ij/ D 0
</p>
<p>for any i, j, by recalling the definition of O�ij.
(c) Show that
</p>
<p>X
</p>
<p>i
</p>
<p>. O�i� � O�/ D 0
</p>
<p>for any i, by recalling the definition of O�i� and O�.
(d) Show that
</p>
<p>X
</p>
<p>j
</p>
<p>. O�j� � O�/ D 0
</p>
<p>for any j, by recalling the definition of O�j� and O�.</p>
<p/>
</div>
<div class="page"><p/>
<p>196 8 Experiments
</p>
<p>(e) Now show that
</p>
<p>X
</p>
<p>ijk
</p>
<p>.xijk � O�/2 D
</p>
<p>2
</p>
<p>6
</p>
<p>6
</p>
<p>4
</p>
<p>P
</p>
<p>ijk.xijk � O�ij/2C
GL2
</p>
<p>P
</p>
<p>i. O�i� � O�/2C
GL1
</p>
<p>P
</p>
<p>j. O��j � O�/2C
G
P
</p>
<p>ij. O�ij � O�i� � O��j C O�/2
</p>
<p>3
</p>
<p>7
</p>
<p>7
</p>
<p>5
</p>
<p>:
</p>
<p>Unbalanced One-Way Experiments
</p>
<p>8.3 The Rules of Rugby You will find a dataset giving the times of passages of play in games of rugby at http://www.statsci.
</p>
<p>org/data/oz/rugby.html. The data was collected by Hollings and Triggs in 1993. The first five games were played under the
</p>
<p>old rules, and the second five under the new rules. Use an unbalanced one-way ANOVA to determine whether the change of
</p>
<p>rules made a difference in the times of passages of play.
</p>
<p>8.4 Eye Color and Flicker Frequency You will find a dataset recording the critical flicker frequency and eye color for
</p>
<p>19 individuals at http://www.statsci.org/data/general/flicker.html. The data was collected by Devore and Peck in 1973. Use
</p>
<p>an unbalanced one-way ANOVA to determine whether individuals with different eye colors have different critical flicker
</p>
<p>frequencies.
</p>
<p>8.5 Survival on the Titanic You will find a dataset recording the survival status of passengers on the Titanic at http://
</p>
<p>www.statsci.org/data/general/titanic.html. This data comes originally from Encyclopedia Titanica, by Philip Hinde. Use an
</p>
<p>unbalanced one-way ANOVA to determine whether the class of the passenger&rsquo;s ticket had an effect on their survival.
</p>
<p>Two-Way Experiments
</p>
<p>8.6 Paper Planes You will find a dataset recording the performance of paper planes at http://www.statsci.org/data/oz/planes.
</p>
<p>html. This data comes originally from the paper What is the use of experiments conducted by statistics students?, by M.S.
</p>
<p>Mackisack, which appeared in the Journal of Statistics Education in 1994. Use a two-way ANOVA to analyze the effects of
</p>
<p>paper and angle on the distance covered by the plane. Is there an interaction between these variables?</p>
<p/>
<div class="annotation"><a href="http://www.statsci.org/data/oz/rugby.html">http://www.statsci.org/data/oz/rugby.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/oz/rugby.html">http://www.statsci.org/data/oz/rugby.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/general/flicker.html">http://www.statsci.org/data/general/flicker.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/general/titanic.html">http://www.statsci.org/data/general/titanic.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/general/titanic.html">http://www.statsci.org/data/general/titanic.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/oz/planes.html">http://www.statsci.org/data/oz/planes.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/oz/planes.html">http://www.statsci.org/data/oz/planes.html</a></div>
</div>
<div class="page"><p/>
<p>9Inferring Probability Models fromData
</p>
<p>One very useful way to draw conclusions from a dataset is to fit a probability model to that dataset. Once this is done, we can
</p>
<p>apply any of our procedures to the probability model to (for example) predict new data or estimate properties of future data.
</p>
<p>For example, you could flip a coin ten times and see five heads and five tails. To be able to estimate the probability of seeing
</p>
<p>heads on a future flip, you would need to fit a model. But once you had done so, you could also estimate the probability that
</p>
<p>five future flips would give you three heads and two tails, and so on.
</p>
<p>The first step is to choose a model. I have described a relatively small subset of available probability models (really!), and
</p>
<p>so the choice of model will mostly be obvious. For example, we will use binomial or geometric models for coin flips, and so
</p>
<p>on. The procedures I describe, however, are quite general. They extend in principle to any model. Furthermore, they do not
</p>
<p>require that the model be right. Surprisingly, you can often extract quite useful information from a dataset by fitting a model
</p>
<p>that isn&rsquo;t the model that produced the dataset.
</p>
<p>Once you have a model, you need to estimate values for its parameters. For example, if you use a binomial model for a coin
</p>
<p>flip, then you need to determine the probability a flip will come up heads. There are two kinds of procedure for estimating
</p>
<p>parameter values. Maximum likelihood finds the values of the parameters that make the observed data most likely. Bayesian
</p>
<p>inference produces a posterior probability distribution on the parameter values, and extracts information from that. Mostly,
</p>
<p>the description of these procedures is straightforward, but actually using them takes a little practice, so the sections in this
</p>
<p>chapter are mostly worked examples.
</p>
<p>9.1 EstimatingModel Parameters with Maximum Likelihood
</p>
<p>Assume we have a dataset D D fxg, and a probability model we believe applies to that dataset. Generally, application
logic suggests the type of model (i.e. normal probability density; Poisson probability; geometric probability; and so on). But
</p>
<p>usually, we do not know values for the parameters of the model&mdash;for example, the mean and standard deviation of a normal
</p>
<p>distribution; the intensity of a poisson distribution; and so on. Notice that this situation is unlike what we have seen to date.
</p>
<p>In Chap. 5, we assumed that we knew parameters, and could then use the model to assign a probability to a set of data items
</p>
<p>D. Here we know the value of D, but don&rsquo;t know the parameters. Our model will be better or worse depending on how well
</p>
<p>we choose the parameters. We need a strategy to estimate the parameters of a model from a sample dataset. Notice how each
</p>
<p>of the following examples fits this pattern. There is an important, and widespread, convention that I shall adhere to. Unknown
</p>
<p>parameters are widely referred to as � (which could be a scalar, or a vector, or, if you&rsquo;re lucky, much more interesting than
</p>
<p>that).
</p>
<p>Example 9.1 (Inferring p from Repeated Flips&mdash;Binomial) Imagine we flip a coin N times, and count the number of
</p>
<p>heads h. An appropriate probability model for a set of independent coin flips is the binomial model Pb.hIN; �/, where
� is the probability a flipped coin comes up heads (which was written p.H/ or p in the binomial model). But we do not
</p>
<p>know p.H/, which is the parameter. I wrote this as � because we do not know it. We need a strategy to extract a value
</p>
<p>of � from the data.
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_9
</p>
<p>197</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_9">https://doi.org/10.1007/978-3-319-64410-3_9</a></div>
</div>
<div class="page"><p/>
<p>198 9 Inferring Probability Models from Data
</p>
<p>Example 9.2 (Inferring p from Repeated Flips&mdash;Geometric) Imagine we flip coin repeatedly until we see a head. The
</p>
<p>number of flips has the geometric distribution with parameter p.H/. In this case, the data is a sequence of T&rsquo;s with
</p>
<p>a final H from the coin flips. There are N flips (or terms) and the last flip is a head. We know that an appropriate
</p>
<p>probability model is the geometric distribution Pg.NI �/. But we do not know p.H/, which is the parameter I wrote
as � .
</p>
<p>Example 9.3 (Inferring the Intensity of Spam&mdash;Poisson) It is reasonable to assume that the number of spam emails
</p>
<p>one gets in an hour has a Poisson distribution. But what is the intensity parameter, written � in the definition, of that
</p>
<p>distribution? We could count the number of spam emails that arrive in each of a set of distinct hours, giving a dataset
</p>
<p>of counts D. We need a strategy to wrestle an estimate of the intensity parameter, which I shall write � because we
</p>
<p>don&rsquo;t know it, from this dataset.
</p>
<p>Example 9.4 (Inferring the Mean and Standard Deviation of Normal Data) Imagine we know for some reason that
</p>
<p>our data is well described by a normal distribution. The missing parameters are now the mean and standard deviation
</p>
<p>of the normal distribution that best represents the data.
</p>
<p>9.1.1 TheMaximum Likelihood Principle
</p>
<p>We have a dataset D, a family of probability models P.Dj�/. We need a &ldquo;reasonable&rdquo; procedure to estimate a value of �
so that the resulting model describes our data well. A natural choice is the value of � that makes the data observed &ldquo;most
</p>
<p>probable&rdquo;. If we knew � , then the probability of observing the data D would be P.Dj�/. We can construct an expression for
P.Dj�/ using our model. Now we know D, and we don&rsquo;t know � , so the value of P.Dj�/ is a function of � . This function is
known as the likelihood.
</p>
<p>Definition 9.1 (Likelihood) The function P.Dj�/, which is a function of � , is known as the likelihood of the data D,
and is often written L.�/ (or L.� ID/ if you want to remember that data is involved).
</p>
<p>The maximum likelihood principle asks for a choice of � such that the probability of observing the data you actually see,
</p>
<p>is maximised. This should strike you as being a reasonable choice.
</p>
<p>Definition 9.2 (Maximum Likelihood Principle) The maximum likelihood principle chooses � such that L.�/ D
P.Dj�/ is maximised, as a function of � .
</p>
<p>For the examples we work with, the data will be independent and identically distributed or IID. This means that each
</p>
<p>data item is an idependently obtained sample from the same probability distribution (see Sect. 4.3.1). In turn, this means that
</p>
<p>the likelihood is a product of terms, one for each data item, which we can write as
</p>
<p>L.�/ D P.Dj�/ D
Y
</p>
<p>i2dataset
</p>
<p>P.xij�/:</p>
<p/>
</div>
<div class="page"><p/>
<p>9.1 Estimating Model Parameters with Maximum Likelihood 199
</p>
<p>There are two, distinct, important concepts we must work with. One is the unknown parameter(s), which we will write � .
</p>
<p>The other is the estimate of the value(s), which we will write O� . This estimate is the best we can do&mdash;it may not be the &ldquo;true&rdquo;
value of the parameter, which we will likely never know.
</p>
<p>Procedure 9.1 (Estimating with Maximum Likelihood) Given a dataset fDg, and a model with unknown param-
eter(s) � , compute an estimate O� of the value of the parameters by constructing the likelihood of the data under the
model
</p>
<p>L.�/ D P.Dj�/
</p>
<p>which in our case will always be
</p>
<p>L.�/ D
Y
</p>
<p>i2dataset
</p>
<p>P.xij�/:
</p>
<p>Now estimate O� as
O� D argmax
</p>
<p>�
L.�/:
</p>
<p>You should see Procedure 9.1 as a straightforward recipe, because that&rsquo;s what it is. It is a highly successful recipe. The
</p>
<p>main difficulty in applying the recipe is actually finding the maximum. The following sections show examples for important
</p>
<p>cases.
</p>
<p>9.1.2 Binomial, Geometric andMultinomial Distributions
</p>
<p>Worked example 9.1 (Inferring p(H) for a Coin from Flips Using a Binomial Model) In N independent coin flips,
</p>
<p>you observe k heads. Use the maximum likelihood principle to infer p.H/.
</p>
<p>Solution The coin has � D p.H/, which is the unknown parameter. We know that an appropriate probability model is
the binomial model Pb.kIN; �/. We have that
</p>
<p>L.�/ D P.Dj�/ D Pb.kIN; �/
</p>
<p>D
�
</p>
<p>N
</p>
<p>k
</p>
<p>�
</p>
<p>� k.1 � �/.N�k/
</p>
<p>which is a function of �&mdash;the unknown probability that a coin comes up heads; k and N are known. We must find the
</p>
<p>value of � that maximizes this expression. Now the maximum occurs when
</p>
<p>@L.�/
</p>
<p>@�
D 0:
</p>
<p>We have
@L.�/
</p>
<p>@�
D
�
</p>
<p>N
</p>
<p>k
</p>
<p>�
</p>
<p>�
</p>
<p>k� k�1.1 � �/.N�k/ � � k.N � k/.1 � �/.n�k�1/
�
</p>
<p>and this is zero when
</p>
<p>k� k�1.1 � �/.N�k/ D � k.N � k/.1 � �/.N�k�1/
</p>
<p>so the maximum occurs when
</p>
<p>k.1 � �/ D �.N � k/:
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>200 9 Inferring Probability Models from Data
</p>
<p>This means the maximum likelihood estimate is
</p>
<p>O� D k
N
:
</p>
<p>Worked example 9.1 produces a result that seems natural to most people, and it&rsquo;s very likely that you would guess this
</p>
<p>form without knowing the maximum likelihood principle. But now we have a procedure we can apply to other problems.
</p>
<p>Notice one quirk of the method that this example exposes. Generally, the method is more reliable with more data. If you flip
</p>
<p>a coin once, and get a T , the procedure will estimate O� D 0, which should strike you as a poor estimate.
</p>
<p>Worked example 9.2 (Inferring p(H) from Coin Flips Using a Geometric Model). You flip a coin N times, stopping
</p>
<p>when you see a head. Use the maximum likelihood principle to infer p.H/ for the coin.
</p>
<p>Solution The coin has � D p.H/, which is the unknown parameter. We know that an appropriate probability model is
the geometric model Pg.NI �/. We have that
</p>
<p>L.�/ D P.Dj�/ D Pg.NI �/ D .1 � �/.N�1/�
</p>
<p>which is a function of �&mdash;the unknown probability that a coin comes up heads; N is known. We must find the value of
</p>
<p>� that maximizes this expression. Now the maximum occurs when
</p>
<p>@L.�/
</p>
<p>@�
D 0 D ..1 � �/.N�1/
</p>
<p>�.N � 1/.1 � �/.N�2/�/
</p>
<p>So the maximum likelihood estimate is
</p>
<p>O� D 1
N
:
</p>
<p>Most people don&rsquo;t guess the estimate of Worked example 9.2, though it usually seems reasonable in retrospect. Obtaining
</p>
<p>the maximum of the likelihood can get interesting, as the following worked example suggests.
</p>
<p>Worked example 9.3 (Inferring Die Probabilities from Multiple Rolls and a Multinomial Distribution). You
</p>
<p>throw a die N times, and see n1 ones, : : : and n6 sixes. Write p1; : : : ; p6 for the probabilities that the die comes up one,
</p>
<p>: : :, six. Use the maximum likelihood principle to estimate p1; : : : ; p6 for a multinomial model.
</p>
<p>Solution The data are N, n1; : : : ; n6. The parameters are � D .p1; : : : ; p6/. P.Dj�/ comes from the multinomial
distribution. In particular,
</p>
<p>L.�/ D P.Dj�/ D nŠ
n1Š : : : n6Š
</p>
<p>p
n1
1 p
</p>
<p>n2
2 : : : p
</p>
<p>n6
6
</p>
<p>which is a function of � D .p1; : : : ; p6/. Now we want to maximize this function by choice of � . Notice that we could
do this by simply making all pi very large&mdash;but this omits a fact, which is that p1 C p2 C p3 C p4 C p5 C p6 D 1. So
we substitute using p6 D 1 � p1 � p2 � p3 � p4 � p5 (there are other, neater, ways of dealing with this issue, but they
take more background knowledge). At the maximum, we must have that for all i,
</p>
<p>@L.�/
</p>
<p>@pi
D 0
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>9.1 Estimating Model Parameters with Maximum Likelihood 201
</p>
<p>which means that, for pi, we must have
</p>
<p>nip
.ni�1/
i .1� p1 � p2 � p3 � p4 � p5/n6 � pnii n6.1� p1 � p2 � p3 � p4 � p5/.n6�1/ D 0
</p>
<p>so that, for each pi, we have
</p>
<p>ni.1 � p1 � p2 � p3 � p4 � p5/ � n6pi D 0
</p>
<p>or
pi
</p>
<p>1 � p1 � p2 � p3 � p4 � p5
D ni
</p>
<p>n6
:
</p>
<p>You can check that this equation is solved by
</p>
<p>O� D 1
.n1 C n2 C n3 C n4 C n5 C n6/
</p>
<p>.n1; n2; n3; n4; n5; n6/
</p>
<p>9.1.3 Poisson and Normal Distributions
</p>
<p>Maximizing the likelihood presents a problem. We usually need to take derivatives of products, which can quickly lead to
</p>
<p>quite unmanageable expressions. There is a straightforward cure. The logarithm is a monotonic function for non-negative
</p>
<p>numbers (i.e. if x &gt; 0, y &gt; 0, x &gt; y, then log.x/ &gt; log.y/). This means that the values of � that maximise the log-likelihood
</p>
<p>are the same as the values that maximise the likelihood. This observation allows us to transform a product into a sum, and
</p>
<p>the derivative of a sum is easy.
</p>
<p>Definition 9.3 (Log-Likelihood of a Dataset Under a Model) The log-likelihood of a dataset under a model is a
</p>
<p>function of the unknown parameters, and you will often see it written as
</p>
<p>logL.�/ D logP.Dj�/
</p>
<p>D
X
</p>
<p>i2dataset
</p>
<p>logP.dij�/:
</p>
<p>Worked example 9.4 (Poisson Distributions). You observe N intervals, each of the same, fixed length (in time,
</p>
<p>or space). You know that, in these intervals, events occur with a Poisson distribution (for example, you might be
</p>
<p>observing Prussian officers being kicked by horses, or telemarketer calls: : :). You know also that the intensity of the
</p>
<p>Poisson distribution is the same for each observation. The number of events you observe in the i&rsquo;th interval is ni. What
</p>
<p>is the intensity of the Poisson distribution?
</p>
<p>Solution Write � for the unknown intensity. The likelihood is
</p>
<p>L.�/ D
Y
</p>
<p>i2intervals
</p>
<p>P.fni eventsg j�/
</p>
<p>D
Y
</p>
<p>i2intervals
</p>
<p>�nie��
</p>
<p>niŠ
:
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>202 9 Inferring Probability Models from Data
</p>
<p>It will be easier to work with logs. The log-likelihood is
</p>
<p>logL.�/ D
X
</p>
<p>i
</p>
<p>.ni log � � � � log niŠ/
</p>
<p>so that we must solve
@ logL.�/
</p>
<p>@�
D
X
</p>
<p>i
</p>
<p>.
ni
</p>
<p>�
� 1/ D 0
</p>
<p>which yields a maximum likelihood estimate of
</p>
<p>O� D
P
</p>
<p>i ni
</p>
<p>N
</p>
<p>Worked example 9.5 Worked example 9.5 (The Intensity of Swearing). A famously sweary politician gives a talk.
</p>
<p>You listen to the talk, and for each of 30 intervals 1 min long, you record the number of swearwords. You record this
</p>
<p>as a histogram (i.e. you count the number of intervals with zero swear words, with one, etc.). For the first 10 intervals,
</p>
<p>you see
</p>
<p>No. of swear words 0 1 2 3 4
</p>
<p>No. of intervals 5 2 2 1 0
</p>
<p>and for the following 20 intervals, you see
</p>
<p>No. of swear words 0 1 2 3 4
</p>
<p>No. of intervals 9 5 3 2 1
</p>
<p>Assume that the politician&rsquo;s use of swearwords is Poisson. What is the intensity using the first 10 intervals? the second
</p>
<p>20 intervals? all the intervals? why are they different?
</p>
<p>Solution Use the expression from Worked example 9.12 to find
</p>
<p>O�10 D
total number of swearwords
</p>
<p>number of intervals
</p>
<p>D 9
10
</p>
<p>O�20 D
total number of swearwords
</p>
<p>number of intervals
</p>
<p>D 21
20
</p>
<p>O�30 D
total number of swearwords
</p>
<p>number of intervals
</p>
<p>D 30
30
</p>
<p>:
</p>
<p>These are different because the maximum likelihood estimate is an estimate&mdash;we can&rsquo;t expect to recover the exact
</p>
<p>value from a dataset. Notice, however, that the estimates are quite close.</p>
<p/>
</div>
<div class="page"><p/>
<p>9.1 Estimating Model Parameters with Maximum Likelihood 203
</p>
<p>Worked example 9.6 (The Mean of a Normal Distribution). Assume we have x1; : : : ; xN , and we wish to model
</p>
<p>these data with a normal distribution. Use the maximum likelihood principle to estimate the mean of that normal
</p>
<p>distribution.
</p>
<p>Solution The likelihood of a set of data values under the normal distribution with unknown mean � and standard
</p>
<p>deviation � is
</p>
<p>L.�/ D P.x1; : : : xN j�; �/
</p>
<p>D P.x1j�; �/P.x2j�; �/ : : :P.xN j�; �/
</p>
<p>D
N
Y
</p>
<p>iD1
</p>
<p>1p
2��
</p>
<p>exp
</p>
<p>�
</p>
<p>� .xi � �/
2
</p>
<p>2�2
</p>
<p>�
</p>
<p>and this expression is a moderate nuisance to work with. The log of the likelihood is
</p>
<p>logL.�/ D
 
</p>
<p>N
X
</p>
<p>iD1
� .xi � �/
</p>
<p>2
</p>
<p>2�2
</p>
<p>!
</p>
<p>C term not depending on �:
</p>
<p>We can find the maximum by differentiating wrt � and setting to zero, which yields
</p>
<p>@ logL.�/
</p>
<p>@�
D
</p>
<p>N
X
</p>
<p>iD1
</p>
<p>2.xi � �/
2�2
</p>
<p>D 0
</p>
<p>D 1
�2
</p>
<p> 
</p>
<p>N
X
</p>
<p>iD1
xi � N�
</p>
<p>!
</p>
<p>so the maximum likelihood estimate is
</p>
<p>O� D
PN
</p>
<p>iD1 xi
N
</p>
<p>which probably isn&rsquo;t all that surprising. Notice we did not have to pay attention to � in this derivation&mdash;we did not
</p>
<p>assume it was known, it just doesn&rsquo;t do anything.
</p>
<p>Remember this: The mean of a dataset is the maximum likelihood estimate of the mean of a normal model fit to that
</p>
<p>dataset.
</p>
<p>Worked example 9.7 (The Standard Deviation of a Normal Distribution). Assume we have x1; : : : ; xN which are
</p>
<p>data that can be modelled with a normal distribution. Use the maximum likelihood principle to estimate the standard
</p>
<p>deviation of that normal distribution.
</p>
<p>Solution Now we have to write out the log of the likelihood in more detail. Write � for the mean of the normal
</p>
<p>distribution and � for the unknown standard deviation of the normal distribution. We get
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>204 9 Inferring Probability Models from Data
</p>
<p>logL.�/ D
 
</p>
<p>N
X
</p>
<p>iD1
� .xi � �/
</p>
<p>2
</p>
<p>2�2
</p>
<p>!
</p>
<p>� N log �
</p>
<p>C Term not depending on �
</p>
<p>We can find the maximum by differentiating wrt � and setting to zero, which yields
</p>
<p>@ logL.�/
</p>
<p>@�
D �2
</p>
<p>�3
</p>
<p>N
X
</p>
<p>iD1
</p>
<p>�.xi � �/2
2
</p>
<p>� N
�
</p>
<p>D 0
</p>
<p>so the maximum likelihood estimate is
</p>
<p>O� D
</p>
<p>s
</p>
<p>PN
iD1.xi � �/2
</p>
<p>N
</p>
<p>which probably isn&rsquo;t all that surprising, either.
</p>
<p>Remember this: The standard deviation of a dataset is the maximum likelihood estimate of the standard deviation of
</p>
<p>a normal model fit to that dataset.
</p>
<p>You should notice that one could maximize the likelihood of a normal distribution with respect to mean and standard
</p>
<p>deviation in one go (i.e. I could have done Worked examples 9.14 and 9.16 in one worked example, instead of two). I did
</p>
<p>this example in two parts because I felt it was more accessible that way; if you object, you&rsquo;re likely to be able to fill in the
</p>
<p>details yourself very easily.
</p>
<p>Remember this: If you have many data items and a probability model, you really should use maximum likelihood to
</p>
<p>estimate the parameters of the model.
</p>
<p>9.1.4 Confidence Intervals for Model Parameters
</p>
<p>Assume we have a dataset D D fxg, and a probability model we believe applies to that dataset. We know how to estimate
appropriate parameter values by maximizing the likelihood function L.�/. But we do not yet have a way to think about
</p>
<p>how accurately the data determines the best choice of parameter value. In particular, we should like to be able to construct
</p>
<p>a confidence interval for a parameter. This interval should capture our certainty in the value of the parameter. If a small
</p>
<p>change in the dataset would cause a large change in the parameter we recovered, then the interval should be large. But if
</p>
<p>quite extensive changes in the dataset will result in about the same recovered value, the interval should be small.
</p>
<p>For maximum likelihood problems, it is hard to apply the reasoning of Sect. 6.2 directly. However, the underlying notion&mdash;
</p>
<p>the confidence interval represents an interval within which the population mean will lie for most samples&mdash;is naturally
</p>
<p>associated with repeated experiments. When the data is explained by a parametric probability model, we can use that model
</p>
<p>to produce other possible datasets. If we compute a maximum likelihood estimate O� of the parameters of the model, we can
draw IID samples from the model. We then look at the estimate from that new dataset; the spread of the estimates yields our
</p>
<p>confidence interval.
</p>
<p>A .1 � 2˛/ confidence interval for a parameter is an interval Œc˛; c.1�˛/&#141;. We construct the interval such that, if we were
to perform a very large number of repetitions of our original experiment then estimate a parameter value for each, c˛ would
</p>
<p>be the ˛ quantile and c.1�˛/ would be the .1 � ˛/ quantile of those parameter values. We interpret this to mean that, with
confidence .1�2˛/, the correct value of our parameter lies in this interval. This definition isn&rsquo;t really watertight. How do we</p>
<p/>
</div>
<div class="page"><p/>
<p>9.1 Estimating Model Parameters with Maximum Likelihood 205
</p>
<p>perform a very large number of repetitions? If we don&rsquo;t, how can we tell how good the confidence interval is? Nonetheless,
</p>
<p>we can construct intervals that illustrate how sensitive our original inference is to the data that we have.
</p>
<p>There is a natural, simulation based, algorithm for estimating confidence intervals. The algorithm should feel so natural
</p>
<p>to you that you may already have guessed what to do. First, we compute the maximum likelihood estimate of the parameters,
O� . We assume this estimate is right, but need to see how our estimates of O� would vary with different collections of data
from our model with that parameter value. So we compute a collection of simulated datasets, Di, each the same size as the
</p>
<p>original dataset. We obtain these by simulating P.Dj O�/. Next, we compute a maximum likelihood estimate for each of these
simulated datasets, O�i. Finally, we compute the relevant percentiles of these datasets. The result is our interval.
</p>
<p>Procedure 9.2 (Estimating Confidence Intervals for Maximum Likelihood Estimates Using Simulation) Assume
</p>
<p>we have a dataset D D fxg of N items. We have a parametric model of this data p.xj�/, and write the likelihood
L.� ID/ D P.Dj�/. We construct .1 � 2˛/ confidence intervals using the following steps.
</p>
<p>1. Compute the maximum likelihood estimate of the parameter, O� D argmax
�
</p>
<p>L.� ID/.
</p>
<p>2. Construct R simulated datasets Di, each consisting of N IID samples drawn from p.xj O�/.
3. For each such dataset, compute O�i D argmax� L.� ID/.
</p>
<p>4. Obtain c˛. O�i/, the ˛&rsquo;th quantile of the collection O�i and c.1�˛/. O�i/, the 1 � ˛&rsquo;th quantile of the collection O�i.
</p>
<p>The confidence interval is Œc˛; c.1�˛/&#141;.
</p>
<p>Figure 9.1 shows an example. In this case, I worked with simulated data from a normal distribution. In each case, the
</p>
<p>normal distribution had mean 0, but there are two different standard deviations (1 and 10). I simulated 10 different datasets
</p>
<p>from each of these distributions, containing 10; 40; 90; : : : ; 810; 1000 data items. For each, I computed the maximum
</p>
<p>likelihood estimate of the mean. This isn&rsquo;t zero, even though the data was drawn from a zero-mean distribution, because
</p>
<p>the dataset is finite. I then estimated the confidence intervals for each using 10,000 simulated datasets of the same size. I
</p>
<p>show 95% confidence intervals for the two cases, plotted against the size of the dataset used for the estimate. Notice that
</p>
<p>these intervals aren&rsquo;t symmetric about zero, because the maximum likelihood estimate isn&rsquo;t zero. They shrink as the dataset
</p>
<p>grows, but slowly. They are bigger when the standard deviation is bigger. It should seem reasonable that you can&rsquo;t expect
</p>
<p>an accurate estimate of the mean of a normal distribution with large standard deviation using only a few data points. If you
</p>
<p>think of a probability model as being like a population (it&rsquo;s a very large dataset, that is hidden, and from which you draw
</p>
<p>samples with replacement), then it should also seem reasonable to you that the intervals shrink as N goes up, because this is
</p>
<p>what the reasoning of Sect. 6.2.2 predicts.
</p>
<p>0 200 400 600 800 1000
&minus;1
</p>
<p>&minus;0.5
</p>
<p>0
</p>
<p>0.5
</p>
<p>1
</p>
<p>Number of data points
</p>
<p>M
ea
</p>
<p>n
 v
</p>
<p>al
u
e
</p>
<p>90% confidence intervals for normal data, sd=1
</p>
<p>0 200 400 600 800 1000
</p>
<p>&minus;5
</p>
<p>0
</p>
<p>5
</p>
<p>Number of data points
</p>
<p>M
ea
</p>
<p>n
 v
</p>
<p>al
u
e
</p>
<p>90% confidence intervals for normal data, sd=10
</p>
<p>Fig. 9.1 Confidence intervals computed for simulated normal data; details in the text</p>
<p/>
</div>
<div class="page"><p/>
<p>206 9 Inferring Probability Models from Data
</p>
<p>Worked example 9.8 (Confidence Intervals by Simulation&mdash;II). Construct a 90% confidence interval for the
</p>
<p>intensity estimate for the data of Example 9.5 for the cases of 10 observations, 20 observations, and all 30 observations.
</p>
<p>Solution Recall from that example the maximum likelihood estimates of the intensity are 7/10, 22/20, and 29/30 in
</p>
<p>the three cases. I used the Matlab function poissrnd to get 10,000 replicates of a dataset of 10 (resp. 20, 30) items
</p>
<p>from a Poisson distribution with the relevant intensities. I then used prctile to get the 5% and 95% percentiles,
</p>
<p>yielding the intervals
</p>
<p>Œ0:3; 1:2&#141; For 10 observations
</p>
<p>Œ0:75; 1:5&#141; For 20 observations
</p>
<p>Œ0:6667; 1:2667&#141; For 30 observations
</p>
<p>Notice how having more observations makes the confidence interval smaller.
</p>
<p>9.1.5 Cautions About Maximum Likelihood
</p>
<p>The maximum likelihood principle has a variety of neat properties we cannot expound. One worth knowing about is
</p>
<p>consistency; for our purposes, this means that the maximum likelihood estimate of parameters can be made arbitrarily
</p>
<p>close to the right answer by having a sufficiently large dataset. Now assume that our data doesn&rsquo;t actually come from the
</p>
<p>underlying model. This is the usual case, because we can&rsquo;t usually be sure that, say, the data truly is normal or truly comes
</p>
<p>from a Poisson distribution. Instead we choose a model that we think will be useful. When the data doesn&rsquo;t come from
</p>
<p>the model, maximum likelihood produces an estimate of � that corresponds to the model that is (in quite a strong sense,
</p>
<p>which we can&rsquo;t explore here) the closest to the source of the data. Maximum likelihood is very widely used because of these
</p>
<p>neat properties. But there are some problems. One important problem is that it might be hard to find the maximum of the
</p>
<p>likelihood exactly. There are strong numerical methods for maximizing functions, and these are very helpful, but even today
</p>
<p>there are likelihood functions where it is very hard to find the maximum.
</p>
<p>The second is that small amounts of data can present nasty problems. For example, in the binomial case, if we have only
</p>
<p>one flip we will estimate p as either 1 or 0. We should find this report unconvincing. In the geometric case, with a fair coin,
</p>
<p>there is a probability 0.5 that we will perform the estimate and then report that the coin has p D 1. This should also worry
you. As another example, if we throw a die only a few times, we could reasonably expect that, for some i, ni D 0. This
doesn&rsquo;t necessarily mean that pi D 0, though that&rsquo;s what the maximum likelihood inference procedure will tell us.
</p>
<p>This creates a very important technical problem&mdash;how can I estimate the probability of events that haven&rsquo;t occurred? This
</p>
<p>might seem like a slightly silly question to you, but it isn&rsquo;t. Solving this problem has really significant practical consequences.
</p>
<p>As one example, consider a biologist trying to count the number of butterfly species on an island. The biologist catches and
</p>
<p>classifies a lot of butterflies, then leaves. But are there more butterfly species on the island? To get some sense that we can
</p>
<p>reason successfully about this problem, compare two cases. In the first, the biologist catches many individuals of each of
</p>
<p>the species observed. In this case, you should suspect that catching more butterflies is unlikely to yield more species. In the
</p>
<p>second case, there are many species where the biologist sees only one individual of that species. In this case, you should
</p>
<p>suspect that catching more butterflies might very well yield new species.
</p>
<p>9.2 Incorporating Priors with Bayesian Inference
</p>
<p>Another important issue with maximum likelihood is that there is no mechanism to incorporate prior beliefs. For example,
</p>
<p>imagine you get a new die from a reliable store, roll it six times and see a one once. You would be happy to believe that
</p>
<p>p.6/ D 1=6 for this die. Now imagine you borrow a die from a friend with a long history of making weighted dice. Your
friend tells you this die is weighted so that p.1/ D 1=2. You roll the die six times and see a one once; in this case, you
might worry that p.1/ isn&rsquo;t 1=6, and you just happened to get a slightly unusual set of rolls. You&rsquo;d worry because you have</p>
<p/>
</div>
<div class="page"><p/>
<p>9.2 Incorporating Priors with Bayesian Inference 207
</p>
<p>good reason to believe the die isn&rsquo;t fair, and you&rsquo;d want more evidence to believe p.6/ D 1=6. Maximum likelihood can&rsquo;t
distinguish between these two cases.
</p>
<p>The difference lies in prior information&mdash;information we possess before we look at the data. We would like to take this
</p>
<p>information into account when we estimate the model. One way to do so is to place a prior probability distribution p.�/ on
</p>
<p>the parameters � . Then, rather than working with the likelihood p.Dj�/, we could apply Bayes&rsquo; rule, and form the posterior
P.� jD/. This posterior represents the probability that � takes various values, given the data D. Bayes&rsquo; rule tells us that
</p>
<p>P.� jD/ D P.Dj�/ � P.�/
P.D/
</p>
<p>D Likelihood � Prior
Normalizing constant
</p>
<p>:
</p>
<p>Be aware that the prior distribution is often written with a � rather than a P or a p.
</p>
<p>Definition 9.4 (Bayesian Inference) Extracting information from the posterior P.� jD/ is usually called Bayesian
inference.
</p>
<p>Having the posterior probability distribution immediately allows us to answer quite sophisticated questions. For example,
</p>
<p>we could immediately compute
</p>
<p>P.f� 2 Œ0:2; 0:4&#141;g jD/
</p>
<p>in a straightforward way. Quite often, we just want to extract an estimate of � . For this, we can use the � that maximizes the
</p>
<p>posterior.
</p>
<p>Definition 9.5 (MAP Estimate) A natural estimate of � is the value that maximizes the posterior P.� jD/. This
estimate is known as a maximum a posteriori estimate or MAP estimate.
</p>
<p>To get this � , we do not need to know the value of the posterior, and it is enough to work with
</p>
<p>P.� jD/ / P.Dj�/P.�/:
</p>
<p>P.� jD/ / P.Dj�/ � P.�/
</p>
<p>/ Likelihood � Prior
</p>
<p>This form exposes similarities and differences between Bayesian and maximum likelihood inference. To reason about the
</p>
<p>posterior, you need to have a prior P.�/. If you assume that this prior has the same value for every � , you&rsquo;ll end up doing
</p>
<p>maximum likelihood, because P.�/ is some constant. Using a prior that isn&rsquo;t constant means that the MAP estimate may be
</p>
<p>different from the maximum likelihood estimate. This difference is occurring because you have prior beliefs that some � are
</p>
<p>more likely to occur than others. Supplying these prior beliefs is part of the modelling process.
</p>
<p>Worked example 9.9 (Flipping a Coin). We have a coin with probability � of coming up heads when flipped. We start
</p>
<p>knowing nothing about � . We then flip the coin 10 times, and see 7 heads (and 3 tails). Plot a function proportional to
</p>
<p>p.� j f7 heads and 3 tailsg/. What happens if there are 3 heads and 7 tails?
</p>
<p>Solution We know nothing about p, except that 0 � � � 1, so we choose a uniform prior on p. We have that
p.f7 heads and 3 tailsg j�/ is binomial. The joint distribution is p.f7 heads and 3 tailsg j�/ � p.�/ but p.�/ is uniform,
so doesn&rsquo;t depend on � . So the posterior is proportional to: �7.1 � �/3 which is graphed in Fig. 9.2. The figure also
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>208 9 Inferring Probability Models from Data
</p>
<p>0 0.2 0.4 0.6 0.8 1
0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>P(H)
</p>
<p>P
o
st
</p>
<p>er
io
</p>
<p>r 
v
al
</p>
<p>u
e
</p>
<p>Posterior of P(H), given 7H and 3T
</p>
<p>0 0.2 0.4 0.6 0.8 1
0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>P(H)
</p>
<p>P
o
st
</p>
<p>er
io
</p>
<p>r 
v
al
</p>
<p>u
e
</p>
<p>Posterior of P(H), given 3H and 7T
</p>
<p>Fig. 9.2 The curves show a function proportional to the posterior on � , for the two cases of Example 9.9. Notice that this information is rather
richer than the single value we would get from maximum likelihood inference
</p>
<p>Fig. 9.3 The probability that an
unknown coin will come up
heads when flipped is p.H/. For
these figures, I simulated coin
flips from a coin with p D 0:75. I
then plotted the posterior for
various data. Notice how, as we
see more flips, we get more
confident about p. The graph gets
higher as it gets narrower because
the posterior probability must
integrate to one
</p>
<p>0 0.2 0.4 0.6 0.8 1
</p>
<p>p(H)
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>p
o
st
</p>
<p>er
io
</p>
<p>r 
o
n
 p
</p>
<p>(H
)
</p>
<p>3H, 0T
7H, 3T
</p>
<p>17H, 13T
</p>
<p>72H, 28T
</p>
<p>shows �3.1� �/7 which is proportional to the posterior for 3 heads and 7 tails. In each case, the evidence does not rule
out the possibility that � D 0:5, but tends to discourage the conclusion. Maximum likelihood would give � D 0:7 or
� D 0:3, respectively.
</p>
<p>Figure 9.2 shows curves proportional to the posterior. The functions are not the true posterior, because they do not
</p>
<p>integrate to one. The fact that we are missing this constant of proportionality means that, for example, we cannot compute
</p>
<p>P.f� 2 Œ0:3; 0:6&#141;g jD/. The constant of proportionality can be computed by noticing that
</p>
<p>P.D/ D
Z
</p>
<p>�
</p>
<p>P.Dj�/P.�/d�:
</p>
<p>It is usually impossible to do this integral in closed form, so we would have to use a numerical integral or a trick. For the
</p>
<p>case of Fig. 9.2, it is fairly easy to estimate the constant of proportionality (using either numerical integration or the fact that
</p>
<p>they&rsquo;re proportional to a binomial distribution). Figure 9.3 shows a set of true posteriors for different sets of evidence, using
</p>
<p>a uniform prior. The integral becomes much harder for more elaborate problems.</p>
<p/>
<div class="annotation"><a href="9.9">9.9</a></div>
</div>
<div class="page"><p/>
<p>9.2 Incorporating Priors with Bayesian Inference 209
</p>
<p>9.2.1 Conjugacy
</p>
<p>Here is one really useful trick for computing the normalizing constant. In some cases, P.�/ and P.Dj�/, when multiplied
together, take a familiar form. This happens when P.Dj�/ and P.�/ each belong to parametric families where there is a
special relationship between the families. The property is known as conjugacy, and when a prior has this property, it is
</p>
<p>called a conjugate prior. The property is best captured in examples; the two in this section are occasionally worth knowing,
</p>
<p>but the most important example is in a section on its own (section Worked example 14.13).
</p>
<p>Worked example 9.10 (Flipping a Coin&mdash;II). We have a coin with probability � of coming up heads when flipped.
</p>
<p>We model the prior on � with a Beta distribution, with parameters ˛ &gt; 0, ˇ &gt; 0. We then flip the coin N times, and
</p>
<p>see h heads. What is P.� jN; h; ˛; ˇ/?
</p>
<p>Solution We have that P.N; hj�/ is binomial, and that P.� jN; h; ˛; ˇ/ / P.N; hj�/P.� j˛; ˇ/. This means that
</p>
<p>P.� jN; h; ˛; ˇ/ /
�
</p>
<p>N
</p>
<p>h
</p>
<p>�
</p>
<p>�h.1 � �/.N�h/
</p>
<p>&#128;.˛ C ˇ/
&#128;.˛/&#128;.ˇ/
</p>
<p>� .˛�1/.1 � �/.ˇ�1/:
</p>
<p>and we can write
</p>
<p>P.� jN; h; ˛; ˇ/ / � .˛Ch�1/.1 � �/.ˇCN�h�1/:
</p>
<p>Notice this has the form of a Beta distribution, so it is easy to recover the constant of proportionality. We have
</p>
<p>P.� jN; h; ˛; ˇ/ D &#128;.˛ C ˇ C N/
&#128;.˛ C h/&#128;.ˇ C N � h/�
</p>
<p>.˛Ch�1/.1 � �/.ˇCN�h�1/:
</p>
<p>The normalizing constant for P.� jN; h; ˛; ˇ/ was easy to recover because the Beta distribution is a conjugate prior for
the binomial distribution.
</p>
<p>Remember this: The Beta distribution is a conjugate prior for the binomial distribution
</p>
<p>Worked example 9.11 (More Sweary Politicians). Example 9.5 gives some data from a sweary politician. Assume
</p>
<p>we have only the first 10 intervals of observations, and we wish to estimate the intensity using a Poisson model. Write
</p>
<p>� for this parameter. Use a Gamma distribution as a prior, and write out the posterior.
</p>
<p>Solution We have that
</p>
<p>p.Dj�/ D
�
</p>
<p>�0e��
</p>
<p>0Š
</p>
<p>�5 �
�1e��
</p>
<p>1Š
</p>
<p>�2
</p>
<p>�
</p>
<p>�
</p>
<p>�2e��
</p>
<p>2Š
</p>
<p>�2 �
�3e��
</p>
<p>3Š
</p>
<p>�1
</p>
<p>D �
9e�10�
</p>
<p>12
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>210 9 Inferring Probability Models from Data
</p>
<p>and
</p>
<p>p.� j˛; ˇ/ D ˇ
˛
</p>
<p>&#128;.˛/
� .˛�1/e�ˇ�
</p>
<p>This means that
</p>
<p>p.� jD; ˛; ˇ/ / � .˛�1C9/e�.ˇC10/� :
</p>
<p>Notice this has the form of another Gamma distribution, so we can write
</p>
<p>p.� jD; ˛; ˇ/ D .ˇ C 10/
.˛C9/
</p>
<p>&#128;.˛ C 9/ �
.˛�1C9/e�.ˇC10/�
</p>
<p>The normalizing constant for P.� jD; ˛; ˇ/ was easy to recover because the Gamma distribution is a conjugate prior
for the Poisson distribution.
</p>
<p>Remember this: The Gamma distribution is a conjugate prior for the Poisson distribution
</p>
<p>9.2.2 MAP Inference
</p>
<p>Look at Example 9.1, where we estimated the probability a coin would come up heads with maximum likelihood. We could
</p>
<p>not change our estimate just by knowing the coin was fair, but we could come up with a number for � D p.H/ (rather than,
say, a posterior distribution). A natural way to produce a point estimate for � that incorporates prior information is to choose
O� such that
</p>
<p>O� D argmax
�
</p>
<p>P.� jD/ D argmax
�
</p>
<p>P.�;D/
</p>
<p>P.D/
</p>
<p>This is the MAP estimate. If we wish to perform MAP inference, P.D/ doesn&rsquo;t matter (it changes the value, but not the
</p>
<p>location, of the maximum). This means we can work with P.�;D/, often called the joint distribution.
</p>
<p>Worked example 9.12 (Flipping a Coin&mdash;II). We have a coin with probability � of coming up heads when flipped.
</p>
<p>We model the prior on � with a Beta distribution, with parameters ˛ &gt; 0, ˇ &gt; 0. We then flip the coin N times, and
</p>
<p>see h heads. What is the MAP estimate of �?
</p>
<p>Solution We have that
</p>
<p>P.� jN; h; ˛; ˇ/ D &#128;.˛ C ˇ C N/
&#128;.˛ C h/&#128;.ˇ C N � h/�
</p>
<p>.˛Ch�1/.1 � �/.ˇCN�h�1/:
</p>
<p>You can get the MAP estimate by differentiating and setting to 0, yielding
</p>
<p>O� D ˛ � 1C h
˛ C ˇ � 2C N :
</p>
<p>This has rather a nice interpretation. You can see ˛ and ˇ as extra counts of heads (resp. tails) that are added to the
</p>
<p>observed counts. So, for example, if you were fairly sure that the coin should be fair, you might make ˛ and ˇ large
</p>
<p>and equal. When ˛ D 1 and ˇ D 1, we have a uniform prior as in the previous examples.</p>
<p/>
</div>
<div class="page"><p/>
<p>9.3 Bayesian Inference for Normal Distributions 211
</p>
<p>Worked example 9.13 Worked example 9.13 (More Sweary Politicians). We observe our swearing politician for N
</p>
<p>intervals, seeing ni swear words in the i&rsquo;th interval. We model the swearing with a Poisson model. We wish to estimate
</p>
<p>the intensity, which we write � . We use a Gamma distribution for the prior on � . What is the MAP estimate of �?
</p>
<p>Solution Write T D
PN
</p>
<p>iD1. We have that
</p>
<p>p.� jD/ D .ˇ C N/
.˛CT/
</p>
<p>&#128;.˛ C T/ �
.˛�1CT/e�.ˇCT/�
</p>
<p>and the MAP estimate is
</p>
<p>O� D .˛ � 1C T/
.ˇ C N/
</p>
<p>(which you can get by differentiating with respect to � , then setting to zero). Notice that if ˇ is close to zero, you can
</p>
<p>interpret ˛ as extra counts; if ˇ is large, then it strongly discourages large values of O� , even if the counts are large.
</p>
<p>Useful Facts 9.1 (Bayesian Inference is Particularly Good with Little Data)
</p>
<p>If you have few data items and a model and a reasonable choice of prior, you really should use Bayesian inference.
</p>
<p>9.2.3 Cautions About Bayesian Inference
</p>
<p>Just like maximum likelihood inference, bayesian inference is not a recipe that can be applied without thought. It turns out
</p>
<p>that, when there is a lot of data, the prior has little influence on the outcome of the inference, and the MAP solution looks a lot
</p>
<p>like the maximum likelihood solution. So the difference between the two approaches is most interesting when there is little
</p>
<p>data, where the prior matters. The difficulty is that it might be hard to know what to use as a good prior. In the examples, I
</p>
<p>emphasized mathematical convenience, choosing priors that lead to clean posteriors. There is no reason to believe that nature
</p>
<p>uses conjugate priors (even though conjugacy is a neat property). How should one choose a prior for a real problem?
</p>
<p>This isn&rsquo;t an easy point. If there is little data, then the choice could really affect the inference. Sometimes we&rsquo;re lucky, and
</p>
<p>the logic of the problem dictates a choice of prior. Mostly, we have to choose and live with the consequences of the choice.
</p>
<p>Often, doing so is successful in applications.
</p>
<p>The fact we can&rsquo;t necessarily justify a choice of prior seems to be one of life&rsquo;s inconveniences, but it represents a
</p>
<p>significant philosophical problem. It&rsquo;s been at the core of a long series of protracted, often quite intense, arguments about the
</p>
<p>philosophical basis of statistics. I haven&rsquo;t followed these arguments closely enough to summarize them; they seem to have
</p>
<p>largely died down without any particular consensus being reached.
</p>
<p>9.3 Bayesian Inference for Normal Distributions
</p>
<p>Normal distribution models allow a variety of quite special tricks. Some algebra will establish that a normal prior and a
</p>
<p>normal likelihood yield a normal posterior. This turns out to be quite useful, because representing normal distributions
</p>
<p>is easy, and we can write straightforward equations for the mean and standard deviation of the posterior given prior and
</p>
<p>likelihood. You should remember from Sect. 1.3.3 that it is possible to compute the mean and standard deviation of a dataset
</p>
<p>if you see it one element at a time. Remarkably, the rules for can be put into a similar form. This means that bayesian
</p>
<p>inference for some kinds of time signal is quite straightforward.</p>
<p/>
</div>
<div class="page"><p/>
<p>212 9 Inferring Probability Models from Data
</p>
<p>9.3.1 Example: Measuring Depth of a Borehole
</p>
<p>Assume we drop a measuring device down a borehole. A braking system will stop its fall and catch onto the side of the
</p>
<p>hole after it has fallen �� meters. On board is a device to measure its depth. The measuring device measures depth in feet
</p>
<p>(not meters: it&rsquo;s my example, so I can do what I like and I&rsquo;ve seen this sort of foolishness in real life). This device reports
</p>
<p>the correct depth in feet plus a zero mean normal random variable, which we call &ldquo;noise&rdquo;. The device reports depth every
</p>
<p>second, over wireless.
</p>
<p>The first question to ask is what depth do we believe the device is at before we receive any measurement? We designed the
</p>
<p>braking system to stop at �� meters, so we are not completely ignorant about where it is. However, it may not have worked
</p>
<p>absolutely correctly. We choose to model the depth at which it stops as �� meters plus a zero mean normal random variable
</p>
<p>(&ldquo;noise&rdquo;). The noise term could be caused by error in the braking system, etc. We could estimate the standard deviation of the
</p>
<p>noise term (which we write �� ) either by dropping devices down holes, then measuring with tape measures, or by analysis
</p>
<p>of likely errors in our braking system. The depth of the object is the unknown parameter of the model; we write this depth � .
</p>
<p>Now the model says that � is a normal random variable with mean �� and standard deviation �� .
</p>
<p>Now assume we receive a single measurement&mdash;what do we now know about the device&rsquo;s depth? The first thing to notice
</p>
<p>is that there is something to do here. Ignoring the prior and taking the measurement might not be wise. For example, imagine
</p>
<p>that the noise in the wireless system is large, so that the measurement is often corrupted. In this case, our original guess about
</p>
<p>the device&rsquo;s location might be better than the measurement. Similarly, ignoring the measurement and just taking the prior is
</p>
<p>unwise, too. The measurement tells us something about the borehole that isn&rsquo;t represented in the prior, and we should use
</p>
<p>that.
</p>
<p>Another reason to use the measurement is that we will receive another measurement in a second&rsquo;s time. Remember
</p>
<p>that each measurement is the true depth in feet plus zero-mean noise. Averaging multiple measurements will produce an
</p>
<p>estimate of depth that improves as the number of measurements goes up (by the standard error reasoning of Sect. 6.2.2).
</p>
<p>Since measurements will keep arriving, we want an online procedure that gives the best estimate of depth with current
</p>
<p>measurements, and then updates that estimate when a new measurement arrives. It turns out such a procedure is easy to
</p>
<p>construct.
</p>
<p>9.3.2 Normal Prior and Normal Likelihood Yield Normal Posterior
</p>
<p>When both P.Dj�/ and P.�/ are normal with known standard deviation, the posterior is normal, too. The mean and standard
deviation of the posterior take a simple form. Assume P.�/ is normal, with mean �� and standard deviation �� (remember,
</p>
<p>priors are often written with � somewhere). So
</p>
<p>logP.�/ D � .� � ��/
2
</p>
<p>2�2�
</p>
<p>C constant not dependent on �:
</p>
<p>Start by assuming that D is a single measurement x1. The measurement x1 could be in different units from � , and we will
</p>
<p>assume that the relevant scaling constant c1 is known. We assume that P.x1j�/ is normal with known standard deviation
�m;1, and with mean c1� . Equivalently, x1 is obtained by adding noise to c1� . The noise will have zero mean and standard
</p>
<p>deviation �m;1. This means that
</p>
<p>logP.Dj�/ D logP.x1j�/ D �
.x1 � c1�/2
</p>
<p>2�2m;1
</p>
<p>C constant not dependent on x1 or �:
</p>
<p>We would like to know P.� jx/. We have that
</p>
<p>logP.� jx1/ D log p.x1j�/C log p.�/
</p>
<p>C terms not depending on �</p>
<p/>
</div>
<div class="page"><p/>
<p>9.3 Bayesian Inference for Normal Distributions 213
</p>
<p>D � .x1 � c1�/
2
</p>
<p>2�2m;1
� .� � ��/
</p>
<p>2
</p>
<p>2�2�
</p>
<p>C terms not depending on �:
</p>
<p>D �
"
</p>
<p>�2
</p>
<p> 
</p>
<p>c21
</p>
<p>2�2m;1
C 1
</p>
<p>2�2�
</p>
<p>!
</p>
<p>��
 
</p>
<p>c1x1
</p>
<p>2�2m;1
C ��
</p>
<p>2�2�
</p>
<p>!#
</p>
<p>C terms not depending on �:
</p>
<p>Now some trickery will get us an expression for P.� jx1/. Notice first that logP.� jx1/ is of degree 2 in � (i.e. it has terms �2,
� and things that don&rsquo;t depend on � ). This means that P.� jx1/ must be a normal distribution, because we can rearrange its
log into the form of the log of a normal distribution.
</p>
<p>Now we can show that P.� jD/ is normal when there are more measurements. Assume we have N measurements,
x1; : : : ; xN . The measurements are IID samples from a normal distribution conditioned on � . We will assume that each
</p>
<p>measurement is in its own set of units (captured by a constant ci), and each measurement incorporates noise of different
</p>
<p>standard deviation (with standard deviation �m;i). So
</p>
<p>logP.xij�/ D �
.xi � ci�/2
</p>
<p>2�2m;i
</p>
<p>C constant not dependent on x1 or �:
</p>
<p>Now
</p>
<p>logP.Dj�/ D
X
</p>
<p>i
</p>
<p>logP.xij�/
</p>
<p>so we can write
</p>
<p>logP.� jD/ D log p.xN j�/C : : :C log p.x2j�/
</p>
<p>C log p.x1j�/C log p.�/
</p>
<p>C terms not depending on �
</p>
<p>D log p.xN j�/C : : :C log p.x2j�/
</p>
<p>C log p.� jx1/C terms not
</p>
<p>depending on �
</p>
<p>D log p.xN j�/C : : :C log p.� jx1; x2/
</p>
<p>C terms not depending on �:
</p>
<p>This lays out the induction. We have that P.� jx1/ is normal, with known standard deviation. Now regard this as the prior,
and P.x2j�/ as the likelihood; we have that P.� jx1; x2/ is normal, and so on. So under our assumptions, P.� jD/ is normal.
We now have a really useful fact.
</p>
<p>Remember this: A normal prior and a normal likelihood yield a normal posterior when both standard deviations are
</p>
<p>known
</p>
<p>Some straightforward thrashing through algebra, relegated to the exercises, will yield expressions for the mean and
</p>
<p>standard deviation of the posterior. These are captured in the box below.</p>
<p/>
</div>
<div class="page"><p/>
<p>214 9 Inferring Probability Models from Data
</p>
<p>Useful Facts 9.2 (The Parameters of a Normal Posterior with a Single Measurement)
</p>
<p>Assume we wish to estimate a parameter � . The prior distribution for � is normal, with known mean �� and known
</p>
<p>standard deviation �� . We receive a single data item x1 and a scale c1. The likelihood of x1 is normal with mean c1�
</p>
<p>and standard deviation �m;1, where �m;1 is known. Then the posterior, p.� jx1; c1; �m;1; �� ; ��/, is normal, with mean
</p>
<p>�1 D
c1x1�
</p>
<p>2
� C ���2m;1
</p>
<p>�2m;1 C c21�2�
</p>
<p>and standard deviation
</p>
<p>�1 D
s
</p>
<p>�2m;1�
2
�
</p>
<p>�2m;1 C c2�2�
:
</p>
<p>The equations of box 9.2 &ldquo;make sense&rdquo;. Recall the example of dropping the depth measuring device down a borehole.
</p>
<p>Imagine that the mechanical design for the braking system was very good, but the measuring system is inaccurate. Then �� is
</p>
<p>very small, and �m;1 is very big. In turn, the mean of P.� jx1/ is about �� . Equivalently, because our prior was very accurate,
and the measurement was unreliable, the posterior mean is about the prior mean Similarly, if the measurement is reliable (i.e.
</p>
<p>�m;1 is small) and the prior has high variance (i.e. �� is large), the mean of P.� jx1/ is about x1=c1.&mdash;i.e. the measurement,
rescaled to the same units as �
</p>
<p>Worked example 9.14 (MAP for Normal Prior and Likelihood with Known Standard Deviation). We wish to
</p>
<p>estimate a parameter � . The prior distribution for � is normal, with known mean �� and known standard deviation �� .
</p>
<p>We have a single data item x1. The likelihood P.x1j�/ is normal, with mean c1� and standard deviation �m;1. What is
the MAP estimate of �?
</p>
<p>Solution The equations are in a box, above (page 214). A normal distribution has a maximum at the mean, so
</p>
<p>O� D
c1x1�
</p>
<p>2
� C ���2m;1
</p>
<p>�2m;1 C c21�2�
</p>
<p>9.3.3 Filtering
</p>
<p>Recall the device we dropped down a borehole produced a measurement every second. It does not make sense to wait all
</p>
<p>day, then use the day&rsquo;s measurements to produce a single depth estimate. Instead, we should update our estimate each time
</p>
<p>we get a measurement. The induction sketched in Sect. 9.3.2 gives a procedure to do this.
</p>
<p>In words, our initial representation of the parameters we are trying to estimate is the prior, which is normal. We see one
</p>
<p>measurement, which has normal likelihood, so the posterior is normal. You can think of this posterior as a prior for the
</p>
<p>parameter estimate based on the next measurement. But we know what to do with a normal prior, a normal likelihood, and
</p>
<p>a measurement, so we can incorporate the measurement and go again. This means we can exploit our expression for the
</p>
<p>posterior mean and standard deviation in the case of normal likelihood and normal prior and a single measurement to deal
</p>
<p>with multiple measurements very easily. This process of updating a representation of a dataset as new data arrives is known
</p>
<p>as filtering.
</p>
<p>To restate using mathematical notation, I will use the notation and assumptions of that section (so you have to read it,
</p>
<p>sorry). We assumed that the prior, P.�/, was normal, and the likelihood for the first measurement, P.x1j�/, was normal. This
meant that the posterior after the first measurement, P.� jx1/, was normal too. Now we can treat P.� jx1; : : : ; xi�1/ (which is</p>
<p/>
</div>
<div class="page"><p/>
<p>9.4 You Should 215
</p>
<p>normal) as a prior for the likelihood P.xij�/ (which is also normal). This will produce the posterior P.� jx1; : : : ; xi/, which will
be normal. This can operate as a prior for the likelihood P.xiC1j�/, and so on. In turn, this gives us a pattern for incorporating
measurements one at a time.
</p>
<p>Useful Facts 9.3 (Normal Posteriors Can Be Updated Online)
</p>
<p>Assume we wish to estimate a parameter � . The prior distribution for � is normal, with known mean �� and known
</p>
<p>standard deviation �� . We write xi for the i&rsquo;th data item. The likelihood for each separate data item is normal,
</p>
<p>with mean ci� and standard deviation �m;i. We have already received k data items. The posterior p.� jx1; : : : ; xk; c1;
: : : ; ck; �m;1; : : : ; �m;k; �� ; ��/ is normal, with mean �k and standard deviation �k. We receive a new data item xkC1.
The likelihood of this data item is normal with mean ckC1� and standard deviation �m;.kC1/, where ckC1 and �m;.kC1/
are known. Then the posterior, p.� jx1; : : : ; xkC1; c1; : : : ; ck; ckC1, �m;1; : : : ; �m;.kC1/; �� ; ��/, is normal, with mean
</p>
<p>�kC1 D
ckC1xkC1�2k C �k�2m;.kC1/
</p>
<p>�2
m;.kC1/ C c2kC1�2k
</p>
<p>and
</p>
<p>�2kC1 D
�2
m;.kC1/�
</p>
<p>2
k
</p>
<p>�2
m;.kC1/ C c2kC1�2k
</p>
<p>:
</p>
<p>Again, notice the very useful fact that, if everything is normal, we can update our posterior representation when new data
</p>
<p>arrives using a very simple recursive form.
</p>
<p>Worked example 9.15 (Estimating the Weekly Percent Growth in a Stock Price). Assume the weekly percent
</p>
<p>growth in the price of MSFT is an (unknown) constant. Use the stock price dataset at http://archive.ics.uci.edu/ml/
</p>
<p>datasets/Dow+Jones+Index to estimate this constant at the end of each week. Assume that �m;i D 1:9 and that ci D 1
for each i. Use �� D 0 and �� D 5. Plot the mean and standard deviation of your current posterior at the end of each
week. How do the standard deviations of the posteriors change with more measurements?
</p>
<p>Solution This dataset is part of the UC Irvine Machine Learning archive. It was collected by Michael Brown. It gives
</p>
<p>a variety of numbers for a variety of stocks at the end of each of 25 weeks. The exercise requires a few lines of code to
</p>
<p>implement the recursions of box 9.3, and rather more lines of code to produce a plot. A little algebra will show that the
</p>
<p>k&rsquo;th standard deviation should be proportional to 1=k (quick experiment shows the relevant constant is close to 1:7).
</p>
<p>Figure 9.4 shows the results.
</p>
<p>9.4 You Should
</p>
<p>9.4.1 Remember These Definitions
</p>
<p>Likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
</p>
<p>Maximum likelihood principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
</p>
<p>Log-likelihood of a dataset under a model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
</p>
<p>Bayesian inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
</p>
<p>MAP estimate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index">http://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index">http://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index</a></div>
</div>
<div class="page"><p/>
<p>216 9 Inferring Probability Models from Data
</p>
<p>&minus;
6
</p>
<p>&minus;
4
</p>
<p>&minus;
2
</p>
<p>0
2
</p>
<p>4
6
</p>
<p>Week
</p>
<p>M
S
</p>
<p>F
T
</p>
<p> p
e
</p>
<p>rc
e
</p>
<p>n
t 
</p>
<p>c
h
</p>
<p>a
n
</p>
<p>g
e
</p>
<p>Weekly percent change in stock price for MSFT
</p>
<p>0 5 10 15 20 25 0 5 10 15 20 25
</p>
<p>0
1
</p>
<p>2
3
</p>
<p>4
5
</p>
<p>6
</p>
<p>Week
</p>
<p>S
ta
</p>
<p>n
d
</p>
<p>a
rd
</p>
<p> d
e
</p>
<p>v
ia
</p>
<p>ti
o
</p>
<p>n
</p>
<p>Posterior standard deviations for MSFT
</p>
<p>Fig. 9.4 On the left, a representation of the posterior on the weekly percent change in price of MSFT stock. The open circles are the observed
prices. Distributions are represented by filled circles for the means and bars for the standard deviation (one posterior standard deviation up and
down). The first distribution is the prior; then, slightly after each measurement, there&rsquo;s a representation of the posterior for that and all previous
measurements. On the right, a plot of the posterior standard deviation after the k&rsquo;th measurement (open circles) together with 1:7=.kC0:11/ (filled
diamonds); the 0:11 is to avoid division by zero for the prior. The close agreement suggests that the k&rsquo;th standard deviation should be proportional
to 1=k, which simple algebra will confirm
</p>
<p>9.4.2 Remember These Terms
</p>
<p>independent and identically distributed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
</p>
<p>IID . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
</p>
<p>consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
</p>
<p>prior probability distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
</p>
<p>posterior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
</p>
<p>Bayesian inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
</p>
<p>maximum a posteriori estimate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
</p>
<p>MAP estimate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
</p>
<p>conjugacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
</p>
<p>conjugate prior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
</p>
<p>joint . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
</p>
<p>filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
</p>
<p>9.4.3 Remember These Facts
</p>
<p>Bayesian inference is particularly good with little data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
</p>
<p>The parameters of a normal posterior with a single measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
</p>
<p>Normal posteriors can be updated online . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 217
</p>
<p>9.4.4 Use These Procedures
</p>
<p>Estimating parameters with maximum likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
</p>
<p>Constructing confidence intervals from simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
</p>
<p>9.4.5 Be Able to
</p>
<p>&bull; Write out the likelihood for a set of independent data items produced by models from Chap. 5 (at least Normal, Binomial,
</p>
<p>Multinomial, Poisson, Beta, Gamma, Exponential).
</p>
<p>&bull; Write out the log likelihood for a set of independent data items produced by models from Chap. 5 (at least Normal,
</p>
<p>Binomial, Multinomial, Poisson, Beta, Gamma, Exponential).
</p>
<p>&bull; Find maximum likelihood solutions for parameters of these models from a set of independent data items (in this case,
</p>
<p>ignore Beta and Gamma; finding maximum likelihood estimates for these can be tricky, and isn&rsquo;t important to us).
</p>
<p>&bull; Describe situations where maximum likelihood estimates might not be reliable.
</p>
<p>&bull; Describe the difference between maximum likelihood estimation and Bayesian inference.
</p>
<p>&bull; Write an expression for the posterior or log-posterior of model parameters given a set of independent data items.
</p>
<p>&bull; Compute the MAP estimate for the cases shown in the worked examples.
</p>
<p>&bull; Compute on-line estimates of the maximum likelihood estimate of the mean and standard deviation of a normal model.
</p>
<p>&bull; Compute on-line estimates of the MAP estimate of the mean and standard deviation in the case of a normal prior and a
</p>
<p>normal likelihood.
</p>
<p>Problems
</p>
<p>Maximum LikelihoodMethods
</p>
<p>9.1 Fitting a Normal Distribution: You are given a dataset of N numbers. Write xi for the i&rsquo;th number. You wish to model
</p>
<p>this dataset with a normal distribution.
</p>
<p>(a) Show the maximum likelihood estimate of the mean of this distribution is mean .fxg/.
(b) Show the maximum likelihood estimate of the standard deviation of this distribution is std .x/.
</p>
<p>(c) Now assume that all of these numbers take the same value&mdash;what happens to your estimate of the standard deviation?
</p>
<p>9.2 Fitting an Exponential Distribution: You are given a dataset of N non-negative numbers. Write xi for the i&rsquo;th number.
</p>
<p>You wish to model this dataset with an exponential distribution, with probability density function P.xj�/ D �e��x. Show the
maximum likelihood estimate of � is
</p>
<p>N
P
</p>
<p>i xi
</p>
<p>9.3 Fitting a Poisson Distribution: You count the number of times that the annoying &ldquo;MacSweeper&rdquo; popup window appears
</p>
<p>per hour when you surf the web. You wish to model these counts with a Poisson distribution. On day 1, you surf for 4 h, and
</p>
<p>see counts of 3; 1; 4; 2 (in hours 1 through 4 respectively). On day 2, you surf for 3 h, and observe counts of 2; 1; 2. On day
</p>
<p>3, you surf for 5 h, and observe counts of 3; 2; 2; 1; 4. On day 4, you surf for 6 h, but keep only the count for all 6 h, which is
</p>
<p>13. You wish to model the intensity in counts per hour.
</p>
<p>(a) What is the maximum likelihood estimate of the intensity for each of days 1, 2, and 3 separately?
</p>
<p>(b) What is the maximum likelihood estimate of the intensity for day 4?
</p>
<p>(c) What is the maximum likelihood estimate of the intensity for all days taken together?</p>
<p/>
</div>
<div class="page"><p/>
<p>218 9 Inferring Probability Models from Data
</p>
<p>9.4 Fitting a Geometric Model: You wish to determine the number of zeros on a roulette wheel without looking at the
</p>
<p>wheel. You will do so with a geometric model. Recall that when a ball on a roulette wheel falls into a non-zero slot, odd/even
</p>
<p>bets are paid; when it falls into a zero slot, they are not paid. There are 36 non-zero slots on the wheel.
</p>
<p>(a) Assume you observe a total of r odd/even bets being paid before you see a bet not being paid. What is the maximum
</p>
<p>likelihood estimate of the number of slots on the wheel?
</p>
<p>(b) How reliable is this estimate? Why?
</p>
<p>(c) You decide to watch the wheel k times to make an estimate. In the first experiment, you see r1 odd/even bets being paid
</p>
<p>before you see a bet not being paid; in the second, r2; and in the third, r3. What is the maximum likelihood estimate of
</p>
<p>the number of slots on the wheel?
</p>
<p>9.5 Fitting a Binomial Model: You encounter a deck of Martian playing cards. There are 87 cards in the deck. You cannot
</p>
<p>read Martian, and so the meaning of the cards is mysterious. However, you notice that some cards are blue, and others are
</p>
<p>yellow.
</p>
<p>(a) You shuffle the deck, and draw one card. It is yellow. What is the maximum likelihood estimate of the fraction of blue
</p>
<p>cards in the deck?
</p>
<p>(b) You repeat the previous exercise 10 times, replacing the card you drew each time before shuffling. You see 7 yellow and
</p>
<p>3 blue cards in the deck. What is the maximum likelihood estimate of the fraction of blue cards in the deck?
</p>
<p>9.6 Fitting a Least Squares Model: We observe a set of N data items. The i&rsquo;th data item consists of a vector xi and a
</p>
<p>number yi. We believe that this data is explained by a model where P.yjx; �/ is normal, with mean xT� and (known) standard
deviation � . Here � is a vector of unknown parameters. At first sight, this model may strike you as being a bit strange, though
</p>
<p>we&rsquo;ll do a lot with it later. You can visualize this model by noting that y is generated by (a) forming xT� then (b) adding a
</p>
<p>zero-mean normal random variable with standard deviation � .
</p>
<p>(a) Show that a maximum likelihood estimate O� of the value of � is obtained by solving
X
</p>
<p>i
</p>
<p>.yi � xTi O�/2 D 0:
</p>
<p>(b) Stack the yi into a vector y and the xi into a matrix X according to
</p>
<p>y D
</p>
<p>2
</p>
<p>6
</p>
<p>6
</p>
<p>4
</p>
<p>y1
y2
: : :
</p>
<p>yN
</p>
<p>3
</p>
<p>7
</p>
<p>7
</p>
<p>5
</p>
<p>X D
</p>
<p>2
</p>
<p>6
</p>
<p>6
</p>
<p>4
</p>
<p>xT1
xT2
: : :
</p>
<p>xTN
</p>
<p>3
</p>
<p>7
</p>
<p>7
</p>
<p>5
</p>
<p>:
</p>
<p>Now show that a maximum likelihood estimate O� of the value of � is obtained by solving the equation X TX O� D X Ty.
</p>
<p>9.7 Logistic Regression: We observe a set of N data items. The i&rsquo;th data item consists of a vector xi and a discrete yi, which
</p>
<p>can take the values 0 or 1. We believe that this data is explained by a model where yi is a draw from a Bernoulli distribution.
</p>
<p>The Bernoulli distribution has the property that
</p>
<p>log
P.y D 1jx; �/
P.y D 0jx; �/ D x
</p>
<p>T�:
</p>
<p>This is known as a logistic model. Here � is a vector of unknown parameters.
</p>
<p>(a) Show that
</p>
<p>P.y D 1jx; �/ D exp.x
T�/
</p>
<p>1C exp.xT�/</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 219
</p>
<p>(b) Show that the log-likelihood of a dataset is given by
</p>
<p>X
</p>
<p>i
</p>
<p>�
</p>
<p>yix
T
i � � log
</p>
<p>�
</p>
<p>1C exp.xTi �/
��
</p>
<p>:
</p>
<p>(c) Now show that a maximum likelihood estimate O� of the value of � is obtained by solving the equation
</p>
<p>X
</p>
<p>i
</p>
<p>��
</p>
<p>yi �
exp.xTi �/
</p>
<p>1C exp.xTi �/
</p>
<p>��
</p>
<p>D 0:
</p>
<p>Likelihood Functions
</p>
<p>9.8 You have a dataset of N 1D data items xi. Each data item is a measurement of the length of an object, in centimeters.
</p>
<p>You wish to model these items with a normal distribution, with mean �c and standard deviation �c.
</p>
<p>(a) Show that the likelihood, as a function of �c and �c, is
</p>
<p>Lc.�; �/ D
1p
2��c
</p>
<p>Y
</p>
<p>i
</p>
<p>exp�.xi��c/2=2�2c :
</p>
<p>(b) Now assume that you rescale each length by measuring in meters. Your data set now consists of yi D 100xi. Show that
</p>
<p>Lm.�m; �m/ D
1p
2��m
</p>
<p>Y
</p>
<p>i
</p>
<p>exp�.yi��m/2=2�2m
</p>
<p>D .1=100/Lc.�c; �c/
</p>
<p>(c) Use this to argue that the value of the likelihood is not directly meaningful.
</p>
<p>BayesianMethods
</p>
<p>9.9 Zeros on a Roulette Wheel: We now wish to make a more sophisticated estimate of the number of zeros on a roulette
</p>
<p>wheel without looking at the wheel. We will do so with Bayesian inference. Recall that when a ball on a roulette wheel falls
</p>
<p>into a non-zero slot, odd/even bets are paid; when it falls into a zero slot, they are not paid. There are 36 non-zero slots
</p>
<p>on the wheel. We assume that the number of zeros is one of f0; 1; 2; 3g. We assume that these cases have prior probability
f0:1; 0:2; 0:4; 0:3g.
</p>
<p>(a) Write n for the event that, in a single spin of the wheel, an odd/even bet will not be paid (equivalently, the ball lands in
</p>
<p>one of the zeros). Write z for the number of zeros in the wheel. What is P.njz/ for each of the possible values of z (i.e.
each of f0; 1; 2; 3g)?
</p>
<p>(b) Under what circumstances is P.z D 0jobservations/ NOT 0?
(c) You observe 36 independent spins of the same wheel. A zero comes up in 2 of these spins. What is P.zjobservations/?
</p>
<p>9.10 Which random number generator? You have two random number generators. R1 generates numbers that are
</p>
<p>distributed uniformly and at random in the range �1&ndash;1. R2 generates standard normal random variables. A program chooses
one of these two random number generators uniformly and at random, then using that generator produces three numbers x1,
</p>
<p>x2 and x3.
</p>
<p>(a) Write R1 for the event the program chose R1, etc. When is P.R1jx1; x2; x3/ D 0?
(b) You observe x1 D �0:1, x2 D 0:4 and x3 D �0:9. What is P.R1jx1; x2; x3/?</p>
<p/>
</div>
<div class="page"><p/>
<p>220 9 Inferring Probability Models from Data
</p>
<p>9.11 Which random number generator, again? You have r &gt; 1 random number generators. The i&rsquo;th random number
</p>
<p>generator generates numbers that are distributed normally, with zero mean and standard deviation i. A program chooses
</p>
<p>one of these random number generators uniformly and at random, then using that generator produces N numbers x1; : : : ; xN .
</p>
<p>Write Ri for the event the program chose the i&rsquo;th random number generator, etc. Write an expression for P.Rijx1; : : : ; xN/ D 0
</p>
<p>9.12 Which random number generator, yet again? You have r &gt; 1 random number generators. The i&rsquo;th random number
</p>
<p>generator generates numbers that are distributed normally, with mean i and standard deviation 2. A program chooses one of
</p>
<p>these random number generators uniformly and at random, then using that generator produces N numbers x1; : : : ; xN . Write
</p>
<p>Ri for the event the program chose the i&rsquo;th random number generator, etc. Write an expression for P.Rijx1; : : : ; xN/ D 0
</p>
<p>9.13 A Normal Distribution: You are given a dataset of 3 numbers, �1; 0; 20. You wish to model this dataset with a normal
distribution with unknown mean � and standard deviation 1. You will make an MAP estimate of �. The prior on � is normal,
</p>
<p>with mean 0 and standard deviation 10.
</p>
<p>(a) What is the MAP estimate of �?
</p>
<p>(b) A new datapoint, with value 1, arrives. What is the new MAP estimate of �?
</p>
<p>Bayesian Confidence Intervals
</p>
<p>9.14 In Worked example 7.10, we found no reason to reject the idea that mouse weights are normally distributed, using the
</p>
<p>dataset at http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml.
</p>
<p>(a) Construct a 75% confidence interval for the weight of a mouse that eats chow, using this data. You should get this
</p>
<p>interval using reasoning about standard errors&mdash;this isn&rsquo;t Bayesian.
</p>
<p>(b) Now construct a Bayesian 75% confidence interval for the weight of a mouse that eats chow, using this data. You should
</p>
<p>assume that the prior on the weight of such a mouse is normal, with mean 32 and standard deviation 10. Recall from
</p>
<p>Sect. 9.3.2 that a normal prior and a normal likelihood lead to normal posterior.
</p>
<p>(c) Compare the intervals constructed above with a Bayesian 75% confidence interval for the weight of a mouse that eats
</p>
<p>chow, using this data and assuming the prior on the weight of such a mouse is normal, with mean 32 and standard
</p>
<p>deviation 1. What does this tell you about the importance of the prior?
</p>
<p>Programming Exercises
</p>
<p>Simulation andMaximum Likelihood
</p>
<p>9.15 One interesting way to evaluate maximum likelihood estimation is to use simulations. We will compare maximum
</p>
<p>likelihood estimates to true parameter values for normal distributions. Write a program that draws s sets of k samples from a
</p>
<p>normal distribution with mean zero and standard deviation one. Now compute the maximum likelihood estimate of the mean
</p>
<p>of this distribution from each set of samples. You should see s different values of this estimate, one for each set. How does
</p>
<p>the variance of the estimate change with k?
</p>
<p>9.16 Write a program that draws a sample of a Bernoulli random variable ı with P.ı D 1/ D 0:5. If this sample takes the
value 1, your program should draw a sample from a normal distribution with mean zero and standard deviation 1. Otherwise,
</p>
<p>your program should draw a sample from a normal distribution with mean 1 and standard deviation 1. Write x1 for the
</p>
<p>resulting sample. We will use x1 to infer the value of ı1.
</p>
<p>(a) Show that
</p>
<p>ı D
�
</p>
<p>1 ifx1 &lt; 0:5
</p>
<p>0 otherwise
</p>
<p>is a maximum likelihood estimate of ı1.</p>
<p/>
<div class="annotation"><a href="http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml">http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml</a></div>
</div>
<div class="page"><p/>
<p>Programming Exercises 221
</p>
<p>(b) Now draw 100 sets each of one sample from this program, and infer for each the value of ı1. How often do you get the
</p>
<p>right answer?
</p>
<p>(c) Show that the true error rate is
</p>
<p>2
</p>
<p>Z 1
</p>
<p>0:5
</p>
<p>1p
2�
</p>
<p>exp
</p>
<p>�
</p>
<p>.u � 1/2
2
</p>
<p>�
</p>
<p>du:
</p>
<p>(Hint: I did a devious change of variables to get the leading 2). Compare the number obtained from your simulation with
</p>
<p>an estimate of this integral using the error function.
</p>
<p>9.17 Logistic regression: We observe a set of N data items. The i&rsquo;th data item consists of a vector xi and a discrete yi, which
</p>
<p>can take the values 0 or 1. We believe that this data is explained by a model where yi is a draw from a Bernoulli distribution.
</p>
<p>The Bernoulli distribution has the property that
</p>
<p>log
P.y D 1jx; �/
P.y D 0jx; �/ D x
</p>
<p>T�:
</p>
<p>This is known as a logistic model. Here � is a vector of unknown parameters. Inferring � is often known as logistic regression.
</p>
<p>We will investigate logistic regression using simulation.
</p>
<p>(a) Write a program that accepts ten dimensional vector � and then (a) generates a sample of 1000 samples xi, each of which
</p>
<p>is an IID sample from a normal distribution with mean zero and covariance matrix the identity matrix; and (b) for each
</p>
<p>xi, forms yi which is a sample from a Bernoulli distribution where
</p>
<p>P.yi D 1jxi; �/ D
exp xTi �
</p>
<p>1C exp xTi �
:
</p>
<p>This is a sample dataset. Call this program the dataset maker.
</p>
<p>(b) Write a program that accepts a sample dataset and estimates O� (the value of � that was used to generate the sample
dataset) using maximum likelihood. This will require that you use some optimization code, or write your own. Call this
</p>
<p>program the inference engine.
</p>
<p>(c) Choose a � (a sample from a normal distribution with mean zero and covariance matrix the identity matrix is one way
</p>
<p>to do this), then create 100 sample datasets. For each, apply the inference engine, and obtain a O� . How does the mean of
these estimates of � compare to the true value? What are the eigenvalues of the covariance of these estimates like?
</p>
<p>(d) Choose a � (a sample from a normal distribution with mean zero and covariance matrix the identity matrix is one way to
</p>
<p>do this), then create 2 sample datasets. For the first, apply the inference engine, and obtain a O� . Now use this O� to predict
the yi values of the second, using the logistic regression model. How do your predictions compare to the true values?
</p>
<p>should the difference be zero? why?
</p>
<p>Simulation Based Confidence Intervals
</p>
<p>9.18 In the mouse dataset at http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml, there are 92 mice that ate a chow diet
</p>
<p>(&ldquo;chow&rdquo; in the relevant column) and where the weight at sacrifice is known (the value of Weight2).
</p>
<p>(a) Draw a sample of 30 chow eating mice uniformly at random, and compute the mean weight of these mice. Now use the
</p>
<p>simulation method of Sect. 9.1.4 to estimate a centered 75% confidence interval for the mean weight of a mouse eating
</p>
<p>a chow diet, estimated from a sample of 30 mice.
</p>
<p>(b) Draw 1000 samples of 30 chow eating mice uniformly at random, and use these samples to estimate a centered 75%
</p>
<p>confidence interval for the mean weight of a mouse eating a chow diet, estimated from a sample of 30 mice. How does
</p>
<p>this estimate compare to the previous estimate?</p>
<p/>
<div class="annotation"><a href="http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml">http://cgd.jax.org/datasets/phenotype/SvensonDO.shtml</a></div>
</div>
<div class="page"><p/>
<p>222 9 Inferring Probability Models from Data
</p>
<p>Bayesian Confidence Intervals
</p>
<p>9.19 Example 9.5 gives data on swearing by a politician (which I&rsquo;ve reproduced below, for your convenience).
</p>
<p>No. of swear words 0 1 2 3 4
</p>
<p>No. of intervals 5 2 2 1 0
</p>
<p>and for the following 20 intervals, you see
</p>
<p>No. of swear words 0 1 2 3 4
</p>
<p>No. of intervals 9 5 3 2 1
</p>
<p>Worked example 9.13 shows how to use a conjugate prior gamma distribution to obtain a gamma posterior. Write a
</p>
<p>program to identify a centered, 90% bayesian confidence interval for the intensity of the politicians swearing for different
</p>
<p>values of the prior parameters. How do different choices of these parameters affect your interval?</p>
<p/>
</div>
<div class="page"><p/>
<p>Part IV
</p>
<p>Tools</p>
<p/>
</div>
<div class="page"><p/>
<p>10Extracting Important Relationships in High Dimensions
</p>
<p>Chapter 2 described methods to explore the relationship between two elements in a dataset. We could extract a pair of
</p>
<p>elements and construct various plots. For vector data, we could also compute the correlation between different pairs of
</p>
<p>elements. But if each data item is d-dimensional, there could be a lot of pairs to deal with, and it is hard to plot d-dimensional
</p>
<p>vectors.
</p>
<p>To really get what is going on we need methods that can represent all relationships in a dataset in one go. These methods
</p>
<p>visualize the dataset as a &ldquo;blob&rdquo; in a d-dimensional space. Many such blobs are flattened in some directions, because
</p>
<p>components of the data are strongly correlated. Finding the directions in which the blobs are flat yields methods to compute
</p>
<p>lower dimensional representations of the dataset. This analysis yields an important practical fact. Most high dimensional
</p>
<p>datasets consist of low dimensional data in a high dimensional space (think of a line in 3D). Such datasets can be represented
</p>
<p>accurately using a small number of directions. Finding these directions will give us considerable insight into the structure of
</p>
<p>high dimensional datasets.
</p>
<p>10.1 Summaries and Simple Plots
</p>
<p>In this chapter, we assume that our data items are vectors. This means that we can add and subtract values and multiply values
</p>
<p>by a scalar without any distress. This is an important assumption, but it doesn&rsquo;t necessarily mean that data is continuous (for
</p>
<p>example, you can meaningfully add the number of children in one family to the number of children in another family). It
</p>
<p>does rule out a lot of discrete data. For example, you can&rsquo;t add &ldquo;sports&rdquo; to &ldquo;grades&rdquo; and expect a sensible answer.
</p>
<p>When we plotted histograms, we saw that mean and variance were a very helpful description of data that had a unimodal
</p>
<p>histogram. If the histogram had more than one mode, one needed to be somewhat careful to interpret the mean and variance;
</p>
<p>in the pizza example, we plotted diameters for different manufacturers to try and see the data as a collection of unimodal
</p>
<p>histograms. In higher dimensions, the analogue of a unimodal histogram is a &ldquo;blob&rdquo;&mdash;a group of data points that clusters
</p>
<p>nicely together and should be understood together.
</p>
<p>You might not believe that &ldquo;blob&rdquo; is a technical term, but it&rsquo;s quite widely used. This is because it is relatively easy to
</p>
<p>understand a single blob of data. There are good summary representations (mean and covariance, which I describe below).
</p>
<p>If a dataset forms multiple blobs, we can usually coerce it into a representation as a collection of blobs (using the methods
</p>
<p>of Chap. 12). But many datasets really are single blobs, and we concentrate on such data here. There are quite useful tricks
</p>
<p>for understanding blobs of low dimension by plotting them, which I describe below. To understand a high dimensional blob,
</p>
<p>we will need to think about the coordinate transformations that places it into a particularly convenient form.
</p>
<p>Notation: Our data items are vectors, and we write a vector as x. The data items are d-dimensional, and there are N of
</p>
<p>them. The entire data set is fxg. When we need to refer to the i&rsquo;th data item, we write xi. We write fxig for a new dataset made
up of N items, where the i&rsquo;th item is xi. If we need to refer to the j&rsquo;th component of a vector xi, we will write x
</p>
<p>.j/
i (notice this
</p>
<p>isn&rsquo;t in bold, because it is a component not a vector, and the j is in parentheses because it isn&rsquo;t a power). Vectors are always
</p>
<p>column vectors.
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_10
</p>
<p>225</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_10">https://doi.org/10.1007/978-3-319-64410-3_10</a></div>
</div>
<div class="page"><p/>
<p>226 10 Extracting Important Relationships in High Dimensions
</p>
<p>10.1.1 TheMean
</p>
<p>For one-dimensional data, we wrote
</p>
<p>mean .fxg/ D
P
</p>
<p>i xi
</p>
<p>N
:
</p>
<p>This expression is meaningful for vectors, too, because we can add vectors and divide by scalars. We write
</p>
<p>mean .fxg/ D
P
</p>
<p>i xi
</p>
<p>N
</p>
<p>and call this the mean of the data. Notice that each component of mean .fxg/ is the mean of that component of the data.
There is not an easy analogue of the median, however (how do you order high dimensional data?) and this is a nuisance.
</p>
<p>Notice that, just as for the one-dimensional mean, we have
</p>
<p>mean .fx � mean .fxg/g/ D 0
</p>
<p>(i.e. if you subtract the mean from a data set, the resulting data set has zero mean).
</p>
<p>10.1.2 Stem Plots and Scatterplot Matrices
</p>
<p>Plotting high dimensional data is tricky. If there are relatively few dimensions, you could just choose two (or three) of them
</p>
<p>and produce a 2D (or 3D) scatterplot. Figure 10.1 shows such a scatterplot, for data that was originally four dimensional.
</p>
<p>This is the famous Iris dataset, collected by Edgar Anderson in 1936, and made popular amongst statisticians by Ronald
</p>
<p>Fisher in that year. I found a copy at the UC Irvine repository of datasets that are important in machine learning. You can
</p>
<p>find the repository at http://archive.ics.uci.edu/ml/index.html.
</p>
<p>Sepal.Length
</p>
<p>P
e
ta
</p>
<p>l.
L
e
n
g
th
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
</p>
<p>6
</p>
<p>7
</p>
<p>5 6 7 8
</p>
<p>setosa versicolor virginica
</p>
<p>Sepal.Length
Petal.Width
</p>
<p>Petal.Length
</p>
<p>setosa versicolor virginica
</p>
<p>Fig. 10.1 Left: a 2D scatterplot for the famous Iris data. I have chosen two variables from the four, and have plotted each species with a different
marker. Right: a 3D scatterplot for the same data. You can see from the plots that the species cluster quite tightly, and are different from one
another. If you compare the two plots, you can see how suppressing a variable leads to a loss of structure. Notice that, on the left, some crosses lie
on top of boxes; you can see that this is an effect of projection by looking at the 3D picture (for each of these data points, the petal widths are quite
different). You should worry that leaving out the last variable might have suppressed something important like this</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/index.html">http://archive.ics.uci.edu/ml/index.html</a></div>
</div>
<div class="page"><p/>
<p>10.1 Summaries and Simple Plots 227
</p>
<p>0
</p>
<p>200
</p>
<p>400
</p>
<p>600
</p>
<p>800
</p>
<p>1000
</p>
<p>1200
</p>
<p>0 2 4 6 8 10 12 14 0 2 4 6 8 10 12 14
0
</p>
<p>200
</p>
<p>400
</p>
<p>600
</p>
<p>800
</p>
<p>1000
</p>
<p>1200
</p>
<p>class 1
</p>
<p>class 2
</p>
<p>class 3
</p>
<p>Fig. 10.2 On the left, a stem plot of the mean of all data items in the wine dataset, from http://archive.ics.uci.edu/ml/datasets/Wine. On the right,
I have overlaid stem plots of each class mean from the wine dataset, from http://archive.ics.uci.edu/ml/datasets/Wine, so that you can see the
differences between class means
</p>
<p>Another simple but useful plotting mechanism is the stem plot. This is can be a useful way to plot a few high dimensional
</p>
<p>data points. One plots each component of the vector as a vertical line, typically with a circle on the end (easier seen than said;
</p>
<p>look at Fig. 10.2). The dataset I used for this is the wine dataset, again from the UC Irvine machine learning data repository
</p>
<p>(you can find this dataset at http://archive.ics.uci.edu/ml/datasets/Wine). For each of three types of wine, the data records the
</p>
<p>values of 13 different attributes. In the figure, I show the overall mean of the dataset, and also the mean of each type of wine
</p>
<p>(also known as the class means, or class conditional means). A natural way to compare class means is to plot them on top of
</p>
<p>one another in a stem plot (Fig. 10.2).
</p>
<p>Another strategy that is very useful when there aren&rsquo;t too many dimensions is to use a scatterplot matrix. To build one,
</p>
<p>you lay out scatterplots for each pair of variables in a matrix. On the diagonal, you name the variable that is the vertical axis
</p>
<p>for each plot in the row, and the horizontal axis in the column. This sounds more complicated than it is; look at the example
</p>
<p>of Fig. 10.3, which shows both a 3D scatter plot and a scatterplot matrix for the same dataset.
</p>
<p>Figure 10.4 shows a scatter plot matrix for four of the variables in the height-weight dataset of http://www2.stetson.edu/~
</p>
<p>jrasp/data.htm (look for bodyfat.xls at that URL). This is originally a 16-dimensional dataset, but a 16 by 16 scatterplot
</p>
<p>matrix is squashed and hard to interpret. For Fig. 10.4, you can see that weight and adiposity appear to show quite strong
</p>
<p>correlations, but weight and age are pretty weakly correlated. Height and age seem to have a low correlation. It is also easy
</p>
<p>to visualize unusual data points. Usually one has an interactive process to do so&mdash;you can move a &ldquo;brush&rdquo; over the plot to
</p>
<p>change the color of data points under the brush.
</p>
<p>10.1.3 Covariance
</p>
<p>Variance, standard deviation and correlation can each be obtained by performing a more general operation on data. We have
</p>
<p>a dataset fxg of N vectors xi, and we are interested in relationships between the j&rsquo;th and the k&rsquo;th components. As with
correlation, we would like to know whether one component tends to be large (resp. small) when the other is large. Remember
</p>
<p>that I write x
.j/
i for the j&rsquo;th component of the i&rsquo;th vector.
</p>
<p>Definition 10.1 (Covariance) We compute the covariance by
</p>
<p>cov .fxg I j; k/ D
P
</p>
<p>i
</p>
<p>�
</p>
<p>x
.j/
i � mean
</p>
<p>�˚
</p>
<p>x.j/
��
</p>
<p>� �
</p>
<p>x
.k/
i � mean
</p>
<p>�˚
</p>
<p>x.k/
��
</p>
<p>�
</p>
<p>N</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Wine">http://archive.ics.uci.edu/ml/datasets/Wine</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Wine">http://archive.ics.uci.edu/ml/datasets/Wine</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Wine">http://archive.ics.uci.edu/ml/datasets/Wine</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
</div>
<div class="page"><p/>
<p>228 10 Extracting Important Relationships in High Dimensions
</p>
<p>Sepal.Length
</p>
<p>Petal.Width
</p>
<p>Pe
ta
</p>
<p>l.
L
e
n
g
th
</p>
<p>setosa versicolor virginica
</p>
<p>Scatter Plot Matrix
</p>
<p>Sepal
</p>
<p>Length
</p>
<p>7
</p>
<p>8
7 8
</p>
<p>5
</p>
<p>6
</p>
<p>5 6
</p>
<p>Sepal
</p>
<p>Width
</p>
<p>3.5
</p>
<p>4.0
</p>
<p>4.5
</p>
<p>3.5 4.0 4.5
</p>
<p>2.0
</p>
<p>2.5
</p>
<p>3.0
</p>
<p>2.0 2.5 3.0
</p>
<p>Petal
</p>
<p>Length
4
</p>
<p>5
</p>
<p>6
</p>
<p>7
4 5 6 7
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>1 2 3 4
</p>
<p>Petal
</p>
<p>Width
</p>
<p>1.5
</p>
<p>2.0
</p>
<p>2.5
1.5 2.0 2.5
</p>
<p>0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>0.0 0.5 1.0
</p>
<p>Fig. 10.3 Left: the 3D scatterplot of the iris data of Fig. 10.1, for comparison. Right: a scatterplot matrix for the Iris data. There are four variables,
measured for each of three species of iris. I have plotted each species with a different marker. You can see from the plot that the species cluster
quite tightly, and are different from one another
</p>
<p>Just like mean, standard deviation and variance, covariance can refer either to a property of a dataset (as in the definition
</p>
<p>here) or a particular expectation (as in Chap. 4). From the expression, it should be clear we have seen examples of covariance
</p>
<p>already. Notice that
</p>
<p>std
�
</p>
<p>x.j/
�2 D var
</p>
<p>�˚
</p>
<p>x.j/
��
</p>
<p>D cov .fxg I j; j/
</p>
<p>which you can prove by substituting the expressions. Recall that variance measures the tendency of a dataset to be different
</p>
<p>from the mean, so the covariance of a dataset with itself is a measure of its tendency not to be constant. More important is
</p>
<p>the relationship between covariance and correlation, in the box below.
</p>
<p>Remember this:
</p>
<p>corr
�˚
</p>
<p>.x.j/; x.k//
��
</p>
<p>D cov .fxg I j; k/p
cov .fxg I j; j/
</p>
<p>p
</p>
<p>cov .fxg I k; k/
</p>
<p>This is occasionally a useful way to think about correlation. It says that the correlation measures the tendency of fxg and
fyg to be larger (resp. smaller) than their means for the same data points, compared to how much they change on their own.
</p>
<p>10.1.4 The Covariance Matrix
</p>
<p>Working with covariance (rather than correlation) allows us to unify some ideas. In particular, for data items which are
</p>
<p>d dimensional vectors, it is straightforward to compute a single matrix that captures all covariances between all pairs of
</p>
<p>components&mdash;this is the covariance matrix.</p>
<p/>
</div>
<div class="page"><p/>
<p>10.1 Summaries and Simple Plots 229
</p>
<p>20 40
20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>100
</p>
<p>0 50
20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>100
</p>
<p>100 200 300 400
20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>100
</p>
<p>Age
</p>
<p>20 40
100
</p>
<p>200
</p>
<p>300
</p>
<p>400
</p>
<p>0 50
100
</p>
<p>200
</p>
<p>300
</p>
<p>400
</p>
<p>Weight
</p>
<p>50 100
100
</p>
<p>200
</p>
<p>300
</p>
<p>400
</p>
<p>20 40
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>Height
</p>
<p>100 200 300 400
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>50 100
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>Adiposity
</p>
<p>0 50
10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>100 200 300 400
10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>50 100
10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>Fig. 10.4 This is a scatterplot matrix for four of the variables in the height weight dataset of http://www2.stetson.edu/~jrasp/data.htm. Each plot
is a scatterplot of a pair of variables. The name of the variable for the horizontal axis is obtained by running your eye down the column; for the
vertical axis, along the row. Although this plot is redundant (half of the plots are just flipped versions of the other half), that redundancy makes it
easier to follow points by eye. You can look at a column, move down to a row, move across to a column, etc. Notice how you can spot correlations
between variables and outliers (the arrows)
</p>
<p>Definition 10.2 (Covariance Matrix) The covariance matrix is:
</p>
<p>Covmat .fxg/ D
P
</p>
<p>i.xi � mean .fxg//.xi � mean .fxg//T
N
</p>
<p>Notice that it is quite usual to write a covariance matrix as &dagger;, and we will follow this convention.
</p>
<p>Covariance matrices are often written as &dagger;, whatever the dataset (you get to figure out precisely which dataset is intended,
</p>
<p>from context). Generally, when we want to refer to the j, k&rsquo;th entry of a matrix A, we will write Ajk, so &dagger;jk is the covariance
</p>
<p>between the j&rsquo;th and k&rsquo;th components of the data.</p>
<p/>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
</div>
<div class="page"><p/>
<p>230 10 Extracting Important Relationships in High Dimensions
</p>
<p>Useful Facts 10.1 (Properties of the Covariance Matrix)
</p>
<p>&bull; The j, k&rsquo;th entry of the covariance matrix is the covariance of the j&rsquo;th and the k&rsquo;th components of x, which we write
</p>
<p>cov .fxg I j; k/.
&bull; The j, j&rsquo;th entry of the covariance matrix is the variance of the j&rsquo;th component of x.
</p>
<p>&bull; The covariance matrix is symmetric.
</p>
<p>&bull; The covariance matrix is always positive semi-definite; it is positive definite, unless there is some vector a such that
</p>
<p>aT.xi � mean .fxig/ D 0 for all i.
</p>
<p>Proposition
</p>
<p>Covmat .fxg/jk D cov .fxg I j; k/
</p>
<p>Proof Recall
</p>
<p>Covmat .fxg/ D
P
</p>
<p>i.xi � mean .fxg//.xi � mean .fxg//T
N
</p>
<p>and the j, k&rsquo;th entry in this matrix will be
</p>
<p>P
</p>
<p>i.x
.j/
i � mean
</p>
<p>�˚
</p>
<p>x.j/
��
</p>
<p>/.x
.k/
i � mean
</p>
<p>�˚
</p>
<p>x.k/
��
</p>
<p>/T
</p>
<p>N
</p>
<p>which is cov .fxg I j; k/.
</p>
<p>Proposition
</p>
<p>Covmat .fxg/jj D &dagger;jj D var
�˚
</p>
<p>x.j/
��
</p>
<p>Proof
</p>
<p>Covmat .fxg/jj D cov .fxg I j; j/
</p>
<p>D var
�˚
</p>
<p>x.j/
��
</p>
<p>Proposition
</p>
<p>Covmat .fxg/ D Covmat .fxg/T
</p>
<p>Proof We have
</p>
<p>Covmat .fxg/jk D cov .fxg I j; k/
</p>
<p>D cov .fxg I k; j/
</p>
<p>D Covmat .fxg/kj</p>
<p/>
</div>
<div class="page"><p/>
<p>10.2 Using Mean and Covariance to Understand High Dimensional Data 231
</p>
<p>Proposition Write &dagger; D Covmat .fxg/. If there is no vector a such that aT.xi � mean .fxg// D 0 for all i, then for
any vector u, such that jjujj &gt; 0,
</p>
<p>uT&dagger;u &gt; 0:
</p>
<p>If there is such a vector a, then
</p>
<p>uT&dagger;u � 0:
</p>
<p>Proof We have
</p>
<p>uT&dagger;u D 1
N
</p>
<p>X
</p>
<p>i
</p>
<p>�
</p>
<p>uT.xi � mean .fxg//
� �
</p>
<p>.xi � mean .fxg//Tu
�
</p>
<p>D 1
N
</p>
<p>X
</p>
<p>i
</p>
<p>�
</p>
<p>uT.xi � mean .fxg//
�2
:
</p>
<p>Now this is a sum of squares. If there is some a such that aT.xi � mean .fxg// D 0 for every i, then the covariance
matrix must be positive semidefinite (because the sum of squares could be zero in this case). Otherwise, it is positive
</p>
<p>definite, because the sum of squares will always be positive.
</p>
<p>10.2 UsingMean and Covariance to Understand High Dimensional Data
</p>
<p>The trick to interpreting high dimensional data is to use the mean and covariance to understand the blob. Figure 10.5 shows
</p>
<p>a two-dimensional data set. Notice that there is obviously some correlation between the x and y coordinates (it&rsquo;s a diagonal
</p>
<p>blob), and that neither x nor y has zero mean. We can easily compute the mean and subtract it from the data points, and this
</p>
<p>translates the blob so that the origin is at the mean (Fig. 10.5). The mean of the new, translated dataset is zero.
</p>
<p>Notice this blob is diagonal. We know what that means from our study of correlation&mdash;the two measurements are
</p>
<p>correlated. Now consider rotating the blob of data about the origin. This doesn&rsquo;t change the distance between any pair
</p>
<p>of points, but it does change the overall appearance of the blob of data. We can choose a rotation that means the blob
</p>
<p>looks (roughly!) like an axis aligned ellipse. In these coordinates there is no correlation between the horizontal and vertical
</p>
<p>components. But one direction has more variance than the other.
</p>
<p>It turns out we can extend this approach to high dimensional blobs. We will translate their mean to the origin, then rotate
</p>
<p>the blob so that there is no correlation between any pair of distinct components (this turns out to be straightforward, which
</p>
<p>may not be obvious to you). Now the blob looks like an axis-aligned ellipsoid, and we can reason about (a) what axes are
</p>
<p>&ldquo;big&rdquo; and (b) what that means about the original dataset.
</p>
<p>10.2.1 Mean and Covariance Under Affine Transformations
</p>
<p>We have a d dimensional dataset fxg. An affine transformation of this data is obtained by choosing some matrix A and vector
b, then forming a new dataset fmg, where mi D Axi C b. Here A doesn&rsquo;t have to be square, or symmetric, or anything else;
it just has to have second dimension d.
</p>
<p>It is easy to compute the mean and covariance of fmg. We have
</p>
<p>mean .fmg/ D mean .fAx C bg/
</p>
<p>D Amean .fxg/C b;
</p>
<p>so you get the new mean by multiplying the original mean by A and adding b.</p>
<p/>
</div>
<div class="page"><p/>
<p>232 10 Extracting Important Relationships in High Dimensions
</p>
<p>Translate center to origin
</p>
<p>Fig. 10.5 On the left, a &ldquo;blob&rdquo; in two dimensions. This is a set of data points that lie somewhat clustered around a single center, given by the
mean. I have plotted the mean of these data points with a hollow square (it&rsquo;s easier to see when there is a lot of data). To translate the blob to the
origin, we just subtract the mean from each datapoint, yielding the blob on the right
</p>
<p>The new covariance matrix is easy to compute as well. We have:
</p>
<p>Covmat .fmg/ D Covmat .fAx C bg/
</p>
<p>D
P
</p>
<p>i.mi � mean .fmg//.mi � mean .fmg//T
N
</p>
<p>D
P
</p>
<p>i.Axi C b �Amean .fxg/ � b/.Axi C b �Amean .fxg/ � b/T
N
</p>
<p>D
A
�
P
</p>
<p>i.xi � mean .fxg//.xi � mean .fxg//T
�
</p>
<p>AT
</p>
<p>N
</p>
<p>D ACovmat .fxg/AT :
</p>
<p>All this means that we can try and choose affine transformations that yield &ldquo;good&rdquo; means and covariance matrices. It is
</p>
<p>natural to choose b so that the mean of the new dataset is zero. An appropriate choice of A can reveal a lot of information
</p>
<p>about the dataset.
</p>
<p>10.2.2 Eigenvectors and Diagonalization
</p>
<p>Recall a matrix M is symmetric if M D MT . A symmetric matrix is necessarily square. Assume S is a d � d symmetric
matrix, u is a d � 1 vector, and � is a scalar. If we have
</p>
<p>Su D �u
</p>
<p>then u is referred to as an eigenvector of S and � is the corresponding eigenvalue. Matrices don&rsquo;t have to be symmetric to
</p>
<p>have eigenvectors and eigenvalues, but the symmetric case is the only one of interest to us.
</p>
<p>In the case of a symmetric matrix, the eigenvalues are real numbers, and there are d distinct eigenvectors that are normal
</p>
<p>to one another, and can be scaled to have unit length. They can be stacked into a matrix U D Œu1; : : : ;ud&#141;. This matrix is
orthonormal, meaning that UTU D I.</p>
<p/>
</div>
<div class="page"><p/>
<p>10.2 Using Mean and Covariance to Understand High Dimensional Data 233
</p>
<p>This means that there is a diagonal matrix ƒ and an orthonormal matrix U such that
</p>
<p>SU D Uƒ:
In fact, there is a large number of such matrices, because we can reorder the eigenvectors in the matrix U , and the equation
</p>
<p>still holds with a new ƒ, obtained by reordering the diagonal elements of the original ƒ. There is no reason to keep track of
</p>
<p>this complexity. Instead, we adopt the convention that the elements of U are always ordered so that the elements of ƒ are
</p>
<p>sorted along the diagonal, with the largest value coming first. This gives us a particularly important procedure.
</p>
<p>Procedure 10.1 (Diagonalizing a Symmetric Matrix) We can convert any symmetric matrix S to a diagonal form
</p>
<p>by computing
</p>
<p>UTSU D ƒ:
</p>
<p>Numerical and statistical programming environments have procedures to compute U and ƒ for you. We assume that
</p>
<p>the elements of U are always ordered so that the elements of ƒ are sorted along the diagonal, with the largest value
</p>
<p>coming first.
</p>
<p>Useful Facts 10.2 (Orthonormal Matrices are Rotations)
</p>
<p>You should think of orthonormal matrices as rotations, because they do not change lengths or angles. For x a vector, R
</p>
<p>an orthonormal matrix, and m D Rx, we have
</p>
<p>uTu D xTRTRx D xTIx D xTx:
</p>
<p>This means that R doesn&rsquo;t change lengths. For y, z both unit vectors, we have that the cosine of the angle between
</p>
<p>them is
</p>
<p>yTx:
</p>
<p>By the argument above, the inner product of Ry and Rx is the same as yTx. This means that R doesn&rsquo;t change angles,
</p>
<p>either.
</p>
<p>10.2.3 Diagonalizing Covariance by Rotating Blobs
</p>
<p>We start with a dataset of N d-dimensional vectors fxg. We can translate this dataset to have zero mean, forming a new
dataset fmg where mi D xi � mean .fxg/. Now recall that, if we were to form a new dataset fag where
</p>
<p>ai D Ami
</p>
<p>the covariance matrix of fag would be
</p>
<p>Covmat .fag/ D ACovmat .fmg/AT
</p>
<p>D ACovmat .fxg/AT :
</p>
<p>Recall also we can diagonalize Covmat .fmg/ D Covmat .fxg/ to get
</p>
<p>UTCovmat .fxg/U D ƒ:</p>
<p/>
</div>
<div class="page"><p/>
<p>234 10 Extracting Important Relationships in High Dimensions
</p>
<p>But this means we could form the dataset frg, using the rule
</p>
<p>ri D UTmi D UT.xi � mean .fxg//:
</p>
<p>The mean of this new dataset is clearly 0. The covariance of this dataset is
</p>
<p>Covmat .frg/ D Covmat
�˚
</p>
<p>UTx
��
</p>
<p>D UTCovmat .fxg/U
</p>
<p>D ƒ;
</p>
<p>where ƒ is a diagonal matrix of eigenvalues of Covmat .fxg/ that we obtained by diagonalization. We now have a very useful
fact about frg: its covariance matrix is diagonal. This means that every pair of distinct components has covariance zero, and
so has correlation zero. Remember that, in describing diagonalization, we adopted the convention that the eigenvectors of
</p>
<p>the matrix being diagonalized were ordered so that the eigenvalues are sorted in descending order along the diagonal of ƒ.
</p>
<p>Our choice of ordering means that the first component of r has the highest variance, the second component has the second
</p>
<p>highest variance, and so on.
</p>
<p>The transformation from fxg to frg is a translation followed by a rotation (remember U is orthonormal, and so a rotation).
So this transformation is a high dimensional version of what I showed in Figs. 10.5 and 10.6.
</p>
<p>Useful Facts 10.3 (You Can Transform Data to Zero Mean and Diagonal Covariance)
</p>
<p>We can translate and rotate any blob of data into a coordinate system where it has (a) zero mean and (b) diagonal
</p>
<p>covariance matrix.
</p>
<p>Rotate to diagonalize 
</p>
<p>covariance
</p>
<p>Fig. 10.6 On the left, the translated blob of Fig. 10.5. This blob lies somewhat diagonally, because the vertical and horizontal components are
correlated. On the right, that blob of data rotated so that there is no correlation between these components. We can now describe the blob by
the vertical and horizontal variances alone, as long as we do so in the new coordinate system. In this coordinate system, the vertical variance is
significantly larger than the horizontal variance&mdash;the blob is short and wide</p>
<p/>
</div>
<div class="page"><p/>
<p>10.2 Using Mean and Covariance to Understand High Dimensional Data 235
</p>
<p>10.2.4 Approximating Blobs
</p>
<p>The mean of frg is zero, and the covariance matrix of frg is diagonal. It is quite usual for high dimensional datasets to have a
small number of large values on the diagonal, and a lot of small values. These values give the variance of the corresponding
</p>
<p>components of frg. Now imagine choosing a component of frg that has a small variance, and replacing that with zero.
Because this component has zero mean (like every other one), and small variance, replacing it with zero will not result in
</p>
<p>much error.
</p>
<p>If we can replace components with zero without causing much error, the blob of data is really a low dimensional blob in a
</p>
<p>high dimensional space. For example, think about a blob lying along, but very close to the x-axis in 3D. Replacing each data
</p>
<p>items y and z values with zero will not change the shape of the blob very much. As a visual example, look at Fig. 10.3; the
</p>
<p>scatterplot matrix strongly suggests that the blob of data is flattened (eg look at the petal width vs petal length plot).
</p>
<p>The data set frg is d-dimensional. We will try to represent it with an s dimensional dataset, and see what error we incur.
Choose some s &lt; d. Now take each data point ri and replace the last d � s components with 0. Call the resulting data item
pi. We should like to know the average error in representing ri with pi.
</p>
<p>This error is
1
</p>
<p>N
</p>
<p>X
</p>
<p>i
</p>
<p>�
</p>
<p>.ri � pi/T .ri � pi/T
�
</p>
<p>:
</p>
<p>Write r
.j/
i for the j
</p>
<p>0 component of ri, and so on. Remember that pi is zero in the last d � s components. The error is then
</p>
<p>1
</p>
<p>N
</p>
<p>X
</p>
<p>i
</p>
<p>2
</p>
<p>4
</p>
<p>jDd
X
</p>
<p>jDsC1
</p>
<p>�
</p>
<p>r
.j/
i
</p>
<p>�2
</p>
<p>3
</p>
<p>5 :
</p>
<p>Because frg has zero mean, we have that 1
N
</p>
<p>P
</p>
<p>i
</p>
<p>�
</p>
<p>r
.j/
i
</p>
<p>�2
</p>
<p>is the variance of the j&rsquo;th component of frg. So the error is
</p>
<p>jDd
X
</p>
<p>jDsC1
var
</p>
<p>�˚
</p>
<p>r.j/
��
</p>
<p>which is the sum of the diagonal elements of the covariance matrix from sC 1; sC 1 to d; d. If this sum is small compared
to the sum of the first s components, then dropping the last d � s components results in a small error. In that case, we could
think about the data as being s dimensional. Figure 10.7 shows the result of using this approach to represent the blob we&rsquo;ve
</p>
<p>used as a running example as a 1D dataset.
</p>
<p>This is an observation of great practical importance. As a matter of experimental fact, a great deal of high dimensional
</p>
<p>data produces relatively low dimensional blobs. We can identify the main directions of variation in these blobs, and use them
</p>
<p>to understand and to represent the dataset.
</p>
<p>10.2.5 Example: Transforming the Height-Weight Blob
</p>
<p>Translating a blob of data doesn&rsquo;t change the scatterplot matrix in any interesting way (the axes change, but the picture
</p>
<p>doesn&rsquo;t). Rotating a blob produces really interesting results, however. Figure 10.8 shows the dataset of Fig. 10.4, translated
</p>
<p>to the origin and rotated to diagonalize it. Now we do not have names for each component of the data (they&rsquo;re linear
</p>
<p>combinations of the original components), but each pair is now not correlated. This blob has some interesting shape features.
</p>
<p>Figure 10.8 shows the gross shape of the blob best. Each panel of this figure has the same scale in each direction. You can
</p>
<p>see the blob extends about 80 units in direction 1, but only about 15 units in direction 2, and much less in the other two
</p>
<p>directions. You should think of this blob as being rather cigar-shaped; it&rsquo;s long in one direction, but there isn&rsquo;t much in the
</p>
<p>others. The cigar metaphor isn&rsquo;t perfect because there aren&rsquo;t any four dimensional cigars, but it&rsquo;s helpful. You can think of
</p>
<p>each panel of this figure as showing views down each of the four axes of the cigar.
</p>
<p>Now look at Fig. 10.9. This shows the same rotation of the same blob of data, but now the scales on the axis have changed
</p>
<p>to get the best look at the detailed shape of the blob. First, you can see that blob is a little curved (look at the projection onto
</p>
<p>direction 2 and direction 4). There might be some effect here worth studying. Second, you can see that some points seem to</p>
<p/>
</div>
<div class="page"><p/>
<p>236 10 Extracting Important Relationships in High Dimensions
</p>
<p>Project to x-axis
</p>
<p>Fig. 10.7 On the left, the translated and rotated blob of Fig. 10.6. This blob is stretched&mdash;one direction has more variance than another. Setting
the y coordinate to zero for each of these datapoints results in a representation that has relatively low error, because there isn&rsquo;t much variance in
these values. This results in the blob on the right. The text shows how the error that results from this projection is computed
</p>
<p>lie away from the main blob. I have plotted each data point with a dot, and the interesting points with a number. These points
</p>
<p>are clearly special in some way.
</p>
<p>The problem with these figures is that the axes are meaningless. The components are weighted combinations of
</p>
<p>components of the original data, so they don&rsquo;t have any units, etc. This is annoying, and often inconvenient. But I obtained
</p>
<p>Fig. 10.8 by translating, rotating and projecting data. It&rsquo;s straightforward to undo the rotation and the translation&mdash;this takes
</p>
<p>the projected blob (which we know to be a good approximation of the rotated and translated blob) back to where the original
</p>
<p>blob was. Rotation and translation don&rsquo;t change distances, so the result is a good approximation of the original blob, but
</p>
<p>now in the original blob&rsquo;s coordinates. Figure 10.10 shows what happens to the data of Fig. 10.4. This is a two dimensional
</p>
<p>version of the original dataset, embedded like a thin pancake of data in a four dimensional space. Crucially, it represents the
</p>
<p>original dataset quite accurately.
</p>
<p>10.3 Principal Components Analysis
</p>
<p>We have seen that a blob of data can be translated so that it has zero mean, then rotated so the covariance matrix is diagonal.
</p>
<p>In this coordinate system, we can set some components to zero, and get a representation of the data that is still accurate.
</p>
<p>The rotation and translation can be undone, yielding a dataset that is in the same coordinates as the original, but lower
</p>
<p>dimensional. The new dataset is a good approximation to the old dataset. All this yields a really powerful idea: we can
</p>
<p>represent the original dataset with a small number of appropriately chosen vectors.
</p>
<p>10.3.1 The LowDimensional Representation
</p>
<p>We start with a dataset of N d-dimensional vectors fxg. We translate this dataset to have zero mean, forming a new dataset
fmg where mi D xi � mean .fxg/. We diagonalize Covmat .fmg/ D Covmat .fxg/ to get
</p>
<p>UTCovmat .fxg/U D ƒ
</p>
<p>and form the dataset frg, using the rule
</p>
<p>ri D UTmi D UT.xi � mean .fxg//:</p>
<p/>
</div>
<div class="page"><p/>
<p>10.3 Principal Components Analysis 237
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>Direction 4
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>Direction 3
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>Direction 2
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>Direction 1
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>&minus;100 0 100
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>Fig. 10.8 A panel plot of the bodyfat dataset of Fig. 10.4, now rotated so that the covariance between all pairs of distinct dimensions is zero. Now
we do not know names for the directions&mdash;they&rsquo;re linear combinations of the original variables. Each scatterplot is on the same set of axes, so you
can see that the dataset extends more in some directions than in others
</p>
<p>We saw the mean of this dataset is zero, and the covariance is diagonal. We then represented the d-dimensional data set frg
with an s dimensional dataset, by choosing some r &lt; d, then taking each data point ri and replacing the last d�s components
with 0. We call the resulting data item pi.
</p>
<p>Now consider undoing the rotation and translation. We would form a new dataset fOxg, with the i&rsquo;th element given by
</p>
<p>Oxi D Upi C mean .fxg/
</p>
<p>(you should check this expression). But this expression says that Oxi is constructed by forming a weighted sum of the first s
columns of U (because all the other components of pi are zero), then adding mean .fxg/. If we write uj for the j&rsquo;th column
of U , we have
</p>
<p>Oxi D
s
X
</p>
<p>jD1
r
.j/
i uj C mean .fxg/:
</p>
<p>What is important about this sum is that s is usually a lot less than d. The uj are known as principal components of the
</p>
<p>dataset. You can easily derive an expression for r
.j/
i from all this (exercises), but for reference, here it is:
</p>
<p>r
.j/
i D uTj .xi � mean .fxg//:</p>
<p/>
</div>
<div class="page"><p/>
<p>238 10 Extracting Important Relationships in High Dimensions
</p>
<p>&minus;100 0 100
&minus;5
</p>
<p>0
</p>
<p>5
</p>
<p>1
</p>
<p>2
3
</p>
<p>4 5
</p>
<p>&minus;50 0 50
&minus;5
</p>
<p>0
</p>
<p>5
</p>
<p>1
</p>
<p>2
3
</p>
<p>45
</p>
<p>&minus;20 0 20
&minus;5
</p>
<p>0
</p>
<p>5
</p>
<p>1
</p>
<p>2
3
</p>
<p>45 Direction 4
</p>
<p>&minus;100 0 100
&minus;20
</p>
<p>&minus;10
</p>
<p>0
</p>
<p>10
</p>
<p>1
</p>
<p>2
</p>
<p>3
4
</p>
<p>5
</p>
<p>&minus;50 0 50
&minus;20
</p>
<p>&minus;10
</p>
<p>0
</p>
<p>10
</p>
<p>1
</p>
<p>2
</p>
<p>3
4
</p>
<p>5
Direction 3
</p>
<p>&minus;5 0 5
&minus;20
</p>
<p>&minus;10
</p>
<p>0
</p>
<p>10
</p>
<p>1
</p>
<p>2
</p>
<p>3
4
</p>
<p>5
</p>
<p>&minus;100 0 100
&minus;50
</p>
<p>0
</p>
<p>50
</p>
<p>1
</p>
<p>23
</p>
<p>4
</p>
<p>5 Direction 2
</p>
<p>&minus;20 0 20
&minus;50
</p>
<p>0
</p>
<p>50
</p>
<p>1
</p>
<p>2 3
</p>
<p>4
</p>
<p>5
</p>
<p>&minus;5 0 5
&minus;50
</p>
<p>0
</p>
<p>50
</p>
<p>1
</p>
<p>23
</p>
<p>4
</p>
<p>5
</p>
<p>Direction 1
</p>
<p>&minus;50 0 50
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>1
</p>
<p>2
</p>
<p>3 4
</p>
<p>5
</p>
<p>&minus;20 0 20
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>1
</p>
<p>2
</p>
<p>34
</p>
<p>5
</p>
<p>&minus;5 0 5
&minus;100
</p>
<p>0
</p>
<p>100
</p>
<p>1
</p>
<p>2
</p>
<p>3 4
</p>
<p>5
</p>
<p>Fig. 10.9 A panel plot of the bodyfat dataset of Fig. 10.4, now rotated so that the covariance between all pairs of distinct dimensions is zero.
Now we do not know names for the directions&mdash;they&rsquo;re linear combinations of the original variables. I have scaled the axes so you can see details;
notice that the blob is a little curved, and there are several data points that seem to lie some way away from the blob, which I have numbered
</p>
<p>Remember this: Data items in a d dimensional data set can usually be represented with good accuracy as a weighted
</p>
<p>sum of a small number s of d dimensional vectors, together with the mean. This means that the dataset lies on an
</p>
<p>s-dimensional subspace of the d-dimensional space. The subspace is spanned by the principal components of the data.
</p>
<p>10.3.2 The Error Caused by Reducing Dimension
</p>
<p>We can easily determine the error in approximating fxg with fOxg. The error in representing frg by fpsg was easy to compute.
We had
</p>
<p>1
</p>
<p>N
</p>
<p>X
</p>
<p>i
</p>
<p>�
</p>
<p>.ri � pi/T .ri � pi/T
�
</p>
<p>D 1
N
</p>
<p>X
</p>
<p>i
</p>
<p>2
</p>
<p>4
</p>
<p>jDd
X
</p>
<p>jDsC1
</p>
<p>�
</p>
<p>r
.j/
i
</p>
<p>�2
</p>
<p>3
</p>
<p>5 :</p>
<p/>
</div>
<div class="page"><p/>
<p>10.3 Principal Components Analysis 239
</p>
<p>20 40
20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>100
</p>
<p>0 50
20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>100
</p>
<p>100 200 300 400
20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>100
</p>
<p>Age
</p>
<p>20 40
100
</p>
<p>200
</p>
<p>300
</p>
<p>400
</p>
<p>0 50
100
</p>
<p>200
</p>
<p>300
</p>
<p>400
</p>
<p>Weight
</p>
<p>50 100
100
</p>
<p>200
</p>
<p>300
</p>
<p>400
</p>
<p>20 40
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>Height
</p>
<p>100 200 300 400
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>50 100
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>Adiposity
</p>
<p>0 50
10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>100 200 300 400
10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>50 100
10
</p>
<p>20
</p>
<p>30
</p>
<p>40
</p>
<p>50
</p>
<p>Fig. 10.10 The data of Fig. 10.4, represented by translating and rotating so that the covariance is diagonal, projecting off the two smallest
directions, then undoing the rotation and translation. This blob of data is two dimensional (because we projected off two dimensions), but is
represented in a four dimensional space. You can think of it as a thin pancake of data in the four dimensional space (you should compare to
Fig. 10.4 on page 229). It is a good representation of the original data. Notice that it looks slightly thickened on edge, because it isn&rsquo;t aligned with
the coordinate system&mdash;think of a view of a plate at a slight slant
</p>
<p>This was the sum of the diagonal elements of the covariance matrix of frg from s; s to d; d. If this sum is small compared to
the sum of the first s components, then dropping the last d � s components results in a small error.
</p>
<p>The error in representing fxg with fOxg is now easy to get. Rotations and translations do not change lengths. This means
that
</p>
<p>jjxi � Oxijj2 D jjri � pr;ijj2 D
d
X
</p>
<p>uDrC1
.r
</p>
<p>.u/
i /
</p>
<p>2
</p>
<p>which is the sum of the diagonal elements of the covariance matrix of frg from s; s to d; d which is easy to evaluate, because
these are the values of the d�s eigenvalues that we decided to ignore. Now we could choose s by identifying how much error
we can tolerate. More usual is to plot the eigenvalues of the covariance matrix, and look for a &ldquo;knee&rdquo;, like that in Fig. 10.11.
</p>
<p>You can see that the sum of remaining eigenvalues is small.</p>
<p/>
</div>
<div class="page"><p/>
<p>240 10 Extracting Important Relationships in High Dimensions
</p>
<p>300 400 500 600 700 800
0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
</p>
<p>0.25
</p>
<p>0.3
Mean spectral reflectance
</p>
<p>Wavelength (nm)
</p>
<p>R
ef
</p>
<p>le
ct
</p>
<p>an
ce
</p>
<p> v
al
</p>
<p>u
e
</p>
<p>0 50 100 150
0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
Sorted eigenvalues, 1995 spectra
</p>
<p>Number of eigenvalue
</p>
<p>V
al
</p>
<p>u
e
</p>
<p>200 400 600 800
&minus;0.2
</p>
<p>&minus;0.15
</p>
<p>&minus;0.1
</p>
<p>&minus;0.05
</p>
<p>0
First PC of spectral reflectance
</p>
<p>Wavelength (nm)
</p>
<p>R
ef
</p>
<p>le
ct
</p>
<p>an
ce
</p>
<p> v
al
</p>
<p>u
e
</p>
<p>300 400 500 600 700 800
&minus;0.2
</p>
<p>&minus;0.1
</p>
<p>0
</p>
<p>0.1
</p>
<p>0.2
Second PC of spectral reflectance
</p>
<p>Wavelength (nm)
</p>
<p>R
ef
</p>
<p>le
ct
</p>
<p>an
ce
</p>
<p> v
al
</p>
<p>u
e
</p>
<p>300 400 500 600 700 800
&minus;0.3
</p>
<p>&minus;0.2
</p>
<p>&minus;0.1
</p>
<p>0
</p>
<p>0.1
Third PC of spectral reflectance
</p>
<p>Wavelength (nm)
</p>
<p>R
ef
</p>
<p>le
ct
</p>
<p>an
ce
</p>
<p> v
al
</p>
<p>u
e
</p>
<p>Fig. 10.11 On the top left, the mean spectral reflectance of a dataset of 1995 spectral reflectances, collected by Kobus Barnard (at http://www.cs.
sfu.ca/~colour/data/). On the top right, eigenvalues of the covariance matrix of spectral reflectance data, from a dataset of 1995 spectral reflectances,
collected by Kobus Barnard (at http://www.cs.sfu.ca/~colour/data/). Notice how the first few eigenvalues are large, but most are very small; this
suggests that a good representation using few principal components is available. The bottom row shows the first three principal components. A
linear combination of these, with appropriate weights, added to the mean, gives a good representation of any item in the dataset
</p>
<p>Procedure 10.2 (Principal Components Analysis) Assume we have a general data set xi, consisting of N d-
</p>
<p>dimensional vectors. Now write &dagger; D Covmat .fxg/ for the covariance matrix.
Form U , ƒ, such that
</p>
<p>&dagger;U D Uƒ
</p>
<p>(these are the eigenvectors and eigenvalues of &dagger;). Ensure that the entries of ƒ are sorted in decreasing order. Choose
</p>
<p>s, the number of dimensions you wish to represent. Typically, we do this by plotting the eigenvalues and looking for a
</p>
<p>&ldquo;knee&rdquo; (Fig. 10.11). It is quite usual to do this by hand.
</p>
<p>Constructing a low-dimensional representation: Write ui for the j&rsquo;th column of U . Represent the data point xi as
</p>
<p>Oxi D mean .fxg/C
s
X
</p>
<p>jD1
</p>
<p>�
</p>
<p>uTj .xi � mean .fxg//
�
</p>
<p>uj</p>
<p/>
<div class="annotation"><a href="http://www.cs.sfu.ca/~colour/data/">http://www.cs.sfu.ca/~colour/data/</a></div>
<div class="annotation"><a href="http://www.cs.sfu.ca/~colour/data/">http://www.cs.sfu.ca/~colour/data/</a></div>
<div class="annotation"><a href="http://www.cs.sfu.ca/~colour/data/">http://www.cs.sfu.ca/~colour/data/</a></div>
</div>
<div class="page"><p/>
<p>10.3 Principal Components Analysis 241
</p>
<p>10.3.3 Example: Representing Colors with Principal Components
</p>
<p>Diffuse surfaces reflect light uniformly in all directions. Examples of diffuse surfaces include matte paint, many styles of
</p>
<p>cloth, many rough materials (bark, cement, stone, etc.). One way to tell a diffuse surface is that it does not look brighter (or
</p>
<p>darker) when you look at it along different directions. Diffuse surfaces can be colored, because the surface reflects different
</p>
<p>fractions of the light falling on it at different wavelengths. This effect can be represented by measuring the spectral reflectance
</p>
<p>of a surface, which is the fraction of light the surface reflects as a function of wavelength. This is usually measured in the
</p>
<p>visual range of wavelengths (about 380 nm to about 770 nm). Typical measurements are every few nm, depending on the
</p>
<p>measurement device. I obtained data for 1995 different surfaces from http://www.cs.sfu.ca/~colour/data/ (there are a variety
</p>
<p>of great datasets here, from Kobus Barnard).
</p>
<p>Each spectrum has 101 measurements, which are spaced 4 nm apart. This represents surface properties to far greater
</p>
<p>precision than is really useful. Physical properties of surfaces suggest that the reflectance can&rsquo;t change too fast from
</p>
<p>wavelength to wavelength. It turns out that very few principal components are sufficient to describe almost any spectral
</p>
<p>reflectance function. Figure 10.11 shows the mean spectral reflectance of this dataset, and Fig. 10.11 shows the eigenvalues
</p>
<p>of the covariance matrix.
</p>
<p>This is tremendously useful in practice. One should think of a spectral reflectance as a function, usually written �.�/.
</p>
<p>What the principal components analysis tells us is that we can represent this function rather accurately on a (really small)
</p>
<p>finite dimensional basis. This basis is shown in Fig. 10.11. This means that there is a mean function r.�/ and k functions
</p>
<p>�m.�/ such that, for any �.�/,
</p>
<p>�.�/ D r.�/C
k
X
</p>
<p>iD1
ci�i.�/C e.�/
</p>
<p>where e.�/ is the error of the representation, which we know is small (because it consists of all the other principal
</p>
<p>components, which have tiny variance). In the case of spectral reflectances, using a value of k around 3&ndash;5 works fine for
</p>
<p>most applications (Fig. 10.12). This is useful, because when we want to predict what a particular object will look like under
</p>
<p>a particular light, we don&rsquo;t need to use a detailed spectral reflectance model; instead, it&rsquo;s enough to know the ci for that
</p>
<p>object. This comes in useful in a variety of rendering applications in computer graphics. It is also the key step in an important
</p>
<p>computer vision problem, called color constancy. In this problem, we see a picture of a world of colored objects under
</p>
<p>unknown colored lights, and must determine what color the objects are. Modern color constancy systems are quite accurate,
</p>
<p>even though the problem sounds underconstrained. This is because they are able to exploit the fact that relatively few ci are
</p>
<p>enough to accurately describe a surface reflectance.
</p>
<p>400 500 600 700
0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>Approx with 0, 3, 5, 7 PCs
</p>
<p>400 500 600 700
&minus;0.2
</p>
<p>&minus;0.1
</p>
<p>0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>0.4
</p>
<p>Error with 0, 3, 5, 7 PCs
</p>
<p>Fig. 10.12 On the left, a spectral reflectance curve (dashed) and approximations using the mean, the mean and 3 principal components, the mean
and 5 principal components, and the mean and 7 principal components. Notice the mean is a relatively poor approximation, but as the number of
principal components goes up, the error falls rather quickly. On the right is the error for these approximations. Figure plotted from a dataset of
1995 spectral reflectances, collected by Kobus Barnard (at http://www.cs.sfu.ca/~colour/data/)</p>
<p/>
<div class="annotation"><a href="http://www.cs.sfu.ca/~colour/data/">http://www.cs.sfu.ca/~colour/data/</a></div>
<div class="annotation"><a href="http://www.cs.sfu.ca/~colour/data/">http://www.cs.sfu.ca/~colour/data/</a></div>
</div>
<div class="page"><p/>
<p>242 10 Extracting Important Relationships in High Dimensions
</p>
<p>0 1000 2000 3000 4000
0
</p>
<p>5
</p>
<p>10
</p>
<p>15
</p>
<p>20
</p>
<p>Eigenvalues, total of 213 images
</p>
<p>Number of eigenvalue
</p>
<p>V
al
</p>
<p>u
e
</p>
<p>0 5 10 15 20
0
</p>
<p>5
</p>
<p>10
</p>
<p>15
</p>
<p>20
</p>
<p>Eigenvalues, total of 213 images
</p>
<p>Number of eigenvalue
</p>
<p>V
al
</p>
<p>u
e
</p>
<p>Fig. 10.13 On the left,the eigenvalues of the covariance of the Japanese facial expression dataset; there are 4096, so it&rsquo;s hard to see the curve
(which is packed to the left). On the right, a zoomed version of the curve, showing how quickly the values of the eigenvalues get small
</p>
<p>10.3.4 Example: Representing Faces with Principal Components
</p>
<p>An image is usually represented as an array of values. We will consider intensity images, so there is a single intensity value
</p>
<p>in each cell. You can turn the image into a vector by rearranging it, for example stacking the columns onto one another.
</p>
<p>This means you can take the principal components of a set of images. Doing so was something of a fashionable pastime in
</p>
<p>computer vision for a while, though there are some reasons that this is not a great representation of pictures. However, the
</p>
<p>representation yields pictures that can give great intuition into a dataset.
</p>
<p>Figure 10.14 shows the mean of a set of face images encoding facial expressions of Japanese women (available at http://
</p>
<p>www.kasrl.org/jaffe.html; there are tons of face datasets at http://www.face-rec.org/databases/). I reduced the images to
</p>
<p>64 � 64, which gives a 4096 dimensional vector. The eigenvalues of the covariance of this dataset are shown in Fig. 10.13;
there are 4096 of them, so it&rsquo;s hard to see a trend, but the zoomed figure suggests that the first couple of dozen contain most
</p>
<p>of the variance. Once we have constructed the principal components, they can be rearranged into images; these images are
</p>
<p>shown in Fig. 10.14. Principal components give quite good approximations to real images (Fig. 10.15).
</p>
<p>The principal components sketch out the main kinds of variation in facial expression. Notice how the mean face in
</p>
<p>Fig. 10.14 looks like a relaxed face, but with fuzzy boundaries. This is because the faces can&rsquo;t be precisely aligned, because
</p>
<p>each face has a slightly different shape. The way to interpret the components is to remember one adjusts the mean towards a
</p>
<p>data point by adding (or subtracting) some scale times the component. So the first few principal components have to do with
</p>
<p>the shape of the haircut; by the fourth, we are dealing with taller/shorter faces; then several components have to do with the
</p>
<p>height of the eyebrows, the shape of the chin, and the position of the mouth; and so on. These are all images of women who
</p>
<p>are not wearing spectacles. In face pictures taken from a wider set of models, moustaches, beards and spectacles all typically
</p>
<p>appear in the first couple of dozen principal components.
</p>
<p>10.4 Multi-Dimensional Scaling
</p>
<p>One way to get insight into a dataset is to plot it. But choosing what to plot for a high dimensional dataset could be difficult.
</p>
<p>Assume we must plot the dataset in two dimensions (by far the most common choice). We wish to build a scatter plot in
</p>
<p>two dimensions&mdash;but where should we plot each data point? One natural requirement is that the points be laid out in two
</p>
<p>dimensions in a way that reflects how they sit in many dimensions. In particular, we would like points that are far apart in
</p>
<p>the high dimensional space to be far apart in the plot, and points that are close in the high dimensional space to be close in
</p>
<p>the plot.</p>
<p/>
<div class="annotation"><a href="http://www.kasrl.org/jaffe.html">http://www.kasrl.org/jaffe.html</a></div>
<div class="annotation"><a href="http://www.kasrl.org/jaffe.html">http://www.kasrl.org/jaffe.html</a></div>
<div class="annotation"><a href="http://www.face-rec.org/databases/">http://www.face-rec.org/databases/</a></div>
</div>
<div class="page"><p/>
<p>10.4 Multi-Dimensional Scaling 243
</p>
<p>Fig. 10.14 The mean and first 16 principal components of the Japanese facial expression dataset
</p>
<p>10.4.1 Choosing LowD Points Using High D Distances
</p>
<p>We will plot the high dimensional point xi at vi, which is a two-dimensional vector. Now the squared distance between points
</p>
<p>i and j in the high dimensional space is
</p>
<p>D
.2/
ij .x/ D .xi � xj/T.xi � xj/
</p>
<p>(where the superscript is to remind you that this is a squared distance). We could build an N �N matrix of squared distances,
which we write D.2/.x/. The i, j&rsquo;th entry in this matrix is D
</p>
<p>.2/
ij .x/, and the x argument means that the distances are between
</p>
<p>points in the high-dimensional space. Now we could choose the vi to make
</p>
<p>X
</p>
<p>ij
</p>
<p>�
</p>
<p>D
.2/
ij .x/ � D
</p>
<p>.2/
ij .v/
</p>
<p>�2
</p>
<p>as small as possible. Doing so should mean that points that are far apart in the high dimensional space are far apart in the
</p>
<p>plot, and that points that are close in the high dimensional space are close in the plot.
</p>
<p>In its current form, the expression is difficult to deal with, but we can refine it. Because translation does not change the
</p>
<p>distances between points, it cannot change either of the D.2/ matrices. So it is enough to solve the case when the mean of the
</p>
<p>points xi is zero. We can assume that
1
</p>
<p>N
</p>
<p>X
</p>
<p>i
</p>
<p>xi D 0:</p>
<p/>
</div>
<div class="page"><p/>
<p>244 10 Extracting Important Relationships in High Dimensions
</p>
<p>Fig. 10.15 Approximating a face image by the mean and some principal components; notice how good the approximation becomes with relatively
few components
</p>
<p>Now write 1 for the n-dimensional vector containing all ones, and I for the identity matrix. Notice that
</p>
<p>D
.2/
ij D .xi � xj/T.xi � xj/ D xi � xi � 2xi � xj C xj � xj:
</p>
<p>Now write
</p>
<p>A D
�
</p>
<p>I � 1
N
</p>
<p>11T
�
</p>
<p>:
</p>
<p>Using this expression, you can show that the matrix M, defined below,
</p>
<p>M.x/ D �1
2
AD.2/.x/AT
</p>
<p>has i, jth entry xi � xj (exercises). I now argue that, to make D.2/.v/ is close to D.2/.x/, it is enough to make M.v/ close to
M.x/. Proving this will take us out of our way unnecessarily, so I omit a proof.
</p>
<p>We need some notation. Take the dataset of N d-dimensional column vectors xi, and form a matrix X by stacking the
</p>
<p>vectors, so
</p>
<p>X D
</p>
<p>2
</p>
<p>6
</p>
<p>6
</p>
<p>4
</p>
<p>xT1
xT2
: : :
</p>
<p>xTN
</p>
<p>3
</p>
<p>7
</p>
<p>7
</p>
<p>5
</p>
<p>:
</p>
<p>In this notation, we have
</p>
<p>M.x/ D XX T :
</p>
<p>Notice M.x/ is symmetric, and it is positive semidefinite. It can&rsquo;t be positive definite, because the data is zero mean, so
</p>
<p>M.x/1 D 0.
We must now choose a set of vi that makes D
</p>
<p>.2/.v/ close to D.2/.x/. We do so by choosing a M.v/ that is close to M.x/.
</p>
<p>But this means we must choose V D Œv1; v2; : : : ; vN &#141;T so that VVT is close to M.x/. We are computing an approximate
factorization of the matrix M.x/.</p>
<p/>
</div>
<div class="page"><p/>
<p>10.4 Multi-Dimensional Scaling 245
</p>
<p>10.4.2 Factoring a Dot-Product Matrix
</p>
<p>We seek a set of k dimensional v that can be stacked into a matrix V . This must produce a M.v/ D VVT that must (a) be as
close as possible to M.x/ and (b) have rank at most k. It can&rsquo;t have rank larger than k because there must be some V which
</p>
<p>is N � k so that M.v/ D VVT . The rows of this V are our vTi .
We can obtain the best factorization of M.x/ from a diagonalization. Write write U for the matrix of eigenvectors of
</p>
<p>M.x/ and ƒ for the diagonal matrix of eigenvalues sorted in descending order, so we have
</p>
<p>M.x/ D UƒUT
</p>
<p>and write ƒ.1=2/ for the matrix of positive square roots of the eigenvalues. Now we have
</p>
<p>M.x/ D Uƒ1=2ƒ1=2UT D
�
</p>
<p>Uƒ1=2
� �
</p>
<p>Uƒ1=2
�T
</p>
<p>which allows us to write
</p>
<p>X D Uƒ1=2:
</p>
<p>Now think about approximating M.x/ by the matrix M.v/. The error is a sum of squares of the entries,
</p>
<p>err.M.x/;A/ D
X
</p>
<p>ij
</p>
<p>.mij � aij/2:
</p>
<p>Because U is a rotation, it is straightforward to show that
</p>
<p>err.UTM.x/U ;UTM.v/U/ D err.M.x/;M.v//:
</p>
<p>But
</p>
<p>UTM.x/U D ƒ
</p>
<p>which means that we could find M.v/ from the best rank k approximation to ƒ. This is obtained by setting all but the k
</p>
<p>largest entries of ƒ to zero. Call the resulting matrix ƒk. Then we have
</p>
<p>M.v/ D UƒkU
</p>
<p>and
</p>
<p>V D Uƒ.1=2/k :
</p>
<p>The first k columns of V are non-zero. We drop the remaining N � k columns of zeros. The rows of the resulting matrix are
our vi, and we can plot these. This method for constructing a plot is known as principal coordinate analysis.
</p>
<p>This plot might not be perfect, because reducing the dimension of the data points should cause some distortions. In
</p>
<p>many cases, the distortions are tolerable. In other cases, we might need to use a more sophisticated scoring system that
</p>
<p>penalizes some kinds of distortion more strongly than others. There are many ways to do this; the general problem is known
</p>
<p>as multidimensional scaling.
</p>
<p>Procedure 10.3 (Principal Coordinate Analysis) Assume we have a matrix D.2/ consisting of the squared differ-
</p>
<p>ences between each pair of N points. We do not need to know the points. We wish to compute a set of points in r
</p>
<p>dimensions, such that the distances between these points are as similar as possible to the distances in D.2/.
</p>
<p>&bull; Form A D
�
</p>
<p>I � 1
N
</p>
<p>11T
�
</p>
<p>.
</p>
<p>&bull; Form W D 1
2
AD.2/AT .
</p>
<p>&bull; Form U , ƒ, such that WU D Uƒ (these are the eigenvectors and eigenvalues of W). Ensure that the entries of ƒ
are sorted in decreasing order.
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>246 10 Extracting Important Relationships in High Dimensions
</p>
<p>&bull; Choose r, the number of dimensions you wish to represent. Form ƒr, the top left r � r block of ƒ. Form ƒ.1=2/r ,
whose entries are the positive square roots of ƒr. Form Ur, the matrix consisting of the first r columns of U .
</p>
<p>Then
</p>
<p>VT D ƒ.1=2/r UTr D Œv1; : : : ; vN &#141;
</p>
<p>is the set of points to plot.
</p>
<p>10.4.3 Example: Mapping withMultidimensional Scaling
</p>
<p>Multidimensional scaling gets positions (the V of Sect. 10.4.1) from distances (the D.2/.x/ of Sect. 10.4.1). This means
</p>
<p>we can use the method to build maps from distances alone. I collected distance information from the web (I used http://
</p>
<p>www.distancefromto.net, but a google search on &ldquo;city distances&rdquo; yields a wide range of possible sources), then applied
</p>
<p>multidimensional scaling. I obtained distances between the South African provincial capitals, in kilometers. I then used
</p>
<p>principal coordinate analysis to find positions for each capital, and rotated, translated and scaled the resulting plot to check
</p>
<p>it against a real map (Fig. 10.16).
</p>
<p>One natural use of principal coordinate analysis is to see if one can spot any structure in a dataset. Does the dataset form
</p>
<p>a blob, or is it clumpy? This isn&rsquo;t a perfect test, but it&rsquo;s a good way to look and see if anything interesting is happening. In
</p>
<p>Fig. 10.17, I show a 3D plot of the spectral data, reduced to three dimensions using principal coordinate analysis. The plot
</p>
<p>is quite interesting. You should notice that the data points are spread out in 3D, but actually seem to lie on a complicated
</p>
<p>curved surface&mdash;they very clearly don&rsquo;t form a uniform blob. To me, the structure looks somewhat like a butterfly. I don&rsquo;t
</p>
<p>know why this occurs (perhaps the universe is doodling), but it certainly suggests that something worth investigating is going
</p>
<p>on. Perhaps the choice of samples that were measured is funny; perhaps the measuring instrument doesn&rsquo;t make certain kinds
</p>
<p>of measurement; or perhaps there are physical processes that prevent the data from spreading out over the space.
</p>
<p>Our algorithm has one really interesting property. In some cases, we do not actually know the datapoints as vectors.
</p>
<p>Instead, we just know distances between the datapoints. This happens often in the social sciences, but there are important
</p>
<p>cases in computer science as well. As a rather contrived example, one could survey people about breakfast foods (say, eggs,
</p>
<p>bacon, cereal, oatmeal, pancakes, toast, muffins, kippers and sausages for a total of 9 items). We ask each person to rate
</p>
<p>the similarity of each pair of distinct items on some scale. We advise people that similar items are ones where, if they were
</p>
<p>offered both, they would have no particular preference; but, for dissimilar items, they would have a strong preference for one
</p>
<p>&minus;800 &minus;600 &minus;400 &minus;200 0 200 400
&minus;1000
</p>
<p>&minus;800
</p>
<p>&minus;600
</p>
<p>&minus;400
</p>
<p>&minus;200
</p>
<p>0
</p>
<p>200
</p>
<p>400
</p>
<p>Cape Town
</p>
<p>Kimberley
</p>
<p>Mahikeng
</p>
<p>Nelspruit
</p>
<p>Polokwane
</p>
<p>Pietermaritzburg
</p>
<p>Johannesburg
</p>
<p>Bloemfontein
</p>
<p>Bhisho
</p>
<p>Fig. 10.16 On the left, a public domain map of South Africa, obtained from http://commons.wikimedia.org/wiki/File:Map_of_South_Africa.svg,
and edited to remove surrounding countries. On the right, the locations of the cities inferred by multidimensional scaling, rotated, translated and
scaled to allow a comparison to the map by eye. The map doesn&rsquo;t have all the provincial capitals on it, but it&rsquo;s easy to see that MDS has placed the
ones that are there in the right places (use a piece of ruled tracing paper to check)</p>
<p/>
<div class="annotation"><a href="http://www.distancefromto.net">http://www.distancefromto.net</a></div>
<div class="annotation"><a href="http://www.distancefromto.net">http://www.distancefromto.net</a></div>
<div class="annotation"><a href="http://commons.wikimedia.org/wiki/File:Map_of_South_Africa.svg">http://commons.wikimedia.org/wiki/File:Map_of_South_Africa.svg</a></div>
</div>
<div class="page"><p/>
<p>10.5 Example: Understanding Height and Weight 247
</p>
<p>&minus;0.4
</p>
<p>&minus;0.2
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
&minus;0.3&minus;0.2&minus;0.100.10.2
</p>
<p>&minus;0.2
</p>
<p>&minus;0.1
</p>
<p>0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>&minus;0.4 &minus;0.2 0 0.2 0.4
</p>
<p>&minus;0.3&minus;0.2&minus;0.100.10.2
</p>
<p>&minus;0.2
</p>
<p>&minus;0.15
</p>
<p>&minus;0.1
</p>
<p>&minus;0.05
</p>
<p>0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
</p>
<p>Fig. 10.17 Two views of the spectral data of Sect. 10.3.3, plotted as a scatter plot by applying principal coordinate analysis to obtain a 3D set
of points. Notice that the data spreads out in 3D, but seems to lie on some structure; it certainly isn&rsquo;t a single blob. This suggests that further
investigation would be fruitful
</p>
<p>&minus;600
&minus;400
</p>
<p>&minus;200
</p>
<p>&minus;100&minus;50
050
</p>
<p>&minus;40
</p>
<p>&minus;20
</p>
<p>0
</p>
<p>20
</p>
<p>40
</p>
<p>&minus;500
&minus;400
</p>
<p>&minus;300
&minus;200
</p>
<p>&minus;100
</p>
<p>0
</p>
<p>100
&minus;50
</p>
<p>0
</p>
<p>50
</p>
<p>Fig. 10.18 Two views of a multidimensional scaling to three dimensions of the height-weight dataset. Notice how the data seems to lie in a flat
structure in 3D, with one outlying data point. This means that the distances between data points can be (largely) explained by a 2D representation
</p>
<p>over the other. The scale might be &ldquo;very similar&rdquo;, &ldquo;quite similar&rdquo;, &ldquo;similar&rdquo;, &ldquo;quite dissimilar&rdquo;, and &ldquo;very dissimilar&rdquo; (scales
</p>
<p>like this are often called Likert scales). We collect these similarities from many people for each pair of distinct items, and
</p>
<p>then average the similarity over all respondents. We compute distances from the similarities in a way that makes very similar
</p>
<p>items close and very dissimilar items distant. Now we have a table of distances between items, and can compute a V and
</p>
<p>produce a scatter plot. This plot is quite revealing, because items that most people think are easily substituted appear close
</p>
<p>together, and items that are hard to substitute are far apart. The neat trick here is that we did not start with a X , but with just
</p>
<p>a set of distances; but we were able to associate a vector with &ldquo;eggs&rdquo;, and produce a meaningful plot.
</p>
<p>10.5 Example: Understanding Height andWeight
</p>
<p>Recall the height-weight data set of Sect. 1.2.4 (from http://www2.stetson.edu/~jrasp/data.htm; look for bodyfat.xls at that
</p>
<p>URL). This is, in fact, a 16-dimensional dataset. The entries are (in this order): bodyfat; density; age; weight; height;
</p>
<p>adiposity; neck; chest; abdomen; hip; thigh; knee; ankle; biceps; forearm; wrist. We know already that many of these entries
</p>
<p>are correlated, but it&rsquo;s hard to grasp a 16 dimensional dataset in one go. The first step is to investigate with a multidimensional
</p>
<p>scaling (Fig. 10.18).</p>
<p/>
<div class="annotation"><a href="http://www2.stetson.edu/~jrasp/data.htm">http://www2.stetson.edu/~jrasp/data.htm</a></div>
</div>
<div class="page"><p/>
<p>248 10 Extracting Important Relationships in High Dimensions
</p>
<p>Fig. 10.19 A multidimensional
scaling to two dimensions of the
height-weight dataset. One data
point is clearly special, and
another looks pretty special. The
data seems to form a blob, with
one axis quite a lot more
important than another
</p>
<p>&minus;500 &minus;400 &minus;300 &minus;200
&minus;100
</p>
<p>&minus;50
</p>
<p>0
</p>
<p>50
</p>
<p>Height&minus;Weight 2D MDS
</p>
<p>Fig. 10.20 The mean of the
bodyfat.xls dataset. Each
component is likely in a different
unit (though I don&rsquo;t know the
units), making it difficult to plot
the data without being
misleading. I&rsquo;ve adopted one
solution here, by plotting a stem
plot. You shouldn&rsquo;t try to
compare the values to one
another. Instead, think of this plot
as a compact version of a table
</p>
<p>2 4 6 8 10 12 14 16 18
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>100
</p>
<p>120
</p>
<p>140
</p>
<p>160
</p>
<p>180
</p>
<p>bodyfat
</p>
<p>density
</p>
<p>age
</p>
<p>weight
</p>
<p>height
</p>
<p>adiposity
</p>
<p>neck
</p>
<p>chest
abdomen
</p>
<p>hip
</p>
<p>thigh
</p>
<p>knee
</p>
<p>ankle
biceps
</p>
<p>forearm
</p>
<p>wrist
</p>
<p>Height&minus;Weight mean
</p>
<p>Section 1.2.4 shows a multidimensional scaling of this dataset down to three dimensions. The dataset seems to lie on
</p>
<p>a (fairly) flat structure in 3D, meaning that inter-point distances are relatively well explained by a 2D representation. Two
</p>
<p>points seem to be special, and lie far away from the flat structure. The structure isn&rsquo;t perfectly flat, so there will be small
</p>
<p>errors in a 2D representation; but it&rsquo;s clear that a lot of dimensions are redundant. Figure 10.19 shows a 2D representation
</p>
<p>of these points. They form a blob that is stretched along one axis, and there is no sign of multiple blobs. There&rsquo;s still at least
</p>
<p>one special point, which we shall ignore but might be worth investigating further. The distortions involved in squashing this
</p>
<p>dataset down to 2D seem to have made the second special point less obvious than it was in Sect. 1.2.4.
</p>
<p>The next step is to try a principal component analysis. Figure 10.20 shows the mean of the dataset. The components of
</p>
<p>the dataset have different units, and shouldn&rsquo;t really be compared. But it is difficult to interpret a table of 16 numbers, so
</p>
<p>I have plotted the mean as a stem plot. Figure 10.21 shows the eigenvalues of the covariance for this dataset. Notice how
</p>
<p>one dimension is very important, and after the third principal component, the contributions become small. Of course, I could
</p>
<p>have said &ldquo;fourth&rdquo;, or &ldquo;fifth&rdquo;, or whatever&mdash;the precise choice depends on how small a number you think is &ldquo;small&rdquo;.
</p>
<p>Figure 10.21 also shows the first principal component. The eigenvalues justify thinking of each data item as (roughly)
</p>
<p>the mean plus some weight times this principal component. From this plot you can see that data items with a larger value of
</p>
<p>weight will also have larger values of most other measurements, except age and density. You can also see how much larger;
</p>
<p>if the weight goes up by 8.5 units, then the abdomen will go up by 3 units, and so on. This explains the main variation in the
</p>
<p>dataset.</p>
<p/>
</div>
<div class="page"><p/>
<p>10.5 Example: Understanding Height and Weight 249
</p>
<p>2 4 6 8 10 12 14 16
0
</p>
<p>200
</p>
<p>400
</p>
<p>600
</p>
<p>800
</p>
<p>1000
</p>
<p>1200
Height&minus;weight covariance eigenvalues
</p>
<p>0 2 4 6 8 10 12 14 16 18
</p>
<p>0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>0.4
</p>
<p>0.5
</p>
<p>0.6
</p>
<p>0.7
</p>
<p>0.8
</p>
<p>0.9
</p>
<p>bodyfat
</p>
<p>density
</p>
<p>age
</p>
<p>weight
</p>
<p>height
</p>
<p>adiposity
neck
</p>
<p>chest
</p>
<p>abdomen
</p>
<p>hip
</p>
<p>thigh
</p>
<p>knee
ankle
</p>
<p>biceps
forearm
</p>
<p>wrist
</p>
<p>Height&minus;Weight first principal component
</p>
<p>Fig. 10.21 On the left, the eigenvalues of the covariance matrix for the bodyfat data set. Notice how fast the eigenvalues fall off; this means that
most principal components have very small variance, so that data can be represented well with a small number of principal components. On the
right, the first principal component for this dataset, plotted using the same convention as for Fig. 10.20
</p>
<p>0 2 4 6 8 10 12 14 16 18
&minus;0.2
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>bodyfat
</p>
<p>density
</p>
<p>age
</p>
<p>weight
height
</p>
<p>adiposity
neck
</p>
<p>chest
</p>
<p>abdomen
</p>
<p>hip
thigh
</p>
<p>knee
</p>
<p>ankle
</p>
<p>biceps
forearm
</p>
<p>wrist
</p>
<p>Height&minus;Weight second principal component
</p>
<p>0 2 4 6 8 10 12 14 16 18
&minus;0.4
</p>
<p>&minus;0.2
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>bodyfat
</p>
<p>density
</p>
<p>age weight
height
</p>
<p>adiposity
</p>
<p>neck
</p>
<p>chest
</p>
<p>abdomen
</p>
<p>hip thigh
</p>
<p>knee ankle
</p>
<p>biceps
</p>
<p>forearm
wrist
</p>
<p>Height&minus;Weight third principal component
</p>
<p>Fig. 10.22 On the left, the second principal component, and on the right the third principal component of the height-weight dataset
</p>
<p>In the rotated coordinate system, the components are not correlated, and they have different variances (which are the
</p>
<p>eigenvalues of the covariance matrix). You can get some sense of the data by adding these variances; in this case, we get
</p>
<p>1404. This means that, in the translated and rotated coordinate system, the average data point is about 37 D
p
1404 units
</p>
<p>away from the center (the origin). Translations and rotations do not change distances, so the average data point is about 37
</p>
<p>units from the center in the original dataset, too. If we represent a datapoint by using the mean and the first three principal
</p>
<p>components, there will be some error. We can estimate the average error from the component variances. In this case, the
</p>
<p>sum of the first three eigenvalues is 1357, so the mean square error in representing a datapoint by the first three principal
</p>
<p>components is
p
</p>
<p>.1404 � 1357/, or 6:8. The relative error is 6:8=37 D 0:18. Another way to represent this information,
which is more widely used, is to say that the first three principal components explain all but .1404 � 1357/=1404 D 0:034,
or 3:4% of the variance; notice that this is the square of the relative error, which will be a much smaller number.
</p>
<p>All this means that explaining a data point as the mean and the first three principal components produces relatively small
</p>
<p>errors. Figure 10.22 shows the second and third principal component of the data. These two principal components suggest</p>
<p/>
</div>
<div class="page"><p/>
<p>250 10 Extracting Important Relationships in High Dimensions
</p>
<p>some further conclusions. As age gets larger, height and weight get slightly smaller, but the weight is redistributed; abdomen
</p>
<p>gets larger, whereas thigh gets smaller. A smaller effect (the third principal component) links bodyfat and abdomen. As
</p>
<p>bodyfat goes up, so does abdomen.
</p>
<p>10.6 You Should
</p>
<p>10.6.1 Remember These Definitions
</p>
<p>Covariance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
</p>
<p>Covariance Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
</p>
<p>10.6.2 Remember These Terms
</p>
<p>symmetric . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
</p>
<p>eigenvector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
</p>
<p>eigenvalue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
</p>
<p>principal components . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
</p>
<p>color constancy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
</p>
<p>principal coordinate analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
</p>
<p>multidimensional scaling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
</p>
<p>Likert scales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247
</p>
<p>10.6.3 Remember These Facts
</p>
<p>Properties of the covariance matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
</p>
<p>Orthonormal matrices are rotations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
</p>
<p>You can transform data to zero mean and diagonal covariance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
</p>
<p>10.6.4 Use These Procedures
</p>
<p>To diagonalize a symmetric matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
</p>
<p>To construct a low-d representation with principal components . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
</p>
<p>To make a low dimensional map. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246
</p>
<p>10.6.5 Be Able to
</p>
<p>&bull; Create, plot and interpret the first few principal components of a dataset.
</p>
<p>&bull; Compute the error resulting from ignoring some principal components.
</p>
<p>Problems
</p>
<p>Summaries
</p>
<p>10.1 You have a dataset fxg of N vectors, xi, each of which is d-dimensional. We will consider a linear function of this
dataset. Write a for a constant vector; then the value of this linear function evaluated on the i&rsquo;th data item is aTxi. Write
</p>
<p>fi D aTxi. We can make a new dataset ff g out of the values of this linear function.</p>
<p/>
</div>
<div class="page"><p/>
<p>Programming Exercises 251
</p>
<p>Fig. 10.23 Figure for the
question
</p>
<p>&minus;10 &minus;5 0 5 10
&minus;10
</p>
<p>&minus;5
</p>
<p>0
</p>
<p>5
</p>
<p>10
</p>
<p>(a) Show that mean .ff g/ D aTmean .fxg/ (easy).
(b) Show that var .ff g/ D aTCovmat .fxg/a (harder, but just push it through the definition).
(c) Assume the dataset has the special property that there exists some a so that aTCovmat .fxg/a. Show that this means that
</p>
<p>the dataset lies on a hyperplane.
</p>
<p>10.2 On Fig. 10.23, mark the mean of the dataset, the first principal component, and the second principal component.
</p>
<p>10.3 You have a dataset fxg of N vectors, xi, each of which is d-dimensional. Assume that Covmat .fxg/ has one non-zero
eigenvalue. Assume that x1 and x2 do not have the same value.
</p>
<p>(a) Show that you can choose a set of ti so that you can represent every data item xi exactly
</p>
<p>xi D x1 C ti.x2 � x1/:
</p>
<p>(b) Now consider the dataset of these t values. What is the relationship between (a) std .t/ and (b) the non-zero eigenvalue
</p>
<p>of Covmat .fxg/? Why?
</p>
<p>Programming Exercises
</p>
<p>10.4 Obtain the iris dataset from the UC Irvine machine learning data repository at http://https://archive.ics.uci.edu/ml/
</p>
<p>machine-learning-databases/iris/iris.data.
</p>
<p>(a) Plot a scatterplot matrix of this dataset, showing each species with a different marker.
</p>
<p>(b) Now obtain the first two principal components of the data. Plot the data on those two principal components alone, again
</p>
<p>showing each species with a different marker. Has this plot introduced significant distortions? Explain
</p>
<p>10.5 Take the wine dataset from the UC Irvine machine learning data repository at https://archive.ics.uci.edu/ml/datasets/
</p>
<p>Wine.
</p>
<p>(a) Plot the eigenvalues of the covariance matrix in sorted order. How many principal components should be used to
</p>
<p>represent this dataset? Why?
</p>
<p>(b) Construct a stem plot of each of the first 3 principal components (i.e. the eigenvectors of the covariance matrix with
</p>
<p>largest eigenvalues). What do you see?
</p>
<p>(c) Compute the first two principal components of this dataset, and project it onto those components. Now produce a scatter
</p>
<p>plot of this two dimensional dataset, where data items of class 1 are plotted as a &lsquo;1&rsquo;, class 2 as a &lsquo;2&rsquo;, and so on.</p>
<p/>
<div class="annotation"><a href="http://https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data">http://https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data</a></div>
<div class="annotation"><a href="http://https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data">http://https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Wine">https://archive.ics.uci.edu/ml/datasets/Wine</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Wine">https://archive.ics.uci.edu/ml/datasets/Wine</a></div>
</div>
<div class="page"><p/>
<p>252 10 Extracting Important Relationships in High Dimensions
</p>
<p>10.6 Take the wheat kernel dataset from the UC Irvine machine learning data repository at http://archive.ics.uci.edu/ml/
</p>
<p>datasets/seeds. Compute the first two principal components of this dataset, and project it onto those components.
</p>
<p>(a) Produce a scatterplot of this projection. Do you see any interesting phenomena?
</p>
<p>(b) Plot the eigenvalues of the covariance matrix in sorted order. How many principal components should be used to
</p>
<p>represent this dataset? why?
</p>
<p>10.7 The UC Irvine machine learning data repository hosts a collection of data on breast cancer diagnostics, donated by Olvi
</p>
<p>Mangasarian, Nick Street, and William H. Wolberg. You can find this data at http://archive.ics.uci.edu/ml/datasets/Breast+
</p>
<p>Cancer+Wisconsin+(Diagnostic). For each record, there is an id number, 10 continuous variables, and a class (benign or ma-
</p>
<p>lignant). There are 569 examples. Separate this dataset randomly into 100 validation, 100 test, and 369 training examples. Plot
</p>
<p>this dataset on the first three principal components, using different markers for benign and malignant cases. What do you see?
</p>
<p>10.8 The UC Irvine Machine Learning data archive hosts a dataset of measurements of abalone at http://archive.ics.uci.
</p>
<p>edu/ml/datasets/Abalone. Compute the principal components of all variables except Sex. Now produce a scatter plot of the
</p>
<p>measurements projected onto the first two principal components, plotting an &ldquo;m&rdquo; for male abalone, an &ldquo;f&rdquo; for female abalone
</p>
<p>and an &ldquo;i&rdquo; for infants. What do you see?
</p>
<p>10.9 Choose a state. For the 15 largest cities in your chosen state, find the distance between cities and the road mileage
</p>
<p>between cities. These differ because of the routes that roads take; you can find these distances by careful use of the internet.
</p>
<p>Prepare a map showing these cities on the plane using principal coordinate analysis for each of these two distances. How
</p>
<p>badly does using the road network distort to make a map distort the state? Does this differ from state to state? Why?
</p>
<p>10.10 CIFAR-10 is a dataset of 32 � 32 images in 10 categories, collected by Alex Krizhevsky, Vinod Nair, and Geoffrey
Hinton. It is often used to evaluate machine learning algorithms. You can download this dataset from https://www.cs.toronto.
</p>
<p>edu/~kriz/cifar.html.
</p>
<p>(a) For each category, compute the mean image and the first 20 principal components. Plot the error resulting from
</p>
<p>representing the images of each category using the first 20 principal components against the category.
</p>
<p>(b) Compute the distances between mean images for each pair of classes. Use principal coordinate analysis to make a 2D
</p>
<p>map of the means of each categories. For this exercise, compute distances by thinking of the images as vectors.
</p>
<p>(c) Here is another measure of the similarity of two classes. For class A and class B, define E.A ! B/ to be the average
error obtained by representing all the images of class A using the mean of class A and the first 20 principal components
</p>
<p>of class B. Now define the similarity between classes to be .1=2/.E.A ! B/ C E.B ! A//. Use principal coordinate
analysis to make a 2D map of the classes. Compare this map to the map in the previous exercise&mdash;are they different?
</p>
<p>why?</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/seeds">http://archive.ics.uci.edu/ml/datasets/seeds</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/seeds">http://archive.ics.uci.edu/ml/datasets/seeds</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Abalone">http://archive.ics.uci.edu/ml/datasets/Abalone</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Abalone">http://archive.ics.uci.edu/ml/datasets/Abalone</a></div>
<div class="annotation"><a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></div>
<div class="annotation"><a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></div>
</div>
<div class="page"><p/>
<p>11Learning to Classify
</p>
<p>A classifier is a procedure that accepts a set of features and produces a class label for them. Classifiers are immensely
</p>
<p>useful, and find wide application, because many problems are naturally classification problems. For example, if you wish to
</p>
<p>determine whether to place an advert on a web-page or not, you would use a classifier (i.e. look at the page, and say yes or
</p>
<p>no according to some rule). As another example, if you have a program that you found for free on the web, you would use a
</p>
<p>classifier to decide whether it was safe to run it (i.e. look at the program, and say yes or no according to some rule). As yet
</p>
<p>another example, credit card companies must decide whether a transaction is good or fraudulent.
</p>
<p>All these examples are two class classifiers, but in many cases it is natural to have more classes. You can think of sorting
</p>
<p>laundry as applying a multi-class classifier. You can think of doctors as complex multi-class classifiers: a doctor accepts a set
</p>
<p>of features (your complaints, answers to questions, and so on) and then produces a response which we can describe as a class.
</p>
<p>The grading procedure for any class is a multi-class classifier: it accepts a set of features&mdash;performance in tests, homeworks,
</p>
<p>and so on&mdash;and produces a class label (the letter grade).
</p>
<p>A classifier is usually trained by obtaining a set of labelled training examples and then searching for a classifier that
</p>
<p>optimizes some cost function which is evaluated on the training data. What makes training classifiers interesting is that
</p>
<p>performance on training data doesn&rsquo;t really matter. What matters is performance on run-time data, which may be extremely
</p>
<p>hard to evaluate because one often does not know the correct answer for that data. For example, we wish to classify credit-
</p>
<p>card transactions as safe or fraudulent. We could obtain a set of transactions with true labels, and train with those. But what
</p>
<p>we care about is new transactions, where it would be very difficult to know whether the classifier&rsquo;s answers are right. To be
</p>
<p>able to do anything at all, the set of labelled examples must be representative of future examples in some strong way. We will
</p>
<p>always assume that the labelled examples are an IID sample from the set of all possible examples, though we never use the
</p>
<p>assumption explicitly.
</p>
<p>Definition 11.1 (Classifier) A classifier is a procedure that accepts a set of features and produces a label. Classifiers
</p>
<p>are trained on labelled examples, but the goal is to get a classifier that performs well on data which is not seen at the
</p>
<p>time of training. Training a classifier requires labelled data that is representative of future data.
</p>
<p>11.1 Classification: The Big Ideas
</p>
<p>We will write the training dataset .xi; yi/. For the i&rsquo;th example, xi represents the values taken by a collection of features. In
</p>
<p>the simplest case, xi would be a vector of real numbers. In some cases, xi could contain categorical data or even unknown
</p>
<p>values. Although xi isn&rsquo;t guaranteed to be a vector, it&rsquo;s usually referred to as a feature vector. The yi are labels giving the
</p>
<p>type of the object that generated the example. We must use these labelled examples to come up with a classifier.
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_11
</p>
<p>253</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_11">https://doi.org/10.1007/978-3-319-64410-3_11</a></div>
</div>
<div class="page"><p/>
<p>254 11 Learning to Classify
</p>
<p>11.1.1 The Error Rate, and Other Summaries of Performance
</p>
<p>We can summarize the performance of any particular classifier using the error or total error rate (the percentage of
</p>
<p>classification attempts that gave the wrong answer) and the accuracy (the percentage of classification attempts that give
</p>
<p>the right answer). For most practical cases, even the best choice of classifier will make mistakes. For example, an alien tries
</p>
<p>to classify humans into male and female, using only height as a feature. Whatever the alien&rsquo;s classifier does with that feature,
</p>
<p>it will make mistakes. This is because the classifier must choose, for each value of height, whether to label the humans with
</p>
<p>that height male or female. But for the vast majority of heights, there are some males and some females with that height, and
</p>
<p>so the alien&rsquo;s classifier must make some mistakes.
</p>
<p>As the example suggests, a particular feature vector x may appear with different labels (so the alien will see six foot males
</p>
<p>and six foot females, quite possibly in the training dataset and certainly in future data). Labels appear with some probability
</p>
<p>conditioned on the observations, P.yjx/. If there are parts of the feature space where P.x/ is relatively large (so we expect to
see observations of that form) and where P.yjx/ has relatively large values for more than one label, even the best possible
classifier will have a high error rate. If we knew P.yjx/ (which is seldom the case), we could identify the classifier with the
smallest error rate and compute its error rate. The minimum expected error rate obtained with the best possible classifier
</p>
<p>applied to a particular problem is known as the Bayes risk for that problem. In most cases, it is hard to know what the Bayes
</p>
<p>risk is, because to compute it requires knowing P.yjx/, which isn&rsquo;t usually known.
The error rate of a classifier is not that meaningful on its own, because we don&rsquo;t usually know the Bayes risk for a
</p>
<p>problem. It is more helpful to compare a particular classifier with some natural alternatives, sometimes called baselines. The
</p>
<p>choice of baseline for a particular problem is almost always a matter of application logic. The simplest general baseline is a
</p>
<p>know-nothing strategy. Imagine classifying the data without using the feature vector at all&mdash;how well does this strategy do?
</p>
<p>If each of the C classes occurs with the same frequency, then it&rsquo;s enough to label the data by choosing a label uniformly and
</p>
<p>at random, and the error rate for this strategy is 1 � 1=C. If one class is more common than the others, the lowest error rate
is obtained by labelling everything with that class. This comparison is often known as comparing to chance.
</p>
<p>It is very common to deal with data where there are only two labels. You should keep in mind this means the highest
</p>
<p>possible error rate is 50%&mdash;if you have a classifier with a higher error rate, you can improve it by switching the outputs.
</p>
<p>If one class is much more common than the other, training becomes more complicated because the best strategy&mdash;labelling
</p>
<p>everything with the common class&mdash;becomes hard to beat.
</p>
<p>11.1.2 More Detailed Evaluation
</p>
<p>The error rate is a fairly crude summary of the classifier&rsquo;s behavior. For a two-class classifier and a 0&ndash;1 loss function, one
</p>
<p>can report the false positive rate (the percentage of negative test data that was classified positive) and the false negative rate
</p>
<p>(the percentage of positive test data that was classified negative). Note that it is important to provide both, because a classifier
</p>
<p>with a low false positive rate tends to have a high false negative rate, and vice versa. As a result, you should be suspicious of
</p>
<p>reports that give one number but not the other. Alternative numbers that are reported sometimes include the sensitivity (the
</p>
<p>percentage of true positives that are classified positive) and the specificity (the percentage of true negatives that are classified
</p>
<p>negative).
</p>
<p>The false positive and false negative rates of a two-class classifier can be generalized to evaluate a multi-class classifier,
</p>
<p>yielding the class confusion matrix. This is a table of cells, where the i, j&rsquo;th cell contains the count of cases where the true
</p>
<p>label was i and the predicted label was j (some people show the fraction of cases rather than the count). Table 11.1 gives an
</p>
<p>example. This is a class confusion matrix from a classifier built on a dataset where one tries to predict the degree of heart
</p>
<p>disease from a collection of physiological and physical measurements. There are five classes (0 : : : 4). The i, j&rsquo;th cell of the
</p>
<p>table shows the number of data points of true class i that were classified to have class j. As I find it hard to recall whether
</p>
<p>rows or columns represent true or predicted classes, I have marked this on the table. For each row, there is a class error rate,
</p>
<p>which is the percentage of data points of that class that were misclassified. The first thing to look at in a table like this is
</p>
<p>the diagonal; if the largest values appear there, then the classifier is working well. This clearly isn&rsquo;t what is happening for
</p>
<p>Table 11.1. Instead, you can see that the method is very good at telling whether a data point is in class 0 or not (the class
</p>
<p>error rate is rather small), but cannot distinguish between the other classes. This is a strong hint that the data can&rsquo;t be used to
</p>
<p>draw the distinctions that we want. It might be a lot better to work with a different set of classes.</p>
<p/>
</div>
<div class="page"><p/>
<p>11.1 Classification: The Big Ideas 255
</p>
<p>Table 11.1 The class confusion
matrix for a multiclass classifier
</p>
<p>True Predict
</p>
<p>0 1 2 3 4 Class error
</p>
<p>0 151 7 2 3 1 7.9%
</p>
<p>1 32 5 9 9 0 91%
</p>
<p>2 10 9 7 9 1 81%
</p>
<p>3 6 13 9 5 2 86%
</p>
<p>4 2 3 2 6 0 100%
</p>
<p>This is a table of cells, where the i, j&rsquo;th cell contains the
count of cases where the true label was i and the predicted
label was j (some people show the fraction of cases rather
than the count). Further details about the dataset and this
example appear in Worked example 11.20
</p>
<p>11.1.3 Overfitting and Cross-Validation
</p>
<p>Choosing and evaluating a classifier takes some care. The goal is to get a classifier that works well on future data for which
</p>
<p>we might never know the true label, using a training set of labelled examples. This isn&rsquo;t necessarily easy. For example, think
</p>
<p>about the (silly) classifier that takes any data point and, if it is the same as a point in the training set, emits the class of that
</p>
<p>point; otherwise, it chooses randomly between the classes.
</p>
<p>The training error of a classifier is the error rate on examples used to train the classifier. In contrast, the test error is error
</p>
<p>on examples not used to train the classifier. Classifiers that have small training error might not have small test error, because
</p>
<p>the classification procedure is chosen to do well on the training data. This effect is sometimes called overfitting. Other names
</p>
<p>include selection bias, because the training data has been selected and so isn&rsquo;t exactly like the test data, and generalizing
</p>
<p>badly, because the classifier must generalize from the training data to the test data. The effect occurs because the classifier has
</p>
<p>been chosen to perform well on the training dataset. An efficient training procedure is quite likely to find special properties
</p>
<p>of the training dataset that aren&rsquo;t representative of the test dataset, because the training dataset is not the same as the test
</p>
<p>dataset. The training dataset is typically a sample of all the data one might like to have classified, and so is quite likely a lot
</p>
<p>smaller than the test dataset. Because it is a sample, it may have quirks that don&rsquo;t appear in the test dataset. One consequence
</p>
<p>of overfitting is that classifiers should always be evaluated on data that was not used in training.
</p>
<p>Now assume that we want to estimate the error rate of the classifier on test data. We cannot estimate the error rate of the
</p>
<p>classifier using data that was used to train the classifier, because the classifier has been trained to do well on that data, which
</p>
<p>will mean our error rate estimate will be too low. An alternative is to separate out some training data to form a validation set
</p>
<p>(confusingly, this is sometimes called a test set), then train the classifier on the rest of the data, and evaluate on the validation
</p>
<p>set. The error estimate on the validation set is the value of a random variable, because the validation set is a sample of all
</p>
<p>possible data you might classify. But this error estimate is unbiased, meaning that the expected value of the error estimate is
</p>
<p>the true value of the error. You can see this by thinking about the error estimate as a sample mean and applying the ideas of
</p>
<p>Chap. 6.
</p>
<p>However, separating out some training data presents the difficulty that the classifier will not be the best possible, because
</p>
<p>we left out some training data when we trained it. This issue can become a significant nuisance when we are trying to tell
</p>
<p>which of a set of classifiers to use&mdash;did the classifier perform poorly on validation data because it is not suited to the problem
</p>
<p>representation or because it was trained on too little data?
</p>
<p>We can resolve this problem with cross-validation, which involves repeatedly: splitting data into training and validation
</p>
<p>sets uniformly and at random, training a classifier on the training set, evaluating it on the validation set, and then averaging
</p>
<p>the error over all splits. Each different split is usually called a fold. This procedure yields an estimate of the likely future
</p>
<p>performance of a classifier, at the expense of substantial computation. A common form of this algorithm uses a single data
</p>
<p>item to form a validation set. This is known as leave-one-out cross-validation.
</p>
<p>Remember this: Classifiers usually perform better on training data than on test data, because the classifier was chosen
</p>
<p>to do well on the training data. This effect is known as overfitting. To get an accurate estimate of future performance,
</p>
<p>classifiers should always be evaluated on data that was not used in training.</p>
<p/>
</div>
<div class="page"><p/>
<p>256 11 Learning to Classify
</p>
<p>11.2 Classifying with Nearest Neighbors
</p>
<p>Assume we have a labelled dataset consisting of N pairs .xi; yi/. Here xi is the i&rsquo;th feature vector, and yi is the i&rsquo;th class
</p>
<p>label. We wish to predict the label y for any new example x; this is often known as a query example or query. Here is a really
</p>
<p>effective strategy: Find the labelled example xc that is closest to x, and report the class of that example.
</p>
<p>How well can we expect this strategy to work? A precise analysis would take us way out of our way, but simple reasoning
</p>
<p>is informative. Assume there are two classes, 1 and �1 (the reasoning will work for more, but the description is slightly
more involved). We expect that, if u and v are sufficiently close, then p.yju/ is similar to p.yjv/. This means that if a labelled
example xi is close to x, then p.yjx/ is similar to p.yjxi/. Furthermore, we expect that queries are &ldquo;like&rdquo; the labelled dataset,
in the sense that points that are common (resp. rare) in the labelled data will appear often (resp. seldom) in the queries.
</p>
<p>Now imagine the query comes from a location where p.y D 1jx/ is large. The closest labelled example xc should be
nearby (because queries are &ldquo;like&rdquo; the labelled data) and should be labelled with 1 (because nearby examples have similar
</p>
<p>label probabilities). So the method should produce the right answer with high probability.
</p>
<p>Alternatively, imagine the query comes from a location where p.y D 1jx/ is about the same as p.y D �1jx/. The closest
labelled example xc should be nearby (because queries are &ldquo;like&rdquo; the labelled data). But think about a set of examples that
</p>
<p>are about as close. The labels in this set should vary significantly (because p.y D 1jx/ is about the same as p.y D �1jx/.
This means that, if the query is labelled 1 (resp. �1), a small change in the query will cause it to be labelled �1 (resp. 1).
In these regions the classifier will tend to make mistakes more often, as it should. Using a great deal more of this kind of
</p>
<p>reasoning, nearest neighbors can be shown to produce an error that is no worse than twice the best error rate, if the method
</p>
<p>has enough examples. There is no prospect of seeing enough examples in practice for this result to apply.
</p>
<p>One important generalization is to find the k nearest neighbors, then choose a label from those. A .k; l/ nearest neighbor
</p>
<p>classifier finds the k example points closest to the point being considered, and classifies this point with the class that has
</p>
<p>the highest number of votes, as long as this class has more than l votes (otherwise, the point is classified as unknown). In
</p>
<p>practice, one seldom uses more than three nearest neighbors.
</p>
<p>11.2.1 Practical Considerations for Nearest Neighbors
</p>
<p>One practical difficulty in using nearest neighbor classifiers is you need a lot of labelled examples for the method to work.
</p>
<p>For some problems, this means you can&rsquo;t use the method. A second practical difficulty is you need to use a sensible choice of
</p>
<p>distance. For features that are obviously of the same type, such as lengths, the usual metric may be good enough. But what if
</p>
<p>one feature is a length, one is a color, and one is an angle? It is almost always a good idea to scale each feature independently
</p>
<p>so that the variance of each feature is the same, or at least consistent; this prevents features with very large scales dominating
</p>
<p>those with very small scales. Another possibility is to transform the features so that the covariance matrix is the identity (this
</p>
<p>is sometimes known as whitening; the method follows from the ideas of Chap. 10). This can be hard to do if the dimension
</p>
<p>is so large that the covariance matrix is hard to estimate.
</p>
<p>A third practical difficulty is you need to be able to find the nearest neighbors for your query point. This is surprisingly
</p>
<p>difficult to do faster than simply checking the distance to each training example separately. If your intuition tells you to use a
</p>
<p>tree and the difficulty will go away, your intuition isn&rsquo;t right. It turns out that nearest neighbors in high dimensions is one of
</p>
<p>those problems that is a lot harder than it seems, because high dimensional spaces are quite hard to reason about informally.
</p>
<p>There&rsquo;s a long history of methods that appear to be efficient but, once carefully investigated, turn out to be bad.
</p>
<p>Fortunately, it is usually enough to use an approximate nearest neighbor. This is an example that is, with high
</p>
<p>probability, almost as close to the query point as the nearest neighbor is. Obtaining an approximate nearest neighbor is
</p>
<p>very much easier than obtaining a nearest neighbor. We can&rsquo;t go into the details here, but there are several distinct methods
</p>
<p>for finding approximate nearest neighbors. Each involves a series of tuning constants and so on, and, on different datasets,
</p>
<p>different methods and different choices of tuning constant produce the best results. If you want to use a nearest neighbor
</p>
<p>classifier on a lot of run-time data, it is usually worth a careful search over methods and tuning constants to find an algorithm
</p>
<p>that yields a very fast response to a query. It is known how to do this search, and there is excellent software available
</p>
<p>(FLANN, http://www.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN, by Marius Muja and David G. Lowe).
</p>
<p>It is straightforward to use cross-validation to estimate the error rate of a nearest neighbor classifier. Split the labelled
</p>
<p>training data into two pieces, a (typically large) training set and a (typically small) validation set. Now take each element of
</p>
<p>the validation set and label it with the label of the closest element of the training set. Compute the fraction of these attempts
</p>
<p>that produce an error (the true label and predicted labels differ). Now repeat this for a different split, and average the errors
</p>
<p>over splits. With care, the code you&rsquo;ll write is shorter than this description.</p>
<p/>
<div class="annotation"><a href="http://www.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN">http://www.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN</a></div>
</div>
<div class="page"><p/>
<p>11.3 Classifying with Naive Bayes 257
</p>
<p>Worked example 11.1 (Classifying Usi- ng Nearest Neighbors) Build a nearest neighbor classifier to classify the
</p>
<p>MNIST digit data. This dataset is very widely used to check simple methods. It was originally constructed by Yann
</p>
<p>Lecun, Corinna Cortes, and Christopher J.C. Burges. It has been extensively studied. You can find this dataset in
</p>
<p>several places. The original dataset is at http://yann.lecun.com/exdb/mnist/. The version I used was used for a Kaggle
</p>
<p>competition (so I didn&rsquo;t have to decompress Lecun&rsquo;s original format). I found it at http://www.kaggle.com/c/digit-
</p>
<p>recognizer.
</p>
<p>Solution I used R for this problem. As you&rsquo;d expect, R has nearest neighbor code that seems quite good (I haven&rsquo;t had
</p>
<p>any real problems with it, at least). There isn&rsquo;t really all that much to say about the code. I used the R FNN package. I
</p>
<p>trained on 1000 of the 42,000 examples in the Kaggle version, and I tested on the next 200 examples. For this (rather
</p>
<p>small) case, I found the following class confusion matrix:
</p>
<p>True Predict
</p>
<p>0 1 2 3 4 5 6 7 8 9
</p>
<p>0 12 0 0 0 0 0 0 0 0 0
</p>
<p>1 0 20 4 1 0 1 0 2 2 1
</p>
<p>2 0 0 20 1 0 0 0 0 0 0
</p>
<p>3 0 0 0 12 0 0 0 0 4 0
</p>
<p>4 0 0 0 0 18 0 0 0 1 1
</p>
<p>5 0 0 0 0 0 19 0 0 1 0
</p>
<p>6 1 0 0 0 0 0 18 0 0 0
</p>
<p>7 0 0 1 0 0 0 0 19 0 2
</p>
<p>8 0 0 1 0 0 0 0 0 16 0
</p>
<p>9 0 0 0 2 3 1 0 1 1 14
</p>
<p>There are no class error rates here, because I couldn&rsquo;t recall the magic line of R to get them. However, you can see
</p>
<p>the classifier works rather well for this case. MNIST is comprehensively explored in the exercises.
</p>
<p>Remember this: Nearest neighbors has good properties. With enough training data and a low enough dimension, the
</p>
<p>error rate is guaranteed to be no more than twice the best error rate. The method is wonderfully flexible about the
</p>
<p>labels the classifier predicts. Nothing changes when you go from a two-class classifier to a multi-class classifier.
</p>
<p>There are important difficulties. You need a large training dataset. If you don&rsquo;t have a reliable measure of how far
</p>
<p>apart two things are, you shouldn&rsquo;t be doing nearest neighbors. And you need to be able to query a large dataset of
</p>
<p>examples to find the nearest neighbor of a point.
</p>
<p>11.3 Classifying with Naive Bayes
</p>
<p>One straightforward source of a classifier is a probability model. For the moment, assume we know p.yjx/ for our data.
Assume also that all errors in classification are equally important. Then the following rule produces smallest possible
</p>
<p>expected classification error rate:
</p>
<p>For a test example x, report the class y that has the highest value of .p.yjx//. If the largest value is achieved by more
than one class, choose randomly from that set of classes.
</p>
<p>Usually, we do not have p.yjx/. If we have p.xjy/ (often called either a likelihood or class conditional probability,
compare Sect. 9.1), and p.y/ (often called a prior, compare Sect. 9.2) then we can use Bayes&rsquo; rule to form
</p>
<p>p.yjx/ D p.xjy/p.y/
p.x/</p>
<p/>
<div class="annotation"><a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></div>
<div class="annotation"><a href="http://www.kaggle.com/c/digit-recognizer">http://www.kaggle.com/c/digit-recognizer</a></div>
<div class="annotation"><a href="http://www.kaggle.com/c/digit-recognizer">http://www.kaggle.com/c/digit-recognizer</a></div>
</div>
<div class="page"><p/>
<p>258 11 Learning to Classify
</p>
<p>(the posterior, compare Sect. 9.2). This isn&rsquo;t much help in this form, but write x.j/ for the j&rsquo;th component of x. Now assume
</p>
<p>that features are conditionally independent conditioned on the class of the data item. Our assumption is
</p>
<p>p.xjy/ D
Y
</p>
<p>j
</p>
<p>p.x.j/jy/:
</p>
<p>It is very seldom the case that this assumption is true, but it turns out to be fruitful to pretend that it is. This assumption
</p>
<p>means that
</p>
<p>p.yjx/ D p.xjy/p.y/
p.x/
</p>
<p>D
</p>
<p>�
</p>
<p>Q
</p>
<p>j p.x
.j/jy/
</p>
<p>�
</p>
<p>p.y/
</p>
<p>p.x/
</p>
<p>/
</p>
<p>0
</p>
<p>@
</p>
<p>Y
</p>
<p>j
</p>
<p>p.x.j/jy/
</p>
<p>1
</p>
<p>A p.y/:
</p>
<p>Now to make a decision, we need to choose the class that has the largest value of p.yjx/. In turn, this means we need only
know the posterior values up to scale at x, so we don&rsquo;t need to estimate p.x/. In the case of where all errors have the same
</p>
<p>cost, this yields the rule
</p>
<p>choose y such that
</p>
<p>2
</p>
<p>4
</p>
<p>0
</p>
<p>@
</p>
<p>Y
</p>
<p>j
</p>
<p>p.x.j/jy/
</p>
<p>1
</p>
<p>A p.y/
</p>
<p>3
</p>
<p>5 is largest:
</p>
<p>This rule suffers from a practical problem. You can&rsquo;t actually multiply a large number of probabilities and expect to get an
</p>
<p>answer that a floating point system thinks is different from zero. Instead, you should add the log probabilities. Notice that
</p>
<p>the logarithm function has one nice property: it is monotonic, meaning that a &gt; b is equivalent to log a &gt; log b. This means
</p>
<p>the following, more practical, rule is equivalent:
</p>
<p>choose y such that
</p>
<p>2
</p>
<p>4
</p>
<p>0
</p>
<p>@
</p>
<p>X
</p>
<p>j
</p>
<p>log p.x.j/jy/
</p>
<p>1
</p>
<p>AC log p.y/
</p>
<p>3
</p>
<p>5 is largest:
</p>
<p>To use this rule, we need models for p.y/ and for p.x.j/jy/ for each j. The usual way to find a model of p.y/ is to count the
number of training examples in each class, then divide by the number of classes.
</p>
<p>It turns out that simple parametric models work really well for p.x.j/jy/. For example, one could use a normal distribution
for each x.j/ in turn, for each possible value of y, using the training data. The parameters of this normal distribution are
</p>
<p>chosen using maximum likelihood. The logic of the measurements might suggest other distributions, too. If one of the x.j/&rsquo;s
</p>
<p>was a count, we might fit a Poisson distribution (again, using maximum likelihood). If it was a 0&ndash;1 variable, we might fit a
</p>
<p>Bernoulli distribution. If it was a discrete variable, then we might use a multinomial model. Even if the x.j/ is continuous, we
</p>
<p>can use a multinomial model by quantizing to some fixed set of values; this can be quite effective.
</p>
<p>A naive bayes classifier that has poorly fitting models for each feature could classify data very well. This (reliably
</p>
<p>confusing property) occurs because classification doesn&rsquo;t require a good model of p.xjy/, or even of p.yjx/. All that needs
to happen is that, at any x, the score for the right class is higher than the score for all other classes. Figure 11.1 shows an
</p>
<p>example where a normal model of the class-conditional histograms is poor, but the normal model will result in a good naive
</p>
<p>bayes classifier. This works because a data item from (say) class one will reliably have a larger probability under the normal
</p>
<p>model for class one than it will for class two.</p>
<p/>
</div>
<div class="page"><p/>
<p>11.3 Classifying with Naive Bayes 259
</p>
<p>Fig. 11.1 The figure shows class
conditional histograms of a
feature x for two different classes.
The histograms have been
normalized so that the counts
sum to one, so you can think of
them as probability distributions.
It should be fairly obvious that a
normal model (superimposed)
doesn&rsquo;t describe these histograms
well. However, the normal model
will result in a good naive bayes
classifier
</p>
<p>Worked example 11.2 (Classifying Breast Tissue Samples). The &ldquo;breast tissue&rdquo; dataset at https://archive.ics.uci.edu/
</p>
<p>ml/datasets/Breast+Tissue contains measurements of a variety of properties of six different classes of breast tissue.
</p>
<p>Build and evaluate a naive bayes classifier to distinguish between the classes automatically from the measurements.
</p>
<p>Solution I used R for this example, because I could then use packages easily. The main difficulty here is finding
</p>
<p>appropriate packages, understanding their documentation, and checking they&rsquo;re right (unless you want to write the
</p>
<p>source yourself, which really isn&rsquo;t all that hard). I used the R package caret to do train-test splits, cross-validation,
</p>
<p>etc. on the naive bayes classifier in the R package klaR. I separated out a test set randomly (approx 20% of the cases
</p>
<p>for each class, chosen at random), then trained with cross-validation on the remainder. I used a normal model for each
</p>
<p>feature. The class-confusion matrix on the test set was:
</p>
<p>True Predict
</p>
<p>adi car con fad gla mas
</p>
<p>adi 2 0 0 0 0 0
</p>
<p>car 0 3 0 0 0 1
</p>
<p>con 2 0 2 0 0 0
</p>
<p>fad 0 0 0 0 1 0
</p>
<p>gla 0 0 0 0 2 1
</p>
<p>mas 0 1 0 3 0 1
</p>
<p>which is fairly good. The accuracy is 52%. In the training data, the classes are nearly balanced and there are six classes,
</p>
<p>meaning that chance is about 17%. These numbers, and the class-confusion matrix, will vary with test-train split. I have
</p>
<p>not averaged over splits, which would give a somewhat more accurate estimate of accuracy.
</p>
<p>11.3.1 Cross-Validation to Choose aModel
</p>
<p>Naive bayes presents us with a new problem. We can choose from several different types of model for p.x.j/jy/ (eg normal
models vs. Poisson models), and we need to know which one produces the best classifier. We also need to know how well
</p>
<p>that classifier will work. It is natural to use cross-validation to estimate how well each type of model works. You can&rsquo;t
</p>
<p>just look at every type of model for every variable, because that would yield too many models. Instead, choose M types of
</p>
<p>model that seem plausible (for example, by looking at histograms of feature components conditioned on class and using your
</p>
<p>judgement). Now compute a cross-validated error for each of M types of model, and choose the type of model with lowest
</p>
<p>cross-validated error. Computing the cross-validated error involves repeatedly splitting the training set into two pieces, fitting
</p>
<p>the model on one and computing the error on the other, then averaging the errors. Notice this means the model you fit to each
</p>
<p>fold will have slightly different parameter values, because each fold has slightly different training data.</p>
<p/>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Breast+Tissue">https://archive.ics.uci.edu/ml/datasets/Breast+Tissue</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Breast+Tissue">https://archive.ics.uci.edu/ml/datasets/Breast+Tissue</a></div>
</div>
<div class="page"><p/>
<p>260 11 Learning to Classify
</p>
<p>However, once we have chosen the type of model, we have two problems. First, we do not know the correct values for
</p>
<p>the parameters of the best type of model. For each fold in the cross-validation, we estimated slightly different parameters
</p>
<p>because we trained on slightly different data, and we don&rsquo;t know which estimate is right. Second, we do not have a good
</p>
<p>estimate of how well the best model works. This is because we chose the type of model with the smallest error estimate,
</p>
<p>which is likely smaller than the true error estimate for that type of model.
</p>
<p>This problem is easily dealt with if you have a reasonably sized dataset. Split the labelled dataset into two pieces. One
</p>
<p>(call it the training set) is used for training and for choosing a model type, the other (call it the test set) is used only for
</p>
<p>evaluating the final model. Now for each type of model, compute the cross-validated error on the training set.
</p>
<p>Now use the cross-validated error to choose the type of model. Very often this just means you choose the type that
</p>
<p>produces the lowest cross-validated error, but there might be cases where two types produce about the same error and one is
</p>
<p>a lot faster to evaluate, etc. Take the entire training set, and use this to estimate the parameters for that type of model. This
</p>
<p>estimate should be (a little) better than any of the estimates produced in the cross-validation, because it uses (slightly) more
</p>
<p>data. Finally, evaluate the resulting model on the test set.
</p>
<p>This procedure is rather harder to describe than to do (there&rsquo;s a pretty natural set of nested loops here). There are some
</p>
<p>strong advantages. First, the estimate of how well a particular model type works is unbiased, because we evaluated on data
</p>
<p>not used on training. Second, once you have chosen a type of model, the parameter estimate you make is the best you can
</p>
<p>because you used all the training set to obtain it. Finally, your estimate of how well that particular model works is unbiased,
</p>
<p>too, because you obtained it using data that wasn&rsquo;t used to train or to select a model.
</p>
<p>Remember this: Naive bayes classifiers are straightforward to build, and very effective. Experience has shown they
</p>
<p>are particularly effective at high dimensional data. A straightforward variant of cross-validation helps select which
</p>
<p>particular model to use.
</p>
<p>11.4 The Support Vector Machine
</p>
<p>Assume we have a labelled dataset consisting of N pairs .xi; yi/. Here xi is the i&rsquo;th feature vector, and yi is the i&rsquo;th class label.
</p>
<p>We will assume that there are two classes, and that yi is either 1 or �1. We wish to predict the sign of y for any point x. We
will use a linear classifier, so that for a new data item x, we will predict
</p>
<p>sign
�
</p>
<p>aTx C b
�
</p>
<p>and the particular classifier we use is given by our choice of a and b.
</p>
<p>You should think of a and b as representing a hyperplane, given by the points where aTx C b D 0. Notice that the
magnitude of aTx C b grows as the point x moves further away from the hyperplane. This hyperplane separates the positive
data from the negative data, and is an example of a decision boundary. When a point crosses the decision boundary, the label
</p>
<p>predicted for that point changes. All classifiers have decision boundaries. Searching for the decision boundary that yields the
</p>
<p>best behavior is a fruitful strategy for building classifiers.
</p>
<p>Example 11.1 (A Linear Model with a Single Feature) Assume we use a linear model with one feature. For an example
</p>
<p>with feature value x, predicts sign .axC b/. Equivalently, the model tests x against the threshold �b=a.
</p>
<p>Example 11.2 (A Linear Model with Two Features) Assume we use a linear model with two features. For an example
</p>
<p>with feature vector x, the model predicts sign
�
</p>
<p>aTx C b
�
</p>
<p>. The sign changes along the line aTx C b D 0. You should
check that this is, indeed, a line. On one side of this line, the model makes positive predictions; on the other, negative.
</p>
<p>Which side is which can be swapped by multiplying a and b by �1.</p>
<p/>
</div>
<div class="page"><p/>
<p>11.4 The Support Vector Machine 261
</p>
<p>This family of classifiers may look bad to you, and it is easy to come up with examples that it misclassifies badly. In
</p>
<p>fact, the family is extremely strong. First, it is easy to estimate the best choice of rule for very large datasets. Second, linear
</p>
<p>classifiers have a long history of working very well in practice on real data. Third, linear classifiers are fast to evaluate.
</p>
<p>In practice, examples that are classified badly by the linear rule usually are classified badly because there are too few
</p>
<p>features. Remember the case of the alien who classified humans into male and female by looking at their heights; if that alien
</p>
<p>had looked at their chromosomes as well as height, the error rate would have been smaller. In practical examples, experience
</p>
<p>shows that the error rate of a poorly performing linear classifier can usually be improved by adding features to the vector x.
</p>
<p>We will choose a and b by choosing values that minimize a cost function. The cost function must achieve two goals. First,
</p>
<p>the cost function needs a term that ensures each training example should be on the right side of the decision boundary (or, at
</p>
<p>least, not be too far on the wrong side). Second, the cost function needs a term that should penalize errors on query examples.
</p>
<p>The appropriate cost function has the form:
</p>
<p>Training error cost C � penalty term
</p>
<p>where � is an unknown weight that balances these two goals. We will eventually set the value of � by a search process.
</p>
<p>11.4.1 The Hinge Loss
</p>
<p>Write
</p>
<p>&#13;i D aTxi C b
</p>
<p>for the value that the linear function takes on example i. Write C.&#13;i; yi/ for a function that compares &#13;i with yi. The training
</p>
<p>error cost will be of the form
</p>
<p>.1=N/
</p>
<p>N
X
</p>
<p>iD1
C.&#13;i; yi/:
</p>
<p>A good choice of C should have some important properties.
</p>
<p>&bull; If &#13;i and yi have different signs, then C should be large, because the classifier will make the wrong prediction for this
</p>
<p>training example. Furthermore, if &#13;i and yi have different signs and &#13;i has large magnitude, then the classifier will very
</p>
<p>likely make the wrong prediction for test examples that are close to xi. This is because the magnitude of .a
Tx C b/ grows
</p>
<p>as x gets further from the decision boundary. So C should get larger as the magnitude of &#13;i gets larger in this case.
</p>
<p>&bull; If &#13;i and yi have the same signs, but &#13;i has small magnitude, then the classifier will classify xi correctly, but might not
</p>
<p>classify points that are nearby correctly. This is because a small magnitude of &#13;i means that xi is close to the decision
</p>
<p>boundary, so there will be points nearby that are on the other side of the decision boundary. We want to discourage this,
</p>
<p>so C should not be zero in this case.
</p>
<p>&bull; Finally, if &#13;i and yi have the same signs and &#13;i has large magnitude, then C can be zero because xi is on the right side of
</p>
<p>the decision boundary and so are all the points near to xi.
</p>
<p>The hinge loss, which takes the form
</p>
<p>C.yi; &#13;i/ D max.0; 1 � yi&#13;i/;
</p>
<p>has these properties (Fig. 11.2).
</p>
<p>&bull; If &#13;i and yi have different signs, then C will be large. Furthermore, the cost grows linearly as xi moves further away from
</p>
<p>the boundary on the wrong side.
</p>
<p>&bull; If &#13;i and yi have the same sign, but yi&#13;i &lt; 1 (which means that xi is close to the decision boundary), there is some cost,
</p>
<p>which gets larger as xi gets closer to the boundary.
</p>
<p>&bull; If yi&#13;i &gt; 1 (so the classifier predicts the sign correctly and xi is far from the boundary) there is no cost.
</p>
<p>A classifier trained to minimize this loss is encouraged to (a) make strong positive (or negative) predictions for positive (or
</p>
<p>negative) examples and (b) for examples it gets wrong, make predictions with the smallest magnitude that it can. A linear
</p>
<p>classifier trained with the hinge loss is known as a support vector machine or SVM.</p>
<p/>
</div>
<div class="page"><p/>
<p>262 11 Learning to Classify
</p>
<p>Fig. 11.2 The hinge loss,
plotted for the case yi D 1. The
horizontal variable is the
&#13;i D aTxi C b of the text. Notice
that giving a strong negative
response to this positive example
causes a loss that grows linearly
as the magnitude of the response
grows. Notice also that giving an
insufficiently positive response
also causes a loss. Giving a
strongly positive response is free
</p>
<p>&minus;4 &minus;2 0 2 4
0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
Hinge loss for a single example
</p>
<p>with y=1
</p>
<p>L
o
ss
</p>
<p>γ
</p>
<p>11.4.2 Regularization
</p>
<p>The penalty term is needed, because the hinge loss has one odd property. Assume that the pair a, b correctly classifies all
</p>
<p>training examples, so that yi.a
Txi C b/ &gt; 0. Then we can always ensure that the hinge loss for the dataset is zero, by scaling
</p>
<p>a and b, because you can choose a scale so that yj.a
Txj C b/ &gt; 1 for every example index j. This scale hasn&rsquo;t changed the
</p>
<p>result of the classification rule on the training data. Now if a and b result in a hinge loss of zero, then so do 2a and 2b. This
</p>
<p>should worry you, because it means we can&rsquo;t choose the classifier parameters uniquely.
</p>
<p>Now think about future examples. We don&rsquo;t know what their feature values will be, and we don&rsquo;t know their labels. But
</p>
<p>we do know that the hinge loss for an example with feature vector x and unknown label y will be max.0; 1 � y
�
</p>
<p>aTx C b
�
</p>
<p>/.
</p>
<p>Now imagine the hinge loss for this example isn&rsquo;t zero. If the example is classified correctly, then it is close to the decision
</p>
<p>boundary. We expect that there are fewer of these examples than examples that are far from the decision boundary and on the
</p>
<p>wrong side, so we concentrate on examples that are misclassified. For misclassified examples, if jjajj is small, then at least the
hinge loss will be small. By this argument, we would like to achieve a small value of the hinge loss on the training examples
</p>
<p>using an a that has small length.
</p>
<p>We can do so by adding a penalty term to the hinge loss to favor solutions where jjajj is small. To obtain an a of small length,
it is enough to ensure that .1=2/aTa is small (the factor of 1=2 makes the gradient cleaner). This penalty term will ensure
</p>
<p>that there is a unique choice of classifier parameters in the case the hinge loss is zero. Experience (and some theory we can&rsquo;t
</p>
<p>go into here) shows that having a small jjajj helps even if there is no pair that classifies all training examples correctly. Doing
so improves the error on future examples. Adding a penalty term to improve the solution of a learning problem is sometimes
</p>
<p>referred to as regularization. The penalty term is often referred to as a regularizer, because it tends to discourage solutions
</p>
<p>that are large (and so have possible high loss on future test data) but are not strongly supported by the training data. The
</p>
<p>parameter � is often referred to as the regularization parameter.
</p>
<p>Using the hinge loss to form the training cost, and regularizing with a penalty term .1=2/aTa means our cost function is:
</p>
<p>S.a; bI�/ D
"
</p>
<p>.1=N/
</p>
<p>N
X
</p>
<p>iD1
max.0; 1 � yi
</p>
<p>�
</p>
<p>aTxi C b
�
</p>
<p>/
</p>
<p>#
</p>
<p>C �
�
</p>
<p>aTa
</p>
<p>2
</p>
<p>�
</p>
<p>:
</p>
<p>There are now two problems to solve. First, assume we know �; we will need to find a and b that minimize S.a; bI�/. Second,
we have no theory that tells us how to choose �, so we will need to search for a good value.
</p>
<p>11.4.3 Finding a Classifier with Stochastic Gradient Descent
</p>
<p>The usual recipes for finding a minimum are ineffective for our cost function. First, write u D Œa; b&#141; for the vector obtained
by stacking the vector a together with b. We have a function g.u/, and we wish to obtain a value of u that achieves the</p>
<p/>
</div>
<div class="page"><p/>
<p>11.4 The Support Vector Machine 263
</p>
<p>minimum for that function. Sometimes we can solve a problem like this by constructing the gradient and finding a value of
</p>
<p>u the makes the gradient zero, but not this time (try it; the max creates problems). We must use a numerical method.
</p>
<p>Typical numerical methods take a point u.n/, update it to u.nC1/, then check to see whether the result is a minimum. This
process is started from a start point. The choice of start point may or may not matter for general problems, but for our
</p>
<p>problem a random start point is fine. The update is usually obtained by computing a direction p.n/ such that for small values
</p>
<p>of �, g.u.n/ C �p.n// is smaller than g.u.n//. Such a direction is known as a descent direction. We must then determine how
far to go along the descent direction, a process known as line search.
</p>
<p>Obtaining a descent direction: One method to choose a descent direction is gradient descent, which uses the negative
</p>
<p>gradient of the function. Recall our notation that
</p>
<p>u D
</p>
<p>0
</p>
<p>B
</p>
<p>B
</p>
<p>@
</p>
<p>u1
u2
: : :
</p>
<p>ud
</p>
<p>1
</p>
<p>C
</p>
<p>C
</p>
<p>A
</p>
<p>and that
</p>
<p>rg D
</p>
<p>0
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>B
</p>
<p>@
</p>
<p>@g
</p>
<p>@u1
@g
</p>
<p>@u2
: : :
@g
</p>
<p>@ud
</p>
<p>1
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>C
</p>
<p>A
</p>
<p>:
</p>
<p>We can write a Taylor series expansion for the function g.u.n/ C �p.n//. We have that
</p>
<p>g.u.n/ C �p.n// D g.u.n//C �
�
</p>
<p>.rg/Tp.n/
�
</p>
<p>C O.�2/
</p>
<p>This means that we can expect that if
</p>
<p>p.n/ D �rg.u.n//;
</p>
<p>we expect that, at least for small values of h, g.u.n/C�p.n// will be less than g.u.n//. This works (as long as g is differentiable,
and quite often when it isn&rsquo;t) because g must go down for at least small steps in this direction.
</p>
<p>But recall that our cost function is a sum of a penalty term and one error cost per example. This means the cost function
</p>
<p>looks like
</p>
<p>g.u/ D
"
</p>
<p>.1=N/
</p>
<p>N
X
</p>
<p>iD1
gi.u/
</p>
<p>#
</p>
<p>C g0.u/;
</p>
<p>as a function of u. Gradient descent would require us to form
</p>
<p>�rg.u/ D �
 "
</p>
<p>.1=N/
</p>
<p>N
X
</p>
<p>iD1
rgi.u/
</p>
<p>#
</p>
<p>Crg0.u/
!
</p>
<p>and then take a small step in this direction. But if N is large, this is unattractive, as we might have to sum a lot of terms.
</p>
<p>This happens a lot in building classifiers, where you might quite reasonably expect to deal with millions (billions; perhaps
</p>
<p>trillions) of examples. Touching each example at each step really is impractical.
</p>
<p>Stochastic gradient descent is an algorithm that replaces the exact gradient with an approximation that has a random
</p>
<p>error, but is simple and quick to compute. The term
</p>
<p>.
1
</p>
<p>N
/
</p>
<p>N
X
</p>
<p>iD1
rgi.u/:
</p>
<p>is a population mean, and we know how to deal with those. We can estimate this term by drawing a random sample (a batch)
</p>
<p>of Nb (the batch size) examples, with replacement, from the population of N examples, then computing the mean for that
</p>
<p>sample. We approximate the population mean by</p>
<p/>
</div>
<div class="page"><p/>
<p>264 11 Learning to Classify
</p>
<p>.
1
</p>
<p>Nb
/
X
</p>
<p>j2batch
</p>
<p>rgj.u/:
</p>
<p>The batch size is usually determined using considerations of computer architecture (how many examples fit neatly into
</p>
<p>cache?) or of database design (how many examples are recovered in one disk cycle?). One common choice is Nb D 1, which
is the same as choosing one example uniformly and at random. We form
</p>
<p>p
.n/
Nb
</p>
<p>D �
</p>
<p>0
</p>
<p>@
</p>
<p>2
</p>
<p>4.1=Nb/
X
</p>
<p>j2batch
</p>
<p>rgi.u/
</p>
<p>3
</p>
<p>5Crg0.u/
</p>
<p>1
</p>
<p>A
</p>
<p>and then take a small step along p
.n/
Nb
</p>
<p>. Our new point becomes
</p>
<p>u.nC1/ D u.n/ C �p.n/Nb ;
</p>
<p>where � is called the steplength (or sometimes step size or learning rate, even though it isn&rsquo;t the size or the length of the
</p>
<p>step we take, or a rate!).
</p>
<p>Because the expected value of the sample mean is the population mean, if we take many small steps along pNb , they
</p>
<p>should average out to a step backwards along the gradient. This approach is known as stochastic gradient descent because
</p>
<p>we&rsquo;re not going along the gradient, but along a random vector which is the gradient only in expectation. It isn&rsquo;t obvious that
</p>
<p>stochastic gradient descent is a good idea. Although each step is easy to take, we may need to take more steps. The question
</p>
<p>is then whether we gain in the increased speed of the step what we lose by having to take more steps. Not much is known
</p>
<p>theoretically, but in practice the approach is hugely successful for training classifiers.
</p>
<p>Choosing a steplength: Choosing a steplength � takes some work. We can&rsquo;t search for the step that gives us the best value
</p>
<p>of g, because we don&rsquo;t want to evaluate the function g (doing so involves looking at each of the gi terms). Instead, we use an
</p>
<p>� that is large at the start&mdash;so that the method can explore large changes in the values of the classifier parameters&mdash;and small
</p>
<p>steps later&mdash;so that it settles down. The choice of how � gets smaller is often known as a steplength schedule.
</p>
<p>Here are useful examples of steplength schedules. Often, you can tell how many steps are required to have seen the whole
</p>
<p>dataset; this is called an epoch. A common steplength schedule sets the steplength in the e&rsquo;th epoch to be
</p>
<p>�.e/ D m
eC n ;
</p>
<p>where m and n are constants chosen by experiment with small subsets of the dataset. When there are a lot of examples, an
</p>
<p>epoch is a long time to fix the steplength, and this approach can reduce the steplength too slowly. Instead, you can divide
</p>
<p>training into what I shall call seasons (blocks of a fixed number of iterations, smaller than epochs), and make the steplength
</p>
<p>a function of the season number.
</p>
<p>There is no good test for whether stochastic gradient descent has converged to the right answer, because natural tests
</p>
<p>involve evaluating the gradient and the function, and doing so is expensive. More usual is to plot the error as a function of
</p>
<p>iteration on the validation set, and interrupt or stop training when the error has reached an acceptable level. The error (resp.
</p>
<p>accuracy) should vary randomly (because the steps are taken in directions that only approximate the gradient) but should
</p>
<p>decrease (resp. increase) overall as training proceeds (because the steps do approximate the gradient). Figures 11.3 and 11.4
</p>
<p>show examples of these curves, which are sometimes known as learning curves.
</p>
<p>11.4.4 Searching for�
</p>
<p>We do not know a good value for �. We will obtain a value by choosing a set of different values, fitting an SVM using each
</p>
<p>value, and taking the � value that will yield the best SVM. Experience has shown that the performance of a method is not
</p>
<p>profoundly sensitive to the value of �, so that we can look at values spaced quite far apart. It is usual to take some small
</p>
<p>number (say, 1e� 4), then multiply by powers of 10 (or 3, if you&rsquo;re feeling fussy and have a fast computer). So, for example,
we might look at � 2 f1e � 4; 1e � 3; 1e � 2; 1e � 1g. We know how to fit an SVM to a particular value of � (Sect. 11.4.3).
The problem is to choose the value that yields the best SVM, and to use that to get the best classifier.
</p>
<p>We have seen a version of this problem before (Sect. 11.3.1). There, we chose from several different types of model to
</p>
<p>obtain the best naive bayes classifier. The recipe from that section is easily adapted to the current problem. We regard each</p>
<p/>
</div>
<div class="page"><p/>
<p>11.4 The Support Vector Machine 265
</p>
<p>0 50 100
0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
</p>
<p>6
</p>
<p>Season
</p>
<p>S
iz
</p>
<p>e 
o
</p>
<p>f 
w
</p>
<p>1e&minus;7
</p>
<p>1e&minus;5
</p>
<p>1e&minus;3
</p>
<p>1e&minus;1
</p>
<p>1
</p>
<p>0 20 40 60 80 100
0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>Season
</p>
<p>H
el
</p>
<p>d
 o
</p>
<p>u
t 
</p>
<p>er
ro
</p>
<p>r
</p>
<p>Fig. 11.3 On the left, the magnitude of the weight vector a at the end of each season for the first training regime described in the text. On the right,
the accuracy on held out data at the end of each season. Notice how different choices of regularization parameter lead to different magnitudes of
a; how the method isn&rsquo;t particularly sensitive to choice of regularization parameter (they change by factors of 100); how the accuracy settles down
fairly quickly; and how overlarge values of the regularization parameter do lead to a loss of accuracy
</p>
<p>0 50 100
0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
</p>
<p>6
</p>
<p>Season
</p>
<p>S
iz
</p>
<p>e 
o
f 
</p>
<p>w
</p>
<p>1e&minus;7
</p>
<p>1e&minus;5
</p>
<p>1e&minus;3
</p>
<p>1e&minus;1
</p>
<p>1
</p>
<p>0 20 40 60 80 100
0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>Season
</p>
<p>H
el
</p>
<p>d
 o
</p>
<p>u
t 
</p>
<p>er
ro
</p>
<p>r
</p>
<p>Fig. 11.4 On the left, the magnitude of the weight vector a at the end of each season for the second training regime described in the text. On the
right, the accuracy on held out data at the end of each season. Notice how different choices of regularization parameter lead to different magnitudes
of a; how the method isn&rsquo;t particularly sensitive to choice of regularization parameter (they change by factors of 100); how the accuracy settles
down fairly quickly; and how overlarge values of the regularization parameter do lead to a loss of accuracy
</p>
<p>different � value as representing a different model. We split the data into two pieces: one is a training set, used for fitting and
</p>
<p>choosing models; the other is a test set, used for evaluating the final chosen model.
</p>
<p>Now for each value of �, compute the cross-validated error of an SVM using that � on the training set. Do this by
</p>
<p>repeatedly splitting the training set into two pieces (training and validation); fitting the SVM with that � to the training
</p>
<p>piece using stochastic gradient descent; evaluating the error on the validation piece; and averaging these errors. Now use the
</p>
<p>cross-validated error to choose the best � value. Very often this just means you choose the value that produces the lowest
</p>
<p>cross-validated error, but there might be cases where two values produce about the same error and one is preferred for some
</p>
<p>other reason. Notice that you can compute the standard deviation of the cross-validated error as well as the mean, so you can
</p>
<p>tell whether differences between cross-validated errors are significant.
</p>
<p>Now take the entire training set, and use this to fit an SVM for the chosen � value. This should be (a little) better than any
</p>
<p>of the SVMs obtained in the cross-validation, because it uses (slightly) more data. Finally, evaluate the resulting SVM on the
</p>
<p>test set.
</p>
<p>This procedure is rather harder to describe than to do (there&rsquo;s a pretty natural set of nested loops here). There are some
</p>
<p>strong advantages. First, the estimate of how well a particular SVM type works is unbiased, because we evaluated on data</p>
<p/>
</div>
<div class="page"><p/>
<p>266 11 Learning to Classify
</p>
<p>not used on training. Second, once you have chosen the cross-validation parameter, the SVM you fit is the best you can fit
</p>
<p>because you used all the training set to obtain it. Finally, your estimate of how well that particular SVM works is unbiased,
</p>
<p>too, because you obtained it using data that wasn&rsquo;t used to train or to select a model.
</p>
<p>11.4.5 Example: Training an SVMwith Stochastic Gradient Descent
</p>
<p>I have summarized the SVM training procedure in a set of boxes, below. You should be aware that the recipe there admits
</p>
<p>many useful variations, though. One useful practical trick is to rescale the feature vector components so each has unit
</p>
<p>variance. This doesn&rsquo;t change anything conceptual as the best choice of decision boundary for rescaled data is easily derived
</p>
<p>from the best choice for unscaled, and vice versa. Rescaling very often makes stochastic gradient descent perform better
</p>
<p>because the method takes steps that are even in each component.
</p>
<p>It is quite usual to use packages to fit SVM&rsquo;s, and good packages may use a variety of tricks which we can&rsquo;t go into to
</p>
<p>make training more efficient. Nonetheless, you should have a grasp of the overall process, because it follows a pattern that is
</p>
<p>useful for training other models (among other things, most deep networks are trained using this pattern).
</p>
<p>Procedure 11.1 (Training an SVM: Overall) Start with a dataset containing N pairs .xi; yi/. Each xi is a d-
</p>
<p>dimensional feature vector, and each yi is a label, either 1 or �1. Optionally, rescale the xi so that each component
has unit variance. Choose a set of possible values of the regularization weight �. Separate the dataset into two sets:
</p>
<p>test and training. Reserve the test set. For each value of the regularization weight, use the training set to estimate the
</p>
<p>accuracy of an SVM with that � value, using cross-validation as in Procedure 11.2 and stochastic gradient descent.
</p>
<p>Use this information to choose �0, the best value of � (usually, the one that yields the highest accuracy). Now use the
</p>
<p>training set to fit the best SVM using �0 as the regularization constant. Finally, use the test set to compute the accuracy
</p>
<p>or error rate of that SVM, and report that
</p>
<p>Procedure 11.2 (Training an SVM: Estimating the Accuracy) Repeatedly: split the training dataset into two
</p>
<p>components (training and validation), at random; use the training component to train an SVM; and compute the
</p>
<p>accuracy on the validation component. Now average the resulting accuracy values.
</p>
<p>Procedure 11.3 (Training an SVM: Stochastic Gradient Descent) Obtain u D .a; b/ by stochastic gradient descent
on the cost function
</p>
<p>g.u/ D
"
</p>
<p>.1=N/
</p>
<p>N
X
</p>
<p>iD1
gi.u/
</p>
<p>#
</p>
<p>C g0.u/
</p>
<p>where g0.u/ D �.aTa/=2 and gi.u/ D max.0; 1 � yi
�
</p>
<p>aTxi C b
�
</p>
<p>/.
</p>
<p>Do so by first choosing a fixed number of items per batch Nb, the number of steps per season Ns, and the number
</p>
<p>of steps k to take before evaluating the model (this is usually a lot smaller than Ns). Choose a random start point. Now
</p>
<p>iterate:
</p>
<p>&bull; Update the stepsize. In the s&rsquo;th season, the step size is typically �.s/ D m
sCn for constants m and n chosen by
</p>
<p>small-scale experiments.
</p>
<p>&bull; Split the training dataset into a training part and a validation part. This split changes each season. Use the validation
</p>
<p>set to get an unbiased estimate of error during that season&rsquo;s training.
</p>
<p>&bull; Now, until the end of the season (i.e. until you have taken Ns steps):
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>11.4 The Support Vector Machine 267
</p>
<p>&ndash; Take k steps. Each step is taken by selecting a batch of Nb data items uniformly and at random from the training
</p>
<p>part for that season. Write D for this set. Now compute
</p>
<p>p.n/ D � 1
Nb
</p>
<p> 
</p>
<p>X
</p>
<p>i2D
rgi.u.n//
</p>
<p>!
</p>
<p>� �u.n/;
</p>
<p>and update the model by computing
</p>
<p>u.nC1/ D u.n/ C �p.n/
</p>
<p>&ndash; Evaluate the current model u.n/ by computing the accuracy on the validation part for that season. Plot the accuracy
</p>
<p>as a function of step number.
</p>
<p>There are two ways to stop. You can choose a fixed number of seasons (or of epochs) and stop when that is done.
</p>
<p>Alternatively, you can watch the error plot and stop when the error reaches some level or meets some criterion.
</p>
<p>Here is an example in some detail. I downloaded the dataset at http://archive.ics.uci.edu/ml/datasets/Adult. This dataset
</p>
<p>apparently contains 48,842 data items, but I worked with only the first 32,000. Each consists of a set of numeric and
</p>
<p>categorical features describing a person, together with whether their annual income is larger than or smaller than 50 K$.
</p>
<p>I ignored the categorical features to prepare these figures. This isn&rsquo;t wise if you want a good classifier, but it&rsquo;s fine for an
</p>
<p>example. I used these features to predict whether income is over or under 50 K$. I split the data into 5000 test examples, and
</p>
<p>27,000 training examples. It&rsquo;s important to do so at random. There are 6 numerical features. I subtracted the mean (which
</p>
<p>doesn&rsquo;t usually make much difference) and rescaled each so that the variance was 1 (which is often very important).
</p>
<p>Setting up stochastic gradient descent: We have estimates a.n/ and b.n/ of the classifier parameters, and we want to
</p>
<p>improve the estimates. I used a batch size of Nb D 1. Pick the r&rsquo;th example at random. The gradient is
</p>
<p>r
�
</p>
<p>max.0; 1 � yr
�
</p>
<p>aTxr C b
�
</p>
<p>/C �
2
</p>
<p>aTa
</p>
<p>�
</p>
<p>:
</p>
<p>Assume that yk
�
</p>
<p>aTxr C b
�
</p>
<p>&gt; 1. In this case, the classifier predicts a score with the right sign, and a magnitude that is greater
</p>
<p>than one. Then the first term is zero, and the gradient of the second term is easy. Now if yk
�
</p>
<p>aTxr C b
�
</p>
<p>&lt; 1, we can ignore the
</p>
<p>max, and the first term is 1� yr
�
</p>
<p>aTxr C b
�
</p>
<p>; the gradient is again easy. If yr
�
</p>
<p>aTxr C b
�
</p>
<p>D 1, there are two distinct values we
could choose for the gradient, because the max term isn&rsquo;t differentiable. It does not matter which value we choose because
</p>
<p>this situation hardly ever happens. We choose a steplength �, and update our estimates using this gradient. This yields:
</p>
<p>a.nC1/ D a.n/ � �
�
</p>
<p>�a if yk
�
</p>
<p>aTxk C b
�
</p>
<p>� 1
�a � ykx otherwise
</p>
<p>and
</p>
<p>b.nC1/ D b.n/ � �
�
</p>
<p>0 if yk
�
</p>
<p>aTxk C b
�
</p>
<p>� 1
�yk otherwise
</p>
<p>:
</p>
<p>Training: I used two different training regimes. In the first training regime, there were 100 seasons. In each season, I
</p>
<p>applied 426 steps. For each step, I selected one data item uniformly at random (sampling with replacement), then stepped
</p>
<p>down the gradient. This means the method sees a total of 42,600 data items. This means that there is a high probability it has
</p>
<p>touched each data item once (27,000 isn&rsquo;t enough, because we are sampling with replacement, so some items get seen more
</p>
<p>than once). I chose five different values for the regularization parameter and trained with a steplength of 1=.0:01 � sC 50/,
where s is the season. At the end of each season, I computed aTa and the accuracy (fraction of examples correctly classified)
</p>
<p>of the current classifier on the held out test examples. Figure 11.3 shows the results. You should notice that the accuracy
</p>
<p>changes slightly each season; that for larger regularizer values aTa is smaller; and that the accuracy settles down to about 0.8
</p>
<p>very quickly.
</p>
<p>In the second training regime, there were 100 seasons. In each season, I applied 50 steps. For each step, I selected one
</p>
<p>data item uniformly at random (sampling with replacement), then stepped down the gradient. This means the method sees a</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Adult">http://archive.ics.uci.edu/ml/datasets/Adult</a></div>
</div>
<div class="page"><p/>
<p>268 11 Learning to Classify
</p>
<p>total of 5000 data items, and about 3000 unique data items&mdash;it hasn&rsquo;t seen the whole training set. I chose five different values
</p>
<p>for the regularization parameter and trained with a steplength of 1=.0:01 � sC 50/, where s is the season. At the end of each
season, I computed aTa and the accuracy (fraction of examples correctly classified) of the current classifier on the held out
</p>
<p>test examples. Figure 11.4 shows the results.
</p>
<p>This is an easy classification example. Points worth noting are
</p>
<p>&bull; the accuracy makes large changes early, then settles down to make slight changes each season;
</p>
<p>&bull; quite large changes in regularization constant have small effects on the outcome, but there is a best choice;
</p>
<p>&bull; for larger values of the regularization constant, aTa is smaller;
</p>
<p>&bull; there isn&rsquo;t much difference between the two training regimes;
</p>
<p>&bull; and the method doesn&rsquo;t need to see all the training data to produce a classifier that is about as good as it would be if the
</p>
<p>method had seen all training data.
</p>
<p>All of these points are relatively typical of SVM&rsquo;s trained using stochastic gradient descent with very large datasets.
</p>
<p>Remember this: Linear SVM&rsquo;s are a go-to classifier. When you have a binary classification problem, the first step
</p>
<p>should be to try a linear SVM. Training with stochastic gradient descent is straightforward, and extremely effective.
</p>
<p>Finding an appropriate value of the regularization constant requires an easy search. There is an immense quantity of
</p>
<p>good software available.
</p>
<p>11.4.6 Multi-Class Classification with SVMs
</p>
<p>I have shown how one trains a linear SVM to make a binary prediction (i.e. predict one of two outcomes). But what if there
</p>
<p>are three, or more, labels? In principle, you could write a binary code for each label, then use a different SVM to predict each
</p>
<p>bit of the code. It turns out that this doesn&rsquo;t work terribly well, because an error by one of the SVM&rsquo;s is usually catastrophic.
</p>
<p>There are two methods that are widely used. In the all-vs-all approach, we train a binary classifier for each pair of classes.
</p>
<p>To classify an example, we present it to each of these classifiers. Each classifier decides which of two classes the example
</p>
<p>belongs to, then records a vote for that class. The example gets the class label with the most votes. This approach is simple,
</p>
<p>but scales very badly with the number of classes (you have to build O.N2/ different SVM&rsquo;s for N classes).
</p>
<p>In the one-vs-all approach, we build a binary classifier for each class. This classifier must distinguish its class from all
</p>
<p>the other classes. We then take the class with the largest classifier score. One can think up quite good reasons this approach
</p>
<p>shouldn&rsquo;t work. For one thing, the classifier isn&rsquo;t told that you intend to use the score to tell similarity between classes. In
</p>
<p>practice, the approach works rather well and is quite widely used. This approach scales a bit better with the number of classes
</p>
<p>(O.N/).
</p>
<p>Remember this: It is straightforward to build a multi-class classifier out of binary classifiers. Any decent SVM package
</p>
<p>will do this for you.
</p>
<p>11.5 Classifying with Random Forests
</p>
<p>One way to build a classifier is to use a sequence of simple tests, where each test is allowed to use the results of all previous
</p>
<p>tests. This class of rule can be drawn as a tree (Fig. 11.5), where each node represents a test, and the edges represent the
</p>
<p>possible outcomes of the test. To classify a test item with such a tree, you present it to the first node; the outcome of the test
</p>
<p>determines which node it goes to next; and so on, until the example arrives at a leaf. When it does arrive at a leaf, we label
</p>
<p>the test item with the most common label in the leaf. This object is known as a decision tree. Notice one attractive feature of
</p>
<p>this decision tree: it deals with multiple class labels quite easily, because you just label the test item with the most common
</p>
<p>label in the leaf that it arrives at when you pass it down the tree.</p>
<p/>
</div>
<div class="page"><p/>
<p>11.5 Classifying with Random Forests 269
</p>
<p>Fig. 11.5 This&mdash;the household
robot&rsquo;s guide to obstacles&mdash;is a
typical decision tree. I have
labelled only one of the outgoing
branches, because the other is the
negation. So if the obstacle
moves, bites, but isn&rsquo;t furry, then
it&rsquo;s a toddler. In general, an item
is passed down the tree until it
hits a leaf. It is then labelled with
the leaf&rsquo;s label
</p>
<p>cat
</p>
<p>dogtoddler
</p>
<p>chair leg
</p>
<p>boxsofa
</p>
<p>moves
</p>
<p>bites
</p>
<p>furry
</p>
<p>big
</p>
<p>cardboard
</p>
<p>Fig. 11.6 A straightforward
decision tree, illustrated in two
ways. On the left, I have given the
rules at each split; on the right, I
have shown the data points in two
dimensions, and the structure that
the tree produces in the feature
space
</p>
<p>&minus;5 0 5
&minus;5
</p>
<p>0
</p>
<p>5
</p>
<p>y&gt;.32
</p>
<p>x&gt;1.06x&gt;-0.58
</p>
<p>x.o+
</p>
<p>Figure 11.6 shows a simple 2D dataset with four classes, next to a decision tree that will correctly classify at least the
</p>
<p>training data. Actually classifying data with a tree like this is straightforward. We take the data item, and pass it down the
</p>
<p>tree. Notice it can&rsquo;t go both left and right, because of the way the tests work. This means each data item arrives at a single
</p>
<p>leaf. We take the most common label at the leaf, and give that to the test item. In turn, this means we can build a geometric
</p>
<p>structure on the feature space that corresponds to the decision tree. I have illustrated that structure in Fig. 11.6, where the
</p>
<p>first decision splits the feature space in half (which is why the term split is used so often), and then the next decisions split
</p>
<p>each of those halves into two.
</p>
<p>The important question is how to get the tree from data. We will always use a binary tree, because it&rsquo;s easier to describe,
</p>
<p>because it&rsquo;s usual, and because it doesn&rsquo;t change anything important in the algorithm. Each non-leaf node has a decision
</p>
<p>function, which takes data items and returns either 1 or �1. We train the tree by thinking about its effect on the training data.
We pass the whole pool of training data into the root. The decision function at any non-leaf node splits incoming data into
</p>
<p>two pools, one for the left child (all the data that the decision function labels 1) and the other for the right child (ditto, �1).
This goes on recursively until finally, each leaf contains a pool of data, which it can&rsquo;t split because it is a leaf.
</p>
<p>To classify a data item, we pass it down the tree, applying decision functions to choose left or right, until we reach a
</p>
<p>leaf. Any data item that reaches a particular leaf will get that leaf&rsquo;s label. This means that we would like all the items in
</p>
<p>the training data pool at a given leaf to agree on a label. But it matters how we achieve this. For example, a very large tree
</p>
<p>with one data item in each leaf will have excellent training accuracy, but is likely to have poor test accuracy. Intuition should
</p>
<p>suggest that good test accuracy can be obtained by a tree where each leaf has a large pool of data that all has one label.
</p>
<p>All this means that it is quite difficult to determine the best tree. A really powerful alternative is to build a many simple
</p>
<p>trees using algorithms that incorporate a great deal of randomness. The algorithms ensure that we get a different tree each
</p>
<p>time we train a tree on a dataset. None of the individual trees will be particularly good (they are often referred to as &ldquo;weak
</p>
<p>learners&rdquo;). But with many such trees (a decision forest), we can allow each to vote; the class that gets the most votes, wins.
</p>
<p>This strategy is extremely effective.</p>
<p/>
</div>
<div class="page"><p/>
<p>270 11 Learning to Classify
</p>
<p>11.5.1 Building a Decision Tree: General Algorithm
</p>
<p>There are many algorithms for building decision trees. I will sketch an approach chosen for simplicity and effectiveness; be
</p>
<p>aware there are others. I will leave out enough detail that you probably couldn&rsquo;t implement a program from my description.
</p>
<p>I&rsquo;ve used this approach because most people never need to implement a program (there are excellent packages available),
</p>
<p>and need only a moderate understanding of how one could be built. For the people who want more detail, there is more in
</p>
<p>the mathematical material in the end (Sect. 15.3).
</p>
<p>Training the tree uses a straightforward algorithm. First, we choose a class of decision functions to use at each node.
</p>
<p>It turns out that a very effective decision function is to choose a single feature at random, then test whether its value is
</p>
<p>larger than, or smaller than a threshold (some minor adjustments are required if the feature chosen isn&rsquo;t ordinal). For this
</p>
<p>approach to work, one needs to be quite careful about the choice of threshold, which is what we describe in the next section.
</p>
<p>Surprisingly, being clever about the choice of feature doesn&rsquo;t seem add a great deal of value. We won&rsquo;t spend more time on
</p>
<p>other kinds of decision function, though there are lots.
</p>
<p>Now assume we use a decision function as described, and we know how to choose a threshold. We start with the root
</p>
<p>node, then recursively either split the pool of data at that node, passing the left pool left and the right pool right, or stop
</p>
<p>splitting and return. Splitting involves choosing a decision function from the class to give the &ldquo;best&rdquo; split for a leaf. The main
</p>
<p>questions are how to choose the best split (next section), and when to stop.
</p>
<p>Stopping is relatively straightforward. Quite simple strategies for stopping are very good. It is hard to choose a decision
</p>
<p>function with very little data, so we must stop splitting when there is too little data at a node. We can tell this is the case by
</p>
<p>testing the amount of data against a threshold, chosen by experiment. If all the data at a node belongs to a single class, there
</p>
<p>is no point in splitting. Finally, constructing a tree that is too deep tends to result in generalization problems, so we usually
</p>
<p>allow no more than a fixed depth D of splits. In applications, D can be quite small. It is quite common to use D D 1 (when
the chopped down tree is, rather unhappily, known as a decision stump).
</p>
<p>11.5.2 Building a Decision Tree: Choosing a Split
</p>
<p>Choosing the best splitting threshold is more complicated. Figure 11.7 shows two possible splits of a pool of training data.
</p>
<p>One is quite obviously a lot better than the other. In the good case, the split separates the pool into positives and negatives.
</p>
<p>In the bad case, each side of the split has the same number of positives and negatives. We cannot usually produce splits as
</p>
<p>good as the good case here. What we are looking for is a split that will make the proper label more certain.
</p>
<p>Figure 11.8 shows a more subtle case to illustrate this. The splits in this figure are obtained by testing the horizontal
</p>
<p>feature against a threshold. In one case, the left and the right pools contain about the same fraction of positive (&lsquo;x&rsquo;) and
</p>
<p>negative (&lsquo;o&rsquo;) examples. In the other, the left pool is all positive, and the right pool is mostly negative. This is the better
</p>
<p>choice of threshold. If we were to label any item on the left side positive and any item on the right side negative, the error
</p>
<p>rate would be fairly small. If you count, the best error rate for the informative split is 20% on the training data, and for the
</p>
<p>uninformative split it is 40% on the training data.
</p>
<p>But we need some way to score the splits, so we can tell which threshold is best. Notice that, in the uninformative
</p>
<p>case, knowing that a data item is on the left (or the right) does not tell me much more about the data than I already knew
</p>
<p>before I had the split. In this case, we have that p.1jleft pool, uninformative/ D 2=3 � 3=5 D p.1jparent pool/ and
p.1jright pool, uninformative/ D 1=2 � 3=5 D p.1jparent pool/. For the informative split, knowing a data item is on the left
classifies it completely, and knowing that it is on the right allows us to classify it an error rate of 1=3. The informative split
</p>
<p>means that my uncertainty about what class the data item belongs to is significantly reduced if I know whether it goes left
</p>
<p>or right. To choose a good threshold, we need a score of how informative a split is. The score is known as the information
</p>
<p>gain (where larger is better). The details of how to compute information gain are involved, and of little interest unless you
</p>
<p>need to implement a decision tree; I&rsquo;ve put this in the mathematical material at the end (Sect. 15.3.2).
</p>
<p>We now have a relatively straightforward blueprint for an algorithm, which I have put in a box. It&rsquo;s a blueprint, because
</p>
<p>there are a variety of ways in which it can be revised and changed.
</p>
<p>Procedure 11.4 (Building a Decision Tree: Overall) We have a dataset containing N pairs .xi; yi/. Each xi is a
</p>
<p>d-dimensional feature vector, and each yi is a label. Call this dataset a pool. Now recursively apply the following
</p>
<p>procedure:
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>11.5 Classifying with Random Forests 271
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
</p>
<p>o
</p>
<p>Informative split
x
</p>
<p>x
</p>
<p>x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
</p>
<p>o
</p>
<p>Less informative split
</p>
<p>x
x
</p>
<p>x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>Fig. 11.7 Two possible splits of a pool of training data. Positive data is represented with an &lsquo;x&rsquo;, negative data with a &lsquo;o&rsquo;. Notice that if we split this
pool with the informative line, all the points on the left are &lsquo;o&rsquo;s, and all the points on the right are &lsquo;x&rsquo;s. This is an excellent choice of split&mdash;once
we have arrived in a leaf, everything has the same label. Compare this with the less informative split. We started with a node that was half &lsquo;x&rsquo; and
half &lsquo;o&rsquo;, and now have two nodes each of which is half &lsquo;x&rsquo; and half &lsquo;o&rsquo;&mdash;this isn&rsquo;t an improvement, because we do not know more about the label
as a result of the split
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>Less informative splitInformative split
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>o
o
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>x
x
</p>
<p>x
x
</p>
<p>x
</p>
<p>Fig. 11.8 Two possible splits of a pool of training data. Positive data is represented with an &lsquo;x&rsquo;, negative data with a &lsquo;o&rsquo;. Notice that if we split
this pool with the informative line, all the points on the left are &lsquo;x&rsquo;s, and two-thirds of the points on the right are &lsquo;o&rsquo;s. This means that knowing
which side of the split a point lies would give us a good basis for estimating the label. In the less informative case, about two-thirds of the points
on the left are &lsquo;x&rsquo;s and about half on the right are &lsquo;x&rsquo;s&mdash;knowing which side of the split a point lies is much less useful in deciding what the label is0
</p>
<p>&bull; If the pool is too small, or if all items in the pool have the same label, or if the depth of the recursion has reached
</p>
<p>a limit, stop.
</p>
<p>&bull; Otherwise, search the features for a good split that divides the pool into two, then apply this procedure to each child.
</p>
<p>We search for a good split by the following procedure:
</p>
<p>&bull; Choose a subset of the feature components at random. Typically, one uses a subset whose size is about the square
</p>
<p>root of the feature dimension.
</p>
<p>&bull; For each component of this subset, search for a good split. If the component is ordinal, do so using the procedure
</p>
<p>of box 11.5, otherwise use the procedure of box 11.6.</p>
<p/>
</div>
<div class="page"><p/>
<p>272 11 Learning to Classify
</p>
<p>Procedure 11.5 (Splitting an Ordinal Feature) We search for a good split on a given ordinal feature by the following
</p>
<p>procedure:
</p>
<p>&bull; Select a set of possible values for the threshold.
</p>
<p>&bull; For each value split the dataset (every data item with a value of the component below the threshold goes left, others
</p>
<p>go right), and compute the information gain for the split.
</p>
<p>Keep the threshold that has the largest information gain.
</p>
<p>A good set of possible values for the threshold will contain values that separate the data &ldquo;reasonably&rdquo;. If the pool
</p>
<p>of data is small, you can project the data onto the feature component (i.e. look at the values of that component alone),
</p>
<p>then choose the N � 1 distinct values that lie between two data points. If it is big, you can randomly select a subset of
the data, then project that subset on the feature component and choose from the values between data points.
</p>
<p>Procedure 11.6 (Splitting a Non-Ordinal Feature) Split the values this feature takes into sets pools by flipping an
</p>
<p>unbiased coin for each value&mdash;if the coin comes up H, any data point with that value goes left, and if it comes up T ,
</p>
<p>any data point with that value goes right. Repeating this procedure F times, computing the information gain for each
</p>
<p>split, then keep the split that has the best information gain. We choose F in advance, and it usually depends on the
</p>
<p>number of values the categorical variable can take.
</p>
<p>11.5.3 Forests
</p>
<p>Rather than build the best possible tree, we have built a tree efficiently, but with a number of random choices. If we were
</p>
<p>to rebuild the tree, we would obtain a different result. This suggests the following extremely effective strategy: build many
</p>
<p>trees, and classify by merging their results.
</p>
<p>There are two important strategies for building and evaluating decision forests. I am not aware of evidence strongly
</p>
<p>favoring one over the other, but different software packages use different strategies, and you should be aware of the options.
</p>
<p>In one strategy, we separate labelled data into a training and a test set. We then build multiple decision trees, training each
</p>
<p>using the whole training set. Finally, we evaluate the forest on the test set. In this approach, the forest has not seen some
</p>
<p>fraction of the available labelled data, because we used it to test. However, each tree has seen every training data item.
</p>
<p>Procedure 11.7 (Building a Decision Forest) We have a dataset containing N pairs .xi; yi/. Each xi is a d-dimensional
</p>
<p>feature vector, and each yi is a label. Separate the dataset into a test set and a training set. Train multiple distinct decision
</p>
<p>trees on the training set, recalling that the use of a random set of components to find a good split means you will obtain
</p>
<p>a distinct tree each time.
</p>
<p>In the other strategy, sometimes called bagging, each time we train a tree we randomly subsample the labelled data with
</p>
<p>replacement, to yield a training set the same size as the original set of labelled data. Notice that there will be duplicates in
</p>
<p>this training set, which is like a bootstrap replicate. This training set is often called a bag. We keep a record of the examples
</p>
<p>that do not appear in the bag (the &ldquo;out of bag&rdquo; examples). Now to evaluate the forest, we evaluate each tree on its out of bag
</p>
<p>examples. Each example gets votes for labels from each tree for which it is out of bag. Now classify each example using
</p>
<p>these votes, and compute the error for every example. In this approach, the entire forest has seen all labelled data, yet we get
</p>
<p>a good estimate of error, because no tree in the forest has been evaluated on data used to train it.</p>
<p/>
</div>
<div class="page"><p/>
<p>11.5 Classifying with Random Forests 273
</p>
<p>Procedure 11.8 (Building a Decision Forest Using Bagging) We have a dataset containing N pairs .xi; yi/. Each xi
is a d-dimensional feature vector, and each yi is a label. Now build k bootstrap replicates of the training data set. Train
</p>
<p>one decision tree on each replicate.
</p>
<p>Once we have a forest, we must classify test data items. There are two major strategies. The simplest is to classify the
</p>
<p>item with each tree in the forest, then take the class with the most votes. This is effective, but discounts some evidence that
</p>
<p>might be important. For example, imagine one of the trees in the forest has a leaf with many data items with the same class
</p>
<p>label; another tree has a leaf with exactly one data item in it. One might not want each leaf to have the same vote.
</p>
<p>Procedure 11.9 (Classification with a Decision Forest) Given a test example x, pass it down each tree of the forest.
</p>
<p>Now choose one of the following strategies.
</p>
<p>&bull; Each time the example arrives at a leaf, record one vote for the label that occurs most often at the leaf. Now choose
</p>
<p>the label with the most votes.
</p>
<p>&bull; Each time the example arrives at a leaf, record Nl votes for each of the labels that occur at the leaf, where Nl is the
</p>
<p>number of times the label appears in the training data at the leaf. Now choose the label with the most votes.
</p>
<p>An alternative strategy that takes this observation into account is to pass the test data item down each tree. When it arrives
</p>
<p>at a leaf, we record one vote for each of the training data items in that leaf. The vote goes to the class of the training data
</p>
<p>item. Finally, we take the class with the most votes. This approach allows big, accurate leaves to dominate the voting process.
</p>
<p>Both strategies are in use, and I am not aware of compelling evidence that one is always better than the other. This may be
</p>
<p>because the randomness in the training process makes big, accurate leaves uncommon in practice.
</p>
<p>Worked example 11.3 (Classifying Heart Disease Data) Build a random forest classifier to classify the &ldquo;heart&rdquo;
</p>
<p>dataset from the UC Irvine machine learning repository. The dataset is at http://archive.ics.uci.edu/ml/datasets/
</p>
<p>Heart+Disease. There are several versions. You should look at the processed Cleveland data, which is in the file
</p>
<p>&ldquo;processed.cleveland.data.txt&rdquo;.
</p>
<p>Solution I used the R random forest package. This uses a bagging strategy. This package makes it quite simple to fit a
</p>
<p>random forest, as you can see. In this dataset, variable 14 (V14) takes the value 0, 1, 2, 3 or 4 depending on the severity
</p>
<p>of the narrowing of the arteries. Other variables are physiological and physical measurements pertaining to the patient
</p>
<p>(read the details on the website). I tried to predict all five levels of variable 14, using the random forest as a multivariate
</p>
<p>classifier. This works rather poorly, as the out-of-bag class confusion matrix below shows. The total out-of-bag error
</p>
<p>rate was 45%.
</p>
<p>True Predict
</p>
<p>Class
</p>
<p>0 1 2 3 4 error
</p>
<p>0 151 7 2 3 1 7.9%
</p>
<p>1 32 5 9 9 0 91%
</p>
<p>2 10 9 7 9 1 81%
</p>
<p>3 6 13 9 5 2 86%
</p>
<p>4 2 3 2 6 0 100%
This is the example of a class confusion matrix from Table 11.1. Fairly clearly, one can predict narrowing or
</p>
<p>no narrowing from the features, but not the degree of narrowing (at least, not with a random forest). So it is
</p>
<p>natural to quantize variable 14 to two levels, 0 (meaning no narrowing), and 1 (meaning any narrowing, so the
</p>
<p>(continued)</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Heart+Disease">http://archive.ics.uci.edu/ml/datasets/Heart+Disease</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Heart+Disease">http://archive.ics.uci.edu/ml/datasets/Heart+Disease</a></div>
</div>
<div class="page"><p/>
<p>274 11 Learning to Classify
</p>
<p>original value could have been 1, 2, or 3). I then built a random forest to predict this quantized variable from the
</p>
<p>other variables. The total out-of-bag error rate was 19%, and I obtained the following out-of-bag class confusion matrix
</p>
<p>True Predict
</p>
<p>0 1 Class error
</p>
<p>0 138 26 16%
</p>
<p>1 31 108 22%
</p>
<p>Notice that the false positive rate (16%, from 26=164) is rather better than the false negative rate (22%). You might
</p>
<p>wonder whether it is better to train on and predict 0; : : : ; 4, then quantize the predicted value. If you do this, you will
</p>
<p>find you get a false positive rate of 7:9%, but a false negative rate that is much higher (36%, from 50=139). In this
</p>
<p>application, a false negative is likely more of a problem than a false positive, so the tradeoff is unattractive.
</p>
<p>Remember this: Random forests are straightforward to build, and very effective. They can predict any kind of label.
</p>
<p>Good software implementations are easily available.
</p>
<p>11.6 You Should
</p>
<p>11.6.1 Remember These Definitions
</p>
<p>Classifier . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
</p>
<p>11.6.2 Remember These Terms
</p>
<p>classifier . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
</p>
<p>feature vector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
</p>
<p>error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>total error rate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>accuracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>Bayes risk . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>baselines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>comparing to chance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>false positive rate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>false negative rate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>sensitivity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>specificity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>class confusion matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>class error rate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>training error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
</p>
<p>test error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
</p>
<p>overfitting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
</p>
<p>selection bias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
</p>
<p>generalizing badly . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
</p>
<p>validation set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
</p>
<p>unbiased . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
</p>
<p>cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
</p>
<p>fold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255</p>
<p/>
</div>
<div class="page"><p/>
<p>11.6 You Should 275
</p>
<p>leave-one-out cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
</p>
<p>whitening . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256
</p>
<p>approximate nearest neighbor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256
</p>
<p>likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
</p>
<p>class conditional probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
</p>
<p>prior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
</p>
<p>posterior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
</p>
<p>decision boundary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
</p>
<p>hinge loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
</p>
<p>support vector machine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
</p>
<p>SVM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
</p>
<p>regularization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
</p>
<p>regularizer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
</p>
<p>regularization parameter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
</p>
<p>descent direction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
</p>
<p>line search . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
</p>
<p>gradient descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
</p>
<p>Stochastic gradient descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
</p>
<p>batch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
</p>
<p>batch size . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
</p>
<p>steplength . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
</p>
<p>step size . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
</p>
<p>learning rate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
</p>
<p>steplength schedule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
</p>
<p>epoch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
</p>
<p>learning curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
</p>
<p>all-vs-all . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
</p>
<p>one-vs-all . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
</p>
<p>decision tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
</p>
<p>decision function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
</p>
<p>decision forest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
</p>
<p>information gain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
</p>
<p>bagging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
</p>
<p>bag . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
</p>
<p>11.6.3 Remember These Facts
</p>
<p>11.6.4 Use These Procedures
</p>
<p>To fit an SVM with stochastic gradient descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
</p>
<p>To train an SVM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
</p>
<p>To estimate accuracy of an SVM with known � . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
</p>
<p>Overall approach to build a decision tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
</p>
<p>To split an ordinal feature in a decision tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
</p>
<p>To split a non-ordinal feature in a decision tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
</p>
<p>To build a decision forest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
</p>
<p>To build a decision forest using bagging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
</p>
<p>To classify with a decision forest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273</p>
<p/>
</div>
<div class="page"><p/>
<p>276 11 Learning to Classify
</p>
<p>11.6.5 Be Able to
</p>
<p>&bull; build a nearest neighbors classifier using your preferred software package, and produce a cross-validated estimate of its
</p>
<p>error rate or its accuracy;
</p>
<p>&bull; build a naive bayes classifier using your preferred software package, and produce a cross-validated estimate of its error
</p>
<p>rate or its accuracy;
</p>
<p>&bull; build an SVM using your preferred software package, and produce a cross-validated estimate of its error rate or its
</p>
<p>accuracy;
</p>
<p>&bull; write code to train an SVM using stochastic gradient descent, and produce a cross-validated estimate of its error rate or
</p>
<p>its accuracy;
</p>
<p>&bull; and build a decision forest using your preferred software package, and produce a cross-validated estimate of its error rate
</p>
<p>or its accuracy.
</p>
<p>Programming Exercises
</p>
<p>11.1 The UC Irvine machine learning data repository hosts a famous collection of data on whether a patient has diabetes
</p>
<p>(the Pima Indians dataset), originally owned by the National Institute of Diabetes and Digestive and Kidney Diseases and
</p>
<p>donated by Vincent Sigillito. This can be found at http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes. This data
</p>
<p>has a set of attributes of patients, and a categorical variable telling whether the patient is diabetic or not. This is an exercise
</p>
<p>oriented to users of R, because you can use some packages to help.
</p>
<p>(a) Build a simple naive Bayes classifier to classify this data set. You should hold out 20% of the data for evaluation, and
</p>
<p>use the other 80% for training. You should use a normal distribution to model each of the class-conditional distributions.
</p>
<p>You should write this classifier yourself.
</p>
<p>(b) Now use the caret and klaR packages to build a naive bayes classifier for this data. The caret package does cross-
</p>
<p>validation (look at train) and can be used to hold out data. The klaR package can estimate class-conditional densities
</p>
<p>using a density estimation procedure that I will describe much later in the course. Use the cross-validation mechanisms
</p>
<p>in caret to estimate the accuracy of your classifier.
</p>
<p>(c) Now install SVMLight, which you can find at http://svmlight.joachims.org, via the interface in klaR (look for
</p>
<p>svmlight in the manual) to train and evaluate an SVM to classify this data. You don&rsquo;t need to understand much
</p>
<p>about SVM&rsquo;s to do this&mdash;we&rsquo;ll do that in following exercises. You should hold out 20% of the data for evaluation, and
</p>
<p>use the other 80% for training.
</p>
<p>11.2 The UC Irvine machine learning data repository hosts a collection of data on student performance in Portugal,
</p>
<p>donated by Paulo Cortez, University of Minho, in Portugal. You can find this data at https://archive.ics.uci.edu/ml/datasets/
</p>
<p>Student+Performance. It is described in P. Cortez and A. Silva. &ldquo;Using Data Mining to Predict Secondary School Student
</p>
<p>Performance,&rdquo; In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC
</p>
<p>2008) pp. 5-12, Porto, Portugal, April, 2008,
</p>
<p>There are two datasets (for grades in mathematics and for grades in Portugese). There are 30 attributes each for 649
</p>
<p>students, and 3 values that can be predicted (G1, G2 and G3). Of these, ignore G1 and G2.
</p>
<p>(a) Use the mathematics dataset. Take the G3 attribute, and quantize this into two classes, G3 &gt; 12 and G3 � 12. Build
and evaluate a naive bayes classifier that predicts G3 from all attributes except G1 and G2. You should build this
</p>
<p>classifier from scratch (i.e. DON&rsquo;T use the packages described in the code snippets). For binary attributes, you should
</p>
<p>use a binomial model. For the attributes described as &ldquo;numeric&rdquo;, which take a small set of values, you should use a
</p>
<p>multinomial model. For the attributes described as &ldquo;nominal&rdquo;, which take a small set of values, you should again use
</p>
<p>a multinomial model. Ignore the &ldquo;absence&rdquo; attribute. Estimate accuracy by cross-validation. You should use at least
</p>
<p>tenfolds, excluding 15% of the data at random to serve as test data, and average the accuracy over those folds. Report
</p>
<p>the mean and standard deviation of the accuracy over the folds.
</p>
<p>(b) Now revise your classifier of the previous part so that, for the attributes described as &ldquo;numeric&rdquo;, which take a small set
</p>
<p>of values, you use a multinomial model. For the attributes described as &ldquo;nominal&rdquo;, which take a small set of values, you
</p>
<p>should still use a multinomial model. Ignore the &ldquo;absence&rdquo; attribute. Estimate accuracy by cross-validation. You should</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes">http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes</a></div>
<div class="annotation"><a href="http://svmlight.joachims.org">http://svmlight.joachims.org</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Student+Performance">https://archive.ics.uci.edu/ml/datasets/Student+Performance</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Student+Performance">https://archive.ics.uci.edu/ml/datasets/Student+Performance</a></div>
</div>
<div class="page"><p/>
<p>Programming Exercises 277
</p>
<p>use at least tenfolds, excluding 15% of the data at random to serve as test data, and average the accuracy over those
</p>
<p>folds. Report the mean and standard deviation of the accuracy over the folds.
</p>
<p>(c) Which classifier do you believe is more accurate and why?
</p>
<p>11.3 The UC Irvine machine learning data repository hosts a collection of data on heart disease. The data was collected
</p>
<p>and supplied by Andras Janosi, M.D., of the Hungarian Institute of Cardiology, Budapest; William Steinbrunn, M.D., of
</p>
<p>the University Hospital, Zurich, Switzerland; Matthias Pfisterer, M.D., of the University Hospital, Basel, Switzerland; and
</p>
<p>Robert Detrano, M.D., Ph.D., of the V.A. Medical Center, Long Beach and Cleveland Clinic Foundation. You can find this
</p>
<p>data at https://archive.ics.uci.edu/ml/datasets/Heart+Disease.
</p>
<p>Use the processed Cleveland dataset, where there are a total of 303 instances with 14 attributes each. The irrelevant
</p>
<p>attributes described in the text have been removed in these. The 14&rsquo;th attribute is the disease diagnosis. There are records
</p>
<p>with missing attributes, and you should drop these.
</p>
<p>(a) Take the disease attribute, and quantize this into two classes, num D 0 and num &gt; 0. Build and evaluate a naive bayes
classifier that predicts the class from all other attributes Estimate accuracy by cross-validation. You should use at least
</p>
<p>tenfolds, excluding 15% of the data at random to serve as test data, and average the accuracy over those folds. Report
</p>
<p>the mean and standard deviation of the accuracy over the folds.
</p>
<p>(b) Now revise your classifier to predict each of the possible values of the disease attribute (0&ndash;4 as I recall). Estimate
</p>
<p>accuracy by cross-validation. You should use at least tenfolds, excluding 15% of the data at random to serve as test data,
</p>
<p>and average the accuracy over those folds. Report the mean and standard deviation of the accuracy over the folds.
</p>
<p>11.4 The UC Irvine machine learning data repository hosts a collection of data on breast cancer diagnostics, donated by Olvi
</p>
<p>Mangasarian, Nick Street, and William H. Wolberg. You can find this data at http://archive.ics.uci.edu/ml/datasets/Breast+
</p>
<p>Cancer+Wisconsin+(Diagnostic). For each record, there is an id number, 10 continuous variables, and a class (benign or
</p>
<p>malignant). There are 569 examples. Separate this dataset randomly into 100 validation, 100 test, and 369 training examples.
</p>
<p>Write a program to train a support vector machine on this data using stochastic gradient descent. You should not use a
</p>
<p>package to train the classifier (you don&rsquo;t really need one), but your own code. You should ignore the id number, and use the
</p>
<p>continuous variables as a feature vector. You should scale these variables so each has unit variance. You should search for an
</p>
<p>appropriate value of the regularization constant, trying at least the values � D Œ1e � 3; 1e � 2; 1e � 1; 1&#141;. Use the validation
set for this search.
</p>
<p>You should use at least 50 epochs of at least 100 steps each. In each epoch, you should separate out 50 training examples
</p>
<p>at random for evaluation. You should compute the accuracy of the current classifier on the set held out for the epoch every
</p>
<p>10 steps. You should produce:
</p>
<p>(a) A plot of the accuracy every 10 steps, for each value of the regularization constant.
</p>
<p>(b) Your estimate of the best value of the regularization constant, together with a brief description of why you believe that
</p>
<p>is a good value.
</p>
<p>(c) Your estimate of the accuracy of the best classifier on held out data
</p>
<p>11.5 The UC Irvine machine learning data repository hosts a collection of data on adult income, donated by Ronny Kohavi
</p>
<p>and Barry Becker. You can find this data at https://archive.ics.uci.edu/ml/datasets/Adult For each record, there is a set of
</p>
<p>continuous attributes, and a class �50 K or &lt;50 K. There are 48,842 examples. You should use only the continous attributes
(see the description on the web page) and drop examples where there are missing values of the continuous attributes. Separate
</p>
<p>the resulting dataset randomly into 10% validation, 10% test, and 80% training examples.
</p>
<p>Write a program to train a support vector machine on this data using stochastic gradient descent. You should not use a
</p>
<p>package to train the classifier (you don&rsquo;t really need one), but your own code. You should ignore the id number, and use the
</p>
<p>continuous variables as a feature vector. You should scale these variables so that each has unit variance. You should search
</p>
<p>for an appropriate value of the regularization constant, trying at least the values � D Œ1e � 3; 1e � 2; 1e � 1; 1&#141;. Use the
validation set for this search
</p>
<p>You should use at least 50 epochs of at least 300 steps each. In each epoch, you should separate out 50 training examples
</p>
<p>at random for evaluation. You should compute the accuracy of the current classifier on the set held out for the epoch every
</p>
<p>30 steps. You should produce:</p>
<p/>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Heart+Disease">https://archive.ics.uci.edu/ml/datasets/Heart+Disease</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Adult ">https://archive.ics.uci.edu/ml/datasets/Adult </a></div>
</div>
<div class="page"><p/>
<p>278 11 Learning to Classify
</p>
<p>(a) A plot of the accuracy every 30 steps, for each value of the regularization constant.
</p>
<p>(b) Your estimate of the best value of the regularization constant, together with a brief description of why you believe that
</p>
<p>is a good value.
</p>
<p>(c) Your estimate of the accuracy of the best classifier on held out data
</p>
<p>11.6 The UC Irvine machine learning data repository hosts a collection of data on the whether p53 expression is active or
</p>
<p>inactive. You can find out what this means, and more information about the dataset, by reading: Danziger, S.A., Baronio, R.,
</p>
<p>Ho, L., Hall, L., Salmon, K., Hatfield, G.W., Kaiser, P., and Lathrop, R.H. &ldquo;Predicting Positive p53 Cancer Rescue Regions
</p>
<p>Using Most Informative Positive (MIP) Active Learning,&rdquo; PLOS Computational Biology, 5(9), 2009; Danziger, S.A., Zeng, J.,
</p>
<p>Wang, Y., Brachmann, R.K. and Lathrop, R.H. &ldquo;Choosing where to look next in a mutation sequence space: Active Learning
</p>
<p>of informative p53 cancer rescue mutants&rdquo;, Bioinformatics, 23(13), 104&ndash;114, 2007; and Danziger, S.A., Swamidass, S.J.,
</p>
<p>Zeng, J., Dearth, L.R., Lu, Q., Chen, J.H., Cheng, J., Hoang, V.P., Saigo, H., Luo, R., Baldi, P., Brachmann, R.K. and
</p>
<p>Lathrop, R.H. &ldquo;Functional census of mutation sequence spaces: the example of p53 cancer rescue mutants,&rdquo; IEEE/ACM
</p>
<p>transactions on computational biology and bioinformatics, 3, 114&ndash;125, 2006.
</p>
<p>You can find this data at https://archive.ics.uci.edu/ml/datasets/p53+Mutants. There are a total of 16,772 instances, with
</p>
<p>5409 attributes per instance. Attribute 5409 is the class attribute, which is either active or inactive. There are several versions
</p>
<p>of this dataset. You should use the version K8.data.
</p>
<p>(a) Train an SVM to classify this data, using stochastic gradient descent. You will need to drop data items with missing
</p>
<p>values. You should estimate a regularization constant using cross-validation, trying at least three values. Your training
</p>
<p>method should touch at least 50% of the training set data. You should produce an estimate of the accuracy of this
</p>
<p>classifier on held out data consisting of 10% of the dataset, chosen at random.
</p>
<p>(b) Now train a naive bayes classifier to classify this data. You should produce an estimate of the accuracy of this classifier
</p>
<p>on held out data consisting of 10% of the dataset, chosen at random.
</p>
<p>(c) Compare your classifiers. Which one is better? why?
</p>
<p>11.7 The UC Irvine machine learning data repository hosts a collection of data on whether a mushroom is edible, donated
</p>
<p>by Jeff Schlimmer and to be found at http://archive.ics.uci.edu/ml/datasets/Mushroom. This data has a set of categorical
</p>
<p>attributes of the mushroom, together with two labels (poisonous or edible). Use the R random forest package (as in the
</p>
<p>example in the chapter) to build a random forest to classify a mushroom as edible or poisonous based on its attributes.
</p>
<p>(a) Produce a class-confusion matrix for this problem. If you eat a mushroom based on your classifier&rsquo;s prediction it is
</p>
<p>edible, what is the probability of being poisoned?
</p>
<p>MNIST Exercises
</p>
<p>The following exercises are elaborate, but rewarding. The MNIST dataset is a dataset of 60,000 training and 10,000 test
</p>
<p>examples of handwritten digits, originally constructed by Yann Lecun, Corinna Cortes, and Christopher J.C. Burges. It is
</p>
<p>very widely used to check simple methods. There are 10 classes in total (&ldquo;0&rdquo; to &ldquo;9&rdquo;). This dataset has been extensively
</p>
<p>studied, and there is a history of methods and feature constructions at https://en.wikipedia.org/wiki/MNIST_database and
</p>
<p>at http://yann.lecun.com/exdb/mnist/. You should notice that the best methods perform extremely well. The original dataset
</p>
<p>is at http://yann.lecun.com/exdb/mnist/. It is stored in an unusual format, described in detail on that website. Writing your
</p>
<p>own reader is pretty simple, but web search yields readers for standard packages. There is reader code in matlab available (at
</p>
<p>least) at http://ufldl.stanford.edu/wiki/index.php/Using_the_MNIST_Dataset. There is reader code for R available (at least)
</p>
<p>at https://stackoverflow.com/questions/21521571/how-to-read-mnist-database-in-r.
</p>
<p>The dataset consists of 28�28 images. These were originally binary images, but appear to be grey level images as a result
of some anti-aliasing. I will ignore mid grey pixels (there aren&rsquo;t many of them) and call dark pixels &ldquo;ink pixels&rdquo;, and light
</p>
<p>pixels &ldquo;paper pixels&rdquo;. The digit has been centered in the image by centering the center of gravity of the image pixels. Here
</p>
<p>are some options for re-centering the digits that I will refer to in the exercises.
</p>
<p>&bull; Untouched: do not re-center the digits, but use the images as is.
</p>
<p>&bull; Bounding box: construct an b � b bounding box so that the horizontal (resp. vertical) range of ink pixels is centered in
the box.</p>
<p/>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/p53+Mutants">https://archive.ics.uci.edu/ml/datasets/p53+Mutants</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Mushroom">http://archive.ics.uci.edu/ml/datasets/Mushroom</a></div>
<div class="annotation"><a href="https://en.wikipedia.org/wiki/MNIST_database">https://en.wikipedia.org/wiki/MNIST_database</a></div>
<div class="annotation"><a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></div>
<div class="annotation"><a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></div>
<div class="annotation"><a href="http://ufldl.stanford.edu/wiki/index.php/Using_the_MNIST_Dataset">http://ufldl.stanford.edu/wiki/index.php/Using_the_MNIST_Dataset</a></div>
<div class="annotation"><a href="https://stackoverflow.com/questions/21521571/how-to-read-mnist-database-in-r">https://stackoverflow.com/questions/21521571/how-to-read-mnist-database-in-r</a></div>
</div>
<div class="page"><p/>
<p>Programming Exercises 279
</p>
<p>&bull; Stretched bounding box: construct an b � b bounding box so that the horizontal (resp. vertical) range of ink pixels runs
the full horizontal (resp. vertical) range of the box. Obtaining this representation will involve rescaling image pixels: you
</p>
<p>find the horizontal and vertical ink range, cut that out of the original image, then resize the result to b � b.
</p>
<p>Once the image has been re-centered, you can compute features. Here are some options for constructing features that I will
</p>
<p>refer to in the exercises.
</p>
<p>&bull; Raw pixels: use the raw pixel values from images.
</p>
<p>&bull; PCA: project images onto the first d principal components computed for the entire dataset.
</p>
<p>&bull; Local PCA: first, compute the first d principal components for each digit class separately. Now for any image, compute a
</p>
<p>10d dimensional feature vector by, for each class, subtracting that class mean from the image, then projecting the image
</p>
<p>onto the d principal components for that class. Finally, stack all 10 d dimensional features you get. This measures how
</p>
<p>much the difference between the image and the class mean looks like the difference between images of that class and the
</p>
<p>class mean.
</p>
<p>11.8 Investigate classifying MNIST using naive bayes. Use the procedures of Sect. 11.3.1 to compare four cases on raw
</p>
<p>pixel image features. These cases are obtained by choosing either normal model or binomial model for every feature, and
</p>
<p>untouched images or stretched bounding box images.
</p>
<p>(a) Which is the best case?
</p>
<p>(b) How accurate is the best case? (remember, the answer to this is not obtained by taking the best accuracy from the
</p>
<p>previous subexercise&mdash;check Sect. 11.3.1 if you&rsquo;re vague on this point).
</p>
<p>11.9 Investigate classifying MNIST using nearest neighbors. You will use approximate nearest neighbors. Obtain
</p>
<p>the FLANN package for approximate nearest neighbors from http://www.cs.ubc.ca/~mariusm/index.php/FLANN/
</p>
<p>FLANN. To use this package, you should consider first using a function that builds an index for the training dataset
</p>
<p>(flann_build_index(), or variants), then querying with your test points (flann_find_nearest_neighbors
</p>
<p>_index(), or variants). The alternative (flann_find_nearest_neighbors(), etc.) builds the index then throws it
</p>
<p>away, which can be inefficient if you don&rsquo;t use it correctly.
</p>
<p>(a) Compare untouched raw pixels with bounding box raw pixels and with stretched bounding box raw pixels. Which works
</p>
<p>better? Why? Is there a difference in query times?
</p>
<p>(b) Does rescaling each feature (i.e. each pixel value) so that it has unit variance improve either classifier from the previous
</p>
<p>subexercise?
</p>
<p>(c) Plot accuracy against d for a variety of d values for stretched bounding box PCA. You should use some large values of
</p>
<p>d, reasonably close to 784 (D 28 � 28). Compare this to the accuracy of stretched bounding box raw pixels (equivalent
to d D 784).
</p>
<p>(d) Does rescaling each feature (i.e. each projected direction) so that it has unit variance improve results from the previous
</p>
<p>subexercise?
</p>
<p>11.10 Investigate classifying MNIST using an SVM. Compare the following four cases: untouched raw pixels; stretched
</p>
<p>bounding box raw pixels; stretched bounding box PCA; and stretched bounding box local PCA. Which works best? Why?
</p>
<p>11.11 Investigate classifying MNIST using a decision forest. Using the same parameters for your forest construction (i.e.
</p>
<p>same depth of tree; same number of trees; etc.), compare the following four cases: untouched raw pixels; stretched bounding
</p>
<p>box raw pixels; stretched bounding box PCA; and stretched bounding box local PCA. Which works best? Why?
</p>
<p>11.12 If you&rsquo;ve done all four previous exercises, you&rsquo;re likely tired of MNIST, but very well informed. Compare your
</p>
<p>methods to the table of methods at http://yann.lecun.com/exdb/mnist/. What improvements could you make?</p>
<p/>
<div class="annotation"><a href="http://www.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN">http://www.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN</a></div>
<div class="annotation"><a href="http://www.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN">http://www.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN</a></div>
<div class="annotation"><a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></div>
</div>
<div class="page"><p/>
<p>12Clustering: Models of High Dimensional Data
</p>
<p>High-dimensional data comes with problems. Data points tend not to be where you think; they can scattered quite far apart,
</p>
<p>and can be quite far from the mean. There is an important rule of thumb for coping with high dimensional data: Use simple
</p>
<p>models. One very good, very simple, model for high dimensional data is to assume that it consists of multiple blobs. To
</p>
<p>build models like this, we must determine which datapoints belong to which blob by collecting together data points that are
</p>
<p>close and forming blobs out of them. This process is known as clustering. It is so useful that there is a very wide range of
</p>
<p>clustering algorithms
</p>
<p>One important application for clustering methods is building features. If we need to classify signals (eg audio, images,
</p>
<p>video, accelerometer data) that have repeated structures in them, clustering pieces of signal in the training set will expose
</p>
<p>what structures are repeated commonly. A new signal can be described by recording how often each cluster center appears in
</p>
<p>the signal. This process yields a convenient and effective feature description of the signal that can be fed into the classifiers
</p>
<p>from the previous chapter.
</p>
<p>Clustering is a somewhat puzzling activity. It is extremely useful to cluster data, and it seems to be quite important to
</p>
<p>do it reasonably well. But it surprisingly hard to give crisp criteria for a good (resp. bad) clustering of a dataset. Usually,
</p>
<p>clustering is part of building a model, and the main way to know that the clustering algorithm is good is that the resulting
</p>
<p>model is useful.
</p>
<p>12.1 The Curse of Dimension
</p>
<p>High dimensional models display uninituitive behavior (or, rather, it can take years to make your intuition see the true
</p>
<p>behavior of high-dimensional models as natural). In these models, most data lies in places you don&rsquo;t expect. A very simple
</p>
<p>example dataset will illustrate these problems. The dataset is an IID sample from a uniform probability density in a cube,
</p>
<p>with edge length two, centered on the origin. At every point in the cube, this density P.x/ D 1
2d
</p>
<p>(and it is zero elsewhere).
</p>
<p>The mean of this density is at the origin, which we write as 0. Each component of every xi must lie in the range Œ�1; 1&#141;.
</p>
<p>12.1.1 Minor Banes of Dimension
</p>
<p>It is difficult to build histogram representations for high dimensional datasets, because you end up with too many boxes. In the
</p>
<p>case of our cube, imagine we wish to divide each dimension in half (i.e. between Œ�1; 0&#141; and between Œ0; 1&#141;), which would
produce a very crude histogram. Then we must have 2d boxes. This presents two problems. First, we will have difficulty
</p>
<p>representing this number of boxes. Second, unless we are exceptionally lucky, most boxes must be empty because we will
</p>
<p>not have 2d data items. Splitting each dimension into a larger number of pieces just makes things a great deal worse.
</p>
<p>Covariance matrices are hard to work with because the number of entries in the matrix grows as the square of the
</p>
<p>dimension. This means the matrix can get big and difficult to store. More important, the amount of data we need to get
</p>
<p>an accurate estimate of all the entries in the matrix grows fast. As we are estimating more numbers, we need more data to
</p>
<p>be confident that our estimates are reasonable. There are a variety of straightforward work-arounds for this effect. In some
</p>
<p>cases, we have so much data there is no need to worry. In other cases, we assume that the covariance matrix has a particular
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_12
</p>
<p>281</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_12">https://doi.org/10.1007/978-3-319-64410-3_12</a></div>
</div>
<div class="page"><p/>
<p>282 12 Clustering: Models of High Dimensional Data
</p>
<p>parametric form, and just estimate those parameters. There are two strategies that are usual. In one, we assume that the
</p>
<p>covariance matrix is diagonal, and estimate only the diagonal entries. In the other, we assume that the covariance matrix is a
</p>
<p>scaled version of the identity, and just estimate this scale. You should see these strategies as acts of desperation, to be used
</p>
<p>only when computing the full covariance matrix seems to produce more problems than using these approaches.
</p>
<p>12.1.2 The Curse: Data Isn&rsquo;t Where You Think It Is
</p>
<p>The first surprising fact about high dimensional data is that most of the data can lie quite far away from the mean. For
</p>
<p>example, we can divide our cube into two pieces. A.�/ consists of all data items where every component of the data has a
</p>
<p>value in the range Œ�.1� �/; .1� �/&#141;. B.�/ consists of all the rest of the data. If you think of the data set as forming a cubical
orange, then B.�/ is the rind (which has thickness �) and A.�/ is the fruit.
</p>
<p>Your intuition will tell you that there is more fruit than rind. It is wrong, as a simple calculation shows. We can
</p>
<p>compute P.fx 2 A.�/g/ and P.fx 2 B.�/g/. These probabilities tell us the probability a data item lies in the fruit (resp.
rind). P.fx 2 A.�/g/ is easy to compute as
</p>
<p>P.fx 2 A.�/g/ D .2.1 � �///d
�
</p>
<p>1
</p>
<p>2d
</p>
<p>�
</p>
<p>D .1 � �/d
</p>
<p>and
P.fx 2 B.�/g/ D 1 � P.fx 2 A.�/g/ D 1 � .1 � �/d:
</p>
<p>But notice that, as d ! 1,
P.fx 2 A.�/g/ ! 0:
</p>
<p>This means that, for large d, we expect most of the data to be in B.�/ (the rind is bigger than the fruit). Equivalently, for large
</p>
<p>d, we expect that at least one component of each data item is close to either 1 or �1. In high dimensions, volume doesn&rsquo;t
behave like you think, and so you do not expect the rind to dominate. The fact that the dataset is a cube, rather than a sphere,
</p>
<p>makes the calculations easier (most people don&rsquo;t remember the expressions for volume of high dimensional spheres). But
</p>
<p>the shape has nothing to do with the real problem.
</p>
<p>The fact that P.fx 2 A.�/g/ is small for large d suggests that much data is quite far from the origin, because most of it
lies in B.�/. This turns out to be true. It is easy to compute the average of the squared distance of data from the origin. We
</p>
<p>want
</p>
<p>E
�
</p>
<p>xTx
�
</p>
<p>D E
"
</p>
<p>X
</p>
<p>i
</p>
<p>x2i
</p>
<p>#
</p>
<p>D
X
</p>
<p>i
</p>
<p>E
�
</p>
<p>x2i
�
</p>
<p>D
X
</p>
<p>i
</p>
<p>Z
</p>
<p>cube
x2i P.x/dx:
</p>
<p>Now each component of x is independent, so that P.x/ D P.x1/P.x2/ : : :P.xd/. Now we substitute, to get
</p>
<p>E
�
</p>
<p>xTx
�
</p>
<p>D
X
</p>
<p>i
</p>
<p>Z 1
</p>
<p>�1
x2i P.xi/dxi D
</p>
<p>X
</p>
<p>i
</p>
<p>1
</p>
<p>2
</p>
<p>Z 1
</p>
<p>�1
x2i dxi
</p>
<p>D d
3
;
</p>
<p>so as d gets bigger, most data points will be further and further from the origin. Worse, as d gets bigger, data points tend to
</p>
<p>get further and further from one another. We can see this by computing the average of the squared distance of data points
</p>
<p>from one another. Write u for one data point and v for another; we can compute
</p>
<p>E
�
</p>
<p>d.u; v/2
�
</p>
<p>D E
�
</p>
<p>.u � v/T.u � v/
�
</p>
<p>D E
�
</p>
<p>uTu
�
</p>
<p>C E
�
</p>
<p>vTv
�
</p>
<p>� 2E
�
</p>
<p>uTv
�</p>
<p/>
</div>
<div class="page"><p/>
<p>12.2 Clustering Data 283
</p>
<p>but since u and v are independent, we have E
�
</p>
<p>uTv
�
</p>
<p>D EŒu&#141;TEŒv&#141; D 0. This means
</p>
<p>E
�
</p>
<p>d.u; v/2
�
</p>
<p>D 2d
3
:
</p>
<p>This means that, for large d, we expect our data points to be quite far apart, too.
</p>
<p>Remember this: High dimensional data does not behave in a way that is consistent with most people&rsquo;s intuition. Points
</p>
<p>are always close to the boundary and further apart than you think. This property makes a nuisance of itself in a variety
</p>
<p>of ways. The most important is that only the simplest models work well in high dimensions.
</p>
<p>12.2 Clustering Data
</p>
<p>In high dimensional spaces, there is &ldquo;too much&rdquo; space for any reasonable amount of data to fill it up (that&rsquo;s what the curse
</p>
<p>of dimension is about). It is ineffective to cut space up into boxes and see how much data lies in each box: too many boxes,
</p>
<p>and not enough data. An alternative is to break up the dataset, rather than the space. We form clusters&mdash;coherent blobs of
</p>
<p>datapoints that are near one another. A cluster center is a summary of an entire cluster. One natural summary is the average
</p>
<p>of the elements of the cluster. Another natural summary is a data item that is close to all the items in the cluster.
</p>
<p>Clusters have a variety of uses. For example, we could form a representation that will function very like a histogram by
</p>
<p>reporting the center of each cluster and the number of data items in each cluster. As another example, chunks of data that
</p>
<p>are similar should appear in the same cluster, so cluster centers can be used to build a dictionary of patterns that repeat in a
</p>
<p>dataset (Sect. 12.4).
</p>
<p>12.2.1 Agglomerative and Divisive Clustering
</p>
<p>There are two natural recipes to produce clustering algorithms. In agglomerative clustering, you start with each data item
</p>
<p>being a cluster, and then merge clusters recursively to yield a good clustering (Procedure 12.1). The difficulty here is that
</p>
<p>we need to know a good way to measure the distance between clusters, which can be somewhat harder than the distance
</p>
<p>between points. There are three standard choices. In single-link clustering, the distance between the two closest elements is
</p>
<p>the inter-cluster distance. This tends to produce &ldquo;long&rdquo; clusters. In complete-link clustering, the maximum distance between
</p>
<p>an element of the first cluster and one of the second is the inter-cluster distance. This tends to yield rounded clusters. In group
</p>
<p>average clustering, an average of distances between elements in the clusters is the distance. This also tends to yield rounded
</p>
<p>clusters.
</p>
<p>Procedure 12.1 (Agglomerative Clustering) Choose an inter-cluster distance. Make each point a separate cluster.
</p>
<p>Now, until the clustering is satisfactory,
</p>
<p>&bull; Merge the two clusters with the smallest inter-cluster distance.
</p>
<p>In divisive clustering, you start with the entire data set being a cluster, and then split clusters recursively to yield a good
</p>
<p>clustering (Procedure 12.2). The difficulty here is we need to know some criterion for splitting clusters. This tends to be
</p>
<p>something that follows from the logic of the application, because the ideal is an efficient method to find a natural split in a
</p>
<p>large dataset. We won&rsquo;t pursue divisive clustering further.</p>
<p/>
</div>
<div class="page"><p/>
<p>284 12 Clustering: Models of High Dimensional Data
</p>
<p>d
is
</p>
<p>ta
n
ce
</p>
<p>1    2   3   4   5    6
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
</p>
<p>6
</p>
<p>1 cluster
</p>
<p>2 clusters
</p>
<p>6 clusters
</p>
<p>Fig. 12.1 Left, a data set; right, a dendrogram obtained by agglomerative clustering using single-link clustering. This representation makes it
possible to guess how many clusters there are and to get some insight into how good the clusters are. Select a particular value of distance (vertical
axis); now draw a a horizontal line at that distance. This will break the dendrogram into separate connected pieces, each of which is a cluster. I
have marked some example distances on the dendrogram. Notice there is quite a large range of distances that yield two clusters. This is evidence
that the two clusters are quite far apart, compared to their size, and is usually taken to mean that there is quite a large range of scales over which
two clusters is a good clustering of the dataset
</p>
<p>Procedure 12.2 (Divisive Clustering) Choose a splitting criterion. Regard the entire dataset as a single cluster. Now,
</p>
<p>until the clustering is satisfactory,
</p>
<p>&bull; choose a cluster to split;
</p>
<p>&bull; then split this cluster into two parts.
</p>
<p>We need to know when to stop either algorithm. This is an intrinsically difficult task if there is no model for the process
</p>
<p>that generated the clusters. Both agglomerative and divisive clustering produce a hierarchy of clusters. Usually, this hierarchy
</p>
<p>is displayed to a user in the form of a dendrogram&mdash;a representation of the structure of the hierarchy of clusters that displays
</p>
<p>inter-cluster distances&mdash;and an appropriate choice of clusters is made from the dendrogram (see the example in Fig. 12.1).
</p>
<p>Figure 12.1 illustrates some important properties of clustering, which many people find frustrating. There isn&rsquo;t a single
</p>
<p>right answer. Instead, different clusterings of a dataset might be acceptable; so, for example, in Fig. 12.1, point 6 might
</p>
<p>belong to a cluster with points 4 and 5, or it might reasonably be on its own. Whether an answer is good or not depends on
</p>
<p>appropriate scales of variation in the data. For example, in Fig. 12.1, if the distance between points 1 and 2 is &ldquo;large&rdquo;, there
</p>
<p>are likely six different clusters; but if the distance between points 2 and 6 is &ldquo;small&rdquo;, then there is likely one cluster. Whether
</p>
<p>a distance is &ldquo;large&rdquo; or &ldquo;small&rdquo; depends entirely on the application the data came from.
</p>
<p>Worked example 12.1 (Agglomerative Clustering) Cluster the seed dataset from the UC Irvine Machine Learning
</p>
<p>Dataset Repository (you can find it at http://archive.ics.uci.edu/ml/datasets/seeds).
</p>
<p>Solution This dataset consists of seven geometric parameters measured for wheat kernels of three types of wheat. It
</p>
<p>was donated by M. Charytanowicz, J. Niewczas, P. Kulczycki, P. A. Kowalski, S. Lukasik and S. Zak. You can find
</p>
<p>more information on the webpage. For this example, I used Matlab, but many programming environments will provide
</p>
<p>tools that are useful for agglomerative clustering. I show a dendrogram in Fig. 12.2). I deliberately forced Matlab to
</p>
<p>plot the whole dendrogram, which accounts for the crowded look of the figure (you can allow it to merge small leaves,
</p>
<p>etc.). As you can see from the dendrogram and from Fig. 12.3, this data clusters rather well. There isn&rsquo;t any choice of
</p>
<p>(continued)</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/seeds">http://archive.ics.uci.edu/ml/datasets/seeds</a></div>
</div>
<div class="page"><p/>
<p>12.2 Clustering Data 285
</p>
<p>173207169155192203188186145159162195205193209206146156174177179160151184187150175191176178194190153158167182163183196181154170157144201210197148164168165171172149199161198141143185152147166180200202189142204208  1 59 35 50 56 25 18 47  5 23 26  3  8 29 22  6 57 39 45 48 49 21 54 14 15  7 33 51 53  4 12 46 34 68 16 41 42 30 55 67 69 27 70 32 20 64  2 58 28 43 66 13 19  9 10 36 37 38 11 44 63 24 60 31 65 52 71 77108137 75 96122101123134140 72 76 73 81 74132118107 92 93105 97104112119106 85 98116100113111124131 86 99 88 87110102128117126127109120103 79 95 82 94 80130133135 84 91129125136114138139 61 62 78115 90 83121 89 17 40
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>1.2
</p>
<p>1.4
</p>
<p>1.6
</p>
<p>1.8
</p>
<p>2
</p>
<p>Fig. 12.2 A dendrogram obtained from the seed dataset, using single link clustering. Recall that the data points are on the horizontal axis, and
that the vertical axis is distance; there is a horizontal line linking two clusters that get merged, established at the height at which they&rsquo;re merged. I
have plotted the entire dendrogram, despite the fact it&rsquo;s a bit crowded at the bottom, because you can now see how clearly the data set clusters into
a small set of clusters&mdash;there are a small number of vertical &ldquo;runs&rdquo;
</p>
<p>distance that yields three cleanly separated clusters, even though there are three types of wheat here. At the same time,
</p>
<p>there is a fair range of distances that will yield three rather big clusters with a number of other small or even single
</p>
<p>point clusters. You can interpret this in terms of the feature space. The blobs of data corresponding to each type of
</p>
<p>wheat overlap somewhat, so some data items might be close to more than one blob. Furthermore, because the blobs
</p>
<p>are scattered, there are some points on the fringes of the blobs that are far from all others. This is pretty typical of real
</p>
<p>data. It&rsquo;s optimistic to expect that, because there are three types of wheat, there will be three clear and distinct clusters.
</p>
<p>12.2.2 Clustering and Distance
</p>
<p>You may have noticed the following, occasionally useful, property of agglomerative clustering. There is no need for a feature
</p>
<p>vector for any of the objects you wish to cluster; it is enough to have a table of distances between all pairs of objects. For
</p>
<p>example, you could collect data giving the distances between cities, without knowing where the cities are (as in Sect. 10.4.3,
</p>
<p>particularly Fig. 10.16), then try and cluster using this data. As another example, you could collect data giving similarities
</p>
<p>between breakfast items as in Sect. 10.4.3. These will be in the range Œ0; 1&#141;, where 0 is completely dissimilar and 1 is exactly
</p>
<p>the same. It is straightforward to turn the similarities into distances by taking the negative logarithm. This gives a useable
</p>
<p>table of distances. So it is possible to build a dendrogram and a clustering for the breakfast items of Sect. 10.4.3 without ever
</p>
<p>knowing a feature vector for any item. In this case, the distance is meaningful because you collected the distance information.</p>
<p/>
</div>
<div class="page"><p/>
<p>286 12 Clustering: Models of High Dimensional Data
</p>
<p>Fig. 12.3 A clustering of the
seed dataset, using agglomerative
clustering, single link distance,
and requiring a maximum of 30
clusters. I have plotted each
cluster with a distinct marker
(though some markers differ only
by color). Notice that there are a
set of fairly natural isolated
clusters. The original data is
seven dimensional, which
presents plotting problems; I
show a scatter plot on the first
two principal components
(though I computed distances for
clustering in the original seven
dimensional space)
</p>
<p>&minus;4 &minus;3 &minus;2 &minus;1 0 1 2 3 4 5
&minus;8
</p>
<p>&minus;6
</p>
<p>&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>In the more usual case, we have a feature vector for each object. This doesn&rsquo;t necessarily mean that the distance between
</p>
<p>feature vectors is a good guide to the difference between objects. If the features are poorly scaled, distances (measured in
</p>
<p>the usual way) between data points may not be a good representation of their similarity. This is quite an important point. For
</p>
<p>example, imagine we are clustering data representing brick walls. The features might contain several distances: the spacing
</p>
<p>between the bricks, the length of the wall, the height of the wall, and so on. If these distances are given in the same set of
</p>
<p>units, we could have real trouble. For example, assume that the units are centimeters. Then the spacing between bricks is of
</p>
<p>the order of one or two centimeters, but the heights of the walls will be in the hundreds of centimeters. In turn, this means
</p>
<p>that the distance between two datapoints is likely to be completely dominated by the height and length data. This could be
</p>
<p>what we want, but it might also not be a good thing.
</p>
<p>There are some ways to manage this issue. One is to know what the features measure, and know how they should be
</p>
<p>scaled. Usually, this happens because you have a deep understanding of your data. If you don&rsquo;t (which happens!), then it is
</p>
<p>often a good idea to try and normalize the scale of the data set. There are two good strategies. The simplest is to translate
</p>
<p>the data so that it has zero mean (this is just for neatness&mdash;translation doesn&rsquo;t change distances), then scale each direction
</p>
<p>so that it has unit variance. Another possibility, as in nearest neighbors (Sect. 11.2.1), is to transform the features so that the
</p>
<p>covariance matrix is the identity (this is sometimes known as whitening; the method follows from the ideas of Chap. 10).
</p>
<p>Remember this: High dimensional datasets can be represented by a collection of clusters. Each cluster is a blob of
</p>
<p>data points that are near one another, and is summarized by a cluster center. The choice of distance between data points
</p>
<p>has a significant effect on clustering. Agglomerative clustering starts with each data point a cluster, then recursively
</p>
<p>merges. There are three main ways to compute the distance between clusters. Divisive clustering starts with all in one
</p>
<p>cluster, then recursively splits clusters. The choice of splitting method depends quite strongly on application. Either
</p>
<p>method yields a dendrogram, which is a helpful summary of distances between points and clusters. For datasets that
</p>
<p>are small enough to plot the dendrogram, a look at a dendrogram can yield some helpful information about the data
</p>
<p>and good clusterings.</p>
<p/>
</div>
<div class="page"><p/>
<p>12.3 The K-Means Algorithm and Variants 287
</p>
<p>12.3 The K-Means Algorithm and Variants
</p>
<p>Assume we have a dataset that, we believe, forms many clusters that look like blobs. We would like to choose a clustering
</p>
<p>so that points are &ldquo;close&rdquo; to their cluster centers. It is natural to want to minimize the sum of squared distances from each
</p>
<p>point to its cluster center. We can even guess an algorithm for doing this. If we knew where the center of each of the clusters
</p>
<p>was, it would be easy to tell which cluster each data item belonged to&mdash;it would belong to the cluster with the closest center.
</p>
<p>Similarly, if we knew which cluster each data item belonged to, it would be easy to tell where the cluster centers were&mdash;they&rsquo;d
</p>
<p>be the mean of the data items in the cluster. This is the point closest to every point in the cluster.
</p>
<p>We can formalize this fairly easily by writing an expression for the squared distance between data points and their cluster
</p>
<p>centers. Assume that we know how many clusters there are in the data, and write k for this number. There are N data items.
</p>
<p>The ith data item to be clustered is described by a feature vector xi. We write cj for the center of the jth cluster. We write ıi;j
for a discrete variable that records which cluster a data item belongs to, so
</p>
<p>ıi;j D
�
</p>
<p>1 if xi belongs to cluster j
</p>
<p>0 otherwise
</p>
<p>We require that every data item belongs to exactly one cluster, so that
P
</p>
<p>j ıi;j D 1. We require that every cluster contain at
least one point, because we assumed we knew how many clusters there were, so we must have that
</p>
<p>P
</p>
<p>i ıi;j &gt; 0 for every j.
</p>
<p>We can now write the sum of squared distances from data points to cluster centers as
</p>
<p>ˆ.ı; c/ D
X
</p>
<p>i;j
</p>
<p>ıi;j
�
</p>
<p>.xi � cj/T.xi � cj/
�
</p>
<p>:
</p>
<p>Notice how the ıi;j are acting as &ldquo;switches&rdquo;. For the i&rsquo;th data point, there is only one non-zero ıi;j which selects the distance
</p>
<p>from that data point to the appropriate cluster center. It is natural to want to cluster the data by choosing the ı and c that
</p>
<p>minimizes ˆ.ı; c/. This would yield the set of k clusters and their cluster centers such that the sum of distances from points
</p>
<p>to their cluster centers is minimized.
</p>
<p>There is no known algorithm that can minimize ˆ exactly in reasonable time. The ıi;j are the problem: it turns out to be
</p>
<p>hard to choose the best allocation of points to clusters. The algorithm we guessed above is a remarkably effective approximate
</p>
<p>solution. Notice that if we know the c&rsquo;s, getting the ı&rsquo;s is easy&mdash;for the i&rsquo;th data point, set the ıi;j corresponding to the closest
</p>
<p>cj to one and the others to zer. Similarly, if the ıi;j are known, it is easy to compute the best center for each cluster&mdash;just
</p>
<p>average the points in the cluster. So we iterate:
</p>
<p>&bull; Assume the cluster centers are known and allocate each point to the closest cluster center.
</p>
<p>&bull; Replace each center with the mean of the points allocated to that cluster.
</p>
<p>We choose a start point by randomly choosing cluster centers, and then iterate these stages alternately. This process eventually
</p>
<p>converges to a local minimum of the objective function (the value either goes down or is fixed at each step, and it is bounded
</p>
<p>below). It is not guaranteed to converge to the global minimum of the objective function, however. It is also not guaranteed
</p>
<p>to produce k clusters, unless we modify the allocation phase to ensure that each cluster has some nonzero number of points.
</p>
<p>This algorithm is usually referred to as k-means (summarized in Algorithm 12.3).
</p>
<p>Procedure 12.3 (K-Means Clustering) Choose k. Now choose k data points cj to act as cluster centers. Until the
</p>
<p>cluster centers change very little
</p>
<p>&bull; Allocate each data point to the cluster whose center is nearest.
</p>
<p>&bull; Now ensure that every cluster has at least one data point; one way to do this is by supplying empty clusters with a
</p>
<p>point chosen at random from points far from their cluster center.
</p>
<p>&bull; Replace the cluster centers with the mean of the elements in their clusters.</p>
<p/>
</div>
<div class="page"><p/>
<p>288 12 Clustering: Models of High Dimensional Data
</p>
<p>Sepal.Length
</p>
<p>Petal.Width
</p>
<p>P
e
ta
</p>
<p>l.
L
e
n
g
th
</p>
<p>setosa       versicolor          virginica
</p>
<p>Scatter Plot Matrix
</p>
<p>Sepal
Length
</p>
<p>7
</p>
<p>8
7        8
</p>
<p>5
</p>
<p>6
</p>
<p>5        6
</p>
<p>Sepal
Width
</p>
<p>3.5
</p>
<p>4.0
</p>
<p>4.5
3.5   4.0  4.5
</p>
<p>2.0
</p>
<p>2.5
</p>
<p>3.0
</p>
<p>2.0  2.5  3.0
</p>
<p>Petal
Length
</p>
<p>4
</p>
<p>5
</p>
<p>6
</p>
<p>7
4    5    6    7
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>1    2    3    4
</p>
<p>Petal
Width
</p>
<p>1.5
</p>
<p>2.0
</p>
<p>2.5
1.5  2.0   2.5
</p>
<p>0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>0.0  0.5   1.0
</p>
<p>Fig. 12.4 Left: a 3D scatterplot for the famous Iris data, collected by Edgar Anderson in 1936, and made popular amongst statisticians by Ronald
Fisher in that year. I have chosen three variables from the four, and have plotted each species with a different marker. You can see from the plot that
the species cluster quite tightly, and are different from one another. Right: a scatterplot matrix for the Iris data. There are four variables, measured
for each of three species of iris. I have plotted each species with a different marker. You can see from the plot that the species cluster quite tightly,
and are different from one another
</p>
<p>Usually, we are clustering high dimensional data, so that visualizing clusters can present a challenge. If the dimension
</p>
<p>isn&rsquo;t too high, then we can use panel plots. An alternative is to project the data onto two principal components, and plot the
</p>
<p>clusters there; the process for plotting 2D covariance ellipses from Sect. 12.5.2 comes in useful here. A natural dataset to use
</p>
<p>to explore k-means is the iris data, where we know that the data should form three clusters (because there are three species).
</p>
<p>Recall this dataset from Sect. 10.1.2. I reproduce Fig. 10.3 from that section as Fig. 12.4, for comparison. Figure 12.5 shows
</p>
<p>four different k-means clusterings of the data. By comparison with Fig. 12.4, notice how k D 2 clustering appears to merge
the versicolor and verginica clusters. The k D 3 case appears to reproduce the species correctly. The k D 4 case appears to
have broken setosa into two groups, but left versicolor and verginica as predicted by the species. The k D 5 case appears to
have broken setosa into two groups, and versicolor and verginica into a total of three groups.
</p>
<p>12.3.1 How to Choose K
</p>
<p>The iris data is just a simple example. We know that the data forms clean clusters, and we know there should be three of
</p>
<p>them. Usually, we don&rsquo;t know how many clusters there should be, and we need to choose this by experiment. One strategy is
</p>
<p>to cluster for a variety of different values of k, then look at the value of the cost function for each. If there are more centers,
</p>
<p>each data point can find a center that is close to it, so we expect the value to go down as k goes up. This means that looking for
</p>
<p>the k that gives the smallest value of the cost function is not helpful, because that k is always the same as the number of data
</p>
<p>points (and the value is then zero). However, it can be very helpful to plot the value as a function of k, then look at the &ldquo;knee&rdquo;
</p>
<p>of the curve. Figure 12.6 shows this plot for the iris data. Notice that k D 3&mdash;the &ldquo;true&rdquo; answer&mdash;doesn&rsquo;t look particularly
special, but k D 2, k D 3, or k D 4 all seem like reasonable choices. It is possible to come up with a procedure that makes a
more precise recommendation by penalizing clusterings that use a large k, because they may represent inefficient encodings
</p>
<p>of the data. However, this is often not worth the bother.</p>
<p/>
</div>
<div class="page"><p/>
<p>12.3 The K-Means Algorithm and Variants 289
</p>
<p>Sepal
</p>
<p>Length0
</p>
<p>1
</p>
<p>2 0      1       2
</p>
<p>&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>&minus;2   &minus;1      0
</p>
<p>Sepal
</p>
<p>Width
</p>
<p>1
</p>
<p>2
</p>
<p>3
1     2    3
</p>
<p>&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>&minus;2   &minus;1   0
</p>
<p>Petal
</p>
<p>Length
0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>1.5 0.0 0.5 1.0 1.5
</p>
<p>&minus;1.5
</p>
<p>&minus;1.0
</p>
<p>&minus;0.5
</p>
<p>0.0
</p>
<p>&minus;1.5   &minus;0.5
</p>
<p>Petal
</p>
<p>Width
0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>1.5 0.0 0.5 1.0 1.5
</p>
<p>&minus;1.5
</p>
<p>&minus;1.0
</p>
<p>&minus;0.5
</p>
<p>0.0
</p>
<p>&minus;1.5    &minus;0.5
</p>
<p>Sepal
</p>
<p>Length0
</p>
<p>1
</p>
<p>2 0      1       2
</p>
<p>&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>&minus;2   &minus;1       0
</p>
<p>Sepal
</p>
<p>Width
</p>
<p>1
</p>
<p>2
</p>
<p>3
1     2    3
</p>
<p>&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>&minus;2  &minus;1    0
</p>
<p>Petal
</p>
<p>Length
0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>1.5 0.0 0.5 1.0 1.5
</p>
<p>&minus;1.5
</p>
<p>&minus;1.0
</p>
<p>&minus;0.5
</p>
<p>0.0
</p>
<p>&minus;1.5    &minus;0.5
</p>
<p>Petal
</p>
<p>Width
0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>1.5 0.00.51.01.5
</p>
<p>&minus;1.5
</p>
<p>&minus;1.0
</p>
<p>&minus;0.5
</p>
<p>0.0
</p>
<p>&minus;1.5   &minus;0.5
</p>
<p>Sepal
</p>
<p>Length0
</p>
<p>1
</p>
<p>2 0       1      2
</p>
<p>&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>&minus;2    &minus;1     0
</p>
<p>Sepal
</p>
<p>Width
</p>
<p>1
</p>
<p>2
</p>
<p>3
1     2    3
</p>
<p>&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>&minus;2   &minus;1   0
</p>
<p>Petal
</p>
<p>Length
0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>1.5 0.0 0.5 1.0 1.5
</p>
<p>&minus;1.5
</p>
<p>&minus;1.0
</p>
<p>&minus;0.5
</p>
<p>0.0
</p>
<p>&minus;1.5    &minus;0.5
</p>
<p>Petal
</p>
<p>Width
0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>1.5 0.0  0.5 1.0 1.5
</p>
<p>&minus;1.5
</p>
<p>&minus;1.0
</p>
<p>&minus;0.5
</p>
<p>0.0
</p>
<p>&minus;1.5    &minus;0.5
</p>
<p>3 clusters2 clusters
</p>
<p>5 clusters
</p>
<p>Sepal
</p>
<p>Length0
</p>
<p>1
</p>
<p>2 0      1       2
</p>
<p>&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>&minus;2    &minus;1      0
</p>
<p>Sepal
</p>
<p>Width
</p>
<p>1
</p>
<p>2
</p>
<p>3
1     2    3
</p>
<p>&minus;2
</p>
<p>&minus;1
</p>
<p>0
</p>
<p>&minus;2  &minus;1    0
</p>
<p>Petal
</p>
<p>Length
0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>1.5 0.0 0.5 1.0 1.5
</p>
<p>&minus;1.5
</p>
<p>&minus;1.0
</p>
<p>&minus;0.5
</p>
<p>0.0
</p>
<p>&minus;1.5   &minus;0.5
</p>
<p>Petal
</p>
<p>Width
0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>1.5 0.0 0.5 1.0  1.5
</p>
<p>&minus;1.5
</p>
<p>&minus;1.0
</p>
<p>&minus;0.5
</p>
<p>0.0
</p>
<p>&minus;1.5   &minus;0.5
</p>
<p>4 clusters
</p>
<p>Fig. 12.5 Four panel plots of the iris data, clustered with k-means to different numbers of clusters
</p>
<p>In some special cases (like the iris example), we might know the right answer to check our clustering against. In such
</p>
<p>cases, one can evaluate the clustering by looking at the number of different labels in a cluster (sometimes called the purity),
</p>
<p>and the number of clusters. A good solution will have few clusters, all of which have high purity. Mostly, we don&rsquo;t have a
</p>
<p>right answer to check against. An alternative strategy, which might seem crude to you, for choosing k is extremely important
</p>
<p>in practice. Usually, one clusters data to use the clusters in an application (one of the most important, vector quantization, is
</p>
<p>described in Sect. 12.4). There are usually natural ways to evaluate this application. For example, vector quantization is often
</p>
<p>used as an early step in texture recognition or in image matching; here one can evaluate the error rate of the recognizer, or</p>
<p/>
</div>
<div class="page"><p/>
<p>290 12 Clustering: Models of High Dimensional Data
</p>
<p>Scatter Plot Matrix
</p>
<p>Sepal
</p>
<p>Length
</p>
<p>7
</p>
<p>8
7 8
</p>
<p>5
</p>
<p>6
</p>
<p>5 6
</p>
<p>Sepal
</p>
<p>Width
</p>
<p>3.5
</p>
<p>4.0
</p>
<p>4.5
</p>
<p>3.5 4.0 4.5
</p>
<p>2.0
</p>
<p>2.5
</p>
<p>3.0
</p>
<p>2.0 2.5 3.0
</p>
<p>Petal
</p>
<p>Length
4
</p>
<p>5
</p>
<p>6
</p>
<p>7
4 5 6 7
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>1 2 3 4
</p>
<p>Petal
</p>
<p>Width
</p>
<p>1.5
</p>
<p>2.0
</p>
<p>2.5
1.5 2.0 2.5
</p>
<p>0.0
</p>
<p>0.5
</p>
<p>1.0
</p>
<p>0.0 0.5 1.0
</p>
<p>setosa versicolor virginica
</p>
<p>2 4 6 8 10 12 14
</p>
<p>1
0
0
</p>
<p>2
0
0
</p>
<p>3
0
0
</p>
<p>4
0
0
</p>
<p>5
0
0
</p>
<p>6
0
0
</p>
<p>Number of Clusters
W
</p>
<p>it
h
in
</p>
<p> g
ro
</p>
<p>u
p
s
 s
</p>
<p>u
m
</p>
<p> o
f 
s
q
u
a
re
</p>
<p>s
</p>
<p>Fig. 12.6 On the left, the scatterplot matrix for the Iris data, for reference. On the right, a plot of the value of the cost function for each of several
different values of k. Notice how there is a sharp drop in cost going from k D 1 to k D 2, and again at k D 4; after that, the cost falls off slowly.
This suggests using k D 2, k D 3, or k D 4, depending on the precise application
</p>
<p>the accuracy of the image matcher. One then chooses the k that gets the best evaluation score on validation data. In this view,
</p>
<p>the issue is not how good the clustering is; it&rsquo;s how well the system that uses the clustering works.
</p>
<p>12.3.2 Soft Assignment
</p>
<p>One difficulty with k-means is that each point must belong to exactly one cluster. But, given we don&rsquo;t know how many
</p>
<p>clusters there are, this seems wrong. If a point is close to more than one cluster, why should it be forced to choose? This
</p>
<p>reasoning suggests we assign points to cluster centers with weights. These weights are different from the original ıi;j because
</p>
<p>they are not forced to be either zero or one, however. Write wi;j for the weight connecting point i to cluster center j. Weights
</p>
<p>should be non-negative (i.e. wi;j � 0), and each point should carry a total weight of 1 (i.e.
P
</p>
<p>j wi;j D 1), so that it if the i&rsquo;th
point contributes more to one cluster center, it is forced to contribute less to all others. You should see wi;j as a simplification
</p>
<p>of the ıi;j in the original cost function. We can write a new cost function
</p>
<p>ˆ.w; c/ D
X
</p>
<p>i;j
</p>
<p>wi;j
�
</p>
<p>.xi � cj/T.xi � cj/
�
</p>
<p>;
</p>
<p>which we would like to minimize by choice of w and c. There isn&rsquo;t any improvement in the problem, because for any choice
</p>
<p>of c, the best choice of w is to allocate each point to its closest cluster center. This is because we have not specified any
</p>
<p>relationship between w and c.
</p>
<p>But w and c should be coupled. We would like wi;j to be large when xi is close to cj, and small otherwise. Write di;j for the
</p>
<p>distance jjxi � cjjj, choose a scaling parameter � &gt; 0, and write
</p>
<p>si;j D e
�d2i;j
2�2 :
</p>
<p>This si;j is often called the affinity between the point i and the center j; it is large when they are close in � units, and small
</p>
<p>when they are far apart. Now a natural choice of weights is</p>
<p/>
</div>
<div class="page"><p/>
<p>12.3 The K-Means Algorithm and Variants 291
</p>
<p>wi;j D
si;j
</p>
<p>Pk
lD1 si;l
</p>
<p>:
</p>
<p>All these weights are non-negative, they sum to one. The weight linking a point and a cluster center is large if the point
</p>
<p>is much closer to one center than to any other. The scaling parameter � sets the meaning of &ldquo;much closer&rdquo;&mdash;we measure
</p>
<p>distance in units of � .
</p>
<p>Once we have weights, re-estimating the cluster centers is easy. We use the weights to compute a weighted average of the
</p>
<p>points. In particular, we re-estimate the j&rsquo;th cluster center by
</p>
<p>P
</p>
<p>i wi;jxi
P
</p>
<p>i wi;j
:
</p>
<p>Notice that k-means is a special case of this algorithm where � limits to zero. In this case, each point has a weight of one for
</p>
<p>some cluster, and zero for all others, and the weighted mean becomes an ordinary mean. I have collected the description into
</p>
<p>a box (Procedure 12.4) for convenience.
</p>
<p>Notice one other feature of this procedure. As long as you use sufficient precision for the arithmetic (which might be a
</p>
<p>problem), wi;j is always greater than zero. This means that no cluster is empty. In practice, if � is small compared to the
</p>
<p>distances between points, you can end up with empty clusters. You can tell if this is happening by looking at
P
</p>
<p>i wi;j; if this
</p>
<p>is very small or zero, you have a problem.
</p>
<p>Procedure 12.4 (K-Means with Soft Weights) Choose k. Choose k data points cj to act as initial cluster centers.
</p>
<p>Until the cluster centers change very little:
</p>
<p>&bull; First, we estimate the weights. For each pair of a data point xi and a cluster cj, compute the affinity
</p>
<p>si;j D e
�jjxi�cjjj
</p>
<p>2�2 :
</p>
<p>&bull; Now for each pair of a data point xi and a cluster cj compute the soft weight linking the data point to the center
</p>
<p>wi;j D si;j=
k
X
</p>
<p>lD1
si;l:
</p>
<p>&bull; For each cluster, compute
P
</p>
<p>i wi;j. If this is too small, then this cluster&rsquo;s new center is a point chosen at random from
</p>
<p>points far from their cluster center. Otherwise, the new center is
</p>
<p>cj D
P
</p>
<p>i wi;jxi
P
</p>
<p>i wi;j
</p>
<p>12.3.3 Efficient Clustering and Hierarchical K Means
</p>
<p>One important difficulty occurs in applications. We might need to have an enormous dataset (millions of items is a real
</p>
<p>possibility), and so a very large k. In this case, k-means clustering becomes difficult because identifying which cluster center
</p>
<p>is closest to a particular data point scales linearly with k (and we have to do this for every data point at every iteration). There
</p>
<p>are two useful strategies for dealing with this problem.
</p>
<p>The first is to notice that, if we can be reasonably confident that each cluster contains many data points, some of the data
</p>
<p>is redundant. We could randomly subsample the data, cluster that, then keep the cluster centers. This works, but doesn&rsquo;t scale
</p>
<p>particularly well.
</p>
<p>A more effective strategy is to build a hierarchy of k-means clusters. We randomly subsample the data (typically quite
</p>
<p>aggressively), then cluster this with a small value of k. Each data item is then allocated to the closest cluster center, and the
</p>
<p>data in each cluster is clustered again with k-means. We now have something that looks like a two-level tree of clusters. Of
</p>
<p>course, this process can be repeated to produce a multi-level tree of clusters.</p>
<p/>
</div>
<div class="page"><p/>
<p>292 12 Clustering: Models of High Dimensional Data
</p>
<p>12.3.4 K-Mediods
</p>
<p>In some cases, we want to cluster objects that can&rsquo;t be averaged. One case where this happens is when you have a table of
</p>
<p>distances between objects, but do not know vectors representing the objects. For example, you could collect data giving the
</p>
<p>distances between cities, without knowing where the cities are (as in Sect. 10.4.3, particularly Fig. 10.16), then try and cluster
</p>
<p>using this data. As another example, you could collect data giving similarities between breakfast items as in Sect. 10.4.3, then
</p>
<p>turn the similarities into distances by taking the negative logarithm. This gives a useable table of distances. You still can&rsquo;t
</p>
<p>average kippers with oatmeal, so you couldn&rsquo;t use k-means to cluster this data.
</p>
<p>A variant of k-means, known as k-medoids, applies to this case. In k-medoids, the cluster centers are data items rather
</p>
<p>than averages, and so are called &ldquo;mediods&rdquo;. The rest of the algorithm has a familiar form. We assume k, the number of cluster
</p>
<p>centers, is known. We initialize the cluster centers by choosing examples at random. We then iterate two procedures. In the
</p>
<p>first, we allocate each data point to the closest mediod. In the second, we choose the best medoid for each cluster by finding
</p>
<p>the data point that minimizes the sum of distances of points in the cluster to that medoid. This point can be found by simply
</p>
<p>searching all points.
</p>
<p>12.3.5 Example: Groceries in Portugal
</p>
<p>Clustering can be used to expose structure in datasets that isn&rsquo;t visible with simple tools. Here is an example. At http://archive.
</p>
<p>ics.uci.edu/ml/datasets/Wholesale+customers, you will find a dataset giving sums of money spent annually on different
</p>
<p>commodities by customers in Portugal. The commodities are divided into a set of categories (fresh; milk; grocery; frozen;
</p>
<p>detergents and paper; and delicatessen) relevant for the study. These customers are divided by channel (two channels,
</p>
<p>corresponding to different types of shop) and by region (three regions). You can think of the data as being divided into
</p>
<p>six groups (one for each pair of channel and region). There are 440 customer records, and there are many customers in each
</p>
<p>group. The data was provided by M. G. M. S. Cardoso.
</p>
<p>Figure 12.7 shows a panel plot of the customer data; the data has been clustered, and I gave each of 10 clusters its own
</p>
<p>marker. You (or at least, I) can&rsquo;t see any evidence of the six groups here. This is due to the form of the visualization, rather
</p>
<p>than a true property of the data. People tend to like to live near people who are &ldquo;like&rdquo; them, so you could expect people in a
</p>
<p>region to be somewhat similar; you could reasonably expect differences between groups (regional preferences; differences in
</p>
<p>wealth; and so on). Retailers have different channels to appeal to different people, so you could expect people using different
</p>
<p>channels to be different. But you don&rsquo;t see this in the plot of clusters. In fact, the plot doesn&rsquo;t really show much structure at
</p>
<p>all, and is basically unhelpful.
</p>
<p>Here is a way to think about structure in the data. There are likely to be different &ldquo;types&rdquo; of customer. For example,
</p>
<p>customers who prepare food at home might spend more money on fresh or on grocery, and those who mainly buy prepared
</p>
<p>food might spend more money on delicatessen; similarly, coffee drinkers with cats or with children might spend more on
</p>
<p>milk than the lactose-intolerant, and so on. So we can expect customers to cluster in types. An effect like this is hard to
</p>
<p>see on a panel plot of the clustered data (Fig. 12.7). The plot for this dataset is hard to read, because the dimension is fairly
</p>
<p>high for a panel plot and the data is squashed together in the bottom left corner. However, you can see the effect when you
</p>
<p>cluster the data and look at the cost function in representing the data with different values of k&mdash;quite a small set of clusters
</p>
<p>gives quite a good representation of the customers (Fig. 12.8). The panel plot of cluster membership (also in that figure) isn&rsquo;t
</p>
<p>particularly informative. The dimension is quite high, and clusters get squashed together.
</p>
<p>There is an important effect which isn&rsquo;t apparent in the panel plots. Some of what cause customers to cluster in types are
</p>
<p>driven by things like wealth and the tendency of people to have neighbors who are similar to them. This means that different
</p>
<p>groups should have different fractions of each type of customer. There might be more deli-spenders in wealthier regions;
</p>
<p>more milk-spenders and detergent-spenders in regions where it is customary to have many children; and so on. This sort
</p>
<p>of structure will not be apparent in a panel plot. A group of a few milk-spenders and many detergent-spenders will have
</p>
<p>a few data points with high milk expenditure values (and low other values) and also many data points with high detergent
</p>
<p>expenditure values (and low other values). In a panel plot, this will look like two blobs; but if there is a second group with
</p>
<p>many milk-spenders and few detergent-spenders will also look like two blobs, lying roughly on top of the first set of blobs.
</p>
<p>It will be hard to spot the difference between the groups.
</p>
<p>An easy way to see this difference is to look at histograms of the types of customer within each group. I described each
</p>
<p>group of data by the histogram of customer types that appeared in that group (Fig. 12.9). Notice how the distinction between
</p>
<p>the groups is now apparent&mdash;the groups do appear to contain quite different distributions of customer type. It looks as though</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Wholesale+customers">http://archive.ics.uci.edu/ml/datasets/Wholesale+customers</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Wholesale+customers">http://archive.ics.uci.edu/ml/datasets/Wholesale+customers</a></div>
</div>
<div class="page"><p/>
<p>12.3 The K-Means Algorithm and Variants 293
</p>
<p>Fig. 12.7 A panel plot of the
wholesale customer data of http://
archive.ics.uci.edu/ml/datasets/
Wholesale+customers, which
records sums of money spent
annually on different
commodities by customers in
Portugal. This data is recorded
for six different groups (two
channels each within three
regions). I have plotted each
group with a different marker, but
you can&rsquo;t really see much
structure here, for reasons
explained in the text
</p>
<p>Scatter Plot Matrix
</p>
<p>Fresh
</p>
<p>Milk
</p>
<p>Grocery
</p>
<p>Frozen
</p>
<p>DetPaper
</p>
<p>Delicatessen
</p>
<p>the channels (rows in this figure) are more different than the regions (columns in this figure). To be more confident in this
</p>
<p>analysis, we would need to be sure that different types of customer really are different. We could do this by repeating the
</p>
<p>analysis for fewer clusters, or by looking at the similarity of customer types.
</p>
<p>12.3.6 General Comments on K-Means
</p>
<p>If you experiment with k-means, you will notice one irritating habit of the algorithm. It almost always produces either some
</p>
<p>rather spread out clusters, or some single element clusters. Most clusters are usually rather tight and blobby clusters, but there
</p>
<p>is usually one or more bad cluster. This is fairly easily explained. Because every data point must belong to some cluster, data
</p>
<p>points that are far from all others (a) belong to some cluster and (b) very likely &ldquo;drag&rdquo; the cluster center into a poor location.
</p>
<p>This applies even if you use soft assignment, because every point must have total weight one. If the point is far from all
</p>
<p>others, then it will be assigned to the closest with a weight very close to one, and so may drag it into a poor location, or it
</p>
<p>will be in a cluster on its own.
</p>
<p>There are ways to deal with this. If k is very big, the problem is often not significant, because then you simply have
</p>
<p>many single element clusters that you can ignore. It isn&rsquo;t always a good idea to have too large a k, because then some larger
</p>
<p>clusters might break up. An alternative is to have a junk cluster. Any point that is too far from the closest true cluster center
</p>
<p>is assigned to the junk cluster, and the center of the junk cluster is not estimated. Notice that points should not be assigned
</p>
<p>to the junk cluster permanently; they should be able to move in and out of the junk cluster as the cluster centers move.
</p>
<p>Remember this: K-means clustering is the &ldquo;go-to&rdquo; clustering algorithm. You should see it as a basic recipe from
</p>
<p>which many algorithms can be concocted. The recipe is: iterate: allocate each data point to the closest cluster center;
</p>
<p>re-estimate cluster centers from their data points. There are many variations, improvements, etc. that are possible on
</p>
<p>(continued)</p>
<p/>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Wholesale+customers">http://archive.ics.uci.edu/ml/datasets/Wholesale+customers</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Wholesale+customers">http://archive.ics.uci.edu/ml/datasets/Wholesale+customers</a></div>
<div class="annotation"><a href="http://archive.ics.uci.edu/ml/datasets/Wholesale+customers">http://archive.ics.uci.edu/ml/datasets/Wholesale+customers</a></div>
</div>
<div class="page"><p/>
<p>294 12 Clustering: Models of High Dimensional Data
</p>
<p>0 5 10 15 20 25 30 35
</p>
<p>5
.0
</p>
<p>e
+
</p>
<p>1
0
</p>
<p>1
.0
</p>
<p>e
+
</p>
<p>1
1
</p>
<p>1
.5
</p>
<p>e
+
</p>
<p>1
1
</p>
<p>Number of Clusters
</p>
<p>W
it
h
</p>
<p>in
 g
</p>
<p>ro
u
</p>
<p>p
s
 s
</p>
<p>u
m
</p>
<p> o
f 
</p>
<p>s
q
</p>
<p>u
a
</p>
<p>re
s
</p>
<p>Scatter Plot Matrix
</p>
<p>Fresh
</p>
<p>Milk
</p>
<p>Grocery
</p>
<p>Frozen
</p>
<p>DetPaper
</p>
<p>Delicatessen
</p>
<p>Fig. 12.8 On the left, the cost function (of Sect. 12.3) for clusterings of the customer data with k-means for k running from 2 to 35. This suggests
using a k somewhere in the range 10&ndash;30; I chose 10. On the right, I have clustered this data to 10 cluster centers with k-means. The clusters do
seem to be squashed together, but the plot on the left suggests that clusters do capture some important information. Using too few clusters will
clearly lead to problems. Notice that I did not scale the data, because each of the measurements is in a comparable unit. For example, it wouldn&rsquo;t
make sense to scale expenditures on fresh and expenditures on grocery with a different scale
</p>
<p>this recipe. We have seen soft weights and k-mediods. K-means is not usually best implemented with the method I
</p>
<p>described (which isn&rsquo;t particularly efficient, but gets to the heart of what is going on). Implementations of k-means
</p>
<p>differ in important ways from my rather high-level description of the algorithm; for any but tiny problems, you should
</p>
<p>use a package, and you should look for a package that uses the Lloyd-Hartigan method.
</p>
<p>12.4 Describing Repetition with Vector Quantization
</p>
<p>The classifiers in Chap. 11 can be applied to simple images (the MNIST exercises at the end of the chapter, for example),
</p>
<p>but they will annoy you if you try to apply them as described to more complicated signals. All the methods described apply
</p>
<p>to feature vectors of fixed length. But typical of signals like speech, images, video, or accelerometer outputs is that different
</p>
<p>versions of the same thing have different lengths. For example, pictures appear at different resolutions, and it seems clumsy
</p>
<p>to insist that every image be 28 � 28 before it can be classified. As another example, some speakers are slow, and others are
fast, but it&rsquo;s hard to see much future for a speech understanding system that insisted that everyone speak at the same speed so
</p>
<p>the classifier could operate. We need a construction that will take a signal and produce a useful feature vector of fixed length.
</p>
<p>This section shows one of the most useful such constructions (but be aware, this is an enormous topic).
</p>
<p>Repetition is an important feature of many interesting signals. For example, images contain textures, which are orderly
</p>
<p>patterns that look like large numbers of small structures that are repeated. Examples include the spots of animals such as
</p>
<p>leopards or cheetahs; the stripes of animals such as tigers or zebras; the patterns on bark, wood, and skin. Similarly, speech
</p>
<p>signals contain phonemes&mdash;characteristic, stylised sounds that people assemble together to produce speech (for example,
</p>
<p>the &ldquo;ka&rdquo; sound followed by the &ldquo;tuh&rdquo; sound leading to &ldquo;cat&rdquo;). Another example comes from accelerometers. If a subject
</p>
<p>wears an accelerometer while moving around, the signals record the accelerations during their movements. So, for example,
</p>
<p>brushing one&rsquo;s teeth involves a lot of repeated twisting movements at the wrist, and walking involves swinging the hand back
</p>
<p>and forth.</p>
<p/>
</div>
<div class="page"><p/>
<p>12.4 Describing Repetition with Vector Quantization 295
</p>
<p>0.0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>1 5 10
</p>
<p>Channel 1, Region 1
</p>
<p>F
re
</p>
<p>q
u
e
n
c
y
</p>
<p>0.0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>2 4 6 8 10
</p>
<p>Channel 2, Region 1
</p>
<p>F
re
</p>
<p>q
u
e
n
c
y
</p>
<p>0.0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>2 4 6 8 10
</p>
<p>Channel 1, Region 2
</p>
<p>F
re
</p>
<p>q
u
e
n
c
y
</p>
<p>0.0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>2 4 6 8 10
</p>
<p>Channel 2, Region 2
</p>
<p>F
re
</p>
<p>q
u
e
n
c
y
</p>
<p>0.0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>2 4 6 8 10
</p>
<p>Channel 1, Region 3
</p>
<p>F
re
</p>
<p>q
u
e
n
c
y
</p>
<p>0.0
</p>
<p>0.1
</p>
<p>0.2
</p>
<p>0.3
</p>
<p>2 4 6 8 10
</p>
<p>Channel 2, Region 3
</p>
<p>F
re
</p>
<p>q
u
e
n
c
y
</p>
<p>Fig. 12.9 The histogram of different types of customer, by group, for the customer data. Notice how the distinction between the groups is now
apparent&mdash;the groups do appear to contain quite different distributions of customer type. It looks as though the channels (rows in this figure) are
more different than the regions (columns in this figure)
</p>
<p>Repetition occurs in subtle forms. The essence is that a small number of local patterns can be used to represent a large
</p>
<p>number of examples. You see this effect in pictures of scenes. If you collect many pictures of, say, a beach scene, you will
</p>
<p>expect most to contain some waves, some sky, and some sand. The individual patches of wave, sky or sand can be surprisingly
</p>
<p>similar. However, it&rsquo;s fair to model this by saying different images are made by selecting some patches from a vocabulary of
</p>
<p>patches, then placing them down to form an image. Similarly, pictures of living rooms contain chair patches, TV patches, and
</p>
<p>carpet patches. Many different living rooms can be made from small vocabularies of patches; but you won&rsquo;t often see wave
</p>
<p>patches in living rooms, or carpet patches in beach scenes. This suggests that the patches that are used to make an image
</p>
<p>reveal something about what is in the image. This observation works for speech, for video, and for accelerometer signals too.</p>
<p/>
</div>
<div class="page"><p/>
<p>296 12 Clustering: Models of High Dimensional Data
</p>
<p>An important part of representing signals that repeat is building a vocabulary of patterns that repeat, then describing the
</p>
<p>signal in terms of those patterns. For many problems, knowing what vocabulary elements appear and how often is much more
</p>
<p>important than knowing where they appear. For example, if you want to tell the difference between zebras and leopards, you
</p>
<p>need to know whether stripes or spots are more common, but you don&rsquo;t particularly need to know where they appear. As
</p>
<p>another example, if you want to tell the difference between brushing teeth and walking using accelerometer signals, knowing
</p>
<p>that there are lots of (or few) twisting movements is important, but knowing how the movements are linked together in time
</p>
<p>may not be. As a general rule, one can do quite a good job of classifying video just by knowing what patterns are there (i.e.
</p>
<p>without knowing where or when the patterns appear). However, this doesn&rsquo;t apply to speech, where it really matters what
</p>
<p>sound follows what sound.
</p>
<p>12.4.1 Vector Quantization
</p>
<p>It is natural to try and find patterns by looking for small pieces of signal of fixed size that appear often. In an image, a piece
</p>
<p>of signal might be a 10 � 10 patch, which can be reshaped into a vector. In a sound file, which is likely represented as a
vector, it might be a subvector of fixed size. A 3-axis accelerometer signal is usually represented as a 3� r dimensional array
(where r is the number of samples); in this case, a piece might be a 3� 10 subarray, which can be reshaped into a vector. But
finding patterns that appear often is hard to do, because the signal is continuous&mdash;each pattern will be slightly different, so
</p>
<p>we cannot simply count how many times a particular pattern occurs.
</p>
<p>Here is a strategy. We take a training set of signals, and cut each signal into pieces of fixed size and reshape them into d
</p>
<p>dimensional vectors. We then build a set of clusters out of these pieces. This set of clusters is often thought of as a dictionary,
</p>
<p>because we expect many or most cluster centers to look like pieces that occur often in the signals and so are repeated.
</p>
<p>We can now describe any new piece of signal with the cluster center closest to that piece. This means that a piece of
</p>
<p>signal is described with a number in the range Œ1; : : : ; k&#141; (where you get to choose k), and two pieces that are close should be
</p>
<p>described by the same number. This strategy is known as vector quantization.
</p>
<p>This strategy applies to any kind of signal, and is surprisingly robust to details. We could use d dimensional vectors for a
</p>
<p>sound file;
p
d �
</p>
<p>p
d dimensional patches for an image; or 3 � .d=3/ dimensional subarrays for an accelerometer signal. In
</p>
<p>each case, it is easy to compute the distance between two pieces using sum of squared distances. It seems not to matter much
</p>
<p>if the signals are cut into overlapping or non-overlapping pieces when forming the dictionary, as long as there are enough
</p>
<p>pieces.
</p>
<p>Procedure 12.5 (Vector Quantization&mdash;Building a Dictionary) Take a training set of signals, and cut each signal
</p>
<p>into pieces of fixed size. The size of the piece will affect how well your method works, and is usually chosen by
</p>
<p>experiment. It does not seem to matter much if the pieces overlap. Cluster all the example pieces, and record the k
</p>
<p>cluster centers. It is usual, but not required, to use k-means clustering.
</p>
<p>We can now build features that represent important repeated structure in signals. We take a signal, and cut it up into
</p>
<p>vectors of length d. These might overlap, or be disjoint. We then take each vector, and compute the number that describes it
</p>
<p>(i.e. the number of the closest cluster center, as above). We then compute a histogram of the numbers we obtained for all the
</p>
<p>vectors in the signal. This histogram describes the signal.
</p>
<p>Procedure 12.6 (Vector Quantization&mdash;Representing a Signal) Take your signal, and cut it into pieces of fixed size.
</p>
<p>The size of the piece will affect how well your method works, and is usually chosen by experiment. It does not seem
</p>
<p>to matter much if the pieces overlap. For each piece, record the closest cluster center in the dictionary. Represent the
</p>
<p>signal with a histogram of these numbers, which will be a k dimensional vector.
</p>
<p>Notice several nice features to this construction. First, it can be applied to anything that can be thought of in terms of fixed
</p>
<p>size pieces, so it will work for speech signals, sound signals, accelerometer signals, images, and so on. Another nice feature
</p>
<p>is the construction can accept signals of different length, and produce a description of fixed length. One accelerometer signal</p>
<p/>
</div>
<div class="page"><p/>
<p>12.4 Describing Repetition with Vector Quantization 297
</p>
<p>Fig. 12.10 Top: two images with rather exaggerated repetition, published on flickr.com with a creative commons license by webtreats. Next
to these images, I have placed zoomed sampled 10� 10 patches from those images; although the spots (resp. stripes) aren&rsquo;t necessarily centered in
the patches, it&rsquo;s pretty clear which image each patch comes from. Bottom: a 40 patch dictionary computed using k-means from 4000 samples from
each image. If you look closely, you&rsquo;ll see that some dictionary entries are clearly stripe entries, others clearly spot entries. Stripe images will have
patches represented by stripe entries in the dictionary and spot images by spot entries
</p>
<p>might cover 100 time intervals; another might cover 200; but the description is always a histogram with k buckets, so it&rsquo;s
</p>
<p>always a vector of length k.
</p>
<p>Yet another nice feature is that we don&rsquo;t need to be all that careful how we cut the signal into fixed length vectors. This is
</p>
<p>because it is hard to hide repetition. This point is easier to make with a figure than in text, so look at Fig. 12.10.
</p>
<p>The number of pieces of signal (and so k), might be very big indeed. It is quite reasonable to want to build a dictionary for
</p>
<p>a million items and use tens to hundreds of thousands of cluster centers. In this case, it is a good idea to use hierarchical k-
</p>
<p>means, as in Sect. 12.3.3. Hierarchical k-means produces a tree of cluster centers. It is easy to use this tree to vector quantize
</p>
<p>a query data item. We vector quantize at the first level. Doing so chooses a branch of the tree, and we pass the data item to
</p>
<p>this branch. It is either a leaf, in which case we report the number of the leaf, or it is a set of clusters, in which case we vector
</p>
<p>quantize, and pass the data item down. This procedure is efficient both when one clusters and at run time.
</p>
<p>Representing a signal as a histogram of cluster centers loses information in two important ways. First, the histogram has
</p>
<p>little or no information about how the pieces of signal are arranged. So, for example, the representation can tell whether an
</p>
<p>image has stripy or spotty patches in it, but not where those patches lie. You should not rely on your intuition to tell you
</p>
<p>whether this lost information is important or not. For many kinds of image classification task, histograms of cluster centers
</p>
<p>are much better than you might guess, despite not encoding where patches lie (though still better results are now obtained
</p>
<p>with convolutional neural networks).
</p>
<p>Second, replacing a piece of signal with a cluster center must lose some detail, which might be important, and likely
</p>
<p>results in some classification errors. There is a surprisingly simple construction that can alleviate these problems. Build three
</p>
<p>(or more) dictionaries, rather than one, using different sets of training pieces. For example, you could cut the same signals
</p>
<p>into pieces on a different grid. Now use each dictionary to produce a histogram of cluster centers, and classify with those.
</p>
<p>Finally, use a voting scheme to decide the class of each test signal. In many problems, this approach yields small but useful
</p>
<p>improvements.</p>
<p/>
<div class="annotation"><a href="flickr.com">flickr.com</a></div>
</div>
<div class="page"><p/>
<p>298 12 Clustering: Models of High Dimensional Data
</p>
<p>12.4.2 Example: Activity from Accelerometer Data
</p>
<p>A complex example dataset appears at https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-
</p>
<p>worn+Accelerometer. This dataset consists of examples of the signal from a wrist mounted accelerometer, produced as
</p>
<p>different subjects engaged in different activities of daily life. Activities include: brushing teeth, climbing stairs, combing
</p>
<p>hair, descending stairs, and so on. Each is performed by sixteen volunteers. The accelerometer samples the data at 32 Hz (i.e.
</p>
<p>this data samples and reports the acceleration 32 times per second). The accelerations are in the x, y and z-directions. The
</p>
<p>dataset was collected by Barbara Bruno, Fulvio Mastrogiovanni and Antonio Sgorbissa. Figure 12.11 shows the x-component
</p>
<p>of various examples of toothbrushing.
</p>
<p>There is an important problem with using data like this. Different subjects take quite different amounts of time to perform
</p>
<p>these activities. For example, some subjects might be more thorough tooth-brushers than other subjects. As another example,
</p>
<p>people with longer legs walk at somewhat different frequencies than people with shorter legs. This means that the same
</p>
<p>activity performed by different subjects will produce data vectors that are of different lengths. It&rsquo;s not a good idea to deal
</p>
<p>with this by warping time and resampling the signal. For example, doing so will make a thorough toothbrusher look as though
</p>
<p>they are moving their hands very fast (or a careless toothbrusher look ludicrously slow: think speeding up or slowing down
</p>
<p>a movie). So we need a representation that can cope with signals that are a bit longer or shorter than other signals.
</p>
<p>Another important property of these signals is that all examples of a particular activity should contain repeated patterns.
</p>
<p>For example, brushing teeth should show fast accelerations up and down; walking should show a strong signal at somewhere
</p>
<p>around 2 Hz; and so on. These two points should suggest vector quantization to you. Representing the signal in terms of
</p>
<p>stylized, repeated structures is probably a good idea because the signals probably contain these structures. And if we represent
</p>
<p>the signal in terms of the relative frequency with which these structures occur, the representation will have a fixed length,
</p>
<p>even if the signal doesn&rsquo;t. To do so, we need to consider (a) over what time scale we will see these repeated structures and
</p>
<p>(b) how to ensure we segment the signal into pieces so that we see these structures.
</p>
<p>Generally, repetition in activity signals is so obvious that we don&rsquo;t need to be smart about segment boundaries. I broke
</p>
<p>these signals into 32 sample segments, one following the other. Each segment represents 1 s of activity. This is long enough
</p>
<p>for the body to do something interesting, but not so long that our representation will suffer if we put the segment boundaries
</p>
<p>0 500 1000 1500 2000 2500
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
Brushing teeth &minus; example 1
</p>
<p>Time
</p>
<p>X
 A
</p>
<p>cc
el
</p>
<p>er
at
</p>
<p>io
n
</p>
<p>0 200 400 600 800 1000
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
Brushing teeth &minus; example 2
</p>
<p>Time
</p>
<p>X
 A
</p>
<p>cc
el
</p>
<p>er
at
</p>
<p>io
n
</p>
<p>0 500 1000 1500 2000 2500
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
Brushing teeth &minus; example 3
</p>
<p>Time
</p>
<p>X
 A
</p>
<p>cc
el
</p>
<p>er
at
</p>
<p>io
n
</p>
<p>0 500 1000 1500 2000 2500
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
Brushing teeth &minus; example 4
</p>
<p>Time
</p>
<p>X
 A
</p>
<p>cc
el
</p>
<p>er
at
</p>
<p>io
n
</p>
<p>0 1000 2000 3000 4000 5000
25
</p>
<p>30
</p>
<p>35
</p>
<p>40
</p>
<p>45
</p>
<p>50
Eat meat &minus; example 1
</p>
<p>Time
</p>
<p>X
 A
</p>
<p>cc
el
</p>
<p>er
at
</p>
<p>io
n
</p>
<p>0 2000 4000 6000
25
</p>
<p>30
</p>
<p>35
</p>
<p>40
</p>
<p>45
Eat meat &minus; example 4
</p>
<p>Time
</p>
<p>X
 A
</p>
<p>cc
el
</p>
<p>er
at
</p>
<p>io
n
</p>
<p>0 2000 4000 6000 8000
20
</p>
<p>25
</p>
<p>30
</p>
<p>35
</p>
<p>40
</p>
<p>45
Eat meat &minus; example 3
</p>
<p>Time
</p>
<p>X
 A
</p>
<p>cc
el
</p>
<p>er
at
</p>
<p>io
n
</p>
<p>0 1000 2000 3000 4000 5000
25
</p>
<p>30
</p>
<p>35
</p>
<p>40
</p>
<p>45
Eat meat &minus; example 2
</p>
<p>Time
</p>
<p>X
 A
</p>
<p>cc
el
</p>
<p>er
at
</p>
<p>io
n
</p>
<p>Fig. 12.11 Some examples from the accelerometer dataset at https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+
Wrist-worn+Accelerometer. I have labelled each signal by the activity. These show acceleration in the X direction (Y and Z are in the dataset, too).
There are four examples for brushing teeth and four for eat meat. You should notice that the examples don&rsquo;t have the same length in time (some
are slower and some faster eaters, etc.), but that there seem to be characteristic features that are shared within a category (brushing teeth seems to
involve faster movements than eating meet)</p>
<p/>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer">https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer">https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer">https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer">https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer</a></div>
</div>
<div class="page"><p/>
<p>12.4 Describing Repetition with Vector Quantization 299
</p>
<p>Fig. 12.12 Some cluster centers
from the accelerometer dataset.
Each cluster center represents a
one-second burst of activity.
There are a total of 480 in my
model, which I built using
hierarchical k-means. Notice
there are a couple of centers that
appear to represent movement at
about 5 Hz; another few that
represent movement at about
2 Hz; some that look like 0.5 Hz
movement; and some that seem to
represent much lower frequency
movement. These cluster centers
are samples (rather than chosen
to have this property)
</p>
<p>0 10 20 30 40
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>Time
</p>
<p>X
 A
</p>
<p>cc
el
</p>
<p>er
at
</p>
<p>io
n
</p>
<p>Accelerometer cluster centers
</p>
<p>100 200 300 400
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
Climb stairs
</p>
<p>100 200 300 400
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
Climb stairs
</p>
<p>100 200 300 400
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
Climb stairs
</p>
<p>100 200 300 400
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
Climb stairs
</p>
<p>100 200 300 400
0
</p>
<p>.05
</p>
<p>0.1
</p>
<p>.15
</p>
<p>0.2
Comb hair
</p>
<p>100 200 300 400
0
</p>
<p>.05
</p>
<p>0.1
</p>
<p>.15
</p>
<p>0.2
Comb hair
</p>
<p>100 200 300 400
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
Comb hair
</p>
<p>100 200 300 400
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
Comb hair
</p>
<p>100 200 300 400
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
Brush teeth
</p>
<p>100 200 300 400
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
Brush teeth
</p>
<p>100 200 300 400
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
Brush teeth
</p>
<p>100 200 300 400
0
</p>
<p>0.05
</p>
<p>0.1
</p>
<p>0.15
</p>
<p>0.2
Brush teeth
</p>
<p>Fig. 12.13 Histograms of cluster centers for the accelerometer dataset, for different activities. You should notice that (a) these histograms look
somewhat similar for different actors performing the same activity and (b) these histograms look somewhat different for different activities
</p>
<p>in the wrong place. This resulted in about 40,000 segments. I then used hierarchical k-means to cluster these segments. I
</p>
<p>used two levels, with 40 cluster centers at the first level, and 12 at the second. Figure 12.12 shows some cluster centers at the
</p>
<p>second level.
</p>
<p>I then computed histogram representations for different example signals (Fig. 12.13). You should notice that when the
</p>
<p>activity label is different, the histogram looks different, too.
</p>
<p>Another useful way to check this representation is to compare the average within class chi-squared distance with the
</p>
<p>average between class chi-squared distance. I computed the histogram for each example. Then, for each pair of examples, I</p>
<p/>
</div>
<div class="page"><p/>
<p>300 12 Clustering: Models of High Dimensional Data
</p>
<p>Table 12.1 Each column of the
table represents an activity for the
activity dataset https://archive.ics.
uci.edu/ml/datasets/Dataset+for+
ADL+Recognition+with+Wrist-
worn+Accelerometer, as does
each row
</p>
<p>0:9 2:0 1:9 2:0 2:0 2:0 1:9 2:0 1:9 1:9 2:0 2:0 2:0 2:0
</p>
<p>1:6 2:0 1:8 2:0 2:0 2:0 1:9 1:9 2:0 1:9 1:9 2:0 1:7
</p>
<p>1:5 2:0 1:9 1:9 1:9 1:9 1:9 1:9 1:9 1:9 1:9 2:0
</p>
<p>1:4 2:0 2:0 2:0 2:0 2:0 2:0 2:0 2:0 2:0 1:8
</p>
<p>1:5 1:8 1:7 1:9 1:9 1:8 1:9 1:9 1:8 2:0
</p>
<p>0:9 1:7 1:9 1:9 1:8 1:9 1:9 1:9 2:0
</p>
<p>0:3 1:9 1:9 1:5 1:9 1:9 1:9 2:0
</p>
<p>1:8 1:8 1:9 1:9 1:9 1:9 1:9
</p>
<p>1:7 1:9 1:9 1:9 1:9 1:9
</p>
<p>1:6 1:9 1:9 1:9 2:0
</p>
<p>1:8 1:9 1:9 1:9
</p>
<p>1:8 2:0 1:9
</p>
<p>1:5 2:0
</p>
<p>1:5
</p>
<p>In each of the upper diagonal cells, I have placed
the average chi-squared distance between his-
tograms of examples from that pair of classes (I
dropped the lower diagonal for clarity). Notice that
in general the diagonal terms (average within class
distance) are rather smaller than the off diagonal
terms. This quite strongly suggests we can use
these histograms to classify examples successfully
</p>
<p>computed the chi-squared distance between the pair. Finally, for each pair of activity labels, I computed the average distance
</p>
<p>between pairs of examples where one example has one of the activity labels and the other example has the other activity
</p>
<p>label. In the ideal case, all the examples with the same label would be very close to one another, and all examples with
</p>
<p>different labels would be rather different. Table 12.1 shows what happens with the real data. You should notice that for
</p>
<p>some pairs of activity label, the mean distance between examples is smaller than one would hope for (perhaps some pairs of
</p>
<p>examples are quite close?). But generally, examples of activities with different labels tend to be further apart than examples
</p>
<p>of activities with the same label.
</p>
<p>Yet another way to check the representation is to try classification with nearest neighbors, using the chi-squared distance
</p>
<p>to compute distances. I split the dataset into 80 test pairs and 360 training pairs; using 1-nearest neighbors, I was able to get
</p>
<p>a held-out error rate of 0.79. This suggests that the representation is fairly good at exposing what is important.
</p>
<p>12.5 TheMultivariate Normal Distribution
</p>
<p>All the nasty facts about high dimensional data, above, suggest that we need to use quite simple probability models. By far
</p>
<p>the most important model is the multivariate normal distribution, which is quite often known as the multivariate gaussian
</p>
<p>distribution. We will not use a multivariate normal distribution explicitly in what follows, though if you look hard enough
</p>
<p>you might see it lurking beneath the surface in a couple of places. However, it&rsquo;s useful to have seen the basics, which you are
</p>
<p>quite likely to bump into elsewhere.
</p>
<p>There are two sets of parameters in this model, the mean � and the covariance &dagger;. For a d-dimensional model, the mean
</p>
<p>is a d-dimensional column vector and the covariance is a d � d dimensional matrix. The covariance is a symmetric matrix.
For our definitions to be meaningful, the covariance matrix must be positive definite.
</p>
<p>The form of the distribution p.xj�;&dagger;/ is
</p>
<p>p.xj�;&dagger;/ D 1p
.2�/ddet.&dagger;/
</p>
<p>exp
</p>
<p>�
</p>
<p>�1
2
.x � �/T&dagger;�1.x � �/
</p>
<p>�
</p>
<p>:
</p>
<p>The following facts explain the names of the parameters:</p>
<p/>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer">https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer">https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer">https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer">https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer</a></div>
</div>
<div class="page"><p/>
<p>12.5 The Multivariate Normal Distribution 301
</p>
<p>Useful Facts 12.1 (Parameters of a Multivariate Normal Distribution)
</p>
<p>Assuming a multivariate normal distribution, we have
</p>
<p>&bull; EŒx&#141; D �, meaning that the mean of the distribution is �.
&bull; E
</p>
<p>�
</p>
<p>.x � �/.x � �/T
�
</p>
<p>D &dagger;, meaning that the entries in &dagger; represent covariances.
</p>
<p>Assume I know have a dataset of items xi, where i runs from 1 to N, and we wish to model this data with a multivariate
</p>
<p>normal distribution. The maximum likelihood estimate of the mean, O�, is
</p>
<p>O� D
P
</p>
<p>i xi
</p>
<p>N
</p>
<p>(which is quite easy to show). The maximum likelihood estimate of the covariance, O&dagger;, is
</p>
<p>O&dagger; D
P
</p>
<p>i.xi � O�/.xi � O�/T
N
</p>
<p>(which is rather a nuisance to show, because you need to know how to differentiate a determinant). These facts mean that we
</p>
<p>already know most of what is interesting about multivariate normal distributions (or gaussians).
</p>
<p>12.5.1 Affine Transformations and Gaussians
</p>
<p>Gaussians behave very well under affine transformations. In fact, we&rsquo;ve already worked out all the math. There is one
</p>
<p>caveat, which is worth mentioning. You can&rsquo;t build a multivariate gaussian distribution unless the covariance is positive
</p>
<p>definite, because the distribution doesn&rsquo;t normalize. Assume I have a dataset xi. The mean of the maximum likelihood
</p>
<p>gaussian model is mean .fxig/, and the covariance is Covmat .fxig/, as long as Covmat .fxig/ is positive definite. I can now
transform the data with an affine transformation, to get yi D AxiCb. As long as Covmat .fyig/ is positive definite, we can fit
a multivariate gaussian with maximum likelihood. The mean of the maximum likelihood gaussian model for the transformed
</p>
<p>dataset is mean .fyig/, and we&rsquo;ve dealt with this; similarly, the covariance is Covmat .fyig/, and we&rsquo;ve dealt with this, too.
A very important point follows in an obvious way. I can apply an affine transformation to any multivariate gaussian to
</p>
<p>obtain one with (a) zero mean and (b) independent components. In turn, this means that, in the right coordinate system, any
</p>
<p>gaussian is a product of zero mean one-dimensional normal distributions. This fact is quite useful. For example, it means that
</p>
<p>simulating multivariate normal distributions is quite straightforward&mdash;you could simulate a standard normal distribution for
</p>
<p>each component, then apply an affine transformation.
</p>
<p>12.5.2 Plotting a 2D Gaussian: Covariance Ellipses
</p>
<p>There are some useful tricks for plotting a 2D Gaussian, which are worth knowing both because they&rsquo;re useful, and they
</p>
<p>help to understand Gaussians. Assume we are working in 2D; we have a Gaussian with mean � (which is a 2D vector), and
</p>
<p>covariance &dagger; (which is a 2� 2 matrix). We could plot the collection of points x that has some fixed value of p.xj�;&dagger;/. This
set of points is given by:
</p>
<p>1
</p>
<p>2
</p>
<p>�
</p>
<p>.x � �/T&dagger;�1.x � �/
�
</p>
<p>D c2
</p>
<p>where c is some constant. I will choose c2 D 1
2
, because the choice doesn&rsquo;t matter, and this choice simplifies some algebra.
</p>
<p>You might recall that a set of points x that satisfies a quadratic like this is a conic section. Because &dagger; (and so &dagger;�1) is positive
definite, the curve is an ellipse. There is a useful relationship between the geometry of this ellipse and the Gaussian.
</p>
<p>This ellipse&mdash;like all ellipses&mdash;has a major axis and a minor axis. These are at right angles, and meet at the center of the
</p>
<p>ellipse. We can determine the properties of the ellipse in terms of the Gaussian quite easily. The geometry of the ellipse isn&rsquo;t</p>
<p/>
</div>
<div class="page"><p/>
<p>302 12 Clustering: Models of High Dimensional Data
</p>
<p>affected by rotation or translation, so we will translate the ellipse so that � D 0 (i.e. the mean is at the origin) and rotate it so
that &dagger;�1 is diagonal. Writing x D Œx; y&#141; we get that the set of points on the ellipse satisfies
</p>
<p>1
</p>
<p>2
.
1
</p>
<p>k21
x2 C 1
</p>
<p>k22
y2/ D 1
</p>
<p>2
</p>
<p>where 1
k21
</p>
<p>and 1
k22
</p>
<p>are the diagonal elements of &dagger;�1. We will assume that the ellipse has been rotated so that k1 &lt; k2. The points
</p>
<p>.k1; 0/ and .�k1; 0/ lie on the ellipse, as do the points .0; k2/ and .0;�k2/. The major axis of the ellipse, in this coordinate
system, is the x-axis, and the minor axis is the y-axis. In this coordinate system, x and y are independent. If you do a little
</p>
<p>algebra, you will see that the standard deviation of x is abs .k1/ and the standard deviation of y is abs .k2/. So the ellipse is
</p>
<p>longer in the direction of largest standard deviation and shorter in the direction of smallest standard deviation.
</p>
<p>Now rotating the ellipse is means we will pre- and post-multiply the covariance matrix with some rotation matrix.
</p>
<p>Translating it will move the origin to the mean. As a result, the ellipse has its center at the mean, its major axis is in the
</p>
<p>direction of the eigenvector of the covariance with largest eigenvalue, and its minor axis is in the direction of the eigenvector
</p>
<p>with smallest eigenvalue. A plot of this ellipse, which can be coaxed out of most programming environments with relatively
</p>
<p>little effort, gives us a great deal of information about the underlying Gaussian. These ellipses are known as covariance
</p>
<p>ellipses.
</p>
<p>Remember this: The multivariate normal distribution has the form
</p>
<p>p.xj�;&dagger;/ D 1p
.2�/ddet.&dagger;/
</p>
<p>exp
</p>
<p>�
</p>
<p>�1
2
.x � �/T&dagger;�1.x � �/
</p>
<p>�
</p>
<p>:
</p>
<p>Assume you wish to model a dataset fxg with a multivariate normal distribution. This will work as long as
Covmat .fxg/ is positive definite. The maximum likelihood estimate of the mean is mean .fxg/. The maximum
likelihood estimate of the covariance &dagger; is Covmat .fxg/.
</p>
<p>12.6 You Should
</p>
<p>12.6.1 Remember These Definitions
</p>
<p>12.6.2 Remember These Terms
</p>
<p>clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281
</p>
<p>clusters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
</p>
<p>cluster center . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
</p>
<p>single-link clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
</p>
<p>complete-link clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
</p>
<p>group average clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
</p>
<p>dendrogram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284
</p>
<p>whitening . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286
</p>
<p>k-means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
</p>
<p>affinity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
</p>
<p>vector quantization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296
</p>
<p>covariance ellipses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302</p>
<p/>
</div>
<div class="page"><p/>
<p>Programming Exercises 303
</p>
<p>12.6.3 Remember These Facts
</p>
<p>Parameters of a Multivariate Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301
</p>
<p>12.6.4 Use These Procedures
</p>
<p>To cluster agglomeratively . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
</p>
<p>To cluster divisively . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284
</p>
<p>To cluster with k-means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
</p>
<p>To cluster with k-means, soft weights . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
</p>
<p>To build a dictionary for vector quantization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296
</p>
<p>To represent a signal with vector quantization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296
</p>
<p>Programming Exercises
</p>
<p>12.13 You can find a dataset dealing with European employment in 1979 at http://dasl.datadesk.com/data/view/47. This
</p>
<p>dataset gives the percentage of people employed in each of a set of areas in 1979 for each of a set of European countries.
</p>
<p>(a) Use an agglomerative clusterer to cluster this data. Produce a dendrogram of this data for each of single link, complete
</p>
<p>link, and group average clustering. You should label the countries on the axis. What structure in the data does each
</p>
<p>method expose? it&rsquo;s fine to look for code, rather than writing your own. Hint: I made plots I liked a lot using R&rsquo;s
</p>
<p>hclust clustering function, and then turning the result into a phylogenetic tree and using a fan plot, a trick I found
</p>
<p>on the web; try plot(as.phylo(hclustre- sult),type=&rdquo;fan&rdquo;). You should see dendrograms that &ldquo;make
</p>
<p>sense&rdquo; (at least if you remember some European history), and have interesting differences.
</p>
<p>(b) Using k-means, cluster this dataset. What is a good choice of k for this data and why?
</p>
<p>12.14 Obtain the activities of daily life dataset from the UC Irvine machine learning website (https://archive.ics.uci.
</p>
<p>edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer; data provided by Barbara Bruno, Fulvio
</p>
<p>Mastrogiovanni and Antonio Sgorbissa).
</p>
<p>(a) Build a classifier that classifies sequences into one of the 14 activities provided. To make features, you should vector
</p>
<p>quantize, then use a histogram of cluster centers (as described in the subsection; this gives a pretty explicit set of steps
</p>
<p>to follow). You will find it helpful to use hierarchical k-means to vector quantize. You may use whatever multi-class
</p>
<p>classifier you wish, though I&rsquo;d start with R&rsquo;s decision forest, because it&rsquo;s easy to use and effective. You should report (a)
</p>
<p>the total error rate and (b) the class confusion matrix of your classifier.
</p>
<p>(b) Now see if you can improve your classifier by (a) modifying the number of cluster centers in your hierarchical k-means
</p>
<p>and (b) modifying the size of the fixed length samples that you use.
</p>
<p>CIFAR-10 and Vector Quantization Exercises
</p>
<p>The following exercises are elaborate, but rewarding. The CIFAR-10 dataset is a set of labelled images in 10 classes, collected
</p>
<p>by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The dataset consists of 60,000 32 � 32 colour images in 10 classes,
with 6000 images per class. There are 50,000 training images and 10,000 test images. You can find this dataset at https://www.
</p>
<p>cs.toronto.edu/~kriz/cifar.html; at that site, you will find pointers to information about how well various methods work, etc.,
</p>
<p>too. The creators ask that anyone using this dataset acknowledge the technical report &ldquo;Learning Multiple Layers of Features
</p>
<p>from Tiny Images,&rdquo; by Alex Krizhevsky written in 2009. It is very widely used to check simple image classification methods.</p>
<p/>
<div class="annotation"><a href="http://dasl.datadesk.com/data/view/47">http://dasl.datadesk.com/data/view/47</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer">https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer</a></div>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer">https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer</a></div>
<div class="annotation"><a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></div>
<div class="annotation"><a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></div>
</div>
<div class="page"><p/>
<p>304 12 Clustering: Models of High Dimensional Data
</p>
<p>12.15 We will start by visualizing CIFAR-10.
</p>
<p>(a) For each category, compute the mean image and the first 20 principal components. Plot the error resulting from
</p>
<p>representing the images of each category using the first 20 principal components against the category.
</p>
<p>(b) Compute the distances between mean images for each pair of classes. Use principal coordinate analysis to make a 2D
</p>
<p>map of the means of each categories. For this exercise, compute distances by thinking of the images as vectors.
</p>
<p>(c) Here is another measure of the similarity of two classes. For class A and class B, define E.A ! B/ to be the average
error obtained by representing all the images of class A using the mean of class A and the first 20 principal components
</p>
<p>of class B. Now define the similarity between classes to be .1=2/.E.A ! B/ C E.B ! A//. Use principal coordinate
analysis to make a 2D map of the classes. Compare this map to the map in the previous exercise&mdash;are they different?
</p>
<p>why?
</p>
<p>12.16 We will build a simple baseline. Here is a simple feature construction (called &ldquo;local PCA&rdquo; in the MNIST exercises).
</p>
<p>First, compute the first d principal components for each image class separately. Now for any image, compute a 10d
</p>
<p>dimensional feature vector by, for each class, subtracting that class mean from the image, then projecting the image onto
</p>
<p>the d principal components for that class. Finally, stack all 10 d dimensional features you get. This measures how much the
</p>
<p>difference between the image and the class mean looks like the difference between images of that class and the class mean.
</p>
<p>Use the local PCA construction to form features for the CIFAR 10 dataset. Use a package to train a decision forest to classify
</p>
<p>these images, using this feature vector. Compare the performance of this baseline to: (a) baselines on https://www.cs.toronto.
</p>
<p>edu/~kriz/cifar.html; and (b) chance.
</p>
<p>12.17 We will use the simplest vector quantization and compare to the baseline of the previous exercise. Construct a
</p>
<p>dictionary using N 8� 8 patches selected at random locations from randomly selected training images. Use k cluster centers,
and (hierarchical) k-means to build your dictionary. Now carve your image into 8 � 8 patches, overlapping by 2, and vector
quantize these patches. This will produce a k-dimensional histogram representing the image.
</p>
<p>(a) Use a package to train a decision forest to classify these images using the vector quantized feature, making a choice of
</p>
<p>N and k that seems reasonable to you. Evaluate the accuracy of this classifier on the test set.
</p>
<p>(b) Investigate the effects of changing N and k on the accuracy of your classifier.
</p>
<p>12.18 Can you improve your MNIST classifiers using vector quantization strategies, as above?</p>
<p/>
<div class="annotation"><a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></div>
<div class="annotation"><a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></div>
</div>
<div class="page"><p/>
<p>13Regression
</p>
<p>Classification tries to predict a class from a data item. Regression tries to predict a value. For example, we know the zip code
</p>
<p>of a house, the square footage of its lot, the number of rooms and the square footage of the house, and we wish to predict
</p>
<p>its likely sale price. As another example, we know the cost and condition of a trading card for sale, and we wish to predict a
</p>
<p>likely profit in buying it and then reselling it. As yet another example, we have a picture with some missing pixels&mdash;perhaps
</p>
<p>there was text covering them, and we want to replace it&mdash;and we want to fill in the missing values. As a final example, you
</p>
<p>can think of classification as a special case of regression, where we want to predict either C1 or �1; this isn&rsquo;t usually the
best way to classify, however. Predicting values is very useful, and so there are many examples like this.
</p>
<p>Some formalities are helpful here. In the simplest case, we have a dataset consisting of a set of N pairs .xi; yi/. We want
</p>
<p>to use the examples we have&mdash;the training examples&mdash;to build a model of the dependence between y and x. This model
</p>
<p>will be used to predict values of y for new values of x, which are usually called test examples. We think of yi as the value
</p>
<p>of some function evaluated at xi, but with some random component. This means there might be two data items where the xi
are the same, and the yi are different. We refer to the xi as explanatory variables and the yi as a dependent variable. We
</p>
<p>regularly say that we are regressing the dependent variable against the explanatory variables.
</p>
<p>13.1 Regression toMake Predictions
</p>
<p>Now imagine that we have one independent variable. An appropriate choice of x and of model (details below) will mean that
</p>
<p>the predictions made by this model will lie on a straight line. Figure 13.1 shows two regressions. The data are plotted with a
</p>
<p>scatter plot, and the line gives the prediction of the model for each value on the x axis.
</p>
<p>We cannot guarantee that different values of x produce different values of y. Data just isn&rsquo;t like this (see the crickets
</p>
<p>example Fig. 13.1). This means you can&rsquo;t think of a regression as predicting the true value of y from x because usually there
</p>
<p>isn&rsquo;t one. Instead, you should think of a regression as predicting the expected value of y conditioned on x. Some regression
</p>
<p>models can produce more information about the probability distribution for y conditioned on x. For example, it might be very
</p>
<p>valuable to get both the mean and variance of the distribution of the likely sale value of a house from independent variables.
</p>
<p>It should be clear that none of this will work if there is not some relationship between the training examples and the test
</p>
<p>examples. If I collect training data on the height and weight of children, I&rsquo;m unlikely to get good predictions of the weight of
</p>
<p>adults from their height. We can be more precise with a probabilistic framework. We think of xi as IID samples from some
</p>
<p>(usually unknown) probability distribution P.X/. Then the test examples should also be IID samples from P.X/, or, at least,
</p>
<p>rather like them&mdash;you usually can&rsquo;t check this point with any certainty.
</p>
<p>A probabilistic formalism can help be precise about the yi, too. Assume another random variable Y has joint distribution
</p>
<p>with X given by P.Y;X/. We think of each yi as a sample from P.Yj fX D xig/. Then our modelling problem would be: given
the training data, build a model that takes a test example x and yields EŒYj fX D xig&#141;.
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_13
</p>
<p>305</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_13">https://doi.org/10.1007/978-3-319-64410-3_13</a></div>
</div>
<div class="page"><p/>
<p>306 13 Regression
</p>
<p>Weight vs length in perch from Lake Laengelmavesi
</p>
<p>Length (cm)
</p>
<p>W
e
ig
</p>
<p>h
t 
(g
</p>
<p>r)
</p>
<p>R^2=0.87
</p>
<p>10 20 30 40 14 15 16 17 18 19 20
</p>
<p>0
2
0
0
</p>
<p>4
0
0
</p>
<p>6
0
0
</p>
<p>8
0
0
</p>
<p>1
0
0
0
</p>
<p>7
0
</p>
<p>7
5
</p>
<p>8
0
</p>
<p>8
5
</p>
<p>9
0
</p>
<p>Chirp frequency vs temperature in crickets
</p>
<p>Frequency
</p>
<p>T
e
m
</p>
<p>p
e
ra
</p>
<p>tu
re
</p>
<p>R^2=0.68
</p>
<p>Fig. 13.1 On the left, a regression of weight against length for perch from a Finnish lake (you can find this dataset, and the back story at http://
www.amstat.org/publications/jse/jse_data_archive.htm; look for &ldquo;fishcatch&rdquo; on that page). Notice that the linear regression fits the data fairly
well, meaning that you should be able to predict the weight of a perch from its length fairly well. On the right, a regression of air temperature
against chirp frequency for crickets. The data is fairly close to the line, meaning that you should be able to tell the temperature from the pitch of
cricket&rsquo;s chirp fairly well. This data is from http://mste.illinois.edu/patel/amar430/keyprob1.html. The R2 you see on each figure is a measure of
the goodness of fit of the regression (Sect. 13.3.5)
</p>
<p>Thinking about the problem this way should make it clear that we&rsquo;re not relying on any exact, physical, or causal
</p>
<p>relationship between Y and X. It&rsquo;s enough that their joint probability makes useful predictions possible, something we
</p>
<p>will test by experiment. This means that you can build regressions that work in somewhat surprising circumstances. For
</p>
<p>example, regressing childrens&rsquo; reading ability against their foot size can be quite successful. This isn&rsquo;t because having big
</p>
<p>feet somehow helps you read. It&rsquo;s because on the whole, older children read better, and also have bigger feet. Regression
</p>
<p>isn&rsquo;t magic. Figure 13.2 shows two regressions where the predictions aren&rsquo;t particularly accurate.
</p>
<p>13.2 Regression to Spot Trends
</p>
<p>Regression isn&rsquo;t only used to predict values. Another reason to build a regression model is to compare trends in data. Doing
</p>
<p>so can make it clear what is really happening. Here is an example from Efron (&ldquo;Computer-Intensive methods in statistical
</p>
<p>regression&rdquo;, B. Efron, SIAM Review, 1988). The table in the appendix shows some data from medical devices, which sit in
</p>
<p>the body and release a hormone. The data shows the amount of hormone currently in a device after it has spent some time in
</p>
<p>service, and the time the device spent in service. The data describes devices from three production lots (A, B, and C). Each
</p>
<p>device, from each lot, is supposed to have the same behavior. The important question is: Are the lots the same? The amount
</p>
<p>of hormone changes over time, so we can&rsquo;t just compare the amounts currently in each device. Instead, we need to determine
</p>
<p>the relationship between time in service and hormone, and see if this relationship is different between batches. We can do so
</p>
<p>by regressing hormone against time.
</p>
<p>Figure 13.3 shows how a regression can help. In this case, we have modelled the amount of hormone in the device as
</p>
<p>a � (time in service) C b
</p>
<p>for a, b chosen to get the best fit (much more on this point later!). This means we can plot each data point on a scatter plot,
</p>
<p>together with the best fitting line. This plot allows us to ask whether any particular batch behaves differently from the overall
</p>
<p>model in any interesting way.</p>
<p/>
<div class="annotation"><a href="http://www.amstat.org/publications/jse/jse_data_archive.htm">http://www.amstat.org/publications/jse/jse_data_archive.htm</a></div>
<div class="annotation"><a href="http://www.amstat.org/publications/jse/jse_data_archive.htm">http://www.amstat.org/publications/jse/jse_data_archive.htm</a></div>
<div class="annotation"><a href="http://mste.illinois.edu/patel/amar430/keyprob1.html">http://mste.illinois.edu/patel/amar430/keyprob1.html</a></div>
</div>
<div class="page"><p/>
<p>13.2 Regression to Spot Trends 307
</p>
<p>Longevity vs Thorax in Female Fruitflies
</p>
<p>Thorax Length (mm)
</p>
<p>L
if
e
</p>
<p>s
p
</p>
<p>a
n
</p>
<p>R^2=0.41
</p>
<p>0.65 0.70 0.75 0.80 0.85 0.90 0.95 97 98 99 100
</p>
<p>2
0
</p>
<p>4
0
</p>
<p>6
0
</p>
<p>8
0
</p>
<p>1
0
</p>
<p>0
</p>
<p>6
0
</p>
<p>6
5
</p>
<p>7
0
</p>
<p>7
5
</p>
<p>8
0
</p>
<p>8
5
</p>
<p>9
0
</p>
<p>Heart rate vs temperature in humans
</p>
<p>Temperature (F)
</p>
<p>H
e
</p>
<p>a
rt
</p>
<p> r
a
</p>
<p>te
 (
</p>
<p>b
p
</p>
<p>m
)
</p>
<p>R^2=0.06
</p>
<p>Fig. 13.2 Regressions do not necessarily yield good predictions or good model fits. On the left, a regression of the lifespan of female fruitflies
against the length of their torso as adults (apparently, this doesn&rsquo;t change as a fruitfly ages; you can find this dataset, and the back story at http://
www.amstat.org/publications/jse/jse_data_archive.htm; look for &ldquo;fruitfly&rdquo; on that page). The figure suggests you can make some prediction of
how long your fruitfly will last by measuring its torso, but not a particularly accurate one. On the right, a regression of heart rate against body
temperature for adults. You can find the data at http://www.amstat.org/publications/jse/jse_data_archive.htm as well; look for &ldquo;temperature&rdquo; on
that page. Notice that predicting heart rate from body temperature isn&rsquo;t going to work that well, either
</p>
<p>50 100 150 200
15
</p>
<p>20
</p>
<p>25
</p>
<p>30
</p>
<p>35
</p>
<p>40
</p>
<p>A
</p>
<p>C
</p>
<p>A
C
</p>
<p>C
</p>
<p>A
</p>
<p>B
</p>
<p>C
</p>
<p>A
</p>
<p>BC
A
</p>
<p>C
</p>
<p>A
</p>
<p>B
C
</p>
<p>A
</p>
<p>B
</p>
<p>C
A
</p>
<p>B
</p>
<p>C
</p>
<p>Time in service
</p>
<p>A
m
</p>
<p>o
u
n
t 
</p>
<p>o
f 
</p>
<p>h
o
rm
</p>
<p>o
n
e
</p>
<p>Hormone against time in service
</p>
<p>50 100 150 200
&minus;6
</p>
<p>&minus;4
</p>
<p>&minus;2
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>A
</p>
<p>C
</p>
<p>A
</p>
<p>C
</p>
<p>C
</p>
<p>A
</p>
<p>B C
</p>
<p>A
</p>
<p>BC
</p>
<p>A
</p>
<p>C
</p>
<p>A
</p>
<p>B
</p>
<p>C
</p>
<p>A
</p>
<p>B
</p>
<p>C
</p>
<p>A
</p>
<p>B
</p>
<p>C
</p>
<p>Time in service
</p>
<p>R
es
</p>
<p>id
u
al
</p>
<p>Regression residual against time
</p>
<p>Fig. 13.3 On the left, a scatter plot of hormone against time for devices from Tables 13.1 and 13.1. Notice that there is a pretty clear relationship
between time and amount of hormone (the longer the device has been in service the less hormone there is). The issue now is to understand that
relationship so that we can tell whether lots A, B and C are the same or different. The best fit line to all the data is shown as well, fitted using
the methods of Sect. 13.3. On the right, a scatter plot of residual&mdash;the distance between each data point and the best fit line&mdash;against time for the
devices from Tables 13.1 and 13.1. Now you should notice a clear difference; some devices from lots B and C have positive and some negative
residuals, but all lot A devices have negative residuals. This means that, when we account for loss of hormone over time, lot A devices still have
less hormone in them. This is pretty good evidence that there is a problem with this lot
</p>
<p>However, it is hard to evaluate the distances between data points and the best fitting line by eye. A sensible alternative is
</p>
<p>to subtract the amount of hormone predicted by the model from the amount that was measured. Doing so yields a residual&mdash;
</p>
<p>the difference between a measurement and a prediction. We can then plot those residuals (Fig. 13.3). In this case, the plot
</p>
<p>suggests that lot A is special&mdash;all devices from this lot contain less hormone than our model predicts.</p>
<p/>
<div class="annotation"><a href="http://www.amstat.org/publications/jse/jse_data_archive.htm">http://www.amstat.org/publications/jse/jse_data_archive.htm</a></div>
<div class="annotation"><a href="http://www.amstat.org/publications/jse/jse_data_archive.htm">http://www.amstat.org/publications/jse/jse_data_archive.htm</a></div>
<div class="annotation"><a href="http://www.amstat.org/publications/jse/jse_data_archive.htm">http://www.amstat.org/publications/jse/jse_data_archive.htm</a></div>
</div>
<div class="page"><p/>
<p>308 13 Regression
</p>
<p>Definition 13.2 (Regression) Regression accepts a feature vector and produces a prediction, which is usually a
</p>
<p>number, but can sometimes have other forms. You can use these predictions as predictions, or to study trends in
</p>
<p>data. It is possible, but not usually particularly helpful, to see classification as a form of regression.
</p>
<p>13.3 Linear Regression and Least Squares
</p>
<p>Assume we have a dataset consisting of a set of N pairs .xi; yi/. We want to use the examples we have&mdash;the training
</p>
<p>examples&mdash;to build a model of the dependence between y and x. This model will be used to predict values of y for new
</p>
<p>values of x, which are usually called test examples. The model needs to have some probabilistic component; we do not
</p>
<p>expect that y is a function of x, and there is likely some error in evaluating y anyhow.
</p>
<p>13.3.1 Linear Regression
</p>
<p>We cannot expect that our model makes perfect predictions. Furthermore, y may not be a function of x&mdash;it is quite possible
</p>
<p>that the same value of x could lead to different y&rsquo;s. One way that this could occur is that y is a measurement (and so subject
</p>
<p>to some measurement noise). Another is that there is some randomness in y. For example, we expect that two houses with
</p>
<p>the same set of features (the x) might still sell for different prices (the y&rsquo;s).
</p>
<p>A good, simple model is to assume that the dependent variable (i.e. y) is obtained by evaluating a linear function of the
</p>
<p>explanatory variables (i.e. x), then adding a zero-mean normal random variable. We can write this model as
</p>
<p>y D xTˇ C �
</p>
<p>where � represents random (or at least, unmodelled) effects. In this expression, ˇ is a vector of weights, which we must
</p>
<p>estimate. We will always assume that � has zero mean, so that
</p>
<p>EŒYj fX D xig&#141; D xiˇ:
</p>
<p>When we use this model to predict a value of y for a particular set of explanatory variables x�, we cannot predict the value
that � will take. Our best available prediction is the mean value (which is zero). Notice that if x D 0, the model predicts y D 0.
This may seem like a problem to you&mdash;you might be concerned that we can fit only lines through the origin&mdash;but remember
</p>
<p>that x contains explanatory variables, and we can choose what appears in x. The two examples show how a sensible choice
</p>
<p>of x allows us to fit a line with an arbitrary y-intercept.
</p>
<p>Definition 13.3 (Linear Regression) A linear regression takes the feature vector x and predicts xTˇ, for some vector
</p>
<p>of coefficients ˇ. The coefficients are adjusted, using data, to produce the best predictions.
</p>
<p>Example 13.3 (A Linear Model Fitted to a Single Explanatory Variable) Assume we fit a linear model to a single
</p>
<p>explanatory variable. Then the model has the form y D xˇC � , where � is a zero mean random variable. For any value
x� of the explanatory variable, our best estimate of y is ˇx�. In particular, if x� D 0, the model predicts y D 0, which is
unfortunate. We can draw the model by drawing a line through the origin with slope ˇ in the x, y plane. The y-intercept
</p>
<p>of this line must be zero.</p>
<p/>
</div>
<div class="page"><p/>
<p>13.3 Linear Regression and Least Squares 309
</p>
<p>Example 13.4 (A Linear Model with a Non-Zero y-Intercept) Assume we have a single explanatory variable, which
</p>
<p>we write u. We can then create a vector x D Œu; 1&#141;T from the explanatory variable. We now fit a linear model to this
vector. Then the model has the form y D xTˇC� , where � is a zero mean random variable. For any value x� D Œu�; 1&#141;T
of the explanatory variable, our best estimate of y is .x�/Tˇ, which can be written as y D ˇ1u� C ˇ2. If x� D 0, the
model predicts y D ˇ2. We can draw the model by drawing a line through the origin with slope ˇ1 and y-intercept ˇ2
in the x, y plane.
</p>
<p>13.3.2 Choosing ˇ
</p>
<p>We must determine ˇ. We can proceed in two ways. I show both because different people find different lines of reasoning
</p>
<p>more compelling. Each will get us to the same solution. One is probabilistic, the other isn&rsquo;t. Generally, I&rsquo;ll proceed as if
</p>
<p>they&rsquo;re interchangeable, although at least in principle they&rsquo;re different.
</p>
<p>Probabilistic approach: we could assume that � is a zero mean normal random variable with unknown variance. Then
</p>
<p>P.yjx; ˇ/ is normal, with mean xTˇ, and so we can write out the log-likelihood of the data. Write �2 for the variance of � ,
which we don&rsquo;t know, but will not worry about right now. We have that
</p>
<p>logL.ˇ/ D �
X
</p>
<p>i
</p>
<p>logP.yijxi; ˇ/
</p>
<p>D 1
2�2
</p>
<p>X
</p>
<p>i
</p>
<p>.yi � xTi ˇ/2
</p>
<p>C term not depending on ˇ
</p>
<p>Maximizing the log-likelihood of the data is equivalent to minimizing the negative log-likelihood of the data. Furthermore,
</p>
<p>the term 1
2�2
</p>
<p>does not affect the location of the minimum, so we must have that ˇ minimizes
P
</p>
<p>i.yi � xTi ˇ/2, or anything
proportional to it. It is helpful to minimize an expression that is an average of squared errors, because (hopefully) this doesn&rsquo;t
</p>
<p>grow much when we add data. We therefore minimize
</p>
<p>�
</p>
<p>1
</p>
<p>N
</p>
<p>�
</p>
<p> 
</p>
<p>X
</p>
<p>i
</p>
<p>.yi � xTi ˇ/2
!
</p>
<p>:
</p>
<p>Direct approach: notice that, if we have an estimate of ˇ, we have an estimate of the values of the unmodelled effects �i
for each example. We just take �i D yi � xTi ˇ. It is quite natural to make the unmodelled effects &ldquo;small&rdquo;. A good measure of
size is the mean of the squared values, which means we want to minimize
</p>
<p>�
</p>
<p>1
</p>
<p>N
</p>
<p>�
</p>
<p> 
</p>
<p>X
</p>
<p>i
</p>
<p>.yi � xTi ˇ/2
!
</p>
<p>:
</p>
<p>13.3.3 Solving the Least Squares Problem
</p>
<p>We can write all this more conveniently using vectors and matrices. Write y for the vector
</p>
<p>0
</p>
<p>B
</p>
<p>B
</p>
<p>@
</p>
<p>y1
y2
: : :
</p>
<p>yn
</p>
<p>1
</p>
<p>C
</p>
<p>C
</p>
<p>A</p>
<p/>
</div>
<div class="page"><p/>
<p>310 13 Regression
</p>
<p>and X for the matrix
0
</p>
<p>@
</p>
<p>xT1
xT2
</p>
<p>: : : xTn
</p>
<p>1
</p>
<p>A :
</p>
<p>Then we want to minimize
�
</p>
<p>1
</p>
<p>N
</p>
<p>�
</p>
<p>�
</p>
<p>y � Xˇ/T.y � Xˇ
�
</p>
<p>which means that we must have
</p>
<p>X TXˇ � X Ty D 0:
</p>
<p>For reasonable choices of features, we could expect that X TX&mdash;which should strike you as being a lot like a covariance
</p>
<p>matrix&mdash;has full rank. If it does, which is the usual case, this equation is easy to solve. If it does not, there is more to do,
</p>
<p>which we will do in Sect. 13.4.4.
</p>
<p>Remember this: The vector of coefficients ˇ for a linear regression is usually estimated using a least-squares
</p>
<p>procedure.
</p>
<p>13.3.4 Residuals
</p>
<p>Assume we have produced a regression by solving
</p>
<p>X TX Ǒ � X Ty D 0
</p>
<p>for the value of Ǒ. I write Ǒ because this is an estimate; we likely don&rsquo;t have the true value of the ˇ that generated the data
(the model might be wrong; etc.). We cannot expect that X Ǒ is the same as y. Instead, there is likely to be some error. The
residual is the vector
</p>
<p>e D y � X Ǒ
</p>
<p>which gives the difference between the true value and the model&rsquo;s prediction at each point. Each component of the residual
</p>
<p>is an estimate of the unmodelled effects for that data point. The mean square error is
</p>
<p>m D e
Te
</p>
<p>N
</p>
<p>and this gives the average of the squared error of prediction on the training examples.
</p>
<p>Notice that the mean squared error is not a great measure of how good the regression is. This is because the value depends
</p>
<p>on the units in which the dependent variable is measured. So, for example, if you measure y in meters you will get a different
</p>
<p>mean squared error than if you measure y in kilometers for the same dataset. This is a serious nuisance, because it means that
</p>
<p>the value of the mean squared error cannot tell you how good a regression is. There is an alternative measure of the accuracy
</p>
<p>of a regression which does not depends on the units of y.
</p>
<p>13.3.5 R-Squared
</p>
<p>Unless the dependent variable is a constant (which would make prediction easy), it has some variance. If our model is of
</p>
<p>any use, it should explain some aspects of the value of the dependent variable. This means that the variance of the residual
</p>
<p>should be smaller than the variance of the dependent variable. If the model made perfect predictions, then the variance of the
</p>
<p>residual should be zero.</p>
<p/>
</div>
<div class="page"><p/>
<p>13.3 Linear Regression and Least Squares 311
</p>
<p>We can formalize all this in a relatively straightforward way. We will ensure that X always has a column of ones in it, so
</p>
<p>that the regression can have a non-zero y-intercept. We now fit a model
</p>
<p>y D Xˇ C e
</p>
<p>(where e is the vector of residual values) by choosing ˇ such that eTe is minimized. Then we get some useful technical
</p>
<p>results.
</p>
<p>Useful Facts 13.1 (Regression)
</p>
<p>We write y D X Ǒ C e, where e is the residual. For a vector v of N components, we write v D .1=N/1Tv. Assume X
has a column of ones, and Ǒ is chosen to minimize eTe. Then we have
</p>
<p>1. eTX D 0, i.e. that e is orthogonal to any column of X . If e is not orthogonal to some column of e, we can increase
or decrease the Ǒ term corresponding to that column to make the error smaller. Another way to see this is to notice
that Ǒ is chosen to minimize 1
</p>
<p>N
eTe, which is 1
</p>
<p>N
.y � X Ǒ/T.y � X Ǒ/. Now because this is a minimum, the gradient
</p>
<p>with respect to Ǒ is zero, so .y � X Ǒ/T.�X / D �eTX D 0.
2. eT1 D 0 (recall that X has a column of all ones, and apply the previous result).
3. eTX Ǒ D 0 (first result means that this is true).
4. 1T.y � X Ǒ/ D 0 (same as previous result).
5. y D X Ǒ (same as previous result).
</p>
<p>Now y is a one dimensional dataset arranged into a vector, so we can compute mean .fyg/ and varŒy&#141;. Similarly, X Ǒ is a
one dimensional dataset arranged into a vector (its elements are xTi
</p>
<p>Ǒ), as is e, so we know the meaning of mean and variance
for each. We have a particularly important result:
</p>
<p>varŒy&#141; D var
h
</p>
<p>X Ǒ
i
</p>
<p>C varŒe&#141;:
</p>
<p>This is quite easy to show, with a little more notation. Write y D .1=N/.1Ty/1 for the vector whose entries are all mean .fyg/;
similarly for e and for X Ǒ. We have
</p>
<p>varŒy&#141; D .1=N/.y � y/T.y � y/
</p>
<p>and so on for varŒei&#141;, etc. Notice from the facts that y D X Ǒ. Now
</p>
<p>varŒy&#141; D .1=N/
�h
</p>
<p>X Ǒ � X Ǒ
i
</p>
<p>C Œe � e&#141;
�T �h
</p>
<p>X Ǒ � X Ǒ
i
</p>
<p>C Œe � e&#141;
�
</p>
<p>D .1=N/
�
</p>
<p>h
</p>
<p>X Ǒ � X Ǒ
iT h
</p>
<p>X Ǒ � X Ǒ
i
</p>
<p>C 2 Œe � e&#141;T
h
</p>
<p>X Ǒ � X Ǒ
i
</p>
<p>C Œe � e&#141;T Œe � e&#141;
�
</p>
<p>D .1=N/
�
</p>
<p>h
</p>
<p>X Ǒ � X Ǒ
iT h
</p>
<p>X Ǒ � X Ǒ
i
</p>
<p>C Œe � e&#141;T Œe � e&#141;
�
</p>
<p>because e D 0 and eTX Ǒ D 0 and eT1 D 0
</p>
<p>D var
h
</p>
<p>X Ǒ
i
</p>
<p>C varŒe&#141;:
</p>
<p>This is extremely important, because us allows us to think about a regression as explaining variance in y. As we are better at
</p>
<p>explaining y, varŒe&#141; goes down. In turn, a natural measure of the goodness of a regression is what percentage of the variance
</p>
<p>of y it explains. This is known as R2 (the r-squared measure). We have
</p>
<p>R2 D
var
h
</p>
<p>xTi
Ǒ
i
</p>
<p>varŒyi&#141;</p>
<p/>
</div>
<div class="page"><p/>
<p>312 13 Regression
</p>
<p>which gives some sense of how well the regression explains the training data. Notice that the value of R2 is not affected by
</p>
<p>the units of y (exercises)
</p>
<p>Good predictions result in high values of R2, and a perfect model will have R2 D 1 (which doesn&rsquo;t usually happen). For
example, the regression of Fig. 13.3 has an R2 value of 0.87. Figures 13.1 and 13.2 show the R2 values for the regressions
</p>
<p>plotted there; notice how better models yield larger values of R2. Notice that if you look at the summary that R provides
</p>
<p>for a linear regression, it will offer you two estimates of the value for R2. These estimates are obtained in ways that try to
</p>
<p>account for (a) the amount of data in the regression, and (b) the number of variables in the regression. For our purposes, the
</p>
<p>differences between these numbers and the R2 I defined are not significant. For the figures, I computed R2 as I described in
</p>
<p>the text above, but if you substitute one of R&rsquo;s numbers nothing terrible will happen.
</p>
<p>Remember this: The quality of predictions made by a regression can be evaluated by looking at the fraction of the
</p>
<p>variance in the dependent variable that is explained by the regression. This number is called R2, and lies between zero
</p>
<p>and one; regressions with larger values make better predictions.
</p>
<p>Procedure 13.1 (Linear Regression Using Least Squares) We have a dataset containing N pairs .xi; yi/. Each xi is a
</p>
<p>d-dimensional explanatory vector, and each yi is a single dependent variable. We assume that each data point conforms
</p>
<p>to the model
</p>
<p>yi D xTi ˇ C �i
where �i represents unmodelled effects. We assume that �i are samples of a random variable with 0 mean and unknown
</p>
<p>variance. Sometimes, we assume the random variable is normal. Write
</p>
<p>y D
</p>
<p>0
</p>
<p>@
</p>
<p>y1
: : :
</p>
<p>yn
</p>
<p>1
</p>
<p>A and X D
</p>
<p>0
</p>
<p>@
</p>
<p>xT1
: : :
</p>
<p>xTn
</p>
<p>1
</p>
<p>A :
</p>
<p>We estimate Ǒ (the value of ˇ) by solving the linear system
</p>
<p>X TX Ǒ � X Ty D 0:
</p>
<p>For a data point x, our model predicts xT Ǒ. The residuals are
</p>
<p>e D y � X Ǒ:
</p>
<p>We have that eT1 D 0. The mean square error is given by
</p>
<p>m D e
Te
</p>
<p>N
:
</p>
<p>The R2 is given by
</p>
<p>var
�n
</p>
<p>xTi
Ǒ
o�
</p>
<p>var .fyg/ :
</p>
<p>Values of R2 range from 0 to 1; a larger value means the regression is better at explaining the data.</p>
<p/>
</div>
<div class="page"><p/>
<p>13.4 Producing Good Linear Regressions 313
</p>
<p>13.4 Producing Good Linear Regressions
</p>
<p>Linear regression is useful, but it isn&rsquo;t magic. Some regressions make poor predictions (recall the regressions of Figure 13.2).
</p>
<p>As another example, regressing the first digit of your telephone number against the length of your foot won&rsquo;t work.
</p>
<p>We have some straightforward tests to tell whether a regression is working. You can look at a plot for a dataset with one
</p>
<p>explanatory variable and one dependent variable. You plot the data on a scatter plot, then plot the model as a line on that
</p>
<p>scatterplot. Just looking at the picture can be informative (compare Figs. 13.1 and 13.2).
</p>
<p>You can check if the regression predicts a constant. This is usually a bad sign. You can check this by looking at the
</p>
<p>predictions for each of the training data items. If the variance of these predictions is small compared to the variance of the
</p>
<p>independent variable, the regression isn&rsquo;t working well. If you have only one explanatory variable, then you can plot the
</p>
<p>regression line. If the line is horizontal, or close, then the value of the explanatory variable makes very little contribution to
</p>
<p>the prediction. This suggests that there is no particular relationship between the explanatory variable and the independent
</p>
<p>variable.
</p>
<p>You can also check, by eye, if the residual isn&rsquo;t random. If y�xTˇ is a zero mean normal random variable, then the value
of the residual vector should not depend on the corresponding y-value. Similarly, if y � xTˇ is just a zero mean collection
of unmodelled effects, we want the value of the residual vector to not depend on the corresponding y-value either. If it does,
</p>
<p>that means there is some phenomenon we are not modelling. Looking at a scatter plot of e against y will often reveal trouble
</p>
<p>in a regression (Fig. 13.7). In the case of Fig. 13.7, the trouble is caused by a few data points that are very different from the
</p>
<p>others severely affecting the regression. We will discuss such points in more detail below. Once they have been removed, the
</p>
<p>regression improves markedly (Fig. 13.8).
</p>
<p>Remember this: Linear regressions can make bad predictions. You can check for trouble by: evaluating R2; looking at
</p>
<p>a plot; looking to see if the regression makes a constant prediction; or checking whether the residual is random. Other
</p>
<p>strategies exist, but are beyond the scope of this book.
</p>
<p>13.4.1 Transforming Variables
</p>
<p>Sometimes the data isn&rsquo;t in a form that leads to a good linear regression. In this case, transforming explanatory variables,
</p>
<p>the dependent variable, or both can lead to big improvements. Figure 13.4 shows one example, based on the idea of word
</p>
<p>frequencies. Some words are used very often in text; most are used seldom. The dataset for this figure consists of counts
</p>
<p>of the number of time a word occurred for the 100 most common words in Shakespeare&rsquo;s printed works. It was originally
</p>
<p>collected from a concordance, and has been used to attack a variety of interesting questions, including an attempt to assess
</p>
<p>how many words Shakespeare knew. This is hard, because he likely knew many words that he didn&rsquo;t use in his works, so one
</p>
<p>can&rsquo;t just count. If you look at the plot of Fig. 13.4, you can see that a linear regression of count (the number of times a word
</p>
<p>is used) against rank (how common a word is, 1&ndash;100) is not really useful. The most common words are used very often,
</p>
<p>and the number of times a word is used falls off very sharply as one looks at less common words. You can see this effect
</p>
<p>in the scatter plot of residual against dependent variable in Fig. 13.4&mdash;the residual depends rather strongly on the dependent
</p>
<p>variable. This is an extreme example that illustrates how poor linear regressions can be.
</p>
<p>However, if we regress log-count against log-rank, we get a very good fit indeed. This suggests that Shakespeare&rsquo;s word
</p>
<p>usage (at least for the 100 most common words) is consistent with Zipf&rsquo;s law. This gives the relation between frequency f
</p>
<p>and rank r for a word as
</p>
<p>f / 1
r
</p>
<p>s
</p>
<p>where s is a constant characterizing the distribution. Our linear regression suggests that s is approximately 1:67 for this data.
</p>
<p>In some cases, the natural logic of the problem will suggest variable transformations that improve regression performance.
</p>
<p>For example, one could argue that humans have approximately the same density, and so that weight should scale as the cube
</p>
<p>of height; in turn, this suggests that one regress weight against the cube root of height. Figure 13.5 shows the result of this
</p>
<p>transformation on the fish data, where it appears to help a lot. Generally, shorter people tend not to be scaled versions of taller</p>
<p/>
</div>
<div class="page"><p/>
<p>314 13 Regression
</p>
<p>0
2
0
0
0
</p>
<p>4
0
0
0
</p>
<p>6
0
0
0
</p>
<p>8
0
0
0
</p>
<p>1
0
0
0
0
</p>
<p>1
2
0
0
0
</p>
<p>1
4
0
0
0
</p>
<p>Frequency of word usage in Shakespeare
</p>
<p>Rank
</p>
<p>N
u
m
</p>
<p>b
e
r 
</p>
<p>o
f 
a
p
p
e
a
ra
</p>
<p>n
c
e
s
</p>
<p>0 20 40 60 80 100 0 1 2 3 4
</p>
<p>2
4
</p>
<p>6
8
</p>
<p>Frequency of word usage in Shakespeare, log&minus;log
</p>
<p>Log rank
</p>
<p>L
o
</p>
<p>g
 n
</p>
<p>u
m
</p>
<p>b
e
</p>
<p>r 
o
</p>
<p>f 
a
</p>
<p>p
p
</p>
<p>e
a
</p>
<p>ra
n
</p>
<p>c
e
</p>
<p>s
Fig. 13.4 On the left, word count plotted against rank for the 100 most common words in Shakespeare, using a dataset that comes with R (called
&ldquo;bard&rdquo;, and quite likely originating in an unpublished report by J. Gani and I. Saunders). I show a regression line too. This is a poor fit by eye,
and the R2 is poor, too (R2 D 0:1). On the right, log word count plotted against log rank for the 100 most common words in Shakespeare, using a
dataset that comes with R (called &ldquo;bard&rdquo;, and quite likely originating in an unpublished report by J. Gani and I. Saunders). The regression line is
very close to the data
</p>
<p>people, so the cube root might be too aggressive. The body mass index (BMI: a controversial but not completely pointless
</p>
<p>measure of the relationship between weight and height) uses the square root.
</p>
<p>Remember this: The performance of a regression can be improved by transforming variables. Transformations can
</p>
<p>follow from looking at plots, or thinking about the logic of the problem
</p>
<p>13.4.2 ProblemData Points Have Significant Impact
</p>
<p>Outlying data points can significantly weaken the usefulness of a regression. For some regression problems, we can identify
</p>
<p>data points that might be a problem, and then resolve how to deal with them. One possibility is that they are true outliers&mdash;
</p>
<p>someone recorded a data item wrong, or they represent an effect that just doesn&rsquo;t occur all that often. Another is that they
</p>
<p>are important data, and our linear model may not be good enough. If the data points really are outliers, we can drop them
</p>
<p>from the data set. If they aren&rsquo;t, we may be able to improve the regression by transforming features or by finding a new
</p>
<p>explanatory variable.
</p>
<p>When we construct a regression, we are solving for the ˇ that minimizes
P
</p>
<p>i.yi � xTi ˇ/2, equivalently for the ˇ that
produces the smallest value of
</p>
<p>P
</p>
<p>i e
2
i . This means that residuals with large value can have a very strong influence on the
</p>
<p>outcome&mdash;we are squaring that large value, resulting in an enormous value. Generally, many residuals of medium size will
</p>
<p>have a smaller cost than one large residual and the rest tiny. As Fig. 13.6 illustrates, this means that a data point that lies far
</p>
<p>from the others can swing the regression line significantly (which affects the residual, Fig. 13.7).
</p>
<p>This creates a problem, because data points that are very different from most others (sometimes called outliers) can also
</p>
<p>have the highest influence on the outcome of the regression. Figure 13.8 shows this effect for a simple case. When we have
</p>
<p>only one explanatory variable, there&rsquo;s an easy method to spot problem data points. We produce a scatter plot and a regression
</p>
<p>line, and the difficulty is usually obvious. In particularly tricky cases, printing the plot and using a see-through ruler to draw
</p>
<p>a line by eye can help (if you use an opaque ruler, you may not see some errors).</p>
<p/>
</div>
<div class="page"><p/>
<p>13.4 Producing Good Linear Regressions 315
</p>
<p>0
2
</p>
<p>0
0
</p>
<p>4
0
</p>
<p>0
6
</p>
<p>0
0
</p>
<p>8
0
</p>
<p>0
1
</p>
<p>0
0
</p>
<p>0
Weight vs length^3 in 
</p>
<p> perch from Lake Laengelmavesi
</p>
<p>Length^3 (cm^3)
</p>
<p>W
e
</p>
<p>ig
h
</p>
<p>t 
(g
</p>
<p>r)
</p>
<p>0e+00 2e+04 4e+04 6e+04 8e+04 1e+05 10 20 30 40
</p>
<p>2
4
</p>
<p>6
8
</p>
<p>1
0
</p>
<p>Weight^(1/3) vs length in 
</p>
<p> perch from Lake Laengelmavesi
</p>
<p>Length (cm)
</p>
<p>W
e
</p>
<p>ig
h
</p>
<p>t^
(1
</p>
<p>/3
) 
</p>
<p>(g
r^
</p>
<p>(1
/3
</p>
<p>))
Weight predicted from length^3 in
</p>
<p>perch from Lake Laengelmavesi
</p>
<p>Length (cm)
</p>
<p>W
e
</p>
<p>ig
h
</p>
<p>t 
(g
</p>
<p>r)
</p>
<p>10 20 30 40 10 20 30 40
</p>
<p>0
2
</p>
<p>0
0
</p>
<p>4
0
</p>
<p>0
6
</p>
<p>0
0
</p>
<p>8
0
</p>
<p>0
1
</p>
<p>0
0
</p>
<p>0
</p>
<p>0
2
</p>
<p>0
0
</p>
<p>4
0
</p>
<p>0
6
</p>
<p>0
0
</p>
<p>8
0
</p>
<p>0
1
</p>
<p>0
0
</p>
<p>0
</p>
<p>Weight^(1/3) predicted from length in
</p>
<p>perch from Lake Laengelmavesi
</p>
<p>Length (cm)
</p>
<p>W
e
</p>
<p>ig
h
</p>
<p>t 
(g
</p>
<p>r)
</p>
<p>Fig. 13.5 Two variable transformations on the perch dataset. On the top left, weight predicted from length cubed; on the top right, cube root of
weight predicted from length. On the bottom corresponding plots transformed to weight-length coordinates (you need to look very closely to see
the differences). The non-linear transformation helps significantly
</p>
<p>These data points can come from many sources. They may simply be errors. Failures of equipment, transcription errors,
</p>
<p>someone guessing a value to replace lost data, and so on are some methods that might produce outliers. Another possibility
</p>
<p>is your understanding of the problem is wrong. If there are some rare effects that are very different than the most common
</p>
<p>case, you might see outliers. Major scientific discoveries have resulted from investigators taking outliers seriously, and trying
</p>
<p>to find out what caused them (though you shouldn&rsquo;t see a Nobel prize lurking behind every outlier).
</p>
<p>What to do about outliers is even more fraught. The simplest strategy is to find them, then remove them from the data.
</p>
<p>For low dimensional models, you can do this by plotting data and predictions, then looking for problems. There are other
</p>
<p>methods, but they are too complicated for us. You should be aware that this strategy can get dangerous fairly quickly, whether
</p>
<p>you use a simple or a sophisticated method. First, you might find that each time you remove a few problematic data points,</p>
<p/>
</div>
<div class="page"><p/>
<p>316 13 Regression
</p>
<p>xv
</p>
<p>y
v
</p>
<p>&minus;40 &minus;20 0 20 40 &minus;40 &minus;20 0 20 40
</p>
<p>&minus;
4
</p>
<p>0
&minus;
</p>
<p>2
0
</p>
<p>0
2
</p>
<p>0
4
</p>
<p>0
</p>
<p>&minus;
4
</p>
<p>0
&minus;
</p>
<p>2
0
</p>
<p>0
2
</p>
<p>0
4
</p>
<p>0
</p>
<p>nxv
</p>
<p>n
y
v
</p>
<p>Fig. 13.6 On the left, a synthetic dataset with one independent and one explanatory variable, with the regression line plotted. Notice the line is
close to the data points, and its predictions seem likely to be reliable. On the right, the result of adding a single outlying datapoint to that dataset.
The regression line has changed significantly, because the regression line tries to minimize the sum of squared vertical distances between the data
points and the line. Because the outlying datapoint is far from the line, the squared vertical distance to this point is enormous. The line has moved
to reduce this distance, at the cost of making the other points further from the line
</p>
<p>Weight against height, all points
</p>
<p>Height
</p>
<p>W
e
</p>
<p>ig
h
</p>
<p>t
</p>
<p>30 40 50 60 70 80 100 150 200 250
</p>
<p>1
0
</p>
<p>0
1
</p>
<p>5
0
</p>
<p>2
0
</p>
<p>0
2
</p>
<p>5
0
</p>
<p>3
0
</p>
<p>0
3
</p>
<p>5
0
</p>
<p>&minus;
5
</p>
<p>0
0
</p>
<p>5
0
</p>
<p>1
0
</p>
<p>0
1
</p>
<p>5
0
</p>
<p>Residuals against fitted values, weight against height,
</p>
<p>all points
</p>
<p>Fitted values
</p>
<p>R
e
</p>
<p>s
id
</p>
<p>u
a
</p>
<p>ls
</p>
<p>Fig. 13.7 On the left, weight regressed against height for the bodyfat dataset. The line doesn&rsquo;t describe the data particularly well, because it
has been strongly affected by a few data points (filled-in markers). On the right, a scatter plot of the residual against the value predicted by the
regression. This doesn&rsquo;t look like noise, which is a sign of trouble
</p>
<p>some more data points look strange to you. This process is unlikely to end well. Second, you should be aware that throwing
</p>
<p>out outliers can increase your future prediction error, particularly if they&rsquo;re caused by real effects. An alternative strategy is
</p>
<p>to build methods that can either discount or model the effects of outliers.</p>
<p/>
</div>
<div class="page"><p/>
<p>13.4 Producing Good Linear Regressions 317
</p>
<p>Weight against height, 4 outliers removed
</p>
<p>Height
</p>
<p>W
e
ig
</p>
<p>h
t
</p>
<p>30 40 50 60 70 80 100 150 200 250
</p>
<p>1
0
0
</p>
<p>1
5
0
</p>
<p>2
0
0
</p>
<p>2
5
0
</p>
<p>3
0
0
</p>
<p>3
5
0
</p>
<p>&minus;
5
0
</p>
<p>0
5
0
</p>
<p>1
0
0
</p>
<p>1
5
0
</p>
<p>Residuals against fitted values, weight against height,
</p>
<p>4 outliers removed
</p>
<p>Fitted values
</p>
<p>R
e
s
id
</p>
<p>u
a
ls
</p>
<p>Fig. 13.8 On the left, weight regressed against height for the bodyfat dataset. I have now removed the four suspicious looking data points,
identified in Fig. 13.7 with filled-in markers; these seemed the most likely to be outliers. On the right, a scatter plot of the residual against the value
predicted by the regression. Notice that the residual looks like noise. The residual seems to be uncorrelated to the predicted value; the mean of
the residual seems to be zero; and the variance of the residual doesn&rsquo;t depend on the predicted value. All these are good signs, consistent with our
model, and suggest the regression will yield good predictions
</p>
<p>Remember this: Outliers can affect linear regressions significantly. Usually, if you can plot the regression, you can
</p>
<p>look for outliers by eyeballing the plot. Other methods exist, but are beyond the scope of this text.
</p>
<p>13.4.3 Functions of One Explanatory Variable
</p>
<p>Imagine we have only one measurement to form explanatory variables. For example, in the perch data of Fig. 13.1, we have
</p>
<p>only the length of the fish. If we evaluate functions of that measurement, and insert them into the vector of explanatory
</p>
<p>variables, the resulting regression is still easy to plot. It may also offer better predictions. The fitted line of Fig. 13.1 looks
</p>
<p>quite good, but the data points look as though they might be willing to follow a curve. We can get a curve quite easily. Our
</p>
<p>current model gives the weight as a linear function of the length with a noise term (which we wrote yi D ˇ1xi C ˇ0 C �i).
But we could expand this model to incorporate other functions of the length. In fact, it&rsquo;s quite surprising that the weight of a
</p>
<p>fish should be predicted by its length. If the fish doubled in each direction, say, its weight should go up by a factor of eight.
</p>
<p>The success of our regression suggests that fish do not just scale in each direction as they grow. But we might try the model
</p>
<p>yi D ˇ2x2i Cˇ1xiCˇ0C�i. This is easy to do. The i&rsquo;th row of the matrix X currently looks like Œxi; 1&#141;. We build a new matrix
X .b/, where the i&rsquo;th row is Œx2i ; xi; 1&#141;, and proceed as before. This gets us a new model. The nice thing about this model is that
</p>
<p>it is easy to plot&mdash;our predicted weight is still a function of the length, it&rsquo;s just not a linear function of the length. Several
</p>
<p>such models are plotted in Fig. 13.9.
</p>
<p>You should notice that it can be quite easy to add a lot of functions like this (in the case of the fish, I tried x3i as well).
</p>
<p>However, it&rsquo;s hard to decide whether the regression has actually gotten better. The least-squares error on the training data
</p>
<p>will never go up when you add new explanatory variables, so the R2 will never get worse. This is easy to see, because you
</p>
<p>could always use a coefficient of zero with the new variables and get back the previous regression. However, the models that
</p>
<p>you choose are likely to produce worse and worse predictions as you add explanatory variables. Knowing when to stop can
</p>
<p>be tough, though it&rsquo;s sometimes obvious that the model is untrustworthy (Fig. 13.9).</p>
<p/>
</div>
<div class="page"><p/>
<p>318 13 Regression
</p>
<p>Weight vs length in  perch from Lake
</p>
<p>Laengelmavesi, three models.
</p>
<p>Length (cm)
</p>
<p>W
e
ig
</p>
<p>h
t 
(g
</p>
<p>r)
</p>
<p>linear
quadratic
cubic
</p>
<p>10 20 30 40 10 20 30 40
</p>
<p>0
2
0
0
</p>
<p>4
0
0
</p>
<p>6
0
0
</p>
<p>8
0
0
</p>
<p>1
0
0
0
</p>
<p>0
2
0
0
</p>
<p>4
0
0
</p>
<p>6
0
0
</p>
<p>8
0
0
</p>
<p>1
0
0
0
</p>
<p>Weight vs length in  perch from Lake
</p>
<p>Laengelmavesi, all powers up to 10.
</p>
<p>Length (cm)
</p>
<p>W
e
ig
</p>
<p>h
t 
(g
</p>
<p>r)
Fig. 13.9 On the left, several different models predicting fish weight from length. The line uses the explanatory variables 1 and xi; and the curves
use other monomials in xi as well, as shown by the legend. This allows the models to predict curves that lie closer to the data. It is important to
understand that, while you can make a curve go closer to the data by inserting monomials, that doesn&rsquo;t mean you necessarily have a better model.
On the right, I have used monomials up to x10i . This curve lies very much closer to the data points than any on the other side, at the cost of some
very odd looking wiggles in between data points (look at small lengths; the model goes quite strongly negative there, but I can&rsquo;t bring myself to
change the axes and show predictions that are obvious nonsense). I can&rsquo;t think of any reason that these structures would come from true properties
of fish, and it would be hard to trust predictions from this model
</p>
<p>Remember this: If you have only one measurement, you can construct a high dimensional x by using functions of that
</p>
<p>measurement. This produces a regression that has many explanatory variables, but is still easy to plot. Knowing when
</p>
<p>to stop is hard. An understanding of the problem is helpful.
</p>
<p>13.4.4 Regularizing Linear Regressions
</p>
<p>When we have many explanatory variables, some might be significantly correlated. This means that we can predict, quite
</p>
<p>accurately, the value of one explanatory variable using the values of the other variables. This means there must be a vector
</p>
<p>w so that Xw is small (exercises). In turn, that wTX TXw must be small, so that X TX has some small eigenvalues. These
</p>
<p>small eigenvalues lead to bad predictions, as follows. The vector w has the property that X TXw is small. This means that
</p>
<p>X TX . Ǒ C w/ is not much different from X TX Ǒ (equivalently, the matrix can turn large vectors into small ones). All this
means that .X TX /�1 will turn some small vectors into big ones. A small change in X TY can lead to a large change in the
estimate of Ǒ.
</p>
<p>This is a problem, because we can expect that different samples from the same data will have somewhat different values
</p>
<p>of X TY. For example, imagine the person recording fish measurements in Lake Laengelmavesi recorded a different set of
</p>
<p>fish; we expect changes in X and Y. But, if X TX has small eigenvalues, these changes could produce large changes in our
</p>
<p>model (Figs. 13.10 and 13.11).
</p>
<p>The problem is relatively easy to control. When there are small eigenvalues in X TX , we expect that Ǒ will be large
(because we can add components in the direction of w without changing all that much), and the largest components in Ǒ
might be very inaccurately estimated. If we are trying to predict new y values, we expect that large components in Ǒ turn into
large errors in prediction (exercises).</p>
<p/>
</div>
<div class="page"><p/>
<p>13.4 Producing Good Linear Regressions 319
</p>
<p>log(Lambda)
</p>
<p>M
e
a
n
&minus;
</p>
<p>S
q
u
a
re
</p>
<p>d
 E
</p>
<p>rr
o
r
</p>
<p>NA NA NA NA NA NA NA NA NA NA NA NA NA NA
</p>
<p>four outliers removed
</p>
<p>2 4 6 8 64 66 68 70 72 74 76 78
</p>
<p>4
5
0
</p>
<p>5
0
0
</p>
<p>5
5
0
</p>
<p>6
0
0
</p>
<p>6
5
0
</p>
<p>7
0
0
</p>
<p>7
5
0
</p>
<p>1
2
0
</p>
<p>1
4
0
</p>
<p>1
6
0
</p>
<p>1
8
0
</p>
<p>2
0
0
</p>
<p>2
2
0
</p>
<p>2
4
0
</p>
<p>Linear regression of Weight against Height,
</p>
<p> four outliers removed
</p>
<p>Height
</p>
<p>W
e
ig
</p>
<p>h
t
</p>
<p>no regularization
</p>
<p>regularization
</p>
<p>Fig. 13.10 On the left, cross-validated error estimated for different choices of regularization constant for a linear regression of weight against
height for the bodyfat dataset, with four outliers removed. The horizontal axis is log regression constant; the vertical is cross-validated error. The
mean of the error is shown as a spot, with vertical error bars. The vertical lines show a range of reasonable choices of regularization constant (left
yields the lowest observed error, right the error whose mean is within one standard error of the minimum). On the right, two regression lines on a
scatter plot of this dataset; one is the line computed without regularization, the other is obtained using the regularization parameter that yields the
lowest observed error. In this case, the regularizer doesn&rsquo;t change the line much, but may produce improved values on new data (notice how the
cross-validated error is fairly flat with low values of the regularization constant)
</p>
<p>An important and useful way to suppress these errors is to try to find a Ǒ that isn&rsquo;t large, and also gives a low error. We
can do this by regularizing, using the same trick we saw in the case of classification. Instead of choosing the value of ˇ that
</p>
<p>minimizes
�
</p>
<p>1
</p>
<p>N
</p>
<p>�
</p>
<p>.y � Xˇ/T.y � Xˇ/
</p>
<p>we minimize
</p>
<p>�
</p>
<p>1
</p>
<p>N
</p>
<p>�
</p>
<p>.y � Xˇ/T.y � Xˇ/ C �ˇTˇ
</p>
<p>Error C Regularizer
</p>
<p>Here � &gt; 0 is a constant (the regularization weight, though it&rsquo;s pretty widely known as �) that weights the two requirements
</p>
<p>(small error; small Ǒ) relative to one another. Notice also that dividing the total error by the number of data points means
that our choice of � shouldn&rsquo;t be affected by changes in the size of the data set.
</p>
<p>Regularization helps deal with the small eigenvalue, because to solve for ˇ we must solve the equation
</p>
<p>��
</p>
<p>1
</p>
<p>N
</p>
<p>�
</p>
<p>X TX C �I
�
</p>
<p>Ǒ D
�
</p>
<p>1
</p>
<p>N
</p>
<p>�
</p>
<p>X Ty
</p>
<p>(obtained by differentiating with respect to ˇ and setting to zero) and the smallest eigenvalue of the matrix .
�
</p>
<p>1
N
</p>
<p>�
</p>
<p>.X TXC�I/
will be at least � (exercises). Penalizing a regression with the size of ˇ in this way is sometimes known as ridge regression.
</p>
<p>The value of � that is most helpful depends on the dataset. Typically, one sets up a range of values, then searches, using
</p>
<p>cross-validation to estimate the error.</p>
<p/>
</div>
<div class="page"><p/>
<p>320 13 Regression
</p>
<p>log(Lambda)
</p>
<p>M
e
</p>
<p>a
n
</p>
<p>&minus;
S
</p>
<p>q
u
</p>
<p>a
re
</p>
<p>d
 E
</p>
<p>rr
o
</p>
<p>r
</p>
<p>NA NA NA NA NA NA NA NA NA NA NA NA NA NA
</p>
<p>all points
</p>
<p>2 4 6 8 30 40 50 60 70
</p>
<p>7
0
</p>
<p>0
8
</p>
<p>0
0
</p>
<p>9
0
</p>
<p>0
1
</p>
<p>0
0
</p>
<p>0
1
</p>
<p>1
0
</p>
<p>0
1
</p>
<p>2
0
</p>
<p>0
</p>
<p>1
5
</p>
<p>0
2
</p>
<p>0
0
</p>
<p>2
5
</p>
<p>0
3
</p>
<p>0
0
</p>
<p>3
5
</p>
<p>0
</p>
<p>Linear regression of Weight against Height,
</p>
<p> all points
</p>
<p>Height
</p>
<p>W
e
</p>
<p>ig
h
</p>
<p>t
</p>
<p>no regularization
</p>
<p>regularization
</p>
<p>Fig. 13.11 Regularization doesn&rsquo;t make outliers go away. On the left, cross-validated error estimated for different choices of regularization
constant for a linear regression of weight against height for the bodyfat dataset, with all points. The horizontal axis is log regression constant; the
vertical is cross-validated error. The mean of the error is shown as a spot, with vertical error bars. The vertical lines show a range of reasonable
choices of regularization constant (left yields the lowest observed error, right the error whose mean is within one standard error of the minimum).
On the right, two regression lines on a scatter plot of this dataset; one is the line computed without regularization, the other is obtained using the
regularization parameter that yields the lowest observed error. In this case, the regularizer doesn&rsquo;t change the line much, but may produce improved
values on new data (notice how the cross-validated error is fairly flat with low values of the regularization constant)
</p>
<p>Worked example 13.1 (Predicting the Weight of a Fish with Regularized Linear Regression) We have already
</p>
<p>seen how to predict the weight of a fish using different powers of its length (Sects. 13.4.1 and 13.4.3; Fig. 13.9).
</p>
<p>Section 13.4.3 showed that using too many powers would likely lead to poor predictions on test data. Show that
</p>
<p>regularization can be used to control this problem.
</p>
<p>Solution The main point of this example is how useful good statistical software can be, and to draw your attention to
</p>
<p>an excellent package. The package I use for regressions, glmnet, will choose a good range of regularization weights
</p>
<p>(�&rsquo;s) and compute estimates of the mean and standard deviation of the squared cross-validated error for various values
</p>
<p>in that range. It then prepares a nice plot of this information, which makes the impact of the regularization clear. I&rsquo;ve
</p>
<p>shown such a plot in Fig. 13.12. In this problem, quite a large value of the regularization constant produces the best
</p>
<p>result. I&rsquo;ve also show a plot of the predictions made, with the coefficients of each power of length used in the regression
</p>
<p>for the best value of the regularization constant. You should notice that the coefficient of length and its square are fairly
</p>
<p>high, there&rsquo;s a small value of the coefficient for the cube of length, and for higher powers the coefficients are pretty
</p>
<p>tiny. If you&rsquo;re careful, you&rsquo;ll check that the coefficients are small compared to the scale of the numbers (because the
</p>
<p>10&rsquo;th power of 20, say, is big). The curve has no wiggles in it, because these coefficients mean that high powers make
</p>
<p>almost no contribution to its shape.
</p>
<p>We choose � in the same way we used for classification; split the training set into a training piece and a validation piece,
</p>
<p>train for different values of �, and test the resulting regressions on the validation piece. The error is a random variable,
</p>
<p>random because of the random split. It is a fair model of the error that would occur on a randomly chosen test example</p>
<p/>
</div>
<div class="page"><p/>
<p>13.5 Exploiting Your Neighbors for Regression 321
</p>
<p>log(Lambda)
</p>
<p>M
e
</p>
<p>a
n
</p>
<p>&minus;
S
</p>
<p>q
u
</p>
<p>a
re
</p>
<p>d
 E
</p>
<p>rr
o
</p>
<p>r
</p>
<p>10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
</p>
<p>4 6 8 10 12
10 20 30 40
</p>
<p>0
2
0
0
0
0
</p>
<p>4
0
0
0
0
</p>
<p>6
0
0
0
0
</p>
<p>8
0
0
0
0
</p>
<p>1
0
0
0
0
0
</p>
<p>1
2
0
0
0
0
</p>
<p>0
2
</p>
<p>0
0
</p>
<p>4
0
</p>
<p>0
6
</p>
<p>0
0
</p>
<p>8
0
</p>
<p>0
1
</p>
<p>0
0
</p>
<p>0
</p>
<p>Weight vs length in  perch from Lake Laengelmavesi, 
</p>
<p> all powers up to 10, regularized
</p>
<p>Length (cm)
W
</p>
<p>e
ig
</p>
<p>h
t 
</p>
<p>(g
r)
</p>
<p> 1:  6.72
</p>
<p>  2:  0.12
</p>
<p>  3:  2e&minus;3
</p>
<p>  4:  4e&minus;5
</p>
<p>  5:  7e&minus;7
</p>
<p>  6:  1e&minus;8
</p>
<p>   7:  1e&minus;10
</p>
<p>   8:  7e&minus;13
</p>
<p>  9:&minus;3e&minus;14
</p>
<p>10:&minus;2e&minus;15
</p>
<p>Length: Coefficient of power
</p>
<p>Fig. 13.12 Regularization can be a significant help when there are many predictors. On the left, the glmnet plot of cross-validated prediction error
against log regularization coefficient for the perch data of Fig. 13.9. The set of independent variables includes all powers of length up to 10 (as in
the wiggly graph on the right of Fig. 13.9). Notice that the regularization coefficient that yields the smallest error is quite large (the horizontal axis
is on a logarithmic scale). On the right, the curve of predicted values. The cross-validated error chooses a regularization constant that discourages
wiggles; inspecting the coefficients, shown in the inset, shows that high powers of length are firmly suppressed
</p>
<p>(assuming that the training set is &ldquo;like&rdquo; the test set, in a way that I do not wish to make precise yet). We could use multiple
</p>
<p>splits, and average over the splits. Doing so yields both an average error for a value of � and an estimate of the standard
</p>
<p>deviation of error.
</p>
<p>Statistical software will do all the work for you. I used the glmnet package in R; this package is available in Matlab,
</p>
<p>too. There are likely other such packages. Figure 13.10 shows an example, for weight regressed against height. Notice the
</p>
<p>regularization doesn&rsquo;t change the model (plotted in the figure) all that much. For each value of � (horizontal axis), the method
</p>
<p>has computed the mean error and standard deviation of error using cross-validation splits, and displays these with error bars.
</p>
<p>Notice that � D 0 yields poorer predictions than a larger value; large Ǒ really are unreliable. Notice that now there is now no
� that yields the smallest validation error, because the value of error depends on the random splits used in cross-validation.
</p>
<p>A reasonable choice of � lies between the one that yields the smallest error encountered (one vertical line in the plot) and
</p>
<p>the largest value whose mean error is within one standard deviation of the minimum (the other vertical line in the plot).
</p>
<p>All this is quite similar to regularizing a classification problem. We started with a cost function that evaluated the errors
</p>
<p>caused by a choice of ˇ, then added a term that penalized ˇ for being &ldquo;large&rdquo;. This term is the squared length of ˇ, as a
</p>
<p>vector. It is sometimes known as the L2 norm of the vector.
</p>
<p>Remember this: The performance of a regression can be improved by regularizing, particularly if some explanatory
</p>
<p>variables are correlated. The procedure is similar to that used for classification.
</p>
<p>13.5 Exploiting Your Neighbors for Regression
</p>
<p>Nearest neighbors can clearly predict a number for a query example&mdash;you find the closest training example, and report its
</p>
<p>number. This would be one way to use nearest neighbors for regression, but it isn&rsquo;t terribly effective. One important difficulty
</p>
<p>is that the regression prediction is piecewise constant (Fig. 13.13). If there is an immense amount of data, this may not present
</p>
<p>major problems, because the steps in the prediction will be small and close together. But it&rsquo;s not generally an effective use
</p>
<p>of data.</p>
<p/>
</div>
<div class="page"><p/>
<p>322 13 Regression
</p>
<p>&minus;6 &minus;4 &minus;2 0 2 4 6
</p>
<p>&minus;1
</p>
<p>&minus;0.8
</p>
<p>&minus;0.6
</p>
<p>&minus;0.4
</p>
<p>&minus;0.2
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>Explanatory variable
</p>
<p>D
ep
</p>
<p>en
d
en
</p>
<p>t 
v
ar
</p>
<p>ia
b
le
</p>
<p>Nearest Neighbor Regression
</p>
<p>&minus;6 &minus;4 &minus;2 0 2 4 6
&minus;1
</p>
<p>&minus;0.8
</p>
<p>&minus;0.6
</p>
<p>&minus;0.4
</p>
<p>&minus;0.2
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>Explanatory variable
</p>
<p>D
ep
</p>
<p>en
d
en
</p>
<p>t 
v
ar
</p>
<p>ia
b
le
</p>
<p>Nearest Neighbor Regression, 40 pts, k=5
</p>
<p>Inverse Dist
</p>
<p>Exp si=0.1
</p>
<p>Exp si=0.5
</p>
<p>Exp si=1
</p>
<p>&minus;6 &minus;4 &minus;2 0 2 4 6
&minus;1
</p>
<p>&minus;0.8
</p>
<p>&minus;0.6
</p>
<p>&minus;0.4
</p>
<p>&minus;0.2
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>Explanatory variable
</p>
<p>D
ep
</p>
<p>en
d
en
</p>
<p>t 
v
ar
</p>
<p>ia
b
le
</p>
<p>Nearest Neighbor Regression, 40 pts, k=10
</p>
<p>Inverse Dist
</p>
<p>Exp si=0.1
</p>
<p>Exp si=0.5
</p>
<p>Exp si=1
</p>
<p>&minus;6 &minus;4 &minus;2 0 2 4 6
&minus;1
</p>
<p>&minus;0.8
</p>
<p>&minus;0.6
</p>
<p>&minus;0.4
</p>
<p>&minus;0.2
</p>
<p>0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>Explanatory variable
</p>
<p>D
ep
</p>
<p>en
d
en
</p>
<p>t 
v
ar
</p>
<p>ia
b
le
</p>
<p>Nearest Neighbor Regression, 40 pts, k=20
</p>
<p>Inverse Dist
</p>
<p>Exp si=0.1
</p>
<p>Exp si=0.5
</p>
<p>Exp si=1
</p>
<p>Fig. 13.13 Different forms of nearest neighbors regression, predicting y from a one-dimensional x, using a total of 40 training points. Top left:
reporting the nearest neighbor leads to a piecewise constant function. Top right: improvements are available by forming a weighted average of the
five nearest neighbors, using inverse distance weighting or exponential weighting with three different scales. Notice if the scale is small, then the
regression looks a lot like nearest neighbors, and if it is too large, all the weights in the average are nearly the same (which leads to a piecewise
constant structure in the regression). Bottom left and bottom right show that using more neighbors leads to a smoother regression
</p>
<p>A more effective strategy is to find several nearby training examples, and use them to produce an estimate. This approach
</p>
<p>can produce very good regression estimates, because every prediction is made by training examples that are near to the query
</p>
<p>example. However, producing a regression estimate is expensive, because for every query one must find the nearby training
</p>
<p>examples.
</p>
<p>Write x for the query point, and assume that we have already collected the N nearest neighbors, which we write xi. Write
</p>
<p>yi for the value of the dependent variable for the i&rsquo;th of these points. Notice that some of these neighbors could be quite far
</p>
<p>from the query point. We don&rsquo;t want distant points to make as much contribution to the model as nearby points. This suggests
</p>
<p>forming a weighted average of the predictions of each point. Write wi for the weight at the i&rsquo;th point. Then the estimate is
</p>
<p>ypred D
P
</p>
<p>i wiyi
P
</p>
<p>i wi
:
</p>
<p>A variety of weightings are reasonable choices. Write di D jj.x � xi/jj for the distance between the query point and the
i&rsquo;th nearest neighbor. Then inverse distance weighting uses wi D 1=di. Alternatively, we could use an exponential function
to strongly weight down more distant points, using</p>
<p/>
</div>
<div class="page"><p/>
<p>13.6 You Should 323
</p>
<p>wi D exp
��d2i
2�2
</p>
<p>�
</p>
<p>:
</p>
<p>We will need to choose a scale � , which can be done by cross-validation. Hold out some examples, make predictions at the
</p>
<p>held out examples using a variety of different scales, and choose the scale that gives the best held-out error. Alternatively, if
</p>
<p>there are enough nearest neighbors, we could form a distance weighted linear regression, then predict the value at the query
</p>
<p>point from that regression.
</p>
<p>Each of these strategies presents some difficulties when x has high dimension. In that case, it is usual that the nearest
</p>
<p>neighbor is a lot closer than the second nearest neighbor. If this happens, then each of these weighted averages will boil
</p>
<p>down to evaluating the dependent variable at the nearest neighbor (because all the others will have very small weight in the
</p>
<p>average).
</p>
<p>Remember this: Nearest neighbors can be used for regression. In the simplest approach, you find the nearest
</p>
<p>neighbor to your feature vector, and take that neighbor&rsquo;s number as your prediction. More complex approaches smooth
</p>
<p>predictions over multiple neighbors.
</p>
<p>13.5.1 Using Your Neighbors to Predict More than a Number
</p>
<p>Linear regression takes some features and predicts a number. But in practice, one often wants to predict something more
</p>
<p>complex than a number. For example, I might want to predict a parse tree (which has combinatorial structure) from a
</p>
<p>sentence (the explanatory variables). As another example, I might want to predict a map of the shadows in an image (which
</p>
<p>has spatial structure) against an image (the explanatory variables). As yet another example, I might want to predict which
</p>
<p>direction to move the controls on a radio-controlled helicopter (which have to be moved together) against a path plan and the
</p>
<p>current state of the helicopter (the explanatory variables).
</p>
<p>Looking at neighbors is a very good way to solve such problems. The general strategy is relatively simple. We find a
</p>
<p>large collection of pairs of training data. Write xi for the explanatory variables for the i&rsquo;th example, and yi for the dependent
</p>
<p>variable in the i&rsquo;th example. This dependent variable could be anything&mdash;it doesn&rsquo;t need to be a single number. It might be a
</p>
<p>tree, or a shadow map, or a word, or anything at all. I wrote it as a vector because I needed to choose some notation.
</p>
<p>In the simplest, and most general, approach, we obtain a prediction for a new set of explanatory variables x by (a) finding
</p>
<p>the nearest neighbor and then (b) producing the dependent variable for that neighbor. We might vary the strategy slightly by
</p>
<p>using an approximate nearest neighbor. If the dependent variables have enough structure that it is possible to summarize a
</p>
<p>collection of different dependent variables, then we might recover the k nearest neighbors and summarize their dependent
</p>
<p>variables. How we summarize rather depends on the dependent variables. For example, it is a bit difficult to imagine the
</p>
<p>average of a set of trees, but quite straightforward to average images. If the dependent variable was a word, we might not
</p>
<p>be able to average words, but we can vote and choose the most popular word. If the dependent variable is a vector, we can
</p>
<p>compute either distance weighted averages or a distance weighted linear regression.
</p>
<p>Remember this: Nearest neighbors can be used to predict more than numbers.
</p>
<p>13.6 You Should
</p>
<p>13.6.1 Remember These Definitions
</p>
<p>Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308
</p>
<p>Linear regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308</p>
<p/>
</div>
<div class="page"><p/>
<p>324 13 Regression
</p>
<p>13.6.2 Remember These Terms
</p>
<p>Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
</p>
<p>training examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
</p>
<p>test examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
</p>
<p>explanatory variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
</p>
<p>dependent variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
</p>
<p>residual . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310
</p>
<p>mean square error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310
</p>
<p>Zipf&rsquo;s law . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
</p>
<p>outliers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314
</p>
<p>regularization weight . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
</p>
<p>ridge regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
</p>
<p>L2 norm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321
</p>
<p>13.6.3 Remember These Facts
</p>
<p>Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311
</p>
<p>13.6.4 Remember These Procedures
</p>
<p>To regress using least squares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312
</p>
<p>Appendix: Data
</p>
<p>Table 13.1 A table showing the amount of hormone remaining and the time in service for devices from lot A, lot B and lot C
</p>
<p>Batch A Batch B Batch C
</p>
<p>Amount of Time in Amount of Time in Amount of Time in
</p>
<p>hormone service hormone service hormone service
</p>
<p>25.8 99 16.3 376 28.8 119
</p>
<p>20.5 152 11.6 385 22.0 188
</p>
<p>14.3 293 11.8 402 29.7 115
</p>
<p>23.2 155 32.5 29 28.9 88
</p>
<p>20.6 196 32.0 76 32.8 58
</p>
<p>31.1 53 18.0 296 32.5 49
</p>
<p>20.9 184 24.1 151 25.4 150
</p>
<p>20.9 171 26.5 177 31.7 107
</p>
<p>30.4 52 25.8 209 28.5 125
</p>
<p>The numbering is arbitrary (i.e. there&rsquo;s no relationship between device 3 in lot A and device 3 in lot B). We expect that the amount of hormone goes
down as the device spends more time in service, so cannot compare batches just by comparing numbers. This data appeared in &ldquo;Computer-Intensive
methods in statistical regression&rdquo;, B. Efron, SIAM Review, 1988, and is used for Fig. 13.3</p>
<p/>
</div>
<div class="page"><p/>
<p>Problems 325
</p>
<p>Fig. 13.14 A regression of
blood pressure against age, for 30
data points
</p>
<p>0 20 40 60 80
100
</p>
<p>150
</p>
<p>200
</p>
<p>250
</p>
<p>Age in years
</p>
<p>S
y
st
</p>
<p>o
li
</p>
<p>c 
b
lo
</p>
<p>o
d
 p
</p>
<p>re
ss
</p>
<p>u
re
</p>
<p>Blood pressure against age
</p>
<p>Fig. 13.15 A regression of the
number of breeding pairs of
kittiwakes against the area of an
island, for 22 data points
</p>
<p>0 1000 2000 3000 4000
</p>
<p>0
5
</p>
<p>0
0
</p>
<p>0
1
</p>
<p>0
0
</p>
<p>0
0
</p>
<p>1
5
</p>
<p>0
0
</p>
<p>0
</p>
<p>Population vs area for  kittiwake colonies
</p>
<p>Area (km^2)
</p>
<p>P
o
</p>
<p>p
u
</p>
<p>la
ti
o
</p>
<p>n
 (
</p>
<p>n
o
</p>
<p>. 
o
</p>
<p>f 
b
</p>
<p>re
e
</p>
<p>d
in
</p>
<p>g
 p
</p>
<p>a
ir
s
)
</p>
<p>Problems
</p>
<p>13.1 Figure 13.14 shows a linear regression of systolic blood pressure against age. There are 30 data points.
</p>
<p>(a) Write ei D yi � xTi ˇ for the residual. What is the mean .feg/ for this regression?
(b) For this regression, var .fyg/ D 509 and the R2 is 0.4324. What is var .feg/ for this regression?
(c) How well does the regression explain the data?
</p>
<p>(d) What could you do to produce better predictions of blood pressure (without actually measuring blood pressure)?
</p>
<p>13.2 At http://www.statsci.org/data/general/kittiwak.html, you can find a dataset collected by D.K. Cairns in 1988 measuring
</p>
<p>the area available for a seabird (black-legged kittiwake) colony and the number of breeding pairs for a variety of different
</p>
<p>colonies. Figure 13.15 shows a linear regression of the number of breeding pairs against the area. There are 22 data points.
</p>
<p>(a) Write ei D yi � xTi ˇ for the residual. What is the mean .feg/ for this regression?
(b) For this regression, var .fyg/ D 16;491;357 and the R2 is 0.62. What is var .feg/ for this regression?
(c) How well does the regression explain the data? If you had a large island, to what extent would you trust the prediction
</p>
<p>for the number of kittiwakes produced by this regression? If you had a small island, would you trust the answer more?</p>
<p/>
<div class="annotation"><a href="http://www.statsci.org/data/general/kittiwak.html">http://www.statsci.org/data/general/kittiwak.html</a></div>
</div>
<div class="page"><p/>
<p>326 13 Regression
</p>
<p>Population vs log area for kittiwake colonies
</p>
<p>log Area (log km^2)
</p>
<p>P
o
p
u
la
</p>
<p>ti
o
n
 (
</p>
<p>n
o
. 
o
f 
b
re
</p>
<p>e
d
in
</p>
<p>g
 p
</p>
<p>a
ir
s
)
</p>
<p>4 5 6 7 8 4 5 6 7 8
</p>
<p>0
5
0
0
0
</p>
<p>1
0
0
0
0
</p>
<p>1
5
0
0
0
</p>
<p>0
5
0
0
0
</p>
<p>1
0
0
0
0
</p>
<p>1
5
0
0
0
</p>
<p>Population vs log area for kittiwake colonies
</p>
<p>log Area (log km^2)
</p>
<p>P
o
p
u
la
</p>
<p>ti
o
n
 (
</p>
<p>n
o
. 
o
f 
b
re
</p>
<p>e
d
in
</p>
<p>g
 p
</p>
<p>a
ir
s
)
</p>
<p>Fig. 13.16 Left: A regression of the number of breeding pairs of kittiwakes against the log of area of an island, for 22 data points. Right: A
regression of the number of breeding pairs of kittiwakes against the log of area of an island, for 22 data points, using a method that ignores two
likely outliers
</p>
<p>4
6
</p>
<p>8
1
0
</p>
<p>1
2
</p>
<p>1
4
</p>
<p>Sulfate against time for Brunhilda the baboon
</p>
<p>time (hrs)
</p>
<p>S
u
lf
a
te
</p>
<p> c
o
n
c
e
n
tr
</p>
<p>a
ti
o
n
</p>
<p>0 50 100 150 3 4 5 6 7 8 9
</p>
<p>0
2
</p>
<p>4
6
</p>
<p>Residuals against fitted values for sulfate against
</p>
<p>time for Brunhilda the baboon
</p>
<p>fitted value
</p>
<p>re
s
id
</p>
<p>u
a
l
</p>
<p>Fig. 13.17 Left: A regression of the concentration of sulfate in the blood of Brunhilda the baboon against time. Right: For this regression, a plot
of residual against fitted value
</p>
<p>13.3 At http://www.statsci.org/data/general/kittiwak.html, you can find a dataset collected by D.K. Cairns in 1988 measuring
</p>
<p>the area available for a seabird (black-legged kittiwake) colony and the number of breeding pairs for a variety of different
</p>
<p>colonies. Figure 13.16 shows a linear regression of the number of breeding pairs against the log of area. There are 22 data
</p>
<p>points.
</p>
<p>(a) Write ei D yi � xTi ˇ for the residual. What is the mean .feg/ for this regression?</p>
<p/>
<div class="annotation"><a href="http://www.statsci.org/data/general/kittiwak.html">http://www.statsci.org/data/general/kittiwak.html</a></div>
</div>
<div class="page"><p/>
<p>Problems 327
</p>
<p>(b) For this regression, var .fyg/ D 16;491;357 and the R2 is 0.31. What is var .feg/ for this regression?
(c) How well does the regression explain the data? If you had a large island, to what extent would you trust the prediction for
</p>
<p>the number of kittiwakes produced by this regression? If you had a small island, would you trust the answer more? Why?
</p>
<p>(d) Figure 13.16 shows the result of a linear regression that ignores two likely outliers. Would you trust the predictions of
</p>
<p>this regression more? Why?
</p>
<p>13.4 At http://www.statsci.org/data/general/brunhild.html, you will find a dataset that measures the concentration of a
</p>
<p>sulfate in the blood of a baboon named Brunhilda as a function of time. Figure 13.17 plots this data, with a linear regression
</p>
<p>of the concentration against time. I have shown the data, and also a plot of the residual against the predicted value. The
</p>
<p>regression appears to be unsuccessful.
</p>
<p>(a) What suggests the regression has problems?
</p>
<p>(b) What is the cause of the problem, and why?
</p>
<p>(c) What could you do to improve the problems?
</p>
<p>13.5 Assume we have a dataset where Y D Xˇ C � , for some unknown ˇ and � . The term � is a normal random variable
with zero mean, and covariance �2I (i.e. this data really does follow our model).
</p>
<p>(a) Write Ǒ for the estimate of ˇ recovered by least squares, and OY for the values predicted by our model for the training
data points. Show that
</p>
<p>OY D X
�
</p>
<p>X TX
��1
</p>
<p>X TY
</p>
<p>(b) Show that
</p>
<p>EŒOyi � yi&#141; D 0
</p>
<p>for each training data point yi, where the expectation is over the probability distribution of � .
</p>
<p>(c) Show that
</p>
<p>E
</p>
<p>h
</p>
<p>. Ǒ � ˇ/
i
</p>
<p>D 0
</p>
<p>where the expectation is over the probability distribution of � .
</p>
<p>13.6 In this exercise, I will show that the prediction process of Chap. 2 (see page 42) is a linear regression with two
</p>
<p>independent variables. Assume we have N data items which are 2-vectors .x1; y1/; : : : ; .xN ; yN/, where N &gt; 1. These could
</p>
<p>be obtained, for example, by extracting components from larger vectors. As usual, we will write Oxi for xi in normalized
coordinates, and so on. The correlation coefficient is r (this is an important, traditional notation).
</p>
<p>(a) Assume that we have an xo, for which we wish to predict a y value. Show that the value of the prediction obtained using
</p>
<p>the method of page 43 is
</p>
<p>ypred D
std .y/
</p>
<p>std .x/
r.x0 � mean .fxg//C mean .fyg/
</p>
<p>D
�
</p>
<p>std .y/
</p>
<p>std .x/
r
</p>
<p>�
</p>
<p>x0 C
�
</p>
<p>mean .fyg/ � std .x/
std .y/
</p>
<p>mean .fxg/
�
</p>
<p>:
</p>
<p>(b) Show that
</p>
<p>r D mean .f.x � mean .fxg//.y � mean .fyg//g/
std .x/std .y/
</p>
<p>D mean .fxyg/ � mean .fxg/mean .fyg/
std .x/std .y/
</p>
<p>:
</p>
<p>(c) Now write</p>
<p/>
<div class="annotation"><a href="http://www.statsci.org/data/general/brunhild.html">http://www.statsci.org/data/general/brunhild.html</a></div>
</div>
<div class="page"><p/>
<p>328 13 Regression
</p>
<p>X D
</p>
<p>0
</p>
<p>B
</p>
<p>B
</p>
<p>@
</p>
<p>x1 1
</p>
<p>x2 1
</p>
<p>: : : : : :
</p>
<p>xn 1
</p>
<p>1
</p>
<p>C
</p>
<p>C
</p>
<p>A
</p>
<p>and Y D
</p>
<p>0
</p>
<p>B
</p>
<p>B
</p>
<p>@
</p>
<p>y1
y2
: : :
</p>
<p>yn
</p>
<p>1
</p>
<p>C
</p>
<p>C
</p>
<p>A
</p>
<p>:
</p>
<p>The coefficients of the linear regression will be Ǒ, where X TX Ǒ D X TY. Show that
</p>
<p>X TX D N
�
</p>
<p>mean
�˚
</p>
<p>x2
��
</p>
<p>mean .fxg/
mean .fxg/ 1
</p>
<p>�
</p>
<p>D N
�
</p>
<p>std .x/2 C mean .fxg/2 mean .fxg/
mean .fxg/ 1
</p>
<p>�
</p>
<p>(d) Now show that
</p>
<p>X TY D N
�
</p>
<p>mean .fxyg/
mean .fyg/
</p>
<p>�
</p>
<p>D N
�
</p>
<p>std .x/std .y/rC mean .fxg/mean .fyg/
mean .fyg/
</p>
<p>�
</p>
<p>:
</p>
<p>(e) Now show that
�
</p>
<p>X TX
��1 D 1
</p>
<p>N
</p>
<p>1
</p>
<p>std .x/2
</p>
<p>�
</p>
<p>1 �mean .fxg/
�mean .fxg/ std .x/2 C mean .fxg/2
</p>
<p>�
</p>
<p>(f) Now (finally!) show that if Ǒ is the solution to X TX Ǒ � X TY D 0, then
</p>
<p>Ǒ D
 
</p>
<p>r
std.y/
</p>
<p>std.x/
</p>
<p>mean .fyg/ �
�
</p>
<p>r
std.y/
</p>
<p>std.x/
</p>
<p>�
</p>
<p>mean .fxg/
</p>
<p>!
</p>
<p>and use this to argue that the process of page 42 is a linear regression with two independent variables.
</p>
<p>13.7 This exercise investigates the effect of correlation on a regression. Assume we have N data items, .xi; yi/. We will
</p>
<p>investigate what happens when the data have the property that the first component is relatively accurately predicted by the
</p>
<p>other components. Write xi1 for the first component of xi, and xi;O1 for the vector obtained by deleting the first component of
xi. Choose u to predict the first component of the data from the rest with minimum error, so that xi1 D xT
</p>
<p>iO1u C wi. The error
of prediction is wi. Write w for the vector of errors (i.e. the i&rsquo;th component of w is wi). Because w
</p>
<p>Tw is minimized by choice
</p>
<p>of u, we have wT1 D 0 (i.e. the average of the wi&rsquo;s is zero). Assume that these predictions are very good, so that there is
some small positive number � so that wTw � �.
</p>
<p>(a) Write a D Œ�1;u&#141;T . Show that
aTX TXa � �:
</p>
<p>(b) Now show that the smallest eigenvalue of X TX is less than or equal to �.
</p>
<p>(c) Assume that Ǒ is the solution to X TX Ǒ D X TY. Show that there is a unit vector v such that
</p>
<p>.X TY � X TX . Ǒ C v//T.X TY � X TX . Ǒ C v//
</p>
<p>is bounded above by
</p>
<p>�2
</p>
<p>(d) Use the last sub exercises to explain why correlated data will lead to a poor estimate of Ǒ.</p>
<p/>
</div>
<div class="page"><p/>
<p>Programming Exercises 329
</p>
<p>13.8 This exercise explores the effect of regularization on a regression. Assume we have N data items, .xi; yi/. We will
</p>
<p>investigate what happens when the data have the property that the first component is relatively accurately predicted by the
</p>
<p>other components. Write xi1 for the first component of xi, and xi;O1 for the vector obtained by deleting the first component of
xi. Choose u to predict the first component of the data from the rest with minimum error, so that xi1 D xT
</p>
<p>iO1u C wi. The error
of prediction is wi. Write w for the vector of errors (i.e. the i&rsquo;th component of w is wi). Because w
</p>
<p>Tw is minimized by choice
</p>
<p>of u, we have wT1 D 0 (i.e. the average of the wi&rsquo;s is zero). Assume that these predictions are very good, so that there is
some small positive number � so that wTw � �.
</p>
<p>(a) Show that X TX is positive semi-definite, and so all its eigenvalues are non-negative.
</p>
<p>(b) Show that, for any vector v,
</p>
<p>vT
�
</p>
<p>X TX C �I
�
</p>
<p>v � �vTv
</p>
<p>and use this to argue that the smallest eigenvalue of
�
</p>
<p>X TX C �I
�
</p>
<p>is greater than �.
</p>
<p>(c) Write b for an eigenvector of X TX with eigenvalue �b. Show that b is an eigenvector of
�
</p>
<p>X TX C �I
�
</p>
<p>with eigenvalue
</p>
<p>�b C �.
(d) Assume that X TX is positive definite and has no repeated eigenvalues (this doesn&rsquo;t affect the point of this exercise,
</p>
<p>but it greatly simplifies the reasoning). Recall X TX is a d � d matrix which is symmetric, and so has d orthonormal
eigenvectors. Write bi for the i&rsquo;th such vector, and �bi for the corresponding eigenvalue. Show that
</p>
<p>X TXˇ � X TY D 0
</p>
<p>is solved by
</p>
<p>ˇ D
d
X
</p>
<p>iD1
</p>
<p>�
</p>
<p>YTXbi
�
</p>
<p>bi
</p>
<p>�bi
:
</p>
<p>(Hint: an easy way to do this is to show that the eigenvectors are an orthonormal basis for d dimensional space, and that
�
</p>
<p>X TXˇ � X TY
�
</p>
<p>bi D 0 for any i.)
(e) Using the notation of the previous sub exercise, show that
</p>
<p>.X TX C �I/ˇ � X TY D 0
</p>
<p>is solved by
</p>
<p>ˇ D
d
X
</p>
<p>iD1
</p>
<p>�
</p>
<p>YTXbi
�
</p>
<p>bi
</p>
<p>�bi C �
:
</p>
<p>Use this expression to explain why a regularized regression may produce better results on test data than an unregularized
</p>
<p>regression.
</p>
<p>Programming Exercises
</p>
<p>13.9 At http://www.statsci.org/data/general/brunhild.html, you will find a dataset that measures the concentration of a sulfate
</p>
<p>in the blood of a baboon named Brunhilda as a function of time. Build a linear regression of the log of the concentration
</p>
<p>against the log of time.
</p>
<p>(a) Prepare a plot showing (a) the data points and (b) the regression line in log-log coordinates.
</p>
<p>(b) Prepare a plot showing (a) the data points and (b) the regression curve in the original coordinates.
</p>
<p>(c) Plot the residual against the fitted values in log-log and in original coordinates.
</p>
<p>(d) Use your plots to explain whether your regression is good or bad and why.
</p>
<p>13.10 At http://www.statsci.org/data/oz/physical.html, you will find a dataset of measurements by M. Larner, made in 1996.
</p>
<p>These measurements include body mass, and various diameters. Build a linear regression of predicting the body mass from
</p>
<p>these diameters.</p>
<p/>
<div class="annotation"><a href="http://www.statsci.org/data/general/brunhild.html">http://www.statsci.org/data/general/brunhild.html</a></div>
<div class="annotation"><a href="http://www.statsci.org/data/oz/physical.html">http://www.statsci.org/data/oz/physical.html</a></div>
</div>
<div class="page"><p/>
<p>330 13 Regression
</p>
<p>(a) Plot the residual against the fitted values for your regression.
</p>
<p>(b) Now regress the cube root of mass against these diameters. Plot the residual against the fitted values in both these cube
</p>
<p>root coordinates and in the original coordinates.
</p>
<p>(c) Use your plots to explain which regression is better.
</p>
<p>13.11 At https://archive.ics.uci.edu/ml/datasets/Abalone, you will find a dataset of measurements by W. J. Nash, T. L.
</p>
<p>Sellers, S. R. Talbot, A. J. Cawthorn and W. B. Ford, made in 1992. These are a variety of measurements of blacklip
</p>
<p>abalone (Haliotis rubra; delicious by repute) of various ages and genders.
</p>
<p>(a) Build a linear regression predicting the age from the measurements, ignoring gender. Plot the residual against the fitted
</p>
<p>values.
</p>
<p>(b) Build a linear regression predicting the age from the measurements, including gender. There are three levels for gender;
</p>
<p>I&rsquo;m not sure whether this has to do with abalone biology or difficulty in determining gender. You can represent gender
</p>
<p>numerically by choosing one for one level, 0 for another, and -1 for the third. Plot the residual against the fitted values.
</p>
<p>(c) Now build a linear regression predicting the log of age from the measurements, ignoring gender. Plot the residual against
</p>
<p>the fitted values.
</p>
<p>(d) Now build a linear regression predicting the log age from the measurements, including gender, represented as above.
</p>
<p>Plot the residual against the fitted values.
</p>
<p>(e) It turns out that determining the age of an abalone is possible, but difficult (you section the shell, and count rings). Use
</p>
<p>your plots to explain which regression you would use to replace this procedure, and why.
</p>
<p>(f) Can you improve these regressions by using a regularizer? Use glmnet to obtain plots of the cross-validated prediction
</p>
<p>error.</p>
<p/>
<div class="annotation"><a href="https://archive.ics.uci.edu/ml/datasets/Abalone">https://archive.ics.uci.edu/ml/datasets/Abalone</a></div>
</div>
<div class="page"><p/>
<p>14Markov Chains and HiddenMarkovModels
</p>
<p>There are many situations where one must work with sequences. Here is a simple, and classical, example. We see a sequence
</p>
<p>of words, but the last word is missing. I will use the sequence &ldquo;I had a glass of red wine with my grilled xxxx&rdquo;. What is the
</p>
<p>best guess for the missing word? You could obtain one possible answer by counting word frequencies, then replacing the
</p>
<p>missing word with the most common word. This is &ldquo;the&rdquo;, which is not a particularly good guess because it doesn&rsquo;t fit with
</p>
<p>the previous word. Instead, you could find the most common pair of words matching &ldquo;grilled xxxx&rdquo;, and then choose the
</p>
<p>second word. If you do this experiment (I used Google Ngram viewer, and searched for &ldquo;grilled *&rdquo;), you will find mostly
</p>
<p>quite sensible suggestions (I got &ldquo;meats&rdquo;, &ldquo;meat&rdquo;, &ldquo;fish&rdquo;, &ldquo;chicken&rdquo;, in that order). If you want to produce random sequences
</p>
<p>of words, the next word should depend on some of the words you have already produced.
</p>
<p>This observation leads us to a powerful and useful model of sequences: the next item is produced by a probability that
</p>
<p>depends on a short set of previous items. This model has extremely useful applications when one wants to understand speech,
</p>
<p>sound or language.
</p>
<p>14.1 Markov Chains
</p>
<p>A sequence of random variables Xn is a Markov chain if it has the property that,
</p>
<p>P.Xn D jjvalues of all previous states/ D P.Xn D jjXn�1/;
</p>
<p>or, equivalently, only the last state matters in determining the probability of the current state. The probabilities P.Xn D
jjXn�1 D i/ are the transition probabilities. We will always deal with discrete random variables here, and we will assume
that there is a finite number of states. For all our Markov chains, we will assume that
</p>
<p>P.Xn D jjXn�1 D i/ D P.Xn�1 D jjXn�2 D i/:
</p>
<p>This means that the transition probabilities do not change with time. Formally, we focus on discrete time, time homogenous
</p>
<p>Markov chains in a finite state space. With enough technical machinery one can construct many other kinds of Markov chain.
</p>
<p>One natural way to build Markov chains is to take a finite directed graph and label each directed edge from node i to
</p>
<p>node j with a probability. We interpret these probabilities as P.Xn D jjXn�1 D i/ (so the sum of probabilities over outgoing
edges at any node must be 1). The Markov chain is then a biased random walk on this graph. A bug (or any other small
</p>
<p>object you prefer) sits on one of the graph&rsquo;s nodes. At each time step, the bug chooses one of the outgoing edges at random.
</p>
<p>The probability of choosing an edge is given by the probabilities on the drawing of the graph (equivalently, the transition
</p>
<p>probabilities). The bug then follows that edge. The bug keeps doing this until it hits an end state.
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_14
</p>
<p>331</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_14">https://doi.org/10.1007/978-3-319-64410-3_14</a></div>
</div>
<div class="page"><p/>
<p>332 14 Markov Chains and Hidden Markov Models
</p>
<p>Fig. 14.1 A directed graph
representing the coin flip
example. By convention, the end
state is a double circle, and the
start state has an incoming arrow.
I&rsquo;ve labelled the arrows with the
event that leads to the transition,
but haven&rsquo;t bothered to put in the
probabilities, because each is 0.5
</p>
<p>T
</p>
<p>1 2
</p>
<p>HH
</p>
<p>T
</p>
<p>Fig. 14.2 A directed graph
representing the umbrella
example. Notice you can&rsquo;t arrive
at the office wet with the
umbrella at home (you&rsquo;d have
taken it), and so on. Labelling the
edges with probabilities is left to
the reader
</p>
<p>WD D
</p>
<p>D WD
</p>
<p>Home Office
Me
</p>
<p>Home
</p>
<p>Office
</p>
<p>Umbrella
</p>
<p>Worked example 14.1 (Multiple Coin Flips) You choose to flip a fair coin until you see two heads in a row, and then
</p>
<p>stop. Represent the resulting sequence of coin flips with a Markov chain. What is the probability that you flip the coin
</p>
<p>four times?
</p>
<p>Solution Figure 14.1 shows a simple drawing of the directed graph that represents the chain. The last three flips must
</p>
<p>have been THH (otherwise you&rsquo;d go on too long, or end too early). But, because the second flip must be a T , the first
</p>
<p>could be either H or T . This means there are two sequences that work: HTHH and TTHH. So P.4 flips/ D 2=8 D 1=4.
We might want to answer significantly more interesting questions. For example, what is the probability that we
</p>
<p>must flip the coin more than ten times? It is often possible to answer these questions by analysis, but we will use
</p>
<p>simulations.
</p>
<p>Worked example 14.2 (Umbrellas) I own one umbrella, and I walk from home to the office each morning, and back
</p>
<p>each evening. If it is raining (which occurs with probability p, and my umbrella is with me), I take it; if it is not raining,
</p>
<p>I leave the umbrella where it is. We exclude the possibility that it starts raining while I walk. Where I am, and whether
</p>
<p>I am wet or dry, forms a Markov chain. Draw a state machine for this Markov chain.
</p>
<p>Solution Figure 14.2 gives this chain. A more interesting question is with what probability I arrive at my destination
</p>
<p>wet? Again, we will solve this with simulation.
</p>
<p>Notice an important difference between Examples 14.1 and 14.2. In the coin flip case, the sequence of random variables
</p>
<p>can end (and your intuition likely tells you it should do so reliably). We say the Markov chain has an absorbing state&mdash;a
</p>
<p>state that it can never leave. In the example of the umbrella, there is an infinite sequence of random variables, each depending
</p>
<p>on the last. Each state of this chain is recurrent&mdash;it will be seen repeatedly in this infinite sequence. One way to have a state
</p>
<p>that is not recurrent is to have a state with outgoing but no incoming edges.</p>
<p/>
</div>
<div class="page"><p/>
<p>14.1 Markov Chains 333
</p>
<p>2 1j-1
</p>
<p>W
</p>
<p>L L L L
</p>
<p>W W W
</p>
<p>...
</p>
<p>Fig. 14.3 A directed graph representing the gambler&rsquo;s ruin example. I have labelled each state with the amount of money the gambler has at that
state. There are two end states, where the gambler has zero (is ruined), or has j and decides to leave the table. The problem we discuss is to compute
the probability of being ruined, given the start state is s. This means that any state except the end states could be a start state. I have labelled the
state transitions with &ldquo;W&rdquo; (for win) and &ldquo;L&rdquo; for lose, but have omitted the probabilities
</p>
<p>Worked example 14.3 (The Gambler&rsquo;s Ruin) Assume you bet 1 a tossed coin will come up heads. If you win, you
</p>
<p>get 1 and your original stake back. If you lose, you lose your stake. But this coin has the property that P.H/ D p &lt; 1=2.
You have s when you start. You will keep betting until either (a) you have 0 (you are ruined; you can&rsquo;t borrow money)
</p>
<p>or (b) the amount of money you have accumulated is j, where j &gt; s. The coin tosses are independent. The amount of
</p>
<p>money you have is a Markov chain. Draw the underlying state machine. Write P.ruined, starting with sjp/ D ps. It is
straightforward that p0 D 1, pj D 0. Show that
</p>
<p>ps D ppsC1 C .1 � p/ps�1:
</p>
<p>Solution Figure 14.3 illustrates this example. The recurrence relation follows because the coin tosses are independent.
</p>
<p>If you win the first bet, you have sC 1 and if you lose, you have s � 1.
</p>
<p>The gambler&rsquo;s ruin example illustrates some points that are quite characteristic of Markov chains. You can often write
</p>
<p>recurrence relations for the probability of various events. Sometimes you can solve them in closed form, though we will not
</p>
<p>pursue this thought further.
</p>
<p>Useful Facts 14.1 (Markov Chains)
</p>
<p>A Markov chain is a sequence of random variables Xn with the property that,
</p>
<p>P.Xn D jjvalues of all previous states/ D P.Xn D jjXn�1/:
</p>
<p>14.1.1 Transition Probability Matrices
</p>
<p>Define the matrix P with pij D P.Xn D jjXn�1 D i/. Notice that this matrix has the properties that pij � 0 and
X
</p>
<p>j
</p>
<p>pij D 1
</p>
<p>because at the end of each time step the model must be in some state. Equivalently, the sum of transition probabilities for
</p>
<p>outgoing arrows is one. Non-negative matrices with this property are stochastic matrices. By the way, you should look very
</p>
<p>carefully at the i&rsquo;s and j&rsquo;s here&mdash;Markov chains are usually written in terms of row vectors, and this choice makes sense in
</p>
<p>that context.</p>
<p/>
</div>
<div class="page"><p/>
<p>334 14 Markov Chains and Hidden Markov Models
</p>
<p>Fig. 14.4 A virus can exist in
one of 3 strains. At the end of
each year, the virus mutates. With
probability ˛, it chooses
uniformly and at random from
one of the 2 other strains, and
turns into that; with probability
1� ˛, it stays in the strain it is in.
For this figure, we have transition
probabilities p D .1� ˛/ and
q D .˛=2/ 21 3
</p>
<p>p
</p>
<p>q
</p>
<p>p p
</p>
<p>q
</p>
<p>q q
</p>
<p>q
</p>
<p>q
</p>
<p>Worked example 14.4 (Viruses) Write out the transition probability matrix for the virus of Fig. 14.4, assuming that
</p>
<p>˛ D 0:2.
</p>
<p>Solution We have P.Xn D 1jXn�1 D 1/ D .1 � ˛/ D 0:8, and P.Xn D 2jXn�1 D 1/ D ˛=2 D P.Xn D 3jXn�1 D 1/;
so we get
</p>
<p>0
</p>
<p>@
</p>
<p>0:8 0:1 0:1
</p>
<p>0:1 0:8 0:1
</p>
<p>0:1 0:1 0:8
</p>
<p>1
</p>
<p>A
</p>
<p>Now imagine we do not know the initial state of the chain, but instead have a probability distribution. This gives P.X0 D i/
for each state i. It is usual to take these k probabilities and place them in a k-dimensional row vector, which is usually written
</p>
<p>� . From this information, we can compute the probability distribution over the states at time 1 by
</p>
<p>P.X1 D j/ D
X
</p>
<p>i
</p>
<p>P.X1 D j;X0 D i/
</p>
<p>D
X
</p>
<p>i
</p>
<p>P.X1 D jjX0 D i/P.X0 D i/
</p>
<p>D
X
</p>
<p>i
</p>
<p>pij�i:
</p>
<p>If we write p.n/ for the row vector representing the probability distribution of the state at step n, we can write this expression
</p>
<p>as
</p>
<p>p.1/ D �P :
</p>
<p>Now notice that
</p>
<p>P.X2 D j/ D
X
</p>
<p>i
</p>
<p>P.X2 D j;X1 D i/
</p>
<p>D
X
</p>
<p>i
</p>
<p>P.X2 D jjX1 D i/P.X1 D i/
</p>
<p>D
X
</p>
<p>i
</p>
<p>pij
</p>
<p> 
</p>
<p>X
</p>
<p>ki
</p>
<p>pki�k
</p>
<p>!
</p>
<p>:</p>
<p/>
</div>
<div class="page"><p/>
<p>14.1 Markov Chains 335
</p>
<p>so that
</p>
<p>p.n/ D �Pn:
</p>
<p>This expression is useful for simulation, and also allows us to deduce a variety of interesting properties of Markov chains.
</p>
<p>Useful Facts 14.2 (Transition Probability Matrices)
</p>
<p>A finite state Markov chain can be represented with a matrix P of transition probabilities, where the i, j&rsquo;th element
</p>
<p>pij D P.Xn D jjXn�1 D i/. This matrix is a stochastic matrix. If the probability distribution of state Xn�1 is represented
by �n�1, then the probability distribution of state Xn is given by �Tn�1P .
</p>
<p>14.1.2 Stationary Distributions
</p>
<p>Worked example 14.5 (Viruses) We know that the virus of Fig. 14.4 started in strain 1. After two state transitions,
</p>
<p>what is the distribution of states when ˛ D 0:2? when ˛ D 0:9? What happens after 20 state transitions? If the virus
starts in strain 2, what happens after 20 state transitions?
</p>
<p>Solution If the virus started in strain 1, then � D Œ1; 0; 0&#141;. We must compute �.P.˛//2. This yields Œ0:66; 0:17; 0:17&#141;
for the case ˛ D 0:2 and Œ0:4150; 0:2925; 0:2925&#141; for the case ˛ D 0:9. Notice that, because the virus with small ˛
tends to stay in whatever state it is in, the distribution of states after 2 years is still quite peaked; when ˛ is large, the
</p>
<p>distribution of states is quite uniform. After 20 transitions, we have Œ0:3339; 0:3331; 0:3331&#141; for the case ˛ D 0:2 and
Œ0:3333; 0:3333; 0:3333&#141; for the case ˛ D 0:9; you will get similar numbers even if the virus starts in strain 2. After 20
transitions, the virus has largely &ldquo;forgotten&rdquo; what the initial state was.
</p>
<p>In Example 14.5, the distribution of virus strains after a long interval appears not to depend much on the initial strain. This
</p>
<p>property is true of many Markov chains. Assume that our chain has a finite number of states. Assume that any state can be
</p>
<p>reached from any other state, by some sequence of transitions. Such chains are called irreducible. Notice this means there
</p>
<p>is no absorbing state, and the chain cannot get &ldquo;stuck&rdquo; in a state or a collection of states. Then there is a unique vector s,
</p>
<p>usually referred to as the stationary distribution, such that for any initial state distribution � ,
</p>
<p>lim
</p>
<p>n ! 1�P
.n/ D s:
</p>
<p>Equivalently, if the chain has run through many steps, it no longer matters what the initial distribution is. The probability
</p>
<p>distribution over states will be s.
</p>
<p>The stationary distribution can often be found using the following property. Assume the distribution over states is s, and
</p>
<p>the chain goes through one step. Then the new distribution over states must be s too. This means that
</p>
<p>sP D s
</p>
<p>so that s is an eigenvector of PT , with eigenvalue 1. It turns out that, for an irreducible chain, there is exactly one such
</p>
<p>eigenvector.
</p>
<p>The stationary distribution is a useful idea in applications. It allows us to answer quite natural questions, without
</p>
<p>conditioning on the initial state of the chain. For example, in the umbrella case, we might wish to know the probability
</p>
<p>I arrive home wet. This could depend on where the chain starts (Example 14.6). If you look at the figure, the Markov chain
</p>
<p>is irreducible, so there is a stationary distribution and (as long as I&rsquo;ve been going back and forth long enough for the chain
</p>
<p>to &ldquo;forget&rdquo; where it started), the probability it is in a particular state doesn&rsquo;t depend on where it started. So the most sensible
</p>
<p>interpretation of this probability is the probability of a particular state in the stationary distribution.</p>
<p/>
</div>
<div class="page"><p/>
<p>336 14 Markov Chains and Hidden Markov Models
</p>
<p>Fig. 14.5 In this umbrella
example, there can&rsquo;t be a
stationary distribution; what
happens depends on the initial,
random choice of buying/not
buying an umbrella
</p>
<p>WD D
</p>
<p>D WD
</p>
<p>Home Office
Me
</p>
<p>Home
</p>
<p>Office
</p>
<p>Umbrella
</p>
<p>WDWD
</p>
<p>Worked example 14.6 (Umbrellas, But Without a Stationary Distribution) This is a different version of the
</p>
<p>umbrella problem, but with a crucial difference. When I move to town, I decide randomly to buy an umbrella with
</p>
<p>probability 0.5. I then go from office to home and back. If I have bought an umbrella, I behave as in Example 14.2. If
</p>
<p>I have not, I just get wet. Illustrate this Markov chain with a state diagram.
</p>
<p>Solution Figure 14.5 does this. Notice this chain isn&rsquo;t irreducible. The state of the chain in the far future depends on
</p>
<p>where it started (i.e. did I buy an umbrella or not).
</p>
<p>Useful Facts 14.3 (Many Markov Chains Have Stationary Distributions)
</p>
<p>If a Markov chain has a finite set of states, and if it is possible to get from any state to any other state, then the chain
</p>
<p>will have a stationary distribution. A sample state of the chain taken after it has been running for a long time will be a
</p>
<p>sample from that stationary distribution. Once the chain has run for long enough, it will visit states with a frequency
</p>
<p>corresponding to that stationary distribution, though it may take many state transitions to move from state to state.
</p>
<p>14.1.3 Example: Markov Chain Models of Text
</p>
<p>Imagine we wish to model English text. The very simplest model would be to estimate individual letter frequencies (most
</p>
<p>likely, by counting letters in a large body of example text). We might count spaces and punctuation marks as letters. We
</p>
<p>regard the frequencies as probabilities, then model a sequence by repeatedly drawing a letter from that probability model.
</p>
<p>You could even punctuate with this model by regarding punctuation signs as letters, too. We expect this model will produce
</p>
<p>sequences that are poor models of English text&mdash;there will be very long strings of &lsquo;a&rsquo;s, for example. This is clearly a (rather
</p>
<p>dull) Markov chain. It is sometimes referred to as a 0-th order chain or a 0-th order model, because each letter depends on
</p>
<p>the 0 letters behind it.
</p>
<p>A slightly more sophisticated model would be to work with pairs of letters. Again, we would estimate the frequency of
</p>
<p>pairs by counting letter pairs in a body of text. We could then draw a first letter from the letter frequency table. Assume this
</p>
<p>is an &lsquo;a&rsquo;. We would then draw the second letter by drawing a sample from the conditional probability of encountering each
</p>
<p>letter after &lsquo;a&rsquo;, which we could compute from the table of pair frequencies. Assume this is an &lsquo;n&rsquo;. We get the third letter by
</p>
<p>drawing a sample from the conditional probability of encountering each letter after &lsquo;n&rsquo;, which we could compute from the
</p>
<p>table of pair frequencies, and so on. This is a first order chain (because each letter depends on the one letter behind it).
</p>
<p>Second and higher order chains (or models) follow the general recipe, but the probability of a letter depends on more of
</p>
<p>the letters behind it. You may be concerned that conditioning a letter on the two (or k) previous letters means we don&rsquo;t have
</p>
<p>a Markov chain, because I said that the n&rsquo;th state depends on only the n� 1&rsquo;th state. The cure for this concern is to use states</p>
<p/>
</div>
<div class="page"><p/>
<p>14.1 Markov Chains 337
</p>
<p>that represent two (or k) letters, and adjust transition probabilities so that the states are consistent. So for a second order
</p>
<p>chain, the string &ldquo;abcde&rdquo; is a sequence of four states, &ldquo;ab&rdquo;, &ldquo;bc&rdquo;, &ldquo;cd&rdquo;, and &ldquo;de&rdquo;.
</p>
<p>Worked example 14.7 (Modelling Short Words) Obtain a text resource, and use a trigram letter model to produce
</p>
<p>four letter words. What fraction of bigrams (resp. trigrams) do not occur in this resource? What fraction of the words
</p>
<p>you produce are actual words?
</p>
<p>Solution I used the text of a draft of this chapter. I ignored punctuation marks, and forced capital letters to lower case
</p>
<p>letters. I found 0:44 of the bigrams and 0:90 of the trigrams were not present. I built two models. In one, I just used
</p>
<p>counts to form the probability distributions (so there were many zero probabilities). In the other, I split a probability of
</p>
<p>0.1 between all the cases that had not been observed. A list of 20 word samples from the first model is: &ldquo;ngen&rdquo;, &ldquo;ingu&rdquo;,
</p>
<p>&ldquo;erms&rdquo;, &ldquo;isso&rdquo;, &ldquo;also&rdquo;, &ldquo;plef&rdquo;, &ldquo;trit&rdquo;, &ldquo;issi&rdquo;, &ldquo;stio&rdquo;, &ldquo;esti&rdquo;, &ldquo;coll&rdquo;, &ldquo;tsma&rdquo;, &ldquo;arko&rdquo;, &ldquo;llso&rdquo;, &ldquo;bles&rdquo;, &ldquo;uati&rdquo;, &ldquo;namp&rdquo;, &ldquo;call&rdquo;,
</p>
<p>&ldquo;riat&rdquo;, &ldquo;eplu&rdquo;; two of these are real English words (three if you count &ldquo;coll&rdquo;, which I don&rsquo;t; too obscure), so perhaps
</p>
<p>10% of the samples are real words. A list of 20 word samples from the second model is: &ldquo;hate&rdquo;, &ldquo;ther&rdquo;, &ldquo;sout&rdquo;, &ldquo;vect&rdquo;,
</p>
<p>&ldquo;nces&rdquo;, &ldquo;ffer&rdquo;, &ldquo;msua&rdquo;, &ldquo;ergu&rdquo;, &ldquo;blef&rdquo;, &ldquo;hest&rdquo;, &ldquo;assu&rdquo;, &ldquo;fhsp&rdquo;, &ldquo;ults&rdquo;, &ldquo;lend&rdquo;, &ldquo;lsoc&rdquo;, &ldquo;fysj&rdquo;, &ldquo;uscr&rdquo;, &ldquo;ithi&rdquo;, &ldquo;prow&rdquo;,
</p>
<p>&ldquo;lith&rdquo;; four of these are real English words (you might need to look up &ldquo;lith&rdquo;, but I refuse to count &ldquo;hest&rdquo; as being too
</p>
<p>archaic), so perhaps 20% of the samples are real words. In each case, the samples are too small to take the fraction
</p>
<p>estimates all that seriously.
</p>
<p>Letter models can be good enough for (say) evaluating communication devices, but they&rsquo;re not great at producing words
</p>
<p>(Example 14.7). More effective language models are obtained by working with words. The recipe is as above, but now we
</p>
<p>use words in place of letters. It turns out that this recipe applies to such domains as protein sequencing, dna sequencing and
</p>
<p>music synthesis as well, but now we use amino acids (resp. base pairs; notes) in place of letters. Generally, one decides what
</p>
<p>the basic item is (letter, word, amino acid, base pair, note, etc.). Then individual items are called unigrams and 0&rsquo;th order
</p>
<p>models are unigram models; pairs are bigrams and first order models are bigram models; triples are trigrams, second order
</p>
<p>models trigram models; and for any other n, groups of n in sequence are n-grams and n � 1&rsquo;th order models are n-gram
models.
</p>
<p>Worked example 14.8 (Modelling Text with n-Grams of Words) Build a text model that uses bigrams (resp.
</p>
<p>trigrams, resp. n-grams) of words, and look at the paragraphs that your model produces.
</p>
<p>Solution This is actually a fairly arduous assignment, because it is hard to get good bigram frequencies without
</p>
<p>working with enormous text resources. Rather than solve it, I will follow the grand tradition of looking at other people&rsquo;s
</p>
<p>work.
</p>
<p>There are a variety of places you can find text resources. Google publishes n-gram models for English words
</p>
<p>with the year in which the n-gram occurred and information about how many different books it occurred in. So, for
</p>
<p>example, the word &ldquo;circumvallate&rdquo; appeared 335 times in 1978, in 91 distinct books&mdash;some books clearly felt the need
</p>
<p>to use this term more than once. This information can be found starting at http://storage.googleapis.com/books/ngrams/
</p>
<p>books/datasetsv2.html. The raw dataset is huge, as you would expect. There are numerous n-gram language models
</p>
<p>on the web. Jeff Attwood has a brief discussion of some models at https://blog.codinghorror.com/markov-and-you/;
</p>
<p>Sophie Chou has some examples, and pointers to code snippets and text resources, at http://blog.sophiechou.com/2013/
</p>
<p>how-to-model-markov-chains/. Fletcher Heisler, Michael Herman, and Jeremy Johnson are authors of RealPython, a
</p>
<p>training course in Python, and give a nice worked example of a Markov chain language generator at https://realpython.
</p>
<p>com/blog/python/lyricize-a-flask-app-to-create-lyrics-using-markov-chains/.
</p>
<p>The paragraphs that cleverly trained Markov chain language models produce can be hilarious, and are very effective
</p>
<p>tools for satire. Garkov is Josh Millard&rsquo;s tool for generating comics featuring a well-known cat (at http://joshmillard.
</p>
<p>com/garkov/). There&rsquo;s a nice Markov chain for reviewing wines by Tony Fischetti at http://www.onthelambda.com/
</p>
<p>2014/02/20/how-to-fake-a-sophisticated-knowledge-of-wine-with-markov-chains/
</p>
<p>It is usually straightforward to build a unigram model, because it is usually easy to get enough data to estimate the
</p>
<p>frequencies of the unigrams. There are many more bigrams than unigrams, many more trigrams than bigrams, and so on.</p>
<p/>
<div class="annotation"><a href="http://storage.googleapis.com/books/ngrams/books/datasetsv2.html">http://storage.googleapis.com/books/ngrams/books/datasetsv2.html</a></div>
<div class="annotation"><a href="http://storage.googleapis.com/books/ngrams/books/datasetsv2.html">http://storage.googleapis.com/books/ngrams/books/datasetsv2.html</a></div>
<div class="annotation"><a href="https://blog.codinghorror.com/markov-and-you/">https://blog.codinghorror.com/markov-and-you/</a></div>
<div class="annotation"><a href="http://blog.sophiechou.com/2013/how-to-model-markov-chains/">http://blog.sophiechou.com/2013/how-to-model-markov-chains/</a></div>
<div class="annotation"><a href="http://blog.sophiechou.com/2013/how-to-model-markov-chains/">http://blog.sophiechou.com/2013/how-to-model-markov-chains/</a></div>
<div class="annotation"><a href="https://realpython.com/blog/python/lyricize-a-flask-app-to-create-lyrics-using-markov-chains/">https://realpython.com/blog/python/lyricize-a-flask-app-to-create-lyrics-using-markov-chains/</a></div>
<div class="annotation"><a href="https://realpython.com/blog/python/lyricize-a-flask-app-to-create-lyrics-using-markov-chains/">https://realpython.com/blog/python/lyricize-a-flask-app-to-create-lyrics-using-markov-chains/</a></div>
<div class="annotation"><a href="http://joshmillard.com/garkov/">http://joshmillard.com/garkov/</a></div>
<div class="annotation"><a href="http://joshmillard.com/garkov/">http://joshmillard.com/garkov/</a></div>
<div class="annotation"><a href="http://www.onthelambda.com/2014/02/20/how-to-fake-a-sophisticated-knowledge-of-wine-with-markov-chains/">http://www.onthelambda.com/2014/02/20/how-to-fake-a-sophisticated-knowledge-of-wine-with-markov-chains/</a></div>
<div class="annotation"><a href="http://www.onthelambda.com/2014/02/20/how-to-fake-a-sophisticated-knowledge-of-wine-with-markov-chains/">http://www.onthelambda.com/2014/02/20/how-to-fake-a-sophisticated-knowledge-of-wine-with-markov-chains/</a></div>
</div>
<div class="page"><p/>
<p>338 14 Markov Chains and Hidden Markov Models
</p>
<p>This means that estimating frequencies can get tricky. In particular, you might need to collect an immense amount of data
</p>
<p>to see every possible n-gram several times. Without seeing every possible n-gram several times, you will need to deal with
</p>
<p>estimating the probability of encountering rare n-grams that you haven&rsquo;t seen. Assigning these n-grams a probability of zero
</p>
<p>is unwise, because that implies that they never occur, as opposed to occur seldom.
</p>
<p>There are a variety of schemes for smoothing data (essentially, estimating the probability of rare items that have not been
</p>
<p>seen). The simplest one is to assign some very small fixed probability to every n-gram that has a zero count. It turns out that
</p>
<p>this is not a particularly good approach, because, for even quite small n, the fraction of n-grams that have zero count can
</p>
<p>be very large. In turn, you can find that most of the probability in your model is assigned to n-grams you have never seen.
</p>
<p>An improved version of this model assigns a fixed probability to unseen n-grams, then divides that probability up between
</p>
<p>all of the n-grams that have never been seen before. This approach has its own characteristic problems. It ignores evidence
</p>
<p>that some of the unseen n-grams are more common than others. Some of the unseen n-grams have (n-1) leading terms that
</p>
<p>are (n-1)-grams that we have observed. These (n-1)-grams likely differ in frequency, suggesting that n-grams involving them
</p>
<p>should differ in frequency, too. More sophisticated schemes are beyond our scope, however.
</p>
<p>14.2 Estimating Properties of Markov Chains
</p>
<p>Many problems in probability can be worked out in closed form if one knows enough combinatorial mathematics, or can
</p>
<p>come up with the right trick. Textbooks are full of these, and we&rsquo;ve seen some. Explicit formulas for probabilities are often
</p>
<p>extremely useful. But it isn&rsquo;t always easy or possible to find a formula for the probability of an event in a model. Markov
</p>
<p>chains are a particularly rich source of probability problems that might be too much trouble to solve in closed form. An
</p>
<p>alternative strategy is to build a simulation, run it many times, and count the fraction of outcomes where the event occurs.
</p>
<p>This is a simulation experiment.
</p>
<p>14.2.1 Simulation
</p>
<p>Imagine we have a random variable X with probability distribution P.X/ that takes values in some domain D. Assume that
</p>
<p>we can easily produce independent simulations, and that we wish to know EŒf &#141;, the expected value of the function f under
</p>
<p>the distribution P.X/.
</p>
<p>The weak law of large numbers tells us how to proceed. Define a new random variable F D f .X/. This has a probability
distribution P.F/, which might be difficult to know. We want to estimate EŒf &#141;, the expected value of the function f under the
</p>
<p>distribution P.X/. This is the same as EŒF&#141;. Now if we have a set of IID samples of X, which we write xi, then we can form
</p>
<p>a set of IID samples of F by forming f .xi/ D fi. Write
</p>
<p>FN D
PN
</p>
<p>iD1 fi
N
</p>
<p>:
</p>
<p>This is a random variable, and the weak law of large numbers gives that, for any positive number �
</p>
<p>lim
N!1
</p>
<p>P.fjjFN � EŒF&#141;jj &gt; �g/ D 0:
</p>
<p>You can interpret this as saying that, that for a set of IID random samples xi, the probability that
</p>
<p>PN
iD1 f .xi/
</p>
<p>N
</p>
<p>is very close to EŒf &#141; is high for large N</p>
<p/>
</div>
<div class="page"><p/>
<p>14.2 Estimating Properties of Markov Chains 339
</p>
<p>Worked example 14.9 (Computing an Expectation) Assume the random variable X is uniformly distributed in the
</p>
<p>range Œ0� 1&#141;, and the random variable Y is uniformly distributed in the range Œ0� 10&#141;. X and Z are independent. Write
Z D .Y � 5X/3 � X2. What is var .fZg/?
</p>
<p>Solution With enough work, one could probably work this out in closed form. An easy program will get a good
</p>
<p>estimate. We have that var .fZg/ D E
�
</p>
<p>Z2
�
</p>
<p>�EŒZ&#141;2. My program computed 1000 values of Z (by drawing X and Y from
the appropriate random number generator, then evaluating the function). I then computed EŒZ&#141; by averaging those
</p>
<p>values, and EŒZ&#141;2 by averaging their squares. For a run of my program, I got var .fZg/ D 2:76 � 104.
</p>
<p>You can compute a probability using a simulation, too, because a probability can be computed by taking an expectation.
</p>
<p>Recall the property of indicator functions that
</p>
<p>E
�
</p>
<p>IŒE&#141;
</p>
<p>�
</p>
<p>D P.E/
</p>
<p>(Section 4.3.3). This means that computing the probability of an event E involves writing a function that is 1 when the event
</p>
<p>occurs, and 0 otherwise; we then estimate the expected value of that function.
</p>
<p>Worked example 14.10 (Computing a Probability for Multiple Coin Flips) You flip a fair coin three times. Use a
</p>
<p>simulation to estimate the probability that you see three H&rsquo;s.
</p>
<p>Solution You really should be able to work this out in closed form. But it&rsquo;s amusing to check with a simulation. I
</p>
<p>wrote a simple program that obtained a 1000 � 3 table of uniformly distributed random numbers in the range Œ0 � 1&#141;.
For each number, if it was greater than 0.5 I recorded an H and if it was smaller, I recorded a T . Then I counted the
</p>
<p>number of rows that had 3 H&rsquo;s (i.e. the expected value of the relevant indicator function). This yielded the estimate
</p>
<p>0:127, which compares well to the right answer.
</p>
<p>Worked example 14.11 (Computing a Probability) Assume the random variable X is uniformly distributed in the
</p>
<p>range Œ0 � 1&#141;, and the random variable Y is uniformly distributed in the range Œ0 � 10&#141;. Write Z D .Y � 5X/3 � X2.
What is P.fZ &gt; 3g/?
</p>
<p>Solution With enough work, one could probably work this out in closed form. An easy program will get a good
</p>
<p>estimate. My program computed 1000 values of Z (by drawing X and Y from the appropriate random number generator,
</p>
<p>then evaluating the function) and counted the fraction of Z values that was greater than 3 (which is the relevant indicator
</p>
<p>function). For a run of my program, I got P.fZ &gt; 3g/ � 0:619
</p>
<p>For all the examples we will deal with, producing an IID sample of the relevant probability distribution will be
</p>
<p>straightforward. You should be aware that it can be very hard to produce an IID sample from an arbitrary distribution,
</p>
<p>particularly if that distribution is over a continuous variable in high dimensions.
</p>
<p>14.2.2 Simulation Results as RandomVariables
</p>
<p>The estimate of a probability or of an expectation that comes out of a simulation experiment is a random variable, because it
</p>
<p>is a function of random numbers. If you run the simulation again, you&rsquo;ll get a different value, unless you did something silly
</p>
<p>with the random number generator. Generally, you should expect this random variable to have a normal distribution. You
</p>
<p>can check this by constructing a histogram over a large number of runs. The mean of this random variable is the parameter
</p>
<p>you are trying to estimate. It is useful to know that this random variable tends to be normal, because it means the standard
</p>
<p>deviation of the random variable tells you a lot about the likely values you will observe.</p>
<p/>
</div>
<div class="page"><p/>
<p>340 14 Markov Chains and Hidden Markov Models
</p>
<p>10 100 1000 10000
0
</p>
<p>0.2
</p>
<p>0.4
</p>
<p>0.6
</p>
<p>0.8
</p>
<p>1
</p>
<p>Estimates of P(Z&gt;3) 
</p>
<p>Fig. 14.6 Estimates of the probability from Example 14.11, obtained from different runs of my simulator using different numbers of samples.
In each case, I used 100 runs; the number of samples is shown on the horizontal axis. You should notice that the estimate varies pretty widely
when there are only 10 samples in each run, but the variance (equivalently, the size of the spread) goes down sharply as the number of samples per
run increases to 1000. Because we expect these estimates to be roughly normally distributed, the variance gives a good idea of how accurate the
original probability estimate is
</p>
<p>Another helpful rule of thumb, which is almost always right, is that the standard deviation of this random variable behaves
</p>
<p>like
Cp
N
</p>
<p>where C is a constant that depends on the problem and can be very hard to evaluate, and N is the number of runs of the
</p>
<p>simulation. What this means is that if you want to (say) double the accuracy of your estimate of the probability or the
</p>
<p>expectation, you have to run four times as many simulations. Very accurate estimates are tough to get, because they require
</p>
<p>immense numbers of simulation runs.
</p>
<p>Figure 14.6 shows how the result of a simulation behaves when the number of runs changes. I used the simulation of
</p>
<p>Example 14.11, and ran multiple experiments for each of a number of different samples (i.e. 100 experiments using 10
</p>
<p>samples; 100 using 100 samples; and so on).
</p>
<p>Worked example 14.12 (Getting 14&rsquo;s with 20-Sided Dice) You throw 3 fair 20-sided dice. Estimate the probability
</p>
<p>that the sum of the faces is 14 using a simulation. Use N D Œ1e1; 1e2; 1e3; 1e4; 1e5; 1e6&#141;. Which estimate is likely to
be more accurate, and why?
</p>
<p>Solution You need a fairly fast computer, or this will take a long time. I ran ten versions of each experiment for
</p>
<p>N D Œ1e1; 1e2; 1e3; 1e4; 1e5; 1e6&#141;, yielding ten probability estimates for each N. These were different for each version
of the experiment, because the simulations are random. I got means of Œ0; 0:0030; 0:0096; 0:0100; 0:0096; 0:0098&#141;, and
</p>
<p>standard deviations of [0 0.0067 0.0033 0.0009 0.0002 0.0001]. This suggests the true value is around 0.0098, and the
</p>
<p>estimate from N D 1e6 is best. The reason that the estimate with N D 1e1 is 0 is that the probability is very small, so
you don&rsquo;t usually observe this case at all in only ten trials.
</p>
<p>Small probabilities can be rather hard to estimate, as we would expect. In the case of Example 14.11, let us estimate
</p>
<p>P.fZ &gt; 950g/. A few moments with a computer will show that this probability is of the order of 1e-3 to 1e-4. I obtained
a million different simulated values of Z from my program, and saw 310 where Z &gt; 950. This means that to know this
</p>
<p>probability to, say, three digits of numerical accuracy might involve a daunting number of samples. Notice that this does not
</p>
<p>contradict the rule of thumb that the standard deviation of the random variable defined by a simulation estimate behaves like
Cp
N
</p>
<p>; it&rsquo;s just that in this case, C is very large indeed.</p>
<p/>
</div>
<div class="page"><p/>
<p>14.2 Estimating Properties of Markov Chains 341
</p>
<p>Useful Facts 14.4 (The Properties of Simulations)
</p>
<p>You should remember that
</p>
<p>&bull; The weak law of large numbers means you can estimate expectations and probabilities with a simulation.
</p>
<p>&bull; The result of a simulation is usually a normal random variable.
</p>
<p>&bull; The expected value of this random variable is usually the true value of the expectation or probability you are trying
</p>
<p>to simulate.
</p>
<p>&bull; The standard deviation of this random variable is usually Cp
N
</p>
<p>, where N is the number of examples in the simulation
</p>
<p>and C is a number usually too hard to estimate.
</p>
<p>Worked example 14.13 (Comparing Simulation with Computation) You throw three fair six-sided dice. You wish
</p>
<p>to know the probability the sum is three. Compare the true value of this probability with estimates from six runs of a
</p>
<p>simulation using N D 10;000. What conclusions do you draw?
</p>
<p>Solution I ran six simulations with N D 10;000, and got [ 0.0038, 0.0038, 0.0053, 0.0041, 0.0056, 0.0049]. The mean
is 0:00458, and the standard deviation is 0:0007, which suggests the estimate isn&rsquo;t that great, but the right answer should
</p>
<p>be in the range Œ0:00388; 0:00528&#141; with probability about 0:68. The true value is 1=216 � 0:00463. The estimate is
tolerable, but not super accurate.
</p>
<p>14.2.3 SimulatingMarkov Chains
</p>
<p>We will always assume that we know the states and transition probabilities of the Markov chain. Properties that might be of
</p>
<p>interest in this case include: the probability of hitting an absorbing state; the expected time to go from one state to another;
</p>
<p>the expected time to hit an absorbing state; and which states have high probability under the stationary distribution.
</p>
<p>Worked example 14.14 (Coin Flips with End Conditions) I flip a coin repeatedly until I encounter a sequence
</p>
<p>HTHT, at which point I stop. What is the probability that I flip the coin nine times?
</p>
<p>Solution You might well be able to construct a closed form solution to this if you follow the details of example 14.13
</p>
<p>and do quite a lot of extra work. A simulation is really straightforward to write; notice you can save time by not
</p>
<p>continuing to simulate coin flips once you&rsquo;ve flipped past nine times. I got 0:0411 as the mean probability over 10 runs
</p>
<p>of a simulation of 1000 experiments each, with a standard deviation of 0:0056.
</p>
<p>Worked example 14.15 (A Queue) A bus is supposed to arrive at a bus stop every hour for 10 h each day. The number
</p>
<p>of people who arrive to queue at the bus stop each hour has a Poisson distribution, with intensity 4. If the bus stops,
</p>
<p>everyone gets on the bus and the number of people in the queue becomes zero. However, with probability 0:1 the
</p>
<p>bus driver decides not to stop, in which case people decide to wait. If the queue is ever longer than 15, the waiting
</p>
<p>passengers will riot (and then immediately get dragged off by the police, so the queue length goes down to zero). What
</p>
<p>is the expected time between riots?
</p>
<p>Solution I&rsquo;m not sure whether one could come up with a closed form solution to this problem. A simulation is
</p>
<p>completely straightforward to write. I get a mean time of 441 h between riots, with a standard deviation of 391. It&rsquo;s
</p>
<p>interesting to play around with the parameters of this problem; a less conscientious bus driver, or a higher intensity
</p>
<p>arrival distribution, lead to much more regular riots.</p>
<p/>
</div>
<div class="page"><p/>
<p>342 14 Markov Chains and Hidden Markov Models
</p>
<p>Worked example 14.16 (Inventory) A store needs to control its stock of an item. It can order stocks on Friday
</p>
<p>evenings, which will be delivered on Monday mornings. The store is old-fashioned, and open only on weekdays.
</p>
<p>On each weekday, a random number of customers comes in to buy the item. This number has a Poisson distribution,
</p>
<p>with intensity 4. If the item is present, the customer buys it, and the store makes 100; otherwise, the customer leaves.
</p>
<p>Each evening at closing, the store loses 10 for each unsold item on its shelves. The store&rsquo;s supplier insists that it order
</p>
<p>a fixed number k of items (i.e. the store must order k items each week). The store opens on a Monday with 20 items on
</p>
<p>the shelf. What k should the store use to maximise profits?
</p>
<p>Solution I&rsquo;m not sure whether one could come up with a closed form solution to this problem, either. A simulation is
</p>
<p>completely straightforward to write. To choose k, you run the simulation with different k values to see what happens. I
</p>
<p>computed accumulated profits over 100 weeks for different k values, then ran the simulation five times to see which k
</p>
<p>was predicted. Results were 21; 19; 23; 20; 21. I&rsquo;d choose 21 based on this information.
</p>
<p>For Example 14.16, you should plot accumulated profits. If k is small, the store doesn&rsquo;t lose money by storing items, but it
</p>
<p>doesn&rsquo;t sell as much stuff as it could; if k is large, then it can fill any order but it loses money by having stock on the shelves.
</p>
<p>A little thought will convince you that k should be near 20, because that is the expected number of customers each week, so
</p>
<p>k D 20 means the store can expect to sell all its new stock. It may not be exactly 20, because it must depend a little on the
balance between the profit in selling an item and the cost of storing it. For example, if the cost of storing items is very small
</p>
<p>compared to the profit, an very large k might be a good choice. If the cost of storage is sufficiently high, it might be better to
</p>
<p>never have anything on the shelves; this point explains the absence of small stores selling PC&rsquo;s.
</p>
<p>Quite substantial examples are possible. The game &ldquo;snakes and ladders&rdquo; involves random walk on a Markov chain. If you
</p>
<p>don&rsquo;t know this game, look it up; it&rsquo;s sometimes called &ldquo;chutes and ladders&rdquo;, and there is an excellent Wikipedia page. The
</p>
<p>state is given by where each players&rsquo; token is on the board, so on a 10� 10 board one player involves 100 states, two players
1002 states, and so on. The set of states is finite, though big. Transitions are random, because each player throws dice. The
</p>
<p>snakes (resp. ladders) represent extra edges in the directed graph. Absorbing states occur when a player hits the top square.
</p>
<p>It is straightforward to compute the expected number of turns for a given number of players by simulation, for example. For
</p>
<p>one commercial version, the Wikipedia page gives the crucial numbers: for two players, the expected number of moves to a
</p>
<p>win is 47:76, and the first player wins with probability 0:509. Notice you might need to think a bit about how to write the
</p>
<p>program if there were, say, eight players on a 12 � 12 board&mdash;you would likely avoid storing the entire state space.
</p>
<p>14.3 Example: Ranking theWeb by Simulating aMarkov Chain
</p>
<p>Perhaps the most valuable technical question of the last 30 years has been: Which web pages are interesting? Some idea
</p>
<p>of the importance of this question is that it was only really asked about 20 years ago, and at least one gigantic technology
</p>
<p>company has been spawned by a partial answer. This answer, due to Larry Page and Sergey Brin, and widely known as
</p>
<p>PageRank, revolves around simulating the stationary distribution of a Markov chain.
</p>
<p>You can think of the world wide web as a directed graph. Each page is a state. Directed edges from page to page represent
</p>
<p>links. Count only the first link from a page to another page. Some pages are linked, others are not. We want to know how
</p>
<p>important each page is.
</p>
<p>One way to think about importance is to think about what a random web surfer would do. The surfer can either (a) choose
</p>
<p>one of the outgoing links on a page at random, and follow it or (b) type in the URL of a new page, and go to that instead. This
</p>
<p>is a random walk on a directed graph. We expect that this random surfer should see a lot of pages that have lots of incoming
</p>
<p>links from other pages that have lots of incoming links that (and so on). These pages are important, because lots of pages
</p>
<p>have linked to them.
</p>
<p>For the moment, ignore the surfer&rsquo;s option to type in a URL. Write r.i/ for the importance of the i&rsquo;th page. We model
</p>
<p>importance as leaking from page to page across outgoing links (the same way the surfer jumps). Page i receives importance
</p>
<p>down each incoming link. The amount of importance is proportional to the amount of importance at the other end of the link,
</p>
<p>and inversely proportional to the number of links leaving that page. So a page with only one outgoing link transfers all its</p>
<p/>
</div>
<div class="page"><p/>
<p>14.3 Example: Ranking the Web by Simulating a Markov Chain 343
</p>
<p>importance down that link; and the way for a page to receive a lot of importance is for it to have a lot of important pages link
</p>
<p>to it alone. We write
</p>
<p>r.j/ D
X
</p>
<p>i!j
</p>
<p>r.i/
</p>
<p>j i j
</p>
<p>where j i j means the total number of links pointing out of page i. We can stack the r.j/ values into a row vector r, and
construct a matrix P , where
</p>
<p>pij D
� 1
</p>
<p>jij if i points to j
0 otherwise
</p>
<p>With this notation, the importance vector has the property
</p>
<p>r D rP
</p>
<p>and should look a bit like the stationary distribution of a random walk to you, except that P isn&rsquo;t stochastic&mdash;there may be
</p>
<p>some rows where the row sum of P is zero, because there are no outgoing links from that page. We can fix this easily by
</p>
<p>replacing each row that sums to zero with .1=n/1, where n is the total number of pages. Call the resulting matrix G (it&rsquo;s quite
</p>
<p>often called the raw Google matrix).
</p>
<p>The web has pages with no outgoing links (which we&rsquo;ve dealt with), pages with no incoming links, and even pages with
</p>
<p>no links at all. A random walk could get trapped by moving to a page with no outgoing links. Allowing the surfer to randomly
</p>
<p>enter a URL sorts out all of these problems, because it inserts an edge of small weight from every node to every other node.
</p>
<p>Now the random walk cannot get trapped.
</p>
<p>There are a variety of possible choices for the weight of these inserted edges. The original choice was to make each
</p>
<p>inserted edge have the same weight. Write 1 for the n dimensional column vector containing a 1 in each component, and let
</p>
<p>0 &lt; ˛ &lt; 1. We can write the matrix of transition probabilities as
</p>
<p>G.˛/ D ˛ .11
T/
</p>
<p>n
C .1 � ˛/G
</p>
<p>where G is the original Google matrix. An alternative choice is to choose a weight for each web page. This weight could
</p>
<p>come from: a query; advertising revenues; thaumaturgy; blind prejudice; page visit statistics; other sources; or a mixture of
</p>
<p>all (Google keeps quiet about the details). Write this weight vector v, and require that 1Tv D 1 (i.e. the coefficients sum to
one). Then we could have
</p>
<p>G.˛; v/ D ˛ .1v
T/
</p>
<p>n
C .1 � ˛/G:
</p>
<p>Now the importance vector r is the (unique, though I won&rsquo;t prove this) row vector r such that
</p>
<p>r D rG.˛; v/:
</p>
<p>How do we compute this vector? One natural algorithm is to estimate r with a random walk, because r is the stationary
</p>
<p>distribution of a Markov chain. If we simulate this walk for many steps, the probability that the simulation is in state j should
</p>
<p>be r.j/, at least approximately.
</p>
<p>This simulation is easy to build. Imagine our random walking bug sits on a web page. At each time step, it transitions
</p>
<p>to a new page by either (a) picking from all existing pages at random, using v as a probability distribution on the pages
</p>
<p>(which it does with probability ˛); or (b) chooses one of the outgoing links uniformly and at random, and follows it (which
</p>
<p>it does with probability 1�˛). The stationary distribution of this random walk is r. Another fact that I shall not prove is that,
when ˛ is sufficiently large, this random walk very quickly &ldquo;forgets&rdquo; it&rsquo;s initial distribution. As a result, you can estimate
</p>
<p>the importance of web pages by starting this random walk in a random location; letting it run for a bit; then stopping it, and
</p>
<p>collecting the page you stopped on. The pages you see like this are independent, identically distributed samples from r; so
</p>
<p>the ones you see more often are more important, and the ones you see less often are less important.</p>
<p/>
</div>
<div class="page"><p/>
<p>344 14 Markov Chains and Hidden Markov Models
</p>
<p>14.4 HiddenMarkovModels and Dynamic Programming
</p>
<p>Imagine we wish to build a program that can transcribe speech sounds into text. Each small chunk of text can lead to one,
</p>
<p>or some, sounds, and some randomness is involved. For example, some people pronounce the word &ldquo;fishing&rdquo; rather like
</p>
<p>&ldquo;fission&rdquo;. As another example, the word &ldquo;scone&rdquo; is sometimes pronounced rhyming with &ldquo;stone&rdquo;, sometimes rhyming with
</p>
<p>&ldquo;gone&rdquo;, and occasionally rhyming with &ldquo;loon&rdquo;. A Markov chain supplies a model of all possible text sequences, and allows
</p>
<p>us to compute the probability of any particular sequence. We will use a Markov chain to model text sequences, but what we
</p>
<p>observe is sound. We must have a model of how sound is produced by text. With that model and the Markov chain, we want
</p>
<p>to produce text that (a) is a likely sequence of words and (b) is likely to have produced the sounds we hear.
</p>
<p>Many applications contain the main elements of this example. We might wish to transcribe music from sound. We might
</p>
<p>wish to understand American sign language from video. We might wish to produce a written description of how someone
</p>
<p>moves from video observations. We might wish to break a substitution cipher. In each case, what we want to recover is
</p>
<p>a sequence that can be modelled with a Markov chain, but we don&rsquo;t see the states of the chain. Instead, we see noisy
</p>
<p>measurements that depend on the state of the chain, and we want to recover a state sequence that is (a) likely under the
</p>
<p>Markov chain model and (b) likely to have produced the measurements we observe.
</p>
<p>14.4.1 HiddenMarkovModels
</p>
<p>Assume we have a finite state, time homogenous Markov chain, with S states. This chain will start at time 1, and the
</p>
<p>probability distribution P.X1 D i/ is given by the vector �. At time u, it will take the state Xu, and its transition probability
matrix is pij D P.XuC1 D jjXu D i/. We do not observe the state of the chain. Instead, we observe some Yu. We will assume
that Yu is also discrete, and there are a total of O possible states for Yu for any u. We can write a probability distribution for
</p>
<p>these observations P.YujXu D i/ D qi.Yu/. This distribution is the emission distribution of the model. For simplicity, we
will assume that the emission distribution does not change with time.
</p>
<p>We can arrange the emission distribution into a matrix Q. A hidden Markov model consists of the transition probability
</p>
<p>distribution for the states, the relationship between the state and the probability distribution on Yu, and the initial distribution
</p>
<p>on states, that is, .P;Q;�/. These models are often dictated by an application. An alternative is to build a model that best
</p>
<p>fits a collection of observed data, but doing so requires technical machinery we cannot expound here.
</p>
<p>I will sketch how one might build a model for transcribing speech, but you should keep in mind this is just a sketch
</p>
<p>of a very rich area. We can obtain the probability of a word following some set of words using n-gram resources, as in
</p>
<p>Sect. 14.1.3. We then build a model of each word in terms of small chunks of word that are likely to correspond to common
</p>
<p>small chunks of sound. We will call these chunks of sound phonemes. We can look up the different sets of phonemes that
</p>
<p>correspond to a word using a pronunciation dictionary. We can combine these two resources into a model of how likely it is
</p>
<p>one will pass from one phoneme inside a word to another, which might either be inside this word or inside another word. We
</p>
<p>now have P . We will not spend much time on �, and might even model it as a uniform distribution. We can use a variety
</p>
<p>of strategies to build Q. One is to build discrete features of a sound signal, then count how many times a particular set of
</p>
<p>features is produced when a particular phoneme is played.
</p>
<p>14.4.2 Picturing Inference with a Trellis
</p>
<p>Assume that we have a sequence of N measurements Yi that we believe to be the output of a known hidden Markov model.
</p>
<p>We wish to recover the &ldquo;best&rdquo; corresponding sequence of Xi. Doing so is inference. We will choose to recover a sequence Xi
that maximises
</p>
<p>logP.X1;X2; : : : ;XN jY1;Y2; : : : ;YN ;P;Q;�/
</p>
<p>which is
</p>
<p>log
</p>
<p>�
</p>
<p>P.X1;X2; : : : ;XN ;Y1;Y2; : : : ;YN jP;Q;�/
P.Y1;Y2; : : : ;YN/
</p>
<p>�</p>
<p/>
</div>
<div class="page"><p/>
<p>14.4 Hidden Markov Models and Dynamic Programming 345
</p>
<p>and this is
</p>
<p>logP.X1;X2; : : : ;XN ;Y1;Y2; : : : ;YN jP;Q;�/
</p>
<p>� logP.Y1;Y2; : : : ;YN/:
</p>
<p>Notice that P.Y1;Y2; : : : ;YN/ doesn&rsquo;t depend on the sequence of Xu we choose, and so the second term can be ignored. What
</p>
<p>is important here is that we can decompose logP.X1;X2; : : : ;XN ;Y1;Y2; : : : ;YN jP;Q;�/ in a very useful way, because the
Xu form a Markov chain. We want to maximise
</p>
<p>logP.X1;X2; : : : ;XN ;Y1;Y2; : : : ;YN jP;Q;�/
</p>
<p>but this is
</p>
<p>logP.X1/C logP.Y1jX1/C
</p>
<p>logP.X2jX1/C logP.Y2jX2/C
</p>
<p>: : :
</p>
<p>logP.XN jXn�1/C logP.YN jXN/:
</p>
<p>Notice that this cost function has an important structure. It is a sum of terms. There are terms that depend on a single Xi
(unary terms) and terms that depend on two (binary terms). Any state Xi appears in at most two binary terms.
</p>
<p>We can illustrate this cost function in a structure called a trellis. This is a weighted, directed graph consisting of N copies
</p>
<p>of the state space, which we arrange in columns. There is a column corresponding to each measurement. We add a directed
</p>
<p>arrow from any state in the u&rsquo;th column to any state in the u C 1&rsquo;th column if the transition probability between the states
isn&rsquo;t 0. This represents the fact that there is a possible transition between these states. We then label the trellis with weights.
</p>
<p>We weight the node representing the case that state Xu D j in the column corresponding to Yu with logP.YujXu D j/. We
weight the arc from the node representing Xu D i to that representing XuC1 D j with logP.XuC1 D jjXu D i/.
</p>
<p>The trellis has two crucial properties. Each directed path through the trellis from the start column to the end column
</p>
<p>represents a legal sequence of states. Now for some directed path from the start column to the end column, sum all the
</p>
<p>weights for the nodes and edges along this path. This sum is the log of the joint probability of that sequence of states with
</p>
<p>the measurements. You can verify each of these statements easily by reference to a simple example (try Fig. 14.7)
</p>
<p>There is an efficient algorithm for finding the path through a trellis which maximises the sum of terms. The algorithm is
</p>
<p>usually called dynamic programming or the Viterbi algorithm. I will describe this algorithm both in narrative, and as a
</p>
<p>recursion. We want to find the best path from each node in the first column to each node in the last. There are S such paths,
</p>
<p>one for each node in the first column. Once we have these paths, we can choose the one with highest log joint probability.
</p>
<p>Now consider one of these paths. It passes through the i&rsquo;th node in the u&rsquo;th column. The path segment from this node to
</p>
<p>the end column must, itself, be the best path from this node to the end. If it wasn&rsquo;t, we could improve the original path by
</p>
<p>substituting the best. This is the key insight that gives us an algorithm.
</p>
<p>Start at the final column of the tellis. We can evaluate the best path from each node in the final column to the final column,
</p>
<p>because that path is just the node, and the value of that path is the node weight. Now consider a two-state path, which will
</p>
<p>start at the second last column of the trellis (look at panel I in Fig. 14.8). We can easily obtain the value of the best path
</p>
<p>leaving each node in this column. Consider a node: we know the weight of each arc leaving the node and the weight of the
</p>
<p>node at the far end of the arc, so we can choose the path segment with the largest value of the sum; this arc is the best we
</p>
<p>can do leaving that node. This sum is the best value obtainable on leaving that node&mdash;which is often known as the cost to go
</p>
<p>function.
</p>
<p>Now, because we know the best value obtainable on leaving each node in the second-last column, we can figure out the
</p>
<p>best value obtainable on leaving each node in the third-last column (panel II in Fig. 14.8). At each node in the third-last
</p>
<p>column, we have a choice of arcs. Each of these reaches a node from which we know the value of the best path. So we can
</p>
<p>choose the best path leaving a node in the third-last column by finding the path that has the best value of: the arc weight
</p>
<p>leaving the node; the weight of the node in the second-last column the arc arrives at; and the value of the path leaving that</p>
<p/>
</div>
<div class="page"><p/>
<p>346 14 Markov Chains and Hidden Markov Models
</p>
<p>1 2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>log P(Y | X =2)
</p>
<p>p
12
</p>
<p>p
23
</p>
<p>p
13
</p>
<p>p
31
</p>
<p>Y
1
</p>
<p>Y
2
</p>
<p>Y
3
</p>
<p>1 1
</p>
<p>log P(Y | X =3)
1 1
</p>
<p>log P(Y | X =1)
1 1
</p>
<p>p
12
</p>
<p>log
</p>
<p>p
13
</p>
<p>log
</p>
<p>p
23
</p>
<p>log
</p>
<p>p
31
</p>
<p>log
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>Y
4
</p>
<p>Fig. 14.7 At the top left, a simple state transition model. Each outgoing edge has some probability, though the topology of the model forces two
of these probabilities to be 1. Below, the trellis corresponding to that model. Each path through the trellis corresponds to a legal sequence of states,
for a sequence of three measurements. We weight the arcs with the log of the transition probabilities, and the nodes with the log of the emission
probabilities. I have shown some weights
</p>
<p>node. This is much more easily done than described. All this works just as well for the fourth-last column, etc. (panel III in
</p>
<p>Fig. 14.8) so we have a recursion. To find the value of the best path with X1 D i, we go to the corresponding node in the first
column, then add the value of the node to the value of the best path leaving that node (panel IV in Fig. 14.8). Finally, to find
</p>
<p>the value of the best path leaving the first column, we compute the maximum value over all nodes in the first column.
</p>
<p>We can also get the path with the maximum likelihood value. When we compute the value of a node, we erase all but the
</p>
<p>best arc leaving that node. Once we reach the first column, we simply follow the path from the node with the best value. This
</p>
<p>path is illustrated by dashed edges in Fig. 14.8.
</p>
<p>14.4.3 Dynamic Programming for HMM&rsquo;s: Formalities
</p>
<p>We will formalize the recursion of the previous section with two ideas. First, we define Cw.j/ to be the cost of the best path
</p>
<p>segment to the end of the trellis leaving the node representing Xw D j. Second, we define Bw.j/ to be the node in column
wC 1 that lies on the best path leaving the node representing Xw D j. So Cw.j/ tells you the cost of the best path, and Bw.j/
tells you what node is next on the best path.
</p>
<p>Now it is straightforward to find the cost of the best path leaving each node in the second last column, and also the path.
</p>
<p>In symbols, we have
</p>
<p>CN�1.j/ D max
u
</p>
<p>ŒlogP.XN D ujXN�1 D j/
</p>
<p>C logP.YN jXN D u/&#141;
</p>
<p>and
</p>
<p>BN�1.j/ D argmaxu ŒlogP.XN D ujXN�1 D j/
</p>
<p>C logP.YN jXN D u/&#141; :
</p>
<p>You should check this against step I of Fig. 14.8</p>
<p/>
</div>
<div class="page"><p/>
<p>14.4 Hidden Markov Models and Dynamic Programming 347
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>-1
</p>
<p>-3
</p>
<p>-9
</p>
<p>-1
</p>
<p>-3
</p>
<p>-9
</p>
<p>-1
</p>
<p>-3
</p>
<p>-9
</p>
<p>-1
</p>
<p>-3
</p>
<p>-9
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>-1
</p>
<p>-3
</p>
<p>-9
</p>
<p>-1
</p>
<p>-3
</p>
<p>-9
</p>
<p>-1
</p>
<p>-3
</p>
<p>-9
</p>
<p>-1
</p>
<p>-3.69
</p>
<p>-9
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>-1
</p>
<p>-3
</p>
<p>-9
</p>
<p>-1
</p>
<p>-3
</p>
<p>-9
</p>
<p>-4.69
</p>
<p>-10
</p>
<p>-10.69
</p>
<p>Cost to goCost to go III
</p>
<p>Cost of pathIVCost to goIII
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>-14.69
</p>
<p>-16.69
</p>
<p>-20.69
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>-1
</p>
<p>-3
</p>
<p>-9
</p>
<p>-13.69
</p>
<p>-13.69
</p>
<p>-11.69
</p>
<p>Fig. 14.8 An example of finding the best path through a trellis. The probabilities of leaving a node are uniform (and remember, ln 2 � �0:69).
Details in the text
</p>
<p>Once we have the best path leaving each node in the wC1&rsquo;th column and its cost, it&rsquo;s straightforward to find the best path
leaving the w&rsquo;th column and its cost. In symbols, we have
</p>
<p>Cw.j/ D max
u
</p>
<p>ŒlogP.XwC1 D ujXw D j/
</p>
<p>C logP.YwC1jXwC1 D u/C CwC1.u/&#141;
</p>
<p>and
</p>
<p>Bw.j/ D argmaxu ŒlogP.XwC1 D ujXw D j/C logP.YwC1jXwC1 D u/C CwC1.u/&#141; :
</p>
<p>Check this against steps II and III in Fig. 14.8.</p>
<p/>
</div>
<div class="page"><p/>
<p>348 14 Markov Chains and Hidden Markov Models
</p>
<p>14.4.4 Example: Simple Communication Errors
</p>
<p>Hidden Markov models can be used to correct text errors. We will simplify somewhat, and assume we have text that has no
</p>
<p>punctuation marks, and no capital letters. This means there are a total of 27 symbols (26 lower case letters, and a space).
</p>
<p>We send this text down some communication channel. This could be a telephone line, a fax line, a file saving procedure or
</p>
<p>anything else. This channel makes errors independently at each character. For each location, with probability 1�p the output
character at that location is the same as the input character. With probability p, the channel chooses randomly between the
</p>
<p>character one ahead or one behind in the character set, and produces that instead. You can think of this as a simple model
</p>
<p>for a mechanical error in one of those now ancient printers where a character strikes a ribbon to make a mark on the paper.
</p>
<p>We must reconstruct the transmission from the observations (Tables 14.1, 14.2 and 14.3 show some uni-, bi- and trigram
</p>
<p>probabilities).
</p>
<p>I built a unigram model, a bigram model, and a trigram model. I stripped the text of this chapter of punctuation marks
</p>
<p>and mapped the capital letters to lower case letters. I used an HMM package (in my case, for Matlab; but there&rsquo;s a good one
</p>
<p>for R as well) to perform inference. The main programming here is housekeeping to make sure the transition and emission
</p>
<p>models are correct. About 40% of the bigrams and 86% of the trigrams did not appear in the text. I smoothed the bigram
</p>
<p>and trigram probabilities by dividing the probability 0.01 evenly between all unobserved bigrams (resp. trigrams). The most
</p>
<p>common unigrams, bigrams and trigrams appear in the tables. As an example sequence, I used
</p>
<p>the trellis has two crucial properties each directed path through the trellis from the start column to the end column represents a legal
sequence of states now for some directed path from the start column to the end column sum all the weights for the nodes and edges along
this path this sum is the log of the joint probability of that sequence of states with the measurements you can verify each of these statements
easily by reference to a simple example
</p>
<p>Table 14.1 The most common single letters (unigrams) that I counted from a draft of this chapter, with their probabilities
</p>
<p>* e t i a o s n r h
</p>
<p>1.9e-1 9.7e-2 7.9e-2 6.6e-2 6.5e-2 5.8e-2 5.5e-2 5.2e-2 4.8e-2 3.7e-2
</p>
<p>The &lsquo;*&rsquo; stands for a space. Spaces are common in this text, because I have tended to use short words (from the probability of the &lsquo;*&rsquo;, average word
length is between five and six letters)
</p>
<p>Table 14.2 The most common bigrams that I counted from a draft of this chapter, with their probabilities
</p>
<p>Lead char
</p>
<p>* *t (2.7e-2) *a (1.7e-2) *i (1.5e-2) *s (1.4e-2) *o (1.1e-2)
</p>
<p>e e* (3.8e-2) er (9.2e-3) es (8.6e-3) en (7.7e-3) el (4.9e-3)
</p>
<p>t th (2.2e-2) t* (1.6e-2) ti (9.6e-3) te (9.3e-3) to (5.3e-3)
</p>
<p>i in (1.4e-2) is (9.1e-3) it (8.7e-3) io (5.6e-3) im (3.4e-3)
</p>
<p>a at (1.2e-2) an (9.0e-3) ar (7.5e-3) a* (6.4e-3) al (5.8e-3)
</p>
<p>o on (9.4e-3) or (6.7e-3) of (6.3e-3) o* (6.1e-3) ou (4.9e-3)
</p>
<p>s s* (2.6e-2) st (9.4e-3) se (5.9e-3) si (3.8e-3) su (2.2e-3)
</p>
<p>n n* (1.9e-2) nd (6.7e-3) ng (5.0e-3) ns (3.6e-3) nt (3.6e-3)
</p>
<p>r re (1.1e-2) r* (7.4e-3) ra (5.6e-3) ro (5.3e-3) ri (4.3e-3)
</p>
<p>h he (1.4e-2) ha (7.8e-3) h* (5.3e-3) hi (5.1e-3) ho (2.1e-3)
</p>
<p>The &lsquo;*&rsquo; stands for a space. For each of the ten most common letters, I have shown the five most common bigrams with that letter in the lead. This
gives a broad view of the bigrams, and emphasizes the relationship between unigram and bigram frequencies. Notice that the first letter of a word
has a slightly different frequency than letters (top row; bigrams starting with a space are first letters). About 40% of the possible bigrams do not
appear in the text
</p>
<p>Table 14.3 The most frequent ten trigrams in a draft of this chapter, with their probabilities
</p>
<p>*th the he* is* *of of* on* es* *a* ion
</p>
<p>1.7e-2 1.2e-2 9.8e-3 6.2e-3 5.6e-3 5.4e-3 4.9e-3 4.9e-3 4.9e-3 4.9e-3
</p>
<p>tio e*t in* *st *in at* ng* ing *to *an
</p>
<p>4.6e-3 4.5e-3 4.2e-3 4.1e-3 4.1e-3 4.0e-3 3.9e-3 3.9e-3 3.8e-3 3.7e-3
</p>
<p>Again, &lsquo;*&rsquo; stands for space. You can see how common &lsquo;the&rsquo; and &lsquo;*a*&rsquo; are; &lsquo;he*&rsquo; is common because &lsquo;*the*&rsquo; is common. About 80% of possible
trigrams do not appear in the text</p>
<p/>
</div>
<div class="page"><p/>
<p>14.5 You Should 349
</p>
<p>(which is text you could find in a draft of this chapter). There are 456 characters in this sequence.
</p>
<p>When I ran this through the noise process with p D 0:0333, I got
the trellis has two crucial properties each directed path through the tqdllit from the start column to the end coluln represents a legal
sequencezof states now for some directed path from the start column to thf end column sum aml the veights for the nodes and edges along
this path this sum is the log of the joint probability oe that sequence of states wish the measurements youzcan verify each of these statements
easily by reference to a simple examqle
</p>
<p>which is mangled but not too badly (13 of the characters are changed, so 443 locations are the same).
</p>
<p>The unigram model produces
</p>
<p>the trellis has two crucial properties each directed path through the tqdllit from the start column to the end coluln represents a legal sequence
of states now for some directed path from the start column to thf end column sum aml the veights for the nodes and edges along this path
this sum is the log of the joint probability oe that sequence of states wish the measurements you can verify each of these statements easily
by reference to a simple examqle
</p>
<p>which fixes three errors. The unigram model only changes an observed character when the probability of encountering that
</p>
<p>character on its own is less than the probability it was produced by noise. This occurs only for &ldquo;z&rdquo;, which is unlikely on its
</p>
<p>own and is more likely to have been a space. The bigram model produces
</p>
<p>she trellis has two crucial properties each directed path through the trellit from the start column to the end coluln represents a legal sequence
of states now for some directed path from the start column to the end column sum aml the veights for the nodes and edges along this path
this sum is the log of the joint probability oe that sequence of states wish the measurements you can verify each of these statements easily
by reference to a simple example
</p>
<p>This is the same as the correct text in 449 locations, so somewhat better than the noisy text. The trigram model produces
</p>
<p>the trellis has two crucial properties each directed path through the trellit from the start column to the end column represents a legal sequence
of states now for some directed path from the start column to the end column sum all the weights for the nodes and edges along this path
this sum is the log of the joint probability of that sequence of states with the measurements you can verify each of these statements easily
by reference to a simple example
</p>
<p>which corrects all but one of the errors (look for &ldquo;trellit&rdquo;).
</p>
<p>Remember this: A hidden Markov model can be used to model many sequences. Observations are noisy versions of
</p>
<p>underlying hidden states, and the states form a Markov chain. One can infer the hidden states from the observations
</p>
<p>with dynamic programming. This approach applies very widely, and is extremely useful in practice.
</p>
<p>14.5 You Should
</p>
<p>14.5.1 Remember These Definitions
</p>
<p>14.5.2 Remember These Terms
</p>
<p>Markov chain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331
</p>
<p>transition probabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331
</p>
<p>biased random walk . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331
</p>
<p>absorbing state . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332
</p>
<p>recurrent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332
</p>
<p>stochastic matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333
</p>
<p>irreducible . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335
</p>
<p>stationary distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335
</p>
<p>unigrams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
</p>
<p>unigram models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
</p>
<p>bigrams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
</p>
<p>bigram models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
</p>
<p>trigrams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337</p>
<p/>
</div>
<div class="page"><p/>
<p>350 14 Markov Chains and Hidden Markov Models
</p>
<p>trigram models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
</p>
<p>n-grams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
</p>
<p>n-gram models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
</p>
<p>smoothing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338
</p>
<p>raw Google matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343
</p>
<p>emission distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
</p>
<p>hidden Markov model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
</p>
<p>phonemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
</p>
<p>trellis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
</p>
<p>dynamic programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
</p>
<p>Viterbi algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
</p>
<p>cost to go function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
</p>
<p>14.5.3 Remember These Facts
</p>
<p>Markov chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333
</p>
<p>Transition probability matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335
</p>
<p>Many Markov chains have stationary distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336
</p>
<p>The properties of simulations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
</p>
<p>14.5.4 Be Able to
</p>
<p>&bull; Estimate various probabilities and expectations for a Markov chain by simulation.
</p>
<p>&bull; Evaluate the results of multiple runs of a simple simulation.
</p>
<p>&bull; Set up a simple HMM and use it to solve problems.
</p>
<p>Problems
</p>
<p>14.1 Multiple die rolls: You roll a fair die until you see a five, then a six; after that, you stop. Write P.N/ for the probability
</p>
<p>that you roll the die N times.
</p>
<p>(a) What is P.1/?
</p>
<p>(b) Show that P.2/ D .1=36/.
(c) Draw a directed graph encoding all the sequences of die rolls that you could encounter. Don&rsquo;t write the events on the
</p>
<p>edges; instead, write their probabilities. There are five ways not to get a five, but only one probability, so this simplifies
</p>
<p>the drawing.
</p>
<p>(d) Show that P.3/ D .1=36/.
(e) Now use your directed graph to argue that P.N/ D .5=6/P.N � 1/C .25=36/P.N � 2/.
</p>
<p>14.2 More complicated multiple coin flips: You flip a fair coin until you see either HTH or THT , and then you stop. We
</p>
<p>will compute a recurrence relation for P.N/.
</p>
<p>(a) Draw a directed graph for this chain.
</p>
<p>(b) Think of the directed graph as a finite state machine. Write &dagger;N for some string of length N accepted by this finite state
</p>
<p>machine. Use this finite state machine to argue that SigmaN has one of four forms:
</p>
<p>a. TT&dagger;N�2
b. HH&dagger;N�3
c. THH&dagger;N�2
d. HTT&dagger;N�3
</p>
<p>(c) Now use this argument to show that P.N/ D .1=2/P.N � 2/C .1=4/P.N � 3/.</p>
<p/>
</div>
<div class="page"><p/>
<p>Programming Exercises 351
</p>
<p>14.3 For the umbrella example of Worked example 14.2, assume that with probability 0.7 it rains in the evening, and 0.2 it
</p>
<p>rains in the morning. I am conventional, and go to work in the morning, and leave in the evening.
</p>
<p>(a) Write out a transition probability matrix.
</p>
<p>(b) What is the stationary distribution? (you should use a simple computer program for this).
</p>
<p>(c) What fraction of evenings do I arrive at home wet?
</p>
<p>(d) What fraction of days do I arrive at my destination dry?
</p>
<p>Programming Exercises
</p>
<p>14.4 A dishonest gambler has two dice and a coin. The coin and one die are both fair. The other die is unfair. It has
</p>
<p>P.n/ D Œ0:5; 0:1; 0:1; 0:1; 0:1; 0:1&#141; (where n is the number displayed on the top of the die). The gambler starts by choosing a
die. Choosing a die is by flipping a coin; if the coin comes up heads, the gambler chooses the fair die, otherwise, the unfair
</p>
<p>die. The gambler rolls the chosen die repeatedly until a six comes up. When a six appears, the gambler chooses again (by
</p>
<p>flipping a coin, etc), and continues.
</p>
<p>(a) Model this process with a hidden markov model. The emitted symbols should be 1; : : : ; 6. Doing so requires only two
</p>
<p>hidden states (which die is in hand). Simulate a long sequence of rolls using this model. What is the probability the
</p>
<p>emitted symbol is 1?
</p>
<p>(b) Use your simulation to produce 10 sequences of 100 symbols. Record the hidden state sequence for each of these. Now
</p>
<p>recover the hidden state using dynamic programming (you should likely use a software package for this; there are many
</p>
<p>good ones for R and Matlab). What fraction of the hidden states is correctly identified by your inference procedure?
</p>
<p>(c) Does inference accuracy improve when you use sequences of 1000 symbols?
</p>
<p>14.5 Warning: this exercise is fairly elaborate, though straightforward. We will correct text errors using a hidden
</p>
<p>Markov model.
</p>
<p>(a) Obtain the text of a copyright-free book in plain characters. One natural source is Project Gutenberg, at https://www.
</p>
<p>gutenberg.org. Simplify this text by dropping all punctuation marks except spaces, mapping capital letters to lower case,
</p>
<p>and mapping groups of many spaces to a single space. The result will have 27 symbols (26 lower case letters and a
</p>
<p>space). From this text, count unigram, bigram and trigram letter frequencies.
</p>
<p>(b) Use your counts to build models of unigram, bigram and trigram letter probabilities. You should build both an
</p>
<p>unsmoothed model, and at least one smoothed model. For the smoothed models, choose some small amount of probability
</p>
<p>� and split this between all events with zero count. Your models should differ only by the size of �.
</p>
<p>(c) Construct a corrupted version of the text by passing it through a process that, with probability pc, replaces a character
</p>
<p>with a randomly chosen character, and otherwise reports the original character.
</p>
<p>(d) For a reasonably sized block of corrupted text, use an HMM inference package to recover the best estimate of your true
</p>
<p>text. Be aware that your inference will run more slowly as the block gets bigger, but you won&rsquo;t see anything interesting
</p>
<p>if the block is (say) too small to contain any errors.
</p>
<p>(e) For pc D 0:01 and pc D 0:1, estimate the error rate for the corrected text for different values of �. Keep in mind that the
corrected text could be worse than the corrupted text.</p>
<p/>
<div class="annotation"><a href="https://www.gutenberg.org">https://www.gutenberg.org</a></div>
<div class="annotation"><a href="https://www.gutenberg.org">https://www.gutenberg.org</a></div>
</div>
<div class="page"><p/>
<p>Part V
</p>
<p>Mathematical Bits and Pieces</p>
<p/>
</div>
<div class="page"><p/>
<p>15Resources and Extras
</p>
<p>This chapter contains some mathematical material that you will likely have seen, but some may not have stayed with you. I
</p>
<p>have also relegated the detailed discussion of how one splits a node in a decision tree to this chapter.
</p>
<p>15.1 Useful Material About Matrices
</p>
<p>Terminology:
</p>
<p>&bull; A matrix M is symmetric if M D MT . A symmetric matrix is necessarily square.
&bull; We write I for the identity matrix.
</p>
<p>&bull; A matrix is diagonal if the only non-zero elements appear on the diagonal. A diagonal matrix is necessarily symmetric.
</p>
<p>&bull; A symmetric matrix is positive semidefinite if, for any x such that xTx &gt; 0 (i.e. this vector has at least one non-zero
</p>
<p>component), we have xTMx � 0.
&bull; A symmetric matrix is positive definite if, for any x such that xTx &gt; 0, we have xTMx &gt; 0.
</p>
<p>&bull; A matrix R is orthonormal if RTR D I D IT D RRT . Orthonormal matrices are necessarily square.
</p>
<p>Orthonormal matrices: You should think of orthonormal matrices as rotations, because they do not change lengths or
</p>
<p>angles. For x a vector, R an orthonormal matrix, and u D Rx, we have uTu D xTRTRx D xTIx D xTx. This means that R
doesn&rsquo;t change lengths. For y, z both unit vectors, we have that the cosine of the angle between them is yTx; but, by the same
</p>
<p>argument as above, the inner product of Ry and Rx is the same as yTx. This means that R doesn&rsquo;t change angles, either.
</p>
<p>Eigenvectors and Eigenvalues: Assume S is a d � d symmetric matrix, v is a d � 1 vector, and � is a scalar. If we have
</p>
<p>Sv D �v
</p>
<p>then v is referred to as an eigenvector of S and � is the corresponding eigenvalue. Matrices don&rsquo;t have to be symmetric to
</p>
<p>have eigenvectors and eigenvalues, but the symmetric case is the only one of interest to us.
</p>
<p>In the case of a symmetric matrix, the eigenvalues are real numbers, and there are d distinct eigenvectors that are normal
</p>
<p>to one another, and can be scaled to have unit length. They can be stacked into a matrix U D Œv1; : : : ; vd&#141;. This matrix is
orthonormal, meaning that UTU D I. This means that there is a diagonal matrix ƒ such that
</p>
<p>SU D Uƒ:
</p>
<p>In fact, there is a large number of such matrices, because we can reorder the eigenvectors in the matrix U , and the equation
</p>
<p>still holds with a new ƒ, obtained by reordering the diagonal elements of the original ƒ. There is no reason to keep track of
</p>
<p>this complexity. Instead, we adopt the convention that the elements of U are always ordered so that the elements of ƒ are
</p>
<p>sorted along the diagonal, with the largest value coming first.
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3_15
</p>
<p>355</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3_15">https://doi.org/10.1007/978-3-319-64410-3_15</a></div>
</div>
<div class="page"><p/>
<p>356 15 Resources and Extras
</p>
<p>Diagonalizing a symmetric matrix: This gives us a particularly important procedure. We can convert any symmetric
</p>
<p>matrix S to a diagonal form by computing
</p>
<p>UTSU D ƒ:
</p>
<p>This procedure is referred to as diagonalizing a matrix. Again, we assume that the elements of U are always ordered so that
</p>
<p>the elements of ƒ are sorted along the diagonal, with the largest value coming first. Diagonalization allows us to show that
</p>
<p>positive definiteness is equivalent to having all positive eigenvalues, and positive semidefiniteness is equivalent to having all
</p>
<p>non-negative eigenvalues.
</p>
<p>Factoring a matrix: Assume that S is symmetric and positive semidefinite. We have that
</p>
<p>S D UƒUT
</p>
<p>and all the diagonal elements of ƒ are non-negative. Now construct a diagonal matrix whose diagonal entries are the positive
</p>
<p>square roots of the diagonal elements of ƒ; call this matrix ƒ.1=2/. We have ƒ.1=2/ƒ.1=2/ D ƒ and .ƒ.1=2//T D ƒ.1=2/. Then
we have that
</p>
<p>SD.Uƒ.1=2//.ƒ.1=2/UT/D.Uƒ.1=2//.Uƒ.1=2//T
</p>
<p>so we can factor S into the form XX T by computing the eigenvectors and eigenvalues.
</p>
<p>15.1.1 The Singular Value Decomposition
</p>
<p>For any m � p matrix X , it is possible to obtain a decomposition
</p>
<p>X D U&dagger;VT
</p>
<p>where U is m �m, V is p � p, and &dagger; is m � p and is diagonal. If you don&rsquo;t recall what a diagonal matrix looks like when the
matrix isn&rsquo;t square, it&rsquo;s simple. All entries are zero, except the i; i entries for i in the range 1 to min.m; p/. So if &dagger; is tall and
</p>
<p>thin, the top square is diagonal and everything else is zero; if &dagger; is short and wide, the left square is diagonal and everything
</p>
<p>else is zero. Both U and V are orthonormal (i.e. UUT D I and VVT D I).
Notice that there is a relationship between forming an SVD and diagonalizing a matrix. In particular, X TX is symmetric,
</p>
<p>and it can be diagonalized as
</p>
<p>X TX D V&dagger;T&dagger;VT :
</p>
<p>Similarly, XX T is symmetric, and it can be diagonalized as
</p>
<p>XX T D U&dagger;&dagger;TU :
</p>
<p>15.1.2 Approximating A Symmetric Matrix
</p>
<p>Assume we have a k � k symmetric matrix T , and we wish to construct a matrix A that approximates it. We require that (a)
the rank of A is precisely r &lt; k and (b) the approximation should minimize the Frobenius norm, that is,
</p>
<p>jj.T �A/ jjF2 D
X
</p>
<p>ij
</p>
<p>.Tij � Aij/2:
</p>
<p>It turns out that there is a straightforward construction that yields A.
</p>
<p>The first step is to notice that if U is orthonormal and M is any matrix, then
</p>
<p>jjUM jjF D jjMU jjF D jjM jjF:</p>
<p/>
</div>
<div class="page"><p/>
<p>15.1 Useful Material About Matrices 357
</p>
<p>This is true because U is a rotation (as is UT D U�1), and rotations do not change the length of vectors. So, for example, if we
write M as a table of row vectors M D Œm1;m2; : : :mk&#141;, then UM D ŒUm1;Um2; : : :Umk&#141;. Now jjM jjF2 D
</p>
<p>Pk
jD1 jjmjjj
</p>
<p>2,
</p>
<p>so jjUM jjF2 D
Pk
</p>
<p>iD1 jjUmkjj
2. But rotations do not change lengths, so jjUmkjj2 D jjmkjj2, and so jjUM jjF D jjM jjF. To see
</p>
<p>the result for the case of MU , just think of M as a table of row vectors.
</p>
<p>Notice that, if U is the orthonormal matrix whose columns are eigenvectors of T , then we have
</p>
<p>jj.T �A/ jjF2 D jjUT.T �A/U jjF
2
:
</p>
<p>Now write ƒr for U
TAU , and ƒ for the diagonal matrix of eigenvalues of T . Then we have
</p>
<p>jj.T �A/ jjF2 D jjƒ �ƒA jjF2;
</p>
<p>an expression that is easy to solve for ƒA. We know that ƒ is diagonal, so the best ƒA is diagonal, too. The rank of A must
</p>
<p>be r, so the rank of ƒA must be r as well. To get the best ƒA, we keep the r largest diagonal values of ƒ, and set the rest to
</p>
<p>zero; ƒA has rank r because it has only r non-zero entries on the diagonal, and every other entry is zero.
</p>
<p>Now to recover A from ƒA, we know that U
TU D UUT D I (remember, I is the identity). We have ƒA D UTAU , so
</p>
<p>A D UƒAUT :
</p>
<p>We can clean up this representation in a useful way. Notice that only the first r columns of U (and the corresponding rows of
</p>
<p>UT ) contribute to A. The remaining k � r are each multiplied by one of the zeros on the diagonal of ƒA. Remember that, by
convention, ƒ was sorted so that the diagonal values are in descending order (i.e. the largest value is in the top left corner).
</p>
<p>We now keep only the top left r � r block of ƒA, which we write ƒr. We then write Ur for the k � r matrix consisting of the
first r columns of U . Then
</p>
<p>A D UrƒrUT
</p>
<p>This is so useful a result, I have displayed it in a box; you should remember it.
</p>
<p>Procedure 15.1 (Approximating a Symmetric Matrix with a Low Rank Matrix) Assume we have a symmetric
</p>
<p>k � k matrix T . We wish to approximate T with a matrix A that has rank r &lt; k. Write U for the matrix whose
columns are eigenvectors of T , and ƒ for the diagonal matrix of eigenvalues of A (so AU D Uƒ). Remember that,
by convention, ƒ was sorted so that the diagonal values are in descending order (i.e. the largest value is in the top left
</p>
<p>corner).
</p>
<p>Now construct ƒr from ƒ by setting the k� r smallest values of ƒ to zero, and keeping only the top left r� r block.
Construct Ur, the k � r matrix consisting of the first r columns of U . Then
</p>
<p>A D UrƒrUTr
</p>
<p>is the best possible rank r approximation to T in the Frobenius norm.
</p>
<p>Now if A is positive semidefinite (i.e. if at least the r largest eigenvalues of T are non-negative), then we can factor A as
</p>
<p>in the previous section. This yields a procedure to approximate a symmetric matrix by factors. This is so useful a result, I
</p>
<p>have displayed it in a box; you should remember it.
</p>
<p>Procedure 15.2 (Approximating a Symmetric Matrix with Low Dimensional Factors) Assume we have a
</p>
<p>symmetric k � k matrix T . We wish to approximate T with a matrix A that has rank r &lt; k. We assume that at
least the r largest eigenvalues of T are non-negative. Write U for the matrix whose columns are eigenvectors of T , and
</p>
<p>ƒ for the diagonal matrix of eigenvalues of A (so AU D Uƒ). Remember that, by convention, ƒ was sorted so that
the diagonal values are in descending order (i.e. the largest value is in the top left corner).
</p>
<p>(continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>358 15 Resources and Extras
</p>
<p>Now construct ƒr from ƒ by setting the k� r smallest values of ƒ to zero and keeping only the top left r� r block.
Construct ƒ
</p>
<p>.1=2/
r by replacing each diagonal element of ƒ with its positive square root. Construct Ur, the k � r matrix
</p>
<p>consisting of the first r columns of U . Then write V D .Urƒ.1=2/r /
</p>
<p>A D VVT
</p>
<p>is the best possible rank r approximation to T in the Frobenius norm.
</p>
<p>15.2 Some Special Functions
</p>
<p>Error functions and Gaussians: The error function is defined by
</p>
<p>erf.x/ D 2p
�
</p>
<p>Z x
</p>
<p>0
</p>
<p>e�t
2
</p>
<p>dt
</p>
<p>and programming environments can typically evaluate the error function. This fact is made useful to us by a simple change
</p>
<p>of variables. We get
</p>
<p>1p
2�
</p>
<p>Z x
</p>
<p>0
</p>
<p>e
�u2
2 du D 1p
</p>
<p>�
</p>
<p>Z xp
2
</p>
<p>0
</p>
<p>e�t
2
</p>
<p>dt D 1
2
</p>
<p>erf
</p>
<p>�
</p>
<p>xp
2
</p>
<p>�
</p>
<p>:
</p>
<p>A particularly useful manifestation of this fact comes by noticing that
</p>
<p>1p
2�
</p>
<p>Z 0
</p>
<p>�1
e
</p>
<p>�t2
2 dt D 1=2
</p>
<p>(because 1p
2�
e
</p>
<p>�u2
2 is a probability density function, and is symmetric about 0). As a result, we get
</p>
<p>1p
2�
</p>
<p>Z x
</p>
<p>�1
e
</p>
<p>�t2
2 dt D 1=2
</p>
<p>�
</p>
<p>1C erf
�
</p>
<p>xp
2
</p>
<p>��
</p>
<p>:
</p>
<p>Inverse error functions: We sometimes wish to know the value of x such that
</p>
<p>1p
2�
</p>
<p>Z x
</p>
<p>�1
e
</p>
<p>�t2
2 dt D p
</p>
<p>for some given p. The relevant function of p is known as the probit function or the normal quantile function. We write
</p>
<p>x D ˆ.p/:
</p>
<p>The probit function ˆ can be expressed in terms of the inverse error function. Most programming environments can evaluate
</p>
<p>the inverse error function (which is the inverse of the error function). We have that
</p>
<p>ˆ.p/ D
p
2erf�1.2p � 1/:
</p>
<p>One problem we solve with some regularity is: choose u such that
</p>
<p>Z u
</p>
<p>�u
</p>
<p>1p
2�
</p>
<p>exp .�x2=2/dx D p:</p>
<p/>
</div>
<div class="page"><p/>
<p>15.3 Splitting a Node in a Decision Tree 359
</p>
<p>Notice that
</p>
<p>p
</p>
<p>2
D 1p
</p>
<p>2�
</p>
<p>Z u
</p>
<p>0
</p>
<p>e
�t2
2 dt
</p>
<p>D 1
2
</p>
<p>erf
</p>
<p>�
</p>
<p>up
2
</p>
<p>�
</p>
<p>so that
</p>
<p>u D
p
2erf�1.p/:
</p>
<p>Gamma functions: The gamma function &#128;.x/ is defined by a series of steps. First, we have that for n an integer,
</p>
<p>&#128;.n/ D .n � 1/Š
</p>
<p>and then for z a complex number with positive real part (which includes positive real numbers), we have
</p>
<p>&#128;.z/ D
Z 1
</p>
<p>0
</p>
<p>tz
e�t
</p>
<p>t
dt:
</p>
<p>By doing this, we get a function on positive real numbers that is a smooth interpolate of the factorial function. We won&rsquo;t
</p>
<p>do any real work with this function, so won&rsquo;t expand on this definition. In practice, we&rsquo;ll either look up a value in tables or
</p>
<p>require a software environment to produce it.
</p>
<p>15.3 Splitting a Node in a Decision Tree
</p>
<p>We want to choose a split that yields the most information about the classes. To do so, we need to be able to account for
</p>
<p>information. The proper measure is entropy (described in more detail below). You should think of entropy as the number of
</p>
<p>bits, on average, that would be required to determine the value of a random variable. Filling in the details will allow us to
</p>
<p>determine which of two splits is better, and to tell whether it is worth splitting at all. At a high level, it is easy to compute
</p>
<p>which of two splits is better. We determine the entropy of the class conditioned on each split, then take the split which yields
</p>
<p>the lowest entropy. This works because less information (fewer bits) are required to determine the value of the class once we
</p>
<p>have that split. Similarly, it is easy to compute whether to split or not. We compare the entropy of the class conditioned on
</p>
<p>each split to the entropy of the class without a split, and choose the case with the lowest entropy, because less information
</p>
<p>(fewer bits) are required to determine the value of the class in that case.
</p>
<p>15.3.1 Accounting for Information with Entropy
</p>
<p>It turns out to be straightforward to keep track of information, in simple cases. We will start with an example. Assume I have
</p>
<p>4 classes. There are 8 examples in class 1, 4 in class 2, 2 in class 3, and 2 in class 4. How much information on average will
</p>
<p>you need to send me to tell me the class of a given example? Clearly, this depends on how you communicate the information.
</p>
<p>You could send me the complete works of Edward Gibbon to communicate class 1; the Encyclopaedia for class 2; and so
</p>
<p>on. But this would be redundant. The question is how little can you send me. Keeping track of the amount of information is
</p>
<p>easier if we encode it with bits (i.e. you can send me sequences of &lsquo;0&rsquo;s and &lsquo;1&rsquo;s).
</p>
<p>Imagine the following scheme. If an example is in class 1, you send me a &lsquo;1&rsquo;. If it is in class 2, you send me &lsquo;01&rsquo;; if it is
</p>
<p>in class 3, you send me &lsquo;001&rsquo;; and in class 4, you send me &lsquo;101&rsquo;. Then the expected number of bits you will send me is
</p>
<p>p.class = 1/1C p.2/2C p.3/3C p.4/3
</p>
<p>D 1
2
1C 1
</p>
<p>4
2C 1
</p>
<p>8
3C 1
</p>
<p>8
3
</p>
<p>which is 1:75 bits. This number doesn&rsquo;t have to be an integer, because it&rsquo;s an expectation.</p>
<p/>
</div>
<div class="page"><p/>
<p>360 15 Resources and Extras
</p>
<p>Notice that for the i&rsquo;th class, you have sent me � log2 p.i/ bits. We can write the expected number of bits you need to send
me as
</p>
<p>�
X
</p>
<p>i
</p>
<p>p.i/ log2 p.i/:
</p>
<p>This expression handles other simple cases correctly, too. You should notice that it isn&rsquo;t really important how many objects
</p>
<p>appear in each class. Instead, the fraction of all examples that appear in the class is what matters. This fraction is the prior
</p>
<p>probability that an item will belong to the class. You should try what happens if you have two classes, with an even number
</p>
<p>of examples in each; 256 classes, with an even number of examples in each; and 5 classes, with p.1/ D 1=2, p.2/ D 1=4,
p.3/ D 1=8, p.4/ D 1=16 and p.5/ D 1=16. If you try other examples, you may find it hard to construct a scheme where you
can send as few bits on average as this expression predicts. It turns out that, in general, the smallest number of bits you will
</p>
<p>need to send me is given by the expression
</p>
<p>�
X
</p>
<p>i
</p>
<p>p.i/ log2 p.i/
</p>
<p>under all conditions, though it may be hard or impossible to determine what representation is required to achieve this number.
</p>
<p>The entropy of a probability distribution is a number that scores how many bits, on average, would need to be known to
</p>
<p>identify an item sampled from that probability distribution. For a discrete probability distribution, the entropy is computed
</p>
<p>as
</p>
<p>�
X
</p>
<p>i
</p>
<p>p.i/ log2 p.i/
</p>
<p>where i ranges over all the numbers where p.i/ is not zero. For example, if we have two classes and p.1/ D 0:99, then
the entropy is 0:0808, meaning you need very little information to tell which class an object belongs to. This makes sense,
</p>
<p>because there is a very high probability it belongs to class 1; you need very little information to tell you when it is in class 2.
</p>
<p>If you are worried by the prospect of having to send 0:0808 bits, remember this is an average, so you can interpret the number
</p>
<p>as meaning that, if you want to tell which class each of 104 independent objects belong to, you could do so in principle with
</p>
<p>only 808 bits.
</p>
<p>Generally, the entropy is larger if the class of an item is more uncertain. Imagine we have two classes and p.1/ D 0:5,
then the entropy is 1, and this is the largest possible value for a probability distribution on two classes. You can always tell
</p>
<p>which of two classes an object belongs to with just one bit (though you might be able to tell with even less than one bit).
</p>
<p>15.3.2 Choosing a Split with Information Gain
</p>
<p>Write P for the set of all data at the node. Write Pl for the left pool, and Pr for the right pool. The entropy of a pool C scores
</p>
<p>how many bits would be required to represent the class of an item in that pool, on average. Write n.iI C/ for the number of
items of class i in the pool, and N.C/ for the number of items in the pool. Then the entropy H.C/ of the pool C is
</p>
<p>�
X
</p>
<p>i
</p>
<p>n.iI C/
N.C/
</p>
<p>log2
n.iI C/
N.C
</p>
<p>:
</p>
<p>It is straightforward that H.P/ bits are required to classify an item in the parent pool P . For an item in the left pool, we need
</p>
<p>H.Pl/ bits; for an item in the right pool, we need H.Pr/ bits. If we split the parent pool, we expect to encounter items in the
</p>
<p>left pool with probability
</p>
<p>N.Pl/
</p>
<p>N.P/
</p>
<p>and items in the right pool with probability
</p>
<p>N.Pr/
</p>
<p>N.P/
:</p>
<p/>
</div>
<div class="page"><p/>
<p>15.3 Splitting a Node in a Decision Tree 361
</p>
<p>This means that, on average, we must supply
</p>
<p>N.Pl/
</p>
<p>N.P/
H.Pl/C
</p>
<p>N.Pr/
</p>
<p>N.P/
H.Pr/
</p>
<p>bits to classify data items if we split the parent pool. Now a good split is one that results in left and right pools that are
</p>
<p>informative. In turn, we should need fewer bits to classify once we have split than we need before the split. You can see the
</p>
<p>difference
</p>
<p>I.Pl;PrIP/ D H.P/ �
�
</p>
<p>N.Pl/
</p>
<p>N.P/
H.Pl/C
</p>
<p>N.Pr/
</p>
<p>N.P/
H.Pr/
</p>
<p>�
</p>
<p>as the information gain caused by the split. This is the average number of bits that you don&rsquo;t have to supply if you know
</p>
<p>which side of the split an example lies. Better splits have larger information gain.
</p>
<p>Recall that our decision function is to choose a feature at random, then test its value against a threshold. Any data point
</p>
<p>where the value is larger goes to the left pool; where the value is smaller goes to the right. This may sound much too simple
</p>
<p>to work, but it is actually effective and popular. Assume that we are at a node, which we will label k. We have the pool of
</p>
<p>training examples that have reached that node. The i&rsquo;th example has a feature vector xi, and each of these feature vectors is
</p>
<p>a d dimensional vector.
</p>
<p>We choose an integer j in the range 1 : : : d uniformly and at random. We will split on this feature, and we store j in the
</p>
<p>node. Recall we write x
.j/
i for the value of the j&rsquo;th component of the i&rsquo;th feature vector. We will choose a threshold tk, and
</p>
<p>split by testing the sign of x
.j/
i � tk. Choosing the value of tk is easy. Assume there are Nk examples in the pool. Then there
</p>
<p>are Nk � 1 possible values of tk that lead to different splits. To see this, sort the Nk examples by x.j/, then choose values of tk
halfway between example values. For each of these values, we compute the information gain of the split. We then keep the
</p>
<p>threshold with the best information gain.
</p>
<p>We can elaborate this procedure in a useful way, by choosing m features at random, finding the best split for each, then
</p>
<p>keeping the feature and threshold value that is best. It is important that m is a lot smaller than the total number of features&mdash;a
</p>
<p>usual root of thumb is that m is about the square root of the total number of features. It is usual to choose a single m, and
</p>
<p>choose that for all the splits.</p>
<p/>
</div>
<div class="page"><p/>
<p>Index
</p>
<p>Symbols
</p>
<p>L2 norm, 321
�2-distribution, 171
�2-statistic, 171
3D bar chart, 30
</p>
<p>A
</p>
<p>absorbing state, 332
accuracy, 254
affinity, 290
Agglomerative Clustering, 283
all-vs-all, 268
analysis of variance, 182
ANOVA, 182
ANOVA table, 182
approximate nearest neighbor, 256
Approximating a symmetric matrix with a low rank matrix, 357
Approximating a symmetric matrix with low dimensional factors, 358
average, 7
</p>
<p>B
</p>
<p>bag, 272
bagging, 272
balanced, 180
balanced experiment, 183
bar chart, 5
baselines, 254
Basic properties of the probability events, 55
batch, 263
batch size, 263
Bayes risk, 254
Bayes&rsquo; rule, 89
Bayesian inference, 207
Bayesian inference is particularly good with little data, 211
Bernoulli random variable, 116
Beta distribution, 120
between group variation, 182
biased estimate, 147
biased random walk, 331
bigram models, 337
bigrams, 337
bimodal, 16
Binomial distribution, 117
Binomial distribution for large N, 130
bootstrap, 152
bootstrap replicates, 152
box plot, 20
Building a decision forest, 272
Building a decision forest using bagging, 273
Building a decision tree: overall, 271
</p>
<p>C
</p>
<p>categorical, 3
Centered confidence interval for a population mean,
</p>
<p>146
Chebyshev&rsquo;s inequality, 100
class conditional probability, 257
class confusion matrix, 254
class error rate, 254
class-conditional histograms, 7
Classification with a decision forest, 273
Classifier, 253
classifier, 253
</p>
<p>definition, 253
nearest neighbors, 256
</p>
<p>cluster center, 283
clustering, 281
</p>
<p>using K-means, 287
clusters, 283
color constancy, 241
comparing to chance, 254
complete-link clustering, 283
Computing a one-sided p-value for a T-test, 163
Computing a two-sided p-value for a T-test, 163
conditional histograms, 7
Conditional independence, 72
Conditional probability, 66
Conditional probability for independent events, 71
Conditional probability formulas, 70
Confidence interval for a population mean, 146
conjugacy, 209
conjugate prior, 209
consistency, 206
Constructing a centered 1 � 2˛ confidence interval for a population
</p>
<p>mean for a large sample, 151
Constructing a centered 1 � 2˛ confidence interval for a population
</p>
<p>mean for a small sample, 151
continuous, 3
contrasts, 185
correlation, 36, 39
Correlation coefficient, 39
cost to go function, 345
Covariance, 97, 227
covariance ellipses, 302
Covariance Matrix, 229
Covariance, useful expression, 97
cross-validation, 255
Cumulative distribution of a discrete random variable, 88
</p>
<p>D
</p>
<p>decision function, 269
decision boundary, 260
</p>
<p>&copy; Springer International Publishing AG 2018
D. Forsyth, Probability and Statistics for Computer Science,
https://doi.org/10.1007/978-3-319-64410-3
</p>
<p>363</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-64410-3">https://doi.org/10.1007/978-3-319-64410-3</a></div>
</div>
<div class="page"><p/>
<p>364 Index
</p>
<p>decision forest, 269
decision tree, 105, 268
degrees of freedom, 147
dendrogram, 284
density, 91
dependent variable, 305
descent direction, 263
descriptive statistics, 98
diagonal, 355
diagonalizing, 356
Diagonalizing a symmetric matrix, 233
Discrete random variable, 87
distributions
</p>
<p>how often a normal random variable is how far from the mean,
125
</p>
<p>mean and variance of a bernoulli random variable, 116
mean and variance of a beta distribution, 121
mean and variance of a geometric distribution, 116
mean and variance of the binomial distribution, 117
mean and variance of the exponential distribution, 122
mean and variance of the gamma distribution, 121
mean and variance of the normal distribution, 124
mean and variance of the poisson distribution, 119
mean and variance of the standard normal distribution, 123
</p>
<p>Divisive Clustering, 284
dynamic programming, 345
</p>
<p>E
</p>
<p>Easy confidence intervals for a big sample, 150
eigenvalue, 232, 355
eigenvector, 232, 355
emission distribution, 344
empirical distribution, 99, 152
entropy, 360
epoch, 264
error, 254
error bars, 150
error function, 125, 358
Estimating Confidence Intervals for Maximum Likelihood Estimates
</p>
<p>using Simulation, 205
Estimating with maximum likelihood, 199
Evaluating whether a treatment has significant effects with a one-way
</p>
<p>ANOVA for balanced experiments, 183
Event, 55
Expectation, 94
Expectation of a continuous random variable, 95
Expectations are linear, 95
Expected value, 93
Expected value of a continuous random variable, 95
explanatory variables, 305
Exponential distribution, 122
Expressions for mean and variance of the sample mean, 144
</p>
<p>F
</p>
<p>F-distribution, 170
F-statistic, 170
false positive rate, 254
false negative rate, 254
feature vector, 253
filtering, 214
fold, 255
Forming and interpreting a two-way ANOVA table, 191
Frobenius norm, 356
</p>
<p>G
</p>
<p>gambler&rsquo;s fallacy, 64
Gamma distribution, 121
gaussian distributions, 124
generalizing badly, 255
Geometric distribution, 116
gradient descent, 263
group average clustering, 283
</p>
<p>H
</p>
<p>heat map, 30
hidden Markov model, 344
hinge loss, 261
histogram, 6
</p>
<p>I
</p>
<p>IID, 198
iid samples, 99
independent and identically distributed, 198
Independent events, 62
independent identically distributed samples, 99
Independent random variables, 90
Independent random variables have zero covariance, 97
indicator function, 100
Indicator functions, 100
information gain, 270, 361
intensity, 119
interaction mean squares, 189
Interquartile Range, 15
inverse error function, 358
irreducible, 335
</p>
<p>J
</p>
<p>joint, 210
Joint probability distribution of two discrete random variables, 89
</p>
<p>K
</p>
<p>k-means, see clustering, 287
K-Means Clustering, 287
K-Means with Soft Weights, 291
</p>
<p>L
</p>
<p>latent variable, 45
learning curves, 264
learning rate, 264
leave-one-out cross-validation, 255
Likelihood, 198
likelihood, 257
Likert scales, 247
line search, 263
Linear regression, 308
Linear Regression using Least Squares, 312
location parameter, 9
Log-likelihood of a dataset under a model, 201
</p>
<p>M
</p>
<p>Many Markov chains have stationary distributions, 336
MAP estimate, 207
Marginal probability of a random variable, 90</p>
<p/>
</div>
<div class="page"><p/>
<p>Index 365
</p>
<p>Markov chain, 331
Markov chains, 333
Markov&rsquo;s inequality, 100
maximum a posteriori estimate, 207
Maximum likelihood principle, 198
Mean, 7
mean and variance of
</p>
<p>a bernoulli random variable, 116
a beta distribution, 121
a geometric distribution, 116
the binomial distribution, 117
the exponential distribution, 122
the gamma distribution, 121
the normal distribution, 124
the poisson distribution, 119
the standard normal distribution, 123
</p>
<p>Mean or expected value, 96
mean square error, 310
Median, 13
mode, 16
multidimensional scaling, 245
multimodal, 16
Multinomial distribution, 118
</p>
<p>N
</p>
<p>n-gram models, 337
n-grams, 337
normal distribution, 124
Normal data, 19
Normal distribution, 124
normal distribution, 124
Normal posteriors can be updated online, 215
normal quantile function, 358
normal random variable, 124
normalizing, 92
normalizing constant, 92
</p>
<p>O
</p>
<p>odds, 104
one factor, 182
one-sided p-value, 163
one-vs-all, 268
ordinal, 3
orthonormal, 355
Orthonormal matrices are rotations, 233
outcomes, 53
outlier, 13
outliers, 314
overfitting, 255
</p>
<p>P
</p>
<p>p-value, 162
p-value hacking, 174
Pairwise independence, 72
Parameters of a Multivariate Normal Distribution, 301
pdf, 91
Percentile, 14
phonemes, 344
pie chart, 29
Poisson distribution, 119
Poisson point process, 119
population, 141
population mean, 141
</p>
<p>positive definite, 355
positive semidefinite, 355
posterior, 207, 258
Predicting a value using correlation, 43
Predicting a value using correlation: Rule of thumb - 1, 44
Predicting a value using correlation: Rule of thumb - 2, 44
principal components, 237
Principal Components Analysis, 240
Principal Coordinate Analysis, 246
principal coordinate analysis, 245
prior, 257
prior probability distribution, 207
probability, 54
probability density function, 91
Probability distribution of a discrete random variable, 88
probability mass function, 88
probit function, 358
procedure
</p>
<p>predicting a value using correlation, 43
the t-test of significance for a hypothesized mean, 162
agglomerative clustering, 283
approximating a symmetric matrix with a low rank matrix, 357
approximating a symmetric matrix with low dimensional factors,
</p>
<p>358
building a decision forest, 272
building a decision forest using bagging, 273
building a decision tree: overall, 271
classification with a decision forest, 273
computing a one-sided p-value for a t-test, 163
computing a two-sided p-value for a t-test, 163
constructing a centered 1� 2˛ confidence interval for a population
</p>
<p>mean for a large sample, 151
constructing a centered 1� 2˛ confidence interval for a population
</p>
<p>mean for a small sample, 151
diagonalizing a symmetric matrix, 233
divisive clustering, 284
estimating confidence intervals for maximum likelihood estimates
</p>
<p>using simulation, 205
estimating with maximum likelihood, 199
evaluating whether a treatment has significant effects with a
</p>
<p>one-way anova for balanced experiments, 183
forming and interpreting a two-way anova table, 191
k-means clustering, 287
k-means with soft weights, 291
linear regression using least squares, 312
predicting a value using correlation: rule of thumb&mdash;1, 44
predicting a value using correlation: rule of thumb&mdash;2, 44
principal components analysis, 240
principal coordinate analysis, 246
setting up a two-way anova, 191
splitting a non-ordinal feature, 272
splitting an ordinal feature, 272
testing whether two populations have the same mean, for different
</p>
<p>population standard deviations, 169
testing whether two populations have the same mean, for known
</p>
<p>population standard deviations, 166
testing whether two populations have the same mean, for same but
</p>
<p>unknown population standard deviations, 167
the �2-test of significance of fit to a model, 172
the bootstrap, 153
the f-test of significance for equality of variance, 170
training an svm: estimating the accuracy, 266
training an svm: overall, 266
training an svm: stochastic gradient descent, 267
vector quantization&mdash;building a dictionary, 296
vector quantization&mdash;representing a signal, 296</p>
<p/>
</div>
<div class="page"><p/>
<p>366 Index
</p>
<p>Properties of normal data, 20
Properties of probability density functions, 92
Properties of sample and population means, 142
Properties of standard deviation, 10
Properties of the correlation coefficient, 40
Properties of the covariance matrix, 230
Properties of the interquartile range, 15
Properties of the mean, 8
Properties of the median, 14
Properties of the probability of events, 59
Properties of variance, 13, 96
prosecutor&rsquo;s fallacy, 72
</p>
<p>Q
</p>
<p>Quartiles, 14
</p>
<p>R
</p>
<p>Randomization, 179
raw Google matrix, 343
realization, 99
recurrent, 332
Regression, 305, 308, 311
regularization, 262
regularization parameter, 262
regularization weight, 319
regularizer, 262
residual, 310
residual variation, 181
ridge regression, 319
</p>
<p>S
</p>
<p>sample, 99, 141
sample mean, 141
Sample space, 53
scale parameter, 10
scatter plot, 33
selection bias, 255
sensitivity, 254
Setting up a two-way ANOVA, 191
single-link clustering, 283
skew, 16
smoothing, 338
specificity, 254
Splitting a non-ordinal feature, 272
Splitting an ordinal feature, 272
stacked bar chart, 30
Standard coordinates, 18
Standard deviation, 9, 98
standard deviation, 98
Standard error, 147
standard normal curve, 19
Standard normal data, 19
Standard Normal distribution, 123
standard normal distribution, 123
standard normal random variable, 123
stationary distribution, 335
statistic, 146
Statistical significance, 162
step size, 264
steplength, 264
steplength schedule, 264
Stochastic gradient descent, 263
stochastic matrices, 333
</p>
<p>Sums and differences of normal random variables, 165
support vector machine, 261
SVM, 261
symmetric, 232, 355
</p>
<p>T
</p>
<p>T-distribution, 149
T-random variable, 149
T-test, 162
tails, 16
test error, 255
test examples, 305
test statistic, 160
Testing whether two populations have the same mean, for different
</p>
<p>population standard deviations, 169
Testing whether two populations have the same mean, for known
</p>
<p>population standard deviations, 166
Testing whether two populations have the same mean, for same but
</p>
<p>unknown population standard deviations, 167
The �2-test of significance of fit to a model, 172
The bootstrap, 153
The F-test of significance for equality of variance, 170
The parameters of a normal posterior with a single measurement, 214
The properties of simulations, 341
The T-test of significance for a hypothesized mean, 162
total error rate, 254
Training an SVM: estimating the accuracy, 266
Training an SVM: Overall, 266
Training an SVM: stochastic gradient descent, 267
training error, 255
training examples, 305
transition probabilities, 331
Transition probability matrices, 335
treatment one mean squares, 190
treatment two mean squares, 190
treatment variation, 182
trellis, 345
trial, 99
trigram models, 337
trigrams, 337
two-factor ANOVA, 191
two-sided p-value, 163
two-way ANOVA, 191
</p>
<p>U
</p>
<p>unbalanced experiment, 183
unbiased, 255
unbiased estimate, 147
uniform distribution, 120
Uniform distribution, continuous, 120
uniform random variable, 120
Uniform random variable, discrete, 115
unigram models, 337
unigrams, 337
unimodal, 16
useful facts
</p>
<p>basic properties of the probability events, 55
bayesian inference is particularly good with little data, 211
binomial distribution for large n, 130
conditional probability for independent events, 71
conditional probability formulas, 70
covariance, useful expression, 97
easy confidence intervals for a big sample, 150
expectations are linear, 95</p>
<p/>
</div>
<div class="page"><p/>
<p>Index 367
</p>
<p>expressions for mean and variance of the sample mean, 144
how often a normal random variable is how far from the mean, 125
independent random variables have zero covariance, 97
many markov chains have stationary distributions, 336
markov chains, 333
mean and variance of a bernoulli random variable, 116
mean and variance of a beta distribution, 121
mean and variance of a geometric distribution, 116
mean and variance of the binomial distribution, 117
mean and variance of the exponential distribution, 122
mean and variance of the gamma distribution, 121
mean and variance of the normal distribution, 124
mean and variance of the poisson distribution, 119
mean and variance of the standard normal distribution, 123
normal posteriors can be updated online, 215
orthonormal matrices are rotations, 233
parameters of a multivariate normal distribution, 301
properties of normal data, 20
properties of probability density functions, 92
properties of sample and population means, 142
properties of standard deviation, 10
properties of the correlation coefficient, 40
properties of the covariance matrix, 230
properties of the interquartile range, 15
properties of the median, 14
properties of the probability of events, 59
properties of variance, 13, 96
regression, 311
sums and differences of normal random variables, 165
the parameters of a normal posterior with a single measurement,
</p>
<p>214
the properties of simulations, 341
</p>
<p>transition probability matrices, 335
variance as covariance, 98
variance, a useful expression, 96
you can transform data to zero mean and diagonal covariance, 234
</p>
<p>utility, 107
</p>
<p>V
</p>
<p>validation set, 255
Variance, 13, 96
Variance as covariance, 98
Variance, a useful expression, 96
vector quantization, 296
Vector Quantization - Building a Dictionary, 296
Vector Quantization - Representing a Signal, 296
Viterbi algorithm, 345
</p>
<p>W
</p>
<p>Weak Law of Large Numbers, 102
whitening, 256, 286
within group variation, 181
within group mean squares, 189
</p>
<p>Y
</p>
<p>You can transform data to zero mean and diagonal covariance, 234
</p>
<p>Z
</p>
<p>Zipf&rsquo;s law, 313</p>
<p/>
</div>
<ul>	<li>Preface</li>
<ul>	<li>Reading and Teaching This Book</li>
<ul>	<li>Describing Datasets</li>
	<li>Probability</li>
	<li>Inference</li>
	<li>Tools</li>
	<li>Mathematical Bits and Pieces</li>
</ul>
</ul>
	<li>Acknowledgments</li>
	<li>Contents</li>
	<li>About the Author</li>
	<li>Notation and Conventions</li>
<ul>	<li>Background Information</li>
</ul>
	<li>Part I Describing Datasets</li>
<ul>	<li>1 First Tools for Looking at Data</li>
<ul>	<li>1.1 Datasets</li>
	<li>1.2 What's Happening? Plotting Data</li>
<ul>	<li>1.2.1 Bar Charts</li>
	<li>1.2.2 Histograms</li>
	<li>1.2.3 How to Make Histograms</li>
	<li>1.2.4 Conditional Histograms</li>
</ul>
	<li>1.3 Summarizing 1D Data</li>
<ul>	<li>1.3.1 The Mean</li>
	<li>1.3.2 Standard Deviation</li>
	<li>1.3.3 Computing Mean and Standard Deviation Online</li>
	<li>1.3.4 Variance</li>
	<li>1.3.5 The Median</li>
	<li>1.3.6 Interquartile Range</li>
	<li>1.3.7 Using Summaries Sensibly</li>
</ul>
	<li>1.4 Plots and Summaries</li>
<ul>	<li>1.4.1 Some Properties of Histograms</li>
	<li>1.4.2 Standard Coordinates and Normal Data</li>
	<li>1.4.3 Box Plots</li>
</ul>
	<li>1.5 Whose is Bigger? Investigating Australian Pizzas</li>
	<li>1.6 You Should</li>
<ul>	<li>1.6.1 Remember These Definitions</li>
	<li>1.6.2 Remember These Terms</li>
	<li>1.6.3 Remember These Facts</li>
	<li>1.6.4 Be Able to</li>
</ul>
	<li>Problems</li>
	<li>Programming Exercises</li>
</ul>
	<li>2 Looking at Relationships</li>
<ul>	<li>2.1 Plotting 2D Data</li>
<ul>	<li>2.1.1 Categorical Data, Counts, and Charts</li>
	<li>2.1.2 Series</li>
	<li>2.1.3 Scatter Plots for Spatial Data</li>
	<li>2.1.4 Exposing Relationships with Scatter Plots</li>
</ul>
	<li>2.2 Correlation</li>
<ul>	<li>2.2.1 The Correlation Coefficient</li>
	<li>2.2.2 Using Correlation to Predict</li>
	<li>2.2.3 Confusion Caused by Correlation</li>
</ul>
	<li>2.3 Sterile Males in Wild Horse Herds</li>
	<li>2.4 You Should</li>
<ul>	<li>2.4.1 Remember These Definitions</li>
	<li>2.4.2 Remember These Terms</li>
	<li>2.4.3 Remember These Facts</li>
	<li>2.4.4 Use These Procedures</li>
	<li>2.4.5 Be Able to</li>
</ul>
	<li>Problems</li>
	<li>Programming Exercises</li>
</ul>
</ul>
	<li>Part II Probability</li>
<ul>	<li>3 Basic Ideas in Probability</li>
<ul>	<li>3.1 Experiments, Outcomes and Probability</li>
<ul>	<li>3.1.1 Outcomes and Probability</li>
</ul>
	<li>3.2 Events</li>
<ul>	<li>3.2.1 Computing Event Probabilities by Counting Outcomes</li>
	<li>3.2.2 The Probability of Events</li>
	<li>3.2.3 Computing Probabilities by Reasoning About Sets</li>
</ul>
	<li>3.3 Independence</li>
<ul>	<li>3.3.1 Example: Airline Overbooking</li>
</ul>
	<li>3.4 Conditional Probability</li>
<ul>	<li>3.4.1 Evaluating Conditional Probabilities</li>
	<li>3.4.2 Detecting Rare Events Is Hard</li>
	<li>3.4.3 Conditional Probability and Various Forms of Independence</li>
	<li>3.4.4 Warning Example: The Prosecutor's Fallacy</li>
	<li>3.4.5 Warning Example: The Monty Hall Problem</li>
</ul>
	<li>3.5 Extra Worked Examples</li>
<ul>	<li>3.5.1 Outcomes and Probability</li>
	<li>3.5.2 Events</li>
	<li>3.5.3 Independence</li>
	<li>3.5.4 Conditional Probability</li>
</ul>
	<li>3.6 You Should</li>
<ul>	<li>3.6.1 Remember These Definitions</li>
	<li>3.6.2 Remember These Terms</li>
	<li>3.6.3 Remember and Use These Facts</li>
	<li>3.6.4 Remember These Points</li>
	<li>3.6.5 Be Able to</li>
</ul>
	<li>Problems</li>
<ul>	<li>Outcomes</li>
	<li>The Probability of an Outcome</li>
	<li>Events</li>
	<li>Computing Probabilities by Counting Outcomes</li>
	<li>The Probability of Events</li>
	<li>Permutations and Combinations</li>
	<li>Independence</li>
	<li>Conditional Probability</li>
	<li>The Monty Hall Problem</li>
</ul>
</ul>
	<li>4 Random Variables and Expectations</li>
<ul>	<li>4.1 Random Variables</li>
<ul>	<li>4.1.1 Joint and Conditional Probability for Random Variables</li>
	<li>4.1.2 Just a Little Continuous Probability</li>
</ul>
	<li>4.2 Expectations and Expected Values</li>
<ul>	<li>4.2.1 Expected Values</li>
	<li>4.2.2 Mean, Variance and Covariance</li>
	<li>4.2.3 Expectations and Statistics</li>
</ul>
	<li>4.3 The Weak Law of Large Numbers</li>
<ul>	<li>4.3.1 IID Samples</li>
	<li>4.3.2 Two Inequalities</li>
	<li>4.3.3 Proving the Inequalities</li>
	<li>4.3.4 The Weak Law of Large Numbers</li>
</ul>
	<li>4.4 Using the Weak Law of Large Numbers</li>
<ul>	<li>4.4.1 Should You Accept a Bet?</li>
	<li>4.4.2 Odds, Expectations and Bookmaking: A Cultural Diversion</li>
	<li>4.4.3 Ending a Game Early</li>
	<li>4.4.4 Making a Decision with Decision Trees and Expectations</li>
	<li>4.4.5 Utility</li>
</ul>
	<li>4.5 You Should</li>
<ul>	<li>4.5.1 Remember These Definitions</li>
	<li>4.5.2 Remember These Terms</li>
	<li>4.5.3 Use and Remember These Facts</li>
	<li>4.5.4 Remember These Points</li>
	<li>4.5.5 Be Able to</li>
</ul>
	<li>Problems</li>
<ul>	<li>Joint and Conditional Probability for Random Variables</li>
	<li>Continuous Random Variables</li>
	<li>Expected Values</li>
	<li>Mean, Variance and Covariance</li>
	<li>Expectations and Descriptive Statistics</li>
	<li>Markov and Chebyshev Inequalities</li>
	<li>Using Expectations</li>
</ul>
	<li>Programming Exercises</li>
</ul>
	<li>5 Useful Probability Distributions</li>
<ul>	<li>5.1 Discrete Distributions</li>
<ul>	<li>5.1.1 The Discrete Uniform Distribution</li>
	<li>5.1.2 Bernoulli Random Variables</li>
	<li>5.1.3 The Geometric Distribution</li>
	<li>5.1.4 The Binomial Probability Distribution</li>
	<li>5.1.5 Multinomial Probabilities</li>
	<li>5.1.6 The Poisson Distribution</li>
</ul>
	<li>5.2 Continuous Distributions</li>
<ul>	<li>5.2.1 The Continuous Uniform Distribution</li>
	<li>5.2.2 The Beta Distribution</li>
	<li>5.2.3 The Gamma Distribution</li>
	<li>5.2.4 The Exponential Distribution</li>
</ul>
	<li>5.3 The Normal Distribution</li>
<ul>	<li>5.3.1 The Standard Normal Distribution</li>
	<li>5.3.2 The Normal Distribution</li>
	<li>5.3.3 Properties of the Normal Distribution</li>
</ul>
	<li>5.4 Approximating Binomials with Large N</li>
<ul>	<li>5.4.1 Large N</li>
	<li>5.4.2 Getting Normal</li>
	<li>5.4.3 Using a Normal Approximation to the Binomial Distribution</li>
</ul>
	<li>5.5 You Should</li>
<ul>	<li>5.5.1 Remember These Definitions</li>
	<li>5.5.2 Remember These Terms</li>
	<li>5.5.3 Remember These Facts</li>
	<li>5.5.4 Remember These Points</li>
</ul>
	<li>Problems</li>
<ul>	<li>Sums and Differences of Discrete Random Variables</li>
	<li>The Geometric Distribution</li>
	<li>Bernoulli Random Variables</li>
	<li>The Binomial Distribution</li>
	<li>The Multinomial Distribution</li>
	<li>The Poisson Distribution</li>
	<li>Sums of Continuous Random Variables</li>
	<li>The Normal Distribution</li>
	<li>The Binomial Distribution for Large N</li>
</ul>
	<li>Programming Exercises</li>
</ul>
</ul>
	<li>Part III Inference</li>
<ul>	<li>6 Samples and Populations</li>
<ul>	<li>6.1 The Sample Mean</li>
<ul>	<li>6.1.1 The Sample Mean Is an Estimate of the Population Mean</li>
	<li>6.1.2 The Variance of the Sample Mean</li>
	<li>6.1.3 When The Urn Model Works</li>
	<li>6.1.4 Distributions Are Like Populations</li>
</ul>
	<li>6.2 Confidence Intervals</li>
<ul>	<li>6.2.1 Constructing Confidence Intervals</li>
	<li>6.2.2 Estimating the Variance of the Sample Mean</li>
	<li>6.2.3 The Probability Distribution of the Sample Mean</li>
	<li>6.2.4 Confidence Intervals for Population Means</li>
	<li>6.2.5 Standard Error Estimates from Simulation</li>
</ul>
	<li>6.3 You Should</li>
<ul>	<li>6.3.1 Remember These Definitions</li>
	<li>6.3.2 Remember These Terms</li>
	<li>6.3.3 Remember These Facts</li>
	<li>6.3.4 Use These Procedures</li>
	<li>6.3.5 Be Able to</li>
</ul>
	<li>Problems</li>
<ul>	<li>Estimating the Population Standard Deviation</li>
	<li>Samples and Populations</li>
	<li>Confidence Intervals for Population Means</li>
</ul>
	<li>Programming Exercises</li>
</ul>
	<li>7 The Significance of Evidence</li>
<ul>	<li>7.1 Significance</li>
<ul>	<li>7.1.1 Evaluating Significance</li>
	<li>7.1.2 P-Values</li>
</ul>
	<li>7.2 Comparing the Mean of Two Populations</li>
<ul>	<li>7.2.1 Assuming Known Population Standard Deviations</li>
	<li>7.2.2 Assuming Same, Unknown Population Standard Deviation</li>
	<li>7.2.3 Assuming Different, Unknown Population Standard Deviation</li>
</ul>
	<li>7.3 Other Useful Tests of Significance</li>
<ul>	<li>7.3.1 F-Tests and Standard Deviations</li>
	<li>7.3.2 χ2 Tests of Model Fit</li>
</ul>
	<li>7.4 P-Value Hacking and Other Dangerous Behavior</li>
	<li>7.5 You Should</li>
<ul>	<li>7.5.1 Remember These Definitions</li>
	<li>7.5.2 Remember These Terms</li>
	<li>7.5.3 Remember These Facts</li>
	<li>7.5.4 Use These Procedures</li>
	<li>7.5.5 Be Able to</li>
</ul>
	<li>Problems</li>
<ul>	<li>Fractions of Samples</li>
	<li>Significance</li>
	<li>Chi-Squared Tests</li>
</ul>
</ul>
	<li>8 Experiments</li>
<ul>	<li>8.1 A Simple Experiment: The Effect of a Treatment</li>
<ul>	<li>8.1.1 Randomized Balanced Experiments</li>
	<li>8.1.2 Decomposing Error in Predictions</li>
	<li>8.1.3 Estimating the Noise Variance</li>
	<li>8.1.4 The ANOVA Table</li>
	<li>8.1.5 Unbalanced Experiments</li>
	<li>8.1.6 Significant Differences</li>
</ul>
	<li>8.2 Two Factor Experiments</li>
<ul>	<li>8.2.1 Decomposing the Error</li>
	<li>8.2.2 Interaction Between Effects</li>
	<li>8.2.3 The Effects of a Treatment</li>
	<li>8.2.4 Setting Up An ANOVA Table</li>
</ul>
	<li>8.3 You Should</li>
<ul>	<li>8.3.1 Remember These Definitions</li>
	<li>8.3.2 Remember These Terms</li>
	<li>8.3.3 Remember These Facts</li>
	<li>8.3.4 Use These Procedures</li>
	<li>8.3.5 Be Able to</li>
</ul>
	<li>Problems</li>
<ul>	<li>Decomposing the Squared Error</li>
	<li>Unbalanced One-Way Experiments</li>
	<li>Two-Way Experiments</li>
</ul>
</ul>
	<li>9 Inferring Probability Models from Data</li>
<ul>	<li>9.1 Estimating Model Parameters with Maximum Likelihood</li>
<ul>	<li>9.1.1 The Maximum Likelihood Principle</li>
	<li>9.1.2 Binomial, Geometric and Multinomial Distributions</li>
	<li>9.1.3 Poisson and Normal Distributions</li>
	<li>9.1.4 Confidence Intervals for Model Parameters</li>
	<li>9.1.5 Cautions About Maximum Likelihood</li>
</ul>
	<li>9.2 Incorporating Priors with Bayesian Inference</li>
<ul>	<li>9.2.1 Conjugacy</li>
	<li>9.2.2 MAP Inference</li>
	<li>9.2.3 Cautions About Bayesian Inference</li>
</ul>
	<li>9.3 Bayesian Inference for Normal Distributions</li>
<ul>	<li>9.3.1 Example: Measuring Depth of a Borehole</li>
	<li>9.3.2 Normal Prior and Normal Likelihood Yield Normal Posterior</li>
	<li>9.3.3 Filtering</li>
</ul>
	<li>9.4 You Should</li>
<ul>	<li>9.4.1 Remember These Definitions</li>
	<li>9.4.2 Remember These Terms</li>
	<li>9.4.3 Remember These Facts</li>
	<li>9.4.4 Use These Procedures</li>
	<li>9.4.5 Be Able to</li>
</ul>
	<li>Problems</li>
<ul>	<li>Maximum Likelihood Methods</li>
	<li>Likelihood Functions</li>
	<li>Bayesian Methods</li>
	<li>Bayesian Confidence Intervals</li>
</ul>
	<li>Programming Exercises</li>
<ul>	<li>Simulation and Maximum Likelihood</li>
	<li>Simulation Based Confidence Intervals</li>
	<li>Bayesian Confidence Intervals</li>
</ul>
</ul>
</ul>
	<li>Part IV Tools</li>
<ul>	<li>10 Extracting Important Relationships in High Dimensions</li>
<ul>	<li>10.1 Summaries and Simple Plots</li>
<ul>	<li>10.1.1 The Mean</li>
	<li>10.1.2 Stem Plots and Scatterplot Matrices</li>
	<li>10.1.3 Covariance</li>
	<li>10.1.4 The Covariance Matrix</li>
</ul>
	<li>10.2 Using Mean and Covariance to Understand High Dimensional Data</li>
<ul>	<li>10.2.1 Mean and Covariance Under Affine Transformations</li>
	<li>10.2.2 Eigenvectors and Diagonalization</li>
	<li>10.2.3 Diagonalizing Covariance by Rotating Blobs</li>
	<li>10.2.4 Approximating Blobs</li>
	<li>10.2.5 Example: Transforming the Height-Weight Blob</li>
</ul>
	<li>10.3 Principal Components Analysis</li>
<ul>	<li>10.3.1 The Low Dimensional Representation</li>
	<li>10.3.2 The Error Caused by Reducing Dimension</li>
	<li>10.3.3 Example: Representing Colors with Principal Components</li>
	<li>10.3.4 Example: Representing Faces with Principal Components</li>
</ul>
	<li>10.4 Multi-Dimensional Scaling</li>
<ul>	<li>10.4.1 Choosing Low D Points Using High D Distances</li>
	<li>10.4.2 Factoring a Dot-Product Matrix</li>
	<li>10.4.3 Example: Mapping with Multidimensional Scaling</li>
</ul>
	<li>10.5 Example: Understanding Height and Weight</li>
	<li>10.6 You Should</li>
<ul>	<li>10.6.1 Remember These Definitions</li>
	<li>10.6.2 Remember These Terms</li>
	<li>10.6.3 Remember These Facts</li>
	<li>10.6.4 Use These Procedures</li>
	<li>10.6.5 Be Able to</li>
</ul>
	<li>Problems</li>
<ul>	<li>Summaries</li>
</ul>
	<li>Programming Exercises</li>
</ul>
	<li>11 Learning to Classify</li>
<ul>	<li>11.1 Classification: The Big Ideas</li>
<ul>	<li>11.1.1 The Error Rate, and Other Summaries of Performance</li>
	<li>11.1.2 More Detailed Evaluation</li>
	<li>11.1.3 Overfitting and Cross-Validation</li>
</ul>
	<li>11.2 Classifying with Nearest Neighbors</li>
<ul>	<li>11.2.1 Practical Considerations for Nearest Neighbors</li>
</ul>
	<li>11.3 Classifying with Naive Bayes</li>
<ul>	<li>11.3.1 Cross-Validation to Choose a Model</li>
</ul>
	<li>11.4 The Support Vector Machine</li>
<ul>	<li>11.4.1 The Hinge Loss</li>
	<li>11.4.2 Regularization</li>
	<li>11.4.3 Finding a Classifier with Stochastic Gradient Descent</li>
	<li>11.4.4 Searching for λ</li>
	<li>11.4.5 Example: Training an SVM with Stochastic Gradient Descent</li>
	<li>11.4.6 Multi-Class Classification with SVMs</li>
</ul>
	<li>11.5 Classifying with Random Forests</li>
<ul>	<li>11.5.1 Building a Decision Tree: General Algorithm</li>
	<li>11.5.2 Building a Decision Tree: Choosing a Split</li>
	<li>11.5.3 Forests</li>
</ul>
	<li>11.6 You Should</li>
<ul>	<li>11.6.1 Remember These Definitions</li>
	<li>11.6.2 Remember These Terms</li>
	<li>11.6.3 Remember These Facts</li>
	<li>11.6.4 Use These Procedures</li>
	<li>11.6.5 Be Able to</li>
</ul>
	<li>Programming Exercises</li>
<ul>	<li>MNIST Exercises</li>
</ul>
</ul>
	<li>12 Clustering: Models of High Dimensional Data</li>
<ul>	<li>12.1 The Curse of Dimension</li>
<ul>	<li>12.1.1 Minor Banes of Dimension</li>
	<li>12.1.2 The Curse: Data Isn't Where You Think It Is</li>
</ul>
	<li>12.2 Clustering Data</li>
<ul>	<li>12.2.1 Agglomerative and Divisive Clustering</li>
	<li>12.2.2 Clustering and Distance</li>
</ul>
	<li>12.3 The K-Means Algorithm and Variants</li>
<ul>	<li>12.3.1 How to Choose K</li>
	<li>12.3.2 Soft Assignment</li>
	<li>12.3.3 Efficient Clustering and Hierarchical K Means</li>
	<li>12.3.4 K-Mediods</li>
	<li>12.3.5 Example: Groceries in Portugal</li>
	<li>12.3.6 General Comments on K-Means</li>
</ul>
	<li>12.4 Describing Repetition with Vector Quantization</li>
<ul>	<li>12.4.1 Vector Quantization</li>
	<li>12.4.2 Example: Activity from Accelerometer Data</li>
</ul>
	<li>12.5 The Multivariate Normal Distribution</li>
<ul>	<li>12.5.1 Affine Transformations and Gaussians</li>
	<li>12.5.2 Plotting a 2D Gaussian: Covariance Ellipses</li>
</ul>
	<li>12.6 You Should</li>
<ul>	<li>12.6.1 Remember These Definitions</li>
	<li>12.6.2 Remember These Terms</li>
	<li>12.6.3 Remember These Facts</li>
	<li>12.6.4 Use These Procedures</li>
</ul>
	<li>Programming Exercises</li>
<ul>	<li>CIFAR-10 and Vector Quantization Exercises</li>
</ul>
</ul>
	<li>13 Regression</li>
<ul>	<li>13.1 Regression to Make Predictions</li>
	<li>13.2 Regression to Spot Trends</li>
	<li>13.3 Linear Regression and Least Squares</li>
<ul>	<li>13.3.1 Linear Regression</li>
	<li>13.3.2 Choosing β</li>
	<li>13.3.3 Solving the Least Squares Problem</li>
	<li>13.3.4 Residuals</li>
	<li>13.3.5 R-Squared</li>
</ul>
	<li>13.4 Producing Good Linear Regressions</li>
<ul>	<li>13.4.1 Transforming Variables</li>
	<li>13.4.2 Problem Data Points Have Significant Impact</li>
	<li>13.4.3 Functions of One Explanatory Variable</li>
	<li>13.4.4 Regularizing Linear Regressions</li>
</ul>
	<li>13.5 Exploiting Your Neighbors for Regression</li>
<ul>	<li>13.5.1 Using Your Neighbors to Predict More than a Number</li>
</ul>
	<li>13.6 You Should</li>
<ul>	<li>13.6.1 Remember These Definitions</li>
	<li>13.6.2 Remember These Terms</li>
	<li>13.6.3 Remember These Facts</li>
	<li>13.6.4 Remember These Procedures</li>
</ul>
	<li>Appendix: Data</li>
	<li>Problems</li>
	<li>Programming Exercises</li>
</ul>
	<li>14 Markov Chains and Hidden Markov Models</li>
<ul>	<li>14.1 Markov Chains</li>
<ul>	<li>14.1.1 Transition Probability Matrices</li>
	<li>14.1.2 Stationary Distributions</li>
	<li>14.1.3 Example: Markov Chain Models of Text</li>
</ul>
	<li>14.2 Estimating Properties of Markov Chains</li>
<ul>	<li>14.2.1 Simulation</li>
	<li>14.2.2 Simulation Results as Random Variables</li>
	<li>14.2.3 Simulating Markov Chains</li>
</ul>
	<li>14.3 Example: Ranking the Web by Simulating a Markov Chain</li>
	<li>14.4 Hidden Markov Models and Dynamic Programming</li>
<ul>	<li>14.4.1 Hidden Markov Models</li>
	<li>14.4.2 Picturing Inference with a Trellis</li>
	<li>14.4.3 Dynamic Programming for HMM's: Formalities</li>
	<li>14.4.4 Example: Simple Communication Errors</li>
</ul>
	<li>14.5 You Should</li>
<ul>	<li>14.5.1 Remember These Definitions</li>
	<li>14.5.2 Remember These Terms</li>
	<li>14.5.3 Remember These Facts</li>
	<li>14.5.4 Be Able to</li>
</ul>
	<li>Problems</li>
	<li>Programming Exercises</li>
</ul>
</ul>
	<li>Part V Mathematical Bits and Pieces</li>
<ul>	<li>15 Resources and Extras</li>
<ul>	<li>15.1 Useful Material About Matrices</li>
<ul>	<li>15.1.1 The Singular Value Decomposition</li>
	<li>15.1.2 Approximating A Symmetric Matrix</li>
</ul>
	<li>15.2 Some Special Functions</li>
	<li>15.3 Splitting a Node in a Decision Tree</li>
<ul>	<li>15.3.1 Accounting for Information with Entropy</li>
	<li>15.3.2 Choosing a Split with Information Gain</li>
</ul>
</ul>
</ul>
	<li>Index</li>
</ul>
</body></html>